[[(100210, 0), [['For example:'], ['results in the two values, three seconds apart:']], [[' import datetime\na = datetime.datetime(100,1,1,11,34,59)\nb = a + datetime.timedelta(0,3) # days, seconds, then other fields.\nprint a.time()\nprint b.time()\n']], ['What is the standard way to add N seconds to datetime.time in Python?'], 5, 1], [(100210, 1), [['results in the two values, three seconds apart:'], ['You could also opt for the more readable']], [[' 11:34:59\n11:35:02\n']], ['What is the standard way to add N seconds to datetime.time in Python?'], 5, 0], [(100210, 3), [["If you're after a function that can do this, you can look into using  addSecs  below:"], ['This outputs:']], [[' import datetime\n\ndef addSecs(tm, secs):\n    fulldate = datetime.datetime(100, 1, 1, tm.hour, tm.minute, tm.second)\n    fulldate = fulldate + datetime.timedelta(seconds=secs)\n    return fulldate.time()\n\na = datetime.datetime.now().time()\nb = addSecs(a, 300)\nprint a\nprint b\n']], ['What is the standard way to add N seconds to datetime.time in Python?'], 5, 1], [(100210, 4), [['This outputs:'], ['-10000']], [['  09:11:55.775695\n 09:16:55\n']], ['What is the standard way to add N seconds to datetime.time in Python?'], 5, 0], [(121025, 0), [['-10000'], ['or']], [[' os.path.getmtime(filepath)\n']], ['How do I get the modified date/time of a file in Python?'], 2, 1], [(121025, 1), [['or'], ['-10000']], [[' os.stat(filepath).st_mtime\n']], ['How do I get the modified date/time of a file in Python?'], 2, 1], [(168409, 0), [["Here's a more verbose version of  @Greg Hewgill 's answer . It is the most conforming to the question requirements. It makes a distinction between creation and modification dates (at least on Windows)."], ['Example:']], [[" #!/usr/bin/env python\nfrom stat import S_ISREG, ST_CTIME, ST_MODE\nimport os, sys, time\n\n# path to the directory (relative or absolute)\ndirpath = sys.argv[1] if len(sys.argv) == 2 else r'.'\n\n# get all entries in the directory w/ stats\nentries = (os.path.join(dirpath, fn) for fn in os.listdir(dirpath))\nentries = ((os.stat(path), path) for path in entries)\n\n# leave only regular files, insert creation date\nentries = ((stat[ST_CTIME], path)\n           for stat, path in entries if S_ISREG(stat[ST_MODE]))\n#NOTE: on Windows `ST_CTIME` is a creation date \n#  but on Unix it could be something else\n#NOTE: use `ST_MTIME` to sort by a modification date\n\nfor cdate, path in sorted(entries):\n    print time.ctime(cdate), os.path.basename(path)\n"]], ['How do you get a directory listing sorted by creation date in python?'], 2, 1], [(168409, 1), [['Example:'], ['-10000']], [[' $ python stat_creation_date.py\nThu Feb 11 13:31:07 2009 stat_creation_date.py\n']], ['How do you get a directory listing sorted by creation date in python?'], 2, 0], [(187273, 1), [["_bin(x, 8) will now give a zero padded representation of x's lower 8 bits.  This can be used to build a lookup table, allowing your converter to process 8 bits at a time (or more if you want to devote the memory to it)."], ["Then you can use this in your real function, stripping off leading zeroes when returning it.  I've also added handling for signed numbers, as without it you will get an infinite loop (Negative integers conceptually have an infinite number of set sign bits.)"]], [[' _conv_table = [_bin(x,8) for x in range(256)]\n']], ['Base-2 (Binary) Representation Using Python'], 4, 0], [(187273, 2), [["Then you can use this in your real function, stripping off leading zeroes when returning it.  I've also added handling for signed numbers, as without it you will get an infinite loop (Negative integers conceptually have an infinite number of set sign bits.)"], ["[Edit] Changed code to handle signed integers. \n[Edit2] Here are some timing figures of the various solutions.  bin is the function above, constantin_bin is from  Constantin's answer  and num_bin is the original version.  Out of curiosity, I also tried a 16 bit lookup table variant of the above (bin16 below), and tried out Python3's builtin bin() function.  All timings were for 100000 runs using an 01010101 bit pattern."]], [[' def bin(x):\n    if x == 0: \n        return \'0\' #Special case: Don\'t strip leading zero if no other digits\n    elif x < 0:\n        sign=\'-\'\n        x*=-1\n    else:\n        sign = \'\'\n    l=[]\n    while x:\n        l.append(_conv_table[x & 0xff])\n        x >>= 8\n    return sign + \'\'.join(reversed(l)).lstrip("0")\n']], ['Base-2 (Binary) Representation Using Python'], 4, 0], [(187273, 3), [["[Edit] Changed code to handle signed integers. \n[Edit2] Here are some timing figures of the various solutions.  bin is the function above, constantin_bin is from  Constantin's answer  and num_bin is the original version.  Out of curiosity, I also tried a 16 bit lookup table variant of the above (bin16 below), and tried out Python3's builtin bin() function.  All timings were for 100000 runs using an 01010101 bit pattern."], ["As you can see, when processing long values using large chunks really pays off, but nothing beats the low-level C code of python3's builtin (which bizarrely seems consistently faster at 256 bits than 128!).  Using a 16 bit lookup table improves things, but probably isn't worth it unless you really need it, as it uses up a large chunk of memory, and can introduce a small but noticalbe startup delay to precompute the table."]], [[" Num Bits:              8       16       32       64      128      256\n---------------------------------------------------------------------\nbin                0.544    0.586    0.744    1.942    1.854    3.357 \nbin16              0.542    0.494    0.592    0.773    1.150    1.886\nconstantin_bin     2.238    3.803    7.794   17.869   34.636   94.799\nnum_bin            3.712    5.693   12.086   32.566   67.523  128.565\nPython3's bin      0.079    0.045    0.062    0.069    0.212    0.201 \n"]], ['Base-2 (Binary) Representation Using Python'], 4, 0], [(227461, 1), [['This example adds line numbers to your file:'], ['-10000']], [[' import fileinput\n\nfor line in fileinput.input ("b.txt",inplace=1):\n    print "%d: %s" % (fileinput.lineno(),line),\n']], ['Open file, read it, process, and write back - shortest method in Python'], 2, 1], [(296055, 0), [['Update:  The first response( below) does not accept parameters. So put this snippet at the end of the ipy_user_conf.py file ( it is in your home directory ).'], ['Before update: \nDoes it has to be %magic?\nYou can use the macro and store magic to reproduce this behavior without the magic %.']], [[' def ed_xed(self,arg):\n    ip = self.api\n    return ip.magic.im_class.magic_edit(ip.IP," -x %s "%arg)\n\nip.expose_magic(\'xed\',ed_xed)\n']], ['In IPython how do I create aliases for %magics?'], 2, 1], [(296055, 1), [['Before update: \nDoes it has to be %magic?\nYou can use the macro and store magic to reproduce this behavior without the magic %.'], ['for magic alias from the documentation ( %magic? ):']], [[' In [5]: %edit -x\nIn [6]: macro xed 5\nIn [7]: store xed\nIn [8]: xed\n']], ['In IPython how do I create aliases for %magics?'], 2, 0], [(296499, 0), [['Adapted version of  the script  is:'], ['Example:']], [[' #!/usr/bin/env python\nfrom __future__ import with_statement\nfrom contextlib import closing\nfrom zipfile import ZipFile, ZIP_DEFLATED\nimport os\n\ndef zipdir(basedir, archivename):\n    assert os.path.isdir(basedir)\n    with closing(ZipFile(archivename, "w", ZIP_DEFLATED)) as z:\n        for root, dirs, files in os.walk(basedir):\n            #NOTE: ignore empty directories\n            for fn in files:\n                absfn = os.path.join(root, fn)\n                zfn = absfn[len(basedir)+len(os.sep):] #XXX: relative path\n                z.write(absfn, zfn)\n\nif __name__ == \'__main__\':\n    import sys\n    basedir = sys.argv[1]\n    archivename = sys.argv[2]\n    zipdir(basedir, archivename)\n']], ['How do I zip the contents of a folder using python (version 2.5)?'], 2, 1], [(296499, 1), [['Example:'], ["It creates  'C:\\zipdir\\test.zip'  archive with the contents of the  'c:\\tmp\\test'  directory."]], [[' C:\\zipdir> python -mzipdir c:\\tmp\\test test.zip\n']], ['How do I zip the contents of a folder using python (version 2.5)?'], 2, 0], [(324214, 0), [['-10000'], ['-10000']], [[' for event, elem in iterparse(source):\n    if elem.tag == "record":\n        ... process record elements ...\n        elem.clear()\n']], ['What is the fastest way to parse large XML docs in Python?'], 2, 1], [(324214, 1), [['-10000'], ['The  lxml.iterparse()  does not allow this.']], [[' # get an iterable\ncontext = iterparse(source, events=("start", "end"))\n\n# turn it into an iterator\ncontext = iter(context)\n\n# get the root element\nevent, root = context.next()\n\nfor event, elem in context:\n    if event == "end" and elem.tag == "record":\n        ... process record elements ...\n        root.clear()\n']], ['What is the fastest way to parse large XML docs in Python?'], 2, 1], [(359903, 1), [['Which would look like...'], ['...in production code.']], [[' if a.count( a[0] ) != len(a)\n']], ['Comparing List of Arguments to it self?'], 2, 1], [(409732, 0), [['-10000'], ['or']], [[' bool_list[:] = [False] * len(bool_list)\n']], ['Python: Alter elements of a list'], 2, 1], [(409732, 1), [['or'], ['-10000']], [[' bool_list[:] = [False for item in bool_list]\n']], ['Python: Alter elements of a list'], 2, 1], [(465144, 1), [["Convert the documents to background-transparent PNGs with ImageMagick's  convert :"], ['-10000']], [[' $ convert -background none input.svg output.png\n']], ['Tools for creating text as bitmaps (anti-aliased text, custom spacing, transparent background)'], 2, 0], [(508657, 0), [['You can create it using nested lists:'], ["If it has to be dynamic it's more complicated, why not write a small class yourself?"]], [[' matrix = [[a,b],[c,d],[e,f]]\n']], ['Multidimensional array in Python'], 5, 1], [(508657, 1), [["If it has to be dynamic it's more complicated, why not write a small class yourself?"], ['This can be used like this:']], [[' class Matrix(object):\n    def __init__(self, rows, columns, default=0):\n        self.m = []\n        for i in range(rows):\n            self.m.append([default for j in range(columns)])\n\n    def __getitem__(self, index):\n        return self.m[index]\n']], ['Multidimensional array in Python'], 5, 1], [(508657, 2), [['This can be used like this:'], ["If you need multidimensional arrays you can either create an array and calculate the offset or you'd use arrays in arrays in arrays, which can be pretty bad for memory. (Could be faster though…) I've implemented the first idea like this:"]], [[' m = Matrix(10,5)\nm[3][6] = 7\nprint m[3][6] // -> 7\n']], ['Multidimensional array in Python'], 5, 0], [(508657, 3), [["If you need multidimensional arrays you can either create an array and calculate the offset or you'd use arrays in arrays in arrays, which can be pretty bad for memory. (Could be faster though…) I've implemented the first idea like this:"], ['Can be used like this:']], [[' class Matrix(object):\n    def __init__(self, *dims):\n        self._shortcuts = [i for i in self._create_shortcuts(dims)]\n        self._li = [None] * (self._shortcuts.pop())\n        self._shortcuts.reverse()\n\n    def _create_shortcuts(self, dims):\n        dimList = list(dims)\n        dimList.reverse()\n        number = 1\n        yield 1\n        for i in dimList:\n            number *= i\n            yield number\n\n    def _flat_index(self, index):\n        if len(index) != len(self._shortcuts):\n            raise TypeError()\n\n        flatIndex = 0\n        for i, num in enumerate(index):\n            flatIndex += num * self._shortcuts[i]\n        return flatIndex\n\n    def __getitem__(self, index):\n        return self._li[self._flat_index(index)]\n\n    def __setitem__(self, index, value):\n        self._li[self._flat_index(index)] = value\n']], ['Multidimensional array in Python'], 5, 1], [(508657, 4), [['Can be used like this:'], ['-10000']], [[" m = Matrix(4,5,2,6)\nm[2,3,1,3] = 'x'\nm[2,3,1,3] // -> 'x'\n"]], ['Multidimensional array in Python'], 5, 0], [(519633, 0), [['To write a lazy function, just use  yield :'], ['-10000']], [[' def read_in_chunks(file_object, chunk_size=1024):\n    """Lazy function (generator) to read a file piece by piece.\n    Default chunk size: 1k."""\n    while True:\n        data = file_object.read(chunk_size)\n        if not data:\n            break\n        yield data\n\n\nf = open(\'really_big_file.dat\')\nfor piece in read_in_chunks(f):\n    process_data(piece)\n']], ['Lazy Method for Reading Big File in Python?'], 3, 1], [(519633, 1), [['-10000'], ['-10000']], [[" f = open('really_big_file.dat')\ndef read1k():\n    return f.read(1024)\n\nfor piece in iter(read1k, ''):\n    process_data(piece)\n"]], ['Lazy Method for Reading Big File in Python?'], 3, 1], [(544923, 0), [['Ok, I figured this out.  The answer is:  \n \n 1. you need a local printer (if you need to print to a network printer, download the drivers and add it as a local printer) \n 2. use win32print to get and set default printer \n 3. also using win32print, use the following code: \n'], ['-10000']], [[' import win32print\nPRINTER_DEFAULTS = {"DesiredAccess":win32print.PRINTER_ALL_ACCESS}\npHandle = win32print.OpenPrinter(\'RICOH-LOCAL\', PRINTER_DEFAULTS)\nproperties = win32print.GetPrinter(pHandle, 2) #get the properties\npDevModeObj = properties["pDevMode"] #get the devmode\nautomaticTray = 7\ntray_one = 1\ntray_two = 3\ntray_three = 2\nprinter_tray = []\npDevModeObj.DefaultSource = tray_three #set the tray\nproperties["pDevMode"]=pDevModeObj #write the devmode back to properties\nwin32print.SetPrinter(pHandle,2,properties,0) #save the properties to the printer\n']], ['Switching Printer Trays'], 2, 0], [(544923, 1), [['-10000'], ['-10000']], [[' from win32com import client\n    import time\n    ie = client.Dispatch("InternetExplorer.Application")\n    def printPDFDocument(filename):\n        ie.Navigate(filename)\n        if ie.Busy:\n            time.sleep(1)\n        ie.Document.printAll()\n    ie.Quit()\n']], ['Switching Printer Trays'], 2, 0], [(555344, 0), [['-10000'], ['or even shorter:']], [[' paren_pattern = re.compile(r"\\(([^()]*)\\)(?=(?:\\s*\\([^()]*\\))*\\s*$)")\n\ndef getParens(s):\n  return paren_pattern.findall(s)\n']], ['Match series of (non-nested) balanced parentheses at end of string'], 3, 1], [(555344, 1), [['or even shorter:'], ['explaination:']], [[' getParens = re.compile(r"\\(([^()]*)\\)(?=(?:\\s*\\([^()]*\\))*\\s*$)").findall\n']], ['Match series of (non-nested) balanced parentheses at end of string'], 3, 1], [(555344, 2), [['explaination:'], ['-10000']], [[' \\(                     # opening paren\n([^()]*)               # content, captured into group 1\n\\)                     # closing paren\n(?=                    # look ahead for...\n  (?:\\s*\\([^()]*\\))*   #   a series of parens, separated by whitespace\n  \\s*                  #   possibly more whitespace after\n  $                    #   end of string\n)                      # end of look ahead\n']], ['Match series of (non-nested) balanced parentheses at end of string'], 3, 0], [(572263, 0), [["Here's what I ended up doing. I wrote a custom template stringfilter to switch the tags around. Now, my template code looks like this:"], ["Here's a functional but ugly implementation of  pretty_checkbox  - this code doesn't have any error handling, it assumes that the Django generated attributes are formatted in a very specific way, and it would be a bad idea to use anything like this in your code:"]], [[' {% load pretty_forms %}\n<form action="." method="POST">\n{{ form.as_p|pretty_checkbox }}\n<p><input type="submit" value="Submit"></p>\n</form>\n']], ['How do I create a Django form that displays a checkbox label to the right of the checkbox?'], 2, 0], [(582723, 0), [["Your ' lib/__init__.py ' might look like this:"], ['-10000']], [[" from . import settings # or just 'import settings' on old Python versions\nclass Helper(object):\n      pass\n"]], ['How to import classes defined in __init__.py'], 4, 0], [(582723, 1), [['-10000'], ['-10000']], [[' from lib.settings import Values\nfrom lib import Helper\n']], ['How to import classes defined in __init__.py'], 4, 0], [(582723, 2), [['-10000'], ['Output:']], [[' $ python import_submodule.py\n']], ['How to import classes defined in __init__.py'], 4, 0], [(582723, 3), [['Output:'], ['-10000']], [[' settings\nhelper\nHelper in lib.settings\nsomeobject\nHelper in lib.foo.someobject\n\n# ./import_submodule.py\nimport fnmatch, os\nfrom lib.settings import Values\nfrom lib import Helper\n\nprint\nfor root, dirs, files in os.walk(\'.\'):\n    for f in fnmatch.filter(files, \'*.py\'):\n        print "# %s/%s" % (os.path.basename(root), f)\n        print open(os.path.join(root, f)).read()\n        print\n\n\n# lib/helper.py\nprint \'helper\'\nclass Helper(object):\n    def __init__(self, module_name):\n        print "Helper in", module_name\n\n\n# lib/settings.py\nprint "settings"\nimport helper\n\nclass Values(object):\n    pass\n\nhelper.Helper(__name__)\n\n\n# lib/__init__.py\n#from __future__ import absolute_import\nimport settings, foo.someobject, helper\n\nHelper = helper.Helper\n\n\n# foo/someobject.py\nprint "someobject"\nfrom .. import helper\n\nhelper.Helper(__name__)\n\n\n# foo/__init__.py\nimport someobject\n']], ['How to import classes defined in __init__.py'], 4, 0], [(645864, 0), [['Briefly, I have an xdir.py file, which writes Windows commands to stdout:'], ['Then an xdir.cmd file:']], [[' # Obviously, this should be more interesting..\nimport sys\nprint "cd", sys.argv[1]\n']], ['Changing prompt working directory via Python script'], 4, 0], [(645864, 1), [['Then an xdir.cmd file:'], ['Then I create a doskey alias:']], [[' @echo off\npython xdir.py %* >%TEMP%\\__xdir.cmd\ncall %TEMP%\\__xdir.cmd\n']], ['Changing prompt working directory via Python script'], 4, 0], [(645864, 2), [['Then I create a doskey alias:'], ['The end result is that I can type']], [[' doskey x=xdir.cmd $*\n']], ['Changing prompt working directory via Python script'], 4, 0], [(645864, 3), [['The end result is that I can type'], ['and change into subdir.']], [[' $ x subdir\n']], ['Changing prompt working directory via Python script'], 4, 0], [(682504, 0), [['Actually  None  is much better for "magic" values:'], ['Now if you want complete freedom of adding more parameters:']], [[' class Cheese():\n    def __init__(self, num_holes = None):\n        if num_holes is None:\n            ...\n']], ['What is a clean, pythonic way to have multiple constructors in Python?'], 3, 1], [(682504, 1), [['Now if you want complete freedom of adding more parameters:'], ['To better explain the concept of  *args  and  **kwargs  (you can actually change these names):']], [[" class Cheese():\n    def __init__(self, *args, **kwargs):\n        #args -- tuple of anonymous arguments\n        #kwargs -- dictionary of named arguments\n        self.num_holes = kwargs.get('num_holes',random_holes())\n"]], ['What is a clean, pythonic way to have multiple constructors in Python?'], 3, 1], [(682504, 2), [['To better explain the concept of  *args  and  **kwargs  (you can actually change these names):'], ['http://docs.python.org/reference/expressions.html#calls']], [[" def f(*args, **kwargs):\n   print 'args: ', args, ' kwargs: ', kwargs\n\n>>> f('a')\nargs:  ('a',)  kwargs:  {}\n>>> f(ar='a')\nargs:  ()  kwargs:  {'ar': 'a'}\n>>> f(1,2,param=3)\nargs:  (1, 2)  kwargs:  {'param': 3}\n"]], ['What is a clean, pythonic way to have multiple constructors in Python?'], 3, 0], [(706755, 1), [['-10000'], ['I am leaving this as the correct answer, since it got me pointed in the right direction.']], [[' conn = MySQLdb(host...)\n\nc = conn.cursor()\nc.execute("INSERT INTO...")\nnewID = c.lastrowid\n']], ['How do you safely and efficiently get the row id after an insert with mysql using MySQLdb in python?'], 2, 1], [(706813, 0), [['You could do it this way:'], ['You can of course pass some variables in the method() call too:']], [[" def method1(name):\n    def wrapper():\n        return 'Hello ' + name\n    return wrapper\n\ndef method2(method, question):\n    output = method()\n    return output + ', ' + question\n\nmethod2(method1(name = 'Sam'), 'How are you?')\n"]], ['What is the best way to pass a method (with parameters) to another method in python'], 2, 1], [(706813, 1), [['You can of course pass some variables in the method() call too:'], ['-10000']], [[" def method1(name):\n    def wrapper(greeting):\n        return greeting + name\n    return wrapper\n\ndef method2(method, question):\n    output = method(greeting = 'Hello ')\n    return output + ', ' + question\n\nmethod2(method1(name = 'Sam'), 'How are you?')\n"]], ['What is the best way to pass a method (with parameters) to another method in python'], 2, 1], [(765305, 0), [['The simplest was is to simply catch the IOError exception from urllib:'], ['Also, from  this blog post - "check status proxy address"  (with some slight improvements):']], [[' try:\n    urllib.urlopen(\n        "http://example.com",\n        proxies={\'http\':\'http://example.com:8080\'}\n    )\nexcept IOError:\n    print "Connection error! (Check proxy)"\nelse:\n    print "All was fine"\n']], ['Proxy Check in python'], 2, 1], [(765305, 1), [['Also, from  this blog post - "check status proxy address"  (with some slight improvements):'], ['Remember this could double the time the script takes, if the proxy is down (as you will have to wait for two connection-timeouts).. Unless you specifically have to know the proxy is at fault, handling the IOError is far cleaner, simpler and quicker..']], [[' import urllib2\nimport socket\n\ndef is_bad_proxy(pip):    \n    try:\n        proxy_handler = urllib2.ProxyHandler({\'http\': pip})\n        opener = urllib2.build_opener(proxy_handler)\n        opener.addheaders = [(\'User-agent\', \'Mozilla/5.0\')]\n        urllib2.install_opener(opener)\n        req=urllib2.Request(\'http://www.example.com\')  # change the URL to test here\n        sock=urllib2.urlopen(req)\n    except urllib2.HTTPError, e:\n        print \'Error code: \', e.code\n        return e.code\n    except Exception, detail:\n        print "ERROR:", detail\n        return True\n    return False\n\ndef main():\n    socket.setdefaulttimeout(120)\n\n    # two sample proxy IPs\n    proxyList = [\'125.76.226.9:80\', \'213.55.87.162:6588\']\n\n    for currentProxy in proxyList:\n        if is_bad_proxy(currentProxy):\n            print "Bad Proxy %s" % (currentProxy)\n        else:\n            print "%s is working" % (currentProxy)\n\nif __name__ == \'__main__\':\n    main()\n']], ['Proxy Check in python'], 2, 1], [(870652, 0), [['Something like:'], ['Full example:']], [[' zip(t[::2], t[1::2])\n']], ['Pythonic way to split comma separated numbers into pairs'], 2, 1], [(870652, 1), [['Full example:'], ['If the number of items is odd, the last element will be ignored.  Only complete pairs will be included.']], [[" >>> s = ','.join(str(i) for i in range(10))\n>>> s\n'0,1,2,3,4,5,6,7,8,9'\n>>> t = [int(i) for i in s.split(',')]\n>>> t\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n>>> p = zip(t[::2], t[1::2])\n>>> p\n[(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)]\n>>>\n"]], ['Pythonic way to split comma separated numbers into pairs'], 2, 1], [(897362, 0), [['Use  map  only for functions without side effects (like  print ). That is, use it only for functions that just return something. In this case a regular loop is more idiomatic:'], ['File  map.py :']], [[' for f in lst:\n    f("event_info")\n']], ['What is the idiomatic way of invoking a list of functions in Python?'], 3, 1], [(897362, 1), [['File  map.py :'], ['2to3-3.0 map.py  output:']], [[' map(lambda x: x, range(10))\n']], ['What is the idiomatic way of invoking a list of functions in Python?'], 3, 0], [(897362, 2), [['2to3-3.0 map.py  output:'], ['-10000']], [[' RefactoringTool: Skipping implicit fixer: buffer\nRefactoringTool: Skipping implicit fixer: idioms\nRefactoringTool: Skipping implicit fixer: set_literal\nRefactoringTool: Skipping implicit fixer: ws_comma\n--- map.py (original)\n+++ map.py (refactored)\n@@ -1,1 +1,1 @@\n-map(lambda x: x, range(10))\n+list(map(lambda x: x, list(range(10))))\nRefactoringTool: Files that need to be modified:\nRefactoringTool: map.py\nRefactoringTool: Warnings/messages while refactoring:\nRefactoringTool: ### In file map.py ###\nRefactoringTool: Line 1: You should use a for loop here\n']], ['What is the idiomatic way of invoking a list of functions in Python?'], 3, 0], [(899138, 0), [['Basically, you create a Function interface:'], ['Your method could either apply the function to each element in-place:']], [[' public interface Func<In, Out> {\n    public Out apply(In in);\n}\n']], ['Python-like list comprehension in Java'], 3, 0], [(899138, 1), [['Your method could either apply the function to each element in-place:'], ['or create a new  List  (basically creating a mapping from the input list to the output list):']], [[' public static <T> void applyToListInPlace(List<T> list, Func<T, T> f) {\n    ListIterator<T> itr = list.listIterator();\n    while (itr.hasNext()) {\n        T output = f.apply(itr.next());\n        itr.set(output);\n    }\n}\n// ...\nList<String> myList = ...;\napplyToListInPlace(myList, new Func<String, String>() {\n    public String apply(String in) {\n        return in.toLowerCase();\n    }\n});\n']], ['Python-like list comprehension in Java'], 3, 0], [(899138, 2), [['or create a new  List  (basically creating a mapping from the input list to the output list):'], ['Which one is preferable depends on your use case. If your list is extremely large, the in-place solution may be the only viable one; if you wish to apply many different functions to the same original list to make many derivative lists, you will want the  map  version.']], [[' public static <In, Out> List<Out> map(List<In> in, Func<In, Out> f) {\n    List<Out> out = new ArrayList<Out>(in.size());\n    for (In inObj : in) {\n        out.add(f.apply(inObj));\n    }\n    return out;\n}\n// ...\nList<String> myList = ...;\nList<String> lowerCased = map(myList, new Func<String, String>() {\n    public String apply(String in) {\n        return in.toLowerCase();\n    }\n});\n']], ['Python-like list comprehension in Java'], 3, 0], [(933612, 0), [['Just cut your view code to this line:'], ['And do this in the template:']], [[' entries = Entry.objects.filter(user=request.user).order_by("-timestamp")\n']], ['What is the best way to fetch/render one-to-many relationships?'], 6, 0], [(933612, 1), [['And do this in the template:'], ['I am a big fan of using  related_name  in Models, however, so you could change this line:']], [[' {% for entry in entries %}\n    <td>{{ entry.datadesc }}</td>\n    <td><table>\n    {% for file in entry.entryfile_set.all %}\n        <td>{{ file.datafile.name|split:"/"|last }}</td>\n        <td>{{ file.datafile.size|filesizeformat }}</td>\n        <td><a href="{{ object.datafile.url }}">download</a></td>\n        <td><a href="{% url main.views.delete object.id %}">delete</a></td>\n    {% endfor %}\n    </table></td>\n{% endfor %}\n']], ['What is the best way to fetch/render one-to-many relationships?'], 6, 0], [(933612, 2), [['I am a big fan of using  related_name  in Models, however, so you could change this line:'], ['To this:']], [[' entry = models.ForeignKey(Entry)\n']], ['What is the best way to fetch/render one-to-many relationships?'], 6, 0], [(933612, 3), [['To this:'], ['And then you can access all the files for a particular entry by changing this:']], [[" entry = models.ForeignKey(Entry, related_name='files')\n"]], ['What is the best way to fetch/render one-to-many relationships?'], 6, 0], [(933612, 4), [['And then you can access all the files for a particular entry by changing this:'], ['To the more readable/obvious:']], [[' {% for file in files.entryfile_set.all %}\n']], ['What is the best way to fetch/render one-to-many relationships?'], 6, 0], [(933612, 5), [['To the more readable/obvious:'], ['-10000']], [[' {% for file in entry.files.all %}\n']], ['What is the best way to fetch/render one-to-many relationships?'], 6, 0], [(956820, 0), [['You could define a little inline function:'], ['then']], [[' def EntryMatches(e):\n  if use_currency and not (e.currency == currency):\n    return False\n  if use_category and not (e.category == category):\n    return False\n  return True\n']], ['Iterating through large lists with potential conditions in Python'], 2, 0], [(956820, 1), [['then'], ['EntryMatches() will have access to all variables in enclosing scope, so no need to pass in any more arguments. You get the advantage that all of the logic for which entries to use is in one place, you still get to use the list comprehension to make the sum() more readable, but you can have arbitrary logic in EntryMatches() now.']], [[" totals['quantity'] = sum([e.quantity for e in entries if EntryMatches(e)])\n"]], ['Iterating through large lists with potential conditions in Python'], 2, 0], [(973481, 0), [["Setup your environment (I'm using the SQLite in-memory db to test):"], ['Define your table:']], [[" >>> from sqlalchemy import create_engine\n>>> engine = create_engine('sqlite:///:memory:', echo=True)\n>>> from sqlalchemy import Table, Column, Integer, String, MetaData\n>>> metadata = MetaData()\n"]], ['Dynamic Table Creation and ORM mapping in SqlAlchemy'], 5, 0], [(973481, 1), [['Define your table:'], ['Define your class:']], [[" >>> players_table = Table('players', metadata,\n...   Column('id', Integer, primary_key=True),\n...   Column('name', String),\n...   Column('score', Integer)\n... )\n>>> metadata.create_all(engine) # create the table\n"]], ['Dynamic Table Creation and ORM mapping in SqlAlchemy'], 5, 0], [(973481, 2), [['Define your class:'], ['Map the class to your table:']], [[' >>> class Player(object):\n...     def __init__(self, name, score):\n...         self.name = name\n...         self.score = score\n...\n...     def __repr__(self):\n...        return "<Player(\'%s\',\'%s\')>" % (self.name, self.score)\n']], ['Dynamic Table Creation and ORM mapping in SqlAlchemy'], 5, 0], [(973481, 3), [['Map the class to your table:'], ['Create a player:']], [[' >>> from sqlalchemy.orm import mapper\n>>> mapper(Player, players_table) \n<Mapper at 0x...; Player>\n']], ['Dynamic Table Creation and ORM mapping in SqlAlchemy'], 5, 0], [(973481, 4), [['Create a player:'], ["That's it, you now have a your player table.   \nAlso, the SqlAlchemy googlegroup is great.   \nMike Bayer is very quick to answer questions."]], [[" >>> a_player = Player('monty', 0)\n>>> a_player.name\n'monty'\n>>> a_player.score\n0\n"]], ['Dynamic Table Creation and ORM mapping in SqlAlchemy'], 5, 0], [(1008038, 0), [['Aha!! I have solved this by first attempting to remove the function from the stream: '], ['and then adding the updated/new version:']], [[' stream = stream | Transformer(\'.//head/script["functionName()"]\').remove()\n']], ['How do I test if a string exists in a Genshi stream?'], 2, 0], [(1008038, 1), [['and then adding the updated/new version:'], ['-10000']], [[' stream = stream | Transformer(\'.//head\').append(tag.script(functionNameCode, type="text/javascript"))\n']], ['How do I test if a string exists in a Genshi stream?'], 2, 0], [(1029207, 0), [['The UnivariateSpline class in scipy makes doing splines much more pythonic.'], ['To find x at y then do:']], [[" x = [70, 80, 90, 100, 110]\ny = [49.7, 80.6, 122.5, 153.8, 163.0]\nf = interpolate.UnivariateSpline(x, y, s=0)\nxnew = np.arange(70,111,1)\n\nplt.plot(x,y,'x',xnew,f(xnew))\n"]], ['Interpolation in SciPy: Finding X that produces Y'], 2, 0], [(1042751, 0), [['One idea would be something like this (untested):'], ['Or this, which fits your data better.']], [[" years, months, days = the_string.split('-')\ndays, time = days.split(' ')\ntime = time.split(':')\n"]], ['Splitting a string @ once using different seps'], 2, 1], [(1042751, 1), [['Or this, which fits your data better.'], ['-10000']], [[' date, time = the_string.split(\' \')\nyears, months, days = date.split(\'-\')\nhours, minute, seconds = time.split(":")\n']], ['Splitting a string @ once using different seps'], 2, 1], [(1060193, 0), [['In this case, you need to make your function return the decorator. (Anything can be solved by another level of indirection...)'], ["This means  substitute_args  isn't a decorator itself, it's a decorator  factory . Here's the equivalent without the  decorator  module."]], [[' from decorator import decorator\ndef substitute_args(arg_sub_dict):\n  @decorator\n  def wrapper(fun, arg):\n    new_arg = arg_sub_dict.get(arg, arg)\n    return fun(new_arg)\n  return wrapper\n']], ['Python Decorator 3.0 and arguments to the decorator'], 4, 1], [(1060193, 2), [["Three levels deep isn't very convenient, but remember two of them are when the function is defined:"], ['Which is equivalent to:']], [[' @substitute_args({}) # this function is called and return value is the decorator\ndef f(x):\n  return x\n# that (anonymous) decorator is applied to f\n']], ['Python Decorator 3.0 and arguments to the decorator'], 4, 0], [(1060193, 3), [['Which is equivalent to:'], ['-10000']], [[' def f(x):\n  return x\nf = substitude_args({})(f) # notice the double call\n']], ['Python Decorator 3.0 and arguments to the decorator'], 4, 0], [(1123337, 1), [['You could then wrap a model in this way:'], ['etc...']], [[' modelDict = DictModelAdaptor(DictModel)\nmodelDict["name"] = "Bob Jones"\n']], ["Django: Converting an entire set of a Model's objects into a single dictionary"], 2, 0], [(1144702, 0), [["You can use the  setattr  function, which takes three arguments: the object, the name of the attribute, and it's value. For example,"], ['is equivalent to:']], [[" setattr(self, 'wavelength', wavelength_val)\n"]], ['Using Eval in Python to create class variables'], 3, 0], [(1144702, 1), [['is equivalent to:'], ['So you could do something like this:']], [[' self.wavelength = wavelength_val\n']], ['Using Eval in Python to create class variables'], 3, 0], [(1144702, 2), [['So you could do something like this:'], ['-10000']], [[" for variable in self.variable_list:\n       var_type,var_text_ctrl,var_name = variable\n       if var_type == 'f' :\n           setattr(self, var_name, var_text_ctrl.GetValue())\n"]], ['Using Eval in Python to create class variables'], 3, 1], [(1175208, 0), [['This is pretty thorough:'], ["Works with all these (and doesn't harm already-un-cameled versions):"]], [[" def convert(name):\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n"]], ['Elegant Python function to convert CamelCase to snake_case?'], 4, 1], [(1175208, 1), [["Works with all these (and doesn't harm already-un-cameled versions):"], ["Or if you're going to call it a zillion times, you can pre-compile the regexes:"]], [[" >>> convert('CamelCase')\n'camel_case'\n>>> convert('CamelCamelCase')\n'camel_camel_case'\n>>> convert('Camel2Camel2Case')\n'camel2_camel2_case'\n>>> convert('getHTTPResponseCode')\n'get_http_response_code'\n>>> convert('get2HTTPResponseCode')\n'get2_http_response_code'\n>>> convert('HTTPResponseCode')\n'http_response_code'\n>>> convert('HTTPResponseCodeXYZ')\n'http_response_code_xyz'\n"]], ['Elegant Python function to convert CamelCase to snake_case?'], 4, 0], [(1175208, 2), [["Or if you're going to call it a zillion times, you can pre-compile the regexes:"], ["Don't forget to import the regular expression module"]], [[" first_cap_re = re.compile('(.)([A-Z][a-z]+)')\nall_cap_re = re.compile('([a-z0-9])([A-Z])')\ndef convert(name):\n    s1 = first_cap_re.sub(r'\\1_\\2', name)\n    return all_cap_re.sub(r'\\1_\\2', s1).lower()\n"]], ['Elegant Python function to convert CamelCase to snake_case?'], 4, 1], [(1175208, 3), [["Don't forget to import the regular expression module"], ['-10000']], [[' import re\n']], ['Elegant Python function to convert CamelCase to snake_case?'], 4, 0], [(1210099, 0), [['Count the number of users:'], ['You can use the same to count the number of profile objects (assuming every user has at most 1 profile), e.g. if Profile is the profile model:']], [[' import django.contrib.auth\ndjango.contrib.auth.models.User.objects.all().count()\n']], ['How to find number of users, number of users with a profile object, and monthly logins in Django'], 2, 0], [(1210099, 1), [['You can use the same to count the number of profile objects (assuming every user has at most 1 profile), e.g. if Profile is the profile model:'], ["To count the number of logins in a month you'd need to create a table logging each login with a time stamp. Then it's a matter of using count() again."]], [[' Profile.objects.all().count()\n']], ['How to find number of users, number of users with a profile object, and monthly logins in Django'], 2, 0], [(1267314, 0), [['I think this is what you want...'], ['or the "comprehensive" solution, for those who prefer that style:']], [[' import unicodedata\ndef eval_unicode(s):\n    #sum all the unicode fractions\n    u = sum(map(unicodedata.numeric, filter(lambda x: unicodedata.category(x)=="No",s)))\n    #eval the regular digits (with optional dot) as a float, or default to 0\n    n = float("".join(filter(lambda x:x.isdigit() or x==".", s)) or 0)\n    return n+u\n']], ['How do I calculate the numeric value of a string with unicode components in python?'], 2, 1], [(1267314, 1), [['or the "comprehensive" solution, for those who prefer that style:'], ["But beware, there are many unicode values that seem to not have a numeric value assigned in python (for example ⅜⅝ don't work... or maybe is just a matter with my keyboard xD)."]], [[' import unicodedata\ndef eval_unicode(s):\n    #sum all the unicode fractions\n    u = sum(unicodedata.numeric(i) for i in s if unicodedata.category(i)=="No")\n    #eval the regular digits (with optional dot) as a float, or default to 0\n    n = float("".join(i for i in s if i.isdigit() or i==".") or 0)\n    return n+u\n']], ['How do I calculate the numeric value of a string with unicode components in python?'], 2, 1], [(1295415, 0), [["why don't you just try:"], ['example :']], [[' f = replacement_f\n']], ['How to replace Python function while supporting all passed in parameters'], 2, 1], [(1295415, 1), [['example :'], ['-10000']], [[" >>> def rep(*args):\n    print(*args, sep=' -- ')\n\n>>> def ori(*args):\n    print(args)\n\n>>> ori('dfef', 32)\n('dfef', 32)\n>>> ori = rep\n>>> ori('dfef', 32)\ndfef -- 32\n"]], ['How to replace Python function while supporting all passed in parameters'], 2, 0], [(1305532, 0), [['Update:  In Python 2.6 and onwards, consider whether the  namedtuple  data structure suits your needs:'], ['The alternative (original answer contents) is:']], [[' >>> from collections import namedtuple\n>>> MyStruct = namedtuple(\'MyStruct\', \'a b d\')\n>>> s = MyStruct(a=1, b={\'c\': 2}, d=[\'hi\'])\n>>> s\nMyStruct(a=1, b={\'c\': 2}, d=[\'hi\'])\n>>> s.a\n1\n>>> s.b\n{\'c\': 2}\n>>> s.c\nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\nAttributeError: \'MyStruct\' object has no attribute \'c\'\n>>> s.d\n[\'hi\']\n']], ['Convert Python dict to object?'], 3, 1], [(1305532, 2), [['Then, you can use:'], ['-10000']], [[" >>> args = {'a': 1, 'b': 2}\n>>> s = Struct(**args)\n>>> s\n<__main__.Struct instance at 0x01D6A738>\n>>> s.a\n1\n>>> s.b\n2\n"]], ['Convert Python dict to object?'], 3, 0], [(1389180, 0), [['Here is the complete solution:'], ['-10000']], [[' from functools import wraps\nimport inspect\n\n\ndef initializer(func):\n    """\n    Automatically assigns the parameters.\n\n    >>> class process:\n    ...     @initializer\n    ...     def __init__(self, cmd, reachable=False, user=\'root\'):\n    ...         pass\n    >>> p = process(\'halt\', True)\n    >>> p.cmd, p.reachable, p.user\n    (\'halt\', True, \'root\')\n    """\n    names, varargs, keywords, defaults = inspect.getargspec(func)\n\n    @wraps(func)\n    def wrapper(self, *args, **kargs):\n        for name, arg in list(zip(names[1:], args)) + list(kargs.items()):\n            setattr(self, name, arg)\n\n        for name, default in zip(reversed(names), reversed(defaults)):\n            if not hasattr(self, name):\n                setattr(self, name, default)\n\n        func(self, *args, **kargs)\n\n    return wrapper\n']], ['Python: Automatically initialize instance variables?'], 4, 1], [(1389180, 1), [['-10000'], ['-10000']], [[' from functools import wraps\nimport inspect\n\ndef initializer(fun):\n   names, varargs, keywords, defaults = inspect.getargspec(fun)\n   @wraps(fun)\n   def wrapper(self, *args, **kargs):\n       for name, arg in zip(names[1:], args) + kargs.items():\n           setattr(self, name, arg)\n       fun(self, *args, **kargs)\n   return wrapper\n']], ['Python: Automatically initialize instance variables?'], 4, 1], [(1389180, 2), [['-10000'], ['Output:']], [[' from functools import wraps\nimport inspect\n\ndef initializer(fun):\n    names, varargs, keywords, defaults = inspect.getargspec(fun)\n    @wraps(fun)\n    def wrapper(self, *args):\n        for name, arg in zip(names[1:], args):\n            setattr(self, name, arg)\n        fun(self, *args)\n    return wrapper\n\nclass process:\n    @initializer\n    def __init__(self, PID, PPID, cmd, FDs, reachable, user):\n        pass\n']], ['Python: Automatically initialize instance variables?'], 4, 1], [(1389180, 3), [['Output:'], ['-10000']], [[" >>> c = process(1, 2, 3, 4, 5, 6)\n>>> c.PID\n1\n>>> dir(c)\n['FDs', 'PID', 'PPID', '__doc__', '__init__', '__module__', 'cmd', 'reachable', 'user'\n"]], ['Python: Automatically initialize instance variables?'], 4, 0], [(1423251, 0), [['Assuming that this is the case, I can cause a very similar TCP sequence with this code for the server:'], ['and this for the client:']], [[" # server.py\nimport socket\nfrom time import sleep\n\ndef f(s):\n        r,a = s.accept()\n        print r.recv(100)\n\ns = socket.socket()\ns.bind(('localhost',1234))\ns.listen(1)\n\nf(s)\n# wait around a bit for the client to send it's second packet\nsleep(10)\n"]], ['talking between python tcp server and a c++ client'], 3, 0], [(1423251, 1), [['and this for the client:'], ['Start your packet sniffer, then run server.py and then, client.py. Here is the outout of  tcpdump -A -i lo , which matches your observations:']], [[" # client.py\nimport socket\nfrom time import sleep\n\ns = socket.socket()\ns.connect(('localhost',1234))\n\ns.send('hello 1')\n# wait around for a while so that the socket in server.py goes out of scope\nsleep(5)\ns.send('hello 2')\n"]], ['talking between python tcp server and a c++ client'], 3, 0], [(1423251, 2), [['Start your packet sniffer, then run server.py and then, client.py. Here is the outout of  tcpdump -A -i lo , which matches your observations:'], ['-10000']], [[' tcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on lo, link-type EN10MB (Ethernet), capture size 96 bytes\n12:42:37.683710 IP localhost:33491 > localhost.1234: S 1129726741:1129726741(0) win 32792 <mss 16396,sackOK,timestamp 640881101 0,nop,wscale 7>\nE..<R.@.@...............CVC.........I|....@....\n&3..........\n12:42:37.684049 IP localhost.1234 > localhost:33491: S 1128039653:1128039653(0) ack 1129726742 win 32768 <mss 16396,sackOK,timestamp 640881101 640881101,nop,wscale 7>\nE..<..@.@.<.............C<..CVC.....Ia....@....\n&3..&3......\n12:42:37.684087 IP localhost:33491 > localhost.1234: . ack 1 win 257 <nop,nop,timestamp 640881102 640881101>\nE..4R.@.@...............CVC.C<......1......\n&3..&3..\n12:42:37.684220 IP localhost:33491 > localhost.1234: P 1:8(7) ack 1 win 257 <nop,nop,timestamp 640881102 640881101>\nE..;R.@.@...............CVC.C<......./.....\n&3..&3..hello 1\n12:42:37.684271 IP localhost.1234 > localhost:33491: . ack 8 win 256 <nop,nop,timestamp 640881102 640881102>\nE..4.(@.@...............C<..CVC.....1}.....\n&3..&3..\n12:42:37.684755 IP localhost.1234 > localhost:33491: F 1:1(0) ack 8 win 256 <nop,nop,timestamp 640881103 640881102>\nE..4.)@.@...............C<..CVC.....1{.....\n&3..&3..\n12:42:37.685639 IP localhost:33491 > localhost.1234: . ack 2 win 257 <nop,nop,timestamp 640881104 640881103>\nE..4R.@.@...............CVC.C<......1x.....\n&3..&3..\n12:42:42.683367 IP localhost:33491 > localhost.1234: P 8:15(7) ack 2 win 257 <nop,nop,timestamp 640886103 640881103>\nE..;R.@.@...............CVC.C<......./.....\n&3%W&3..hello 2\n12:42:42.683401 IP localhost.1234 > localhost:33491: R 1128039655:1128039655(0) win 0\nE..(..@.@.<.............C<......P...b...\n\n9 packets captured\n27 packets received by filter\n0 packets dropped by kernel\n']], ['talking between python tcp server and a c++ client'], 3, 0], [(1448820, 0), [['This is a carryover from the C formatting markup:'], ["If you want left-justified text (for entries shorter than  max_title_width ), put a '-' before the '*'."]], [[' print "%*s, blah" % (max_title_width,column)\n']], ['variable length of %s with the % operator in python'], 5, 0], [(1448820, 1), [["If you want left-justified text (for entries shorter than  max_title_width ), put a '-' before the '*'."], ['If the len field is shorter than the text string, the string just overflows:']], [[' >>> text = "abcdef"\n>>> print "<%*s>" % (len(text)+2,text)\n<  abcdef>\n>>> print "<%-*s>" % (len(text)+2,text)\n<abcdef  >\n>>>\n']], ['variable length of %s with the % operator in python'], 5, 0], [(1448820, 2), [['If the len field is shorter than the text string, the string just overflows:'], ["If you want to clip at a maximum length, use the '.' precision field of the format placeholder:"]], [[' >>> print "<%*s>" % (len(text)-2,text)\n<abcdef>\n']], ['variable length of %s with the % operator in python'], 5, 0], [(1448820, 3), [["If you want to clip at a maximum length, use the '.' precision field of the format placeholder:"], ['Put them all together this way:']], [[' >>> print "<%.*s>" % (len(text)-2,text)\n<abcd>\n']], ['variable length of %s with the % operator in python'], 5, 0], [(1448820, 4), [['Put them all together this way:'], ['-10000']], [[" %\n- if left justified\n* or integer - min width (if '*', insert variable length in data tuple)\n.* or .integer - max width (if '*', insert variable length in data tuple)\n"]], ['variable length of %s with the % operator in python'], 5, 1], [(1470453, 0), [['I am able to solve my problem by writing a modifed version of python  trace  module , which can be enabled disabled, basically modify  Trace  class something like this'], ['Output:']], [[" import sys\nimport trace\n\nclass MyTrace(trace.Trace):\n    def __init__(self, *args, **kwargs):\n        trace.Trace.__init__(self, *args, **kwargs)\n        self.enabled = False\n\n    def localtrace_trace_and_count(self, *args, **kwargs):\n        if not self.enabled:\n            return None \n        return trace.Trace.localtrace_trace_and_count(self, *args, **kwargs)\n\ntracer = MyTrace(ignoredirs=[sys.prefix, sys.exec_prefix],)\n\ndef main():\n    a = 1\n    tracer.enabled = True\n    a = 2\n    tracer.enabled = False\n    a = 3\n\n# run the new command using the given tracer\ntracer.run('main()')\n"]], ['How to check which part of app is consuming CPU?'], 2, 1], [(1470453, 1), [['Output:'], ['Enabling it at the critical points helps me to trace line by line which code statements are executing most.']], [['  --- modulename: untitled-2, funcname: main\nuntitled-2.py(19):     a = 2\nuntitled-2.py(20):     tracer.enabled = False\n']], ['How to check which part of app is consuming CPU?'], 2, 0], [(1480655, 0), [['From the xmacroplay website'], ['This is probably the command you are interested in']], [[' xmacroplay:\nReads lines from the standard input. It can understand the following lines:\n\nDelay [sec]     - delays the program with [sec] secundums\nButtonPress [n] - sends a ButtonPress event with button [n]\n          this emulates the pressing of the mouse button [n]\nButtonRelease [n]   - sends a ButtonRelease event with button [n]\n          this emulates the releasing of the mouse button [n]\n... snip lots more ...\n']], ['How can I, on some global keystroke, paste some text to current active application in linux with Python or C++'], 2, 0], [(1480655, 1), [['This is probably the command you are interested in'], ['There is also  Xnee  which does a similar thing.']], [[' String [max. 1024 long string]\n        - Sends the string as single characters converted to\n          KeyPress and KeyRelease events based on a\n          character table in chartbl.h (currently only\n          Latin1 is used...)\n']], ['How can I, on some global keystroke, paste some text to current active application in linux with Python or C++'], 2, 1], [(1527689, 0), [['-10000'], ['You can use it like this:']], [[' >>> import sys\n>>> class Quitter(object):\n...     def __repr__(self):\n...         sys.exit()\n... \n>>> exit = Quitter()\n']], ['exit from ipython'], 4, 1], [(1527689, 1), [['You can use it like this:'], ['I dont use  ipython  myself, but it seems to have some wierd  sys.exit  handler.\nThe solution I found is as follows:']], [[' >>> exit\n']], ['exit from ipython'], 4, 0], [(1527689, 2), [['I dont use  ipython  myself, but it seems to have some wierd  sys.exit  handler.\nThe solution I found is as follows:'], ['Usage:']], [[" In [1]: type(exit).__repr__ = lambda s: setattr(s.shell, 'exit_now', True) or ''\n"]], ['exit from ipython'], 4, 1], [(1527689, 3), [['Usage:'], ['-10000']], [[' In [2]: exit\n']], ['exit from ipython'], 4, 0], [(1598932, 0), [['New in Django 1.1'], ['or using  an F expression :']], [[" Counter.objects.get_or_create(name = name)\nCounter.objects.filter(name = name).update(count = F('count')+1)\n"]], ['Atomic increment of a counter in django'], 2, 1], [(1598932, 1), [['or using  an F expression :'], ['-10000']], [[" counter = Counter.objects.get_or_create(name = name)\ncounter.count = F('count') +1\ncounter.save()\n"]], ['Atomic increment of a counter in django'], 2, 1], [(1606436, 1), [['Then in the Python REPL:'], ['Or you could do:']], [[' >>> print nt.Point.__doc__\n A point in 2d space \n']], ['Adding docstrings to namedtuples?'], 5, 0], [(1606436, 2), [['Or you could do:'], ['-10000']], [[' >>> help(nt.Point)  # which outputs...\n']], ['Adding docstrings to namedtuples?'], 5, 0], [(1606436, 3), [['-10000'], ['which outputs:']], [[' def NamedTupleWithDocstring(docstring, *ntargs):\n    nt = namedtuple(*ntargs)\n    class NT(nt):\n        __doc__ = docstring\n    return NT\n\nPoint3D = NamedTupleWithDocstring("A point in 3d space", "Point3d", ["x", "y", "z"])\n\np3 = Point3D(1,2,3)\n\nprint p3.__doc__\n']], ['Adding docstrings to namedtuples?'], 5, 0], [(1606436, 4), [['which outputs:'], ['-10000']], [[' A point in 3d space\n']], ['Adding docstrings to namedtuples?'], 5, 0], [(1673483, 0), [['.'], ['Usage notes:']], [[' class WeakCallback (object):\n    """A Weak Callback object that will keep a reference to\n    the connecting object with weakref semantics.\n\n    This allows object A to pass a callback method to object S,\n    without object S keeping A alive.\n    """\n    def __init__(self, mcallback):\n        """Create a new Weak Callback calling the method @mcallback"""\n        obj = mcallback.im_self\n        attr = mcallback.im_func.__name__\n        self.wref = weakref.ref(obj, self.object_deleted)\n        self.callback_attr = attr\n        self.token = None\n\n    def __call__(self, *args, **kwargs):\n        obj = self.wref()\n        if obj:\n            attr = getattr(obj, self.callback_attr)\n            attr(*args, **kwargs)\n        else:\n            self.default_callback(*args, **kwargs)\n\n    def default_callback(self, *args, **kwargs):\n        """Called instead of callback when expired"""\n        pass\n\n    def object_deleted(self, wref):\n        """Called when callback expires"""\n        pass\n']], ['How to store callback methods?'], 2, 1], [(1673483, 1), [['Usage notes:'], ["I use the  WeakCallback.token  attribute in subclasses I've made to manage disconnecting the callback when the connecter goes away"]], [[' # illustration how I typically use it\nweak_call = WeakCallback(self._something_changed)\nlong_lived_object.connect("on_change", weak_call)\n']], ['How to store callback methods?'], 2, 0], [(1738633, 0), [['Probably the most efficient way to do it, if the string is long enough:'], ['This is making use of the  translate  and  maketrans  methods. You can also move the translate table creation outside the function:']], [[" import string\n\ndef complementary_strand(self, strand):\n    return strand.translate(string.maketrans('TAGCtagc', 'ATCGATCG'))\n"]], ['More pythonic way to find a complementary DNA strand'], 2, 1], [(1738633, 1), [['This is making use of the  translate  and  maketrans  methods. You can also move the translate table creation outside the function:'], ['-10000']], [[" import string\ndef __init__(self, ...):\n    self.trans = string.maketrans('TAGCtagc', 'ATCGATCG')\n\ndef complementary_strand(self, strand):\n    return strand.translate(self.trans)\n"]], ['More pythonic way to find a complementary DNA strand'], 2, 1], [(1767565, 0), [['If it is a frequency plot of some kind, then a simple SQL query should do the trick:'], ['After that, the python code to generate data for a histogram plot is the following (this was written precisely in 5 minutes so it is very crude):']], [[' select total, count(total) from faults GROUP BY total;\n']], ['Plotting Histogram: How can I do it from scratch using data stored in a database?'], 4, 0], [(1767565, 1), [['After that, the python code to generate data for a histogram plot is the following (this was written precisely in 5 minutes so it is very crude):'], ['Step #3: Use GNUPlot to generate the histogram. You can use the following script as a starting point (generates an eps image file):']], [[' import MySQLdb\n\ndef DumpHistogramData(databaseHost, databaseName, databaseUsername, databasePassword, dataTableName, binsTableName, binSize, histogramDataFilename):\n    #Open a file for writing into\n    output = open("./" + histogramDataFilename, "w")\n\n    #Connect to the database\n    db = MySQLdb.connect(databaseHost, databaseUsername, databasePassword, databaseName)\n    cursor = db.cursor()\n\n    #Form the query\n    sql = """select b.*, count(*) as total \n            FROM """ + binsTableName + """ b \n            LEFT OUTER JOIN """ + dataTableName + """ a \n            ON a.total between b.min AND b.max \n            group by b.min;"""\n    cursor.execute(sql)\n\n    #Get the result and print it into a file for further processing\n    count = 0;\n    while True:\n        results = cursor.fetchmany(10000)\n        if not results:\n            break\n        for result in results:\n            #print >> output, str(result[0]) + "-" + str(result[1]) + "\\t" + str(result[2])\n    db.close()\n\ndef PrepareHistogramBins(databaseHost, databaseName, databaseUsername, databasePassword, binsTableName, maxValue, totalBins):\n\n    #Connect to the database    \n    db = MySQLdb.connect(databaseHost, databaseUsername, databasePassword, databaseName)\n    cursor = db.cursor()\n\n    #Check if the table was already created\n    sql = """DROP TABLE IF EXISTS """ + binsTableName\n    cursor.execute(sql)\n\n    #Create the table\n    sql = """CREATE TABLE """ + binsTableName + """(min int(11), max int(11));"""\n    cursor.execute(sql)\n\n    #Calculate the bin size\n    binSize = maxValue/totalBins\n\n    #Generate the bin sizes\n    for i in range(0, maxValue, binSize):\n        if i is 0:\n            min = i\n            max = i+binSize\n        else:\n            min = i+1\n            max = i+binSize\n        sql = """INSERT INTO """ + binsTableName + """(min, max) VALUES(""" + str(min) + """, """ + str(max) + """);"""\n        cursor.execute(sql)\n    db.close()\n    return binSize\n\nbinSize = PrepareHistogramBins("localhost", "testing", "root", "", "bins", 5000, 100)\nDumpHistogramData("localhost", "testing", "root", "", "faults", "bins", binSize, "histogram")\n']], ['Plotting Histogram: How can I do it from scratch using data stored in a database?'], 4, 0], [(1767565, 2), [['Step #3: Use GNUPlot to generate the histogram. You can use the following script as a starting point (generates an eps image file):'], ['Step #4: Use gnuplot with the above input script to generate an eps file']], [[' set terminal postscript eps color lw 2 "Helvetica" 20\nset output "output.eps"\nset xlabel "XLABEL"\nset ylabel "YLABEL"\nset title "TITLE"\nset style data histogram\nset style histogram cluster gap 1\nset style fill solid border -1\nset boxwidth 0.9\nset key autotitle columnheader\nset xtics rotate by -45\nplot "input" using 1:2 with linespoints ls 1\n']], ['Plotting Histogram: How can I do it from scratch using data stored in a database?'], 4, 0], [(1767565, 3), [['Step #4: Use gnuplot with the above input script to generate an eps file'], ['Nothing complicated but I figured a couple of bits from this code can be reused. Again, like I said, it is not perfect but you can get the job done :)']], [[' gnuplot sample.script\n']], ['Plotting Histogram: How can I do it from scratch using data stored in a database?'], 4, 0], [(1777344, 0), [['-10000'], ["As you see, the first item of the tuple  mac_ver  returns is a string, not a number (hard to make '10.5.8' into a number!-), but it's pretty easy to manipulate the  10.x.y  string into the kind of numbers you want.  For example,"]], [[" >>> import platform\n>>> platform.mac_ver()\n('10.5.8', ('', '', ''), 'i386')\n"]], ['How to detect Mac OS version using Python?'], 2, 1], [(1781554, 0), [['-10000'], ["However, I'd be curious about the context in which you're using this - there might be other options aside from regex which would be either more efficient or more readable, such as..."]], [[' ^(?!mpeg).*\n']], ['regular expression matching everything except a given regular expression'], 2, 1], [(1783251, 0), [['NumPy actually does have an  append  function, which it seems might do what you want, e.g.,'], ['your second snippet (hstack) will work if you add another line, e.g.,']], [[' import numpy as NP\nmy_data = NP.random.random_integers(0, 9, 9).reshape(3, 3)\nnew_col = NP.array((5, 5, 5)).reshape(3, 1)\nres = NP.append(my_data, new_col, axis=1)\n']], ['Growing matrices columnwise in NumPy'], 5, 0], [(1783251, 1), [['your second snippet (hstack) will work if you add another line, e.g.,'], ['For that reason, the common pattern in NumPy for iterative addition of columns to a 2D array is to initialize an empty target array  once (or pre-allocate a single 2D NumPy array having all of the empty columns) the successively populate those empty columns by setting the desired column-wise offset (index)--much easier to show than to explain:']], [[' my_data = NP.random.random_integers(0, 9, 16).reshape(4, 4)\n# the line to add--does not depend on array dimensions\nnew_col = NP.zeros_like(my_data[:,-1]).reshape(-1, 1)\nres = NP.hstack((my_data, new_col))\n']], ['Growing matrices columnwise in NumPy'], 5, 0], [(1783251, 2), [['For that reason, the common pattern in NumPy for iterative addition of columns to a 2D array is to initialize an empty target array  once (or pre-allocate a single 2D NumPy array having all of the empty columns) the successively populate those empty columns by setting the desired column-wise offset (index)--much easier to show than to explain:'], ['populate NumPy array as in the OP, except each iteration just re-sets the values of M at successive column-wise offsets']], [[" >>> # initialize your skeleton array using 'empty' for lowest-memory footprint \n>>> M = NP.empty(shape=(10, 5), dtype=float)\n\n>>> # create a small function to mimic step-wise populating this empty 2D array:\n>>> fnx = lambda v : NP.random.randint(0, 10, v)\n"]], ['Growing matrices columnwise in NumPy'], 5, 0], [(1783251, 3), [['populate NumPy array as in the OP, except each iteration just re-sets the values of M at successive column-wise offsets'], ["of course if you don't known in advance what size your array should be\njust create one much bigger than you need and trim the 'unused' portions\nwhen you finish populating it"]], [[' >>> for index, itm in enumerate(range(5)):    \n        M[:,index] = fnx(10)\n\n>>> M\n  array([[ 1.,  7.,  0.,  8.,  7.],\n         [ 9.,  0.,  6.,  9.,  4.],\n         [ 2.,  3.,  6.,  3.,  4.],\n         [ 3.,  4.,  1.,  0.,  5.],\n         [ 2.,  3.,  5.,  3.,  0.],\n         [ 4.,  6.,  5.,  6.,  2.],\n         [ 0.,  6.,  1.,  6.,  8.],\n         [ 3.,  8.,  0.,  8.,  0.],\n         [ 5.,  2.,  5.,  0.,  1.],\n         [ 0.,  6.,  5.,  9.,  1.]])\n']], ['Growing matrices columnwise in NumPy'], 5, 0], [(1783251, 4), [["of course if you don't known in advance what size your array should be\njust create one much bigger than you need and trim the 'unused' portions\nwhen you finish populating it"], ['-10000']], [[' >>> M[:3,:3]\n  array([[ 9.,  3.,  1.],\n         [ 9.,  6.,  8.],\n         [ 9.,  7.,  5.]])\n']], ['Growing matrices columnwise in NumPy'], 5, 0], [(1794346, 0), [['You can access data you need without  ctypes :'], ['Update : But sure you can access internal data with  ctypes  too:']], [[' >>> obj = xrange(1,11,2)\n>>> obj.__reduce__()[1]\n(1, 11, 2)\n>>> len(obj)\n5\n']], ['Accessing xrange internal structure'], 2, 1], [(1794346, 1), [['Update : But sure you can access internal data with  ctypes  too:'], ['-10000']], [[" from ctypes import *\n\nPyObject_HEAD = [\n    ('ob_refcnt', c_size_t),\n    ('ob_type', c_void_p),\n]\n\nclass XRangeType(Structure):\n    _fields_ = PyObject_HEAD + [\n        ('start', c_long),\n        ('step', c_long),\n        ('len', c_long),\n    ]\n\nrange_obj = xrange(1, 11, 2)\n\nc_range_obj = cast(c_void_p(id(range_obj)), POINTER(XRangeType)).contents\nprint c_range_obj.start, c_range_obj.step, c_range_obj.len\n"]], ['Accessing xrange internal structure'], 2, 1], [(1822934, 2), [['You generally create instance of classes like so'], ['-10000']], [[' from System.Collections import *\n# create an instance of Hashtable\nh = Hashtable() \n\nfrom System.Collections.Generic import *\n# create an instance of List<string>\nl = List[str]()\n']], ['How do I reference classes using IronPython?'], 3, 0], [(1869034, 0), [['You can do this:'], ['You can achieve the same by doing (propably cleaner):']], [[" import sip # you'll need this import (no worries, it ships with your pyqt install)\nsip.delete(self.sv_widgets[purchase.id])\n"]], ['Removing custom widget from QVBoxLayout'], 2, 1], [(1869034, 1), [['You can achieve the same by doing (propably cleaner):'], ['-10000']], [[' self.vl_seatView.removeWidget(self.sv_widgets[purchase.id])\nself.sv_widgets[purchase.id].setParent(None)\ndel self.sv_widgets[purchase.id]\n']], ['Removing custom widget from QVBoxLayout'], 2, 1], [(1885314, 0), [['-10000'], ['prints']], [[' class ListParser:\n\n def __init__(self, s):\n  self.str = s.split("\\n")\n  print self.str\n  self.answer = []\n\n def parse(self):\n  self.nextLine()\n  self.topList()\n  return\n\n def topList(self):\n  while(len(self.str) > 0):\n   self.topListItem()\n\n def topListItem(self):\n  l = self.nextLine()\n  print "TOP: " + l\n  l = self.nextLine()\n  if l != \'\':\n   raise Exception("expected blank line but found \'%s\'" % l)\n  sub = self.sublist()\n\n def nextLine(self):\n  return self.str.pop(0)\n\n def sublist(self):\n  while True:\n   l = self.nextLine()\n   if l == \'\':\n    return # end of sublist marked by blank line\n   else:\n    print "SUB: " + l\n\nparser = ListParser(s)\nparser.parse() \nprint "done"\n']], ['Parsing multilevel text list'], 2, 1], [(1885314, 1), [['prints'], ['-10000']], [[' TOP: 1 List name\nSUB: 1 item\nSUB: 2 item\nSUB: 3 item\nTOP: 2 List name\nSUB: 1 item\nSUB: 2 item\nSUB: 3 item\nTOP: 3 List name\nSUB: 1 item\nSUB: 2 item\nSUB: 3 item\ndone\n']], ['Parsing multilevel text list'], 2, 0], [(1933784, 0), [["I'm pretty sure whatever you are trying to do can be solved in a better way, but here is something that gives you a clone of the class with a new id:"], ['gives:']], [[' def c():\n    class Clone(object):\n        pass\n\n    return Clone\n\nc1 = c()\nc2 = c()\nprint id(c1)\nprint id(c2)\n']], ['How do you clone a class in Python?'], 2, 1], [(1933784, 1), [['gives:'], ['-10000']], [[' 4303713312\n4303831072\n']], ['How do you clone a class in Python?'], 2, 0], [(1938894, 0), [['-10000'], ['Code:']], [[' $ cat 1938894-simplified.csv\n0,32\n1,21\n1,23\n1,32\n2,23\n2,53\n2,82\n3,82\n4,46\n5,75\n7,86\n8,28\n']], ['csv to sparse matrix in python'], 3, 0], [(1938894, 1), [['Code:'], ['Output:']], [[" #!/usr/bin/env python\n\nimport csv\nfrom scipy import sparse\n\nrows, columns = 10, 100\nmatrix = sparse.lil_matrix( (rows, columns) )\n\ncsvreader = csv.reader(open('1938894-simplified.csv'))\nfor line in csvreader:\n    row, column = map(int, line)\n    matrix.data[row].append(column)\n\nprint matrix.data\n"]], ['csv to sparse matrix in python'], 3, 1], [(1938894, 2), [['Output:'], ['-10000']], [[' [[32] [21, 23, 32] [23, 53, 82] [82] [46] [75] [] [86] [28] []]\n']], ['csv to sparse matrix in python'], 3, 0], [(1960516, 1), [['Then use it like so:'], ['-10000']], [[" json.dumps({'x': decimal.Decimal('5.5')}, cls=DecimalEncoder)\n"]], ['Python JSON serialize a Decimal object'], 2, 0], [(2005234, 1), [['constants.py:'], ['For historical data I used this simple script:']], [[" ADMIN = 1\nAUTHORIZATION_STATUS = 11\nBLPSERVICE_STATUS = 9\nPARTIAL_RESPONSE = 6\nPUBLISHING_DATA = 13\nREQUEST_STATUS = 4\nRESOLUTION_STATUS = 12\nRESPONSE = 5\nSESSION_STATUS = 2\nSUBSCRIPTION_DATA = 8\nSUBSCRIPTION_STATUS = 3\nTIMEOUT = 10\nTOKEN_STATUS = 15\nTOPIC_STATUS = 14\nUNKNOWN = -1\nfields = ['BID']\ntickers = ['AUD Curncy']\ninterval = '' #'interval=5.0'\n"]], ["Asynchronous data through Bloomberg's new data API (COM v3) with Python?"], 3, 0], [(2005234, 2), [['For historical data I used this simple script:'], ['-10000']], [[" import win32com.client\n\nsession = win32com.client.Dispatch('blpapicom.Session')\nsession.QueueEvents = True\nsession.Start()\nstarted = session.OpenService('//blp/refdata')\ndataService = session.GetService('//blp/refdata')\nrequest = dataService.CreateRequest('HistoricalDataRequest')\nrequest.GetElement('securities').AppendValue('5 HK Equity')\nrequest.GetElement('fields').AppendValue('PX_LAST')\nrequest.Set('periodicitySelection', 'DAILY')\nrequest.Set('startDate', '20090119')\nrequest.Set('endDate', '20090130')\ncid = session.SendRequest(request)\nADMIN = 1\nAUTHORIZATION_STATUS = 11\nBLPSERVICE_STATUS = 9\nPARTIAL_RESPONSE = 6\nPUBLISHING_DATA = 13\nREQUEST_STATUS = 4\nRESOLUTION_STATUS = 12\nRESPONSE = 5\nSESSION_STATUS = 2\nSUBSCRIPTION_DATA = 8\nSUBSCRIPTION_STATUS = 3\nTIMEOUT = 10\nTOKEN_STATUS = 15\nTOPIC_STATUS = 14\nUNKNOWN = -1\nstayHere = True\nwhile stayHere:\n    event = session.NextEvent();\n    if event.EventType == PARTIAL_RESPONSE or event.EventType == RESPONSE:\n        iterator = event.CreateMessageIterator()\n        iterator.Next()\n        message = iterator.Message\n        securityData = message.GetElement('securityData')\n        securityName = securityData.GetElement('security')\n        fieldData = securityData.GetElement('fieldData')\n        returnList = [[0 for col in range(fieldData.GetValue(row).NumValues+1)] for row in range(fieldData.NumValues)]\n        for row in range(fieldData.NumValues):\n            rowField = fieldData.GetValue(row)\n            for col in range(rowField.NumValues+1):\n                colField = rowField.GetElement(col)\n                returnList[row][col] = colField.Value\n        stayHere = False\n        break\nelement = None\niterator = None\nmessage = None\nevent = None\nsession = None\nprint returnList\n"]], ["Asynchronous data through Bloomberg's new data API (COM v3) with Python?"], 3, 0], [(2005759, 1), [["Visual module updates the screen as soon as the object is changed. The animation is done by that alteration, in realtime, there's no need for a  show()  or  start_animation()  - it happens as it goes. An example you can run on python command line:"], ['That line creates a sphere, and a window, and shows the sphere in the window already!!!']], [[' >>> from visual import sphere\n>>> s = sphere()\n']], ['Visual module in python assign objects'], 3, 0], [(2005759, 2), [['That line creates a sphere, and a window, and shows the sphere in the window already!!!'], ['That line changes the sphere position on  x  axis to  -100 . The change happens immediatelly on the screen. Just after this line runs, you see the sphere appear to the left of the window.']], [[' >>> s.x = -100\n']], ['Visual module in python assign objects'], 3, 0], [(2012611, 0), [['How about:'], ['It also works with  all()  of course:']], [[" >>> any(isinstance(e, int) and e > 0 for e in [1,2,'joe'])\nTrue\n"]], ['any() function in Python with a callback'], 2, 1], [(2034584, 0), [["This isn't as complicated as you might think. Here's a Category class:"], ['You could use it something like this:']], [[' class Category(db.Model):\n    title = db.StringProperty()\n    subcategories = db.ListProperty(db.Key)\n    quizzes = db.ListProperty(db.Key)\n\n    def add_sub_category(self, title):\n        new_category = Category(title)\n        new_category.put()\n        self.subcategories.append(new_category)\n        self.put()\n\n        return new_category\n']], ['Datastore Design Inquiry'], 2, 1], [(2034584, 1), [['You could use it something like this:'], ['...etc...']], [[' main_category = Category("Main")\nmain_category.put()\n\nsports_category = main_category.add_sub_category("Sports")\nbaseball_category = sports_category.add_sub_category("Baseball")\nfootball_category = sports_category.add_sub_category("Football")\nhockey_category = sports_category.add_sub_category("Hockey")\n\ntv_category = main_category.add_sub_category("TV")\n']], ['Datastore Design Inquiry'], 2, 0], [(2082387, 1), [['Output:'], ['The second correctly handles 2 or more buffered lines, but has more (standard) module dependencies and requires a wee bit of terminal hackery:']], [[' $ ./threads_input.py\nInterrupting text!\nInterrupting text!\nInterrupting text!\n> WELL, PRINCE, Genoa and Lucca are now no more than private estates of the Bo\nInterrupting text!\n> WELL, PRINCE, Genoa and Lucca are now no more than private estates of the Bo\nnaparte family. No, I warn you, that if you do not tell me we are at war,\n']], ['Reading input from raw_input() without having the prompt overwritten by other threads in Python'], 4, 0], [(2082387, 2), [['The second correctly handles 2 or more buffered lines, but has more (standard) module dependencies and requires a wee bit of terminal hackery:'], ['Output. Previous readline lines cleared properly:']], [[" #!/usr/bin/python\n\nimport time,readline,thread\nimport sys,struct,fcntl,termios\n\ndef blank_current_readline():\n    # Next line said to be reasonably portable for various Unixes\n    (rows,cols) = struct.unpack('hh', fcntl.ioctl(sys.stdout, termios.TIOCGWINSZ,'1234'))\n\n    text_len = len(readline.get_line_buffer())+2\n\n    # ANSI escape sequences (All VT100 except ESC[0G)\n    sys.stdout.write('\\x1b[2K')                         # Clear current line\n    sys.stdout.write('\\x1b[1A\\x1b[2K'*(text_len/cols))  # Move cursor up and clear line\n    sys.stdout.write('\\x1b[0G')                         # Move to start of line\n\n\ndef noisy_thread():\n    while True:\n        time.sleep(3)\n        blank_current_readline()\n        print 'Interrupting text!'\n        sys.stdout.write('> ' + readline.get_line_buffer())\n        sys.stdout.flush()          # Needed or text doesn't show until a key is pressed\n\n\nif __name__ == '__main__':\n    thread.start_new_thread(noisy_thread, ())\n    while True:\n        s = raw_input('> ')\n"]], ['Reading input from raw_input() without having the prompt overwritten by other threads in Python'], 4, 1], [(2082387, 3), [['Output. Previous readline lines cleared properly:'], ['-10000']], [[' $ ./threads_input2.py\nInterrupting text!\nInterrupting text!\nInterrupting text!\nInterrupting text!\n> WELL, PRINCE, Genoa and Lucca are now no more than private estates of the Bo\nnaparte family. No, I warn you, that if you do not tell me we are at war,\n']], ['Reading input from raw_input() without having the prompt overwritten by other threads in Python'], 4, 0], [(2126551, 0), [['You can construct your own constant of Unicode upper and lower case letters with:'], ['This makes a string 2153 characters long (narrow Unicode Python build).  For code like  letter in unicode_letters  it would be faster to use a set instead:']], [[" import unicodedata as ud\nall_unicode = ''.join(unichr(i) for i in xrange(65536))\nunicode_letters = ''.join(c for c in all_unicode\n                          if ud.category(c)=='Lu' or ud.category(c)=='Ll')\n"]], ['An equivalent to string.ascii_letters for unicode strings in python 2.x?'], 2, 1], [(2148119, 0), [['Here is the code from the website just in case the link goes bad. '], ['Example usage:']], [[" import cElementTree as ElementTree\n\nclass XmlListConfig(list):\n    def __init__(self, aList):\n        for element in aList:\n            if element:\n                # treat like dict\n                if len(element) == 1 or element[0].tag != element[1].tag:\n                    self.append(XmlDictConfig(element))\n                # treat like list\n                elif element[0].tag == element[1].tag:\n                    self.append(XmlListConfig(element))\n            elif element.text:\n                text = element.text.strip()\n                if text:\n                    self.append(text)\n\n\nclass XmlDictConfig(dict):\n    '''\n    Example usage:\n\n    >>> tree = ElementTree.parse('your_file.xml')\n    >>> root = tree.getroot()\n    >>> xmldict = XmlDictConfig(root)\n\n    Or, if you want to use an XML string:\n\n    >>> root = ElementTree.XML(xml_string)\n    >>> xmldict = XmlDictConfig(root)\n\n    And then use xmldict for what it is... a dict.\n    '''\n    def __init__(self, parent_element):\n        if parent_element.items():\n            self.update(dict(parent_element.items()))\n        for element in parent_element:\n            if element:\n                # treat like dict - we assume that if the first two tags\n                # in a series are different, then they are all different.\n                if len(element) == 1 or element[0].tag != element[1].tag:\n                    aDict = XmlDictConfig(element)\n                # treat like list - we assume that if the first two tags\n                # in a series are the same, then the rest are the same.\n                else:\n                    # here, we put the list in dictionary; the key is the\n                    # tag name the list elements all share in common, and\n                    # the value is the list itself \n                    aDict = {element[0].tag: XmlListConfig(element)}\n                # if the tag has attributes, add those to the dict\n                if element.items():\n                    aDict.update(dict(element.items()))\n                self.update({element.tag: aDict})\n            # this assumes that if you've got an attribute in a tag,\n            # you won't be having any text. This may or may not be a \n            # good idea -- time will tell. It works for the way we are\n            # currently doing XML configuration files...\n            elif element.items():\n                self.update({element.tag: dict(element.items())})\n            # finally, if there are no child tags and no attributes, extract\n            # the text\n            else:\n                self.update({element.tag: element.text})\n"]], ['How to convert an xml string to a dictionary in Python?'], 3, 1], [(2148119, 1), [['Example usage:'], ['//Or, if you want to use an XML string:']], [[" tree = ElementTree.parse('your_file.xml')\nroot = tree.getroot()\nxmldict = XmlDictConfig(root)\n"]], ['How to convert an xml string to a dictionary in Python?'], 3, 0], [(2148119, 2), [['//Or, if you want to use an XML string:'], ['-10000']], [[' root = ElementTree.XML(xml_string)\nxmldict = XmlDictConfig(root)\n']], ['How to convert an xml string to a dictionary in Python?'], 3, 0], [(2170228, 0), [["I've come up with the following method, which works for me because in every case the model will have a ModelForm associated with it."], ['Here is an extract from the template I am using for this particular view:']], [[' def GetModelData(form, fields):\n    """\n    Extract data from the bound form model instance and return a\n    dictionary that is easily usable in templates with the actual\n    field verbose name as the label, e.g.\n\n    model_data{"Address line 1": "32 Memory lane",\n               "Address line 2": "Brainville",\n               "Phone": "0212378492"}\n\n    This way, the template has an ordered list that can be easily\n    presented in tabular form.\n    """\n    model_data = {}\n    for field in fields:\n        model_data[form[field].label] = eval("form.data.%s" % form[field].name)\n    return model_data\n\n@login_required\ndef clients_view(request, client_id):\n    client = Client.objects.get(id=client_id)\n    form = AddClientForm(client)\n\n    fields = ("address1", "address2", "address3", "address4",\n              "phone", "fax", "mobile", "email")\n    model_data = GetModelData(form, fields)\n\n    template_vars = RequestContext(request,\n        {\n            "client": client,\n            "model_data": model_data\n        }\n    )\n    return render_to_response("clients-view.html", template_vars)\n']], ['Iterate over model instance field names and values in template'], 2, 1], [(2170228, 1), [['Here is an extract from the template I am using for this particular view:'], ['The nice thing about this method is that I can choose on a template-by-template basis the order in which I would like to display the field labels, using the tuple passed in to GetModelData and specifying the field names.  This also allows me to exclude certain fields (e.g. a User foreign key) as only the field names passed in via the tuple are built into the final dictionary.']], [[' <table class="client-view">\n    <tbody>\n    {% for field, value in model_data.items %}\n        <tr>\n            <td class="field-name">{{ field }}</td><td>{{ value }}</td>\n        </tr>\n    {% endfor %}\n    </tbody>\n</table>\n']], ['Iterate over model instance field names and values in template'], 2, 0], [(2192658, 0), [['In Python 2.6 or newer, use  format   syntax :'], ['Edit : For steganography, you might be interested in converting a stream of characters into a stream of bits. Here is how you could do that with generators:']], [[" '{0:0=#10b}'.format(my_num)[2:]\n# '00001010'\n"]], ['Is there a better way to convert from decimal to binary in python?'], 4, 1], [(2192658, 1), [['Edit : For steganography, you might be interested in converting a stream of characters into a stream of bits. Here is how you could do that with generators:'], ['And to convert a stream of bits back into a stream of characters:']], [[" def str2bits(astr):\n    for char in astr:    \n        n=ord(char)\n        for bit in '{0:0=#10b}'.format(n)[2:]:\n            yield int(bit)\n"]], ['Is there a better way to convert from decimal to binary in python?'], 4, 0], [(2192658, 2), [['And to convert a stream of bits back into a stream of characters:'], ['For example, you could use the above functions like this:']], [[' def grouper(n, iterable, fillvalue=None):\n    # Source: http://docs.python.org/library/itertools.html#recipes\n    "grouper(3, \'ABCDEFG\', \'x\') --> ABC DEF Gxx"\n    return itertools.izip_longest(*[iter(iterable)]*n,fillvalue=fillvalue)\n\ndef bits2str(bits):\n    for b in grouper(8,bits):\n        yield chr(int(\'\'.join(map(str,b)),2))\n']], ['Is there a better way to convert from decimal to binary in python?'], 4, 0], [(2192658, 3), [['For example, you could use the above functions like this:'], ['Also, SO guru  Ned Batchelder  does some steganography-related experiments using Python and PIL   here . You may be able to find some useful code there.']], [[" for b in str2bits('Hi Zvarberg'):\n    print b,\n# 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1\n\n# To show bits2str is the inverse of str2bits:\nprint ''.join([c for c in bits2str(str2bits('Hi Zvarberg'))])\n# Hi Zvarberg\n"]], ['Is there a better way to convert from decimal to binary in python?'], 4, 0], [(2203351, 0), [['See also the  idle  event in  SystemManager .  This approach works for AIR or Flash Player.'], ['You can get the idle time (in an unsupported way) using ']], [[' application.systemManager.addEventListener(FlexEvent.IDLE, onIdle);\n']], ['Flex: detecting user idle?'], 2, 1], [(2237624, 0), [["In Python 2.6, a  class decorator  is definitely the way to go.  E.g., here's a pretty general one for these kind of tasks:"], ['and now, just']], [[" import inspect\n\ndef decallmethods(decorator, prefix='test_'):\n  def dectheclass(cls):\n    for name, m in inspect.getmembers(cls, inspect.ismethod):\n      if name.startswith(prefix):\n        setattr(cls, name, decorator(m))\n    return cls\n  return dectheclass\n"]], ['Applying python decorators to methods in a class'], 3, 1], [(2237624, 1), [['and now, just'], ["will get you what you desire.  In Python 2.5 or worse, the  @decallmethods  syntax doesn't work for class decoration, but with otherwise exactly the same code you can replace it with the following statement right  after  the end of the  class TestCase  statement:"]], [[' @decallmethods(login_testuser)\nclass TestCase(object):\n    def setUp(self):\n        pass\n\n    def test_1(self):\n        print "test_1()"\n\n    def test_2(self):\n        print "test_2()"\n']], ['Applying python decorators to methods in a class'], 3, 0], [(2237624, 2), [["will get you what you desire.  In Python 2.5 or worse, the  @decallmethods  syntax doesn't work for class decoration, but with otherwise exactly the same code you can replace it with the following statement right  after  the end of the  class TestCase  statement:"], ['-10000']], [[' TestCase = decallmethods(login_testuser)(TestCase)\n']], ['Applying python decorators to methods in a class'], 3, 0], [(2255177, 0), [['func(2 5)**'], ['func(2 31)**']], [[' hashlookup:          0.13s     100%\nlookup:              0.15s     109%\nstringcount:         0.29s     220%\nunrolled_bitwise:    0.36s     272%\nlog_e:               0.60s     450%\nbitcounter:          0.64s     479%\nlog_2:               0.69s     515%\nilog:                0.81s     609%\nbitwise:             1.10s     821%\nolgn:                1.42s    1065%\n']], ['Finding the exponent of n = 2**x using bitwise operations [logarithm in base 2 of n]'], 5, 0], [(2255177, 1), [['func(2 31)**'], ['func(2 128)**']], [[' hashlookup:          0.11s     100%\nunrolled_bitwise:    0.26s     229%\nlog_e:               0.30s     268%\nstringcount:         0.30s     270%\nlog_2:               0.34s     301%\nilog:                0.41s     363%\nbitwise:             0.87s     778%\nolgn:                1.02s     912%\nbitcounter:          1.42s    1264%\n']], ['Finding the exponent of n = 2**x using bitwise operations [logarithm in base 2 of n]'], 5, 0], [(2255177, 2), [['func(2 128)**'], ['func(2 1024)**']], [[' hashlookup:     0.01s     100%\nstringcount:    0.03s     264%\nlog_e:          0.04s     315%\nlog_2:          0.04s     383%\nolgn:           0.18s    1585%\nbitcounter:     1.41s   12393%\n']], ['Finding the exponent of n = 2**x using bitwise operations [logarithm in base 2 of n]'], 5, 0], [(2255177, 3), [['func(2 1024)**'], ['-10000']], [[' log_e:          0.00s     100%\nlog_2:          0.01s     118%\nstringcount:    0.02s     354%\nolgn:           0.03s     707%\nbitcounter:     1.73s   37695%\n']], ['Finding the exponent of n = 2**x using bitwise operations [logarithm in base 2 of n]'], 5, 0], [(2255177, 4), [['-10000'], ['-10000']], [[' import math, sys\n\ndef stringcount(v):\n    """mac"""    \n    return len(bin(v)) - 3\n\ndef log_2(v):\n    """mac"""    \n    return int(round(math.log(v, 2), 0)) # 2**101 generates 100.999999999\n\ndef log_e(v):\n    """bp on mac"""    \n    return int(round(math.log(v)/0.69314718055994529, 0))  # 0.69 == log(2)\n\ndef bitcounter(v):\n    """John Y on mac"""\n    r = 0\n    while v > 1 :\n        v >>= 1\n        r += 1\n    return r\n\ndef olgn(n) :\n    """outis"""\n    if n < 1:\n        return -1\n    low = 0\n    high = sys.getsizeof(n)*8 # not the best upper-bound guesstimate, but...\n    while True:\n        mid = (low+high)//2\n        i = n >> mid\n        if i == 1:\n            return mid\n        if i == 0:\n            high = mid-1\n        else:\n            low = mid+1\n\ndef hashlookup(v):\n    """mac on brone -- limit: v < 2**131"""\n#    def prepareTable(max_log2=130) :\n#        hash_table = {}\n#        for p in range(1, max_log2) :\n#            hash_table[2**p] = p\n#        return hash_table\n\n    global hash_table\n    return hash_table[v] \n\ndef lookup(v):\n    """brone -- limit: v < 2**11"""\n#    def prepareTable(max_log2=10) :\n#        log2s_table=[0]*((1<<max_log2)+1)\n#        for i in range(max_log2+1):\n#            log2s_table[1<<i]=i\n#        return tuple(log2s_table)\n\n    global log2s_table\n    return log2s_table[v]\n\ndef bitwise(v):\n    """Mark Byers -- limit: v < 2**32"""\n    b = (0x2, 0xC, 0xF0, 0xFF00, 0xFFFF0000)\n    S = (1, 2, 4, 8, 16)\n    r = 0\n    for i in range(4, -1, -1) :\n        if (v & b[i]) :\n            v >>= S[i];\n            r |= S[i];\n    return r\n\ndef unrolled_bitwise(v):\n    """x4u on Mark Byers -- limit:   v < 2**33"""\n    r = 0;\n    if v > 0xffff : \n        v >>= 16\n        r = 16;\n    if v > 0x00ff :\n        v >>=  8\n        r += 8;\n    if v > 0x000f :\n        v >>=  4\n        r += 4;\n    if v > 0x0003 : \n        v >>=  2\n        r += 2;\n    return r + (v >> 1)\n\ndef ilog(v):\n    """Gregory Maxwell - (Original code: B. Terriberry) -- limit: v < 2**32"""\n    ret = 1\n    m = (not not v & 0xFFFF0000) << 4;\n    v >>= m;\n    ret |= m;\n    m = (not not v & 0xFF00) << 3;\n    v >>= m;\n    ret |= m;\n    m = (not not v & 0xF0) << 2;\n    v >>= m;\n    ret |= m;\n    m = (not not v & 0xC) << 1;\n    v >>= m;\n    ret |= m;\n    ret += (not not v & 0x2);\n    return ret - 1;\n\n\n# following table is equal to "return hashlookup.prepareTable()" \nhash_table = {...} # numbers have been cut out to avoid cluttering the post\n\n# following table is equal to "return lookup.prepareTable()" - cached for speed\nlog2s_table = (...) # numbers have been cut out to avoid cluttering the post\n']], ['Finding the exponent of n = 2**x using bitwise operations [logarithm in base 2 of n]'], 5, 1], [(2257101, 0), [["You shouldn't call you variables dict and list, because then, you cant use the build-in methods any more. I have renamed them in this example."], ['But you can create a new list containing the (key, value)-tuples from the dictionary, which is sorted by the first list:']], [[" >>> l = [1, 2, 37, 32, 4]\n>>> d = dict = {\n...     32: 'Megumi', \n...     1: 'Ai',\n...     2: 'Risa',\n...     3: 'Eri', \n...     4: 'Sayumi', \n...     37: 'Mai'\n... }\n"]], ['Sorting dictionary keys by values in a list?'], 3, 0], [(2286557, 1), [["As pwdyson points out, if your stopwatches aren't good enough, you might get a tie. So this modification uses dicts instead of lists. The order of the placings is still preserved"], ['If there is a possibility of keys in the second dict that are not in the first you can do something like this']], [[' >>> from operator import itemgetter\n>>> \n>>> after_short_program = {\n...     \'Evgeni Plushenko\':1,\n...     \'Evan Lysacek\':2,\n...     \'Daisuke Takahashi\':3,\n...     \'Stephane Lambiel\':4,\n...     \'Nobunari Oda\':5,\n... }\n>>> \n>>> after_free_skate = {\n...     \'Evan Lysacek\':1,\n...     \'Daisuke Takahashi\':2,\n...     \'Evgeni Plushenko\':3,\n...     \'Stephane Lambiel\':4,   # These are tied\n...     \'Nobunari Oda\':4,       # at 4th place\n... }\n>>> \n>>> for k,v in sorted(after_free_skate.items(),key=itemgetter(1)):\n...     diff = after_short_program[k]-v\n...     print "%s (%+d)"%(k,diff)\n...     \n... \nEvan Lysacek (+1)\nDaisuke Takahashi (+1)\nEvgeni Plushenko (-2)\nNobunari Oda (+1)\nStephane Lambiel (+0)\n>>> \n']], ['Positional Comparisons in Python'], 3, 1], [(2286557, 2), [['If there is a possibility of keys in the second dict that are not in the first you can do something like this'], ['-10000']], [[' for k,v in sorted(after_free_skate.items(),key=itemgetter(1)):\n    try:\n        diff = after_short_program[k]-v\n        print "%s (%+d)"%(k,diff)\n    except KeyError:\n        print "%s (new)"%k\n']], ['Positional Comparisons in Python'], 3, 0], [(2305115, 0), [['For  python2.6'], ['For  python3.1']], [[' with open("file1") as infile:\n    with open("file2","w") as outfile:\n        for i,line in enumerate(infile):\n            if i==2:\n                # 3rd line\n                outfile.write("new line1\\n")\n                outfile.write("new line2\\n")\n                outfile.write("new line3\\n")\n            elif i==3:\n                # 4th line\n                pass\n            else:\n                outfile.write(line)\n']], ['Remove and insert lines in a text file'], 2, 1], [(2305115, 1), [['For  python3.1'], ['-10000']], [[' with open("file1") as infile, open("file2","w") as outfile:\n    for i,line in enumerate(infile):\n        if i==2:\n            # 3rd line\n            outfile.write("new line1\\n")\n            outfile.write("new line2\\n")\n            outfile.write("new line3\\n")\n        elif i==3:\n            # 4th line\n            pass\n        else:\n            outfile.write(line)\n']], ['Remove and insert lines in a text file'], 2, 1], [(2305501, 0), [['1.  Construct a CDF-like list like this:'], ['2.  Construct the sampler like this:']], [[' def build_cdf(distrib):\n    cdf = []\n    val = 0\n    for key, freq in distrib.items():\n        val += freq\n        cdf.append((val, key))\n    return (val, cdf)\n']], ['Sampling keys due to their values'], 3, 0], [(2305501, 1), [['2.  Construct the sampler like this:'], ['Usage:']], [[' import random\ndef sample_from_cdf(val_and_cdf):\n    (val, cdf) = val_and_cdf;\n    rand = random.uniform(0, val)\n    # use bisect.bisect_left to reduce search time from O(n) to O(log n).\n    return [key for index, key in cdf if index > rand][0]\n']], ['Sampling keys due to their values'], 3, 0], [(2305501, 2), [['Usage:'], ['You may want to make this into a class.']], [[' x = build_cdf({"a":0.2, "b":0.3, "c":0.5});\ny = [sample_from_cdf(x) for i in range(0,100000)];\nprint (len([t for t in y if t == "a"]))   # 19864\nprint (len([t for t in y if t == "b"]))   # 29760\nprint (len([t for t in y if t == "c"]))   # 50376\n']], ['Sampling keys due to their values'], 3, 0], [(2337285, 0), [['The documentation is out of date. Use the source, Luke. I do it something like this.'], ['This prints the following.']], [[" from xml.dom.minidom import DOMImplementation\n\nimp = DOMImplementation()\ndoctype = imp.createDocumentType(\n    qualifiedName='foo',\n    publicId='', \n    systemId='http://www.path.to.my.dtd.com/my.dtd',\n)\ndoc = imp.createDocument(None, 'foo', doctype)\ndoc.toxml()\n"]], ['Set a DTD using minidom in python'], 2, 1], [(2337285, 1), [['This prints the following.'], ["Note how the root element is created automatically by createDocument(). Also, your 'something' has been changed to 'foo': the DTD needs to contain the root element name itself."]], [[' <?xml version="1.0" ?><!DOCTYPE foo  SYSTEM \\\'http://www.path.to.my.dtd.com/my.dtd\\\'><foo/>\n']], ['Set a DTD using minidom in python'], 2, 0], [(2358890, 0), [['Adapting the tokenizer to your problem:'], ['To test it, we do:']], [[' import re\n\ntoken_pattern = r"""\n(?P<identifier>[a-zA-Z_][a-zA-Z0-9_]*)\n|(?P<integer>[0-9]+)\n|(?P<dot>\\.)\n|(?P<open_variable>[$][{])\n|(?P<open_curly>[{])\n|(?P<close_curly>[}])\n|(?P<newline>\\n)\n|(?P<whitespace>\\s+)\n|(?P<equals>[=])\n|(?P<slash>[/])\n"""\n\ntoken_re = re.compile(token_pattern, re.VERBOSE)\n\nclass TokenizerException(Exception): pass\n\ndef tokenize(text):\n    pos = 0\n    while True:\n        m = token_re.match(text, pos)\n        if not m: break\n        pos = m.end()\n        tokname = m.lastgroup\n        tokvalue = m.group(tokname)\n        yield tokname, tokvalue\n    if pos != len(text):\n        raise TokenizerException(\'tokenizer stopped at pos %r of %r\' % (\n            pos, len(text)))\n']], ['Python - lexical analysis and tokenization'], 3, 1], [(2358890, 1), [['To test it, we do:'], ['for:']], [[" stuff = r'property.${general.name}.ip = ${general.ip}'\nstuff2 = r'''\ngeneral {\n  name = myname\n  ip = 127.0.0.1\n}\n'''\n\nprint ' stuff '.center(60, '=')\nfor tok in tokenize(stuff):\n    print tok\n\nprint ' stuff2 '.center(60, '=')\nfor tok in tokenize(stuff2):\n    print tok\n"]], ['Python - lexical analysis and tokenization'], 3, 0], [(2358890, 2), [['for:'], ['-10000']], [[" ========================== stuff ===========================\n('identifier', 'property')\n('dot', '.')\n('open_variable', '${')\n('identifier', 'general')\n('dot', '.')\n('identifier', 'name')\n('close_curly', '}')\n('dot', '.')\n('identifier', 'ip')\n('whitespace', ' ')\n('equals', '=')\n('whitespace', ' ')\n('open_variable', '${')\n('identifier', 'general')\n('dot', '.')\n('identifier', 'ip')\n('close_curly', '}')\n========================== stuff2 ==========================\n('newline', '\\n')\n('identifier', 'general')\n('whitespace', ' ')\n('open_curly', '{')\n('newline', '\\n')\n('whitespace', '  ')\n('identifier', 'name')\n('whitespace', ' ')\n('equals', '=')\n('whitespace', ' ')\n('identifier', 'myname')\n('newline', '\\n')\n('whitespace', '  ')\n('identifier', 'ip')\n('whitespace', ' ')\n('equals', '=')\n('whitespace', ' ')\n('integer', '127')\n('dot', '.')\n('integer', '0')\n('dot', '.')\n('integer', '0')\n('dot', '.')\n('integer', '1')\n('newline', '\\n')\n('close_curly', '}')\n('newline', '\\n')\n"]], ['Python - lexical analysis and tokenization'], 3, 0], [(2363954, 0), [['First create a function which can load a given file, as you may want to maintain individual sets and also want to count occurrence of each number, best would be to have a dict for whole file where keys are set names e.g. complex.1 etc, for each such set keep another dict for numbers in set, below code explains it better'], ['Now you can easily write a function which will count a number in given file_dict']], [[" def file_loader(f):\n    file_dict = {}\n    current_set = None\n    for line in f:\n        if line.startswith('d.complex'):\n            file_dict[line] = current_set = {}\n            continue\n\n        if current_set is not None:\n            current_set[line] = current_set.get(line, 0)\n\n    return file_dict\n"]], ['Comparing two lists items in python'], 4, 0], [(2363954, 1), [['Now you can easily write a function which will count a number in given file_dict'], ['e.g here is a usage example']], [[' def count_number(file_dict, num):\n    count = 0\n    for set_name, number_set in file_dict.iteritems():\n        count += number_set.get(num, 0)\n\n    return count\n']], ['Comparing two lists items in python'], 4, 0], [(2363954, 2), [['e.g here is a usage example'], ['output is:']], [[' s = """d.complex.1\n10\n11\n12\n10\n11\n12"""\n\nfile_dict = file_loader(s.split("\\n"))\nprint file_dict\nprint count_number(file_dict, \'10\')\n']], ['Comparing two lists items in python'], 4, 0], [(2363954, 3), [['output is:'], ['You may have to improve file loader, e.g. skip empty lines, convert to int etc']], [[" {'d.complex.1': {'11': 2, '10': 2, '12': 2}}\n2\n"]], ['Comparing two lists items in python'], 4, 0], [(2382905, 0), [['It looks like you might be in need of'], ['Or if you simply need to iterate over this and not necessarily form the list, use']], [[' mus.extend(reversed(mus))\n']], ['Creating a palindrome list with reverse()'], 2, 1], [(2382905, 1), [['Or if you simply need to iterate over this and not necessarily form the list, use'], ['-10000']], [[' import itertools\nfor item in itertools.chain(mus, reversed(mus)):\n    do_something...\n']], ['Creating a palindrome list with reverse()'], 2, 0], [(2389846, 0), [['If you have Python 2.6 or newer, use  format :'], ['For Python 2.5 or older:']], [[" '{0:.3g}'.format(num)\n"]], ['Python Decimals format'], 4, 1], [(2389846, 1), [['For Python 2.5 or older:'], ['For example:']], [[" '%.3g'%(num)\n"]], ['Python Decimals format'], 4, 1], [(2389846, 2), [['For example:'], ['yields']], [[" tests=[(1.00, '1'),\n       (1.2, '1.2'),\n       (1.23, '1.23'),\n       (1.234, '1.23'),\n       (1.2345, '1.23')]\n\nfor num, answer in tests:\n    result = '{0:.3g}'.format(num)\n    if result != answer:\n        print('Error: {0} --> {1} != {2}'.format(num, result, answer))\n        exit()\n    else:\n        print('{0} --> {1}'.format(num,result))\n"]], ['Python Decimals format'], 4, 1], [(2389846, 3), [['yields'], ['-10000']], [[' 1.0 --> 1\n1.2 --> 1.2\n1.23 --> 1.23\n1.234 --> 1.23\n1.2345 --> 1.23\n']], ['Python Decimals format'], 4, 0], [(2397295, 0), [['Use  BeautifulSoup  as a tree builder for  html5lib :'], ['Output:']], [[' from html5lib import HTMLParser, treebuilders\n\nparser = HTMLParser(tree=treebuilders.getTreeBuilder("beautifulsoup"))\n\ntext = "a<b>b<b>c"\nsoup = parser.parse(text)\nprint soup.prettify()\n']], ['Web scraping with Python'], 2, 1], [(2397295, 1), [['Output:'], ['-10000']], [[' <html>\n <head>\n </head>\n <body>\n  a\n  <b>\n   b\n   <b>\n    c\n   </b>\n  </b>\n </body>\n</html>\n']], ['Web scraping with Python'], 2, 0], [(2454494, 0), [['However,'], ['Indeed, this appears to be the case.']], [[' help(httplib.HTTPMessage)\n...\n\nIf multiple header fields with the same name occur, they are combined\naccording to the rules in RFC 2616 sec 4.2:\n\nAppending each subsequent field-value to the first, each separated\nby a comma. The order in which header fields with the same field-name\nare received is significant to the interpretation of the combined\nfield value.\n']], ['urllib2 multiple Set-Cookie headers in response'], 2, 0], [(2454494, 1), [['Indeed, this appears to be the case.'], ['-10000']], [[' import httplib\nfrom StringIO import StringIO\n\nmsg = \\\n"""Set-Cookie: Foo\nSet-Cookie: Bar\nSet-Cookie: Baz\n\nThis is the message"""\n\nmsg = StringIO(msg)\n\nmsg = httplib.HTTPMessage(msg)\n\nassert msg[\'Set-Cookie\'] == \'Foo, Bar, Baz\'\n']], ['urllib2 multiple Set-Cookie headers in response'], 2, 1], [(2468334, 0), [['-10000'], ['or shorter:']], [[' userdata = { "data":[]}\n\ndef fil_userdata():\n  for i in xrange(0,5):\n    user = {}\n    user["name"]=...\n    user["age"]=...\n    user["country"]=...\n    add_user(user)\n\ndef add_user(user):\n  userdata["data"].append(user)\n']], ['Python | How to create dynamic and expandable dictionaries'], 2, 1], [(2468334, 1), [['or shorter:'], ['-10000']], [[' def gen_user():\n  return {"name":"foo", "age":22}\n\nuserdata = {"data": [gen_user() for i in xrange(0,5)]}\n\n# or fill separated from declaration so you can fill later\nuserdata ={"data":None} # None: not initialized\nuserdata["data"]=[gen_user() for i in xrange(0,5)]\n']], ['Python | How to create dynamic and expandable dictionaries'], 2, 1], [(2470764, 0), [['Create an auxiliary dict (work is  O(len(A) ) -- assuming the first three items of a sublist in A uniquely identify it (otherwise you need a dict of lists):'], ['Use said dict to loop once on B (work is  O(len(B)) ) to get B sublists and A indices:']], [[' aud = dict((tuple(a[:3]), i) for i, a in enumerate(A))\n']], ['python union of 2 nested lists with index'], 2, 0], [(2470764, 1), [['Use said dict to loop once on B (work is  O(len(B)) ) to get B sublists and A indices:'], ['-10000']], [[' result = [(b, aud[tuple(b[:3])]) for b in B if tuple(b[:3]) in aud]\n']], ['python union of 2 nested lists with index'], 2, 0], [(2534786, 0), [["First, let's start with a simple  Point  class:"], ['A cubic B-spline is nothing more than a collection of  Point  objects:']], [[' from collections import namedtuple\n\nclass Point(namedtuple("Point", "x y")):\n    __slots__ = ()\n\n    def interpolate(self, other, ratio = 0.5):\n        return Point(x = self.x * (1.0-ratio) + other.x * float(ratio), \\\n                     y = self.y * (1.0-ratio) + other.y * float(ratio))\n']], ['Drawing a clamped uniform cubic B-spline using Cairo'], 5, 0], [(2534786, 1), [['A cubic B-spline is nothing more than a collection of  Point  objects:'], ['We have to repeat the above procedure for each group of 4 consecutive points of the B-spline, so in the end we will need the 1:2 and 2:1 division points between almost any consecutive control point pairs. This is what the following  BSplineDrawer  class does before drawing the curves:']], [[' class CubicBSpline(object):\n    __slots__ = ("points", )\n\n    def __init__(self, points):\n        self.points = [Point(*coords) for coords in points]\n']], ['Drawing a clamped uniform cubic B-spline using Cairo'], 5, 0], [(2534786, 2), [['We have to repeat the above procedure for each group of 4 consecutive points of the B-spline, so in the end we will need the 1:2 and 2:1 division points between almost any consecutive control point pairs. This is what the following  BSplineDrawer  class does before drawing the curves:'], ['Finally, if we want to draw clamped B-splines instead of open B-splines, we simply have to repeat both endpoints of the clamped B-spline three more times:']], [[' class BSplineDrawer(object):\n    def __init__(self, context):\n        self.ctx = context\n\n    def draw(self, bspline):\n        pairs = zip(bspline.points[:-1], bspline.points[1:])\n        one_thirds = [p1.interpolate(p2, 1/3.) for p1, p2 in pairs)\n        two_thirds = [p2.interpolate(p1, 1/3.) for p1, p2 in pairs)\n\n        coords = [None] * 6\n        for i in xrange(len(bspline.points) - 3):\n            start = two_thirds[i].interpolate(one_thirds[i+1])\n            coords[0:2] = one_thirds[i+1]\n            coords[2:4] = two_thirds[i+1]\n            coords[4:6] = two_thirds[i+1].interpolate(one_thirds[i+2])\n\n            self.context.move_to(*start)\n            self.context.curve_to(*coords)\n            self.context.stroke()\n']], ['Drawing a clamped uniform cubic B-spline using Cairo'], 5, 0], [(2534786, 3), [['Finally, if we want to draw clamped B-splines instead of open B-splines, we simply have to repeat both endpoints of the clamped B-spline three more times:'], ['Finally, this is how the code should be used:']], [[' class CubicBSpline(object):\n    [...]\n    def clamped(self):\n        new_points = [self.points[0]] * 3 + self.points + [self.points[-1]] * 3\n        return CubicBSpline(new_points)\n']], ['Drawing a clamped uniform cubic B-spline using Cairo'], 5, 0], [(2534786, 4), [['Finally, this is how the code should be used:'], ['-10000']], [[' import cairo\n\nsurface = cairo.ImageSurface(cairo.FORMAT_ARGB32, 600, 400)\nctx = cairo.Context(surface)\n\npoints = [(100,100), (200,100), (200,200), (100,200), (100,400), (300,400)]\nspline = CubicBSpline(points).clamped()\n\nctx.set_source_rgb(0., 0., 1.)\nctx.set_line_width(5)\nBSplineDrawer(ctx).draw(spline)\n']], ['Drawing a clamped uniform cubic B-spline using Cairo'], 5, 0], [(2572099, 0), [['The function to set the password:'], ['And the function to check the password:']], [[" def set_password(self, raw_password):\n    import random\n    algo = 'sha1'\n    salt = get_hexdigest(algo, str(random.random()), str(random.random()))[:5]\n    hsh = get_hexdigest(algo, salt, raw_password)\n    self.password = '%s$%s$%s' % (algo, salt, hsh)\n"]], ["Python's safest method to store and retrieve passwords from a database"], 2, 0], [(2572099, 1), [['And the function to check the password:'], ['-10000']], [[' def check_password(raw_password, enc_password):\n    """\n    Returns a boolean of whether the raw_password was correct. Handles\n    encryption formats behind the scenes.\n    """\n    algo, salt, hsh = enc_password.split(\'$\')\n    return hsh == get_hexdigest(algo, salt, raw_password)\n']], ["Python's safest method to store and retrieve passwords from a database"], 2, 0], [(2575672, 0), [['Using  xml  from the standard Python library:'], ['Or using  lxml :']], [[' import xml.etree.ElementTree as xee\ncontents=\'\'\'\\\n<?xml version="1.0" encoding="UTF-8"?>\n<Response>\n  <Ip>74.125.45.100</Ip>\n  <Status>OK</Status>\n  <CountryCode>US</CountryCode>\n  <CountryName>United States</CountryName>\n  <RegionCode>06</RegionCode>\n  <RegionName>California</RegionName>\n  <City>Mountain View</City>\n  <ZipPostalCode>94043</ZipPostalCode>\n  <Latitude>37.4192</Latitude>\n  <Longitude>-122.057</Longitude>\n  <TimezoneName>America/Los_Angeles</TimezoneName>\n  <Gmtoffset>-25200</Gmtoffset>\n  <Isdst>1</Isdst>\n</Response>\'\'\'\n\ndoc=xee.fromstring(contents)\nprint dict(((elt.tag,elt.text) for elt in doc))\n']], ["What's an easy and fast way to put returned XML data into a dict?"], 2, 1], [(2575672, 1), [['Or using  lxml :'], ['-10000']], [[" import lxml.etree\nimport urllib2\nurl='http://ipinfodb.com/ip_query.php?ip=74.125.45.100&timezone=true'\ndoc = lxml.etree.parse( urllib2.urlopen(url) ).getroot()\nprint dict(((elt.tag,elt.text) for elt in doc))\n"]], ["What's an easy and fast way to put returned XML data into a dict?"], 2, 1], [(2588364, 0), [['I fixed it. Here is working TEA implementation in python:'], ['And a small sample:']], [[' #!/usr/bin/env python\n#-*- coding: utf-8 -*-\n\nimport sys\nfrom ctypes import *\n\ndef encipher(v, k):\n    y = c_uint32(v[0])\n    z = c_uint32(v[1])\n    sum = c_uint32(0)\n    delta = 0x9e3779b9\n    n = 32\n    w = [0,0]\n\n    while(n>0):\n        sum.value += delta\n        y.value += ( z.value << 4 ) + k[0] ^ z.value + sum.value ^ ( z.value >> 5 ) + k[1]\n        z.value += ( y.value << 4 ) + k[2] ^ y.value + sum.value ^ ( y.value >> 5 ) + k[3]\n        n -= 1\n\n    w[0] = y.value\n    w[1] = z.value\n    return w\n\ndef decipher(v, k):\n    y = c_uint32(v[0])\n    z = c_uint32(v[1])\n    sum = c_uint32(0xc6ef3720)\n    delta = 0x9e3779b9\n    n = 32\n    w = [0,0]\n\n    while(n>0):\n        z.value -= ( y.value << 4 ) + k[2] ^ y.value + sum.value ^ ( y.value >> 5 ) + k[3]\n        y.value -= ( z.value << 4 ) + k[0] ^ z.value + sum.value ^ ( z.value >> 5 ) + k[1]\n        sum.value -= delta\n        n -= 1\n\n    w[0] = y.value\n    w[1] = z.value\n    return w\n\nif __name__ == "__main__":\n    key = [1,2,3,4]\n    v = [1385482522,639876499]\n    enc = encipher(v,key)\n    print enc\n    print decipher(enc,key)\n']], ['Python TEA implementation'], 2, 1], [(2588364, 1), [['And a small sample:'], ['-10000']], [[' >>> v\n[1385482522, 639876499]\n>>> tea.decipher(tea.encipher(v,key),key)\n[1385482522L, 639876499L]\n']], ['Python TEA implementation'], 2, 0], [(2621549, 0), [['Using only AWK:'], ['As a one-liner:']], [[' awk -F, -vOFS=, -vc=1 \'\n    NR == 1 {\n        for (i=1; i<NF; i++) {\n            if ($i != "") {\n                g[c]=i;\n                f[c++]=$i\n            }\n        }\n    }\n    NR>2 {\n        for (i=1; i < c; i++) {\n            print $1,$2, $g[i] > "output_"f[i]".csv"\n        }\n    }\' data.csv\n']], ['Creating multiple csv files from data within a csv file'], 3, 1], [(2621549, 1), [['As a one-liner:'], ['Example output:']], [[' awk -F, -vOFS=, -vc=1 \'NR == 1 {for (i=1; i<NF; i++) {if ($i != "") {g[c]=i; f[c++]=$i}}} NR>2 { for (i=1; i < c; i++) {print $1,$2, $g[i] > "file_"f[i]".csv" }}\' data.csv\n']], ['Creating multiple csv files from data within a csv file'], 3, 1], [(2621549, 2), [['Example output:'], ['-10000']], [[' $ cat file_L1.csv\nEXAMPLEfoo,60,6\nEXAMPLEbar,30,6\nEXAMPLE1,60,3\nEXAMPLE2,120,6\nEXAMPLE3,60,6\nEXAMPLE4,30,6\n$ cat file_L2.csv\nEXAMPLEfoo,60,0\nEXAMPLEbar,30,6\nEXAMPLE1,60,3\nEXAMPLE2,120,0\nEXAMPLE3,60,6\nEXAMPLE4,30,6\n$ cat file_L11.csv\nEXAMPLEfoo,60,0\nEXAMPLEbar,30,6\nEXAMPLE1,60,3\nEXAMPLE2,120,0\nEXAMPLE3,60,0\nEXAMPLE4,30,6\n']], ['Creating multiple csv files from data within a csv file'], 3, 0], [(2654689, 0), [['The  signal  part is how you hook in a function to create a profile for a new User:'], ['This only creates a new profile for a new User.  Existing Users need to have profiles manually added:']], [[' from django.db.models.signals import post_save\nfrom django.contrib.auth import User\nfrom myUserProfileApp import UserProfile\n\ndef make_user_profile(sender, **kwargs):\n    if \'created\' not in kwargs or not kwargs[\'created\']:\n        return\n\n    # Assumes that the `ForeignKey(User)` field in "UserProfile" is named "user".\n    profile = UserProfile(user=kwargs["instance"])\n    # Set anything else you need to in the profile, then...\n    profile.save()\n\npost_save.connect(make_user_profile, sender=User, weak=False)\n']], ['Django - how to write users and profiles handling in best way?'], 3, 0], [(2654689, 1), [['This only creates a new profile for a new User.  Existing Users need to have profiles manually added:'], ["If you have some users with profiles and some without, you'll need to do a bit more work:"]], [[' $ ./manage.py shell\n>>> from django.contrib.auth import User\n>>> from myUserProfileApp import UserProfile\n>>> for u in User.objects.all():\n...  UserProfile(user=u).save() # Add other params as needed.\n...\n']], ['Django - how to write users and profiles handling in best way?'], 3, 0], [(2654689, 2), [["If you have some users with profiles and some without, you'll need to do a bit more work:"], ['-10000']], [[' >>> for u in User.objects.all():\n...  try:\n...   UserProfile(user=u).save() # Add other params as needed.\n...  except:\n...   pass\n']], ['Django - how to write users and profiles handling in best way?'], 3, 0], [(2658026, 0), [["Monkey-patching  time.time  is probably sufficient, actually, as it provides the basis for almost all the other time-based routines in Python.  This appears to handle your use case pretty well, without resorting to more complex tricks, and it doesn't matter when you do it (aside from the few stdlib packages like Queue.py and threading.py that do  from time import time  in which case you must patch before they get imported):"], ['The best approach by far is to build your own date/time service routine(s) which you use exclusively in your application code, and build into that the ability for tests to supply fake results as required.  For example, I do a more complex equivalent of this sometimes:']], [[' >>> import datetime\n>>> datetime.datetime.now()\ndatetime.datetime(2010, 4, 17, 14, 5, 35, 642000)\n>>> import time\n>>> def mytime(): return 120000000.0\n...\n>>> time.time = mytime\n>>> datetime.datetime.now()\ndatetime.datetime(1973, 10, 20, 17, 20)\n']], ['How to change the date/time in Python for all modules?'], 2, 1], [(2716894, 0), [['Numpy has a  dedicated function  for creating histograms the way you need to:'], ['which you can use like:']], [[' histogram(a, bins=10, range=None, normed=False, weights=None, new=None)\n']], ['making binned boxplot in matplotlib with numpy and scipy in Python'], 5, 0], [(2716894, 1), [['which you can use like:'], ['The key point here is to use the  weights  argument: each value  a[i]  will contribute  weights[i]  to the histogram.  Example:']], [[' (hist_data, bin_edges) = histogram(my_array[:,0], weights=my_array[:,1])\n']], ['making binned boxplot in matplotlib with numpy and scipy in Python'], 5, 0], [(2716894, 2), [['The key point here is to use the  weights  argument: each value  a[i]  will contribute  weights[i]  to the histogram.  Example:'], ['The histogram can then be plotted with something like:']], [[' a = [0, 1]\nweights = [10, 2]\n']], ['making binned boxplot in matplotlib with numpy and scipy in Python'], 5, 0], [(2716894, 3), [['The histogram can then be plotted with something like:'], ['If you only need to do a histogram  plot , the similar  hist()  function can directly plot the histogram:']], [[' bar(bin_edges[:-1], hist_data)\n']], ['making binned boxplot in matplotlib with numpy and scipy in Python'], 5, 0], [(2717086, 0), [['I see no  \\r\\n  here. Perhaps you mean repr(xml) contains things like'], ['The following should work:']], [[' "<ParentRedirec\\r\\ntSequenceID>"\n']], ['Dealing with Windows line-endings in Python'], 2, 0], [(2726839, 0), [['Simple approach(untested but should work):'], ['EDIT \nSince you may not want to create your Entry in Python I\'m going to show you a simple way to "numbify" an existing one.']], [[" class NumberEntry(gtk.Entry):\n    def __init__(self):\n        gtk.Entry.__init__(self)\n        self.connect('changed', self.on_changed)\n\n    def on_changed(self, *args):\n        text = self.get_text().strip()\n        self.set_text(''.join([i for i in text if i in '0123456789']))\n"]], ['Creating a pygtk text field that only accepts number'], 2, 1], [(2726839, 1), [['EDIT \nSince you may not want to create your Entry in Python I\'m going to show you a simple way to "numbify" an existing one.'], ['-10000']], [["     def numbify(widget):\n        def filter_numbers(entry, *args):\n            text = entry.get_text().strip()\n            entry.set_text(''.join([i for i in text if i in '0123456789']))\n\n        widget.connect('changed', filter_numbers)\n\n    # Use gtk.Builder rather than glade, you'll need to change the format of your .glade file in Glade accordingly\n    builder = gtk.Builder()\n    builder.add_from_file('yourprogram.glade')\n    entry = builder.get_object('yourentry')\n\n    numbify(entry)\n"]], ['Creating a pygtk text field that only accepts number'], 2, 1], [(2743712, 0), [['set following in  {OSQA_ROOT}\\settings_local.py'], ['-10000']], [[" DATABASE_NAME = 'osqa'             # Or path to database file if using sqlite3.\nDATABASE_USER = 'root'               # Not used with sqlite3.\nDATABASE_PASSWORD = 'PASSWD'               # Not used with sqlite3.  put bitnami here\nDATABASE_ENGINE = 'mysql'  #mysql, etc\n"]], ['Installing OSQA on windows (local system)'], 5, 0], [(2743712, 1), [['-10000'], ['-10000']], [[' <location \'/\'>\n    SetHandler python-program\n    PythonHandler django.core.handlers.modpython\n    PythonPath "[\'{OSQA_ROOT}\'] + sys.path"\n    SetEnv DJANGO_SETTINGS_MODULE osqa.settings\n    PythonDebug On\n</location>\n']], ['Installing OSQA on windows (local system)'], 5, 0], [(2743712, 2), [['-10000'], ['-10000']], [[' easy_install markdown2\neasy_install html5lib\n']], ['Installing OSQA on windows (local system)'], 5, 0], [(2743712, 3), [['-10000'], ['-10000']], [[' mysqladmin create osqa\n']], ['Installing OSQA on windows (local system)'], 5, 0], [(2743712, 4), [['-10000'], ['-10000']], [[' {DJANGOSTACK}\\python\\python.exe manage.py syncdb\n']], ['Installing OSQA on windows (local system)'], 5, 0], [(2777188, 0), [['No, in general you cannot make a Python iterator go backwards. However, if you only want to step back once, you can try something like this:'], ["If you really need a bidirectional iterator, you can implement one yourself, but it's likely to introduce even more overhead than the solution above:"]], [[' def str(self, item):\n    print item\n\n    prev, current = None, self.__iter.next()\n    while isinstance(current, int):\n        print current\n        prev, current = current, self.__iter.next()\n']], ['Making a python iterator go backwards?'], 2, 0], [(2777188, 1), [["If you really need a bidirectional iterator, you can implement one yourself, but it's likely to introduce even more overhead than the solution above:"], ['-10000']], [[' class bidirectional_iterator(object):\n    def __init__(self, collection):\n        self.collection = collection\n        self.index = 0\n\n    def next(self):\n        try:\n            result = self.collection[self.index]\n            self.index += 1\n        except IndexError:\n            raise StopIteration\n        return result\n\n    def prev(self):\n        self.index -= 1\n        if self.index < 0:\n            raise StopIteration\n        return self.collection[self.index]\n\n    def __iter__(self):\n        return self\n']], ['Making a python iterator go backwards?'], 2, 1], [(2785714, 1), [['Or trying both wont hurt either I spose:'], ['-10000']], [[" url = 'domain.com/'\nfor domain in list:\n    domain_minus_www = domain\n    if domain_minus_www.startswith('www.'):\n        domain_minus_www = domain_minus_www[4:]\n    if url.startswith(domain) or url.startswith(domain_minus_www):\n        ... do something ...\n"]], ['Parsing html for domain links'], 2, 1], [(2857634, 0), [['The  foo_cli  module looks like this.'], ['The  foo_gui  module can look like this.']], [[' import foo_core\nimport optparse\n\ndef main():\n    # parse the command-line options\n    # the real work is done by foo_core\n\nif __name__ == "__main__":\n   main()\n']], ['How can I create a GUI on top of a Python APP so it can do either GUI or CLI?'], 3, 0], [(2857634, 1), [['The  foo_gui  module can look like this.'], ['If you want to confuse people, you can write a  foo.py  script that does something like the following.']], [['  import foo_core\n import gtk # or whatever\n\n def main()\n     # build the GUI\n     # real work is done by foo_core under control of the GUI\n\n if __name__ == "__main__":\n     main()\n']], ['How can I create a GUI on top of a Python APP so it can do either GUI or CLI?'], 3, 0], [(2857634, 2), [['If you want to confuse people, you can write a  foo.py  script that does something like the following.'], ['-10000']], [[' try:\n    import foo_gui\n    foo_gui.main()\nexcept ImportError:\n    import foo_cli\n    foo_cli.main()\n']], ['How can I create a GUI on top of a Python APP so it can do either GUI or CLI?'], 3, 0], [(2882308, 0), [['In, say,  alice.py :'], ['In, say,  bob.py :']], [[" def do_stuff(data):\n    print 'alice does stuff with %s' % data\n"]], ['Spawning a thread in python'], 3, 0], [(2882308, 1), [['In, say,  bob.py :'], ['Then in your client code, say,  main.py :']], [[" def do_stuff(data):\n    print 'bob does stuff with %s' % data\n"]], ['Spawning a thread in python'], 3, 0], [(2882308, 2), [['Then in your client code, say,  main.py :'], ['Let me know if I need to clarify.']], [[" import threading\nimport alice, bob\n\ndef get_work_data():\n    return 'data'\n\ndef main():\n    tasks = [alice.do_stuff, bob.do_stuff]\n    data = get_work_data()\n    for task in tasks:\n        t = threading.Thread(target=task, args=(data,))\n        t.start()\n"]], ['Spawning a thread in python'], 3, 1], [(2922769, 0), [["First, start up the IronPython engine on a separate thread (as you assumed). When you go to run the user's code, wrap it in a  try ... catch(ThreadAbortException)  block:"], ["Now, you'll need to keep a reference to the IronPython thread handy. Create a button handler on your form, and call  Thread.Abort() ."]], [[' var engine = Python.CreateEngine();\nbool aborted = false;\ntry {\n    engine.Execute(/* whatever */);\n} catch(ThreadAbortException tae) {\n    if(tae.ExceptionState is Microsoft.Scripting.KeyboardInterruptException) {\n        Thread.ResetAbort();\n        aborted = true;\n    } else { throw; }\n}\n\nif(aborted) {\n    // this is application-specific\n}\n']], ['Embedding IronPython in a WinForms app and interrupting execution'], 2, 0], [(2922769, 1), [["Now, you'll need to keep a reference to the IronPython thread handy. Create a button handler on your form, and call  Thread.Abort() ."], ['The  KeyboardInterruptException  argument allows the Python thread to trap the  ThreadAbortException  and handle it as a  KeyboardInterrupt .']], [[' public void StopButton_OnClick(object sender, EventArgs e) {\n    pythonThread.Abort(new Microsoft.Scripting.KeyboardInterruptException(""));\n}\n']], ['Embedding IronPython in a WinForms app and interrupting execution'], 2, 0], [(2939050, 0), [["CrawlSpider rules don't work that way. You'll probably need to subclass BaseSpider and implement your own link extraction in your spider callback. For example:"], ['You can also try the XPath in the shell, by running for example:']], [[' from scrapy.spider import BaseSpider\nfrom scrapy.http import Request\nfrom scrapy.selector import XmlXPathSelector\n\nclass MySpider(BaseSpider):\n    name = \'myspider\'\n\n    def parse(self, response):\n        xxs = XmlXPathSelector(response)\n        links = xxs.select("//link/text()").extract()\n        return [Request(x, callback=self.parse_link) for x in links]\n']], ['Scrapy - Follow RSS links'], 3, 1], [(2939050, 1), [['You can also try the XPath in the shell, by running for example:'], ['And then typing in the shell:']], [[' scrapy shell http://blog.scrapy.org/rss.xml\n']], ['Scrapy - Follow RSS links'], 3, 0], [(2939050, 2), [['And then typing in the shell:'], ['-10000']], [[' >>> xxs.select("//link/text()").extract()\n[u\'http://blog.scrapy.org\',\n u\'http://blog.scrapy.org/new-bugfix-release-0101\',\n u\'http://blog.scrapy.org/new-scrapy-blog-and-scrapy-010-release\']\n']], ['Scrapy - Follow RSS links'], 3, 0], [(2951701, 0), [['The syntax  a if b else c  is a ternary operator in Python that evaluates to  a  if the condition  b  is true - otherwise, it evaluates to  c . It can be used in comprehension statements:'], ['So for your example,']], [[' >>> [a if a else 2 for a in [0,1,0,3]]\n[2, 1, 2, 3]\n']], ["Is it possible to use 'else' in a python list comprehension?"], 2, 1], [(2951701, 1), [['So for your example,'], ['-10000']], [[" table = ''.join(chr(index) if index in ords_to_keep else replace_with\n                for index in xrange(15))\n"]], ["Is it possible to use 'else' in a python list comprehension?"], 2, 1], [(2964751, 0), [['Hehe, at first I wrote this:'], ['but then I discovered that there is a nifty little method called  convex_hull  that does the polygon conversion for you automatically.']], [[' def close_geometry(self, geometry):\n   if geometry.empty or geometry[0].empty:\n       return geometry # empty\n\n   if(geometry[-1][-1] == geometry[0][0]):\n       return geometry  # already closed\n\n   result = None\n   for linestring in geom:\n      if result is None:\n          resultstring = linestring.clone()\n      else:\n          resultstring.extend(linestring.coords)\n\n   geom = Polygon(resultstring)\n\n   return geom\n']], ['How to convert a GEOS MultiLineString to Polygon using Python?'], 2, 1], [(2964751, 1), [['but then I discovered that there is a nifty little method called  convex_hull  that does the polygon conversion for you automatically.'], ['-10000']], [[' >>> s1 = LineString((0, 0), (1, 1), (1, 2), (0, 1))\n>>> s1.convex_hull\n<Polygon object at ...>\n>>> s1.convex_hull.coords\n(((0.0, 0.0), (0.0, 1.0), (1.0, 2.0), (1.0, 1.0), (0.0, 0.0)),)\n\n>>> m1=MultiLineString(s1)\n>>> m1.convex_hull\n<Polygon object at...>\n>>> m1.convex_hull.coords\n(((0.0, 0.0), (0.0, 1.0), (1.0, 2.0), (1.0, 1.0), (0.0, 0.0)),)\n']], ['How to convert a GEOS MultiLineString to Polygon using Python?'], 2, 1], [(2983959, 0), [['You can write your own split function for lists quite easily by using yield:'], ['An alternative way is to use  list.index  and catch the exception:']], [[' def split_list(l, sep):\n    current = []\n    for x in l:\n        if x == sep:\n            yield current\n            current = []\n        else:\n            current.append(x)\n    yield current\n']], ['Splitting a list in python'], 4, 1], [(2983959, 1), [['An alternative way is to use  list.index  and catch the exception:'], ['Either way you can call it like this:']], [[' def split_list(l, sep):\n    i = 0\n    try:\n        while True:\n            j = l.index(sep, i)\n            yield l[i:j]\n            i = j + 1\n    except ValueError:\n        yield l[i:]\n']], ['Splitting a list in python'], 4, 1], [(2983959, 2), [['Either way you can call it like this:'], ['Result:']], [[" l = ['(', '2', '.', 'x', '.', '(', '3', '-', '1', ')', '+', '4', ')',\n     '/', '3', '.', 'x', '^', '2']\n\nfor r in split_list(l, '+'):\n    print r\n"]], ['Splitting a list in python'], 4, 0], [(2983959, 3), [['Result:'], ['For parsing in Python you might also want to look at something like  pyparsing .']], [[" ['(', '2', '.', 'x', '.', '(', '3', '-', '1', ')']\n['4', ')', '/', '3', '.', 'x', '^', '2']\n"]], ['Splitting a list in python'], 4, 0], [(3038661, 0), [["The comments made me curious as to how the performance of pygraph was for a problem on the order of the OP, so I made a toy program to find out. Here's the output for a slightly smaller version of the problem:"], ["I'd like to say that the process scales well, but I'm still waiting on  biggraph 5 6  on an otherwise idled computer (Athlon 64, 4800  BogoMIPS  per processor, all in core) which has been running for over a quarter hour. At least the memory use is stable at about 0.5GB. And the results are in:"]], [[' $ python2.6 biggraph.py 4 6\nbiggraph generate 10000 nodes     00:00:00\nbiggraph generate 1000000 edges   00:00:00\nbiggraph add edges                00:00:05\nbiggraph Dijkstra                 00:01:32\nbiggraph shortest_path done       00:04:15\nstep: 1915 2\nstep: 0 1\nbiggraph walk done                00:04:15\npath: [9999, 1915, 0]\n']], ['Efficiently finding the shortest path in large graphs'], 3, 0], [(3038661, 1), [["I'd like to say that the process scales well, but I'm still waiting on  biggraph 5 6  on an otherwise idled computer (Athlon 64, 4800  BogoMIPS  per processor, all in core) which has been running for over a quarter hour. At least the memory use is stable at about 0.5GB. And the results are in:"], ["That's a long time, but it was also a heavy computation (and I really wish I'd pickled the result). Here's the code for the curious:"]], [[' biggraph generate 100000 nodes    00:00:00\nbiggraph generate 1000000 edges   00:00:00\nbiggraph add edges                00:00:07\nbiggraph Dijkstra                 00:01:27\nbiggraph shortest_path done       00:23:44\nstep: 48437 4\nstep: 66200 3\nstep: 83824 2\nstep: 0 1\nbiggraph walk done                00:23:44\npath: [99999, 48437, 66200, 83824, 0]\n']], ['Efficiently finding the shortest path in large graphs'], 3, 0], [(3038661, 2), [["That's a long time, but it was also a heavy computation (and I really wish I'd pickled the result). Here's the code for the curious:"], ['-10000']], [[' #!/usr/bin/python\n\nimport pygraph.classes.graph\nimport pygraph.algorithms\nimport pygraph.algorithms.minmax\nimport time\nimport random\nimport sys\n\nif len(sys.argv) != 3:\n    print (\'usage %s: node_exponent edge_exponent\' % sys.argv[0])\n    sys.exit(1)\n\nnnodes = 10**int(sys.argv[1])\nnedges = 10**int(sys.argv[2])\n\nstart_time = time.clock()\ndef timestamp(s):\n    t = time.gmtime(time.clock() - start_time)\n    print \'biggraph\', s.ljust(24), time.strftime(\'%H:%M:%S\', t)\n\ntimestamp(\'generate %d nodes\' % nnodes)\nbg = pygraph.classes.graph.graph()\nbg.add_nodes(xrange(nnodes))\n\ntimestamp(\'generate %d edges\' % nedges)\nedges = set()\nwhile len(edges) < nedges:\n    left, right = random.randrange(nnodes), random.randrange(nnodes)\n    if left == right:\n        continue\n    elif left > right:\n        left, right = right, left\n    edges.add((left, right))\n\ntimestamp(\'add edges\')\nfor edge in edges:\n    bg.add_edge(edge)\n\ntimestamp("Dijkstra")\ntarget = 0\nspan, dist = pygraph.algorithms.minmax.shortest_path(bg, target)\ntimestamp(\'shortest_path done\')\n\n# the paths from any node to target is in dict span, let\'s\n# pick any arbitrary node (the last one) and walk to the\n# target from there, the associated distance will decrease\n# monotonically\nlastnode = nnodes - 1\npath = []\nwhile lastnode != target:\n    nextnode = span[lastnode]\n    print \'step:\', nextnode, dist[lastnode]\n    assert nextnode in bg.neighbors(lastnode)\n    path.append(lastnode)\n    lastnode = nextnode\npath.append(target)\ntimestamp(\'walk done\')\nprint \'path:\', path\n']], ['Efficiently finding the shortest path in large graphs'], 3, 1], [(3065624, 0), [["It gives a ~50x speedup, and a larger speedup is possible if you're okay with the output being numpy arrays instead of lists.  As is:"], ['You can replace your inner loop with a call to np.cumsum()... See my "new_function" function below. This gives a considerable speedup...']], [[' In [86]: %timeit new_function2(close, volume, INTERVAL_LENGTH)\n1 loops, best of 3: 1.15 s per loop\n']], ['How to speed-up python nested loop?'], 4, 0], [(3065624, 1), [['You can replace your inner loop with a call to np.cumsum()... See my "new_function" function below. This gives a considerable speedup...'], ['vs']], [[' In [61]: %timeit new_function(close, volume, INTERVAL_LENGTH)\n1 loops, best of 3: 15.7 s per loop\n']], ['How to speed-up python nested loop?'], 4, 0], [(3065624, 2), [['vs'], ["It should be possible to vectorize the entire thing and avoid for loops entirely, though... Give me an minute, and I'll see what I can do..."]], [[' In [62]: %timeit old_function(close, volume, INTERVAL_LENGTH)\n1 loops, best of 3: 53.1 s per loop\n']], ['How to speed-up python nested loop?'], 4, 0], [(3065624, 3), [["It should be possible to vectorize the entire thing and avoid for loops entirely, though... Give me an minute, and I'll see what I can do..."], ['-10000']], [[' import numpy as np\n\nARRAY_LENGTH = 500000\nINTERVAL_LENGTH = 15\nclose = np.arange(ARRAY_LENGTH, dtype=np.float)\nvolume = np.arange(ARRAY_LENGTH, dtype=np.float)\n\ndef old_function(close, volume, INTERVAL_LENGTH):\n    results = []\n    for i in xrange(len(close) - INTERVAL_LENGTH):\n        for j in xrange(i+1, i+INTERVAL_LENGTH):\n            ret = close[j] / close[i]\n            vol = sum( volume[i+1:j+1] )\n            if (ret > 1.0001) and (ret < 1.5) and (vol > 100):\n                results.append( (i, j, ret, vol) )\n    return results\n\n\ndef new_function(close, volume, INTERVAL_LENGTH):\n    results = []\n    for i in xrange(close.size - INTERVAL_LENGTH):\n        vol = volume[i+1:i+INTERVAL_LENGTH].cumsum()\n        ret = close[i+1:i+INTERVAL_LENGTH] / close[i]\n\n        filter = (ret > 1.0001) & (ret < 1.5) & (vol > 100)\n        j = np.arange(i+1, i+INTERVAL_LENGTH)[filter]\n\n        tmp_results = zip(j.size * [i], j, ret[filter], vol[filter])\n        results.extend(tmp_results)\n    return results\n\ndef new_function2(close, volume, INTERVAL_LENGTH):\n    vol, ret = [], []\n    I, J = [], []\n    for k in xrange(1, INTERVAL_LENGTH):\n        start = k\n        end = volume.size - INTERVAL_LENGTH + k\n        vol.append(volume[start:end])\n        ret.append(close[start:end])\n        J.append(np.arange(start, end))\n        I.append(np.arange(volume.size - INTERVAL_LENGTH))\n\n    vol = np.vstack(vol)\n    ret = np.vstack(ret)\n    J = np.vstack(J)\n    I = np.vstack(I)\n\n    vol = vol.cumsum(axis=0)\n    ret = ret / close[:-INTERVAL_LENGTH]\n\n    filter = (ret > 1.0001) & (ret < 1.5) & (vol > 100)\n\n    vol = vol[filter]\n    ret = ret[filter]\n    I = I[filter]\n    J = J[filter]\n\n    output = zip(I.flat,J.flat,ret.flat,vol.flat)\n    return output\n\nresults = old_function(close, volume, INTERVAL_LENGTH)\nresults2 = new_function(close, volume, INTERVAL_LENGTH)\nresults3 = new_function(close, volume, INTERVAL_LENGTH)\n\n# Using sets to compare, as the output \n# is in a different order than the original function\nprint set(results) == set(results2)\nprint set(results) == set(results3)\n']], ['How to speed-up python nested loop?'], 4, 1], [(3068839, 0), [["I'm not sure if GIO allows you to have more than one monitor at once, but if it does there's no* reason you can't do something like this:"], ["*when I say no reason, there's the possibility that this could become a resource hog, though with nearly zero knowledge about GIO I couldn't really say. It's also entirely possible to roll your own in Python with a few commands ( os.listdir  among others). It might look something like this"]], [[' import gio\nimport os\n\ndef directory_changed(monitor, file1, file2, evt_type):\n    if os.path.isdir(file2):    #maybe this needs to be file1?\n        add_monitor(file2) \n    print "Changed:", file1, file2, evt_type\n\ndef add_monitor(dir):\n    gfile = gio.File(dir)\n    monitor = gfile.monitor_directory(gio.FILE_MONITOR_NONE, None)\n    monitor.connect("changed", directory_changed) \n\nadd_monitor(\'.\')\n\nimport glib\nml = glib.MainLoop()\nml.run()\n']], ['PyGTK/GIO: monitor directory for changes recursively'], 2, 1], [(3068839, 1), [["*when I say no reason, there's the possibility that this could become a resource hog, though with nearly zero knowledge about GIO I couldn't really say. It's also entirely possible to roll your own in Python with a few commands ( os.listdir  among others). It might look something like this"], ['-10000']], [[' import time\nimport os\n\nclass Watcher(object):\n    def __init__(self):\n        self.dirs = []\n        self.snapshots = {}\n\n    def add_dir(self, dir):\n        self.dirs.append(dir)\n\n    def check_for_changes(self, dir):\n        snapshot = self.snapshots.get(dir)\n        curstate = os.listdir(dir)\n        if not snapshot:\n            self.snapshots[dir] = curstate\n        else:\n            if not snapshot == curstate:\n                print \'Changes: \',\n                for change in set(curstate).symmetric_difference(set(snapshot)):\n                    if os.path.isdir(change):\n                        print "isdir"\n                        self.add_dir(change)\n                    print change,\n\n                self.snapshots[dir] = curstate\n                print\n\n    def mainloop(self):\n        if len(self.dirs) < 1:\n            print "ERROR: Please add a directory with add_dir()"\n            return\n\n        while True:\n            for dir in self.dirs:\n                self.check_for_changes(dir)\n            time.sleep(4) # Don\'t want to be a resource hog\n\nw = Watcher()\nw.add_dir(\'.\')\n\n\nw.mainloop()\n']], ['PyGTK/GIO: monitor directory for changes recursively'], 2, 1], [(3083583, 0), [['you have to do '], ['To getting help in general in python you can use builtin   help  function e.g.']], [[' python manage.py --help\n']], ['python help django navigation'], 2, 1], [(3083583, 1), [['To getting help in general in python you can use builtin   help  function e.g.'], ['-10000']], [[" >>> help('help')\n\nWelcome to Python 2.5!  This is the online help utility.\n....\n"]], ['python help django navigation'], 2, 1], [(3102098, 3), [["You can also use services.  This is a bit more involved, since it involves using using  twistd(1)  (or something else that's going to hook the service system up to the reactor).  But you can write a class like this:"], ['And then write a .tac file like this:']], [[' from twisted.application.service import Service\n\nclass ThingDoer(Service):\n    def startService(self):\n        print "The reactor is running now."\n']], ['sound way to feed commands to twisted ssh after reactor.run()'], 7, 0], [(3102098, 4), [['And then write a .tac file like this:'], ['And finally, you can run this .tac file using  twistd(1) :']], [[' from twisted.application.service import Application\n\nfrom thatmodule import ThingDoer\n\napplication = Application("Do Things")\nThingDoer().setServiceParent(application)\n']], ['sound way to feed commands to twisted ssh after reactor.run()'], 7, 0], [(3102098, 5), [['And finally, you can run this .tac file using  twistd(1) :'], ['You can see this in the  Conch examples , for example in sshsimpleclient.py we have:']], [[' $ twistd -ny thatfile.tac\n']], ['sound way to feed commands to twisted ssh after reactor.run()'], 7, 0], [(3121979, 0), [['-10000'], ['or:']], [[' sorted_by_second = sorted(data, key=lambda tup: tup[1])\n']], ['How to sort (list/tuple) of lists/tuples?'], 2, 1], [(3121979, 1), [['or:'], ['-10000']], [[' data.sort(key=lambda tup: tup[1])  # sorts in place\n']], ['How to sort (list/tuple) of lists/tuples?'], 2, 1], [(3145246, 0), [["Here's a working example of ignacio's suggestion to use  itertools.groupby .  "], ['Output:']], [[" class Article(object):\n    def __init__(self, pub_date):\n        self.pub_date = pub_date\n\n\nif __name__ == '__main__':\n    from datetime import date\n    import itertools\n    import operator\n\n    # You'll use your Article query here instead:\n    # a_list = Article.objects.filter(pub_date__lte = date.today())\n    a_list = [\n        Article(date(2010, 1, 2)),\n        Article(date(2010, 2, 3)),\n        Article(date(2010, 1, 2)),\n        Article(date(2011, 3, 2)),\n    ]\n\n\n    keyfunc = operator.attrgetter('pub_date')\n\n    a_list = sorted(a_list, key = keyfunc)\n    group_list = [{ k.strftime('%Y-%m-%d') : list(g)} \n                  for k, g in itertools.groupby(a_list, keyfunc)]\n\n    print group_list\n"]], ['How can I group objects by their date in Django?'], 2, 1], [(3145246, 1), [['Output:'], ['-10000']], [[" [{'2010-01-02': [<__main__.Article object at 0xb76c4fec>, <__main__.Article object at 0xb76c604c>]}, {'2010-02-03': [<__main__.Article object at 0xb76c602c>]}, {'2011-03-02': [<__main__.Article object at 0xb76c606c>]}]\n"]], ['How can I group objects by their date in Django?'], 2, 0], [(3187961, 1), [['You could use it like this:'], ['UPDATE :  Adding an alternative generic version:']], [[' cat = Categories.objects.get(id=1)\nprint cat.get_spamwords_as_list()\n']], ['Split field to array when accessed'], 3, 0], [(3187961, 2), [['UPDATE :  Adding an alternative generic version:'], ['-10000']], [[" def get_word_list(self, name):\n    if name in ['keywords', 'spamwords', 'translations']:\n        return getattr(self, name).split(',')\n\n# or even\ndef __getattr__(self, name):\n    if name[-5:] == '_list' and name[:-5] in ['keywords', 'spamwords', 'translations']:\n        return getattr(self, name[:-5]).split(',')\n    else\n        raise AttributeError\n\ncat = Categories.get(pk=1)\ncat.get_word_list('keywords')  # ['word 1', 'word 2', ...]\ncat.keywords_list              # ['word 1', 'word 2', ...] with 2nd approach\ncat.keywords                   # 'word 1, word 2' -- remains CSV\n"]], ['Split field to array when accessed'], 3, 1], [(3208076, 0), [['Where  pairs  is your list of pairs:'], ['EDIT:  And if you rather want a dictionary then a list of averages:']], [[' averages = [float(sum(values)) / len(values) for key, values in pairs]\n']], ['python: access multiple values in the value portion of a key:value pair'], 2, 1], [(3208076, 1), [['EDIT:  And if you rather want a dictionary then a list of averages:'], ['-10000']], [[' averages = dict([(key, float(sum(values)) / len(values)) for key, values in pairs])\n']], ['python: access multiple values in the value portion of a key:value pair'], 2, 1], [(3234114, 0), [["If you want to get both Chinese phrases when there are two of them (as in adult and aircraft), you'll need to work harder. The code below is for Python 3.x."], ['resulting in:']], [[' #coding: utf8\nimport re\ns = """“作為”(act) ，用於罪行或民事過失時，包括一連串作為、任何違法的不作為和一連串違法的不作為；\n    “行政上訴委員會”(Administrative Appeals Board) 指根據《行政上訴委員會條例》(第442章)設立的行政上訴委員會；(由1994年第6號第32條增補)\n    “成人”、“成年人”(adult)* 指年滿18歲的人；  (由1990年第32號第6條修訂)\n    “飛機”、“航空器”(aircraft) 指任何可憑空氣的反作用而在大氣中獲得支承力的機器；\n    “外籍人士”(alien) 指並非中國公民的人；  (由1998年第26號第4條增補)\n    “修訂”(amend) 包括廢除、增補或更改，亦指同時進行，或以同一條例或文書進行上述全部或其中任何事項；  (由1993年第89號第3條修訂)\n    “可逮捕的罪行”(arrestable offence) 指由法律規限固定刑罰的罪行，或根據、憑藉法例對犯者可處超過12個月監禁的罪行，亦指犯任何這類罪行的企圖；  (由1971年第30號第2條增補)\n    “《基本法》”(Basic Law) 指《中華人民共和國香港特別行政區基本法》；  (由1998年第26號第4條增補)\n    “行政長官”(Chief Executive) 指─"""\nfor zh1, zh2, en in re.findall(r"“([^”]*)”(?:、“([^”]*)”)?\\((.*?)\\)",s):\n    print(ascii((zh1, zh2, en)))\n']], ['Python : match string inside double quotes and bracket'], 2, 1], [(3234114, 1), [['resulting in:'], ['-10000']], [[" ('\\u4f5c\\u70ba', '', 'act')\n('\\u884c\\u653f\\u4e0a\\u8a34\\u59d4\\u54e1\\u6703', '', 'Administrative Appeals Board')\n('\\u6210\\u4eba', '\\u6210\\u5e74\\u4eba', 'adult')\n('\\u98db\\u6a5f', '\\u822a\\u7a7a\\u5668', 'aircraft')\n('\\u5916\\u7c4d\\u4eba\\u58eb', '', 'alien')\n('\\u4fee\\u8a02', '', 'amend')\n('\\u53ef\\u902e\\u6355\\u7684\\u7f6a\\u884c', '', 'arrestable offence')\n('\\u300a\\u57fa\\u672c\\u6cd5\\u300b', '', 'Basic Law')\n('\\u884c\\u653f\\u9577\\u5b98', '', 'Chief Executive')\n"]], ['Python : match string inside double quotes and bracket'], 2, 0], [(3254713, 0), [["Your version is missing an important component: the salt. This is a random string that is concatenated to the original password in order to generate the hash, and then concatenated to the hash itself for storage. The purpose is to ensure that users with the same password don't end up with the same stored hash."], ['You then verify the password by reusing the stored salt:']], [[" import random\n\nprint('Username: ' + os.environ['USER'])\npasswd = getpass('Password: ')\nsalt = ''.join(random.choice('BCDFGHJKLMNPQRSTVWXYZ') for range(4))\nh = hashlib.md5()\nh.update(salt)\nh.update(passwd.encode())\npasswd_encrypt = salt + h.hexdigest()\n"]], ['Generating passwords in Python 3.1.1'], 2, 0], [(3254713, 1), [['You then verify the password by reusing the stored salt:'], ['-10000']], [[" passwd = getpass('Password: ')\nsalt = passwd_encrypt[:4]\nh = hashlib.md5()\nh.update(salt)\nh.update(passwd.encode())\nif passwd_encrypt != salt + h.hexdigest():\n    raise LoginFailed()\n"]], ['Generating passwords in Python 3.1.1'], 2, 0], [(3257619, 1), [['and now make the conversion'], ['and to check for correctness:']], [[' # Fast conversion to linear index\nb_F = numpy.cumprod([1] + nbins)[:-1]\nb_C = numpy.cumprod([1] + nbins[::-1])[:-1][::-1]\n\nbox_index_F = numpy.dot(b_F,binassign)\nbox_index_C = numpy.dot(b_C,binassign)\n']], ['Numpy interconversion between multidimensional and linear indexing'], 5, 0], [(3257619, 2), [['and to check for correctness:'], ['And for completeness, if you want to go back from the 1d index to the multidimensional index in a fast, vectorized-style way:']], [[" # Check\nprint 'Checking correct mapping for each particle F order'\nfor k in xrange(N):\n    ii = box_index_F[k]\n    jj = linind_F[tuple(binassign[:,k])]\n    print 'particle %d %s (%d %d)' % (k,ii == jj,ii,jj)\n\nprint 'Checking correct mapping for each particle C order'\nfor k in xrange(N):\n    ii = box_index_C[k]\n    jj = linind_C[tuple(binassign[:,k])]\n    print 'particle %d %s (%d %d)' % (k,ii == jj,ii,jj)\n"]], ['Numpy interconversion between multidimensional and linear indexing'], 5, 0], [(3257619, 3), [['And for completeness, if you want to go back from the 1d index to the multidimensional index in a fast, vectorized-style way:'], ['and again to check:']], [[" print 'Convert C-style from linear to multi'\nx = box_index_C.reshape(-1,1)\nbassign_rev_C = x / b_C % nbins \n\nprint 'Convert F-style from linear to multi'\nx = box_index_F.reshape(-1,1)\nbassign_rev_F = x / b_F % nbins\n"]], ['Numpy interconversion between multidimensional and linear indexing'], 5, 0], [(3257619, 4), [['and again to check:'], ['-10000']], [[" print 'Check C-order'\nfor k in xrange(N):\n    ii = tuple(binassign[:,k])\n    jj = tuple(bassign_rev_C[k,:])\n    print ii==jj,ii,jj\n\nprint 'Check F-order'\nfor k in xrange(N):\n    ii = tuple(binassign[:,k])\n    jj = tuple(bassign_rev_F[k,:])\n    print ii==jj,ii,jj \n"]], ['Numpy interconversion between multidimensional and linear indexing'], 5, 0], [(3277047, 0), [["So, if you only need to have a  getter  descriptor on your class, and you don't mind that a an attempt to set will overwrite the descriptor, you can do something like this with no metaclass programming:"], ['for']], [[" def classproperty_getter_only(f):\n    class NonDataDescriptor(object):\n        def __get__(self, instance, icls):\n            return f(icls)\n    return NonDataDescriptor()\n\nclass Foo(object):\n\n    @classproperty_getter_only\n    def flup(cls):\n        return 'hello from', cls\n\nprint Foo.flup\nprint Foo().flup\n"]], ['Implementing class descriptors by subclassing the `type` class'], 2, 1], [(3277047, 1), [['for'], ["If you want a full fledged data descriptor, or want to use the built-in property object, then you're right you can use a metaclass and put it there (realizing that this attribute will be totally invisible from instances of your class; metaclasses are not examined when doing attribute lookup on an instance of a class)."]], [[" ('hello from', <class '__main__.Foo'>)\n('hello from', <class '__main__.Foo'>)\n"]], ['Implementing class descriptors by subclassing the `type` class'], 2, 0], [(3306189, 0), [["You can do this using a combination of the Python win32 api packages and Tkinter. What you need to know is that a Tk window is the client section of a Win32 window. The window manager interactions are handled using a wrapper that is the parent of Tk window itself. If you have a Tkinter window 'w' then you can create a PyWin32 window for the frame or just manipulate it directly. You can get the frame hwnd using w.wm_frame() and parsing the hex string returned or by using GetParent on the winfo_id value from the Tk window (although wm_frame is likely to be more reliable)."], ['EDIT ---\nThe following arranges to ensure we modify the window style  after  the window has been fully created and mapped to the display.']], [[' import string, win32ui, win32con\nfrom Tkinter import *\nw = Tk()\nframe = win32ui.CreateWindowFromHandle(string.atoi(w.wm_frame(), 0))\nframe.ModifyStyle(win32con.WS_CAPTION, 0, win32con.SWP_FRAMECHANGED)\n']], ['Using TCL extensions to set native window style in Tkinter'], 2, 1], [(3306189, 1), [['EDIT ---\nThe following arranges to ensure we modify the window style  after  the window has been fully created and mapped to the display.'], ['-10000']], [[' import string, win32ui, win32con\nfrom Tkinter import *\n\ndef decaption(event):\n    w = event.widget\n    frame = win32ui.CreateWindowFromHandle(string.atoi(w.wm_frame(), 0))\n    frame.ModifyStyle(win32con.WS_CAPTION, 0, win32con.SWP_FRAMECHANGED)\n    w.bind("<Map>", None)\n\nroot = Tk()\nroot.bind("<Map>", decaption)\nroot.mainloop()\n']], ['Using TCL extensions to set native window style in Tkinter'], 2, 1], [(3337512, 0), [['Assuming  self.table  is a dict, you could use'], ['Edit:  Perhaps this is closer to what you want:']], [[' self.table.setdefault(field,0)\n']], ['setDefault for Nested dictionary in python'], 3, 1], [(3337512, 1), [['Edit:  Perhaps this is closer to what you want:'], ['Instead of keeping track of the count, perhaps just take the length of the list:']], [[" import collections\nclass Foo(object):\n    def __init__(self):\n        self.CompleteAnalysis=collections.defaultdict(\n            lambda: collections.defaultdict(list))\n\n    def getFilledFields(self,sentence):\n        field, field_value, field_date = sentence.split('|')\n        field_value = field_value.strip('\\n')\n        field_date = field_date.strip('\\n')\n        self.CompleteAnalysis[field]['date'].append(field_date)\n        self.CompleteAnalysis[field]['value'].append(field_value) \n\nfoo=Foo()\nfoo.getFilledFields('A|1|2000-1-1')\nfoo.getFilledFields('A|2|2000-1-2')\nprint(foo.CompleteAnalysis['A']['date'])\n# ['2000-1-1', '2000-1-2']\n\nprint(foo.CompleteAnalysis['A']['value'])\n# ['1', '2']\n"]], ['setDefault for Nested dictionary in python'], 3, 1], [(3337512, 2), [['Instead of keeping track of the count, perhaps just take the length of the list:'], ['-10000']], [[" print(len(foo.CompleteAnalysis['A']['value']))\n# 2\n"]], ['setDefault for Nested dictionary in python'], 3, 0], [(3375374, 0), [['well... there is still a bit that could be improved on:'], ['can be written as:']], [[' more=Many.objects.filter(one=one)\nfor m in more\n    m.one=None\n    m.save()\n#and finally:\none.delete()\n']], ['How do I delete an object in a django relation (While keeping all related objects)?'], 3, 0], [(3387691, 0), [['You can write an object that behaves like a dict quite easily with  ABC s\n(Abstract Base Classes) from the  collections  module.  It even tells you\nif you missed a method, so below is the minimal version that shuts the ABC up.'], ['You get a few free methods from the ABC:']], [[' import collections\n\n\nclass TransformedDict(collections.MutableMapping):\n    """A dictionary that applies an arbitrary key-altering\n       function before accessing the keys"""\n\n    def __init__(self, *args, **kwargs):\n        self.store = dict()\n        self.update(dict(*args, **kwargs))  # use the free update to set keys\n\n    def __getitem__(self, key):\n        return self.store[self.__keytransform__(key)]\n\n    def __setitem__(self, key, value):\n        self.store[self.__keytransform__(key)] = value\n\n    def __delitem__(self, key):\n        del self.store[self.__keytransform__(key)]\n\n    def __iter__(self):\n        return iter(self.store)\n\n    def __len__(self):\n        return len(self.store)\n\n    def __keytransform__(self, key):\n        return key\n']], ['How to "perfectly" override a dict?'], 2, 1], [(3387691, 1), [['You get a few free methods from the ABC:'], ["I wouldn't subclass  dict  (or other builtins) directly. It often makes no sense, because what you actually want to do is  implement the interface of a dict . And that is exactly what ABCs are for."]], [[" class MyTransformedDict(TransformedDict):\n\n    def __keytransform__(self, key):\n        return key.lower()\n\n\ns = MyTransformedDict([('Test', 'test')])\n\nassert s.get('TEST') is s['test']   # free get\nassert 'TeSt' in s                  # free __contains__\n                                    # free setdefault, __eq__, and so on\n\nimport pickle\nassert pickle.loads(pickle.dumps(s)) == s\n                                    # works too since we just use a normal dict\n"]], ['How to "perfectly" override a dict?'], 2, 0], [(3458542, 0), [["Here's a full working example:"], ['Why are you using  cPickle  as well as  pickle ?']], [[' from PyQt4 import QtCore, QtGui, Qt\nimport cPickle\nimport pickle\n']], ['Multiple drag and drop in PyQt4'], 7, 0], [(3458542, 1), [['Why are you using  cPickle  as well as  pickle ?'], ["You probably want to set the selection behavior here, because I'm assuming row-based data presentation.  You may of course change that."]], [[' class DragTable(QtGui.QTableView):\n    def __init__(self, parent = None):\n        super(DragTable, self).__init__(parent)\n        self.setDragEnabled(True)\n        self.setSelectionBehavior(QtGui.QAbstractItemView.SelectRows)\n']], ['Multiple drag and drop in PyQt4'], 7, 0], [(3458542, 2), [["You probably want to set the selection behavior here, because I'm assuming row-based data presentation.  You may of course change that."], ["Your code assumes only one index here, based on the event position.  For a  QTableView , this is unnecessary, as it already handles the mouse click itself.  Instead, it's better to depend on Qt to provide you with the information that you actually  need , as always.  Here, I've chose to use  selectedIndexes() ."]], [['     def dragEnterEvent(self, event):\n        if event.mimeData().hasFormat("application/pubmedrecord"):\n            event.setDropAction(Qt.MoveAction)\n            event.accept()\n        else:\n            event.ignore()\n\n    def startDrag(self, event):\n']], ['Multiple drag and drop in PyQt4'], 7, 0], [(3458542, 3), [["Your code assumes only one index here, based on the event position.  For a  QTableView , this is unnecessary, as it already handles the mouse click itself.  Instead, it's better to depend on Qt to provide you with the information that you actually  need , as always.  Here, I've chose to use  selectedIndexes() ."], ["One thing that may surprise you here, is that indices contains indexes for all  cells  in the table, not all rows, regardless of the selection behavior.  That's why I chose to use a  set  instead of a  list ."]], [['         indices = self.selectedIndexes()\n']], ['Multiple drag and drop in PyQt4'], 7, 0], [(3458542, 4), [["One thing that may surprise you here, is that indices contains indexes for all  cells  in the table, not all rows, regardless of the selection behavior.  That's why I chose to use a  set  instead of a  list ."], ["I left the rest untouched, assuming that you know what you're doing there."]], [['         selected = set()\n        for index in indices:\n            selected.add(index.row())\n']], ['Multiple drag and drop in PyQt4'], 7, 0], [(3458542, 5), [["I left the rest untouched, assuming that you know what you're doing there."], ["Unless you are interfacing with C++-code with this signal, it's not necessary to add a signal argument here, you may also use  dropAccepted  without parentheses and PyQt4 will do the right thing."]], [['         bstream = cPickle.dumps(selected)\n        mimeData = QtCore.QMimeData()\n        mimeData.setData("application/pubmedrecord", bstream)\n        drag = QtGui.QDrag(self)\n        drag.setMimeData(mimeData)\n        pixmap = QtGui.QPixmap(":/drag.png")\n\n        drag.setHotSpot(QtCore.QPoint(pixmap.width()/3, pixmap.height()/3))\n        drag.setPixmap(pixmap)\n        result = drag.start(QtCore.Qt.MoveAction)\n\n    def mouseMoveEvent(self, event):\n        self.startDrag(event)\n\n\nclass TagLabel(QtGui.QLabel):\n    def __init__(self, text, color, parent = None):\n        super(TagLabel, self).__init__(parent)\n        self.tagColor = color\n        self.setText(text)\n        self.setStyleSheet("QLabel { background-color: %s; font-size: 14pt; }" % self.tagColor)\n        self.defaultStyle = self.styleSheet()\n        self.setAlignment(QtCore.Qt.AlignHCenter|QtCore.Qt.AlignVCenter)\n        self.setAcceptDrops(True)\n\n    def dragEnterEvent(self, event):\n        if event.mimeData().hasFormat("application/pubmedrecord"):\n            self.set_bg(True)\n            event.accept()\n        else:\n            event.reject()\n\n    def dragLeaveEvent(self, event):\n        self.set_bg(False)\n        event.accept()\n\n    def dropEvent(self, event):\n        self.set_bg(False)\n        data = event.mimeData()\n        bstream = data.retrieveData("application/pubmedrecord", QtCore.QVariant.ByteArray)\n        selected = pickle.loads(bstream.toByteArray())\n        event.accept()\n        self.emit(QtCore.SIGNAL("dropAccepted(PyQt_PyObject)"), (selected, str(self.text()), str(self.tagColor)))\n']], ['Multiple drag and drop in PyQt4'], 7, 0], [(3458542, 6), [["Unless you are interfacing with C++-code with this signal, it's not necessary to add a signal argument here, you may also use  dropAccepted  without parentheses and PyQt4 will do the right thing."], ['-10000']], [['     def set_bg(self, active = False):\n        if active:\n            style = "QLabel {background: yellow; font-size: 14pt;}"\n            self.setStyleSheet(style)\n        else:\n            self.setStyleSheet(self.defaultStyle)\n\n\n\napp = QtGui.QApplication([])\n\nl = TagLabel("bla bla bla bla bla bla bla", "red")\nl.show()\n\nm = QtGui.QStandardItemModel()\nfor _ in xrange(4):\n    m.appendRow([QtGui.QStandardItem(x) for x in ["aap", "noot", "mies"]])\n\nt = DragTable()\nt.setModel(m)\nt.show()\n\ndef h(o):\n    print "signal handled", o\nl.connect(l, QtCore.SIGNAL("dropAccepted(PyQt_PyObject)"), h)\n\napp.exec_()\n']], ['Multiple drag and drop in PyQt4'], 7, 0], [(3495524, 1), [['Using EXISTS to find those that are  not present :'], ['-10000']], [[' SELECT *\n  FROM TABLE_A a\n WHERE NOT EXISTS(SELECT NULL\n                    FROM TABLE_A$foo f\n                   WHERE a.id = f.id\n                     AND a.value1 = f.value1\n                     AND a.value2 = f.value2)\n']], ['sqlite SQL query for unprocessed rows'], 2, 1], [(3575359, 0), [['BeautifulSoup could also extract node values from your html.'], ['Output:  ']], [[' from BeautifulSoup import BeautifulSoup\n\nhtml = (\'<html><head><title>Page title</title></head>\'\n       \'<body>\'\n       \'<table><tr>\'\n       \'<td class="name"><a href="/torrent/32726/0/">Slackware Linux 13.0 [x86 DVD ISO]</a></td>\'\n       \'<td class="name"><a href="/torrent/32727/0/">Slackware Linux 14.0 [x86 DVD ISO]</a></td>\'\n       \'<td class="name"><a href="/torrent/32728/0/">Slackware Linux 15.0 [x86 DVD ISO]</a></td>\'\n       \'</tr></table>\'\n       \'body\'\n       \'</html>\')\nsoup = BeautifulSoup(html)\nlinks = [td.find(\'a\') for td in soup.findAll(\'td\', { "class" : "name" })]\nfor link in links:\n    print link.string\n']], ['Extracting Text from Parsed HTML with Python'], 2, 1], [(3575359, 1), [['Output:  '], ['-10000']], [[' Slackware Linux 13.0 [x86 DVD ISO]  \nSlackware Linux 14.0 [x86 DVD ISO]  \nSlackware Linux 15.0 [x86 DVD ISO]  \n']], ['Extracting Text from Parsed HTML with Python'], 2, 0], [(3576512, 0), [["apply_async  returns an  AsyncResult  instance, or in this case an  AbortableAsyncResult . Save the  task_id  and use that to instantiate a new  AbortableAsyncResult  later, making sure you supply the backend optional argument if you're not using the  default_backend ."], ['Later:']], [[' abortable_async_result = AsyncBoot.apply_async(args=[name], name=name, connect_timeout=3)\nmyTaskId = abortable_async_result.task_id\n']], ['Abort a running task in Celery within django'], 2, 0], [(3576512, 1), [['Later:'], ['-10000']], [[' abortable_async_result = AbortableAsyncResult(myTaskId)\nabortable_async_result.abort()\n']], ['Abort a running task in Celery within django'], 2, 0], [(3637419, 0), [["Here's the code that I use; hope it helps."], ["In your  models.py  file, you'd add"]], [[' from django.db import connections\n\nclass DBRouter(object):\n    """A router to control all database operations on models in\n    the contrib.auth application"""\n\n    def db_for_read(self, model, **hints):\n        m = model.__module__.split(\'.\')\n        try:\n            d = m[-1]\n            if d in connections:\n                return d\n        except IndexError:\n            pass\n        return None\n\n    def db_for_write(self, model, **hints):\n        m = model.__module__.split(\'.\')\n        try:\n            d = m[-1]\n            if d in connections:\n                return d\n        except IndexError:\n            pass\n        return None\n\n    def allow_syncdb(self, db, model):\n        "Make sure syncdb doesn\'t run on anything but default"\n        if model._meta.app_label == \'myapp\':\n            return False\n        elif db == \'default\':\n            return True\n        return None\n']], ['Multiple Database Config in Django 1.2'], 4, 0], [(3637419, 1), [["In your  models.py  file, you'd add"], ['If you want to have per-model control of database choice, something like this would work:']], [[' from asterisk import *\n']], ['Multiple Database Config in Django 1.2'], 4, 0], [(3637419, 2), [['If you want to have per-model control of database choice, something like this would work:'], ['Then for each model:']], [[' from django.db import connections\n\nclass DBRouter(object):\n    """A router to control all database operations on models in\n    the contrib.auth application"""\n\n    def db_for_read(self, model, **hints):\n        if hasattr(model,\'connection_name\'):\n            return model.connection_name\n        return None\n\n    def db_for_write(self, model, **hints):\n        if hasattr(model,\'connection_name\'):\n            return model.connection_name\n        return None\n\n    def allow_syncdb(self, db, model):\n        if hasattr(model,\'connection_name\'):\n            return model.connection_name\n        return None\n']], ['Multiple Database Config in Django 1.2'], 4, 0], [(3637419, 3), [['Then for each model:'], ['Note that I have not tested this second option.']], [[' class MyModel(models.Model):\n    connection_name="asterisk"\n    #etc...\n']], ['Multiple Database Config in Django 1.2'], 4, 0], [(3708418, 0), [['Since the tag names of Stackoverflow do not have embedded  <   >  you can use the regex:'], ['or']], [[' <(.*?)>\n']], ['Regular Expression (Python) to extract strings of text from inside of < and > - e.g. <stringone><string-two> etc'], 2, 1], [(3708418, 1), [['or'], ['Explanation:']], [[' <([^>]*)>\n']], ['Regular Expression (Python) to extract strings of text from inside of < and > - e.g. <stringone><string-two> etc'], 2, 1], [(3724488, 0), [['The key is to override the  __init__()  method of your  ModelForm  class to supply the currently logged in user instance.'], ['You can then supply the user instance while creating an instance of the form.']], [[" # forms.py\nclass TicketForm(forms.ModelForm):\n    def __init__(self, current_user, *args, **kwargs):\n        super(TicketForm, self).__init__(*args, **kwargs)\n        self.fields['event'].queryset = Event.objects.filter(creator = \n             current_user)\n"]], ['Django model form with selected rows'], 2, 0], [(3724488, 1), [['You can then supply the user instance while creating an instance of the form.'], ['-10000']], [[' ticket_form = TicketForm(request.user)\n']], ['Django model form with selected rows'], 2, 0], [(3738269, 0), [["You'll probably want to start out with a  dogs  table containing all the flat (non array) data for each dog, things which each dog has  one  of, like a name, a sex, and an age:"], ['From there, each dog "has many" measurements, so you need a  dog_mesaurements  table to store the 24 measurements:']], [[" CREATE TABLE `dogs` (\n  `id` INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  `name` VARCHAR(64),\n  `age` INT UNSIGNED,\n  `sex` ENUM('Male','Female')\n);\n"]], ['How to insert arrays into a database?'], 5, 0], [(3738269, 1), [['From there, each dog "has many" measurements, so you need a  dog_mesaurements  table to store the 24 measurements:'], ["You'll then want tables to store the actual frames for each measurement, something like:"]], [[" CREATE TABLE `dog_measurements` (\n  `id` INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  `dog_id` INT UNSIGNED NOT NULL,\n  `paw` ENUM ('Front Left','Front Right','Rear Left','Rear Right'),\n  `taken_at` DATETIME NOT NULL\n);\n"]], ['How to insert arrays into a database?'], 5, 0], [(3738269, 2), [["You'll then want tables to store the actual frames for each measurement, something like:"], ['That way, for each of the 250 frames, you loop through each of the 63 sensors, and store the value for that sensor with the frame number into the database:']], [[' CREATE TABLE `dog_measurement_data` (\n  `id` INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  `dog_measurement_id` INT UNSIGNED NOT NULL,\n  `frame` INT UNSIGNED,\n  `sensor_row` INT UNSIGNED,\n  `sensor_col` INT UNSIGNED,\n  `value` NUMBER\n);\n']], ['How to insert arrays into a database?'], 5, 0], [(3738269, 3), [['That way, for each of the 250 frames, you loop through each of the 63 sensors, and store the value for that sensor with the frame number into the database:'], ['So basically, each  dog_measurement_data  is a  single sensor value for a given frame . That way, to get all the sensor values for all a given frame, you would:']], [[' INSERT INTO `dog_measurement_data` (`dog_measurement_id`,`frame`,`sensor_row`,`sensor_col`,`value`) VALUES\n(*measurement_id?*, *frame_number?*, *sensor_row?*, *sensor_col?*, *value?*)\n']], ['How to insert arrays into a database?'], 5, 0], [(3738269, 4), [['So basically, each  dog_measurement_data  is a  single sensor value for a given frame . That way, to get all the sensor values for all a given frame, you would:'], ['And this will give you all the rows and cols for that frame.']], [[' SELECT `sensor_row`,sensor_col`,`value` FROM `dog_measurement_data`\nWHERE `dog_measurement_id`=*some measurement id* AND `frame`=*some frame number*\nORDER BY `sensor_row`,`sensor_col`\n']], ['How to insert arrays into a database?'], 5, 0], [(3748356, 0), [['That beings said, it is possible to do some work in the template using  custom filters and tags . Using filters it might look like this:'], ['This is a quick untested filter implementation off the top of my head:']], [[' <td>{% documento.cuentasxdocumento_set.all | sum_monto:"pos" %}</td>\n<td>{% documento.cuentasxdocumento_set.all | sum_monto:"neg" %}</td>\n']], ['Summarizing inside a Django template'], 2, 0], [(3748356, 1), [['This is a quick untested filter implementation off the top of my head:'], ['-10000']], [[' from django import template\n\nregister = template.Library()\n\n@register.filter\ndef sum_monto(cuentas, op):\n    if op == "pos":\n         return sum(c.monto for c in cuentas if c.monto > 0)\n    else\n         return sum(c.monto for c in cuentas if c.monto < 0)\n']], ['Summarizing inside a Django template'], 2, 0], [(3788439, 0), [['-10000'], ['-10000']], [['Client Python 2.6.5 (r265:79096, Mar 19 2010, 21:48:26) [MSC v.1500 32 bit (Intel)] on win32\nType "help", "copyright", "credits" or "license" for more information.\n>>> from socket import *\n>>> s=socket()\n>>> s.connect((\'localhost\',5000))\n>>> f=s.makefile()\n>>> f.write(\'\\x04abcd\')\n>>> f.flush()\n']], ['Python socket send EOF'], 2, 0], [(3788439, 1), [['-10000'], ['-10000']], [['Server Python 2.6.5 (r265:79096, Mar 19 2010, 21:48:26) [MSC v.1500 32 bit (Intel)] on win32\nType "help", "copyright", "credits" or "license" for more information.\n>>> from socket import *\n>>> s=socket()\n>>> s.bind((\'localhost\',5000))\n>>> s.listen(1)\n>>> c,a=s.accept()\n>>> f=c.makefile()\n>>> length=ord(f.read(1))\n>>> f.read(length)\n\'abcd\'\n']], ['Python socket send EOF'], 2, 0], [(3821957, 1), [["Then there are various less obvious build issues like third-party libraries that are needed for all of the standard library modules to build and work as expected - GNU readline and bsddb come to mind - so there is no guarantee that you won't run into other problems."], ['You could try using the installer build script in the source tree (in  Mac/BuildScript/ ) but it will likely need to be patched to work correctly on 10.6.']], [[' $ python2.5\nPython 2.5.5 (r255:77872, Sep 29 2010, 10:23:54) \n[GCC 4.0.1 (Apple Inc. build 5494)] on darwin\nType "help", "copyright", "credits" or "license" for more information.\nModule readline not available.\n>>> \n']], ['Compile Python 2.5.5 on OS X 10.6'], 2, 0], [(3843017, 0), [['What about:'], ['Output:']], [[' import numpy\na = [1, 2, 1, 1, -3, -4, 7, 8, 9, 10, -2, 1, -3, 5, 6, 7, -10]\nzero_crossings = numpy.where(numpy.diff(numpy.sign(a)))[0]\n']], ['Efficiently detect sign-changes in python'], 2, 1], [(3843017, 1), [['Output:'], ['i.e. zero_crossings will contain the indices of elements  after  which a zero crossing occurs. If you want the elements  before , just add 1 to that array.']], [[' > zero_crossings\narray([ 3,  5,  9, 10, 11, 12, 15])\n']], ['Efficiently detect sign-changes in python'], 2, 0], [(3862310, 0), [['New-style classes (i.e. subclassed from  object , which is the default in Python 3) have a  __subclasses__  method which returns the subclasses:'], ['Here are the names of the subclasses:']], [[' class Foo(object): pass\nclass Bar(Foo): pass\nclass Baz(Foo): pass\nclass Bing(Bar): pass\n']], ['How can I find all subclasses of a class given its name?'], 5, 0], [(3862310, 1), [['Here are the names of the subclasses:'], ['Here are the subclasses themselves:']], [[" print([cls.__name__ for cls in vars()['Foo'].__subclasses__()])\n# ['Bar', 'Baz']\n"]], ['How can I find all subclasses of a class given its name?'], 5, 1], [(3862310, 2), [['Here are the subclasses themselves:'], ['Confirmation that the subclasses do indeed list  Foo  as their base:']], [[" print(vars()['Foo'].__subclasses__())\n# [<class '__main__.Bar'>, <class '__main__.Baz'>]\n"]], ['How can I find all subclasses of a class given its name?'], 5, 1], [(3862310, 3), [['Confirmation that the subclasses do indeed list  Foo  as their base:'], ["Note if you want subsubclasses, you'll have to recurse:"]], [[" for cls in vars()['Foo'].__subclasses__():\n    print(cls.__base__)\n# <class '__main__.Foo'>\n# <class '__main__.Foo'>\n"]], ['How can I find all subclasses of a class given its name?'], 5, 0], [(3862310, 4), [["Note if you want subsubclasses, you'll have to recurse:"], ['-10000']], [[" def all_subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__()\n                                   for g in all_subclasses(s)]\n\nprint(all_subclasses(vars()['Foo']))\n# [<class '__main__.Bar'>, <class '__main__.Baz'>, <class '__main__.Bing'>]\n"]], ['How can I find all subclasses of a class given its name?'], 5, 1], [(3947313, 0), [['This does directory and all subdirectories:'], ['Or:']], [[' import os, os.path\n\nfor root, _, files in os.walk(dirtocheck):\n    for f in files:\n        fullpath = os.path.join(root, f)\n        if os.path.getsize(fullpath) < 200 * 1024:\n            os.remove(fullpath)\n']], ['Python script to loop through all files in directory, delete any that are less than 200 kB in size'], 2, 1], [(3947313, 1), [['Or:'], ['-10000']], [[' import os, os.path\n\nfileiter = (os.path.join(root, f)\n    for root, _, files in os.walk(dirtocheck)\n    for f in files)\nsmallfileiter = (f for f in fileiter if os.path.getsize(f) < 200 * 1024)\nfor small in smallfileiter:\n    os.remove(small)\n']], ['Python script to loop through all files in directory, delete any that are less than 200 kB in size'], 2, 1], [(3947654, 0), [['Here are some tries:'], ['Now that I have had a moment to think, I realize that the  L2 + L3  thing creates a temporary list that immediately gets thrown away.  So an even better way is:']], [[' L4 = [ n for n in L1 if (n not in L2) and (n not in L3) ]  # parens for clarity\n\ntmpset = set( L2 + L3 )\nL4 = [ n for n in L1 if n not in tmpset ]\n']], ['Python - removing items from lists'], 5, 1], [(3947654, 1), [['Now that I have had a moment to think, I realize that the  L2 + L3  thing creates a temporary list that immediately gets thrown away.  So an even better way is:'], ['Update:  I see some extravagant claims being thrown around about performance, and I want to assert that my solution was already as fast as possible. Creating intermediate results, whether they be intermediate lists or intermediate iterators that then have to be called into repeatedly, will be slower, always, than simply giving  L2  and  L3  for the set to iterate over directly like I have done here.']], [[' tmpset = set(L2)\ntmpset.update(L3)\nL4 = [ n for n in L1 if n not in tmpset ]\n']], ['Python - removing items from lists'], 5, 1], [(3947654, 2), [['Update:  I see some extravagant claims being thrown around about performance, and I want to assert that my solution was already as fast as possible. Creating intermediate results, whether they be intermediate lists or intermediate iterators that then have to be called into repeatedly, will be slower, always, than simply giving  L2  and  L3  for the set to iterate over directly like I have done here.'], ['All other alternatives (that I can think of) will necessarily be slower than this. Doing the loops ourselves, for example, rather than letting the  set()  constructor do them, adds expense:']], [[" $ python -m timeit \\\n  -s 'L1=range(300);L2=range(30,70,2);L3=range(120,220,2)' \\\n  'ts = set(L2); ts.update(L3); L4 = [ n for n in L1 if n not in ts ]'\n10000 loops, best of 3: 39.7 usec per loop\n"]], ['Python - removing items from lists'], 5, 1], [(3947654, 3), [['All other alternatives (that I can think of) will necessarily be slower than this. Doing the loops ourselves, for example, rather than letting the  set()  constructor do them, adds expense:'], ['Using iterators, will all of the state-saving and callbacks they involve, will obviously be even more expensive:']], [[" $ python -m timeit \\\n  -s 'L1=range(300);L2=range(30,70,2);L3=range(120,220,2)' \\\n  'unwanted = frozenset(item for lst in (L2, L3) for item in lst); L4 = [ n for n in L1 if n not in unwanted ]'\n10000 loops, best of 3: 46.4 usec per loop\n"]], ['Python - removing items from lists'], 5, 1], [(3947654, 4), [['Using iterators, will all of the state-saving and callbacks they involve, will obviously be even more expensive:'], ['So I believe that the answer I gave last night is still far and away (for values of "far and away" greater than around 5µsec, obviously) the best, unless the questioner will have duplicates in  L1  and wants them removed once each for every time the duplicate appears in one of the other lists.']], [[" $ python -m timeit \\\n  -s 'L1=range(300);L2=range(30,70,2);L3=range(120,220,2);from itertools import ifilterfalse, chain' \\\n  'L4 = list(ifilterfalse(frozenset(chain(L2, L3)).__contains__, L1))' \n10000 loops, best of 3: 47.1 usec per loop\n"]], ['Python - removing items from lists'], 5, 1], [(3955571, 0), [['File  pybash.sh'], ['File  pytest.py']], [[' #!/bin/bash\n\ndeclare -a list1\ndeclare -a list2\n\nlist1=("Hello" "there" "honey")\nlist2=("More" "strings" "here")\n\ndeclare -a joined\n\njoined=($(./pytest.py ${list1[@]} ${list2[@]}))\necho ${joined[@]}\n']], ['How to pass variable arguments from bash script to python script'], 2, 0], [(3955571, 1), [['File  pytest.py'], ["This will print out a bunch of 'hi' strings if you run the bash script."]], [[' #!/usr/bin/python\n\nimport sys\n\nfor i in sys.argv:\n    print "hi"\n']], ['How to pass variable arguments from bash script to python script'], 2, 0], [(3966201, 1), [['The iter version that was provided by eumiro.'], ['-10000']], [[' >>> results = ( foo() for _ in xrange(10) )\n>>> results\n<generator object <genexpr> at 0x10041f960>\n>>> list(results)\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\nfoo\n[None, None, None, None, None, None, None, None, None, None]\n>>> \n']], ['how to use python list comprehensions replace the function invoke inside of "for" stmt?'], 2, 1], [(3984539, 0), [["Python's regex module does not default to  multi-line  ^  matching , so you need to specify that flag explicitly."], ["It's also possible to include the flag inline to the pattern:"]], [[' r = re.compile(r"^\\s+", re.MULTILINE)\nr.sub("", "a\\n b\\n c") # "a\\nb\\nc"\n\n# or without compiling (only possible for Python 2.7+ because the flags option\n# didn\'t exist in earlier versions of re.sub)\n\nre.sub(r"^\\s+", "", "a\\n b\\n c", flags = re.MULTILINE)\n\n# but mind that \\s includes newlines:\nr.sub("", "a\\n\\n\\n\\n b\\n c") # "a\\nb\\nc"\n']], ['Python: use regular expression to remove the white space from all lines'], 3, 1], [(3984539, 1), [["It's also possible to include the flag inline to the pattern:"], ['An easier solution is to avoid regular expressions because the original problem is very simple:']], [[' re.sub(r"(?m)^\\s+", "", "a\\n b\\n c")\n']], ['Python: use regular expression to remove the white space from all lines'], 3, 1], [(3986345, 0), [["The location of the local minima can be found for an array of arbitrary dimension\nusing  Ivan 's  detect_peaks function , with minor modifications:"], ['which you can use like this:']], [[' import numpy as np\nimport scipy.ndimage.filters as filters\nimport scipy.ndimage.morphology as morphology\n\ndef detect_local_minima(arr):\n    # https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array/3689710#3689710\n    """\n    Takes an array and detects the troughs using the local maximum filter.\n    Returns a boolean mask of the troughs (i.e. 1 when\n    the pixel\'s value is the neighborhood maximum, 0 otherwise)\n    """\n    # define an connected neighborhood\n    # http://www.scipy.org/doc/api_docs/SciPy.ndimage.morphology.html#generate_binary_structure\n    neighborhood = morphology.generate_binary_structure(len(arr.shape),2)\n    # apply the local minimum filter; all locations of minimum value \n    # in their neighborhood are set to 1\n    # http://www.scipy.org/doc/api_docs/SciPy.ndimage.filters.html#minimum_filter\n    local_min = (filters.minimum_filter(arr, footprint=neighborhood)==arr)\n    # local_min is a mask that contains the peaks we are \n    # looking for, but also the background.\n    # In order to isolate the peaks we must remove the background from the mask.\n    # \n    # we create the mask of the background\n    background = (arr==0)\n    # \n    # a little technicality: we must erode the background in order to \n    # successfully subtract it from local_min, otherwise a line will \n    # appear along the background border (artifact of the local minimum filter)\n    # http://www.scipy.org/doc/api_docs/SciPy.ndimage.morphology.html#binary_erosion\n    eroded_background = morphology.binary_erosion(\n        background, structure=neighborhood, border_value=1)\n    # \n    # we obtain the final mask, containing only peaks, \n    # by removing the background from the local_min mask\n    detected_minima = local_min - eroded_background\n    return np.where(detected_minima)       \n']], ['How to find the local minima of a smooth multidimensional array in NumPy efficiently?'], 3, 1], [(3986345, 1), [['which you can use like this:'], ['This says the minima occur at indices [0,0,3], [0,4,0], [1,1,1] and [1,3,3]:']], [[' arr=np.array([[[0,0,0,-1],[0,0,0,0],[0,0,0,0],[0,0,0,0],[-1,0,0,0]],\n              [[0,0,0,0],[0,-1,0,0],[0,0,0,0],[0,0,0,-1],[0,0,0,0]]])\nlocal_minima_locations = detect_local_minima(arr)\nprint(arr)\n# [[[ 0  0  0 -1]\n#   [ 0  0  0  0]\n#   [ 0  0  0  0]\n#   [ 0  0  0  0]\n#   [-1  0  0  0]]\n\n#  [[ 0  0  0  0]\n#   [ 0 -1  0  0]\n#   [ 0  0  0  0]\n#   [ 0  0  0 -1]\n#   [ 0  0  0  0]]]\n']], ['How to find the local minima of a smooth multidimensional array in NumPy efficiently?'], 3, 0], [(3986345, 2), [['This says the minima occur at indices [0,0,3], [0,4,0], [1,1,1] and [1,3,3]:'], ['-10000']], [[' print(local_minima_locations)\n# (array([0, 0, 1, 1]), array([0, 4, 1, 3]), array([3, 0, 1, 3]))\nprint(arr[local_minima_locations])\n# [-1 -1 -1 -1]\n']], ['How to find the local minima of a smooth multidimensional array in NumPy efficiently?'], 3, 0], [(4006970, 0), [["here an example that you can start with, it's not optimized:"], ['to make it more beautiful do this when printing:']], [[' import zipfile\n\nzf = zipfile.ZipFile(\'test.zip\')\n\nuncompress_size = sum((file.file_size for file in zf.infolist()))\n\nextracted_size = 0\n\nfor file in zf.infolist():\n    extracted_size += file.file_size\n    print "%s %%" % (extracted_size * 100/uncompress_size)\n    zf.extract(file)\n']], ['Monitor ZIP File Extraction Python'], 2, 1], [(4006970, 1), [['to make it more beautiful do this when printing:'], ['-10000']], [['  print "%s %%\\r" % (extracted_size * 100/uncompress_size),\n']], ['Monitor ZIP File Extraction Python'], 2, 0], [(4046986, 0), [["This is a minor modification of Doug Hellman's  multiprocessing ActivePool example code  (to use threading). The idea is to have your workers register themselves in a pool, unregister themselves when they finish, using a threading.Lock to coordinate modification of the pool's active list:"], ['yields    ']], [[" import threading\nimport time\nimport random\n\nclass ActivePool(object):\n    def __init__(self):\n        super(ActivePool, self).__init__()\n        self.active=[]\n        self.lock=threading.Lock()\n    def makeActive(self, name):\n        with self.lock:\n            self.active.append(name)\n    def makeInactive(self, name):\n        with self.lock:\n            self.active.remove(name)\n    def numActive(self):\n        with self.lock:\n            return len(self.active)\n    def __str__(self):\n        with self.lock:\n            return str(self.active)\ndef worker(pool):\n    name=threading.current_thread().name\n    pool.makeActive(name)\n    print 'Now running: %s' % str(pool)\n    time.sleep(random.randint(1,3))\n    pool.makeInactive(name)\n\nif __name__=='__main__':\n    poolA=ActivePool()\n    poolB=ActivePool()    \n    jobs=[]\n    for i in range(5):\n        jobs.append(\n            threading.Thread(target=worker, name='A{0}'.format(i),\n                             args=(poolA,)))\n        jobs.append(\n            threading.Thread(target=worker, name='B{0}'.format(i),\n                             args=(poolB,)))\n    for j in jobs:\n        j.daemon=True\n        j.start()\n    while threading.activeCount()>1:\n        for j in jobs:\n            j.join(1)\n            print 'A-threads active: {0}, B-threads active: {1}'.format(\n                poolA.numActive(),poolB.numActive())\n"]], ['python - how to get the numebr of active threads started by specific class?'], 2, 1], [(4046986, 1), [['yields    '], ['-10000']], [[" Now running: ['A0']\nNow running: ['B0']\nNow running: ['A0', 'A1']\nNow running: ['B0', 'B1']\n Now running: ['A0', 'A1', 'A2']\n Now running: ['B0', 'B1', 'B2']\nNow running: ['A0', 'A1', 'A2', 'A3']\nNow running: ['B0', 'B1', 'B2', 'B3']\nNow running: ['A0', 'A1', 'A2', 'A3', 'A4']\nNow running: ['B0', 'B1', 'B2', 'B3', 'B4']\nA-threads active: 4, B-threads active: 5\nA-threads active: 2, B-threads active: 5\nA-threads active: 0, B-threads active: 3\nA-threads active: 0, B-threads active: 3\nA-threads active: 0, B-threads active: 3\nA-threads active: 0, B-threads active: 3\nA-threads active: 0, B-threads active: 3\nA-threads active: 0, B-threads active: 0\nA-threads active: 0, B-threads active: 0\nA-threads active: 0, B-threads active: 0\n"]], ['python - how to get the numebr of active threads started by specific class?'], 2, 0], [(4112561, 0), [["I've missed an FAQ entry in the Boost.Python documentation that gave me the right hint:"], ['Create a thin wrapper function for the add_child method:']], [[' //The node class should be held by std::auto_ptr\nclass_<Node, std::auto_ptr<Node> >("Node")\n']], ['Boost.Python: Ownership of pointer variables'], 3, 0], [(4112561, 1), [['Create a thin wrapper function for the add_child method:'], ['Complete code to expose the node class:']], [[' void node_add_child(Node& n, std::auto_ptr<Node> child) {\n   n.add_child(child.get());\n   child.release();\n}\n']], ['Boost.Python: Ownership of pointer variables'], 3, 0], [(4112561, 2), [['Complete code to expose the node class:'], ['-10000']], [[' //The node class should be held by std::auto_ptr\nclass_<Node, std::auto_ptr<Node> >("Node")\n//expose the thin wrapper function as node.add_child()\n.def("addChild", &node_add_child)\n;\n']], ['Boost.Python: Ownership of pointer variables'], 3, 0], [(4201562, 0), [['Suppose your XML structure is like this:'], ['We parse it:']], [[' <ADDRESS>\n <STREET>One Main Street</STREET>\n <CITY>Gotham City</CITY>\n <ZIP>99999 0123</ZIP>\n <PHONE>555-123-5467</PHONE>\n </ADDRESS>\n']], ['Using lxml to extract data where all elements are not known in advance'], 5, 0], [(4201562, 2), [['Now suppose your XML has extra tags as well; tags you are not aware about. Since we are iterating through the XML, the above code will return those tags as well.'], ['The above code returns:']], [[' <ADDRESS>\n         <STREET>One Main Street</STREET>\n         <STREET1>One Second Street</STREET1>\n        <CITY>Gotham City</CITY>\n         <ZIP>99999 0123</ZIP>\n         <PHONE>555-123-5467</PHONE>         \n         <COUNTRY>USA</COUNTRY>    \n</ADDRESS>\n']], ['Using lxml to extract data where all elements are not known in advance'], 5, 0], [(4201562, 3), [['The above code returns:'], ['Now if we want to get the text of the tags, the procedure is the same. Just print tag.text like this:']], [[' ADDRESS\nSTREET\nSTREET1\nCITY\nZIP\nPHONE\nCOUNTRY\n']], ['Using lxml to extract data where all elements are not known in advance'], 5, 0], [(4201562, 4), [['Now if we want to get the text of the tags, the procedure is the same. Just print tag.text like this:'], ['-10000']], [[' >>> for tags in root.iter():\n...     print tags.text\n... \n\nOne Main Street\nOne Second Street\nGotham City\n99999 0123\n555-123-5467\nUSA\n']], ['Using lxml to extract data where all elements are not known in advance'], 5, 0], [(4219843, 0), [['Here is a thread safe version of ExpireCounter:'], ['which can be used like this:']], [[' import datetime\nimport collections\nimport threading\n\nclass ExpireCounter:\n    """Tracks how many events were added in the preceding time period\n    """\n\n    def __init__(self, timeout=1):\n        self.lock=threading.Lock()        \n        self.timeout = timeout\n        self.events = collections.deque()\n\n    def add(self,item):\n        """Add event time\n        """\n        with self.lock:\n            self.events.append(item)\n            threading.Timer(self.timeout,self.expire).start()\n\n    def __len__(self):\n        """Return number of active events\n        """\n        with self.lock:\n            return len(self.events)\n\n    def expire(self):\n        """Remove any expired events\n        """\n        with self.lock:\n            self.events.popleft()\n\n    def __str__(self):\n        with self.lock:\n            return str(self.events)\n']], ['container where values expire in python'], 2, 1], [(4219843, 1), [['which can be used like this:'], ['-10000']], [[' import time\nc = ExpireCounter()\nassert(len(c) == 0)\nprint(c)\n# deque([])\n\nc.add(datetime.datetime.now())\ntime.sleep(0.75)\nc.add(datetime.datetime.now())    \nassert(len(c) == 2)\nprint(c)\n# deque([datetime.datetime(2010, 11, 19, 8, 50, 0, 91426), datetime.datetime(2010, 11, 19, 8, 50, 0, 842715)])\n\ntime.sleep(0.75)\nassert(len(c) == 1)\nprint(c)\n# deque([datetime.datetime(2010, 11, 19, 8, 50, 0, 842715)])\n']], ['container where values expire in python'], 2, 0], [(4339273, 0), [['-10000'], ['Also possible, and a bit quicker is ']], [[' import numpy as np\ndeltas=np.diff(data)\ndeltas[deltas<0]=0\ndeltas[deltas>100]=0\n']], ['Can I cleanse a numpy array without a loop?'], 2, 1], [(4339273, 1), [['Also possible, and a bit quicker is '], ['-10000']], [[' deltas[(deltas<0) | (deltas>100)]=0\n']], ['Can I cleanse a numpy array without a loop?'], 2, 1], [(4339736, 0), [['You need to base64 encode the binary digest to get it into their format.'], ["EDIT:  By the way if you'd prefer to do this from a terminal/bash script, you can do "]], [[" >>> import hashlib\n>>> import base64\n\n>>> p = hashlib.sha1('password')\n>>> base64.b64encode(p.digest())\n'W6ph5Mm5Pz8GgiULbPgzG37mj9g='\n"]], ['Create a dovecot SHA1 digest using bash or python or some other linux command-line tool'], 2, 1], [(4397859, 0), [["I'm convinced  Zach's answer  is on the right track. Out of curiosity, I've implemented another version (incorporating Zach's comments about using a dict instead of  bisect ) and folded it into a solution that matches your example."], ['If your list of  necessary  prefixes is static or changes infrequently, you can speed up subsequent runs by pickling and reusing the  PickleMatch  object instead of rebuilding it each time. ']], [[' #!/usr/bin/env python\nimport re\nfrom trieMatch import PrefixMatch # https://gist.github.com/736416\n\npm = PrefixMatch([\'YELLOW\', \'GREEN\', \'RED\', ]) # huge list of 10 000 members\n# if list is static, it might be worth picking "pm" to avoid rebuilding each time\n\nf = open("huge_file.txt", "r") ## file with > 100 000 lines\nlines = f.readlines()\nf.close()\n\nregexp = re.compile(r\'^.*?fruit=([A-Z]+)\')\nfiltered = (line for line in lines if pm.match(regexp.match(line).group(1)))\n']], ['Smart filter with python'], 3, 1], [(4397859, 1), [['If your list of  necessary  prefixes is static or changes infrequently, you can speed up subsequent runs by pickling and reusing the  PickleMatch  object instead of rebuilding it each time. '], ['This means that your regex pattern is only evaluated once for each entry (not once for each compare), hence it should not be too expensive to do:']], [[' /* Special wrapper to support stable sorting using the decorate-sort-undecorate\n   pattern.  Holds a key which is used for comparisons and the original record\n   which is returned during the undecorate phase.  By exposing only the key\n   .... */\n']], ['Smart filter with python'], 3, 0], [(4397859, 2), [['This means that your regex pattern is only evaluated once for each entry (not once for each compare), hence it should not be too expensive to do:'], ['-10000']], [[' sorted_generator = sorted(filtered, key=regexp.match(line).group(1))\n']], ['Smart filter with python'], 3, 0], [(4402383, 1), [['For a more general solution (i.e. custom-defined splits), try this function:'], ['Which produces the output:']], [[" def split_on_parts(s, *parts):\n    total = 0\n    buildstr = []\n    for p in parts:\n        buildstr.append(s[total:total+p])\n        total += p\n    return buildstr\n\ns = 'hello world'\nprint split_on_parts(s, 3, 3, 3, 3)\nprint split_on_parts(s, 4, 3, 4)\n"]], ['Split string into array with many char pro items'], 4, 1], [(4402383, 2), [['Which produces the output:'], ["OR  if you're really in the mood for a one-liner:"]], [[" ['hel', 'lo ', 'wor', 'ld']\n['hell', 'o w', 'orld']\n"]], ['Split string into array with many char pro items'], 4, 0], [(4402383, 3), [["OR  if you're really in the mood for a one-liner:"], ['-10000']], [[' def split_on_parts(s, *parts):\n    return [s[sum(parts[:p]):sum(parts[:p+1])] for p in range(len(parts))]\n']], ['Split string into array with many char pro items'], 4, 1], [(4413798, 0), [['-10000'], ['If the endless loop "doesn\'t feel right", ask yourself when and why it should end. Should you have a third input option that exits the loop? Then add:  ']], [[' while True:\n    #this is the menu\n    menu=input("What would you like to do?\\ntype 1 for method1 or 2 for method2: ")\n    if(menu=="1"):\n        method1()\n    if(menu=="2"):\n        method2()\n']], ['python restart the program after running a method'], 2, 1], [(4416013, 0), [["First find the table (as you are doing). Using  find  rather than  findall  returns the first item in the list (rather than returning a list of all finds - in which case we'd have to add an extra  [0]  to take the first element of the list):"], ['Then use  find  again to find the first  td :']], [[" table = soup.find('table' ,attrs={'class':'bp_ergebnis_tab_info'})\n"]], ['Beautiful Soup [Python] and the extracting of text in a table'], 5, 0], [(4416013, 1), [['Then use  find  again to find the first  td :'], ['Then use  renderContents()  to extract the textual contents:']], [[" first_td = table.find('td')\n"]], ['Beautiful Soup [Python] and the extracting of text in a table'], 5, 0], [(4416013, 2), [['Then use  renderContents()  to extract the textual contents:'], ['... and the job is done (though you may also want to use  strip()  to remove leading and trailing spaces:']], [[' text = first_td.renderContents()\n']], ['Beautiful Soup [Python] and the extracting of text in a table'], 5, 0], [(4416013, 3), [['... and the job is done (though you may also want to use  strip()  to remove leading and trailing spaces:'], ['This should give:']], [[' trimmed_text = text.strip()\n']], ['Beautiful Soup [Python] and the extracting of text in a table'], 5, 0], [(4416013, 4), [['This should give:'], ['as desired.']], [[' >>> print trimmed_text\nThis is a sample text\n>>>\n']], ['Beautiful Soup [Python] and the extracting of text in a table'], 5, 0], [(4484985, 0), [["Assuming you've loaded the data into a variable called  raw :"], ['This gives:']], [[' from BeautifulSoup import BeautifulSoup\nsoup = BeautifulSoup(raw)\n\nfor x in soup.findAll("html:td"):\n   if x.string == "Equity share capital":\n       VALS = [y.string for y in x.parent.findAll() if y.has_key("class")]\n\nprint VALS\n']], ['Extract data from HTML in PHP or Python'], 2, 1], [(4484985, 1), [['This gives:'], ["Which you'll note is a list of unicode strings, make sure to convert them to whatever type you desire before processing."]], [[" [u'30.36', u'17.17', u'15.22', u'9.82', u'9.82']\n"]], ['Extract data from HTML in PHP or Python'], 2, 0], [(4534486, 1), [['Output:'], ["To directly answer the question in the title, you can use  time.time()  to get the current time since the epoch in seconds and keep calculating the subsequent fibonacci number until the time limit is reached. I've chosen to use an efficient method of computing fibonacci numbers below to give you a better demonstrating of this concept."]], [[' 3.12172317505\n']], ['finding the greatest Fibonacci number within limited time in python'], 4, 0], [(4534486, 2), [["To directly answer the question in the title, you can use  time.time()  to get the current time since the epoch in seconds and keep calculating the subsequent fibonacci number until the time limit is reached. I've chosen to use an efficient method of computing fibonacci numbers below to give you a better demonstrating of this concept."], ['Sample output:']], [[' def fibTimeLimited(limit):\n  start = time.time()\n  n, f0, f1 = 1, 0, 1\n  while time.time() < start + limit:\n    n += 1\n    f0, f1 = f1, f0+f1\n  return (n, f1)\n']], ['finding the greatest Fibonacci number within limited time in python'], 4, 1], [(4534486, 3), [['Sample output:'], ['-10000']], [[' Calculated 1st fibonacci number as 1 in 0.000001 seconds\nCalculated 31st fibonacci number as 1346269 in 0.000010 seconds\nCalculated 294th fibonacci number as 12384578529797304192493293627316781267732493780359086838016392 in 0.000100 seconds\n']], ['finding the greatest Fibonacci number within limited time in python'], 4, 0], [(4554767, 0), [['You can use  psutil  to find out about child processes, e.g. in pseudo-code:'], ['Note the difference in processes when running without --reload, obtained using  ps -ef | grep manage.py | grep -v grep :']], [[' p = Popen(...)\npp = psutil.Process(p.pid)\nfor child in pp.get_children():\n    child.send_signal(signal.SIGINT)\n']], ['Terminating subprocess in python'], 3, 1], [(4554767, 1), [['Note the difference in processes when running without --reload, obtained using  ps -ef | grep manage.py | grep -v grep :'], ['compared with using the --noreload option:']], [[' vinay 7864 7795  9 22:10 pts/0 00:00:00 python ./manage.py runserver\nvinay 7865 7864 16 22:10 pts/0 00:00:00 /usr/bin/python ./manage.py runserver\n']], ['Terminating subprocess in python'], 3, 0], [(4554767, 2), [['compared with using the --noreload option:'], ['-10000']], [[' vinay 7874 7795  7 22:10 pts/0 00:00:00 python ./manage.py runserver --noreload\n']], ['Terminating subprocess in python'], 3, 0], [(4631601, 0), [["I warn against doing this. There are rare exceptions where it's warranted, but almost all the time it's better avoiding this sort of hackish solution. If you want to though, you could use  vars()  to get a dictionary of attributes and iterate through it. As @Nick points out below, App Engine uses properties instead of values to define its members so you have to use  getattr()  to get their values."], ['Demonstration of what  vars()  does:']], [[" results = q.fetch(5)\nfor p in results:\n    for attribute in vars(p).keys()\n        print '%s = %s' % (attribute, str(getattr(p, attribute)))\n"]], ["Making an object's attributes iterable"], 2, 1], [(4631601, 1), [['Demonstration of what  vars()  does:'], ['-10000']], [[" >>> class A:\n...     def __init__(self, a, b):\n...         self.a = a\n...         self.b = b\n... \n>>> a = A(1, 2)\n>>> vars(a)\n{'a': 1, 'b': 2}\n>>> for attribute in vars(a).keys():\n...     print '%s = %s' % (attribute, str(getattr(a, attribute)))\n... \na = 1\nb = 2\n"]], ["Making an object's attributes iterable"], 2, 1], [(4659579, 0), [['You can do something like this:'], ['Traceback server side:']], [[' from SimpleXMLRPCServer import SimpleXMLRPCServer, SimpleXMLRPCRequestHandler\n\nport = 9999\n\ndef func():\n    print \'Hi!\'\n    print x # error!\n    print \'Bye!\'\n\nclass Handler(SimpleXMLRPCRequestHandler):\n     def _dispatch(self, method, params):\n         try: \n             return self.server.funcs[method](*params)\n         except:\n             import traceback\n             traceback.print_exc()\n             raise\n\n\nif __name__ == \'__main__\':\n    server = SimpleXMLRPCServer(("localhost", port), Handler)\n    server.register_function(func)\n    print "Listening on port %s..." % port\n    server.serve_forever()\n']], ['How to see traceback on xmlrpc server, not client?'], 2, 1], [(4659579, 1), [['Traceback server side:'], ['-10000']], [[' Listening on port 9999...\nHi!\nTraceback (most recent call last):\n  File "xml.py", line 13, in _dispatch\n    value = self.server.funcs[method](*params)\n  File "xml.py", line 7, in func\n    print x # error!\nNameError: global name \'x\' is not defined\nlocalhost - - [11/Jan/2011 17:13:16] "POST /RPC2 HTTP/1.0" 200 \n']], ['How to see traceback on xmlrpc server, not client?'], 2, 0], [(4660250, 0), [['Including the padding, this might work.  (There are list comprehensions in 2.1, right? Just looked it up -- they were added in 2.0.)'], ['In less ancient Python, I would replace the last line by']], [[' a = the_list\na += [0] * (-len(a) % 5)\nresult = [a[i:i + 5] for i in range(0, len(a), 5)]\n']], ['How to return every 5 items from a list in python?'], 2, 1], [(4660250, 1), [['In less ancient Python, I would replace the last line by'], ['-10000']], [[' result = zip(*[iter(a)] * 5)\n']], ['How to return every 5 items from a list in python?'], 2, 0], [(4696418, 0), [["That said, if you're willing to go that path, see  John Gruber's regex for the purpose :"], ['This can be used as follows:']], [[" def extract_urls(your_text):\n  url_re = re.compile(r'\\b(([\\w-]+://?|www[.])[^\\s()<>]+(?:\\([\\w\\d]+\\)|([^[:punct:]\\s]|/)))')\n  for match in url_re.finditer(your_text):\n    yield match.group(0)\n"]], ['Regex to extract all URLs from a page'], 2, 1], [(4696418, 1), [['This can be used as follows:'], ['-10000']], [[" >>> for uri in extract_urls('http://foo.bar/baz irc://freenode.org/bash'):\n...   print uri\nhttp://foo.bar/\nirc://freenode.org\n"]], ['Regex to extract all URLs from a page'], 2, 0], [(4702518, 0), [['are created, rdflib retrieve them in random order so you need to sort them to\n traverse them in the right order.'], ['Now there is exactly the same example but using SPARQL.']], [[' import rdflib\n\nRDF = rdflib.namespace.RDF\n\n#Parse the file\ng = rdflib.Graph()\ng.parse("zot.rdf")\n\n#So that we are sure we get something back\nprint "Number of triples",len(g)\n\n#Couple of handy namespaces to use later\nBIB = rdflib.Namespace("http://purl.org/net/biblio#")\nFOAF = rdflib.Namespace("http://xmlns.com/foaf/0.1/")\n\n#Author counter to print at the bottom\ni=0\n\n#Article for wich we want the list of authors\narticle = rdflib.term.URIRef("http://www.ncbi.nlm.nih.gov/pubmed/18273724")\n\n#First loop filters is equivalent to "get all authors for article x" \nfor triple in g.triples((article,BIB["authors"],None)):\n\n    #This expresions removes the rdf:type predicate cause we only want the bnodes\n    # of the form http://www.w3.org/1999/02/22-rdf-syntax-ns#_SEQ_NUMBER\n    # where SEQ_NUMBER is the index of the element in the rdf:Seq\n    list_triples = filter(lambda y: RDF[\'type\'] != y[1], g.triples((triple[2],None,None)))\n\n    #We sort the authors by the predicate of the triple - order in sequences do matter ;-)\n    # so "http://www.w3.org/1999/02/22-rdf-syntax-ns#_435"[44:] returns 435\n    # and since we want numberic order we do int(x[1][44:]) - (BTW x[1] is the predicate)\n    authors_sorted =  sorted(list_triples,key=lambda x: int(x[1][44:]))\n\n    #We iterate the authors bNodes and we get surname and givenname\n    for author_bnode in authors_sorted:\n        for x in g.triples((author_bnode[2],FOAF[\'surname\'],None)):\n            author_surname = x[2]\n        for y in g.triples((author_bnode[2],FOAF[\'givenname\'],None)):\n            author_name = y[2]\n        print "author(%s): %s %s"%(i,author_name,author_surname)\n        i += 1\n']], ['How to access members of an rdf list with rdflib (or plain sparql)'], 2, 1], [(4702518, 1), [['Now there is exactly the same example but using SPARQL.'], ["As it shows we still have to do the sorting thing because the library doesn't handle it by itself. In the query the variable  seq_index  holds the predicate that contains the information about the sequence order and that is the one to do the sort in the lambda function."]], [[' rdflib.plugin.register(\'sparql\', rdflib.query.Processor,\n                       \'rdfextras.sparql.processor\', \'Processor\')\nrdflib.plugin.register(\'sparql\', rdflib.query.Result,\n                       \'rdfextras.sparql.query\', \'SPARQLQueryResult\')\n\nquery = """\nSELECT ?seq_index ?name ?surname WHERE {\n     <http://www.ncbi.nlm.nih.gov/pubmed/18273724> bib:authors ?seq .\n     ?seq ?seq_index ?seq_bnode .\n     ?seq_bnode foaf:givenname ?name .\n     ?seq_bnode foaf:surname ?surname .\n}\n"""\nfor row in sorted(g.query(query, initNs=dict(rdf=RDF,foaf=FOAF,bib=BIB)),\n                                                  key=lambda x:int(x[0][44:])):\n    print "Author(%s) %s %s"%(row[0][44:],row[1],row[2])\n']], ['How to access members of an rdf list with rdflib (or plain sparql)'], 2, 1], [(4787291, 1), [['To test the above, I had to modify your code a bit; below is the full script.'], ['-10000']], [[" import sys\nimport inspect\nimport os\n\nclass PluginBase(object): pass\n\ndef search(base):\n    for root, dirs, files in os.walk('.'):\n        candidates = [fname for fname in files if fname.endswith('.py') \n                      and not fname.startswith('__')]\n        classList=[]\n        if candidates:\n            for c in candidates:\n                modname = os.path.splitext(c)[0]\n                try:\n                    module=__import__(modname)\n                except (ImportError,NotImplementedError):\n                    continue\n                for cls in dir(module):\n                    cls=getattr(module,cls)\n                    if (inspect.isclass(cls)\n                        and inspect.getmodule(cls)==module\n                        and issubclass(cls,base)):\n                        # print('found in {f}: {c}'.format(f=module.__name__,c=cls))\n                        classList.append(cls)\n        print(classList)\n\nsearch(PluginBase)\n"]], ['Dynamic importing of modules followed by instantiation of objects with a certain baseclass from said modules'], 2, 1], [(4791080, 1), [['I just read your updated question. I think I understand now. You have a file, like this:'], ["and you want to get rid of the empty lines. Instead of modifying the file while you're reading from it, create a new file that you can write the non-empty lines from the old file into, like so:"]], [[' aqua:test$ cat wordlist.txt \nTesting\n\nThis\n\nWordlist\n\nWith\n\nReturns\n\nBetween\n\nLines\n']], ['Delete newline / return carriage in file output'], 6, 0], [(4791080, 3), [['You should get:'], ['If you want something like']], [[' aqua:test$ cat newwordlist.txt \nTesting\nThis\nWordlist\nWith\nReturns\nBetween\nLines\n']], ['Delete newline / return carriage in file output'], 6, 0], [(4791080, 4), [['If you want something like'], ['just comment out ']], [[' TestingThisWordlistWithReturnsBetweenLines\n']], ['Delete newline / return carriage in file output'], 6, 0], [(4791080, 5), [['just comment out '], ['-10000']], [[" wf.write('\\n')\n"]], ['Delete newline / return carriage in file output'], 6, 0], [(4797704, 0), [['The way web.py does this for 301 and other redirect types is by subclassing  web.HTTPError  (which in turn sets  web.ctx.status ). For example:'], ['Then to output this status code you  raise MultipleChoices  in your handler:']], [[' class MultipleChoices(web.HTTPError):\n    def __init__(self, choices):\n        status = \'300 Multiple Choices\'\n        headers = {\'Content-Type\': \'text/html\'}\n        data = \'<h1>Multiple Choices</h1>\\n<ul>\\n\'\n        data += \'\'.join(\'<li><a href="{0}">{0}</a></li>\\n\'.format(c)\n                        for c in choices)\n        data += \'</ul>\'\n        web.HTTPError.__init__(self, status, headers, data)\n']], ['Webpy: how to set http status code to 300'], 2, 0], [(4797704, 1), [['Then to output this status code you  raise MultipleChoices  in your handler:'], ["It'll need tuning for your particular unAPI application, of course."]], [[" class MyHandler:\n    def GET(self):\n        raise MultipleChoices(['http://example.com/', 'http://www.google.com/'])\n"]], ['Webpy: how to set http status code to 300'], 2, 0], [(4808753, 0), [["This depends on what version you're using. If you have ElementTree 1.3+ (including in Python 2.7 standard library) you can use a basic xpath expression, as  described in the docs , like  [@attrib=’value’] :"], ["Unfortunately if you're using an earlier version of ElementTree (1.2, included in standard library for python 2.5 and 2.6) you can't use that convenience and need to filter yourself."]], [[' x = ElmentTree(file=\'testdata.xml\')\ncases = x.findall(".//testcase[@name=\'VHDL_BUILD_Passthrough\'][@classname=\'TestOne\']"\n']], ['Find occurrence using multiple attributes in ElementTree/Python'], 2, 1], [(4808753, 1), [["Unfortunately if you're using an earlier version of ElementTree (1.2, included in standard library for python 2.5 and 2.6) you can't use that convenience and need to filter yourself."], ['-10000']], [[' x = ElmentTree(file=\'testdata.xml\')\nallcases = x12.findall(".//testcase")\ncases = [c for c in allcases if c.get(\'classname\') == \'TestOne\' and c.get(\'name\') == \'VHDL_BUILD_Passthrough\']\n']], ['Find occurrence using multiple attributes in ElementTree/Python'], 2, 1], [(4867037, 0), [["Note  I'm still using django-staticfiles with Django 1.2, but it should work similarly for Django 1.3"], ['and my project looks like this:']], [[' STATIC_URL = "/site_media/static/"\nSTATIC_ROOT = os.path.join(PROJECT_ROOT, "site_media", "static")\nSTATICFILES_DIRS = (\n    os.path.join(PROJECT_ROOT, "static_media"),\n)\n']], ['Django: css referencing media in static files (django dev / 1.3 / static files)'], 2, 0], [(4867037, 1), [['and my project looks like this:'], ["Let me know if you have any questions, and I'll clarify."]], [[' project_dir\n  ...\n  stuff\n  static_media\n    ...\n    css\n    images\n']], ['Django: css referencing media in static files (django dev / 1.3 / static files)'], 2, 0], [(4868900, 1), [['Then when it comes to create a resource, you simply do:'], ['And you can also do some really fancy stuff like:']], [[' r = resource(name="")\na1 = author(name="ninefingers")\na2 = author(name="jon skeet", type="god")\nr.authors.add(a1)\nr.authors.add(a2)\nenglish = languages.objects.get(iso_lang_code="en-GB")\nr.add(english)\nr.save()\n']], ['How do I store multiple copies of the same field in Django?'], 4, 0], [(4868900, 2), [['And you can also do some really fancy stuff like:'], ['Another approach might be to write all the languages as ISO codes modified by a splitter, say  ;  then do ']], [[' english = languages.objects.get(iso_lang_code="en-GB")\nresourcesinenglish = english.resource_set.all()\n\nfor r in resourcesinenglish:\n    # do something on r.\n']], ['How do I store multiple copies of the same field in Django?'], 4, 0], [(4868900, 3), [['Another approach might be to write all the languages as ISO codes modified by a splitter, say  ;  then do '], ['Of course, maintaining said list becomes more difficult that way. I think the ORM is easier by far.']], [[" r = resource.objects.get(id=701)\nlangs = r.languages.split(';')\nfor l in language:\n    print l\n"]], ['How do I store multiple copies of the same field in Django?'], 4, 0], [(4910789, 0), [['Here are ways to handle conditions on columns or rows, inspired by the Zen of Python.'], ['So following the second advice: \na) conditions on column(s), applied to row(s):']], [[' In []: import this\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\n...\n']], ['Getting the row index for a 2D numPy array when multiple column values are known'], 3, 0], [(4910789, 1), [['So following the second advice: \na) conditions on column(s), applied to row(s):'], ['b) conditions on row(s), applied to column(s):']], [[' In []: a= arange(12).reshape(3, 4)\nIn []: a\nOut[]:\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\nIn []: a[2, logical_and(1== a[0, :], 5== a[1, :])]+= 12\nIn []: a\nOut[]:\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8, 21, 10, 11]])\n']], ['Getting the row index for a 2D numPy array when multiple column values are known'], 3, 0], [(4936507, 0), [['Standart middleware'], ['In pyramid creating app code:']], [[" class LoggerMiddleware(object):\n    '''WSGI middleware'''\n\n    def __init__(self, application):\n\n        self.app = application\n\n    def __call__(self, environ, start_response):\n\n        # write logs\n\n        try:\n            return self.app(environ, start_response)\n        except Exception, e:\n            # write logs\n            pass\n        finally:\n            # write logs\n            pass\n"]], ['How do I write a logging middleware for pyramid/pylons 2?'], 2, 0], [(4936507, 1), [['In pyramid creating app code:'], ['-10000']], [[" from paste.httpserver import serve\nfrom pyramid.response import Response\nfrom pyramid.view import view_config\n\n@view_config()\ndef hello(request):\n    return Response('Hello')\n\nif __name__ == '__main__':\n    from pyramid.config import Configurator\n    config = Configurator()\n    config.scan()\n    app = config.make_wsgi_app()\n\n    # Put middleware\n    app = LoggerMiddleware(app)\n\n    serve(app, host='0.0.0.0')\n"]], ['How do I write a logging middleware for pyramid/pylons 2?'], 2, 0], [(4951751, 1), [['For a single string, a tokenizer would be used as follows (explained  here , see section 5 for punkt tokenizer).'], ['-10000']], [[' >>> import nltk.data\n>>> text = """\n... Punkt knows that the periods in Mr. Smith and Johann S. Bach\n... do not mark sentence boundaries.  And sometimes sentences\n... can start with non-capitalized words.  i is a good variable\n... name.\n... """\n>>> tokenizer = nltk.data.load(\'tokenizers/punkt/english.pickle\')\n>>> tokenizer.tokenize(text.strip())\n']], ['Creating a new corpus with NLTK'], 2, 0], [(4975563, 0), [['It is entirely possible to do this. You can do this with regular views, and then create templates that extend the "admin/base_site.html" template like so:'], ['You can also do breadcrumbs like this:']], [[' {% extends "admin/base_site.html" %}\n']], ["Radical Use of Admin's Interface"], 2, 1], [(4975563, 1), [['You can also do breadcrumbs like this:'], ['And then put whatever content you want inside of the "content" block.']], [[' {% block breadcrumbs %}{% if not is_popup %}\n    <div class="breadcrumbs">\n         <a href="/admin/">Home</a> &rsaquo;\n         <a href="/admin/yourpath/">Up One Level</a> &rsaquo; \n         You Are Here\n    </div>\n{% endif %}{% endblock %}\n']], ["Radical Use of Admin's Interface"], 2, 1], [(4976964, 0), [["I would use Python dictionaries where the dictionary keys are column A values and the dictionary values are Python's built-in  Set type  holding column B values"], ['Testing the code above on your input example yields:']], [[' def parse_the_file():\n    lower = str.lower\n    split = str.split\n    with open(\'f.txt\') as f:\n        d = {}\n        lines = f.read().split(\'\\n\')\n        for A,B in [split(l) for l in lines]:\n            try:\n                d[lower(A)].add(B)\n            except KeyError:\n                d[lower(A)] = set(B)\n\n        for a in d:\n            print "%s - %s" % (a,",".join(list(d[a])))\n\nif __name__ == "__main__":\n    parse_the_file()\n']], ['how to get unique values set from a repeating values list'], 2, 1], [(4976964, 1), [['Testing the code above on your input example yields:'], ['-10000']], [[' xxxd - 4\nxxxa - 1,3,2\nxxxb - 2\nxxxc - 3\n']], ['how to get unique values set from a repeating values list'], 2, 0], [(4981815, 0), [["I'm showing that a combination of  lines.pop(0)   l.remove()  and  del l  does the trick."], ['Of course the simpler way (when not trouble-shooting) would be to pop it from the list and call  remove  on the line object without creating a hard reference to it: ']], [[' from matplotlib import pyplot\nimport numpy, weakref\na = numpy.arange(int(1e3))\nfig = pyplot.Figure()\nax  = fig.add_subplot(1, 1, 1)\nlines = ax.plot(a)\n\nl = lines.pop(0)\nwl = weakref.ref(l)  # create a weak reference to see if references still exist\n#                      to this object\nprint wl  # not dead\nl.remove()\nprint wl  # not dead\ndel l\nprint wl  # dead  (remove either of the steps above and this is still live)\n']], ['How to remove lines in a Matplotlib plot'], 2, 1], [(5051795, 0), [["Do you really to modify the dictionary in-place? You can easily generate a new one (thanks to iterators, without even touching the items you don't need):"], ['You  could  also truncate the original one, but that would be less performant for large one and is propably not needed. Semantics are different if someone else is using  d , of course.']], [[' OrderedDict(itertools.islice(d.iteritems(), 500))\n']], ['Truncate the length of a Python dictionary'], 2, 1], [(5051795, 1), [['You  could  also truncate the original one, but that would be less performant for large one and is propably not needed. Semantics are different if someone else is using  d , of course.'], ['-10000']], [[" # can't use .iteritems() as you can't/shouldn't modify something while iterating it\nto_remove = d.keys()[500:] # slice off first 500 keys\nfor key in to_remove:\n    del d[key]\n"]], ['Truncate the length of a Python dictionary'], 2, 1], [(5073624, 1), [['If you want to check for a specific value, how about'], ['this code will most often fail early (quickly)']], [[' testval = 1\nall(val==testval for val in d.values())   # -> True\n']], ['in python, how do I check to see if keys in a dictionary all have the same value x?'], 2, 1], [(5103329, 0), [['As for Python modules, you can do'], ["and you'll get a list of supported methods (more exactly, you get the docstring, which might not contain every single method). If you want that, you can use"]], [[' >>> import module\n>>> help(module)\n']], ['How to find out what methods, properties, etc a python module possesses'], 2, 1], [(5148790, 1), [['Solution:'], ['-10000']], [[' try:\n    int(myvar)\nexcept ValueError:\n    ...Handle the exception...\n']], ['how to convert value of column defined as character into integer in python'], 2, 1], [(5162130, 1), [['using numpy is very useful if performance matters, optimized C math code is doing the work:'], ['-10000']], [[" In [10]: %time a=reduce(list(np.arange(1000000))) #chosen answer\nCPU times: user 6.38 s, sys: 0.08 s, total: 6.46 s\nWall time: 6.39 s\n\nIn [11]: %time c=np.convolve(list(np.arange(1000000)), [.5,.5], mode='valid')[::2]\nCPU times: user 0.59 s, sys: 0.01 s, total: 0.60 s\nWall time: 0.61 s\n"]], ['Elegant way of reducing list by averaging?'], 2, 0], [(5185944, 0), [['The cleanest way to do it is with  cssselect  from  lxml.html  and  urlparse . Here is how:'], ['UPDATE :\nThe  href  filter suggestion in the comments is very helpful, the code will look like this:']], [[' from lxml import html\nfrom urlparse import urlparse\ndoc = html.fromstring(html_data)\nlinks = doc.cssselect("a")\ndomains = set([])\nfor link in links:\n    try: href=link.attrib[\'href\']\n    except KeyError: continue\n    parsed=urlparse(href)\n    domains.add(parsed.netloc)\nprint domains\n']], ['Extract domain from body of email'], 2, 0], [(5185944, 1), [['UPDATE :\nThe  href  filter suggestion in the comments is very helpful, the code will look like this:'], ["You don't need the  try-catch  block since the  href  filter makes sure you catch only the anchors that have  href  attribute in them."]], [[' from lxml import html\nfrom urlparse import urlparse\ndoc = html.fromstring(html_data)\nlinks = doc.cssselect("a[href]")\ndomains = set([])\nfor link in links:\n    href=link.attrib[\'href\']\n    parsed=urlparse(href)\n    domains.add(parsed.netloc)\nprint domains\n']], ['Extract domain from body of email'], 2, 1], [(5198116, 0), [["Let's use smaller dimensions so the result is easier to see:"], ['We can construct a boolean array in a checkerboard pattern:']], [[' import numpy as np\n# w=2948\n# h=1536\nw=6\nh=4\narr=np.arange(w*h).reshape(w,h)\nprint(arr)\nprint(arr.shape)\n# [[ 0  1  2  3]\n#  [ 4  5  6  7]\n#  [ 8  9 10 11]\n#  [12 13 14 15]\n#  [16 17 18 19]\n#  [20 21 22 23]]\n# (6, 4)\n']], ['getting pixels value in a checkerboard pattern in python'], 3, 0], [(5198116, 1), [['We can construct a boolean array in a checkerboard pattern:'], ['Using this  boolean array for indexing , we can extract the values we desire:']], [[' coords=np.ogrid[0:w,0:h]\nidx=(coords[0]+coords[1])%2 == 1\nprint(idx)\nprint(idx.shape)\n# [[False  True False  True]\n#  [ True False  True False]\n#  [False  True False  True]\n#  [ True False  True False]\n#  [False  True False  True]\n#  [ True False  True False]]\n# (6, 4)\n']], ['getting pixels value in a checkerboard pattern in python'], 3, 0], [(5198116, 2), [['Using this  boolean array for indexing , we can extract the values we desire:'], ["PS. Inspiration for this answer came from Ned Batchelder's answer  here ."]], [[' checkerboard=arr[idx].reshape(w,h//2)\nprint(checkerboard)\nprint(checkerboard.shape)\n# [[ 1  3]\n#  [ 4  6]\n#  [ 9 11]\n#  [12 14]\n#  [17 19]\n#  [20 22]]\n# (6, 2)\n']], ['getting pixels value in a checkerboard pattern in python'], 3, 0], [(5222333, 0), [["The other thing you can do is have your script automatically invoke sudo if it wasn't executed as root:"], ['Output:']], [[' import os\nimport sys\n\neuid = os.geteuid()\nif euid != 0:\n    print "Script not started as root. Running sudo.."\n    args = [\'sudo\', sys.executable] + sys.argv + [os.environ]\n    # the next line replaces the currently-running process with the sudo\n    os.execlpe(\'sudo\', *args)\n\nprint \'Running. Your euid is\', euid\n']], ['authentication in python script to run as root'], 2, 1], [(5222333, 1), [['Output:'], ['Use  sudo -k  for testing, to clear your sudo timestamp so the next time the script is run it will require the password again.']], [[' Script not started as root. Running sudo..\n[sudo] password for bob:\nRunning. Your euid is 0\n']], ['authentication in python script to run as root'], 2, 0], [(5276837, 0), [['Employing this function allows to read a file one line at a time, without reading the entire file into memory.'], ["Here's the same, with printings here and there to allow to follow the algorithm."]], [[" from random import randrange, choice\n\n\n# this part is to create an exemple file with newline being :;:\nalphabet = 'abcdefghijklmnopqrstuvwxyz '\nch = ':;:'.join(''.join(choice(alphabet) for nc in xrange(randrange(0,40)))\n                for i in xrange(50))\nwith open('fofo.txt','wb') as g:\n    g.write(ch)\n\n\n# this generator function is an iterator for a file\n# if nl receives an argument whose bool is True,\n# the newlines :;: are returned in the lines\n\ndef liner(filename,eol,lenchunk,nl=0):\n    # nl = 0 or 1 acts as 0 or 1 in splitlines()\n    L = len(eol)\n    NL = len(eol) if nl else 0\n    with open(filename,'rb') as f:\n        chunk = f.read(lenchunk)\n        tail = ''\n        while chunk:\n            last = chunk.rfind(eol)\n            if last==-1:\n                kept = chunk\n                newtail = ''\n            else:\n                kept = chunk[0:last+L]   # here: L\n                newtail = chunk[last+L:] # here: L\n            chunk = tail + kept\n            tail = newtail\n            x = y = 0\n            while y+1:\n                y = chunk.find(eol,x)\n                if y+1: yield chunk[x:y+NL] # here: NL\n                else: break\n                x = y+L # here: L\n            chunk = f.read(lenchunk)\n        yield tail\n\n\n\nfor line in liner('fofo.txt',':;:'):\n    print line\n"]], ['Special End-line characters/string from lines read from text file, using Python'], 5, 1], [(5276837, 2), [["With a 'fofo.txt' file about 10 MB, created with"], ['and measuring times like that:']], [[" alphabet = 'abcdefghijklmnopqrstuvwxyz '\nch = ':;:'.join(''.join(choice(alphabet) for nc in xrange(randrange(0,60)))\n                for i in xrange(324000))\nwith open('fofo.txt','wb') as g:\n    g.write(ch)\n"]], ['Special End-line characters/string from lines read from text file, using Python'], 5, 0], [(5276837, 3), [['and measuring times like that:'], ["I changed my generator function:  liner2()  takes a file-handler instead of the file's name. So the opening of the file can be put out of the measuring of time, as it is for the measuring of chmullig's code"]], [[" te = clock()\nfor line in liner('fofo.txt',':;:', 65536):\n    pass\nprint clock()-te\n\n\nfh = open('fofo.txt', 'rb')\nzenBreaker = SpecialDelimiters(fh, ':;:', 65536)\n\nte = clock()\nfor line in zenBreaker:\n    pass\nprint clock()-te\n"]], ['Special End-line characters/string from lines read from text file, using Python'], 5, 0], [(5276837, 4), [["I changed my generator function:  liner2()  takes a file-handler instead of the file's name. So the opening of the file can be put out of the measuring of time, as it is for the measuring of chmullig's code"], ['The results, after numerous essays to see the minimum times, are']], [[" def liner2(fh,eol,lenchunk,nl=0):\n    L = len(eol)\n    NL = len(eol) if nl else 0\n    chunk = fh.read(lenchunk)\n    tail = ''\n    while chunk:\n        last = chunk.rfind(eol)\n        if last==-1:\n            kept = chunk\n            newtail = ''\n        else:\n            kept = chunk[0:last+L]   # here: L\n            newtail = chunk[last+L:] # here: L\n        chunk = tail + kept\n        tail = newtail\n        x = y = 0\n        while y+1:\n            y = chunk.find(eol,x)\n            if y+1: yield chunk[x:y+NL] # here: NL\n            else: break\n            x = y+L # here: L\n        chunk = fh.read(lenchunk)\n    yield tail\n\nfh = open('fofo.txt', 'rb')\nte = clock()\nfor line in liner2(fh,':;:', 65536):\n    pass\nprint clock()-te\n"]], ['Special End-line characters/string from lines read from text file, using Python'], 5, 1], [(5286022, 1), [['This will still use exponential format if the number is too small, so you have to treat this case separately, for example'], ['-10000']], [[' "%.16f" % f if f >= 1e-16 else "0.0"\n']], ['Python: Suppress exponential format (i.e. 9e-10) in float to string conversion?'], 2, 1], [(5300387, 0), [['Just override the  kind()  method of your class:'], ['You can define a custom baseclass that does this for you:']], [[" class MyModel(db.Model):\n  @classmethod\n  def kind(cls):\n    return 'prefix_%s' % super(MyModel, cls).kind()\n"]], ['Set a kind name independently of the model name (App Engine datastore)'], 2, 1], [(5300387, 1), [['You can define a custom baseclass that does this for you:'], ["Any class that extends ModuleModel will have the name of the module it's defined in prefixed to the kind name."]], [[" class ModuleModel(db.Model):\n  @classmethod\n  def kind(cls):\n    return '%s_%s' % (cls.__module__, super(ModuleModel, cls).kind())\n"]], ['Set a kind name independently of the model name (App Engine datastore)'], 2, 1], [(5321466, 0), [['Yes, you need the  pytz  library:'], ['returns:']], [[" import datetime, pytz\nzoneName = 'America/New_York'\nnow = datetime.datetime.now(pytz.timezone(zoneName))\n"]], ['How to convert string timezones in form (Country/city) into datetime.tzinfo'], 2, 1], [(5321466, 1), [['returns:'], ['-10000']], [[" datetime.datetime(2011, 3, 16, 1, 39, 33, 87375, tzinfo=<DstTzInfo 'America/New_York' EDT-1 day, 20:00:00 DST>)\n"]], ['How to convert string timezones in form (Country/city) into datetime.tzinfo'], 2, 0], [(5332701, 0), [['If you want it between the 5th and 6th characters you could try this:'], ['If you want it after the first hyphen and then one more character:']], [[" s = s[:5] + '-' + s[5:]\n"]], ['How to search & replace in Python?'], 6, 1], [(5332701, 1), [['If you want it after the first hyphen and then one more character:'], ['If you want it just before the first digit:']], [[" i = s.index('-') + 2\ns = s[:i] + '-' + s[i:]\n"]], ['How to search & replace in Python?'], 6, 1], [(5332701, 2), [['If you want it just before the first digit:'], ['-10000']], [[" import re\ni = re.search('\\d', s).start()\ns = s[:i] + '-' + s[i:]\n"]], ['How to search & replace in Python?'], 6, 1], [(5332701, 3), [['-10000'], ['or:']], [[" i = re.search('(?<=\\d\\d)', s).start()\ns = s[:i] + '-' + s[i:]\n"]], ['How to search & replace in Python?'], 6, 1], [(5332701, 4), [['or:'], ['or:']], [[" s = re.sub('(?<=\\d\\d)', '-', s, 1)\n"]], ['How to search & replace in Python?'], 6, 1], [(5332701, 5), [['or:'], ['-10000']], [[" s = re.sub('(\\d\\d)', r'\\1-', s, 1)\n"]], ['How to search & replace in Python?'], 6, 1], [(5447428, 0), [['Your addTerm method could then be something like:'], ['Searching if a word is in the trie would be something like']], [[' def addTerm(self, term):\n   node = self.tree\n   for c in term:\n      c = c.lower()\n      if re.match("[a-z]",c):\n         node = node[0].setdefault(c,[{},None])\n   node[1] = term\n']], ['Accessing a Dynamically Generated Nested Dictionary'], 2, 0], [(5447428, 1), [['Searching if a word is in the trie would be something like'], ['-10000']], [[' def findTerm(self, term):\n    node = self.tree\n    for c in term:\n        c = c.lower()\n        if re.match("[a-z]",c):\n            if c in node[0]:\n                node = node[0][c]\n            else:\n                return False\n    return node[1] != None\n']], ['Accessing a Dynamically Generated Nested Dictionary'], 2, 0], [(5464504, 0), [['Thats right,'], ['module exapmle:']], [[' from module import desired_object\n']], ['Accessing an object created in another module using python'], 2, 0], [(5464504, 1), [['module exapmle:'], ["But make sure the 'my_func' must be called before importing desired_object from your module"]], [[' # Desired Module:\n\ndesired_object = None\ndef my_func():\n    global desired_object\n    desired_object = SomeObject()\n']], ['Accessing an object created in another module using python'], 2, 0], [(5470210, 0), [['I created extra field for user (userattributes extends user):'], ['and method:']], [[' class UserAttributes(User):\n    last_session_key = models.CharField(blank=True, null=True, max_length=40)\n']], ['django one session per user'], 3, 0], [(5470210, 1), [['and method:'], ['and i called it just after login:']], [[' def set_session_key(self, key):\n    if self.last_session_key and not self.last_session_key == key:\n        Session.objects.get(session_key=self.last_session_key).delete()\n    self.last_session_key = key\n    self.save()  \n']], ['django one session per user'], 3, 0], [(5470210, 2), [['and i called it just after login:'], ['-10000']], [[' auth.login(request, user)\nuser.userattributes.set_session_key(request.session.session_key)\n']], ['django one session per user'], 3, 0], [(5472771, 0), [['like '], ['and ']], [[' from django.db import connection\nsql=connection.queries\n']], ['customize django runserver output'], 2, 0], [(5472771, 1), [['and '], ['read more about this in  http://docs.djangoproject.com/en/dev/topics/logging/']], [[' doc = {\n                \'record_hash\': hash,\n                \'level\': record.level,\n                \'channel\': record.channel or u\'\',\n                \'location\': u\'%s:%d\' % (record.filename, record.lineno),\n                "message": record.msg,\n                \'module\': record.module or u\'<unknown>\',\n                \'occurrence_count\': 0,\n                \'solved\': False,\n                \'app_id\': app_id,\n                \'sql\': sql,\n            }\n']], ['customize django runserver output'], 2, 0], [(5478351, 1), [['And the usage is very simple, just use the @timing decorator:'], ["Note I'm calling  f.func_name  to get the function name as a string(in Python 2), or  f.__name__   in Python 3."]], [[' @timing\ndef do_work():\n  #code\n']], ['Python time measure function'], 2, 0], [(5530857, 1), [['Output:'], ['If your attraction to a regex is being terse, here is an equally incomprehensible bit of list comprehension to create a data structure:']], [[' -------------------\n           Name: some filename.mp3             \n        Encoder: Gogo (after 3.0)              \n        Bitrate: 131                           \n-------------------\n           Name: another filename.mp3          \n        Encoder: iTunes                        \n        Bitrate: 128                           \n\nan alternate way:\n           Name: another filename.mp3  \n']], ['Parse XML file into Python object'], 5, 0], [(5530857, 3), [['Which creates a list of tuples of the XML children of  <file>  in document order:'], ['Code golf is on!']], [[" [('Name', 'some filename.mp3'), \n ('Encoder', 'Gogo (after 3.0)'), \n ('Bitrate', '131'), \n ('Name', 'another filename.mp3'), \n ('Encoder', 'iTunes'), \n ('Bitrate', '128')]\n"]], ['Parse XML file into Python object'], 5, 0], [(5532498, 0), [['A slightly verbose writing of another method'], ['Or']], [[' import os\ndir = "E:\\\\test"\nfiles = os.listdir(dir)\nfor file in files:\n    if file.endswith(".txt"):\n        os.remove(os.path.join(dir,file))\n']], ['Delete files with python through OS shell'], 2, 1], [(5532498, 1), [['Or'], ['-10000']], [[' import os\n[os.remove(os.path.join("E:\\\\test",f)) for f in os.listdir("E:\\\\test") if f.endswith(".txt")]\n']], ['Delete files with python through OS shell'], 2, 1], [(5599022, 0), [["That should be fairly easy to parse yourself. Use of the helper libraries would be complicated by not knowing the keys in advance. The filename is in sys.argv[1]. You can build the dictionary with a list of strings split with the '=' character as a delimiter."], ['Output:']], [[" import sys\nfilename = sys.argv[1]\nargs = dict([arg.split('=', maxsplit=1) for arg in sys.argv[2:]])\nprint filename\nprint args\n"]], ['Python: Pass a generic dictionary as a command line arguments'], 2, 1], [(5599022, 1), [['Output:'], ["That's the gist of it, but you may need more robust parsing of the key-value pairs than just splitting the string. Also, make sure you have at least two arguments in  sys.argv  before trying to extract the filename."]], [[" $ Script.py file1 bob=1 sue=2 ben=3\nfile1\n{'bob': '1', 'ben': '3', 'sue': '2'}\n"]], ['Python: Pass a generic dictionary as a command line arguments'], 2, 0], [(5629242, 0), [['You can use  os.listdir(".")  to list the contents of the current directory ("."):'], ['If you want the whole list as a Python list, use a  list comprehension :']], [[' for name in os.listdir("."):\n    if name.endswith(".txt"):\n        print(name)\n']], ['Getting Every File in a Directory, Python'], 2, 1], [(5629242, 1), [['If you want the whole list as a Python list, use a  list comprehension :'], ['-10000']], [[' a = [name for name in os.listdir(".") if name.endswith(".txt")]\n']], ['Getting Every File in a Directory, Python'], 2, 1], [(5678136, 0), [['Here is an example.  I commented out your code where I changed things. I changed the example not to use slicing in exchange for explicit variable assignment.'], ['Outputs:']], [[' subject_dic = {}\ninputFile = open(filename)\n\n# Turn "line1\\nline2\\n" into [\'line1\', \'line2\']\ninputData = inputFile.read().splitlines()\n\n#for line in inputFile:\nfor line in inputData:\n    #split_line = string.split(line, \',\')\n    #subject_dic[split_line[0]] = tuple(split_line[1:3])\n    mykey, myval1, myval2 = line.split(\',\') # Strings always have .split()\n    subject_dic[mykey] = (myval1, myval2) # Explicit tuple assignment\n\nprint subject_dic\n']], ['trying to create a dictionary but do not know how to deal with \\n'], 2, 1], [(5678136, 1), [['Outputs:'], ['-10000']], [[" {'6.00': ('10', '1'),\n '6.01': ('5', '4'),\n '6.02': ('5', '6'),\n '6.03': ('2', '9'),\n '6.04': ('1', '2'),\n '6.05': ('1', '18'),\n '6.06': ('5', '19'),\n '6.07': ('2', '10'),\n '6.08': ('1', '10'),\n '6.09': ('3', '7'),\n '6.10': ('8', '18'),\n '6.11': ('6', '8'),\n '6.12': ('6', '3'),\n '6.13': ('9', '16'),\n '6.14': ('10', '8'),\n '6.15': ('10', '6'),\n '6.16': ('6', '9'),\n '6.17': ('9', '3'),\n '6.18': ('10', '4'),\n '6.19': ('8', '19')}\n"]], ['trying to create a dictionary but do not know how to deal with \\n'], 2, 0], [(5678950, 0), [['And here is some sample code:'], ['If you do not want to place your polygon using axis coordinate system but rather want it positioned using data coordinate system, then you can use the transforms to statically convert the data before positioning.  Best exemplified here:']], [[' from matplotlib import pyplot as plt\nfrom matplotlib.patches import Polygon\nimport numpy as np\nx = np.linspace(0,5,100)\ny = np.sin(x)\n\nplt.plot(x,y)\nax = plt.gca()\n\npolygon = Polygon([[.1,.1],[.3,.2],[.2,.3]], True, transform=ax.transAxes)\nax.add_patch(polygon)\n\nplt.show()\n']], ['Matplotlib artists to stay the same size when zoomed in?'], 2, 1], [(5678950, 1), [['If you do not want to place your polygon using axis coordinate system but rather want it positioned using data coordinate system, then you can use the transforms to statically convert the data before positioning.  Best exemplified here:'], ['-10000']], [[' from matplotlib import pyplot as plt\nfrom matplotlib.patches import Polygon\nimport numpy as np\n\nx = np.linspace(0,5,100)\ny = np.sin(x)\n\nplt.plot(x,y)\nax = plt.gca()\n\ndta_pts = [[.5,-.75],[1.5,-.6],[1,-.4]]\n\n# coordinates converters:\n#ax_to_display = ax.transAxes.transform\ndisplay_to_ax = ax.transAxes.inverted().transform\ndata_to_display = ax.transData.transform\n#display_to_data = ax.transData.inverted().transform\n\nax_pts = display_to_ax(data_to_display(dta_pts))\n\n# this triangle will move with the plot\nax.add_patch(Polygon(dta_pts, True)) \n# this triangle will stay put relative to the axes bounds\nax.add_patch(Polygon(ax_pts, True, transform=ax.transAxes))\n\nplt.show()\n']], ['Matplotlib artists to stay the same size when zoomed in?'], 2, 1], [(5701962, 0), [['Guessing at you really mean, I would rewrite your code as follows:'], ['I changed']], [[' from urlparse import urlparse\nimport csv\nimport re\n\nifile =open(ipath,\'r\')\nofile = open(opath, \'wb\')\nwriter = csv.writer(ofile, dialect=\'excel\')\n\nurl =[urlparse(u).netloc for u in ifile]\nsitesource =  set([re.sub("www.", "", e) for e in url])\n\nfor u in sitesource:\n    print ("Creation de:", u)\n    writer.writerow([u]) \n\nofile.close()\nifile.close()\n']], ['Python .csv writer'], 3, 1], [(5701962, 1), [['I changed'], ['to']], [[' url =[urlparse(u).netloc for u in file (ipath, "r+b")]\n']], ['Python .csv writer'], 3, 0], [(5701962, 2), [['to'], ['because you already had the file open.  I assumed you did not want binary mode if you are reading strings.']], [[' url =[urlparse(u).netloc for u in ifile]\n']], ['Python .csv writer'], 3, 0], [(5722767, 0), [['Great thanks to Craig de Stigter answered my question on django-mptt-dev group, in case anybody need it I am kindly reposting  his  solution from  http://groups.google.com/group/django-mptt-dev/browse_thread/thread/637c8b2fe816304d'], ['Example Node tree: ']], [['    from django.db.models import Q \n   import operator \n   def get_queryset_descendants(nodes, include_self=False): \n       if not nodes: \n           return Node.tree.none() \n       filters = [] \n       for n in nodes: \n           lft, rght = n.lft, n.rght \n           if include_self: \n               lft -=1 \n               rght += 1 \n           filters.append(Q(tree_id=n.tree_id, lft__gt=lft, rght__lt=rght)) \n       q = reduce(operator.or_, filters) \n       return Node.tree.filter(q) \n']], ['django-mptt get_descendants for a list of nodes'], 3, 1], [(5722767, 1), [['Example Node tree: '], ['Example usage:']], [[' T1 \n---T1.1 \n---T1.2 \nT2 \nT3 \n---T3.3 \n------T3.3.3 \n']], ['django-mptt get_descendants for a list of nodes'], 3, 0], [(5722767, 2), [['Example usage:'], ['-10000']], [['    >> some_nodes = [<Node: T1>, <Node: T2>, <Node: T3>]  # QureySet\n   >> print get_queryset_descendants(some_nodes)\n   [<Node: T1.1>, <Node: T1.2>, <Node: T3.3>, <Node: T3.3.3>] \n   >> print get_queryset_descendants(some_nodes, include_self=True)\n   [<Node: T1>, <Node: T1.1>, <Node: T1.2>, <Node: T2>, <Node: T3>, <Node: T3.3>, <Node: T3.3.3>] \n']], ['django-mptt get_descendants for a list of nodes'], 3, 0], [(5726827, 0), [['You can derive your own class from  dict  and override  __str__  method:'], ['Prints:']], [[' # -*- coding: utf-8 -*-\n\nclass MyDict(dict):\n    def __str__(self):\n        return "{"+", ".join(["%s: %s" % (key, self[key]) for key in self])+"}" \n\na = {0:"Velmi žluťoučký kůň"}\nb = MyDict({0:"Velmi žluťoučký kůň"})\nc = "Velmi žluťoučký kůň"\nprint(a)\nprint(b)\nprint(c)\n']], ['how to print a dict which has japanese word using python '], 2, 1], [(5726827, 1), [['Prints:'], ['The derived class will behave exactly the same as  dict , but it will print using the method you specify.']], [[" {0: 'Velmi \\xc5\\xbelu\\xc5\\xa5ou\\xc4\\x8dk\\xc3\\xbd k\\xc5\\xaf\\xc5\\x88'}\n{0: Velmi žluťoučký kůň}\nVelmi žluťoučký kůň\n"]], ['how to print a dict which has japanese word using python '], 2, 0], [(5743548, 0), [['As for finding file types in Python, there is already  mimetypes  module for that. '], ['In action:']], [[' import mimetypes\ntype, subtype = mimetypes.guess_type(filename_or_url)\n']], ['How to know the filetype through python'], 2, 1], [(5743548, 1), [['In action:'], ['-10000']], [[" >>> mimetypes.guess_type('http://upload.wikimedia.org/wikipedia/commons/9/9a/PNG_transparency_demonstration_2.png')\n('image/png', None)\n"]], ['How to know the filetype through python'], 2, 1], [(5761617, 0), [['For example, you have permissions for  Foo  objects, and permissions for  Bar  objects. These ACLs can be found by traversing the resource tree using the urls:'], ['Your resource tree then becomes a hierarchy of permissions, where at any point in the tree you can place an  __acl__  on the resource object:']], [[' /foos/{obj}\n/bars/{obj}\n']], ['Pyramid authorization for stored items'], 6, 0], [(5761617, 1), [['Your resource tree then becomes a hierarchy of permissions, where at any point in the tree you can place an  __acl__  on the resource object:'], ['You can represent this hierarchy in a resource tree:']], [[' root                       (Root)\n|- foos                    (FooContainer)\n|  `- {obj}                (Foo)\n`- bars                    (BarContainer)\n   `- {obj}                (Bar)\n']], ['Pyramid authorization for stored items'], 6, 0], [(5761617, 2), [['You can represent this hierarchy in a resource tree:'], ['With a setup like this, you can then map route patterns to your resource tree:']], [[" class Root(dict):\n    # this is the root factory, you can set an __acl__ here for all resources\n    __acl__ = [\n        (Allow, 'admin', ALL_PERMISSIONS),\n    ]\n    def __init__(self, request):\n        self.request = request\n        self['foos'] = FooContainer(self, 'foos')\n        self['bars'] = BarContainer(self, 'bars')\n\nclass FooContainer(object):\n    # set ACL here for *all* objects of type Foo\n    __acl__ = [\n    ]\n\n    def __init__(self, parent, name):\n        self.__parent__ = parent\n        self.__name__ = name\n\n    def __getitem__(self, key):\n        # get a database connection\n        s = DBSession()\n        obj = s.query(Foo).filter_by(id=key).scalar()\n        if obj is None:\n            raise KeyError\n        obj.__parent__ = self\n        obj.__name__ = key\n        return obj\n\nclass Foo(object):\n    # this __acl__ is computed dynamically based on the specific object\n    @property\n    def __acl__(self):\n        acls = [(Allow, 'u:%d' % o.id, 'view') for o in self.owners]\n        return acls\n\n    owners = relation('FooOwner')\n\nclass Bar(object):\n    # allow any authenticated user to view Bar objects\n    __acl__ = [\n        (Allow, Authenticated, 'view')\n    ]\n"]], ['Pyramid authorization for stored items'], 6, 0], [(5761617, 3), [['With a setup like this, you can then map route patterns to your resource tree:'], ['You will also need to map your route to a specific view:']], [[" config = Configurator()\nconfig.add_route('item_options', '/item/{item}/some_options',\n                 # tell pyramid where in the resource tree to go for this url\n                 traverse='/foos/{item}')\n"]], ['Pyramid authorization for stored items'], 6, 0], [(5761617, 4), [['You will also need to map your route to a specific view:'], ['Great, now we can define our view and use the loaded context object, knowing that if the view is executed, the user has the appropriate permissions!']], [[" config.add_view(route_name='item_options', view='.views.options_view',\n                permission='view', renderer='item_options.mako')\n"]], ['Pyramid authorization for stored items'], 6, 0], [(5761617, 5), [['Great, now we can define our view and use the loaded context object, knowing that if the view is executed, the user has the appropriate permissions!'], ["Using this setup, you are using the default  ACLAuthorizationPolicy , and you are providing row-level permissions for your objects with URL Dispatch. Note also, that because the objects set the  __parent__  property on the children, the policy will bubble up the lineage, inheriting permissions from the parents. This can be avoided by simply putting a  DENY_ALL  ACE in your ACL, or by writing a custom policy that does not use the context's lineage."]], [[" def options_view(request):\n    foo = request.context\n    return {\n        'foo': foo,\n    }\n"]], ['Pyramid authorization for stored items'], 6, 0], [(5771039, 0), [['If you write a function to return the directory structure as a nested list like this:'], ['then you could use  pprint.pformat  to create a passable string representation:']], [[" ['DIR1/',['fileA','fileB','DIR3/',['fileE','fileF']],'DIR2/',['fileC','fileD']]\n"]], ['Python: output for recursively printing out files and folders'], 3, 0], [(5771039, 2), [['yields'], ["Note: The above code assumes your file and directory names do not contain any of the characters  ,[]' ..."]], [[' DIR1/  \n    fileA  \n    fileB  \n    DIR3/  \n        fileE  \n        fileF    \nDIR2/  \n    fileC  \n    fileD   \n']], ['Python: output for recursively printing out files and folders'], 3, 0], [(5808970, 0), [['You can derive from  dict  to change the behaviour of the  get()  method:'], ['prints']], [[' class ClosestDict(dict):\n    def get(self, key):\n        key = min(self.iterkeys(), key=lambda x: abs(x - key))\n        return dict.get(self, key)\n\nd = ClosestDict({10: 3, 100: 2, 1000: 1})\nprint (d.get(20), d.get(60), d.get(200))\n']], ['Custom dictionary lookup in Python'], 2, 1], [(5808970, 1), [['prints'], ['Note that the complexity of  get()  no longer is O(1), but O(n).']], [[' (3, 2, 2)\n']], ['Custom dictionary lookup in Python'], 2, 0], [(5825921, 0), [['I don\'t think any "clever" trick beats the obvious approach, if it\'s well executed:'], ['Or, if the use of booleans for arithmetic irks you, ']], [[' sum(c1 == c2 for c1, c2 in itertools.izip(s1, s2))\n']], ['How do I count the number of identical characters in a string by position using python?'], 2, 1], [(5825921, 1), [['Or, if the use of booleans for arithmetic irks you, '], ['-10000']], [[' sum(1 for c1, c2 in itertools.izip(s1, s2) if c1 == c2)\n']], ['How do I count the number of identical characters in a string by position using python?'], 2, 1], [(5873969, 1), [["This will produce an array with an element per person. Each element will be an array of all the columns, and that will hold an array of all the rows. This way you can easily access the different years, or do things like concatenate the person's title:"], ['Will yield:']], [[' for person in db:\n    print "Name:", person[0][0]\n    print " ".join(s.strip() for s in person[0][1:])\n    print\n']], ['How can I scrape data from a text table using Python?'], 3, 0], [(5873969, 2), [['Will yield:'], ['-10000']], [[' Name: JOHN W. WOODS           \nChairman, President, & Chief Executive Officer of AmSouth & AmSouth Bank N.A.\n\nName: C. STANLEY ...\n']], ['How can I scrape data from a text table using Python?'], 3, 0], [(5901653, 0), [[''], ['\nEDIT: I just noticed this because I got a new upvote on it today (shame on you, upvoter!), but this is no longer correct.']], [[" import os\nappname = os.environ['APPLICATION_ID']\n"]], ['Name of Current App in Google App Engine (Python)'], 2, 0], [(5901653, 1), [['\nEDIT: I just noticed this because I got a new upvote on it today (shame on you, upvoter!), but this is no longer correct.'], ['should be used. The value in  os.environ  will include a "s~" prefix for applications using the HR datastore and, by default, "dev~" on the development server. ( os.environ  should also be avoided entirely on App Engine anyway, since when concurrency support is added with the Python 2.7 runtime, use of  os.environ  won\'t be threadsafe and will allow data to leak from one request to another, although obviously the application ID itself would be the same for multiple requests to the same application at the same time...)']], [[' from google.appengine.api.app_identity import get_application_id\nappname = get_application_id()\n']], ['Name of Current App in Google App Engine (Python)'], 2, 1], [(5909816, 0), [['According to D-Bus specification,  (b(oss))  is a struct of two elements, first  is a boolean, second is a struct of three elements: an object path and two strings. In python this maps to something like:'], ['but it can be used as if it was simply a python tuple like:']], [[' dbus.Struct((dbus.Boolean(a_boolean),\n             dbus.Struct((dbus.ObjectPath(s1),\n                          dbus.String(s2),\n                          dbus.String(s3)))),\n            signature="(b(oss))")\n']], ['How to represent dbus type b(oss) in python?'], 2, 1], [(5914627, 0), [['1st way , can be used if there are no issues to load the file into memory:'], ['2nd way :']], [[" def line_prepender(filename, line):\n    with open(filename, 'r+') as f:\n        content = f.read()\n        f.seek(0, 0)\n        f.write(line.rstrip('\\r\\n') + '\\n' + content)\n"]], ['Prepend line to beginning of a file'], 2, 1], [(5914627, 1), [['2nd way :'], ["I don't know how this method works under the hood and if it can be employed on big big file. The argument 1 passed to input is what allows to rewrite a line in place; the following lines must be moved forwards or backwards in order that the inplace operation takes place, but I don't know the mechanism"]], [[" def line_pre_adder(filename, line_to_prepend):\n    f = fileinput.input(filename, inplace=1)\n    for xline in f:\n        if f.isfirstline():\n            print line_to_prepend.rstrip('\\r\\n') + '\\n' + xline,\n        else:\n            print xline,\n"]], ['Prepend line to beginning of a file'], 2, 1], [(5930036, 0), [['Split with  os.extsep .'], ['If you want everything after the first dot:']], [[" >>> import os\n>>> 'filename.ext1.ext2'.split(os.extsep)\n['filename', 'ext1', 'ext2']\n"]], ['Separating file extensions using python os.path module'], 3, 1], [(5930036, 2), [['If you are using paths with directories that may contain dots:'], ['-10000']], [[' >>> def my_splitext(path):\n...     """splitext for paths with directories that may contain dots."""\n...     li = []\n...     path_without_extensions = os.path.join(os.path.dirname(path), os.path.basename(path).split(os.extsep)[0])\n...     extensions = os.path.basename(path).split(os.extsep)[1:]\n...     li.append(path_without_extensions)\n...     # li.append(extensions) if you want extensions in another list inside the list that is returned.\n...     li.extend(extensions)\n...     return li\n... \n>>> my_splitext(\'/path.with/dots./filename.ext1.ext2\')\n[\'/path.with/dots./filename\', \'ext1\', \'ext2\']\n']], ['Separating file extensions using python os.path module'], 3, 1], [(5947137, 0), [['Do you mean something like this?'], ['or shorter code (but not optimal):']], [[' accumulationList = []\nfor x in originalList:\n    accumulationList.extend(doSomething(x))\nreturn accumulationList\n']], ['How can I use a list comprehension to extend a list in python?'], 4, 1], [(5947137, 1), [['or shorter code (but not optimal):'], ['or the same:']], [[' return sum((doSomething(x) for x in originalList), [])\n']], ['How can I use a list comprehension to extend a list in python?'], 4, 1], [(5947137, 2), [['or the same:'], ['Thanks to @eyquem for the hint (if using Python 2.x):']], [[' return sum(map(doSomething, originalList), [])\n']], ['How can I use a list comprehension to extend a list in python?'], 4, 1], [(5947137, 3), [['Thanks to @eyquem for the hint (if using Python 2.x):'], ['-10000']], [[' import itertools as it\n\nreturn sum(it.imap(doSomething, originalList), [])\n']], ['How can I use a list comprehension to extend a list in python?'], 4, 1], [(5995478, 0), [['Python supports  tuple unpacking .'], ['It even works with other sequences.']], [[" def foo():\n  return 'bar', 42\n\na, b = foo()\n"]], ['Is it possible to assign two different returned values from a python function to two separate variables?'], 3, 1], [(5999241, 0), [['Try using  getheaders()  to get a  list  of the cookies:'], ['Then you can iterate over that  list  and grab whichever cookie you like.  str.startswith()  is your friend:']], [[" >>> msg = resp.info()\n>>> msg.getheaders('Set-Cookie')\n['PREF=ID=5975a5ee255f0949:FF=0:TM=1305336283:LM=1305336283:S=1vkES6eF4Yxd-_oM; expires=Mon, 13-May-2013 01:24:43 GMT; path=/; domain=.google.com.au', 'NID=46=lQVFZg6yKUsoWT529Hqp5gA8B_CKYd2epPIbANmw_J0UzeMt2BhuMF-gtmGsRhenUTeajKz2zILXd9xWpHWT8ZGvDcmNdkzaGX-L_-sKyY1w4e2l3DKd80JzSkt2Vp-H; expires=Sun, 13-Nov-2011 01:24:43 GMT; path=/; domain=.google.com.au; HttpOnly']\n"]], ['Using mimetools.Message in urllib2.urlopen'], 3, 1], [(5999241, 2), [['-10000'], ['-10000']], [['How a newbie can find the documentation in Python % python\nPython 2.7.1 (r271:86832, Jan 29 2011, 13:30:16) \n[GCC 4.2.1 (Apple Inc. build 5664)] on darwin\nType "help", "copyright", "credits" or "license" for more information.\n>>> import urllib2\n>>> req = urllib2.Request(\'http://www.google.com\')\n>>> resp = urllib2.urlopen(req)\n>>> help(resp.info())\n']], ['Using mimetools.Message in urllib2.urlopen'], 3, 0], [(6029912, 0), [["I think you are right --  plt.boxplot  ignores the mask if sent a masked array.\nSo it looks like you'll have to give  boxplot  some extra help by sending it only the values which are not masked. Since each row of the array may have a different number of unmasked values, you won't be able to use a numpy array. You'll have to form a Python sequence of vectors:"], ['For example:']], [[' z = [[y for y in row if y] for row in x.T]\n']], ['Boxplotting Masked Arrays'], 2, 0], [(6029912, 1), [['For example:'], ['']], [[' import matplotlib.pyplot as plt\nimport numpy as np\n\nfig=plt.figure()\n\nN=20\nM=10\n\nx = np.random.random((M,N))\nmask=np.random.random_integers(0,1,N*M).reshape((M,N))\nx = np.ma.array(x,mask=mask)\nax1=fig.add_subplot(2,1,1)\nax1.boxplot(x)\n\nz = [[y for y in row if y] for row in x.T]\nax2=fig.add_subplot(2,1,2)\nax2.boxplot(z)\nplt.show()\n']], ['Boxplotting Masked Arrays'], 2, 1], [(6046049, 0), [['A simple solution for small dicts is'], ['A more efficient, less readable version for larger dicts:']], [[' dict1 = {"a":0.6, "b":0.3, "c":0.9, "d":1.2, "e":0.2}\ndict2 = {"a":1.4, "b":7.7, "c":9.0, "d":2.5, "e":2.0}\nk1 = sorted(dict1, key=dict1.get)\nk2 = sorted(dict2, key=dict2.get)\ndiffs = dict((k, k2.index(k) - k1.index(k)) for k in dict1)\n']], ['python dictionary values sorting'], 2, 1], [(6046049, 1), [['A more efficient, less readable version for larger dicts:'], ['-10000']], [[' ranks1 = dict(map(reversed, enumerate(sorted(dict1, key=dict1.get))))\nranks2 = dict(map(reversed, enumerate(sorted(dict2, key=dict2.get))))\ndiffs = dict((k, ranks2[k] - ranks1[k]) for k in dict1)\n']], ['python dictionary values sorting'], 2, 1], [(6050187, 0), [['The subprocess  proc  inherits file descriptors opened in the parent process.\nSo you can use  os.open  to open passphrase.txt and obtain its associated file descriptor. You can then construct a command which uses that file descriptor:'], ['-10000']], [[" import subprocess\nimport shlex\nimport os\n\nfd=os.open('passphrase.txt',os.O_RDONLY)\ncmd='gpg --passphrase-fd {fd} -c'.format(fd=fd)\nwith open('filename.txt','r') as stdin_fh:\n    with open('filename.gpg','w') as stdout_fh:        \n        proc=subprocess.Popen(shlex.split(cmd),\n                              stdin=stdin_fh,\n                              stdout=stdout_fh)        \n        proc.communicate()\nos.close(fd)\n"]], ['Write to file descriptor 3 of a Python subprocess.Popen object'], 2, 1], [(6071784, 0), [['Pyparsing  makes it easy to write simple one-off parsers for stuff like this:'], ['If you want the original text for each parenthetical bit, then use the originalTextFor modifier:']], [[' >>> text = """show the (name) of the (person)\n...\n... calc the sqrt of (+ (* (2 4) 3))"""\n>>> import pyparsing\n>>> for match in pyparsing.nestedExpr(\'(\',\')\').searchString(text):\n...   print match[0]\n...\n[\'name\']\n[\'person\']\n[\'+\', [\'*\', [\'2\', \'4\'], \'3\']]\n']], ['Regex: Match brackets both greedy and non greedy'], 2, 1], [(6071784, 1), [['If you want the original text for each parenthetical bit, then use the originalTextFor modifier:'], ['-10000']], [[" >>> for match in pyparsing.originalTextFor(pyparsing.nestedExpr('(',')')).searchString(text):\n...   print match[0]\n...\n(name)\n(person)\n(+ (* (2 4) 3))\n"]], ['Regex: Match brackets both greedy and non greedy'], 2, 0], [(6102103, 0), [['If you find that you want to add validation hooks to all your models, you might consider creating a custom child class of  Document  something like:'], ['You can then define hooks for a given model class in a fairly natural way:']], [[' class MyDocument(mongoengine.Document):\n\n    def save(self, *args, **kwargs):\n        for hook in self._pre_save_hooks:\n            # the callable can raise an exception if\n            # it determines that it is inappropriate\n            # to save this instance; or it can modify\n            # the instance before it is saved\n            hook(self):\n\n        super(MyDocument, self).save(*args, **kwargs)\n']], ['Using MongoEngine Document class methods for custom validation and pre-save hooks'], 2, 0], [(6102103, 1), [['You can then define hooks for a given model class in a fairly natural way:'], ['-10000']], [[' class SomeModel(MyDocument):\n    # fields...\n\n    _pre_save_hooks = [\n        some_callable,\n        another_callable\n    ]\n']], ['Using MongoEngine Document class methods for custom validation and pre-save hooks'], 2, 0], [(6154424, 0), [['The idea is build the proper object model, map it to RDMBS and the question does not need to be asked. Also I expect that when using  Single Table Inheritance , the resulting DB schema would be almost identical to the current implementation (you can see the model when you run the script with the option  echo=True ):'], ['The code below is a complete working script that shows both the object model, its mapping to the database and the usage scenarios. As it is designed, the model is easily extendable with other types of questions/answers without any impact on existing classes. Basically you get less hacky and more flexible code simply because you have an object model which properly reflects your case. The code is below:']], [[' CREATE TABLE questions (\n    id INTEGER NOT NULL, \n    text VARCHAR NOT NULL, \n    type VARCHAR(10) NOT NULL, \n    PRIMARY KEY (id)\n)\n\nCREATE TABLE answer_options (\n    id INTEGER NOT NULL, \n    question_id INTEGER NOT NULL, \n    value INTEGER NOT NULL, \n    type VARCHAR(10) NOT NULL, \n    text VARCHAR, \n    input INTEGER, \n    PRIMARY KEY (id), \n    FOREIGN KEY(question_id) REFERENCES questions (id)\n)\n\nCREATE TABLE answers (\n    id INTEGER NOT NULL, \n    type VARCHAR(10) NOT NULL, \n    question_id INTEGER, \n    test_id INTEGER, \n    answer_option_id INTEGER, \n    answer_input INTEGER, \n    PRIMARY KEY (id), \n    FOREIGN KEY(question_id) REFERENCES questions (id), \n    FOREIGN KEY(answer_option_id) REFERENCES answer_options (id), \n    --FOREIGN KEY(test_id) REFERENCES tests (id)\n)\n']], ['Mixed content (float || unicode) for database column'], 2, 0], [(6154424, 1), [['The code below is a complete working script that shows both the object model, its mapping to the database and the usage scenarios. As it is designed, the model is easily extendable with other types of questions/answers without any impact on existing classes. Basically you get less hacky and more flexible code simply because you have an object model which properly reflects your case. The code is below:'], ['I hope that this version of the code answers all the questions asked in the comments.']], [[' from sqlalchemy import create_engine, Column, Integer, SmallInteger, String, ForeignKey, Table, Index\nfrom sqlalchemy.orm import relationship, scoped_session, sessionmaker\nfrom sqlalchemy.ext.declarative import declarative_base\n\n# Configure test data SA\nengine = create_engine(\'sqlite:///:memory:\', echo=True)\nsession = scoped_session(sessionmaker(bind=engine))\nBase = declarative_base()\nBase.query = session.query_property()\n\nclass _BaseMixin(object):\n    """ Just a helper mixin class to set properties on object creation.  \n    Also provides a convenient default __repr__() function, but be aware that \n    also relationships are printed, which might result in loading relations.\n    """\n    def __init__(self, **kwargs):\n        for k,v in kwargs.items():\n            setattr(self, k, v)\n\n    def __repr__(self):\n        return "<%s(%s)>" % (self.__class__.__name__, \n            \', \'.join(\'%s=%r\' % (k, self.__dict__[k]) \n                for k in sorted(self.__dict__) if \'_sa_\' != k[:4] and \'_backref_\' != k[:9])\n            )\n\n### AnswerOption hierarchy\nclass AnswerOption(Base, _BaseMixin):\n    """ Possible answer options (choice or any other configuration).  """\n    __tablename__ = u\'answer_options\'\n    id = Column(Integer, primary_key=True)\n    question_id = Column(Integer, ForeignKey(\'questions.id\'), nullable=False)\n    value = Column(Integer, nullable=False)\n    type = Column(String(10), nullable=False)\n    __mapper_args__ = {\'polymorphic_on\': type}\n\nclass AnswerOptionChoice(AnswerOption):\n    """ A possible answer choice for the question.  """\n    text = Column(String, nullable=True) # when mapped to single-table, must be NULL in the DB\n    __mapper_args__ = {\'polymorphic_identity\': \'choice\'}\n\nclass AnswerOptionInput(AnswerOption):\n    """ A configuration entry for the input-type of questions.  """\n    input = Column(Integer, nullable=True) # when mapped to single-table, must be NULL in the DB\n    __mapper_args__ = {\'polymorphic_identity\': \'input\'}\n\n### Question hierarchy\nclass Question(Base, _BaseMixin):\n    """ Base class for all types of questions.  """\n    __tablename__ = u\'questions\'\n    id = Column(Integer, primary_key=True)\n    text = Column(String, nullable=False)\n    type = Column(String(10), nullable=False)\n    answer_options = relationship(AnswerOption, backref=\'question\')\n    __mapper_args__ = {\'polymorphic_on\': type}\n\n    def get_answer_value(self, answer):\n        """ function to get a value of the answer to the question.  """\n        raise Exception(\'must be implemented in a subclass\')\n\nclass QuestionChoice(Question):\n    """ Single-choice question.  """\n    __mapper_args__ = {\'polymorphic_identity\': \'choice\'}\n\n    def get_answer_value(self, answer):\n        assert isinstance(answer, AnswerChoice)\n        assert answer.answer_option in self.answer_options, "Incorrect choice"\n        return answer.answer_option.value\n\nclass QuestionInput(Question):\n    """ Input type question.  """\n    __mapper_args__ = {\'polymorphic_identity\': \'input\'}\n\n    def get_answer_value(self, answer):\n        assert isinstance(answer, AnswerInput)\n        value_list = sorted([(_i.input, _i.value) for _i in self.answer_options])\n        if not value_list:\n            raise Exception("no input is specified for the question {0}".format(self))\n        if answer.answer_input <= value_list[0][0]:\n            return value_list[0][1]\n        elif answer.answer_input >= value_list[-1][0]:\n            return value_list[-1][1]\n        else: # interpolate in the range:\n            for _pos in range(len(value_list)-1):\n                if answer.answer_input == value_list[_pos+1][0]:\n                    return value_list[_pos+1][1]\n                elif answer.answer_input < value_list[_pos+1][0]:\n                    # interpolate between (_pos, _pos+1)\n                    assert (value_list[_pos][0] != value_list[_pos+1][0])\n                    return value_list[_pos][1] + (value_list[_pos+1][1] - value_list[_pos][1]) * (answer.answer_input - value_list[_pos][0]) / (value_list[_pos+1][0] - value_list[_pos][0])\n        assert False, "should never reach here"\n\n### Answer hierarchy\nclass Answer(Base, _BaseMixin):\n    """ Represents an answer to the question.  """\n    __tablename__ = u\'answers\'\n    id = Column(Integer, primary_key=True)\n    type = Column(String(10), nullable=False)\n    question_id = Column(Integer, ForeignKey(\'questions.id\'), nullable=True) # when mapped to single-table, must be NULL in the DB\n    question = relationship(Question)\n    test_id = Column(Integer, ForeignKey(\'tests.id\'), nullable=True) # @todo: decide if allow answers without a Test\n    __mapper_args__ = {\'polymorphic_on\': type}\n\n    def get_value(self):\n        return self.question.get_answer_value(self)\n\nclass AnswerChoice(Answer):\n    """ Represents an answer to the *Choice* question.  """\n    __mapper_args__ = {\'polymorphic_identity\': \'choice\'}\n    answer_option_id = Column(Integer, ForeignKey(\'answer_options.id\'), nullable=True) \n    answer_option = relationship(AnswerOption, single_parent=True)\n\nclass AnswerInput(Answer):\n    """ Represents an answer to the *Choice* question.  """\n    __mapper_args__ = {\'polymorphic_identity\': \'input\'}\n    answer_input = Column(Integer, nullable=True) # when mapped to single-table, must be NULL in the DB\n\n### other classes (Questionnaire, Test) and helper tables\nassociation_table = Table(\'questionnaire_question\', Base.metadata,\n    Column(\'id\', Integer, primary_key=True),\n    Column(\'questionnaire_id\', Integer, ForeignKey(\'questions.id\')),\n    Column(\'question_id\', Integer, ForeignKey(\'questionnaires.id\'))\n)\n_idx = Index(\'questionnaire_question_u_nci\', \n            association_table.c.questionnaire_id, \n            association_table.c.question_id, \n            unique=True)\n\nclass Questionnaire(Base, _BaseMixin):\n    """ Questionnaire is a compilation of questions.  """\n    __tablename__ = u\'questionnaires\'\n    id = Column(Integer, primary_key=True)\n    name = Column(String, nullable=False)\n    # @note: could use relationship with order or even add question number\n    questions = relationship(Question, secondary=association_table)\n\nclass Test(Base, _BaseMixin):\n    """ Test is a \'test\' - set of answers for a given questionnaire. """\n    __tablename__ = u\'tests\'\n    id = Column(Integer, primary_key=True)\n    # @todo: add user name or reference\n    questionnaire_id = Column(Integer, ForeignKey(\'questionnaires.id\'), nullable=False)\n    questionnaire = relationship(Questionnaire, single_parent=True)\n    answers = relationship(Answer, backref=\'test\')\n    def total_points(self):\n        return sum(ans.get_value() for ans in self.answers)\n\n# -- end of model definition --\n\nBase.metadata.create_all(engine)\n\n# -- insert test data --\nprint \'-\' * 20 + \' Insert TEST DATA ...\'\nq1 =  QuestionChoice(text="What is your fav pet?")\nq1c1 = AnswerOptionChoice(text="cat", value=1, question=q1)\nq1c2 = AnswerOptionChoice(text="dog", value=2, question=q1)\nq1c3 = AnswerOptionChoice(text="caiman", value=3)\nq1.answer_options.append(q1c3)\na1 = AnswerChoice(question=q1, answer_option=q1c2)\nassert a1.get_value() == 2\nsession.add(a1)\nsession.flush()\n\nq2 =  QuestionInput(text="How many liters of beer do you drink a day?")\nq2i1 = AnswerOptionInput(input=0, value=0, question=q2)\nq2i2 = AnswerOptionInput(input=1, value=1, question=q2)\nq2i3 = AnswerOptionInput(input=3, value=5)\nq2.answer_options.append(q2i3)\n\n# test interpolation routine\n_test_ip = ((-100, 0),\n            (0, 0),\n            (0.5, 0.5),\n            (1, 1),\n            (2, 3),\n            (3, 5),\n            (100, 5)\n)\na2 = AnswerInput(question=q2, answer_input=None)\nfor _inp, _exp in _test_ip:\n    a2.answer_input = _inp\n    _res = a2.get_value()\n    assert _res == _exp, "{0}: {1} != {2}".format(_inp, _res, _exp)\na2.answer_input = 2\nsession.add(a2)\nsession.flush()\n\n# create a Questionnaire and a Test\nqn = Questionnaire(name=\'test questionnaire\')\nqn.questions.append(q1)\nqn.questions.append(q2)\nsession.add(qn)\nte = Test(questionnaire=qn)\nte.answers.append(a1)\nte.answers.append(a2)\nassert te.total_points() == 5\nsession.add(te)\nsession.flush()\n\n# -- other tests --\nprint \'-\' * 20 + \' TEST QUERIES ...\'\nsession.expunge_all() # clear the session cache\na1 = session.query(Answer).get(1)\nassert a1.get_value() == 2 # @note: will load all dependant objects (question and answer_options) automatically to compute the value\na2 = session.query(Answer).get(2)\nassert a2.get_value() == 3 # @note: will load all dependant objects (question and answer_options) automatically to compute the value\nte = session.query(Test).get(1)\nassert te.total_points() == 5\n']], ['Mixed content (float || unicode) for database column'], 2, 0], [(6165277, 1), [['You can convert it back to list if you have to:'], ['Otherwise you can iterate over it just like you iterate over a list:']], [[' diff_list = list(diff)\n']], ['compare list elements'], 4, 0], [(6205592, 0), [['Like this.'], ['etc.']], [[' class Rule( object ):\n    def __init__( self, text ):\n        self.text= text\n    def test( self, A, B, C, D, E, F, G ):\n        return eval( self.text )\n\nr1= Rule( "A==B" )\nr2= Rule( "A==B and B==C" )\nr3= Rule( "A in {listname!s}".format( listname=someList ) )\n']], ['How to write small DSL parser with operator module in python'], 3, 1], [(6205592, 1), [['etc.'], ['-10000']], [[' >>> r1.test( 89,  92,  18,  7,   90,  35, 60 )\nFalse\n']], ['How to write small DSL parser with operator module in python'], 3, 0], [(6205592, 2), [['-10000'], ["There's a trick to this.  The trick is to write the Python code; and then enclose the code in quotes.   Any  Python code is legal.  "]], [[' r4= Rule( "re.match( r\'[2-5][0-2]\', str(A) )" )\nr5= Rule( "myfoo(A) > 100" )\nr6= Rule( "A in myfoo(B)" )\n']], ['How to write small DSL parser with operator module in python'], 3, 0], [(6220490, 0), [['Here is a self-contained example with 3 "files", each containing 3 lines. It uses  StringIO  for convenience instead of actual files:'], ['The output is:']], [[' #!/usr/bin/env python\n# coding: utf-8\n\nfrom StringIO import StringIO\n\n# for this example, each "file" has 3 lines instead of 100000\nf1 = \'1\\t10\\n2\\t11\\n3\\t12\'\nf2 = \'1\\t13\\n2\\t14\\n3\\t15\'\nf3 = \'1\\t16\\n2\\t17\\n3\\t18\'\n\nfiles = [f1, f2, f3]\n\n# data is a list of dictionaries mapping population to average age\n# i.e. data[0][10000] contains the average age in location 0 (files[0]) with\n# population of 10000.\ndata = []\n\nfor i,filename in enumerate(files):\n    f = StringIO(filename)\n    # f = open(filename, \'r\')\n    data.append(dict())\n\n    for line in f:\n        population, average_age = (int(s) for s in line.split(\'\\t\'))\n        data[i][population] = average_age\n\nprint data\n\n# gather custom statistics on the data\n\n# i.e. here\'s how to calculate the average age across all locations where\n# population is 2:\nnum_locations = len(data)\npop2_avg = sum((data[loc][2] for loc in xrange(num_locations)))/num_locations\nprint \'Average age with population 2 is\', pop2_avg, \'years old\'\n']], ['Reading files in parallel in python'], 2, 1], [(6220490, 1), [['The output is:'], ['-10000']], [[' [{1: 10, 2: 11, 3: 12}, {1: 13, 2: 14, 3: 15}, {1: 16, 2: 17, 3: 18}]\nAverage age with population 2 is 14 years old\n']], ['Reading files in parallel in python'], 2, 0], [(6235146, 0), [['Django actually already includes a login_required decorator that makes handling user authentication trivial. Just include the following at the top of your view.py page:'], ['and then add ']], [[' from django.contrib.auth.decorators import login_required\n']], ['Converting separate functions into class-based'], 3, 0], [(6235146, 1), [['and then add '], ["You can use that user object to get the profile variable by extending the user module. Set AUTH_PROFILE_MODULE = 'myapp.UserProfile' in your Settings, which will allow you to access a users profile as follows: "]], [[' @login_required \n']], ['Converting separate functions into class-based'], 3, 0], [(6235146, 2), [["You can use that user object to get the profile variable by extending the user module. Set AUTH_PROFILE_MODULE = 'myapp.UserProfile' in your Settings, which will allow you to access a users profile as follows: "], ['More about that here:\n http://www.b-list.org/weblog/2006/jun/06/django-tips-extending-user-model/']], [[' user.get_profile().location. \n']], ['Converting separate functions into class-based'], 3, 0], [(6237378, 0), [['You could use  INSERT OR REPLACE  to update rows with a unique constraint,\nor  INSERT OR IGNORE  to ignore inserts which conflict with a unique constraint:'], ["These sqlite commands are probably faster than writing Python code to do the same thing, though to test this you could use Python's  timeit  module to test the speed of various implementations. For example, you could run"]], [[" import sqlite3\n\ndef insert_or_replace():\n    # https://sqlite.org/lang_insert.html\n    connection=sqlite3.connect(':memory:')\n    cursor=connection.cursor()\n    cursor.execute('CREATE TABLE foo (bar INTEGER UNIQUE, baz INTEGER)')\n    cursor.execute('INSERT INTO foo (bar,baz) VALUES (?, ?)',(1,2))\n    cursor.execute('INSERT OR REPLACE INTO foo (bar,baz) VALUES (?, ?)',(1,3))\n    cursor.execute('SELECT * from foo')\n    data=cursor.fetchall()\n    print(data)\n    # [(1, 3)]\n\n\ndef on_conflict():\n    # https://sqlite.org/lang_insert.html\n    connection=sqlite3.connect(':memory:')\n    cursor=connection.cursor()\n    cursor.execute('CREATE TABLE foo (bar INTEGER UNIQUE, baz INTEGER)')\n    cursor.execute('INSERT INTO foo (bar,baz) VALUES (?, ?)',(1,2))\n    cursor.execute('INSERT OR IGNORE INTO foo (bar,baz) VALUES (?, ?)',(1,3))\n    cursor.execute('SELECT * from foo')\n    data=cursor.fetchall()\n    print(data)\n    # [(1, 2)]    \n\ninsert_or_replace()\non_conflict()\n"]], ['insert into sqlite table with unique column'], 4, 1], [(6237378, 1), [["These sqlite commands are probably faster than writing Python code to do the same thing, though to test this you could use Python's  timeit  module to test the speed of various implementations. For example, you could run"], ['versus']], [[" python -mtimeit -s'import test' 'test.insert_or_replace()'\n"]], ['insert into sqlite table with unique column'], 4, 0], [(6237378, 2), [['versus'], ['versus']], [[" python -mtimeit -s'import test' 'test.filter_nonunique_rows_in_Python()'\n"]], ['insert into sqlite table with unique column'], 4, 0], [(6237378, 3), [['versus'], ['-10000']], [[" python -mtimeit -s'import test' 'test.insert_with_try_catch_blocks()'\n"]], ['insert into sqlite table with unique column'], 4, 0], [(6253617, 0), [['This actually seems pretty easy. Process the file into a data structure, then export it into a csv.'], ['-10000']], [[' school = None\nheaders = None\ndata = {}\nfor line in text.splitlines():\n    if line.startswith("school id"):\n        school = line.split(\'=\')[1].strip()\n        headers = None\n        continue\n    if school is not None and headers is None:\n        headers = line.split(\'|\')\n        continue\n\n    if school is not None and headers is not None and line:\n        if not school in data:\n            data[school] = []\n        datum = dict(zip(headers, line.split(\'|\')))\n        data[school].append(datum)    \n']], ['How can I store data to a data dictionary in Python when headings are in mixed up order'], 2, 1], [(6253617, 1), [['-10000'], ['-10000']], [[" In [29]: data\nOut[29]: \n{'273533123': [{'age': '27',\n                'degree': 'MBA',\n                'name': 'John B. Black',\n                'race': 'hispanic',\n                'year': '2003'},\n               {'age': '28',\n                'degree': 'PhD',\n                'name': 'Steven Smith',\n                'race': 'black',\n                'year': '2005'},\n               {'age': '25',\n                'degree': 'MBA',\n                'name': 'Jacob Waters',\n                'race': 'hispanic',\n                'year': '2003'}],\n '28392': [{'age': '27',\n            'degree': 'PhD',\n            'name': 'Susan A. Smith',\n            'race': 'white',\n            'year': '2007'},\n           {'age': '26',\n            'degree': 'PhD',\n            'name': 'Fred Collins',\n            'race': 'hispanic',\n            'year': '2006'},\n           {'age': '28',\n            'degree': 'MBA',\n            'name': 'Amber Real',\n            'race': 'white',\n            'year': '2007'},\n           {'age': '27',\n            'degree': 'PhD',\n            'name': 'Mike Lee',\n            'race': 'white',\n            'year': '2003'}],\n '3452332': [{'age': '27',\n              'degree': 'Bachelors',\n              'name': 'Peter Hintze',\n              'race': 'white',\n              'year': '2002'},\n             {'age': '25',\n              'degree': 'MBA',\n              'name': 'Ann Graden',\n              'race': 'black',\n              'year': '2004'},\n             {'age': '28',\n              'degree': 'PhD',\n              'name': 'Bryan Stewart',\n              'race': 'white',\n              'year': '2004'}]}    \n"]], ['How can I store data to a data dictionary in Python when headings are in mixed up order'], 2, 0], [(6290105, 0), [['You can create a generator that will traverse the tree for you for (1).'], ['-10000']], [[' def traverse(o, tree_types=(list, tuple)):\n    if isinstance(o, tree_types):\n        for value in o:\n            for subvalue in traverse(value):\n                yield subvalue\n    else:\n        yield o\n\ndata = [(1,1,(1,1,(1,"1"))),(1,1,1),(1,),1,(1,(1,("1",)))]\nprint list(traverse(data))\n# prints [1, 1, 1, 1, 1, \'1\', 1, 1, 1, 1, 1, 1, 1, \'1\']\n\nfor value in traverse(data):\n    print repr(value)\n# prints\n# 1\n# 1\n# 1\n# 1\n# 1\n# \'1\'\n# 1\n# 1\n# 1\n# 1\n# 1\n# 1\n# 1\n# \'1\'\n']], ['Traversing a "list" tree and get the type(item) list with same structure in python?'], 2, 0], [(6315244, 1), [['What I assume you are after is this:'], ['In this case  people  is the master list and you can control when a  Person  gets added and removed from the list (its a dictionary).']], [[" people = {}\npeople['john'] = Person('john')\n\ndef removePerson(personName):\n    del people[personName]\n\nremovePerson('john')\n"]], ['How to give object away to python garbage collection?'], 2, 0], [(6316726, 0), [['You can find the intermediate table where Elixir has hidden it away, but note that it uses fully qualified column names (such as  __package_path_with_underscores__course_id ). To avoid this, define your ManyToMany using e.g.'], ['and then you can access the intermediate table using']], [[" class Course(Entity):\n    ...\n    assistants = ManyToMany('Professor', inverse='courses_assisted',\n                            local_colname='course_id', remote_colname='prof_id',\n                            ondelete='cascade')\n"]], ["SQLAlchemy/Elixir - querying to check entity's membership in a many-to-many relationship list"], 4, 0], [(6316726, 1), [['and then you can access the intermediate table using'], ["Update:  Of course you can do this at a higher level, but not in a single query, because SQLAlchemy doesn't yet support  in_  for relationships. For example, with two queries:"]], [[" rel = Course._descriptor.find_relationship('assistants')\nassert rel\ntable = rel.table\n"]], ["SQLAlchemy/Elixir - querying to check entity's membership in a many-to-many relationship list"], 4, 0], [(6316726, 2), [["Update:  Of course you can do this at a higher level, but not in a single query, because SQLAlchemy doesn't yet support  in_  for relationships. For example, with two queries:"], ['Or, alternatively:']], [[" >>> mit_courses = set(Course.query.join(\n... University).filter(University.name == 'MIT'))\n>>> [p.name for p in Professor.query if set(\n... p.courses_assisted).intersection(mit_courses)]\n"]], ["SQLAlchemy/Elixir - querying to check entity's membership in a many-to-many relationship list"], 4, 0], [(6316726, 3), [['Or, alternatively:'], ['The first step creates a list of lists of assistants. The second step flattens the list of lists and removes duplicates through making a set.']], [[" >>> plist = [c.assistants for c in Course.query.join(\n... University).filter(University.name == 'MIT')]\n>>> [p.name for p in set(itertools.chain(*plist))]\n"]], ["SQLAlchemy/Elixir - querying to check entity's membership in a many-to-many relationship list"], 4, 0], [(6367051, 0), [["A typical solution to this problem is to define a new class that wraps an existing instance of a  file , which automatically counts the numbers. Something like this (just off the top of my head, I haven't tested this):"], ['Use it like this:']], [[" class FileLineWrapper(object):\n    def __init__(self, f):\n        self.f = f\n        self.line = 0\n    def close(self):\n        return self.f.close()\n    def readline(self):\n        self.line += 1\n        return self.f.readline()\n    # to allow using in 'with' statements \n    def __enter__(self):\n        return self\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()\n"]], ['Is there an easy way to tell which line number a file pointer is on?'], 2, 1], [(6367051, 1), [['Use it like this:'], ['It looks like the standard module  fileinput  does much the same thing (and some other things as well); you could use that instead if you like.']], [[' f = FileLineWrapper(open("myfile.txt", "r"))\nf.readline()\nprint(f.line)\n']], ['Is there an easy way to tell which line number a file pointer is on?'], 2, 0], [(6389577, 0), [['-10000'], ['Or all on one line:']], [[' C = zip(A, B)\nD = sorted(C, key=lambda x: x[1])\nA2, B2 = zip(*D)\n']], ['Merge two arrays into a matrix in python and sort'], 2, 1], [(6389577, 1), [['Or all on one line:'], ['-10000']], [[' A2, B2 = zip(*sorted(zip(A,B), key=lambda x: x[1]))\n']], ['Merge two arrays into a matrix in python and sort'], 2, 1], [(6406368, 0), [['use labelpad parameter:'], ['or set it after:']], [[' pl.xlabel("...", labelpad=20)\n']], ['Matplotlib - Move X-Axis label downwards, but not X-Axis Ticks'], 2, 1], [(6406368, 1), [['or set it after:'], ['-10000']], [[' ax.xaxis.labelpad = 20\n']], ['Matplotlib - Move X-Axis label downwards, but not X-Axis Ticks'], 2, 1], [(6444825, 0), [['You should be able, just in the template for your "outer" cms page (ie, the page within which you want to display the contents of another cms page), to get access to the current page like this:'], ["This is by virtue of the cms page middleware. So taking that a step further, you should be able to access the page's placeholders like this:"]], [[' {{ request.current_page }}\n']], ['render cms page within another page'], 2, 0], [(6444825, 1), [["This is by virtue of the cms page middleware. So taking that a step further, you should be able to access the page's placeholders like this:"], ['That\'s one way you could go about rendering a page\'s placeholders "inside" another page.']], [[' {% for placeholder in request.current_page.placeholders %}\n    {{ placeholder.render }}\n{% endfor %}\n']], ['render cms page within another page'], 2, 1], [(6493681, 0), [['Try something like this:'], ['This will give you a string that you could use to send to MySql as a valid  IN  clause:']], [[" '(%s)' % ','.join(map(str,x))\n"]], ['Use of SQL - IN in python'], 2, 1], [(6493681, 1), [['This will give you a string that you could use to send to MySql as a valid  IN  clause:'], ['-10000']], [[' (1,2,3,4,5,6)\n']], ['Use of SQL - IN in python'], 2, 0], [(6540412, 1), [['-10000'], ['-10000']], [[' @classmethod\ndef main(cls):\n    "Create an application containing a single TrimDirView widget."\n    tkinter.NoDefaultRoot()\n    root = cls.create_application_root()\n    cls.attach_window_icon(root, ICON)\n    view = cls.setup_class_instance(root)\n    cls.main_loop(root)\n']], ['Updating a TKinter GUI from a multiprocessing calculation'], 3, 0], [(6540412, 2), [['-10000'], ['-10000']], [[' @staticmethod\ndef main_loop(root):\n    "Process all GUI events according to tkinter\'s settings."\n    target = time.clock()\n    while True:\n        try:\n            root.update()\n        except tkinter.TclError:\n            break\n        target += tkinter._tkinter.getbusywaitinterval() / 1000\n        time.sleep(max(target - time.clock(), 0))\n']], ['Updating a TKinter GUI from a multiprocessing calculation'], 3, 0], [(6566642, 0), [["I would personally just  os.chdir  into the script's directory whenever I execute it. It is just:"], ["However if you did want to refactor this thing into a library, you are in essence wanting a function that is aware of its caller's state. You thus have to make it  psd(__file__, blah) . If you just wanted to write  psd(blah) , you'd have to do cpython-specific tricks with stack frames:"]], [[' import os\nos.chdir(os.path.split(__file__)[0])\n']], ['(python) prepend script dir to a path'], 2, 1], [(6566642, 1), [["However if you did want to refactor this thing into a library, you are in essence wanting a function that is aware of its caller's state. You thus have to make it  psd(__file__, blah) . If you just wanted to write  psd(blah) , you'd have to do cpython-specific tricks with stack frames:"], ['-10000']], [[" import inspect\n\ndef getCallerModule():\n    # gets globals of module called from, and prints out __file__ global\n    print(inspect.currentframe().f_back.f_globals['__file__'])\n"]], ['(python) prepend script dir to a path'], 2, 1], [(6611563, 0), [['SQLAlchemy does not provide an interface to  ON DUPLICATE KEY UPDATE  or  MERGE  or any other similar functionality in its ORM layer. Nevertheless, it has the  session.merge()  function that can replicate the functionality  only if the key in question is a primary key .'], ["But what if you want  ON DUPLICATE KEY UPDATE  functionality with a non-primary key (for example, another unique key)? Unfortunately, SQLAlchemy doesn't have any such function. Instead, you have to create something that resembles Django's  get_or_create() .  Another StackOverflow answer covers it , and I'll just paste a modified, working version of it here for convenience."]], [[' from sqlalchemy.ext.compiler import compiles\nfrom sqlalchemy.sql.expression import Insert\n\n@compiles(Insert)\ndef append_string(insert, compiler, **kw):\n    s = compiler.visit_insert(insert, **kw)\n    if \'append_string\' in insert.kwargs:\n        return s + " " + insert.kwargs[\'append_string\']\n    return s\n\n\nmy_connection.execute(my_table.insert(append_string = \'ON DUPLICATE KEY UPDATE foo=foo\'), my_values)\n']], ['SQLAlchemy ON DUPLICATE KEY UPDATE'], 2, 1], [(6611563, 1), [["But what if you want  ON DUPLICATE KEY UPDATE  functionality with a non-primary key (for example, another unique key)? Unfortunately, SQLAlchemy doesn't have any such function. Instead, you have to create something that resembles Django's  get_or_create() .  Another StackOverflow answer covers it , and I'll just paste a modified, working version of it here for convenience."], ['-10000']], [[' def get_or_create(session, model, defaults=None, **kwargs):\n    instance = session.query(model).filter_by(**kwargs).first()\n    if instance:\n        return instance\n    else:\n        params = dict((k, v) for k, v in kwargs.iteritems() if not isinstance(v, ClauseElement))\n        if defaults:\n            params.update(defaults)\n        instance = model(**params)\n        return instance\n']], ['SQLAlchemy ON DUPLICATE KEY UPDATE'], 2, 1], [(6624152, 0), [["You need to specify re.DOTALL to make the dot able to match even with '\\n'"], ['result']], [[' def test():\n    s = r"""    \n\nFOO=a \\    \n\n  b\n\n  """\n    import re\n    print repr(s)\n    print \'---------------------\'\n    regex = re.compile(r\'^FOO=(.+)(?<!\\\\)$\', re.M)\n    print regex.search(s).group(1)\n    print \'---------------------\'\n    regex = re.compile(r\'^FOO=(.+)(?<!\\\\)$\', re.M|re.DOTALL)\n    print regex.search(s).group(1)\n\ntest()\n']], ['matching a multiline make-line variable assignment with a python regexp'], 2, 1], [(6624152, 1), [['result'], ['-10000']], [[" '    \\n\\nFOO=a \\\\    \\n\\n  b\\n\\n  '\n---------------------\na \\    \n-----\n'a \\\\    '\n---------------------\na \\    \n\n  b\n\n\n-----\n'a \\\\    \\n\\n  b\\n\\n  '\n"]], ['matching a multiline make-line variable assignment with a python regexp'], 2, 0], [(6669828, 0), [['For mutual exclusivity, you have to do the check yourself, for example:'], ['Since the example options here are boolean, you could replace the if line above with:']], [[' parser.add_option("-e", help="e desc", dest="e_opt", action="store_true")\nparser.add_option("-d", help="d desc", dest="d_opt", action="store_true")\n(opts, args) = parser.parse_args()\nif (parser.has_option("-e") and parser.has_option("-d")):\n    print "Error!  Found both d and e options.  You can\'t do that!"\n    sys.exit(1)\n']], ['optparse(): Input validation'], 4, 0], [(6669828, 1), [['Since the example options here are boolean, you could replace the if line above with:'], ["I've never figured out a way to have an optparse option for which a value is, well, optional.  AFAIK, you have to set the option up to have values or to not have values.  The closest I've come is to specify a  default value  for an option which must have a value.  Then that entry doesn't have to be specified on the command line.  Sample code :"]], [[' if (opts.e_opt and opts.d_opt):\n']], ['optparse(): Input validation'], 4, 0], [(6687619, 0), [['-10000'], ['it is probably slightly more efficient to do it like this']], [[' seq="abcdefessdfekgheithrfkopeifhghtryrhfbcvdfersdwtiyuyrterdhcbgjherytyekdnfiwytowihfiwoeirehjiwoqpft"\n>>> n = 4\n>>> overlap = 5\n>>> division = len(seq)/n\n>>> [seq[i*division:(i+1)*division+overlap] for i in range(n)]\n[\'abcdefessdfekgheithrfkopeifhg\', \'eifhghtryrhfbcvdfersdwtiyuyrt\', \'yuyrterdhcbgjherytyekdnfiwyto\', \'iwytowihfiwoeirehjiwoqpft\']\n']], ['Print out a large list from file into multiple sublists with overlapping sequences in python'], 2, 1], [(6687619, 1), [['it is probably slightly more efficient to do it like this'], ['-10000']], [[" >>> [seq[i:i+division+overlap] for i in range(0,n*division,division)]\n['abcdefessdfekgheithrfkopeifhg', 'eifhghtryrhfbcvdfersdwtiyuyrt', 'yuyrterdhcbgjherytyekdnfiwyto', 'iwytowihfiwoeirehjiwoqpft']\n"]], ['Print out a large list from file into multiple sublists with overlapping sequences in python'], 2, 1], [(6727491, 0), [['This is a start:'], ["If you want to do this without wrapping  obj  in some way, it's going to get messy. Here's an option:"]], [[" class MagicWrapper(object):\n    def __init__(self, wrapped):\n        self._wrapped = wrapped\n\n    def __getattr__(self, attr):\n        return getattr(self._wrapped, attr)\n\n    def __setattr__(self, attr, val):\n        if attr == '_wrapped':\n            super(MagicWrapper, self).__setattr__('_wrapped', val)\n        else:\n            setattr(self._wrapped, 'old_' + attr, getattr(self._wrapped, attr))\n            setattr(self._wrapped, attr, val)\n\n\nclass MyObject(object):\n    def __init__(self):\n        self.attr_one = None\n        self.attr_two = 1\n\nobj = MyObject()\nobj = MagicWrapper(obj)\nobj.attr_one = 'new value'\nobj.attr_two = 2\n\nprint obj.old_attr_one\nprint obj.attr_one\nprint obj.old_attr_two\nprint obj.attr_two\n"]], ['Track changes of atributes in instance. Python'], 2, 1], [(6727491, 1), [["If you want to do this without wrapping  obj  in some way, it's going to get messy. Here's an option:"], ['Note that this is extremely invasive if you\'re using it on externally provided objects. It globally modifies the  class  of the object you\'re applying the magic to, not just that one instance. This is because like several other special methods,  __setattr__  is not looked up in the instance\'s attribute dictionary; the lookup skips straight to the class, so there\'s no way to just override  __setattr__  on the instance. I would characterise this sort of code as a bizarre hack if I encountered it in the wild (it\'s "nifty cleverness" if I write it myself, of course ;) ).']], [[" def add_old_setattr_to_class(cls):\n    def __setattr__(self, attr, val):\n        super_setattr = super(self.__class__, self).__setattr__\n        if attr.startswith('old_'):\n            super_setattr(attr, val)\n        else:\n            super_setattr('old_' + attr, getattr(self, attr))\n            super_setattr(attr, val)\n    cls.__setattr__ = __setattr__\n\n\nclass MyObject(object):\n    def __init__(self):\n        self.attr_one = None\n        self.attr_two = 1\n\nobj = MyObject()\nadd_old_setattr_to_class(obj.__class__)\nobj.attr_one = 'new value'\nobj.attr_two = 2\n\nprint obj.old_attr_one\nprint obj.attr_one\nprint obj.old_attr_two\nprint obj.attr_two\n"]], ['Track changes of atributes in instance. Python'], 2, 1], [(6762695, 0), [["You can try the following if you don't care about init list:"], ['If you want to get new one and leave initList as is you can use something like this(note that this is just a sample):']], [[" >>> a = ['AA', 'BB', 'C', 'D']\n>>> a[0] += a.pop(1)\n"]], ['Joining Subsequent List Elements - Python'], 3, 1], [(6762695, 1), [['If you want to get new one and leave initList as is you can use something like this(note that this is just a sample):'], ['Or in some cases you can try to use something like this too:']], [[" a = ['AA', 'BB', 'C', 'D']\noutList = a[:] # make a copy of list values\noutList[0] += outputList.pop(1)\n"]], ['Joining Subsequent List Elements - Python'], 3, 1], [(6762695, 2), [['Or in some cases you can try to use something like this too:'], ['-10000']], [[" from itertools import groupby\n\na = ['AA', 'BB', 'C', 'D']\nres = [''.join((str(z) for z in y)) for x, y in groupby(a, key = lambda x: len(x) == 2)]\n"]], ['Joining Subsequent List Elements - Python'], 3, 1], [(6798490, 0), [['I learned about the  key_name  argument that lets me set my own key names. So every time I create a new edge, I pass in the following argument to the constructor:'], ['Then, instead of running this query multiple times:']], [[" key_name = vertex1.name + ' > ' + vertex2.name\n"]], ['Storing a directed, weighted, complete graph in the GAE datastore'], 3, 0], [(6798490, 1), [['Then, instead of running this query multiple times:'], ['I can retrieve the edges easily since I know how to construct their keys. Using the  Key.from_path()  method, I construct a list of keys that refer to edges. Each key is obtained by doing this:']], [[" edge = Edge.all().filter('better =', vertex1).filter('worse =', vertex2).get()\n"]], ['Storing a directed, weighted, complete graph in the GAE datastore'], 3, 0], [(6798490, 2), [['I can retrieve the edges easily since I know how to construct their keys. Using the  Key.from_path()  method, I construct a list of keys that refer to edges. Each key is obtained by doing this:'], ['I then pass that list of keys to get all the objects in one query.']], [[" db.Key.from_path('Edge', vertex1.name + ' > ' + vertex2.name)\n"]], ['Storing a directed, weighted, complete graph in the GAE datastore'], 3, 0], [(6819640, 1), [['Then access this code:'], ['-10000']], [[" apple = Topic.objects.filter(tag='Apple')\nsub_topics = apple.sub_topics.all() ## Gets all sub_topics.\n"]], ['Django, topic model with subtopics'], 2, 0], [(6852394, 0), [['I just discovered that  getopt  will stop parsing if it encounters  -- :'], ['Note that the above  argv  is the equivalent of calling:']], [[' Python 2.6.6 (r266:84292, Jun 16 2011, 16:59:16) \nType "help", "copyright", "credits" or "license" for more information.\n>>> from getopt import getopt\n>>>\n>>> argv = [\'-v\', \'--plugin=foo\', \'--\', \'--extra=bar\', \'-c\']\n>>> opts, extra = getopt(argv, \'v\', \'plugin=\')\n>>>\n>>> opts\n[(\'-v\', \'\'), (\'--plugin\', \'foo\')]\n>>>\n>>> extra\n[\'--extra=bar\', \'-c\']\n']], ['Ignoring unrecognized options when parsing argv?'], 2, 1], [(6852394, 1), [['Note that the above  argv  is the equivalent of calling:'], ['I like this solution particularly since it gives the user a little extra flexibility in how he wants to order the parameters.']], [[' > main.py -v --plugin=Foo -- --extra=bar -c\n']], ['Ignoring unrecognized options when parsing argv?'], 2, 0], [(6941965, 0), [['Try  dateutil :'], ['output:']], [[" from dateutil import parser\n\ndates = ['30th November 2009', '31st March 2010', '30th September 2010']\n\nfor date in dates:\n    print parser.parse(date).strftime('%Y%m%d')\n"]], ['Convert a date string into YYYYMMDD'], 3, 1], [(6941965, 1), [['output:'], ['or if you want to do it using standard  datetime  module:']], [[' 20091130\n20100331\n20100930\n']], ['Convert a date string into YYYYMMDD'], 3, 0], [(6941965, 2), [['or if you want to do it using standard  datetime  module:'], ['-10000']], [[" from datetime import datetime\n\ndates = ['30th November 2009', '31st March 2010', '30th September 2010']\n\nfor date in dates:\n    part = date.split()\n    print datetime.strptime('%s %s %s' % (part[0][:-2]), part[1], part[2]), '%d %B %Y').strftime('%Y%m%d')\n"]], ['Convert a date string into YYYYMMDD'], 3, 1], [(6943912, 1), [['You can even package this up in a context manager, as follows:'], ['and then']], [[' from contextlib import contextmanager\n\n@contextmanager\ndef flag_regexen(flag):\n    import re\n    re.my_compile = re.compile\n    re.compile = lambda pattern, flags: re.my_compile(pattern, flags | flag)\n    yield\n    re.compile = re.my_compile\n']], ['Using a global flag for python RegExp compile'], 3, 0], [(6943912, 2), [['and then'], ['-10000']], [[' with flag_regexen(re.DOTALL):\n    <do stuff with all regexes DOTALLed>\n']], ['Using a global flag for python RegExp compile'], 3, 0], [(6976372, 0), [['Here is an example to illustrate that,'], ['The result will be:']], [[' from multiprocessing import Pool\nfrom time import sleep\n\ndef square(x):\n    return x * x\n\ndef cube(y):\n    return y * y * y\n\npool = Pool(processes=20)\n\nresult_squares = pool.map_async(f, range(10))\nresult_cubes = pool.map_async(g, range(10))\n']], ['Mulitprocess Pools with different functions'], 2, 1], [(6976372, 1), [['The result will be:'], ['-10000']], [[' >>> print result_squares.get(timeout=1)\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n>>> print result_cubes.get(timeout=1)\n[0, 1, 8, 27, 64, 125, 216, 343, 512, 729]\n']], ['Mulitprocess Pools with different functions'], 2, 0], [(6998245, 0), [['frankeniter with ideas from answers of @agf, @FogleBird, @senderle, a resulting somewhat-neat-looking piece of code is:'], ['and, for some performance information regarding deque/tuple:']], [[' from itertools import chain, repeat, islice\n\ndef window(seq, size=2, fill=0, fill_left=True, fill_right=False):\n    """ Returns a sliding window (of width n) over data from the iterable:\n      s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...\n    """\n    ssize = size - 1\n    it = chain(\n      repeat(fill, ssize * fill_left),\n      iter(seq),\n      repeat(fill, ssize * fill_right))\n    result = tuple(islice(it, size))\n    if len(result) == size:  # `<=` if okay to return seq if len(seq) < size\n        yield result\n    for elem in it:\n        result = result[1:] + (elem,)\n        yield result\n']], ['Iterate over a ‘window’ of adjacent elements in Python'], 2, 1], [(6998245, 1), [['and, for some performance information regarding deque/tuple:'], ["but anyway, if it's numbers then numpy is likely preferable."]], [[' In [32]: kwa = dict(gen=xrange(1000), size=4, fill=-1, fill_left=True, fill_right=True)\nIn [33]: %timeit -n 10000 [a+b+c+d for a,b,c,d in tmpf5.ia(**kwa)]\n10000 loops, best of 3: 358 us per loop\nIn [34]: %timeit -n 10000 [a+b+c+d for a,b,c,d in tmpf5.window(**kwa)]\n10000 loops, best of 3: 368 us per loop\nIn [36]: %timeit -n 10000 [sum(x) for x in tmpf5.ia(**kwa)]\n10000 loops, best of 3: 340 us per loop\nIn [37]: %timeit -n 10000 [sum(x) for x in tmpf5.window(**kwa)]\n10000 loops, best of 3: 432 us per loop\n']], ['Iterate over a ‘window’ of adjacent elements in Python'], 2, 0], [(7050562, 0), [['To make a new copy of your list, try:'], ['Or more  cryptic  concise via slicing:']], [[' newList = list(oldList)\n']], ['Trying to duplicate a list and modify one version of it in Python 2'], 2, 1], [(7050562, 1), [['Or more  cryptic  concise via slicing:'], ['Just  assigning   oldList  to  newList  will result in two names pointing to the same object, like so:']], [[' newlist = oldList[:]\n']], ['Trying to duplicate a list and modify one version of it in Python 2'], 2, 1], [(7086295, 0), [['I quickly knocked up the following example code to illustrate this. Instead of doing any actual testing, it uses the  random  module to fail some tests for demonstration purposes. When created, the classes are inserted into the global namespace so that a call to  unittest.main()  will pick them up. Depending on how you run your tests, you may wish to do something different with the generated classes. '], ['A sample run:']], [[" import os\nimport unittest\n\n# Generate a test class for an individual file.\ndef make_test(filename):\n    class TestClass(unittest.TestCase):\n        def test_file(self):\n            # Do the actual testing here.\n            # parsed = do_my_parsing(filename)\n            # golden = load_golden(filename)\n            # self.assertEquals(parsed, golden, 'Parsing failed.')\n\n            # Randomly fail some tests.\n            import random\n            if not random.randint(0, 10):\n                self.assertEquals(0, 1, 'Parsing failed.')\n\n        # Set the docstring so we get nice test messages.\n        test_file.__doc__ = 'Test parsing of %s' % filename\n\n    return TestClass\n\n# Create a single file test.\nTest1 = make_test('file1.html')\n\n# Create several tests from a list.\nfor i in range(2, 5):\n    globals()['Test%d' % i] = make_test('file%d.html' % i)\n\n# Create them from a directory listing.\nfor dirname, subdirs, filenames in os.walk('tests'):\n    for f in filenames:\n        globals()['Test%s' % f] = make_test('%s/%s' % (dirname, f))\n\n# If this file is being run, run all the tests.\nif __name__ == '__main__':\n    unittest.main()\n"]], ['Proper way to organize testcases that involve a data file for each testcase?'], 2, 1], [(7086295, 1), [['A sample run:'], ['-10000']], [[' $ python tests.py -v\nTest parsing of file1.html ... ok\nTest parsing of file2.html ... ok\nTest parsing of file3.html ... ok\nTest parsing of file4.html ... ok\nTest parsing of tests/file5.html ... ok\nTest parsing of tests/file6.html ... FAIL\nTest parsing of tests/file7.html ... ok\nTest parsing of tests/file8.html ... ok\n\n======================================================================\nFAIL: Test parsing of tests/file6.html\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File "generic.py", line 16, in test_file\n    self.assertEquals(0, 1, \'Parsing failed.\')\nAssertionError: Parsing failed.\n\n----------------------------------------------------------------------\nRan 8 tests in 0.004s\n\nFAILED (failures=1)\n']], ['Proper way to organize testcases that involve a data file for each testcase?'], 2, 0], [(7096090, 0), [['Probably the easiest way to get this to work seems to be to add the following to the top of models.py:'], ['and then under each model add']], [[' from django.db.models import manager\n']], ['Add django model manager code-completion to Komodo'], 4, 0], [(7096090, 1), [['and then under each model add'], ['so that, for example, the following:']], [[' objects = manager.Manager()\n']], ['Add django model manager code-completion to Komodo'], 4, 0], [(7096090, 2), [['so that, for example, the following:'], ['becomes']], [[' class Site(models.Model):\n    name = models.CharField(max_length=200)\n    prefix = models.CharField(max_length=1)\n    secret = models.CharField(max_length=255)\n\n    def __unicode__(self):\n        return self.name\n']], ['Add django model manager code-completion to Komodo'], 4, 0], [(7096090, 3), [['becomes'], ['This is how you would (explicitly) set your own model manager, and by explicitly setting the model manager (to the default) Kommodo picks up the code completion perfectly.']], [[' class Site(models.Model):\n    name = models.CharField(max_length=200)\n    prefix = models.CharField(max_length=1)\n    secret = models.CharField(max_length=255)\n\n    objects = manager.Manager()\n\n    def __unicode__(self):\n        return self.name\n']], ['Add django model manager code-completion to Komodo'], 4, 0], [(7132861, 0), [['This works fine:'], ['Keep in mind that  os.path.join()  exists to smooth over the different path separator characters used by different operating systems, so your code doesn\'t have to special-case each one.  File name "extensions" only have significant meaning on one major operating system (they\'re simply part of the file name on non-Windows systems), and their separator is always a dot.  There\'s no need for a function to join them, but if using one makes you feel better, you can do this:']], [[' os.path.join(dir_name, base_filename + "." + filename_suffix)\n']], ['building full path filename in python,'], 3, 1], [(7132861, 1), [['Keep in mind that  os.path.join()  exists to smooth over the different path separator characters used by different operating systems, so your code doesn\'t have to special-case each one.  File name "extensions" only have significant meaning on one major operating system (they\'re simply part of the file name on non-Windows systems), and their separator is always a dot.  There\'s no need for a function to join them, but if using one makes you feel better, you can do this:'], ['Or, if you want to keep your code really clean, simply include the dot in the suffix:']], [[" os.path.join(dir_name, '.'.join((base_filename, filename_suffix)))\n"]], ['building full path filename in python,'], 3, 1], [(7132861, 2), [['Or, if you want to keep your code really clean, simply include the dot in the suffix:'], ['-10000']], [[" suffix = '.pdf'\nos.path.join(dir_name, base_filename + suffix)\n"]], ['building full path filename in python,'], 3, 1], [(7154171, 0), [['You can use a function attribute that you switch between true and false on each call:'], ['Here is a quick example of how this works:']], [[' def toggleConsole():\n    toggleConsole.show = not getattr(toggleConsole, "show", True)\n    console = win32console.GetConsoleWindow()\n    win32gui.ShowWindow(console, int(toggleConsole.show))\n']], ['How can I set a true/false variable with if?'], 2, 1], [(7171140, 0), [["Try  Liza Daly's fast_iter . After processing an element,  elem , it calls  elem.clear()  to remove descendants and also removes preceding siblings. "], ['The script below shows the difference in behavior. Note in particular that  orig_fast_iter  does not delete the  A1  element, while the  mod_fast_iter  does delete it, thus saving more memory.']], [[' def fast_iter(context, func, *args, **kwargs):\n    """\n    http://lxml.de/parsing.html#modifying-the-tree\n    Based on Liza Daly\'s fast_iter\n    http://www.ibm.com/developerworks/xml/library/x-hiperfparse/\n    See also http://effbot.org/zone/element-iterparse.htm\n    """\n    for event, elem in context:\n        func(elem, *args, **kwargs)\n        # It\'s safe to call clear() here because no descendants will be\n        # accessed\n        elem.clear()\n        # Also eliminate now-empty references from the root node to elem\n        for ancestor in elem.xpath(\'ancestor-or-self::*\'):\n            while ancestor.getprevious() is not None:\n                del ancestor.getparent()[0]\n    del context\n\n\ndef process_element(elem):\n    print elem.xpath( \'description/text( )\' )\n\ncontext = etree.iterparse( MYFILE, tag=\'item\' )\nfast_iter(context,process_element)\n']], ['Using Python Iterparse For Large XML Files'], 2, 1], [(7171140, 1), [['The script below shows the difference in behavior. Note in particular that  orig_fast_iter  does not delete the  A1  element, while the  mod_fast_iter  does delete it, thus saving more memory.'], ['-10000']], [[' import lxml.etree as ET\nimport textwrap\nimport io\n\ndef setup_ABC():\n    content = textwrap.dedent(\'\'\'\\\n      <root>\n        <A1>\n          <B1></B1>\n          <C>1<D1></D1></C>\n          <E1></E1>\n        </A1>\n        <A2>\n          <B2></B2>\n          <C>2<D></D></C>\n          <E2></E2>\n        </A2>\n      </root>\n        \'\'\')\n    return content\n\n\ndef study_fast_iter():\n    def orig_fast_iter(context, func, *args, **kwargs):\n        for event, elem in context:\n            print(\'Processing {e}\'.format(e=ET.tostring(elem)))\n            func(elem, *args, **kwargs)\n            print(\'Clearing {e}\'.format(e=ET.tostring(elem)))\n            elem.clear()\n            while elem.getprevious() is not None:\n                print(\'Deleting {p}\'.format(\n                    p=(elem.getparent()[0]).tag))\n                del elem.getparent()[0]\n        del context\n\n    def mod_fast_iter(context, func, *args, **kwargs):\n        """\n        http://www.ibm.com/developerworks/xml/library/x-hiperfparse/\n        Author: Liza Daly\n        See also http://effbot.org/zone/element-iterparse.htm\n        """\n        for event, elem in context:\n            print(\'Processing {e}\'.format(e=ET.tostring(elem)))\n            func(elem, *args, **kwargs)\n            # It\'s safe to call clear() here because no descendants will be\n            # accessed\n            print(\'Clearing {e}\'.format(e=ET.tostring(elem)))\n            elem.clear()\n            # Also eliminate now-empty references from the root node to elem\n            for ancestor in elem.xpath(\'ancestor-or-self::*\'):\n                print(\'Checking ancestor: {a}\'.format(a=ancestor.tag))\n                while ancestor.getprevious() is not None:\n                    print(\n                        \'Deleting {p}\'.format(p=(ancestor.getparent()[0]).tag))\n                    del ancestor.getparent()[0]\n        del context\n\n    content = setup_ABC()\n    context = ET.iterparse(io.BytesIO(content), events=(\'end\', ), tag=\'C\')\n    orig_fast_iter(context, lambda elem: None)\n    # Processing <C>1<D1/></C>\n    # Clearing <C>1<D1/></C>\n    # Deleting B1\n    # Processing <C>2<D/></C>\n    # Clearing <C>2<D/></C>\n    # Deleting B2\n\n    print(\'-\' * 80)\n    """\n    The improved fast_iter deletes A1. The original fast_iter does not.\n    """\n    content = setup_ABC()\n    context = ET.iterparse(io.BytesIO(content), events=(\'end\', ), tag=\'C\')\n    mod_fast_iter(context, lambda elem: None)\n    # Processing <C>1<D1/></C>\n    # Clearing <C>1<D1/></C>\n    # Checking ancestor: root\n    # Checking ancestor: A1\n    # Checking ancestor: C\n    # Deleting B1\n    # Processing <C>2<D/></C>\n    # Clearing <C>2<D/></C>\n    # Checking ancestor: root\n    # Checking ancestor: A2\n    # Deleting A1\n    # Checking ancestor: C\n    # Deleting B2\n\nstudy_fast_iter()\n']], ['Using Python Iterparse For Large XML Files'], 2, 1], [(7172290, 0), [['Logging can be  disabled  by calling'], ['and turned back on with']], [[' logging.disable(logging.CRITICAL)\n']], ['Override python logging for test efficiency'], 3, 0], [(7172290, 1), [['and turned back on with'], ['Use mocking:']], [[' logging.disable(logging.NOTSET)\n']], ['Override python logging for test efficiency'], 3, 0], [(7172290, 2), [['Use mocking:'], ["This will reduce the time consumed by logging statements to the time it takes to do one attribute lookup and one (noop) function call. If that's not satisfactory, I think the only option left is removing the logging statements themselves."]], [[' class MockLogger(object):\n    def debug(msg, *args, **kwargs): pass\n    def info(msg, *args, **kwargs): pass\n    def warn(msg, *args, **kwargs): pass\n    def error(msg, *args, **kwargs): pass\n    def critical(msg, *args, **kwargs): pass\n\nclass Test(unittest.TestCase):\n    def test_func(self):\n        _logger1=testmodule.logger1\n        _logger2=testmodule.logger2\n        testmodule.logger1=MockLogger()\n        testmodule.logger2=MockLogger()\n        # perform test\n        testmodule.logger1=_logger1\n        testmodule.logger2=_logger2\n']], ['Override python logging for test efficiency'], 3, 1], [(7218865, 0), [['You can use importlib in 2.7:'], ['In older versions you can use the  __import__  function. It defaults to returning the top level of a package import (e.g.  xml ). However, if you pass it a non-empty  fromlist , it returns the named module instead:']], [[" from importlib import import_module\n\nname = 'xml.etree.ElementTree.ElementTree'\nparts = name.rsplit('.', 1)\nElementTree = getattr(import_module(parts[0]), parts[1])\ntree = ElementTree()\n"]], ['How do you map a fully qualified class name to its class object in Python?'], 2, 1], [(7274521, 0), [['-10000'], ['or, using  list_choices = collections.defaultdict(list)  the last line will be:']], [[' list_choices = {}\nfor i in obj:\n    list_choices.setdefault(i.area.region.id, []).append([i.id, i.name])\n']], ['how do i turn for loop iterator into a neat pythonic one line for loop'], 2, 1], [(7274521, 1), [['or, using  list_choices = collections.defaultdict(list)  the last line will be:'], ['-10000']], [[' list_choices[i.area.region.id].append([i.id, i.name])\n']], ['how do i turn for loop iterator into a neat pythonic one line for loop'], 2, 0], [(7302316, 0), [['If you can use  dateutil  with GAE, then'], ["Otherwise, you'll have to rely on  re  to manipulate the date string into a format  strptime  can parse."]], [[" In [70]: import dateutil.parser as parser\nIn [71]: parser.parse('Sunday 31st of July 2005 ( 02:05:50 PM )',fuzzy=True)\nOut[71]: datetime.datetime(2005, 7, 31, 14, 5, 50)\n"]], ['Converting string to datetime object in Python (GAE)?'], 2, 1], [(7302316, 1), [["Otherwise, you'll have to rely on  re  to manipulate the date string into a format  strptime  can parse."], ['-10000']], [[" In [89]: datetime.datetime.strptime(re.sub(r'\\w+ (\\d+)\\w+ of(.+)\\s+\\( (.+) \\)',r'\\1 \\2 \\3','Sunday 31st of July 2005 ( 02:05:50 PM )'),'%d %B %Y %I:%M:%S %p')\nOut[89]: datetime.datetime(2005, 7, 31, 14, 5, 50)\n"]], ['Converting string to datetime object in Python (GAE)?'], 2, 1], [(7376019, 0), [['Sure, you can use slice indexing:'], ['Just to demonstrate the general algorithm, if you were to implement the  my_extend  function in a hypothetical custom  list  class, it would look like this:']], [[' a_list[1:1] = b_list\n']], ['list extend() to index, inserting list elements not only to the end'], 2, 1], [(7376019, 1), [['Just to demonstrate the general algorithm, if you were to implement the  my_extend  function in a hypothetical custom  list  class, it would look like this:'], ["But don't actually make that a function, just use the slice notation when you need to."]], [[' def my_extend(self, other_list, index):\n    self[index:index] = other_list\n']], ['list extend() to index, inserting list elements not only to the end'], 2, 1], [(7407934, 0), [["You could do it like that if you don't need to remeber where the contents come from :  "], ['or, if you want to keep track of the files names, you could use a dictionary :  ']], [[' PathwayList = []\nfor InFileName in FileList:\n    sys.stderr.write("Processing file %s\\n" % InFileName)\n    InFile = open(InFileName, \'r\')\n    PathwayList.append(InFile.readlines())\n    InFile.close()  \n\nfor contents in PathwayList:\n    # do something with contents which is a list of strings\n    print contents  \n']], ['python beginner - how to read contents of several files into unique lists?'], 2, 1], [(7407934, 1), [['or, if you want to keep track of the files names, you could use a dictionary :  '], ['-10000']], [[' PathwayList = {}\nfor InFileName in FileList:\n    sys.stderr.write("Processing file %s\\n" % InFileName)\n    InFile = open(InFileName, \'r\')\n    PathwayList[InFile] = InFile.readlines()\n    InFile.close()\n\nfor filename, contents in PathwayList.items():\n    # do something with contents which is a list of strings\n    print filename, contents  \n']], ['python beginner - how to read contents of several files into unique lists?'], 2, 1], [(7463941, 0), [['Two somewhat easy ways are:'], ['or ']], [[' (x * y.T).T\n']], ['Reshape for array multiplication/division in python'], 2, 1], [(7463941, 1), [['or '], ["Numpy's  broadcasting  is a very powerful feature, and will do exactly what you want automatically, but it expects the last axis (or axes) of the arrays to have the same shape, not the first axes.  Thus, you need to transpose  y  for it to work."]], [[' x.reshape((-1,1)) * y\n']], ['Reshape for array multiplication/division in python'], 2, 1], [(7471055, 0), [['It  might  be this:'], ['... but as it has been written, it is not clear what the rule is exactly. In nested loops:']], [[" l = [['g,g', 'g,g'], ['d,d', 'd,d,d', 'd,d'], ['s,s', 's,s']]\noutput = [ (x, y, z, v) for z, l1 in enumerate(l[::-1]) for y, l2 in enumerate(l1) for x, v in enumerate(l2.split(',')) ]\n"]], ['Python: converting a nested list into a simple list with coord positions'], 2, 1], [(7471055, 1), [['... but as it has been written, it is not clear what the rule is exactly. In nested loops:'], ['-10000']], [[" output = []\nfor z,l1 in enumerate(l[::-1]):\n    for y, l2 in enumerate(l1):\n        for x, v in enumerate(l2.split(',')):\n            output.append((x, y, z, v))\n"]], ['Python: converting a nested list into a simple list with coord positions'], 2, 1], [(7490408, 0), [['Your code will work exactly as you typed it. '], ['will print: ']], [[' def foo(*mylist):\n    bar("first", *mylist)\n\ndef bar(*vals):\n    print "|".join(vals)\n\nfoo("a","b")\n']], ['How to unpack a list?'], 2, 1], [(7490408, 1), [['will print: '], ['-10000']], [[' first|a|b\n']], ['How to unpack a list?'], 2, 0], [(7501557, 0), [['If you want to load from legacy fixture, you could build some intermediate model/table, convert file or customize dumpdata command. Fool dumpdata is possible, as following, but hmm...'], ['Or you could add customized serializer to public serializers and mainly override  its  Deserializer  function to work w/ properties that you have. Mainly override to tweak two lines in  Deserializer  inside  django/core/serializers/python.py']], [[' class VirtualField(object):\n    rel = None\n\n    def contribute_to_class(self, cls, name):\n        self.attname = self.name = name\n        # cls._meta.add_virtual_field(self)\n        get_field = cls._meta.get_field\n        cls._meta.get_field = lambda name, many_to_many=True: self if name == self.name else get_field(name, many_to_many)\n        models.signals.pre_init.connect(self.pre_init, sender=cls) #, weak=False)\n        models.signals.post_init.connect(self.post_init, sender=cls) #, weak=False)\n        setattr(cls, name, self)\n\n    def pre_init(self, signal, sender, args, kwargs, **_kwargs):\n        sender._meta._field_name_cache.append(self)\n\n    def post_init(self, signal, sender, **kwargs):\n        sender._meta._field_name_cache[:] = sender._meta._field_name_cache[:-1]\n\n    def __get__(self, instance, instance_type=None):\n        if instance is None:\n            return self\n        return instance.field1 + \'/\' + instance.field2\n\n    def __set__(self, instance, value):\n        if instance is None:\n             raise AttributeError(u"%s must be accessed via instance" % self.related.opts.object_name)\n        instance.field1, instance.field2 = value.split(\'/\')\n\n    def to_python(self, value):\n        return value\n\nclass A(models.Model):\n     field1 = models.TextField()\n     field2 = models.TextField()\n     virtual_field = VirtualField()\n\n# legacy.json\n[{"pk": 1, "model": "so.a", "fields": {"virtual_field": "A/B"}}, {"pk": 2, "model": "so.a", "fields": {"virtual_field": "199/200"}}]\n\n$ ./manage.py loaddump legacy.json\nInstalled 2 object(s) from 1 fixture(s)\n']], ['Convert property to django model field'], 2, 1], [(7508774, 0), [['I grabbed a complete (at least it should be complete) list of all html tags from w3 to match against.  Try it out:'], ['Produces:']], [[' fixedString = re.sub(">\\s*(\\!--|\\!DOCTYPE|\\\n                           a|abbr|acronym|address|applet|area|\\\n                           b|base|basefont|bdo|big|blockquote|body|br|button|\\\n                           caption|center|cite|code|col|colgroup|\\\n                           dd|del|dfn|dir|div|dl|dt|\\\n                           em|\\\n                           fieldset|font|form|frame|frameset|\\\n                           head|h1|h2|h3|h4|h5|h6|hr|html|\\\n                           i|iframe|img|input|ins|\\\n                           kbd|\\\n                           label|legend|li|link|\\\n                           map|menu|meta|\\\n                           noframes|noscript|\\\n                           object|ol|optgroup|option|\\\n                           p|param|pre|\\\n                           q|\\\n                           s|samp|script|select|small|span|strike|strong|style|sub|sup|\\\n                           table|tbody|td|textarea|tfoot|th|thead|title|tr|tt|\\\n                           u|ul|\\\n                           var)>", "><\\g<1>>", s)\nbs = BeautifulSoup(fixedString)\n']], ['Beautiful Soup - how to fix broken tags'], 3, 1], [(7508774, 1), [['Produces:'], ['-10000']], [[' >>> print s\n\n<tr>\ntd>LABEL1</td><td>INPUT1</td>\n</tr>\n<tr>\n<td>LABEL2</td><td>INPUT2</td>\n</tr>\n\n>>> print re.sub(">\\s*(\\!--|\\!DOCTYPE|\\\n                       a|abbr|acronym|address|applet|area|\\\n                       b|base|basefont|bdo|big|blockquote|body|br|button|\\\n                       caption|center|cite|code|col|colgroup|\\\n                       dd|del|dfn|dir|div|dl|dt|\\\n                       em|\\\n                       fieldset|font|form|frame|frameset|\\\n                       head|h1|h2|h3|h4|h5|h6|hr|html|\\\n                       i|iframe|img|input|ins|\\\n                       kbd|\\\n                       label|legend|li|link|\\\n                       map|menu|meta|\\\n                       noframes|noscript|\\\n                       object|ol|optgroup|option|\\\n                       p|param|pre|\\\n                       q|\\\n                       s|samp|script|select|small|span|strike|strong|style|sub|sup|\\\n                       table|tbody|td|textarea|tfoot|th|thead|title|tr|tt|\\\n                       u|ul|\\\n                       var)>", "><\\g<1>>", s)\n\n<tr><td>LABEL1</td><td>INPUT1</td>\n</tr>\n<tr>\n<td>LABEL2</td><td>INPUT2</td>\n</tr>\n']], ['Beautiful Soup - how to fix broken tags'], 3, 0], [(7508774, 2), [['-10000'], ['-10000']], [[' re.sub(">\\s*(/?)(\\!--|\\!DOCTYPE|\\a|abbr|acronym|address|applet|area|\\\n                 b|base|basefont|bdo|big|blockquote|body|br|button|\\\n                 caption|center|cite|code|col|colgroup|\\\n                 dd|del|dfn|dir|div|dl|dt|\\\n                 em|\\\n                 fieldset|font|form|frame|frameset|\\\n                 head|h1|h2|h3|h4|h5|h6|hr|html|\\\n                 i|iframe|img|input|ins|\\\n                 kbd|\\\n                 label|legend|li|link|\\\n                 map|menu|meta|\\\n                 noframes|noscript|\\\n                 object|ol|optgroup|option|\\\n                 p|param|pre|\\\n                 q|\\\n                 s|samp|script|select|small|span|strike|strong|style|sub|sup|\\\n                 table|tbody|td|textarea|tfoot|th|thead|title|tr|tt|\\\n                 u|ul|\\\n                 var)>", "><\\g<1>\\g<2>>", s)\n']], ['Beautiful Soup - how to fix broken tags'], 3, 1], [(7522721, 0), [["The  cached_db  and  cache  backends don't support it, but it's easy to create your own:"], ['When using Memcached and  cached_db , its a bit more complex because of how that  SessionStore  is implemented.  We just replace it completely:  ']], [[' from django.contrib.sessions.backends.cache import SessionStore as CachedSessionStore\nfrom django.core.cache import get_cache\nfrom django.conf import settings\n\nclass SessionStore(CachedSessionStore):\n    """\n    A cache-based session store.\n    """\n    def __init__(self, session_key=None):\n        self._cache = get_cache(settings.SESSION_CACHE_ALIAS)\n        super(SessionStore, self).__init__(session_key)\n']], ['Django Multiple Caches - How to choose which cache the session goes in?'], 2, 1], [(7522721, 1), [['When using Memcached and  cached_db , its a bit more complex because of how that  SessionStore  is implemented.  We just replace it completely:  '], ['-10000']], [[' from django.conf import settings\nfrom django.contrib.sessions.backends.db import SessionStore as DBStore\nfrom django.core.cache import get_cache\n\nclass SessionStore(DBStore):\n    """\n    Implements cached, database backed sessions.  Now with control over the cache!\n    """\n\n    def __init__(self, session_key=None):\n        super(SessionStore, self).__init__(session_key)\n        self.cache = get_cache(getattr(settings, \'SESSION_CACHE_ALIAS\', \'default\'))\n\n    def load(self):\n        data = self.cache.get(self.session_key, None)\n        if data is None:\n            data = super(SessionStore, self).load()\n            self.cache.set(self.session_key, data, settings.SESSION_COOKIE_AGE)\n        return data\n\n    def exists(self, session_key):\n        return super(SessionStore, self).exists(session_key)\n\n    def save(self, must_create=False):\n        super(SessionStore, self).save(must_create)\n        self.cache.set(self.session_key, self._session, settings.SESSION_COOKIE_AGE)\n\n    def delete(self, session_key=None):\n        super(SessionStore, self).delete(session_key)\n        self.cache.delete(session_key or self.session_key)\n\n    def flush(self):\n        """\n        Removes the current session data from the database and regenerates the\n        key.\n        """\n        self.clear()\n        self.delete(self.session_key)\n        self.create()\n']], ['Django Multiple Caches - How to choose which cache the session goes in?'], 2, 1], [(7537439, 0), [['You could use  set  to increment a counter:'], ['Or you could use  loop.index :']], [[' {% set count = 1 %}\n{% for i in p %}\n  {{ count }}\n  {% set count = count + 1 %}\n{% endfor %}\n']], ['How to increment a variable on a for loop in jinja template?'], 2, 1], [(7537439, 1), [['Or you could use  loop.index :'], ['Check the  template designer documentation .']], [[' {% for i in p %}\n  {{ loop.index }}\n{% endfor %}\n']], ['How to increment a variable on a for loop in jinja template?'], 2, 1], [(7586936, 0), [['Use the /d operator on  for :'], ['A multi-line example:']], [[' for /D %%d in (*) do script.py %%d\n']], ['Batch Scripting: Running python script on all directories in a folder'], 2, 1], [(7586936, 1), [['A multi-line example:'], ['-10000']], [[' for /D %%d in (%1) do (\n   echo processing %%d\n   script.py %%d\n)\n']], ['Batch Scripting: Running python script on all directories in a folder'], 2, 1], [(7681301, 0), [["You're close."], ['If you need to know how many  11 s there are as keys in the inner  dict s, you can:']], [[" idnum = 11\n# The loop and 'if' are good\n# You just had the 'break' in the wrong place\nfor id, idnumber in A.iteritems():\n    if idnum in idnumber.keys(): # you can skip '.keys()', it's the default\n       calculate = some_function_of(idnumber[idnum])\n       break # if we find it we're done looking - leave the loop\n    # otherwise we continue to the next dictionary\nelse:\n    # this is the for loop's 'else' clause\n    # if we don't find it at all, we end up here\n    # because we never broke out of the loop\n    calculate = your_default_value\n    # or whatever you want to do if you don't find it\n"]], ['Search for a key in a nested Python dictionary'], 2, 1], [(7681301, 1), [['If you need to know how many  11 s there are as keys in the inner  dict s, you can:'], ['This works because a key can only be in each  dict  once so you just have to test if the key exits.  in  returns  True  or  False  which are equal to  1  and  0 , so the  sum  is the number of occurences of  idnum .']], [[' idnum = 11\nprint sum(idnum in idnumber for idnumber in A.itervalues())\n']], ['Search for a key in a nested Python dictionary'], 2, 0], [(7700545, 0), [['-10000'], ['Also, you can assign the result directly to a couple of variables:']], [[' max((cell[k], x, y)\n    for (y, row) in enumerate(m)\n    for (x, cell) in enumerate(row))[1:]\n']], ['How to pick the largest number in a matrix of lists in python?'], 2, 1], [(7700545, 1), [['Also, you can assign the result directly to a couple of variables:'], ['This is O( n 2 ), btw.']], [[' (_, x, y) = max((cell[k], x, y)\n                for (y, row) in enumerate(m)\n                for (x, cell) in enumerate(row))\n']], ['How to pick the largest number in a matrix of lists in python?'], 2, 1], [(7734028, 0), [['For example, you can change fore and background colors in any part of a  wx.TextCrtl :'], ['wx.richtext  is also easy to use to write lines with different colors:']], [[' rt = wx.TextCtrl(self, -1,"My Text....",size=(200, 100),style=wx.TE_MULTILINE|wx.TE_RICH2)\nrt.SetInsertionPoint(0)\nrt.SetStyle(2, 5, wx.TextAttr("red", "blue"))\n']], ['different foreground colors for each line in wxPython wxTextCtrl'], 2, 1], [(7734028, 1), [['wx.richtext  is also easy to use to write lines with different colors:'], ['As indicated in other answer the use of a  wx.ListCrtl  can be a very straighforward method if you work with lines of text (instead of multiline text).']], [[' rtc = wx.richtext.RichTextCtrl(self, style=wx.VSCROLL|wx.HSCROLL|wx.NO_BORDER)\nrtc.BeginTextColour((255, 0, 0))\nrtc.WriteText("this color is red")\nrtc.EndTextColour()\nrtc.Newline()\n']], ['different foreground colors for each line in wxPython wxTextCtrl'], 2, 1], [(7741455, 0), [['For example, we want to wrap the return type of:'], ['We could define a wrapper and  def  using it:']], [[' std::function<std::string(int, int)> get_string_function(const std::string& name)\n{\n    return [=](int x, int y)\n    {\n        return name + "(x=" + std::to_string(x) + ", y=" + std::to_string(y) + ")";\n    };\n}\n']], ['Creating a boost::python::object from a std::function'], 3, 0], [(7741455, 2), [['The Python side can now use the result as we want:'], ['-10000']], [[' >>> import s\n>>> s.get_string_function("Coord")\n<Boost.Python.function object at 0x1cca450>\n>>> _(1, 4)\n\'Coord(x=1, y=4)\'\n']], ['Creating a boost::python::object from a std::function'], 3, 0], [(7786737, 0), [['Below is your rf diagram'], ['Your train set should be like below. ']], [['   320   f   60\n   \\   |  / \n    \\  | /\n     \\ |/  \n l--------------r\n       |\n       |\n       |\n']], ['How to use PyBrain?'], 2, 0], [(7821265, 0), [['I have solved this by adding  __setitem__  in class. \nthan i do '], ['and in my class  __setitem__  is like ']], [[' result = as_class()\nfor key,value in dict_expr.items():\n        result.__setitem__(key,value)\n']], ['PYMongo : Parsing|Serializing query output of a collection'], 2, 0], [(7821265, 1), [['and in my class  __setitem__  is like '], ['-10000']], [[' def __setitem__(self,key,value):\n     try:\n        attr = getattr(class_obj,key)\n        if(attr!=None):\n            if(isinstance(value,dict)):\n                for child_key,child_value in value.items(): \n                    attr.__setitem__(child_key,child_value)\n                setattr(class_obj,key,attr)\n            else:\n                setattr(class_obj,key,value)\n\n    except AttributeError:\n       pass\n']], ['PYMongo : Parsing|Serializing query output of a collection'], 2, 0], [(7835030, 0), [["Here's a function that should do what you want, for most cases (all credit to  Sævar ):"], ['-10000']], [[" def get_client_address(environ):\n    try:\n        return environ['HTTP_X_FORWARDED_FOR'].split(',')[-1].strip()\n    except KeyError:\n        return environ['REMOTE_ADDR']\n"]], ['Obtaining Client IP address from a WSGI app using Eventlet'], 3, 0], [(7835030, 1), [['-10000'], ['-10000']], [[" from eventlet import wsgi\nimport eventlet\n\nfrom pprint import pformat\n\ndef show_env(env, start_response):\n    start_response('200 OK', [('Content-Type', 'text/plain')])\n    return ['%s\\r\\n' % pformat(env)]\n\nwsgi.server(eventlet.listen(('', 8090)), show_env)\n"]], ['Obtaining Client IP address from a WSGI app using Eventlet'], 3, 0], [(7877282, 0), [['First, you can save the image to a  tempfile  and remove the local file (if you have one):'], ['Second, set the temp file to the response (as per  this stackoverflow question ):']], [[" from tempfile import NamedTemporaryFile\nfrom shutil import copyfileobj\nfrom os import remove\n\ntempFileObj = NamedTemporaryFile(mode='w+b',suffix='jpg')\npilImage = open('/tmp/myfile.jpg','rb')\ncopyfileobj(pilImage,tempFileObj)\npilImage.close()\nremove('/tmp/myfile.jpg')\ntempFileObj.seek(0,0)\n"]], ['How to send image generated by PIL to browser?'], 2, 0], [(7877282, 1), [['Second, set the temp file to the response (as per  this stackoverflow question ):'], ['-10000']], [[" from flask import send_file\n\n@app.route('/path')\ndef view_method():\n    response = send_file(tempFileObj, as_attachment=True, attachment_filename='myfile.jpg')\n    return response\n"]], ['How to send image generated by PIL to browser?'], 2, 0], [(7886024, 1), [["Edit: I feel like you could add some effort into this yourself, but anyway. To add quotes, I'd change it to this:"], ['-10000']], [[' >>> list1 = [\'name\', \'age\', \'sex\']\n>>> list2 = [\'test\', 10, \'female\']\n>>> f = lambda l: \',\'.join(["\'%s\'" % str(s) for s in l])\n>>> print \'INSERT INTO (%s) VALUES (%s)\' % (f(list1), f(list2))\nINSERT INTO (\'name\',\'age\',\'sex\') VALUES (\'test\',\'10\',\'female\')\n']], ['related to List (want to insert into database)'], 2, 1], [(7907848, 0), [['You can call something like'], ["As you've found out yourself, in the case of Python it looks like this"]], [[' useradd -m -p PASSWORD\n']], ['How to create linux users via my own GUI application in Python?'], 2, 0], [(7907848, 1), [["As you've found out yourself, in the case of Python it looks like this"], ['-10000']], [[' import os \nimport crypt \n\npassword ="testpassword"\nencPass = crypt.crypt(Password,"salt")\nos.system("useradd -p "+encPass+" someuser ")\n']], ['How to create linux users via my own GUI application in Python?'], 2, 1], [(7918240, 0), [['You achieved the parsing, as you can see if you do the following:'], ['Here are some basics, with a simple file I got from my local network:']], [[' >>> tree\n<lxml.etree._ElementTree object at 0x0148AF08>\n']], ['Navigate trough lxml categories'], 2, 0], [(7927670, 0), [['Since PyMinuit uses introspection, you have to use introspection, too.   make_chi_squared()  could be implemented like this:'], ['Example usage:']], [[' import inspect\n\nchi_squared_template = """\ndef chi_squared(%(params)s):\n    return (((f(data_x, %(params)s) - data_y) / errors) ** 2).sum()\n"""\n\ndef make_chi_squared(f, data_x, data_y, errors):\n    params = ", ".join(inspect.getargspec(f).args[1:])\n    exec chi_squared_template % {"params": params}\n    return chi_squared\n']], ['How to define a chi2 value function for arbitrary function?'], 3, 1], [(7927670, 1), [['Example usage:'], ['printing']], [[' import numpy\n\ndef f(x, a1, a2, a3, a4):\n    return a1 + a2*x + a3*x**2 + a4*x**3\n\ndata_x = numpy.arange(50)\nerrors = numpy.random.randn(50) * 0.3\ndata_y = data_x**3 + errors\n\nchi_squared = make_chi_squared(f, data_x, data_y, errors)\nprint inspect.getargspec(chi_squared).args\n']], ['How to define a chi2 value function for arbitrary function?'], 3, 0], [(7927670, 2), [['printing'], ['-10000']], [[" ['a1', 'a2', 'a3', 'a4']\n"]], ['How to define a chi2 value function for arbitrary function?'], 3, 0], [(7933596, 1), [['-10000'], ['-10000']], [[" import eav\nfrom app.models import Patient, Encounter\n\neav.register(Encounter)\neav.register(Patient)\nAttribute.objects.create(name='age', datatype=Attribute.TYPE_INT)\nAttribute.objects.create(name='height', datatype=Attribute.TYPE_FLOAT)\nAttribute.objects.create(name='weight', datatype=Attribute.TYPE_FLOAT)\nAttribute.objects.create(name='city', datatype=Attribute.TYPE_TEXT)\nAttribute.objects.create(name='country', datatype=Attribute.TYPE_TEXT)\n\nself.yes = EnumValue.objects.create(value='yes')\nself.no = EnumValue.objects.create(value='no')\nself.unkown = EnumValue.objects.create(value='unkown')\nynu = EnumGroup.objects.create(name='Yes / No / Unknown')\nynu.enums.add(self.yes)\nynu.enums.add(self.no)\nynu.enums.add(self.unkown)\n\nAttribute.objects.create(name='fever', datatype=Attribute.TYPE_ENUM,\\\n                                       enum_group=ynu)\n\n# When you register a model within EAV,\n# you can access all of EAV attributes:\n\nPatient.objects.create(name='Bob', eav__age=12,\n                           eav__fever=no, eav__city='New York',\n                           eav__country='USA')\n# You can filter queries based on their EAV fields:\n\nquery1 = Patient.objects.filter(Q(eav__city__contains='Y'))\nquery2 = Q(eav__city__contains='Y') |  Q(eav__fever=no)\n"]], ['Django dynamic model fields'], 11, 1], [(7933596, 2), [['-10000'], ["In Django's shell you can use it like this:       "]], [[' #app/models.py\nfrom django.contrib.postgres.fields import HStoreField\nclass Something(models.Model):\n    name = models.CharField(max_length=32)\n    data = models.HStoreField(db_index=True)\n']], ['Django dynamic model fields'], 11, 0], [(7933596, 3), [["In Django's shell you can use it like this:       "], ['You can issue indexed queries against hstore fields:']], [[" >>> instance = Something.objects.create(\n                 name='something',\n                 data={'a': '1', 'b': '2'}\n           )\n>>> instance.data['a']\n'1'        \n>>> empty = Something.objects.create(name='empty')\n>>> empty.data\n{}\n>>> empty.data['a'] = '1'\n>>> empty.save()\n>>> Something.objects.get(name='something').data['a']\n'1'\n"]], ['Django dynamic model fields'], 11, 0], [(7933596, 4), [['You can issue indexed queries against hstore fields:'], ['JSON/JSONB fields support any JSON-encodable data type, not just key/value pairs, but also tend to be faster and (for JSONB) more compact than Hstore.\nSeveral packages implement JSON/JSONB fields including  django-pgfields , but as of Django 1.9,  JSONField  is a built-in using JSONB for storage.\n JSONField  is similar to HStoreField, and may perform better with large dictionaries.  It also supports types other than strings, such as integers, booleans and nested dictionaries.']], [[" # equivalence\nSomething.objects.filter(data={'a': '1', 'b': '2'})\n\n# subset by key/value mapping\nSomething.objects.filter(data__a='1')\n\n# subset by list of keys\nSomething.objects.filter(data__has_keys=['a', 'b'])\n\n# subset by single key\nSomething.objects.filter(data__has_key='a')    \n"]], ['Django dynamic model fields'], 11, 0], [(7933596, 5), [['JSON/JSONB fields support any JSON-encodable data type, not just key/value pairs, but also tend to be faster and (for JSONB) more compact than Hstore.\nSeveral packages implement JSON/JSONB fields including  django-pgfields , but as of Django 1.9,  JSONField  is a built-in using JSONB for storage.\n JSONField  is similar to HStoreField, and may perform better with large dictionaries.  It also supports types other than strings, such as integers, booleans and nested dictionaries.'], ['Creating in the shell:']], [[' #app/models.py\nfrom django.contrib.postgres.fields import JSONField\nclass Something(models.Model):\n    name = models.CharField(max_length=32)\n    data = JSONField(db_index=True)\n']], ['Django dynamic model fields'], 11, 0], [(7933596, 6), [['Creating in the shell:'], ['Indexed queries are nearly identical to HStoreField, except nesting is possible.  Complex indexes may require manually creation (or a scripted migration).']], [[" >>> instance = Something.objects.create(\n                 name='something',\n                 data={'a': 1, 'b': 2, 'nested': {'c':3}}\n           )\n"]], ['Django dynamic model fields'], 11, 0], [(7933596, 7), [['Indexed queries are nearly identical to HStoreField, except nesting is possible.  Complex indexes may require manually creation (or a scripted migration).'], ['-10000']], [[" >>> Something.objects.filter(data__a=1)\n>>> Something.objects.filter(data__nested__c=3)\n>>> Something.objects.filter(data__has_key='a')\n"]], ['Django dynamic model fields'], 11, 0], [(7950124, 0), [['It looks like you want to interpret the strings as integers. Use  int  to do this:'], ['It can also be written using  map  instead of a list comprehension:']], [[' chkseq = [int(line) for line in open("sequence.txt")] \n']], ["strip ' from all members in a list"], 2, 1], [(7950124, 1), [['It can also be written using  map  instead of a list comprehension:'], ['-10000']], [[' chkseq = map(int, open("sequence.txt"))\n']], ["strip ' from all members in a list"], 2, 1], [(7953623, 0), [['How about:'], ['which yields']], [[' import argparse\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser(description = "Print a range.")\n\n    parser.add_argument("start", type = int, help = "Specify start.", )\n    parser.add_argument("stop", type = int, help = "Specify stop.", )\n    parser.add_argument("step", type = int, help = "Specify step.", )\n\n    args=parser.parse_args()\n    print(args)\n']], ['How to modify the metavar for a positional argument in pythons argparse?'], 2, 1], [(7953623, 1), [['which yields'], ['-10000']], [[' % test.py -h\nusage: test.py [-h] start stop step\n\nPrint a range.\n\npositional arguments:\n  start       Specify start.\n  stop        Specify stop.\n  step        Specify step.\n\noptional arguments:\n  -h, --help  show this help message and exit\n']], ['How to modify the metavar for a positional argument in pythons argparse?'], 2, 0], [(8017432, 0), [['You should first  find records from  words  table , where words are exactly the ones you search for. The query could look like this:'], ['-10000']], [[" SELECT `id` FROM `words` WHERE `word` IN ('word1', 'word2', 'word3');\n"]], ['Most efficient way to index words in a document?'], 3, 0], [(8017432, 1), [['-10000'], ['which could be simplified to this:']], [[" SELECT `sentence_id`, `word_id` FROM `sentences_words`\nWHERE `word_id` IN ([here goes list of words' ids]);\n"]], ['Most efficient way to index words in a document?'], 3, 0], [(8017432, 2), [['which could be simplified to this:'], ['-10000']], [[" SELECT `sentence_id`, `word_id` FROM `sentences_words`\nWHERE `word_id` IN (\n    SELECT `id` FROM `words` WHERE `word` IN ('word1', 'word2', 'word3')\n);\n"]], ['Most efficient way to index words in a document?'], 3, 0], [(8019287, 0), [['I used this solution:  Search and replace a line in a file in Python'], ['But it does not work with files that contains non English charecters. ']], [[" from tempfile import mkstemp\nfrom shutil import move\nfrom os import remove, close\n\ndef replace_3_line(file):\n    new_3rd_line = 'new_3_line\\n'\n    #Create temp file\n    fh, abs_path = mkstemp()\n    new_file = open(abs_path,'w')\n    old_file = open(file)\n    counter = 0\n    for line in old_file:\n        counter = counter + 1\n        if counter == 3:\n            new_file.write(new_3rd_line)\n        else:\n            new_file.write(line)\n    #close temp file\n    new_file.close()\n    close(fh)\n    old_file.close()\n    #Remove original file\n    remove(file)\n    #Move new file\n    move(abs_path, file)\n\nreplace_3_line('tmp.ann')\n"]], ['Replace given line in files in Python'], 3, 1], [(8019287, 1), [['But it does not work with files that contains non English charecters. '], ['File is: ']], [[' Traceback (most recent call last):\n  File "D:\\xxx\\replace.py", line 27, in <module>\n    replace_3_line(\'tmp.ann\')\n  File "D:\\xxx\\replace.py", line 12, in replace_3_line\n    for line in old_file:\n  File "C:\\Python31\\lib\\encodings\\cp1251.py", line 23, in decode\n    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\nUnicodeDecodeError: \'charmap\' codec can\'t decode byte 0x98 in position 32: character maps to <undefined>\n']], ['Replace given line in files in Python'], 3, 0], [(8019287, 2), [['File is: '], ['-10000']], [[' фвыафыв\nsdadf\n试试\n阿斯达а\n阿斯顿飞\n']], ['Replace given line in files in Python'], 3, 0], [(8072755, 0), [["You must roll your own -- but it's easy:"], ['A simple example:']], [[' from itertools import zip_longest, starmap\n\ndef map2x(func, *iterables):\n    zipped = zip_longest(*iterables)\n    if func is None:\n        return zipped\n    return starmap(func, zipped)\n']], ['How do I get Python2.x `map` functionality in Python3.x?'], 3, 1], [(8072755, 1), [['A simple example:'], ['which gives us:']], [[" a=['a1']\nb=['b1','b2','b3']\nc=['c1','c2']\n\nprint(list(map2x(None, a, b, c)))\n"]], ['How do I get Python2.x `map` functionality in Python3.x?'], 3, 0], [(8072755, 2), [['which gives us:'], ['-10000']], [[" [('a1', 'b1', 'c1'), (None, 'b2', 'c2'), (None, 'b3', None)]\n"]], ['How do I get Python2.x `map` functionality in Python3.x?'], 3, 0], [(8087485, 1), [["I don't see a way to do this operation without a copy."], ['-10000']], [[' import numpy as np\na = np.arange(36).reshape(6, 6)\nprint(a)\n# [[ 0  1  2  3  4  5]\n#  [ 6  7  8  9 10 11]\n#  [12 13 14 15 16 17]\n#  [18 19 20 21 22 23]\n#  [24 25 26 27 28 29]\n#  [30 31 32 33 34 35]]\nblock3 = a[3:6, 0:3]\n\n# To rotate counterclockwise\nblock3[:] = np.rot90(block3.copy())\nprint(a)\n# [[ 0  1  2  3  4  5]\n#  [ 6  7  8  9 10 11]\n#  [12 13 14 15 16 17]\n#  [20 26 32 21 22 23]\n#  [19 25 31 27 28 29]\n#  [18 24 30 33 34 35]]\n\n# To rotate clockwise\na = np.arange(36).reshape(6, 6)\nblock3 = a[3:6, 0:3]\nblock3[:] = np.rot90(block3.copy(),-1)\nprint(a)\n# [[ 0  1  2  3  4  5]\n#  [ 6  7  8  9 10 11]\n#  [12 13 14 15 16 17]\n#  [30 24 18 21 22 23]\n#  [31 25 19 27 28 29]\n#  [32 26 20 33 34 35]]\n']], ['transpose/rotate a block of a matrix in python'], 2, 1], [(8096798, 0), [['If you  must  do it with regular expressions, try something like this:'], ['Just for the reference, this code does the same, but in a far more robust way:']], [[' a = re.finditer(\'<a.+?question-hyperlink">(.+?)</a>\', html)\nfor m in a: \n    print m.group(1)\n']], ['Python: Find a Sentence between some website-tags using regex'], 2, 1], [(8096798, 1), [['Just for the reference, this code does the same, but in a far more robust way:'], ['-10000']], [[" doc = BeautifulSoup(html)\nfor a in doc.findAll('a', 'question-hyperlink'):\n    print a.text\n"]], ['Python: Find a Sentence between some website-tags using regex'], 2, 1], [(8097844, 1), [["But, if you're going to be making several queries quickly, it would be better to reuse your connection, since making too many connections can waste time."], ['This will make your code perform much better.']], [[' ...\nCONNECTION = MySQLdb.connect(host=..., port=...,\n                             user=..., passwd=..., db=...,\n                             cursorclass=MySQLdb.cursors.DictCursor,\n                             charset = "utf8")\ncursor = CONNECTION.cursor()\ncursor.execute("SELECT ... FROM ... WHERE ... AND some_field=%s", ("first", "amazing", "topic"))\nfirst_result = cursor.fetchall()\n\ncursor.execute("SELECT ... FROM ... WHERE ... AND some_field=%s", (("first", "amazing", "topic")))\nsecond_result = cursor.fetchall()\n\ncursor.close()\n...\n']], ['Executing different queries using mysql-python'], 2, 1], [(8137056, 0), [['I now managed it with the exec() command.'], ['test.php:']], [[' <html>\n<body>\n\n<form action="test.php" method="get">\n<input type="text" name="name" />\n<input type="submit" />\n</form>\n\n</body>\n</html> \n']], ['How to input data from a web page to Python script most efficiently'], 2, 0], [(8147559, 0), [['-10000'], ['You can also do things like this:']], [[' import web\ntemplate_globals = {\n    "cookies": web.cookies,\n}\nrender = web.template.render(\'templates/\', globals=template_globals, base=\'layout\', cache=False)\n']], ['how to get cookie in template webpy'], 2, 1], [(8147559, 1), [['You can also do things like this:'], ['And then you will be able to render partial templates in your templates']], [[" render_partial = web.template.render('templates/', globals=template_globals)\ntemplate_globals.update(render=render_partial)\n"]], ['how to get cookie in template webpy'], 2, 1], [(8180404, 0), [['The easiest way would be to just  configure passwordless logins . Basically, create a local ssh key pair with'], ['Alternatively, use an SSH library such as  Paramiko :']], [[' ssh-keygen -t rsa\n']], ['python + auto ssh proccess to get date info'], 2, 0], [(8180404, 1), [['Alternatively, use an SSH library such as  Paramiko :'], ['-10000']], [[' import paramiko\nssh = paramiko.SSHClient()\n# Uncomment the following line for the equivalent of -oStrictHostKeyChecking=no\n#ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\nssh.connect(\'103.116.140.151\', username=\'user\', password=\'diana_123\')\nstdin, stdout, stderr = ssh.exec_command("date")\ndate = stdout.read()\nprint(date)\n']], ['python + auto ssh proccess to get date info'], 2, 1], [(8249165, 0), [['Something like this, using a  list comprehension :'], ['-10000']], [[' >>> input = [10, ["ETSc", "Juniper Hairstreak"], ["ETSc", "Spotted Turtle"], ["ETSc", "Blanding\'s Turtle"], "IWWH"]\n>>> output = [elt[0] + " (" + elt[1] + ")" if type(elt) == list and elt[0] == "ETSc" else str(elt) for elt in input]\n>>> output\n[\'10\', \'ETSc (Juniper Hairstreak)\', \'ETSc (Spotted Turtle)\', "ETSc (Blanding\'s Turtle)", \'IWWH\']\n']], ['setting a condition for a mixed list'], 2, 1], [(8249165, 1), [['-10000'], ['-10000']], [[' def xform(elt):\n    if type(elt) == list and len(elt) > 1 and elt[0] == "ETSc":\n        return elt[0] + " (" + elt[1] + ")"\n    else:\n        return str(elt)\n\noutput = [xform(elt) for elt in input]\n']], ['setting a condition for a mixed list'], 2, 1], [(8302519, 0), [['Use the  -q  parameter option\n'], ['or\n']], [[" import svmutil\nparam = svmutil.svm_parameter('-q')\n...\n"]], ['Suppressing the output in libsvm (python)'], 2, 1], [(8302519, 1), [['or\n'], ['-10000']], [[" import svmutil\nx = [[0.2, 0.1], [0.7, 0.6]]\ny = [0, 1]\nsvmutil.svm_train(y, x, '-q')\n"]], ['Suppressing the output in libsvm (python)'], 2, 1], [(8329204, 0), [['I do something similar with Jinja / GAE and I use a BaseHandler + a template that I include. BaseHandler:'], ['Then I can inherit the basehandler for eg form handlers:']], [[" class BaseHandler(webapp2.RequestHandler):\n    ...\n    def render_jinja(self, name, **data):\n        data['logout_url']=users.create_logout_url(self.request.uri)\n        template = jinja_environment.get_template('templates/'+name+'.html')\n        self.response.out.write(template.render(data))\n"]], ['Tipfy & Jinja: Creating a logout URL for every page'], 2, 0], [(8329204, 1), [['Then I can inherit the basehandler for eg form handlers:'], ['-10000']], [[" class FileUploadFormHandler(BaseHandler):\n    def get(self):\n        ...\n        self.render_jinja('contact_jinja', form=form, ...\n"]], ['Tipfy & Jinja: Creating a logout URL for every page'], 2, 0], [(8345190, 0), [['try this'], ['Edit** (I forgot to include the extension, here is the revision)']], [[' show_p=re.compile("(.*)\\.s(\\d*)e(\\d*)")\nshow_p.match(x).groups()\n']], ['regex - how to recognise a pattern until a second one is found'], 3, 0], [(8345190, 1), [['Edit** (I forgot to include the extension, here is the revision)'], ['-10000']], [[' show_p=re.compile("^(.*)\\.s(\\d*)e(\\d*).*?([^\\.]*)$")\nshow_p.match(x).groups()\n']], ['regex - how to recognise a pattern until a second one is found'], 3, 1], [(8345190, 2), [['-10000'], ['-10000']], [[' >>> show_p=re.compile("(.*)\\.s(\\d*)e(\\d*).*?([^\\.]*)$")\n>>> x="tv_show.s01e01.episode_name.avi"\n>>> show_p.match(x).groups()\n(\'tv_show\', \'01\', \'01\', \'avi\')\n>>> x="tv_show.s2e1.episode_name.avi"\n>>> show_p.match(x).groups()\n(\'tv_show\', \'2\', \'1\', \'avi\')\n>>> x=\'some.other.tv.show.s04e05.episode_name.avi\'\n>>> show_p.match(x).groups()\n(\'some.other.tv.show\', \'04\', \'05\', \'avi\')\n>>>  \n']], ['regex - how to recognise a pattern until a second one is found'], 3, 1], [(8355262, 0), [['This is what you are desiring?'], ['In that case try this']], [[' >>> x=\'<td>$GETR("wp","1")$Yes$GETR("","2")$No$NOTE()$</td>\'\n>>> if x.count("$GETR")>1:\n    x=x.replace("$GETR","\\n\\t$GETR").replace("</td>","\\n</td>")\n\n\n>>> print x\n<td>\n    $GETR("wp","1")$Yes\n    $GETR("","2")$No$NOTE()$\n</td>\n>>> x=\'<td>$GETR("","2")$No$NOTE()$</td>\'\n>>> if x.count("$GETR")>1:\n    x=x.replace("$GETR","\\n\\t$GETR").replace("</td>","\\n</td>")\n\n\n>>> print x\n<td>$GETR("","2")$No$NOTE()$</td>\n']], ['formatting files with sed/ python/ etc'], 2, 0], [(8405977, 0), [['First, set up the handlers to count on a restful style URI. We use 2 chunks of regex looking for an ID and a potential request format (ie html, xml, json etc)'], ['The get function can be abstracted more but it shows the basic idea of splitting out your logic into different request formats...']], [[' class TaskServer(tornado.web.Application):\n    def __init__(self, newHandlers = [], debug = None):\n        request_format = "(\\.[a-zA-Z]+$)?"\n        baseHandlers = [\n            (r"/jobs" + request_format, JobsHandler),\n            (r"/jobs/", JobsHandler),\n            (r"/jobs/new" + request_format, NewJobsHandler),\n            (r"/jobs/([0-9]+)/edit" + request_format, EditJobsHandler)\n        ]\n        for handler in newHandlers:\n            baseHandlers.append(handler)\n\n\n    tornado.web.Application.__init__(self, baseHandlers, debug = debug)\n']], ['Rendering requested type in Tornado'], 2, 0], [(8405977, 1), [['The get function can be abstracted more but it shows the basic idea of splitting out your logic into different request formats...'], ['-10000']], [[' class JobsHandler(BaseHandler):\n    def parseRestArgs(self, args):\n        idList = []\n        extension = None\n        if len(args) and not args[0] is None:\n            for arg in range(len(args)):\n                match = re.match("[0-9]+", args[arg])\n                if match:\n                    slave_id = int(match.groups()[0])\n\n            match = re.match("(\\.[a-zA-Z]+$)", args[-1])\n            if match:\n                extension = match.groups()[0][1:]\n\n        return idList, extension\n\n    def get(self, *args):\n        ### Read\n        job_id, extension = self.parseRestArgs(args)\n\n        if len(job_id):\n            if extension == None or "html":\n               #self.render(html) # Show with some ID voodoo\n               pass\n            elif extension == \'json\':\n                #self.render(json) # Show with some ID voodoo\n                pass\n            else:\n                raise tornado.web.HTTPError(404) #We don\'t do that sort of thing here...\n        else:\n            if extension == None or "html":\n                pass\n                # self.render(html) # Index- No ID given, show an index\n            elif extension == "json":\n                pass\n                # self.render(json) # Index- No ID given, show an index\n            else:\n                raise tornado.web.HTTPError(404) #We don\'t do that sort of thing here...\n']], ['Rendering requested type in Tornado'], 2, 0], [(8419817, 0), [['Currently all of the values in your list are strings, and you want them to integers, here are the two most straightforward ways to do this:'], ['and']], [[' map(int, your_list)\n']], ['Remove single quotes from python list item'], 3, 1], [(8419817, 1), [['and'], ['If you want to leave the items in your list as strings but display them without the single quotes, you can use the following:']], [[' [int(value) for value in your_list]\n']], ['Remove single quotes from python list item'], 3, 1], [(8419817, 2), [['If you want to leave the items in your list as strings but display them without the single quotes, you can use the following:'], ['-10000']], [[" print('[' + ', '.join(your_list) + ']')\n"]], ['Remove single quotes from python list item'], 3, 1], [(8422308, 0), [['If you simply want to substitute an input file your versionfile.ver should look like this'], ['Now you can use the following task so the values will be substituted']], [[' VERSION=@VERSION@\nDATADIR=@DATADIR@\n']], ['Waf: How to output a generated file?'], 4, 0], [(8422308, 1), [['Now you can use the following task so the values will be substituted'], ['To be able to access version from bld you have to define it during configure']], [[' bld.new_task_gen (\n  features = "subst",\n  source= "versionfile.ver",\n  target= "versionfile.out",\n  VERSION = bld.env[\'VERSION\'],\n  DATADIR = bld.env[\'DATADIR\'])\n']], ['Waf: How to output a generated file?'], 4, 0], [(8422308, 2), [['To be able to access version from bld you have to define it during configure'], ['However when you want to pass on your source file through a python script or any command available you can use the following:']], [[" conf.env['VERSION'] = '0.7.0'\n"]], ['Waf: How to output a generated file?'], 4, 0], [(8422308, 3), [['However when you want to pass on your source file through a python script or any command available you can use the following:'], ['There is also a sample available  here  where in this case g-ir-compiler is used what in your case would be a python script.']], [[" lib_typelib = bld.new_task_gen(\n  name = 'versionfile',\n  source = 'versionfile.ver',\n  target = 'versionfile.out',\n  rule='/path/to/your/python/script ${SRC} -o ${TGT}')\n"]], ['Waf: How to output a generated file?'], 4, 0], [(8431654, 0), [['Using  inspect.getmodule  you can (sometimes) find the module in which an object was defined, e.g.'], ['The module name can be found using  __name__ . Note that the defining module need not be the one you imported from due to re-exports:']], [[" >>> from collections import defaultdict\n>>> import inspect\n>>> inspect.getmodule(defaultdict)\n<module 'collections' from '/usr/lib/python2.6/collections.pyc'>\n"]], ['retrieve the Package.Module.Class name from a (Python) class/type'], 2, 1], [(8470539, 0), [["Well if you like R's data.table, there have been a few (at least) attempts to re-create that functionality in NumPy--through additional classes in NumPy Core and through external Python libraries. The effort i find most promising is the  datarray  library by Fernando Perez. Here's how it works."], ['Instantiate the  DataArray instance , by calling the constructor and passing in an ordinary NumPy array and a list of tuples--one tuple for each axis, and since ndim = 2 here, there are two tuples in the list each tuple is comprised of axis label (str) and a sequence of labels for that axes (list).']], [[' >>> # create a NumPy array for use as our data set\n>>> import numpy as NP\n>>> D = NP.random.randint(0, 10, 40).reshape(8, 5)\n\n>>> # create some generic row and column names to pass to the constructor\n>>> row_ids = [ "row{0}".format(c) for c in range(D1.shape[0]) ]\n>>> rows = \'rows_id\', row_ids\n\n>>> variables = [ "col{0}".format(c) for c in range(D1.shape[1]) ]\n>>> cols = \'variable\', variables\n']], ['How do I index n sets of 4 columns to plot multiple plots using matplotlib?'], 2, 0], [(8470539, 1), [['Instantiate the  DataArray instance , by calling the constructor and passing in an ordinary NumPy array and a list of tuples--one tuple for each axis, and since ndim = 2 here, there are two tuples in the list each tuple is comprised of axis label (str) and a sequence of labels for that axes (list).'], ['-10000']], [[" >>> from datarray.datarray import DataArray as DA\n>>> D1 = DA(D, [rows, cols])\n\n>>> D1.axes\n      (Axis(name='rows', index=0, labels=['row0', 'row1', 'row2', 'row3', \n           'row4', 'row5', 'row6', 'row7']), Axis(name='cols', index=1, \n           labels=['col0', 'col1', 'col2', 'col3', 'col4']))\n\n>>> # now you can use R-like syntax to reference a NumPy data array by column:\n>>> D1[:,'col1']\n      DataArray([8, 5, 0, 7, 8, 9, 9, 4])\n      ('rows',)\n"]], ['How do I index n sets of 4 columns to plot multiple plots using matplotlib?'], 2, 0], [(8530203, 0), [['As python  re  module  documentation  says you may add the  MULTILINE  flag to  re.compile  method. This will let you match entire file at once.'], ['Second code variant']], [[" import re\n\nregex = re.match(r'''(\n    ^\\s*clns\\s+routing$ |\n    ^\\s*bfd\\s+graceful-restart$ |\n    ^\\s*ip\\s+default-network$ |\n    ^\\s*ip\\s+default-gateway$ |\n    ^\\s*ip\\s+subnet-zero$ |\n    ^\\s*ip\\s+cef\\s*$\n)+''', re.MULTILINE | re.VERBOSE)\n"]], ['Match multiple lines in a file using regular expression python'], 2, 1], [(8530203, 1), [['Second code variant'], ['-10000']], [[" import re\n\nregex = re.match(r'''(^\n    \\s*\n    (clns|bfd|ip)\n    \\s+\n    (routing|graceful-restart|default-network|default-gateway|subnet-zero|cef)\n$)+''', re.MULTILINE | re.VERBOSE)\n"]], ['Match multiple lines in a file using regular expression python'], 2, 1], [(8605189, 0), [['-10000'], ['And finally:']], [[" big_list = [\n  [\n    (20, 'Item A', 'Jan'),\n    (30, 'Item B', 'Jan'),\n    (12, 'Item C', 'Jan'),\n  ],\n  [\n    (22, 'Item A', 'Feb'),\n    (34, 'Item B', 'Feb'),\n    (15, 'Item C', 'Feb'),\n  ]]\n\ns = {}\nfor l in big_list:\n    for m in l:\n        s[m[1]] = s.get(m[1], 0) + m[0]\n"]], ['Sorting a list of list of tuples based on the sum of first field in the tuple in Python'], 3, 0], [(8605189, 1), [['And finally:'], ['changes  big_list  to:']], [[' for l in big_list:\n    l.sort(key=lambda x: s[x[1]])\n']], ['Sorting a list of list of tuples based on the sum of first field in the tuple in Python'], 3, 0], [(8605189, 2), [['changes  big_list  to:'], ['This solution works for lists within months in any order and also if some item does not appear in some month.']], [[" [[(12, 'Item C', 'Jan'), (20, 'Item A', 'Jan'), (30, 'Item B', 'Jan')],\n [(15, 'Item C', 'Feb'), (22, 'Item A', 'Feb'), (34, 'Item B', 'Feb')]]\n"]], ['Sorting a list of list of tuples based on the sum of first field in the tuple in Python'], 3, 0], [(8652136, 0), [['This should answer your question:'], ["or if you prefer dictionary with modules' names as keys:"]], [[' references = map(__import__, modules)\n']], ['Dynamic module loading in python'], 2, 1], [(8652136, 1), [["or if you prefer dictionary with modules' names as keys:"], ['Does it answer your question?']], [[' references = dict(zip(modules, map(__import__, modules)))\n']], ['Dynamic module loading in python'], 2, 1], [(8671702, 0), [['Python tuples are converted to sql lists in psycopg2:'], ['would output']], [[' cur.mogrify("SELECT * FROM table WHERE column IN %s;", ((1,2,3),))\n']], ['Passing list of parameters to SQL in psycopg2'], 3, 1], [(8671702, 1), [['would output'], ['For Python new comers: It is unfortunately important to use a tuple, not a list here. Second example:']], [[" 'SELECT * FROM table WHERE column IN (1,2,3);'\n"]], ['Passing list of parameters to SQL in psycopg2'], 3, 0], [(8682336, 0), [['Instead of using a new variable for each customer you could store your object in a Python dictionary:'], ['-10000']], [[" d = dict()\n\nfor record in result:\n    objectname = 'Customer' + str(record[0])\n    customername = str(record[1])\n    d[objectname] = Customer(customername)\n\nprint d\n"]], ['How do I assign a variable to an object name?'], 2, 1], [(8685308, 0), [["Rather than try to get the fractions right, I'd just allocate the goals one at a time in the appropriate ratio. Here the 'allocate_goals' generator assigns a goal to each of the low-ratio goals, then to each of the high-ratio goals (repeating 3 times). Then it repeats. The caller, in allocate cuts off this infinite generator at the required number (the number of players) using itertools.islice."], ['It produces this answer:']], [[' import collections\nimport itertools\nimport string\n\ndef allocate_goals(prop_low, prop_high):\n    prop_high3 = prop_high * 3\n    while True:\n        for g in prop_low:\n            yield g\n        for g in prop_high3:\n            yield g\n\ndef allocate(goals, players):\n    letters = string.ascii_uppercase[:goals]\n    high_count = goals // 2\n    prop_high, prop_low = letters[:high_count], letters[high_count:]\n    g = allocate_goals(prop_low, prop_high)\n    return collections.Counter(itertools.islice(g, players))\n\nfor goals in xrange(2, 9):\n    print goals, sorted(allocate(goals, 8).items())\n']], ['Allocate items according to an approximate ratio in Python'], 3, 1], [(8685308, 1), [['It produces this answer:'], ['Just replace allocate_goals with this:']], [[" 2 [('A', 6), ('B', 2)]\n3 [('A', 4), ('B', 2), ('C', 2)]\n4 [('A', 3), ('B', 3), ('C', 1), ('D', 1)]\n5 [('A', 3), ('B', 2), ('C', 1), ('D', 1), ('E', 1)]\n6 [('A', 2), ('B', 2), ('C', 1), ('D', 1), ('E', 1), ('F', 1)]\n7 [('A', 2), ('B', 1), ('C', 1), ('D', 1), ('E', 1), ('F', 1), ('G', 1)]\n8 [('A', 1), ('B', 1), ('C', 1), ('D', 1), ('E', 1), ('F', 1), ('G', 1), ('H', 1)]\n"]], ['Allocate items according to an approximate ratio in Python'], 3, 0], [(8685308, 2), [['Just replace allocate_goals with this:'], ['-10000']], [[' def allocate_goals(prop_low, prop_high):\n    all_goals = prop_low + prop_high * 3\n    while True:\n        yield random.choice(all_goals)\n']], ['Allocate items according to an approximate ratio in Python'], 3, 0], [(8702772, 0), [['This is the best way to accomplish what you want to do:'], ['In this example,  model  is the actual model, so you can do plenty of things with it:']], [[" from django.db.models import get_app, get_models\n\napp = get_app('my_application_name')\nfor model in get_models(app):\n    # do something with the model\n"]], ['Django get list of models in application'], 2, 1], [(8702772, 1), [['In this example,  model  is the actual model, so you can do plenty of things with it:'], ['UPDATE']], [[' for model in get_models(app):\n    new_object = model() # Create an instance of that model\n    model.objects.filter(...) # Query the objects of that model\n    model._meta.db_table # Get the name of the model in the database\n    model._meta.verbose_name # Get a verbose name of the model\n    # ...\n']], ['Django get list of models in application'], 2, 0], [(8714744, 1), [['List n  = [x+f(x):x ∈ List n-1 ]'], ['then first you need to generate the time sequence and you can use itertools.count for that purpose like']], [[' somelist+=[[x+f(x) for x in somelist[-1]]]\n']], ['Loop over time and over list elements with python -- one-dimensional lake temperature model simulation'], 5, 0], [(8714744, 2), [['then first you need to generate the time sequence and you can use itertools.count for that purpose like'], ['then']], [[' itertools.count(someStartTime,delta)\n']], ['Loop over time and over list elements with python -- one-dimensional lake temperature model simulation'], 5, 0], [(8714744, 3), [['then'], ['Note: f,g,h are python functions which can be defined as']], [[' somelist+=[[x+f(t) for x,t in zip(somelist[-1],itertools.count(someStartTime,delta))]]\n']], ['Loop over time and over list elements with python -- one-dimensional lake temperature model simulation'], 5, 0], [(8714744, 4), [['Note: f,g,h are python functions which can be defined as'], ['-10000']], [[' def f(n):\n    ........\n    return .....\n']], ['Loop over time and over list elements with python -- one-dimensional lake temperature model simulation'], 5, 0], [(8780912, 0), [['To make this a linear equation, take the (natural) log of both sides:'], ['This then simplifies to the polynomial:']], [[' ln(y) = ln(height) - (x - mu)^2 / (2 * sigma^2)\n']], ['How can I perform a least-squares fitting over multiple data sets fast?'], 8, 0], [(8780912, 1), [['This then simplifies to the polynomial:'], ['We can recast this in a bit simpler form:']], [[' ln(y) = -x^2 / (2 * sigma^2) + x * mu / sigma^2 - mu^2 / sigma^2 + ln(height)\n']], ['How can I perform a least-squares fitting over multiple data sets fast?'], 8, 0], [(8780912, 2), [['We can recast this in a bit simpler form:'], ['where:']], [[' ln(y) = A * x^2 + B * x + C\n']], ['How can I perform a least-squares fitting over multiple data sets fast?'], 8, 0], [(8780912, 3), [['where:'], ["Once we've done this, though, it's rather fast. Solving for 262144 different gaussian curves takes only ~1 minute (Be sure to removing the plotting portion of the code if you run it on something that large...).  It's also quite easy to parallelize, if you want..."]], [[' A = 1 / (2 * sigma^2)\nB = mu / (2 * sigma^2)\nC = mu^2 / sigma^2 + ln(height)\n']], ['How can I perform a least-squares fitting over multiple data sets fast?'], 8, 0], [(8780912, 4), [["Once we've done this, though, it's rather fast. Solving for 262144 different gaussian curves takes only ~1 minute (Be sure to removing the plotting portion of the code if you run it on something that large...).  It's also quite easy to parallelize, if you want..."], ["The only thing we'd need to change for a parallel version is the main function. (We also need a dummy function because  multiprocessing.Pool.imap  can't supply additional arguments to its function...) It would look something like this:"]], [[' import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport itertools\n\ndef main():\n    x, data = generate_data(256, 6)\n    model = [invert(x, y) for y in data.T]\n    sigma, mu, height = [np.array(item) for item in zip(*model)]\n    prediction = gaussian(x, sigma, mu, height)\n\n    plot(x, data, linestyle=\'none\', marker=\'o\')\n    plot(x, prediction, linestyle=\'-\')\n    plt.show()\n\ndef invert(x, y):\n    # Use only data within the "peak" (20% of the max value...)\n    key_points = y > (0.2 * y.max())\n    x = x[key_points]\n    y = y[key_points]\n\n    # Fit a 2nd order polynomial to the log of the observed values\n    A, B, C = np.polyfit(x, np.log(y), 2)\n\n    # Solve for the desired parameters...\n    sigma = np.sqrt(-1 / (2.0 * A))\n    mu = B * sigma**2\n    height = np.exp(C + 0.5 * mu**2 / sigma**2)\n    return sigma, mu, height\n\ndef generate_data(numpoints, numcurves):\n    np.random.seed(3)\n    x = np.linspace(0, 500, numpoints)\n\n    height = 100 * np.random.random(numcurves)\n    mu = 200 * np.random.random(numcurves) + 200\n    sigma = 100 * np.random.random(numcurves) + 0.1\n    data = gaussian(x, sigma, mu, height)\n\n    noise = 5 * (np.random.random(data.shape) - 0.5)\n    return x, data + noise\n\ndef gaussian(x, sigma, mu, height):\n    data = -np.subtract.outer(x, mu)**2 / (2 * sigma**2)\n    return height * np.exp(data)\n\ndef plot(x, ydata, ax=None, **kwargs):\n    if ax is None:\n        ax = plt.gca()\n    colorcycle = itertools.cycle(mpl.rcParams[\'axes.color_cycle\'])\n    for y, color in zip(ydata.T, colorcycle):\n        ax.plot(x, y, color=color, **kwargs)\n\nmain()\n']], ['How can I perform a least-squares fitting over multiple data sets fast?'], 8, 1], [(8780912, 5), [["The only thing we'd need to change for a parallel version is the main function. (We also need a dummy function because  multiprocessing.Pool.imap  can't supply additional arguments to its function...) It would look something like this:"], ["Edit:  In cases where the simple polynomial fitting isn't working well, try weighting the problem by the y-values,  as mentioned in the link/paper  that @tslisten shared (and Stefan van der Walt implemented, though my implementation is a bit different)."]], [[' def parallel_main():\n    import multiprocessing\n    p = multiprocessing.Pool()\n    x, data = generate_data(256, 262144)\n    args = itertools.izip(itertools.repeat(x), data.T)\n    model = p.imap(parallel_func, args, chunksize=500)\n    sigma, mu, height = [np.array(item) for item in zip(*model)]\n    prediction = gaussian(x, sigma, mu, height)\n\ndef parallel_func(args):\n    return invert(*args)\n']], ['How can I perform a least-squares fitting over multiple data sets fast?'], 8, 0], [(8780912, 6), [["Edit:  In cases where the simple polynomial fitting isn't working well, try weighting the problem by the y-values,  as mentioned in the link/paper  that @tslisten shared (and Stefan van der Walt implemented, though my implementation is a bit different)."], ['If that\'s still giving you trouble, then try iteratively-reweighting the least-squares problem (The final "best" reccomended method in the link @tslisten mentioned).  Keep in mind that this will be considerably slower, however.']], [[" import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport itertools\n\ndef main():\n    def run(x, data, func, threshold=0):\n        model = [func(x, y, threshold=threshold) for y in data.T]\n        sigma, mu, height = [np.array(item) for item in zip(*model)]\n        prediction = gaussian(x, sigma, mu, height)\n\n        plt.figure()\n        plot(x, data, linestyle='none', marker='o', markersize=4)\n        plot(x, prediction, linestyle='-', lw=2)\n\n    x, data = generate_data(256, 6, noise=100)\n    threshold = 50\n\n    run(x, data, weighted_invert, threshold=threshold)\n    plt.title('Weighted by Y-Value')\n\n    run(x, data, invert, threshold=threshold)\n    plt.title('Un-weighted Linear Inverse'\n\n    plt.show()\n\ndef invert(x, y, threshold=0):\n    mask = y > threshold\n    x, y = x[mask], y[mask]\n\n    # Fit a 2nd order polynomial to the log of the observed values\n    A, B, C = np.polyfit(x, np.log(y), 2)\n\n    # Solve for the desired parameters...\n    sigma, mu, height = poly_to_gauss(A,B,C)\n    return sigma, mu, height\n\ndef poly_to_gauss(A,B,C):\n    sigma = np.sqrt(-1 / (2.0 * A))\n    mu = B * sigma**2\n    height = np.exp(C + 0.5 * mu**2 / sigma**2)\n    return sigma, mu, height\n\ndef weighted_invert(x, y, weights=None, threshold=0):\n    mask = y > threshold\n    x,y = x[mask], y[mask]\n    if weights is None:\n        weights = y\n    else:\n        weights = weights[mask]\n\n    d = np.log(y)\n    G = np.ones((x.size, 3), dtype=np.float)\n    G[:,0] = x**2\n    G[:,1] = x\n\n    model,_,_,_ = np.linalg.lstsq((G.T*weights**2).T, d*weights**2)\n    return poly_to_gauss(*model)\n\ndef generate_data(numpoints, numcurves, noise=None):\n    np.random.seed(3)\n    x = np.linspace(0, 500, numpoints)\n\n    height = 7000 * np.random.random(numcurves)\n    mu = 1100 * np.random.random(numcurves) \n    sigma = 100 * np.random.random(numcurves) + 0.1\n    data = gaussian(x, sigma, mu, height)\n\n    if noise is None:\n        noise = 0.1 * height.max()\n    noise = noise * (np.random.random(data.shape) - 0.5)\n    return x, data + noise\n\ndef gaussian(x, sigma, mu, height):\n    data = -np.subtract.outer(x, mu)**2 / (2 * sigma**2)\n    return height * np.exp(data)\n\ndef plot(x, ydata, ax=None, **kwargs):\n    if ax is None:\n        ax = plt.gca()\n    colorcycle = itertools.cycle(mpl.rcParams['axes.color_cycle'])\n    for y, color in zip(ydata.T, colorcycle):\n        #kwargs['color'] = kwargs.get('color', color)\n        ax.plot(x, y, color=color, **kwargs)\n\nmain()\n"]], ['How can I perform a least-squares fitting over multiple data sets fast?'], 8, 1], [(8780912, 7), [['If that\'s still giving you trouble, then try iteratively-reweighting the least-squares problem (The final "best" reccomended method in the link @tslisten mentioned).  Keep in mind that this will be considerably slower, however.'], ['-10000']], [[' def iterative_weighted_invert(x, y, threshold=None, numiter=5):\n    last_y = y\n    for _ in range(numiter):\n        model = weighted_invert(x, y, weights=last_y, threshold=threshold)\n        last_y = gaussian(x, *model)\n    return model\n']], ['How can I perform a least-squares fitting over multiple data sets fast?'], 8, 0], [(8892307, 0), [['My approach is this: do 2 lists, first one with (id_store, last_success_date) tuples and second one with (id_store, last_date) tuples:'], ['Then take store ids for stores that last data and last success date are equals, and you have the query:']], [[" l_succ = stores.objects.filter( \n                       order__success = True \n                  ).annotate(\n                       last_success=Max('order__date')\n                  ).value_list (\n                       'id', 'last_success'\n                  )\n#l_succ = [ (1, '1/1/2011'), (2, '31/12/2010'), ... ] <-l_succ result\n\nl_last = stores.objects.annotate(\n                       last_date=Max('order__date')\n                  ).value_list (\n                       'id', 'last_date'\n                  )\n#l_last = [ (1, '1/1/2011'), (2, '3/1/2011'), ... ]   <-l_last result\n"]], ['Filtering a model in Django based on a condition upon the latest child record'], 2, 0], [(8892307, 1), [['Then take store ids for stores that last data and last success date are equals, and you have the query:'], ['It seems an elegant solution, only four lines of code for a complex query (but with a simple requeriment). Disclaimer, it is not tested.']], [[' store_success_ids =  [ k[0] for k in l_succ if k in l_last ]\n#store_success_ids = [1, 5, ... ]          <-store_success_ids result\n#Cast l_last to dictionary to do lookups if you have a lot of stores.\n\nresult = Store.objects.filter( pk__in = store_success_ids)        \n']], ['Filtering a model in Django based on a condition upon the latest child record'], 2, 0], [(8916209, 0), [['-10000'], ['Example:']], [[' def nested(flat, level=0):\n    for k, it in itertools.groupby(flat, lambda x: x.split("-")[level]):\n        yield next(it)\n        remainder = list(nested(it, level + 1))\n        if remainder:\n            yield remainder\n']], ['How to build a nested list from a flat one in Python?'], 2, 1], [(8916209, 1), [['Example:'], ['-10000']], [[" >>> list(nested(flat, 0))\n['1', ['1-1', ['1-1-1'], '1-2'], '2', ['2-1', '2-2'], '3']\n"]], ['How to build a nested list from a flat one in Python?'], 2, 0], [(8937566, 0), [['Example 1:'], ['Example 2: ']], [[' >>> import numpy as np\n>>> A = np.ones((5,5), dtype=int)\n>>> B = [1, 3, 7, 23]\n>>> A\narray([[1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1]])\n>>> A_ = A.ravel()\n>>> A_[B] = 0\n>>> A_.reshape(A.shape)\narray([[1, 0, 1, 0, 1],\n       [1, 1, 0, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 0, 1]])\n']], ['Python: multidimensional array masking'], 3, 1], [(8937566, 1), [['Example 2: '], ['-10000']], [[' >>> b_row, b_col = np.vstack([np.unravel_index(b, A.shape) for b in B]).T\n>>> A[b_row, b_col] = 0\n>>> A\narray([[1, 0, 1, 0, 1],\n       [1, 1, 0, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 0, 1]])\n']], ['Python: multidimensional array masking'], 3, 1], [(8937566, 2), [['-10000'], ['-10000']], [[' >>> import numpy as np\n>>> A = np.ones((5,5), dtype=int)\n>>> B = [1, 3, 7, 23]\n>>> A.put(B, [0]*len(B))\n>>> A\narray([[1, 0, 1, 0, 1],\n       [1, 1, 0, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 0, 1]])\n']], ['Python: multidimensional array masking'], 3, 1], [(8948166, 0), [['Here is some simple code. Providing row/column/grand totals is left as an exercise for the reader.'], ['Output:']], [[' class CrossTab(object):\n\n    def __init__(\n        self,\n        missing=0, # what to return for an empty cell.\n                   # Alternatives: \'\', 0.0, None, \'NULL\'\n        ):\n        self.missing = missing\n        self.col_key_set = set()\n        self.cell_dict = {}\n        self.headings_OK = False\n\n    def add_item(self, row_key, col_key, value):\n        self.col_key_set.add(col_key)\n        try:\n            self.cell_dict[row_key][col_key] += value\n        except KeyError:\n            try:\n                self.cell_dict[row_key][col_key] = value\n            except KeyError:\n                self.cell_dict[row_key] = {col_key: value}\n\n    def _process_headings(self):\n        if self.headings_OK:\n            return\n        self.row_headings = list(sorted(self.cell_dict.keys()))\n        self.col_headings = list(sorted(self.col_key_set))\n        self.headings_OK = True\n\n    def get_col_headings(self):\n        self._process_headings()\n        return self.col_headings\n\n    def generate_row_info(self):\n        self._process_headings()\n        for row_key in self.row_headings:\n            row_dict = self.cell_dict[row_key]\n            row_vals = [\n                row_dict.get(col_key, self.missing)\n                for col_key in self.col_headings\n                ]\n            yield row_key, row_vals\n\nif __name__ == "__main__":\n\n    data = [["apples", 2, "New York"], \n      ["peaches", 6, "New York"],\n      ["apples", 6, "New York"],\n      ["peaches", 1, "Vermont"]]  \n\n    ctab = CrossTab(missing=\'uh-oh\')\n    for s in data:\n        ctab.add_item(row_key=s[2], col_key=s[0], value=s[1])\n    print()\n    print(\'Column headings:\', ctab.get_col_headings())\n    for row_heading, row_values in ctab.generate_row_info():\n        print(repr(row_heading), row_values)\n']], ['How to pivot/cross-tab data in Python 3?'], 2, 1], [(8948166, 1), [['Output:'], ['See also  this answer .']], [[" Column headings: ['apples', 'peaches']\n'New York' [8, 6]\n'Vermont' ['uh-oh', 1]\n"]], ['How to pivot/cross-tab data in Python 3?'], 2, 0], [(8948773, 0), [['From the basic tutorial on MongoDB site:'], ['Suppose you now want to do the equivalent of']], [[' j = { name : "mongo" };\nt = { x : 3 };\ndb.things.save(j);\ndb.things.save(t);\n']], ['What is the proper way to perform a contextual search against NoSQL key-value pairs?'], 3, 0], [(8948773, 1), [['Suppose you now want to do the equivalent of'], ['In Mongo Shell, you can do this:']], [[" SELECT * FROM things WHERE name like 'mon%'\n"]], ['What is the proper way to perform a contextual search against NoSQL key-value pairs?'], 3, 0], [(8948773, 2), [['In Mongo Shell, you can do this:'], ['This returns the "mongo" document.']], [[" db.things.find({name:{$regex:'mon'}}).forEach(printjson);\n"]], ['What is the proper way to perform a contextual search against NoSQL key-value pairs?'], 3, 0], [(8950809, 0), [['-10000'], ['Make a string out of the word_list if you want it as a single string instead of a list of words.']], [[" line = '20 30 i love you'.split()\na = int(line[0])\nb = int(line[1])\nword_list = line[2:]\n"]], ['Read each word and rest of line in Python?'], 2, 1], [(8950809, 1), [['Make a string out of the word_list if you want it as a single string instead of a list of words.'], ['-10000']], [[" text = ''.join(word_list)\n"]], ['Read each word and rest of line in Python?'], 2, 0], [(9013354, 0), [['If the numbers in the first column of  a  are in sorted order, then you could use'], ['For example:']], [[' a[a[:,0].searchsorted(b[:,0]),1] = b[:,1]\n']], ['Insert data from one sorted array into another sorted array'], 5, 1], [(9013354, 2), [['yields'], ['If  a[:,0]  is not in sorted order, then you could use  np.argsort  to workaround this:']], [[' [[ 1  0  0  0  0]\n [ 2  0  0  0  0]\n [ 3  1  0  0  0]\n [ 4  0  0  0  0]\n [ 5 18  0  0  0]\n [ 6  0  0  0  0]\n [ 7  2  0  0  0]\n [ 8  0  0  0  0]]\n']], ['Insert data from one sorted array into another sorted array'], 5, 0], [(9013354, 3), [['If  a[:,0]  is not in sorted order, then you could use  np.argsort  to workaround this:'], ['yields']], [[' a = np.array( [(1,0,0,0,0),\n               (2,0,0,0,0),\n               (5,0,0,0,0),\n               (3,0,0,0,0),\n               (4,0,0,0,0),\n               (6,0,0,0,0),\n               (7,0,0,0,0),\n               (8,0,0,0,0),\n               ])\n\nb = np.array([(3, 1),\n              (5, 18),\n              (7, 2)])\n\nperm = np.argsort(a[:,0])\na[:,1][perm[a[:,0][perm].searchsorted(b[:,0])]] = b[:,1]\nprint(a)\n']], ['Insert data from one sorted array into another sorted array'], 5, 1], [(9013354, 4), [['yields'], ['-10000']], [[' [[ 1  0  0  0  0]\n [ 2  0  0  0  0]\n [ 5 18  0  0  0]\n [ 3  1  0  0  0]\n [ 4  0  0  0  0]\n [ 6  0  0  0  0]\n [ 7  2  0  0  0]\n [ 8  0  0  0  0]]\n']], ['Insert data from one sorted array into another sorted array'], 5, 0], [(9017260, 0), [['Try the  intervals  package:'], ['With the sample data this reduces the 15 rows to the following 13 rows (by combining rows 1 and 2 and rows 12 and 13 in the original data frame):']], [[' library(intervals)\n\nf <- function(dd) with(dd, {\n    r <- reduce(Intervals(cbind(start, end)))\n    data.frame(username = username[1],\n         machine = machine[1],\n         start = structure(r[, 1], class = class(start)),\n         end = structure(r[, 2], class = class(end)))\n})\n\ndo.call("rbind", by(d, d[1:2], f))\n']], ['Remove rows from data: overlapping time intervals?'], 2, 1], [(9017260, 1), [['With the sample data this reduces the 15 rows to the following 13 rows (by combining rows 1 and 2 and rows 12 and 13 in the original data frame):'], ['-10000']], [['    username          machine               start                 end\n1     user1 D5599.domain.com 2011-01-03 02:44:18 2011-01-03 03:09:16\n2     user1 D5599.domain.com 2011-01-03 07:07:36 2011-01-03 07:56:17\n3     user1 D5599.domain.com 2011-01-05 08:03:17 2011-01-05 08:23:15\n4     user1 D5599.domain.com 2011-02-14 07:33:39 2011-02-14 07:40:16\n5     user1 D5599.domain.com 2011-02-23 06:54:30 2011-02-23 06:58:23\n6     user1 D5599.domain.com 2011-03-21 04:10:18 2011-03-21 04:32:22\n7     user1 D5645.domain.com 2011-06-09 03:12:41 2011-06-09 03:58:59\n8     user1 D5682.domain.com 2011-01-03 05:03:45 2011-01-03 05:29:43\n9     USER2 D5682.domain.com 2011-01-12 07:26:05 2011-01-12 07:32:53\n10    USER2 D5682.domain.com 2011-01-17 08:06:19 2011-01-17 08:44:22\n11    USER2 D5682.domain.com 2011-01-18 08:07:30 2011-01-18 08:42:43\n12    USER2 D5682.domain.com 2011-01-25 08:20:55 2011-01-25 08:24:38\n13    USER2 D5682.domain.com 2011-02-14 07:59:23 2011-02-14 08:14:47\n']], ['Remove rows from data: overlapping time intervals?'], 2, 0], [(9020831, 0), [['Calling'], ['If you do not want the main process to block, then spawn a thread to handle the calls to  subprocess.Popen :']], [[' self.rsyncRun.communicate()\n']], ['Run multiple subprocesses in foreach loop? One at the time?'], 2, 1], [(9020831, 1), [['If you do not want the main process to block, then spawn a thread to handle the calls to  subprocess.Popen :'], ['-10000']], [[" import threading\n\ndef worker():\n    for share in shares.split(', '):\n        ...\n        rsyncRun = subprocess.Popen(...)\n        out, err = rsyncRun.communicate()\n\nt = threading.Thread(target = worker)\nt.daemon = True\nt.start()\nt.join()\n"]], ['Run multiple subprocesses in foreach loop? One at the time?'], 2, 1], [(9091299, 0), [['For example you can make with jQuery like this,\nin controller you return rendered template:'], ['and in the client side you can use jQuery']], [[" def some_html():\n    return render('my_template.tpl')\n"]], ['How to let js make a request from python and preserve the loaded site in place when answered by python'], 3, 0], [(9091299, 1), [['and in the client side you can use jQuery'], [',where result_from_server its can be id of wrapper div like ']], [[' <script type="text/javascript">\n(\'#result_from_server\').load(\'/some_html\');\n</script>\n']], ['How to let js make a request from python and preserve the loaded site in place when answered by python'], 3, 0], [(9091299, 2), [[',where result_from_server its can be id of wrapper div like '], ['and /some_html, url for call your some_html() function. ']], [[' <div id="result_from_server"></div>\n']], ['How to let js make a request from python and preserve the loaded site in place when answered by python'], 3, 0], [(9151104, 0), [['The simplest solution for doing exactly what you specified is:'], ['This is basically equivalent to the iterative version:']], [[' documents = [sub_list[0] for sub_list in documents]\n']], ['How to iterate through a list of lists in python?'], 2, 1], [(9151104, 1), [['This is basically equivalent to the iterative version:'], ['This is however not really a general way of iterating through a multidimensional list with an arbitrary number of dimensions, since nested list comprehensions / nested for loops can get ugly; however you should be safe doing it for 2 or 3-d lists.']], [[' temp = []\nfor sub_list in documents:\n    temp.append(sub_list[0])\ndocuments = temp\n']], ['How to iterate through a list of lists in python?'], 2, 1], [(9232944, 1), [['You can use  numpy.savez  to save them, by key, to a compressed file:'], ['To load it back:']], [[" >>> numpy.savez('file.npz', **arrs)\n"]], ['How to save big (not huge) dictonaries in Python?'], 3, 1], [(9232944, 2), [['To load it back:'], ['-10000']], [[" >>> npzfile = numpy.load('file.npz')\n>>> npzfile\n<numpy.lib.npyio.NpzFile object at 0x1fa7610>\n>>> npzfile['a']\narray([1, 2])\n>>> npzfile['b']\narray([3, 4])\n>>> npzfile['c']\narray([5, 6])\n"]], ['How to save big (not huge) dictonaries in Python?'], 3, 0], [(9242450, 0), [['-10000'], ['yields']], [[" import itertools\nimport collections\n\ndef borda(ballot):\n    n = len([c for c in ballot if c.isalpha()]) - 1\n    score = itertools.count(n, step = -1)\n    result = {}\n    for group in [item.split('=') for item in ballot.split('>')]:\n        s = sum(next(score) for item in group)/float(len(group))\n        for pref in group:\n            result[pref] = s\n    return result\n\ndef tally(ballots):\n    result = collections.defaultdict(int)\n    for ballot in ballots:\n        for pref,score in borda(ballot).iteritems():\n            result[pref]+=score\n    result = dict(result)\n    return result\n\nballots = ['A>B>C>D>E',\n           'A>B>C=D=E',\n           'A>B=C>D>E', \n           ]\n\nprint(tally(ballots))\n"]], ['Borda Count using python?'], 2, 1], [(9242450, 1), [['yields'], ['-10000']], [[" {'A': 12.0, 'C': 5.5, 'B': 8.5, 'E': 1.0, 'D': 3.0}\n"]], ['Borda Count using python?'], 2, 0], [(9252871, 1), [['-10000'], ['-10000']], [['file2.py def action(name):\n    print name \n']], ['Calling variables from other files in Python'], 2, 0], [(9288169, 0), [['Your  text.split()  already produces an array of words, so you can do:'], ['As an example:']], [[' words = text.split()\ntotalwords = len(words)\n']], ['Python word length function example needed'], 2, 0], [(9288169, 1), [['As an example:'], ['-10000']], [[" '||'.join(['eggs','and','ham'])\n# returns 'eggs||and||ham'\n"]], ['Python word length function example needed'], 2, 0], [(9364754, 0), [['You could scroll to the actual previous values, like you are asking, but are you sure your results will always be the same size? Those numbers could be meaningless in terms of taking you to the right spot again. But just for reference, you would have to access the scroll bar, take its value, then perform your repopulation, and then scroll that value again:'], ['First save the current item by some criteria:']], [[' bar = treeWidget.verticalScrollBar()\nyScroll = bar.value()\n# repopulate here ...\ntreeWidget.scrollContentsBy(0, yScroll)\n']], ['Remembering Scroll value of a QTreeWidget in PyQt'], 3, 0], [(9364754, 1), [['First save the current item by some criteria:'], ['Once you have that data value, be it the text value or some other custom data value, you can repopulate your tree, then look up that item again.']], [[' item = treeWidget.currentItem() # one way\nitem = treeWidget.itemAt(centerOfTree) # another way\n\n# either save the text value or whatever the custom \n# identifying value is of your item\ntext = item.text()\n']], ['Remembering Scroll value of a QTreeWidget in PyQt'], 3, 0], [(9364754, 2), [['Once you have that data value, be it the text value or some other custom data value, you can repopulate your tree, then look up that item again.'], ['You can modify this to suit your actual type of items. You may be storing some other custom value on the items to find them again. ']], [[' # this is assuming the item is both present, \n# and referencing it by its string value\nnewItem = treeWidget.findItems(text)[0]\ntreeWidget.scrollToItem(newItem)\n']], ['Remembering Scroll value of a QTreeWidget in PyQt'], 3, 0], [(9394051, 0), [['-10000'], ['or as a list comprehension']], [[' >>> a = [[1,2,3],[4,5,6]]\n>>> from operator import itemgetter\n>>> map(itemgetter(0,2), a)\n[(1, 3), (4, 6)]\n>>> \n']], ['Get non-contiguous columns from a list of lists'], 2, 1], [(9394051, 1), [['or as a list comprehension'], ['-10000']], [[' >>> [itemgetter(0,2)(i) for i in a]\n[(1, 3), (4, 6)]\n']], ['Get non-contiguous columns from a list of lists'], 2, 1], [(9406400, 0), [['It looks like you are simply calling  get_cmap  wrong. Try:'], ['']], [[' from pylab import imshow, show, get_cmap\nfrom numpy import random\n\nZ = random.random((50,50))   # Test data\n\nimshow(Z, cmap=get_cmap("Spectral"), interpolation=\'nearest\')\nshow()\n']], ['How can I use a pre-made color map for my heat map in matplotlib?'], 3, 1], [(9406400, 1), [[''], ['Gives a list of colormaps, any of which can be substituted for  "Spectral" :']], [[' from pylab import cm\nprint cm.datad.keys()\n']], ['How can I use a pre-made color map for my heat map in matplotlib?'], 3, 0], [(9406400, 2), [['Gives a list of colormaps, any of which can be substituted for  "Spectral" :'], ['-10000']], [[" ['Spectral', 'summer', 'RdBu', 'Set1', 'Set2', 'Set3', 'brg_r', 'Dark2', 'hot', 'PuOr_r', 'afmhot_r', 'terrain_r', 'PuBuGn_r', 'RdPu', 'gist_ncar_r', 'gist_yarg_r', 'Dark2_r', 'YlGnBu', 'RdYlBu', 'hot_r', 'gist_rainbow_r', 'gist_stern', 'gnuplot_r', 'cool_r', 'cool', 'gray', 'copper_r', 'Greens_r', 'GnBu', 'gist_ncar', 'spring_r', 'gist_rainbow', 'RdYlBu_r', 'gist_heat_r', 'OrRd_r', 'bone', 'gist_stern_r', 'RdYlGn', 'Pastel2_r', 'spring', 'terrain', 'YlOrRd_r', 'Set2_r', 'winter_r', 'PuBu', 'RdGy_r', 'spectral', 'flag_r', 'jet_r', 'RdPu_r', 'Purples_r', 'gist_yarg', 'BuGn', 'Paired_r', 'hsv_r', 'bwr', 'YlOrRd', 'Greens', 'PRGn', 'gist_heat', 'spectral_r', 'Paired', 'hsv', 'Oranges_r', 'prism_r', 'Pastel2', 'Pastel1_r', 'Pastel1', 'gray_r', 'PuRd_r', 'Spectral_r', 'gnuplot2_r', 'BuPu', 'YlGnBu_r', 'copper', 'gist_earth_r', 'Set3_r', 'OrRd', 'PuBu_r', 'ocean_r', 'brg', 'gnuplot2', 'jet', 'bone_r', 'gist_earth', 'Oranges', 'RdYlGn_r', 'PiYG', 'YlGn', 'binary_r', 'gist_gray_r', 'Accent', 'BuPu_r', 'gist_gray', 'flag', 'seismic_r', 'RdBu_r', 'BrBG', 'Reds', 'BuGn_r', 'summer_r', 'GnBu_r', 'BrBG_r', 'Reds_r', 'RdGy', 'PuRd', 'Accent_r', 'Blues', 'Greys', 'autumn', 'PRGn_r', 'Greys_r', 'pink', 'binary', 'winter', 'gnuplot', 'pink_r', 'prism', 'YlOrBr', 'rainbow_r', 'rainbow', 'PiYG_r', 'YlGn_r', 'Blues_r', 'YlOrBr_r', 'seismic', 'Purples', 'bwr_r', 'autumn_r', 'ocean', 'Set1_r', 'PuOr', 'PuBuGn', 'afmhot']\n"]], ['How can I use a pre-made color map for my heat map in matplotlib?'], 3, 0], [(9410760, 0), [['You might be able to make use of the suggestion in  this post , summarised below:'], ['When run, the script prints:']], [[' import logging\n\nclass LoggerWriter:\n    def __init__(self, logger, level):\n        self.logger = logger\n        self.level = level\n\n    def write(self, message):\n        if message != \'\\n\':\n            self.logger.log(self.level, message)\n\ndef main():\n    logging.basicConfig(level=logging.DEBUG)\n    logger = logging.getLogger("demo")\n    info_fp = LoggerWriter(logger, logging.INFO)\n    debug_fp = LoggerWriter(logger, logging.DEBUG)\n    print >> info_fp, "An INFO message"\n    print >> debug_fp, "A DEBUG message"\n\nif __name__ == "__main__":\n    main()\n']], ['Redirect stdout to logger in Python'], 2, 1], [(9410760, 1), [['When run, the script prints:'], ['-10000']], [[' INFO:demo:An INFO message\nDEBUG:demo:An DEBUG message\n']], ['Redirect stdout to logger in Python'], 2, 0], [(9416934, 0), [["Thanks to @JoeKington for the suggestion. Here's the best I can come up with using  scipy.ndimage.map_coordinates"], ['Update: Added the tweaks suggested in the comments and tried one or two other things. This is the fastest version:']], [[' # rest as before\nfrom scipy import ndimage\ntic = time.time()\nnew_result = np.zeros(im.shape)\ncoords = np.array([yy,xx,np.zeros(im.shape[:2])])\nfor d in range(im.shape[2]):\n    new_result[:,:,d] = ndimage.map_coordinates(im,coords,order=1)\n    coords[2] += 1\ntoc = time.time()\nprint "interpolation time:",toc-tic\n']], ['Speeding up linear interpolation of many pixel locations in NumPy'], 3, 1], [(9416934, 1), [['Update: Added the tweaks suggested in the comments and tried one or two other things. This is the fastest version:'], ['Example running time:']], [[' tic = time.time()\nnew_result = np.zeros(im.shape)\ncoords = np.array([yy,xx])\nfor d in range(im.shape[2]):\n    ndimage.map_coordinates(im[:,:,d],\n                            coords,order=1,\n                            prefilter=False,\n                            output=new_result[:,:,d] )\ntoc = time.time()\n\nprint "interpolation time:",toc-tic\n']], ['Speeding up linear interpolation of many pixel locations in NumPy'], 3, 1], [(9416934, 2), [['Example running time:'], ['-10000']], [['  original version: 0.463063955307\n   better version: 0.204537153244\n     best version: 0.121845006943\n']], ['Speeding up linear interpolation of many pixel locations in NumPy'], 3, 0], [(9416947, 0), [["You don't need to mess around with descriptors.  It's enough to create a wrapper function inside the  __call__()  method and return it.  Standard Python functions can always act as either a method or a function, depending on context:"], ["A bit of explanation about what's going on when this decorator is used like this:"]], [[' class MyDecorator(object):\n    def __init__(self, argument):\n        self.arg = argument\n\n    def __call__(self, fn):\n        @functools.wraps(fn)\n        def decorated(*args, **kwargs):\n            print "In my decorator before call, with arg %s" % self.arg\n            fn(*args, **kwargs)\n            print "In my decorator after call, with arg %s" % self.arg\n        return decorated\n']], ['Python Class Based Decorator with parameters that can decorate a method or a function'], 2, 1], [(9416947, 1), [["A bit of explanation about what's going on when this decorator is used like this:"], ['The first line creates an instance of  MyDecorator  and passes  "some other func!"  as an argument to  __init__() .  Let\'s call this instance  my_decorator .  Next, the undecorated function object -- let\'s call it  bare_func  -- is created and passed to the decorator instance, so  my_decorator(bare_func)  is executed.  This will invoke  MyDecorator.__call__() , which will create and return a wrapper function.  Finally this wrapper function is assigned to the name  some_other_function .']], [[' @MyDecorator("some other func!")\ndef some_other_function():\n    print "in some other function!"\n']], ['Python Class Based Decorator with parameters that can decorate a method or a function'], 2, 0], [(9419848, 0), [['Assuming  address  contains your raw address.'], ["Then you can replace the break line with a comma, before finally splitting by comma. This is not ideal but for these scenarios when there is no clear separation between elements (spans, id's etc...) then it all comes down to positional checking. "]], [[' <p class="secondary">\n              Some address and street\n              <br />\n              City, State, ZIP\n              (some) phone-number\n             </p>\n']], ['Python - read BeautifulSoup snippet by row? (or other ways of scraping the data I want)'], 3, 0], [(9419848, 2), [['That gives you the following four components in the  addressComponents  list.'], ['-10000']], [[' addressSplit = addressComponents[3].split("\\n")\nprint addressSplit[0] # Zip code\nprint addressSplit[1].strip() # Phone number\n']], ['Python - read BeautifulSoup snippet by row? (or other ways of scraping the data I want)'], 3, 0], [(9456233, 0), [['If you want to sort the dictionary based on the integer value you can do the following.'], ['The  a  will contain a list of tuples:']], [[" d = {'secondly': 2, 'pardon': 6, 'saves': 1, 'knelt': 1}\na = sorted(d.iteritems(), key=lambda x:x[1], reverse=True)\n"]], ['Search and sort through dictionary in Python'], 2, 1], [(9456233, 1), [['The  a  will contain a list of tuples:'], ['Which you can limit to a top 50 by using  a[:50]  and then search through the keys, with youre search pattern.']], [[" [('pardon', 6), ('secondly', 2), ('saves', 1), ('knelt', 1)]\n"]], ['Search and sort through dictionary in Python'], 2, 0], [(9460992, 0), [['According to the documentation, Windows Progress common control has the next additional methods:'], ['If you need a text, use the following construction:']], [[' GetPosition()\nGetState()\nGetStep()\nSetPosition(pos)\nStepIt()\n']], ['progress bar properties python2.72 pywinauto'], 2, 0], [(9460992, 1), [['If you need a text, use the following construction:'], ['Also, you can easily view the properties and methods available through a GUI tool for pywinauto.']], [[" window['Progress1'].Texts()\n"]], ['progress bar properties python2.72 pywinauto'], 2, 1], [(9465236, 0), [['To create  ProxyFactory  that can modify server response headers, content you could override  ProxyClient.handle*()  methods :'], ['To run it as a script or via  twistd , add at the end:']], [[' from twisted.python import log\nfrom twisted.web import http, proxy\n\nclass ProxyClient(proxy.ProxyClient):\n    """Mangle returned header, content here.\n\n    Use `self.father` methods to modify request directly.\n    """\n    def handleHeader(self, key, value):\n        # change response header here\n        log.msg("Header: %s: %s" % (key, value))\n        proxy.ProxyClient.handleHeader(self, key, value)\n\n    def handleResponsePart(self, buffer):\n        # change response part here\n        log.msg("Content: %s" % (buffer[:50],))\n        # make all content upper case\n        proxy.ProxyClient.handleResponsePart(self, buffer.upper())\n\nclass ProxyClientFactory(proxy.ProxyClientFactory):\n    protocol = ProxyClient\n\nclass ProxyRequest(proxy.ProxyRequest):\n    protocols = dict(http=ProxyClientFactory)\n\nclass Proxy(proxy.Proxy):\n    requestFactory = ProxyRequest\n\nclass ProxyFactory(http.HTTPFactory):\n    protocol = Proxy\n']], ['Python - Twisted, Proxy and modifying content'], 4, 0], [(9465236, 1), [['To run it as a script or via  twistd , add at the end:'], ['-10000']], [[' portstr = "tcp:8080:interface=localhost" # serve on localhost:8080\n\nif __name__ == \'__main__\': # $ python proxy_modify_request.py\n    import sys\n    from twisted.internet import endpoints, reactor\n\n    def shutdown(reason, reactor, stopping=[]):\n        """Stop the reactor."""\n        if stopping: return\n        stopping.append(True)\n        if reason:\n            log.msg(reason.value)\n        reactor.callWhenRunning(reactor.stop)\n\n    log.startLogging(sys.stdout)\n    endpoint = endpoints.serverFromString(reactor, portstr)\n    d = endpoint.listen(ProxyFactory())\n    d.addErrback(shutdown, reactor)\n    reactor.run()\nelse: # $ twistd -ny proxy_modify_request.py\n    from twisted.application import service, strports\n\n    application = service.Application("proxy_modify_request")\n    strports.service(portstr, ProxyFactory()).setServiceParent(application)\n']], ['Python - Twisted, Proxy and modifying content'], 4, 0], [(9465236, 2), [['-10000'], ['In another terminal:']], [['Usage $ twistd -ny proxy_modify_request.py\n']], ['Python - Twisted, Proxy and modifying content'], 4, 0], [(9465236, 3), [['In another terminal:'], ['-10000']], [[' $ curl -x localhost:8080 http://example.com\n']], ['Python - Twisted, Proxy and modifying content'], 4, 0], [(9487389, 0), [["Don't change the length of a list while iterating over it. It won't work. "], ["See? The problem is that when you remove an item, the following items are all shifted back by one, but the location of the index remains the same. The effect is that the item after the removed item gets skipped. Depending on what you're doing, a list comprehension is preferable. "]], [[' >>> l = range(10)\n>>> for i in l:\n...     l.remove(i)\n... \n>>> l\n[1, 3, 5, 7, 9]\n']], ['python remove element from list while traversing it'], 2, 0], [(9504638, 0), [['You should  never test a boolean variable with  == True  (or  == False ) . Instead, either write:'], ['or use  any  (and in related problems its cousin  all ):']], [[' if not (var1 or var2 or var3 or var4):\n']], ["Evaluate multiple variables in one 'if' statement?"], 3, 1], [(9504638, 1), [['or use  any  (and in related problems its cousin  all ):'], ["or use Python's  transitive comparisons :"]], [[' if not any((var1, var2, var3, var4)):\n']], ["Evaluate multiple variables in one 'if' statement?"], 3, 1], [(9504638, 2), [["or use Python's  transitive comparisons :"], ['-10000']], [[' if var1 == var2 == var3 == var4 == False:\n']], ["Evaluate multiple variables in one 'if' statement?"], 3, 1], [(9538171, 0), [['Using the python non-numpy .sort() or sorted() on a list of lists (not numpy arrays) automatically does this e.g.'], ['gives']], [[' a = [[1,2,3],[2,3,1],[3,2,1],[1,3,2]]\na.sort()\n']], ['Acquiring the Minimum array out of Multiple Arrays by order in Python'], 3, 1], [(9538171, 1), [['gives'], ['The numpy sort seems to only sort the subarrays recursively so it seems the best way would be to convert it to a python list first. Assuming you have an array of arrays you want to pick the minimum of you could get the minimum as ']], [[' [[1,2,3],[1,3,2],[2,3,1],[3,2,1]]\n']], ['Acquiring the Minimum array out of Multiple Arrays by order in Python'], 3, 0], [(9542738, 0), [['This is the use case you describe: Checking whether something is inside a list or not. As you know, you can use the  in  operator for that:'], ['-10000']], [[' 3 in [1, 2, 3] # => True\n']], ['Python: Find in list'], 8, 1], [(9542738, 1), [['-10000'], ['The latter will return a  generator  which you can imagine as a sort of lazy list that will only be built as soon as you iterate through it. By the way, the first one is exactly equivalent to']], [[' matches = [x for x in lst if fulfills_some_condition(x)]\nmatches = (x for x in lst if x > 6)\n']], ['Python: Find in list'], 8, 1], [(9542738, 2), [['The latter will return a  generator  which you can imagine as a sort of lazy list that will only be built as soon as you iterate through it. By the way, the first one is exactly equivalent to'], ["in Python 2. Here you can see higher-order functions at work. In Python 3,  filter  doesn't return a list, but a generator-like object."]], [[' matches = filter(fulfills_some_condition, lst)\n']], ['Python: Find in list'], 8, 1], [(9542738, 3), [["in Python 2. Here you can see higher-order functions at work. In Python 3,  filter  doesn't return a list, but a generator-like object."], ['which will return the first match or raise a  StopIteration  if none is found. Alternatively, you can use']], [[' next(x for x in lst if ...)\n']], ['Python: Find in list'], 8, 1], [(9542738, 4), [['which will return the first match or raise a  StopIteration  if none is found. Alternatively, you can use'], ['-10000']], [[' next((x for x in lst if ...), [default value])\n']], ['Python: Find in list'], 8, 1], [(9542738, 5), [['-10000'], ['However, note that if you have duplicates,  .index  always returns the lowest index:......']], [[' [1,2,3].index(2) # => 1\n[1,2,3].index(4) # => ValueError\n']], ['Python: Find in list'], 8, 1], [(9575384, 0), [['If you want something that will do exactly what you want, you can do:'], ['Then:']], [[' def zipMap(func, iterable):\n    for x in iterable:\n        yield x,func(x)\n']], ['Combine variable and for each loop python'], 4, 0], [(9575384, 1), [['Then:'], ["Do note that this doesn't save you any typing at all. The only way it would save you typing is if you were using it for  currying :"]], [[' for x,y in zipMap(get_handler, the_list):\n    ...\n']], ['Combine variable and for each loop python'], 4, 0], [(9575384, 2), [["Do note that this doesn't save you any typing at all. The only way it would save you typing is if you were using it for  currying :"], ['In which case it  does  save you typing:']], [[' def withHandler(iterable):\n    for x in iterable:\n        yield x,get_handler(x)\n']], ['Combine variable and for each loop python'], 4, 0], [(9575384, 3), [['In which case it  does  save you typing:'], ['Thus it might be reasonable if you happened to use it a lot. It would not be considered "pythonic" though.']], [[' for x,y in withHandler(the_list):\n    ...\n']], ['Combine variable and for each loop python'], 4, 0], [(9630668, 0), [['calendar.timegm  is the good approach. Just pass it the  utctimetuple()  output from your datetime object:'], ['prints ']], [[' from datetime import datetime\nimport pytz\nimport calendar\n\ndt = datetime.now(pytz.utc)\nsecs = calendar.timegm(dt.utctimetuple())\nprint dt, secs\n']], ['Convert date to second from a reference - Python'], 3, 1], [(9630668, 1), [['prints '], ['just to test it against the epoch:']], [[' 2012-03-09 09:17:14.698500+00:00 1331284634\n']], ['Convert date to second from a reference - Python'], 3, 0], [(9630668, 2), [['just to test it against the epoch:'], ['prints  0 .']], [[' print calendar.timegm(datetime(1970, 1, 1, 0, 0, 0, tzinfo=pytz.utc).utctimetuple())\n']], ['Convert date to second from a reference - Python'], 3, 0], [(9668867, 0), [["I don't think you actually need a regular expression at all, you can just use  endswith .  Here's how I would implement it.  Its not extensible, but it does what you want:"], ["Since you know that  START  happens 5 lines after  PATTERN  there's no need to search for it, so instead I used  assert  to make sure that it is where expected.  The lines matching are stored to  found , and you can print them out nicely with "]], [[" matching = False\nfound = []\nwith open('fileinput.txt', 'r') as file\n    it = iter(file)\n    for line in it:\n        if matching:\n            if line.strip() == '':\n                break\n            else:\n                found.append(line)\n        elif line.endswith('PATTERN:'):\n            for _ in range(6):\n                next(it)\n            matching = True\n"]], ['read snippet of file with regular expressions from text file in python'], 2, 1], [(9668867, 1), [["Since you know that  START  happens 5 lines after  PATTERN  there's no need to search for it, so instead I used  assert  to make sure that it is where expected.  The lines matching are stored to  found , and you can print them out nicely with "], ['-10000']], [[' for line in found:\n    print line\n']], ['read snippet of file with regular expressions from text file in python'], 2, 0], [(9670866, 0), [['You could do something like:'], ['Then, you can access it like any other attribute on your model']], [[' class MyModel(models.Model):\n    ...\n    @property\n    def priority(self):\n        return (1 + (date.today() - self.reset_date) / self.days_to_expiration) * self.importance\n']], ['Dynamic field calculations in Django'], 2, 0], [(9670866, 1), [['Then, you can access it like any other attribute on your model'], ['-10000']], [[' priority = my_model.priority\n']], ['Dynamic field calculations in Django'], 2, 0], [(9671165, 0), [['You can try this:'], ['Since you have a header, then the data and then one extra line, you can skip the header lines and then process only the ones that have the right amount of columns.']], [[" inputFile = open(path,'r')\nfor n, line in enumerate(inputFile):\n    if n > given_number:\n       variableX = line.split(' ')[5]\ninputFile.close()\n"]], ['Open txt file, skip first lines and then monitor a given column of data'], 2, 0], [(9671165, 1), [['Since you have a header, then the data and then one extra line, you can skip the header lines and then process only the ones that have the right amount of columns.'], ['-10000']], [[" inputFile = open(path,'r')\nhead_lines = 4\nfor n, line in enumerate(inputFile):\n    if n > head_lines:\n       cols = line.split()\n       if len(cols) == 9:               \n           variableX = cols[7]\n           # do whatever you need with variableX\ninputFile.close()\n"]], ['Open txt file, skip first lines and then monitor a given column of data'], 2, 1], [(9706041, 0), [['Try the following:'], ['For example:']], [[' min(range(len(a)), key=lambda i: abs(a[i]-11.5))\n']], ["finding index of an item closest to the value in a list that's not entirely sorted"], 3, 1], [(9706041, 1), [['For example:'], ['Or to get the index and the value:']], [[' >>> a = [25.75443, 26.7803, 25.79099, 24.17642, 24.3526, 22.79056, 20.84866, 19.49222, 18.38086, 18.0358, 16.57819, 15.71255, 14.79059, 13.64154, 13.09409, 12.18347, 11.33447, 10.32184, 9.544922, 8.813385, 8.181152, 6.983734, 6.048035, 5.505096, 4.65799]\n>>> min(range(len(a)), key=lambda i: abs(a[i]-11.5))\n16\n']], ["finding index of an item closest to the value in a list that's not entirely sorted"], 3, 1], [(9706041, 2), [['Or to get the index and the value:'], ['-10000']], [[' >>> min(enumerate(a), key=lambda x: abs(x[1]-11.5))\n(16, 11.33447)\n']], ["finding index of an item closest to the value in a list that's not entirely sorted"], 3, 1], [(9761554, 0), [["I'd say you get the model:"], ['You could get first row by doing:']], [[' model = self.treeview.get_model()\n']], ['How to get a list of the elements in TreeView? PyGtk'], 2, 1], [(9761554, 1), [['You could get first row by doing:'], ['And also you could iterate through it...']], [[' model[0]\n']], ['How to get a list of the elements in TreeView? PyGtk'], 2, 0], [(9761562, 0), [["The  %  (modulus) operator gives you the remainder of a division. If that remainder is 0, then  the second multiple is a factor of the second. So just loop through all the numbers from  1  to  n  and check if they're factors; if so, add them to the list with  append :"], ['Or, more concisely using lambdas:']], [[' def factors(n):\n    result = []\n\n    for i in range(1, n + 1):\n        if n % i == 0:\n            result.append(i)\n\n    return result\n']], ['How many factors in an integer'], 2, 1], [(9761562, 1), [['Or, more concisely using lambdas:'], ["Here's a demo."]], [[' def factors(n):\n    return filter(lambda i: n % i == 0, range(1, n + 1))\n']], ['How many factors in an integer'], 2, 1], [(9787427, 0), [['The following regex will match gmails prefix in a pretty safe manner. It ensures that there are 3 commas and the liter text On ... wrote'], ["If the regex should match in a case insensitve way then don't forget to add the modifier."]], [[' On([^,]+,){3}.*?wrote:\n']], ['What would be a good regexp for identifying the "original message" prefix in gmail?'], 3, 1], [(9787427, 1), [["If the regex should match in a case insensitve way then don't forget to add the modifier."], ['Kind Regards, Buckley']], [[' if re.search("On([^,]+,){3}.*?wrote:", subject, re.IGNORECASE):\n    # Successful match\nelse:\n    # Match attempt failed\n']], ['What would be a good regexp for identifying the "original message" prefix in gmail?'], 3, 1], [(9787427, 2), [['Kind Regards, Buckley'], ['-10000']], [[' Match the characters “On” literally «On»\nMatch the regular expression below and capture its match into backreference number 1 «([^,]+,){3}»\n   Exactly 3 times «{3}»\n   Note: You repeated the capturing group itself.  The group will capture only the last iteration.  Put a capturing group around the repeated group to capture all iterations. «{3}»\n   Match any character that is NOT a “,” «[^,]+»\n      Between one and unlimited times, as many times as possible, giving back as needed (greedy) «+»\n   Match the character “,” literally «,»\nMatch any single character that is not a line break character «.*?»\n   Between zero and unlimited times, as few times as possible, expanding as needed (lazy) «*?»\nMatch the characters “wrote:” literally «wrote:»\n\nCreated with RegexBuddy\n']], ['What would be a good regexp for identifying the "original message" prefix in gmail?'], 3, 0], [(9849828, 0), [["Print  '#'  if  red  else print  '.' . If encounted sequence  red , not  red  then print  '.'  for the rest of the array:"], ['-10000']], [[" prev = None\nit = iter(data)\nfor point in it:\n    if point == 'red':\n       print '#',\n    else:\n       print '.',\n       if prev == 'red': # encounted ['red', 'blank']\n          break\n    prev = point\n\nfor point in it:\n    print '.',\nprint\n"]], ['running through a loop and find a condition that match'], 2, 1], [(9849828, 1), [['-10000'], ['-10000']], [['<a href="http://ideone.com/E46gz" rel="nofollow">Example</a> blank blank red red blank red blank red red\n. . # # . . . . .\n']], ['running through a loop and find a condition that match'], 2, 0], [(9857382, 0), [["Most importantly, if you're passing data to the client that will then be sent back in a form, you should make sure that the data coming in is the same as the data that went out (for security's sake). Do this with at  clean_[field]  function on the Form. It should look like the following."], ['-10000']], [[" class MyForm(forms.ModelForm):\n    class Meta:\n        model = MyModel\n    def clean_date_created(self):\n        if self.cleaned_fields['date_created'] != self.instance.date_created:\n            raise ValidationError, 'date_created has been tampered'\n        self.cleaned_fields['date_created']\n"]], ['Django Form with extra information'], 2, 1], [(9857382, 1), [['-10000'], ['-10000']], [[' def recieve_form(request, ...):\n    ...\n    f = MyForm(request.POST, instance=a)\n    new_model_instance = f.save(commit=False)\n    new_model_instance.date_created = <whatever>\n    new_model_instance.save()\n']], ['Django Form with extra information'], 2, 1], [(9897007, 0), [["Not sure if you're still having problems with this but here's an answer that I believe would work for you:"], ['Output:']], [[' #location_regexes.py\nimport re\nparen_pattern = re.compile(r"([^(]+, )?([^(]+?),? \\(([^)]+)\\)")\n\ndef parse_city_state(locations_list):\n    city_list = []\n    state_list = []\n    coordinate_pairs = []\n    for location in locations_list:\n        if \'(\' in location:\n            r = re.match(paren_pattern, location)\n            city_list.append(r.group(2))\n            state_list.append(r.group(3))\n        elif location[0].isdigit() or location[0] == \'-\':\n            coordinate_pairs.append(location.split(\', \'))\n        else:\n            city_list.append(location.split(\', \', 1)[0])\n            state_list.append(location.split(\', \', 1)[1])\n    return city_list, state_list, coordinate_pairs\n\n#to demonstrate output\nif __name__ == "__main__":\n    locations = [\'Washington, DC\', \'Miami, FL\', \'New York, NY\',\n                \'Kaslo/Nelson area (Canada), BC\', \'Plymouth (UK/England)\',\n                \'Mexico, DF - outskirts-, (Mexico),\', \'38.206471, -111.165271\']\n\n    for parse_group in parse_city_state(locations):\n        print parse_group\n']], ['Split string elements of a list with multiple separators/conditions. Any good Python library?'], 2, 1], [(9897007, 1), [['Output:'], ['-10000']], [[" $ python location_regexes.py \n['Washington', 'Miami', 'New York', 'Kaslo/Nelson area', 'Plymouth', 'DF - outskirts-']\n['DC', 'FL', 'NY', 'Canada', 'UK/England', 'Mexico']\n[['38.206471', '-111.165271']]\n"]], ['Split string elements of a list with multiple separators/conditions. Any good Python library?'], 2, 0], [(9950474, 0), [['project_root/SConstruct'], ['libfoo_subrepo/SConstruct']], [[" # This SConstruct orchestrates building 3 subdirs\n\nimport os\n\nsubdirs = ['libfoo_subrepo', 'barapp_subrepo', 'test']\nenv = Environment()\n\nfor subdir in subdirs:\n    SConscript(os.path.join(subdir, 'SConscript'), exports = ['env'])\n"]], ['Real Hierarchical Builds with SCons?'], 5, 0], [(9950474, 1), [['libfoo_subrepo/SConstruct'], ['libfoo_subrepo/SConscript']], [[" # This SConstruct does nothing more than load the SConscript in this dir\n# The Environment() is created in the SConstruct script\n# This dir can be built standalone by executing scons here, or together\n# by executing scons in the parent directory\nenv = Environment()\nSConscript('SConscript', exports = ['env'])\n"]], ['Real Hierarchical Builds with SCons?'], 5, 0], [(9950474, 2), [['libfoo_subrepo/SConscript'], ['barapp_subrepo/SConstruct']], [[" # This SConstruct orchestrates building 2 subdirs\nimport os\n\nImport('env')\nsubdirs = ['src', 'test']\n\nfor subdir in subdirs:\n    SConscript(os.path.join(subdir, 'SConscript'), exports = ['env'])\n"]], ['Real Hierarchical Builds with SCons?'], 5, 0], [(9950474, 3), [['barapp_subrepo/SConstruct'], ['barapp_subrepo/SConscript']], [[" # This SConstruct does nothing more than load the SConscript in this dir\n# The Environment() is created in the SConstruct script\n# This dir can be build standalone by executing scons here, or together\n# by executing scons in the parent directory\nenv = Environment()\nSConscript('SConscript', exports = ['env'])\n"]], ['Real Hierarchical Builds with SCons?'], 5, 0], [(9950474, 4), [['barapp_subrepo/SConscript'], ['I hope the comments in each file explains its purpose.']], [[" # This SConstruct orchestrates building 2 subdirs\nimport os\n\nImport('env')\nsubdirs = ['src', 'test']\n\nfor subdir in subdirs:\n    SConscript(os.path.join(subdir, 'SConscript'), exports = ['env'])\n"]], ['Real Hierarchical Builds with SCons?'], 5, 0], [(9969684, 0), [['A simple way would be:'], ['If you need more spaces, simply add them to the string:']], [[" print str(count) + '  ' + str(conv)\n"]], ['How do I add space between two variables after a print in Python'], 4, 1], [(9969684, 1), [['If you need more spaces, simply add them to the string:'], ['A fancier way, using the new syntax for string formatting:']], [[" print str(count) + '    ' + str(conv)\n"]], ['How do I add space between two variables after a print in Python'], 4, 1], [(9969684, 2), [['A fancier way, using the new syntax for string formatting:'], ['Or using the old syntax, limiting the number of decimals to two:']], [[" print '{0}  {1}'.format(count, conv)\n"]], ['How do I add space between two variables after a print in Python'], 4, 1], [(9969684, 3), [['Or using the old syntax, limiting the number of decimals to two:'], ['-10000']], [[" print '%d  %.2f' % (count, conv)\n"]], ['How do I add space between two variables after a print in Python'], 4, 1], [(10001301, 0), [['You can do this concisely using a list comprehension or generator expression:'], ['Or an alternative that comes from the documentation for  zip() :']], [[" >>> myl = ['A','B','C','D','E','F']\n>>> [''.join(myl[i:i+2]) for i in range(0, len(myl), 2)]\n['AB', 'CD', 'EF']\n>>> print '\\n'.join(''.join(myl[i:i+2]) for i in range(0, len(myl), 2))\nAB\nCD\nEF\n"]], ['List Slicing python'], 2, 1], [(10001301, 1), [['Or an alternative that comes from the documentation for  zip() :'], ['-10000']], [[" >>> map(''.join, zip(*[iter(myl)]*2))\n['AB', 'CD', 'EF']\n"]], ['List Slicing python'], 2, 1], [(10014572, 0), [['-10000'], ['As for the section, you can have a look to this  answer']], [['Case 1: you want to open the file in Python from pyPdf import PdfFileReader, PageObject\n\npdf_toread = PdfFileReader(path_to_your_pdf)\n\n# 1 is the number of the page\npage_one = pdf_toread.getPage(1)\n\n# This will dump the content (unicode string)\n# According to the doc, the formatting is dependent on the\n# structure of the document\nprint page_one.extractText()\n']], ['Python - open pdf file to specific page/section'], 2, 0], [(10024640, 1), [['If you save this as  filemod.pl  you can make doxygen use the filter for each input file by setting the following in the configuration file:'], ['-10000']], [[' INPUT_FILTER = "perl filemod.pl"\n']], ['Automatically Insert file-modification-time after @date command'], 2, 0], [(10040037, 0), [['You can make the template code a lot easier to read if you provide the data as a table in your dictionary. It would look more like this:'], ['You can now iterate over the headers as follows:']], [[" field = {\n    'headers': [u'Birthday:', u'Education', u'Job', u'Child Sex'],\n    'rows': [[datetime.date(2012, 4, 6), u'A1', u'job1', u'M']\n            ,[datetime.date(2012, 4, 27), u'A2', u'job2', u'F']]\n}\n"]], ['Dictionary As Table In Django Template'], 6, 0], [(10040037, 1), [['You can now iterate over the headers as follows:'], ['And each row can be displayed using:']], [[' <tr>\n{% for header in field.headers %}\n    <th>{{ header }}</th>\n{% endfor %}\n</tr>\n']], ['Dictionary As Table In Django Template'], 6, 0], [(10040037, 2), [['And each row can be displayed using:'], ["Now, you can obtain the  'headers'  value using  field.keys() :"]], [[' <tr>    \n{% for value in field.rows %}\n    <td>{{ value }}</td>\n{% endfor %}\n</tr>\n']], ['Dictionary As Table In Django Template'], 6, 0], [(10040037, 3), [["Now, you can obtain the  'headers'  value using  field.keys() :"], ["You can get the  'values'  using the following loop (where  2  is the number of rows):"]], [[" [u'Birthday:', u'Education', u'Job:', u'Child Sex:']\n"]], ['Dictionary As Table In Django Template'], 6, 0], [(10040037, 4), [["You can get the  'values'  using the following loop (where  2  is the number of rows):"], ['Or as a one-liner:']], [[' rows = []\nfor i in xrange(2):\n    row = []\n    for k in field.keys():\n        row.append(field[k][i])\n    rows.append(row)\n']], ['Dictionary As Table In Django Template'], 6, 0], [(10040037, 5), [['Or as a one-liner:'], ['-10000']], [[' rows = [[field[k][i] for k in field.keys()] for i in xrange(2)]\n']], ['Dictionary As Table In Django Template'], 6, 0], [(10048069, 1), [['If you  really need  the remainder (which is a bit of a code smell, IMHO), at least you can  pop()  from the end of the list now (which is fast!):'], ['In general, you can often express your programs more elegantly if you use a more functional style, instead of mutating state (like you do with the list).']], [[' while lst:\n  x = lst.pop()\n  # do something with the element      \n']], ['What is the most pythonic way to pop a random element from a list?'], 2, 1], [(10099326, 0), [['Other modules can be imported to  sandbox  (you mean modules that are created dynamically at runtime) by'], ['or:']], [["     sandbox.other_module = __import__('other_module')\n"]], ['how to do an embedded python module for remote sandbox execution?'], 4, 1], [(10099326, 1), [['or:'], ['Classes']], [["     exec 'import other_module' in sandbox.__dict__\n"]], ['how to do an embedded python module for remote sandbox execution?'], 4, 1], [(10099326, 2), [['Classes'], ["It seems that reloading methods can be easy. I remember that reloading classes defined in a modified source code can be complicated because the old class code can be held by some instance. The instance's code can/need be updated individually in the worst case:"]], [[' >>> class A(object): pass\n... \n>>> a = A()\n>>> A.f = lambda self, x: 2 * x  # or a pickled function\n>>> a.f(1)\n2\n>>> A.f = lambda self, x: 3 * x\n>>> a.f(1)\n3\n']], ['how to do an embedded python module for remote sandbox execution?'], 4, 0], [(10099326, 3), [["It seems that reloading methods can be easy. I remember that reloading classes defined in a modified source code can be complicated because the old class code can be held by some instance. The instance's code can/need be updated individually in the worst case:"], ['I used the latter with a python service accessed via win32com automation and reloading of classes code was succesful without loss instances data']], [['     some_instance.__class__ = sandbox.SomeClass  # that means the same reloaded class\n']], ['how to do an embedded python module for remote sandbox execution?'], 4, 0], [(10099710, 0), [['To change the empty label:'], ['As for your second query, it is also explained the in docs:']], [[' empty_label\n\n    By default the <select> widget used by ModelChoiceField\n    will have an empty choice at the top of the list. You can change the text\n    of this label (which is "---------" by default) with the empty_label\n    attribute, or you can disable the empty label entirely by setting\n    empty_label to None:\n\n    # A custom empty label\n    field1 = forms.ModelChoiceField(queryset=..., empty_label="(Nothing)")\n\n    # No empty label\n    field2 = forms.ModelChoiceField(queryset=..., empty_label=None)\n']], ['How to manually create a select field from a ModelForm in Django?'], 3, 0], [(10099710, 1), [['As for your second query, it is also explained the in docs:'], ['In the end, you should have something like this:']], [[' The __unicode__ method of the model will be called to generate string\nrepresentations of the objects for use in the field\'s choices;\nto provide customized representations, subclass ModelChoiceField and override\nlabel_from_instance. This method will receive a model object, and should return\na string suitable for representing it. For example:\n\nclass MyModelChoiceField(ModelChoiceField):\n    def label_from_instance(self, obj):\n        return "My Object #%i" % obj.id\n']], ['How to manually create a select field from a ModelForm in Django?'], 3, 0], [(10108070, 0), [['How about'], ['or, if you prefer bit twiddling,']], [[' if x < 0:\n   x += 2 ** 64\n']], ['reinterpret signed long as unsigned in Python'], 2, 1], [(10108070, 1), [['or, if you prefer bit twiddling,'], ['-10000']], [[' x &= 2 ** 64 - 1\n']], ['reinterpret signed long as unsigned in Python'], 2, 1], [(10108368, 0), [['The python code emits functions for R: map() and rect().  This USA example map was created with:'], ["and then you can apply the rect()'s accordingly from with in the R GUI interpreter (see below)."]], [[" map('state', plot = TRUE, fill = FALSE, col = palette())\n"]], ['Detecting geographic clusters'], 9, 0], [(10108368, 2), [['Here is an example TSV file (site.tsv)'], ['With my data set, the output of my python script, shown on the USA map.  I changed the colors for clarity.']], [[' LAT     LONG\n36.3312 -94.1334\n36.6828 -121.791\n37.2307 -121.96\n37.3857 -122.026\n37.3857 -122.026\n37.3857 -122.026\n37.3895 -97.644\n37.3992 -122.139\n37.3992 -122.139\n37.402  -122.078\n37.402  -122.078\n37.402  -122.078\n37.402  -122.078\n37.402  -122.078\n37.48   -122.144\n37.48   -122.144\n37.55   126.967\n']], ['Detecting geographic clusters'], 9, 0], [(10108368, 3), [['With my data set, the output of my python script, shown on the USA map.  I changed the colors for clarity.'], ['-10000']], [[' rect(-74.989,39.7667, -73.0419,41.5209, col=c("red"))\nrect(-123.005,36.8144, -121.392,38.3672, col=c("green"))\nrect(-78.2422,38.2474, -76.3,39.9282, col=c("blue"))\n']], ['Detecting geographic clusters'], 9, 0], [(10108368, 4), [['-10000'], ['If you want to narrow in on a portion of a map, you can use  ylim  and  xlim']], [[' map("county", plot=T )\nrect(-122.644,36.7307, -121.46,37.98, col=c("red"))\n']], ['Detecting geographic clusters'], 9, 0], [(10108368, 5), [['If you want to narrow in on a portion of a map, you can use  ylim  and  xlim'], ["You will want to use the 'world' map..."]], [[' map("county", plot=T, ylim=c(36.7307,37.98), xlim=c(-122.644,-121.46))\n# or for more coloring, but choose one or the other map("country") commands\nmap("county", plot=T, fill=T, col=palette(), ylim=c(36.7307,37.98), xlim=c(-122.644,-121.46))\nrect(-122.644,36.7307, -121.46,37.98, col=c("red"))\n']], ['Detecting geographic clusters'], 9, 0], [(10108368, 6), [["You will want to use the 'world' map..."], ['It has been a long time since I have used this python code I have posted below so I will try my best to help you.']], [[' map("world", plot=T )\n']], ['Detecting geographic clusters'], 9, 0], [(10108368, 7), [['It has been a long time since I have used this python code I have posted below so I will try my best to help you.'], ['Here is a complete example.  The TSV file is located on pastebin.com.  I have also included an image generated from R that contains the output of all of the rect() commands.']], [[' threshhold_dist is the size of the bounding box, ie: the geographical area\ntheshhold_location is the number of lat/lng points needed with in\n    the bounding box in order for it to be considered a cluster.\n']], ['Detecting geographic clusters'], 9, 0], [(10108368, 8), [['Here is a complete example.  The TSV file is located on pastebin.com.  I have also included an image generated from R that contains the output of all of the rect() commands.'], ['']], [[' # pyclusters.py\n# May-02-2013\n# -John Taylor\n\n# latlng.tsv is located at http://pastebin.com/cyvEdx3V\n# use the "RAW Paste Data" to preserve the tab characters\n\nimport math\nfrom collections import defaultdict\n\n# See also: http://www.geomidpoint.com/example.html\n# See also: http://www.movable-type.co.uk/scripts/latlong.html\n\nto_rad = math.pi / 180.0  # convert lat or lng to radians\nfname = "latlng.tsv"      # file format: LAT\\tLONG\nthreshhold_dist=20        # adjust to your needs\nthreshhold_locations=20   # minimum # of locations needed in a cluster\nearth_radius_km = 6371\n\ndef coord2cart(lat,lng):\n    x = math.cos(lat) * math.cos(lng)\n    y = math.cos(lat) * math.sin(lng)\n    z = math.sin(lat)\n    return (x,y,z)\n\ndef cart2corrd(x,y,z):\n    lon = math.atan2(y,x)\n    hyp = math.sqrt(x*x + y*y)\n    lat = math.atan2(z,hyp)\n    return(lat,lng)\n\ndef dist(lat1,lng1,lat2,lng2):\n    global to_rad, earth_radius_km\n\n    dLat = (lat2-lat1) * to_rad\n    dLon = (lng2-lng1) * to_rad\n    lat1_rad = lat1 * to_rad\n    lat2_rad = lat2 * to_rad\n\n    a = math.sin(dLat/2) * math.sin(dLat/2) + math.sin(dLon/2) * math.sin(dLon/2) * math.cos(lat1_rad) * math.cos(lat2_rad)\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a)); \n    dist = earth_radius_km * c\n    return dist\n\ndef bounding_box(src, neighbors):\n    neighbors.append(src)\n    # nw = NorthWest se=SouthEast\n    nw_lat = -360\n    nw_lng = 360\n    se_lat = 360\n    se_lng = -360\n\n    for (y,x) in neighbors:\n        if y > nw_lat: nw_lat = y\n        if x > se_lng: se_lng = x\n\n        if y < se_lat: se_lat = y\n        if x < nw_lng: nw_lng = x\n\n    # add some padding\n    pad = 0.5\n    nw_lat += pad\n    nw_lng -= pad\n    se_lat -= pad\n    se_lng += pad\n\n    #print("answer:")\n    #print("nw lat,lng : %s %s" % (nw_lat,nw_lng))\n    #print("se lat,lng : %s %s" % (se_lat,se_lng))\n\n    # sutiable for r\'s map() function\n    return (se_lat,nw_lat,nw_lng,se_lng)\n\ndef sitesDist(site1,site2): \n    # just a helper to shorted list comprehensioin below \n    return dist(site1[0],site1[1], site2[0], site2[1])\n\ndef load_site_data():\n    global fname\n    sites = defaultdict(tuple)\n\n    data = open(fname,encoding="latin-1")\n    data.readline() # skip header\n    for line in data:\n        line = line[:-1]\n        slots = line.split("\\t")\n        lat = float(slots[0])\n        lng = float(slots[1])\n        lat_rad = lat * math.pi / 180.0\n        lng_rad = lng * math.pi / 180.0\n        sites[(lat,lng)] = (lat,lng) #(lat_rad,lng_rad)\n    return sites\n\ndef main():\n    color_list = ( "red", "blue", "green", "yellow", "orange", "brown", "pink", "purple" )\n    color_idx = 0\n    sites_dict = {}\n    sites = load_site_data()\n    for site in sites: \n        #for each site put it in a dictionarry with its value being an array of neighbors \n        sites_dict[site] = [x for x in sites if x != site and sitesDist(site,x) < threshhold_dist] \n\n    print("")\n    print(\'map("state", plot=T)\') # or use: county instead of state\n    print("")\n\n\n    results = {}\n    for site in sites: \n        j = len(sites_dict[site])\n        if j >= threshhold_locations:\n            coord = bounding_box( site, sites_dict[site] )\n            results[coord] = coord\n\n    for bbox in results:\n        yx="ylim=c(%s,%s), xlim=c(%s,%s)" % (results[bbox]) #(se_lat,nw_lat,nw_lng,se_lng)\n\n        # important!\n        # if you want an individual map for each cluster, uncomment this line\n        #print(\'map("county", plot=T, fill=T, col=palette(), %s)\' % yx)\n        if len(color_list) == color_idx:\n            color_idx = 0\n        rect=\'rect(%s,%s, %s,%s, col=c("%s"))\' % (results[bbox][2], results[bbox][0], results[bbox][3], results[bbox][1], color_list[color_idx])\n        color_idx += 1\n        print(rect)\n    print("")\n\n\nmain()\n']], ['Detecting geographic clusters'], 9, 1], [(10112614, 0), [['The common way is the  format()  function:'], ['You can also pass a dictionary with variables:']], [[' >>> s = "This is an {example} with {vars}".format(vars="variables", example="example")\n>>> s\n\'This is an example with variables\'\n']], ['How do I create a multiline Python string with inline variables?'], 3, 1], [(10112614, 1), [['You can also pass a dictionary with variables:'], ['The closest thing to what you asked (in terms of syntax) are  template strings . For example:']], [[' >>> d = { \'vars\': "variables", \'example\': "example" }\n>>> s = "This is an {example} with {vars}"\n>>> s.format(**d)\n\'This is an example with variables\'\n']], ['How do I create a multiline Python string with inline variables?'], 3, 1], [(10112614, 2), [['The closest thing to what you asked (in terms of syntax) are  template strings . For example:'], ["I should add though that the  format()  function is more common because it's readily available and it does not require an import line."]], [[' >>> from string import Template\n>>> t = Template("This is an $example with $vars")\n>>> t.substitute({ \'example\': "example", \'vars\': "variables"})\n\'This is an example with variables\'\n']], ['How do I create a multiline Python string with inline variables?'], 3, 1], [(10126668, 0), [['setup.py :'], ['TestClass :']], [[' from distutils.core import setup\nfrom distutils.extension import Extension\nfrom Cython.Distutils import build_ext\n\nsetup(\n    cmdclass = {\'build_ext\': build_ext},\n    ext_modules = [\n    Extension("elps", \n              sources=["elps.pyx", "src/ITestClass.cpp"],\n              libraries=["elp"],\n              language="c++",\n              )\n    ]\n)\n']], ['Can I override a C++ virtual function within Python with Cython?'], 7, 0], [(10126668, 1), [['TestClass :'], ['ITestClass.h :']], [[' #ifndef TESTCLASS_H_\n#define TESTCLASS_H_\n\n\nnamespace elps {\n\nclass TestClass {\n\npublic:\n    TestClass(){};\n    virtual ~TestClass(){};\n\n    int getA() { return this->a; };\n    virtual int override_me() { return 2; };\n    int calculate(int a) { return a * this->override_me(); }\n\nprivate:\n    int a;\n\n};\n\n} /* namespace elps */\n#endif /* TESTCLASS_H_ */\n']], ['Can I override a C++ virtual function within Python with Cython?'], 7, 0], [(10126668, 2), [['ITestClass.h :'], ['ITestClass.cpp :']], [[' #ifndef ITESTCLASS_H_\n#define ITESTCLASS_H_\n\n// Created by Cython when providing \'public api\' keywords\n#include "../elps_api.h"\n\n#include "../../inc/TestClass.h"\n\nnamespace elps {\n\nclass ITestClass : public TestClass {\npublic:\n    PyObject *m_obj;\n\n    ITestClass(PyObject *obj);\n    virtual ~ITestClass();\n    virtual int override_me();\n};\n\n} /* namespace elps */\n#endif /* ITESTCLASS_H_ */\n']], ['Can I override a C++ virtual function within Python with Cython?'], 7, 0], [(10126668, 3), [['ITestClass.cpp :'], ['Extension : elps.pyx :']], [[' #include "ITestClass.h"\n\nnamespace elps {\n\nITestClass::ITestClass(PyObject *obj): m_obj(obj) {\n    // Provided by "elps_api.h"\n    if (import_elps()) {\n    } else {\n        Py_XINCREF(this->m_obj);\n    }\n}\n\nITestClass::~ITestClass() {\n    Py_XDECREF(this->m_obj);\n}\n\nint ITestClass::override_me()\n{\n    if (this->m_obj) {\n        int error;\n        // Call a virtual overload, if it exists\n        int result = cy_call_func(this->m_obj, (char*)"override_me", &error);\n        if (error)\n            // Call parent method\n            result = TestClass::override_me();\n        return result;\n    }\n    // Throw error ?\n    return 0;\n}\n\n} /* namespace elps */\n']], ['Can I override a C++ virtual function within Python with Cython?'], 7, 0], [(10126668, 4), [['Extension : elps.pyx :'], ['Finally, the python calls :']], [[' cimport cpython.ref as cpy_ref\n\ncdef extern from "src/ITestClass.h" namespace "elps" :\n    cdef cppclass ITestClass:\n        ITestClass(cpy_ref.PyObject *obj)\n        int getA()\n        int override_me()\n        int calculate(int a)\n\ncdef class PyTestClass:\n    cdef ITestClass* thisptr\n\n    def __cinit__(self):\n       ##print "in TestClass: allocating thisptr"\n       self.thisptr = new ITestClass(<cpy_ref.PyObject*>self)\n    def __dealloc__(self):\n       if self.thisptr:\n           ##print "in TestClass: deallocating thisptr"\n           del self.thisptr\n\n    def getA(self):\n       return self.thisptr.getA()\n\n#    def override_me(self):\n#        return self.thisptr.override_me()\n\n    cpdef int calculate(self, int a):\n        return self.thisptr.calculate(a) ;\n\n\ncdef public api int cy_call_func(object self, char* method, int *error):\n    try:\n        func = getattr(self, method);\n    except AttributeError:\n        error[0] = 1\n    else:\n        error[0] = 0\n        return func()\n']], ['Can I override a C++ virtual function within Python with Cython?'], 7, 0], [(10126668, 5), [['Finally, the python calls :'], ["EDIT : On the other hand the above code could be optimized by using 'hasattr' instead of try/catch  block :"]], [[' from elps import PyTestClass as TC;\n\na = TC(); \nprint a.calculate(1);\n\nclass B(TC):\n#   pass\n    def override_me(self):\n        return 5\n\nb = B()\nprint b.calculate(1)\n']], ['Can I override a C++ virtual function within Python with Cython?'], 7, 0], [(10126668, 6), [["EDIT : On the other hand the above code could be optimized by using 'hasattr' instead of try/catch  block :"], ["The above code, of course, makes a difference only in the case where we don't override the 'override_me' method."]], [[' cdef public api int cy_call_func_int_fast(object self, char* method, bint *error):\n    if (hasattr(self, method)):\n        error[0] = 0\n        return getattr(self, method)();\n    else:\n        error[0] = 1\n']], ['Can I override a C++ virtual function within Python with Cython?'], 7, 0], [(10127973, 0), [['I do know that Python has a module for opening webpages, called urllib:'], ['you could also save a new html file with python like this:']], [[" import urllib\nurl = 'https://www.google.com/'\npage = urllib.urlopen(url)\nprint page.read()    \n#page.read is the url's source code, so you would print the source  code here. \n"]], ['Extracting text from webpage, processing with Perl/Python, then rebuilding the page with links added'], 2, 0], [(10127973, 1), [['you could also save a new html file with python like this:'], ["In between you could modify the html source. Keep in mind that the webpages will look silly if you don't figure out how to save the files the pages are using. Hope this helps."]], [[" page = page.read()\nfile = open('url.html', 'w')\nfile.writelines(page)\nfile.close()\n"]], ['Extracting text from webpage, processing with Perl/Python, then rebuilding the page with links added'], 2, 0], [(10154289, 0), [["I'm fairly sure the following should do what you want"], ['EDIT : I just confirmed that it works:']], [[" parsed.find('a').previousSibling # or something like that\n"]], ['Use BeautifulSoup to extract text before the first child tag'], 2, 1], [(10154289, 1), [['EDIT : I just confirmed that it works:'], ['-10000']], [[' >>> from BeautifulSoup import BeautifulSoup\n>>> soup = BeautifulSoup(\'<div class=a>Category: <a href="/">a link</a></div>\')\n>>> soup.find(\'a\')\n<a href="/">a link</a>\n>>> soup.find(\'a\').previousSibling\nu\'Category: \'\n>>> \n']], ['Use BeautifulSoup to extract text before the first child tag'], 2, 1], [(10156909, 0), [['You are almost there. You need two additional clauses:'], ['values  returns a  list  of  dicts  like: ']], [[" day_counts = Post.objects.filter(author=someuser).values('posted_day').annotate(\n                                       dailycount=Count('posted_day')).order_by()\n"]], ['How do I get the number of posts on each day with annotation in Django?'], 3, 0], [(10156909, 1), [['values  returns a  list  of  dicts  like: '], ['so if you wanted the last day the user posted, it would be the last item in the list:']], [[" [{'posted-day': 'the-first-day', 'dailycount': 2}, . . . ,\n {'posted-day': 'the-last-day', 'dailycount': 3}]\n"]], ['How do I get the number of posts on each day with annotation in Django?'], 3, 0], [(10156909, 2), [['so if you wanted the last day the user posted, it would be the last item in the list:'], ["You can then compare  date  to  today()  to see if they match, and if they don't the user didn't post today, and if he did, he posted  count  times."]], [[" last_day_dict = day_counts[-1]\ndate = last_day_dict['posted_day']\ncount = last_day_dict['dailycount']\n"]], ['How do I get the number of posts on each day with annotation in Django?'], 3, 0], [(10211546, 0), [['How about this:'], ['If you want to select programmatically the calls to mock, you could use a generator instead of a list, and  next  rather than  pop :']], [[" fubar = Fubar()\nmyMethod = fubar.myMethod # note instance fubar, resulting in a bound method.\nfubar.myMethod = lambda self, calls = [myMethod, (lambda: 'MyMock'), myMethod]: calls.pop()()\n"]], ['Mock only a subset of all calls to a method'], 2, 1], [(10255972, 0), [['I would use get_text() instead of find_all()'], ['Then you can use lstrip to get rid of the dollar sign']], [[' price_str = price.get_text() # $17.95\n']], ['Parsing text in BS4'], 2, 0], [(10255972, 1), [['Then you can use lstrip to get rid of the dollar sign'], ["And you're done!"]], [[" price_str = price_str.lstrip('$') # 17.95\n"]], ['Parsing text in BS4'], 2, 0], [(10263217, 0), [["Looks like this was complete PEBKAC. I've found an answer. Basically, I was doing this:"], ["Apparently this was confusing X enough that it was doing nothing. The solution that I've stumbled upon was to remove the border_width portion from the window.change_attributes() call, like so:"]], [[' def set_active_border(self, window):\n    border_color = self.colormap.alloc_named_color(\\\n        "#ff00ff").pixel\n    window.configure(border_width = 2)\n    window.change_attributes(None,border_pixel=border_color,\n         border_width = 2)\n    self.dpy.sync()\n']], ['Drawing window border in Python xlib'], 2, 0], [(10263217, 1), [["Apparently this was confusing X enough that it was doing nothing. The solution that I've stumbled upon was to remove the border_width portion from the window.change_attributes() call, like so:"], ['I hope this helps someone later on down the road! ']], [[' def set_active_border(self, window):\n    border_color = self.colormap.alloc_named_color(\\\n        "#ff00ff").pixel\n    window.configure(border_width = 2)\n    window.change_attributes(None,border_pixel=border_color)\n    self.dpy.sync()\n']], ['Drawing window border in Python xlib'], 2, 1], [(10282693, 0), [['The key to this question is to recognize that you can represent each strand on the helix as a combination of sine waves - one for the periodic portion, and one for the "depth" into the page. Once you\'ve parameterized the problem this way, you can control every aspect of your helix. The example below uses  *  and  #  to show the different strands to illustrate the point. If you choose values for the wavelength that do not commensurate with integer values you\'ll get less then optimal results - but now you can play with inputs to find what you consider the most aesthetically pleasing representation. '], ['These values give:']], [[' from numpy import *\n\namp = 10\nlength = 100\nwavelength = 20\n\nomega = (2*pi)/wavelength\nphi   = wavelength*(0.5)\nX = arange(1,length)\nY1 = round_(amp*(sin(omega*X) + 1))\nY2 = round_(amp*(sin(omega*X+phi) + 1))\n\noffset = phi/2\nZ1 = sin(omega*X + offset)\nZ2 = sin(omega*X + phi + offset)\n\nT1 = " ######### "\nT2 = " ********* "\nclen = len(T1)\n\nH = zeros((length,amp*2+clen),dtype=\'str\')\nH[:,:] = " "\n\nfor n,(y1,y2,z1,z2) in enumerate(zip(Y1,Y2,Z1,Z2)):\n    H[n,y1:y1+clen] = list(T1)\n    H[n,y2:y2+clen] = list(T2)\n\n    # Overwrite if first helix is on top\n    if z1>z2: H[n,y1:y1+clen] = list(T1)\n\nfor line in H:\n    print "".join(line)\n']], ['Double helix generating algorithm'], 2, 1], [(10282693, 1), [['These values give:'], ['-10000']], [['    *********  #########        \n  *********      #########     \n *********         #########   \n *********           ######### \n   *********         ######### \n     *********       ######### \n       *********   #########   \n          ****** #########     \n              #########        \n           ######### ****      \n        #########  *********   \n     #########      *********  \n   #########         ********* \n #########           ********* \n #########         *********   \n #########       *********     \n   #########   *********       \n     ###### *********          \n        *********              \n      ********* ####           \n   *********  #########        \n  *********      #########     \n *********         #########   \n *********           ######### \n   *********         ######### \n     *********       ######### \n       *********   #########   \n          ****** #########     \n              #########        \n']], ['Double helix generating algorithm'], 2, 0], [(10303797, 1), [["Using this class you'll have to use  str.format  function instead of the modulus operator ( % ) for formatting. Following are some examples:"], ["Edit : Actually you can add new syntax to format sting using  __format__  method. So, if you want to keep both behaviours, i.e. show leading zero when needed and don't show leading zero when not needed. You may create the  MyFloat  class as follows:"]], [[" >>> print(MyFloat(.4444))\n.4444\n\n>>> print(MyFloat(-.4444))\n-.4444\n\n>>> print('some text {:.3f} some more text',format(MyFloat(.4444)))\nsome text .444 some more text\n\n>>> print('some text {:+.3f} some more text',format(MyFloat(.4444)))\nsome text +.444 some more text\n"]], ['Print floating point values without leading zero'], 4, 0], [(10303797, 3), [['And use this class as follows:'], ["Note that using 'fz' instead of 'f' removes the leading zero."]], [[" >>> print('some text {:.3f} some more text',format(MyFloat(.4444)))\nsome text 0.444 some more text\n>>> print('some text {:.3fz} some more text',format(MyFloat(.4444)))\nsome text .444 some more text\n\n\n>>> print('some text {:+.3f} some more text',format(MyFloat(.4444)))\nsome text +0.444 some more text\n>>> print('some text {:+.3fz} some more text',format(MyFloat(.4444)))\nsome text +.444 some more text\n\n\n>>> print('some text {:.3f} some more text',format(MyFloat(-.4444)))\nsome text -0.444 some more text\n>>> print('some text {:.3fz} some more text',format(MyFloat(-.4444)))\nsome text -.444 some more text\n"]], ['Print floating point values without leading zero'], 4, 0], [(10342939, 0), [['For the powerset,  the  itertools  docs  also give us a recipe:'], ['For example:']], [[' def powerset(iterable):\n    "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"\n    s = list(iterable)\n    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n']], ['Power set and Cartesian Product of a set python'], 2, 0], [(10342939, 1), [['For example:'], ['-10000']], [[' >>> test = {1, 2, 3}\n>>> list(powerset(test))\n[(), (1,), (2,), (3,), (1, 2), (1, 3), (2, 3), (1, 2, 3)]\n>>> list(product(test, test))\n[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]\n']], ['Power set and Cartesian Product of a set python'], 2, 0], [(10429919, 0), [["This is why I think the attribute isn't needed: The only way to make use of that attribute is to scan the entire model, checking each item. Thats not really efficient. The selection should happen in reaction to the signal being emitted."], ['tableView']], [[' myMatPlotView.selectionchanged.connect(myTableView.matplotSelected)\n']], ['QTableView item selection based on a QStandardItem data attribute'], 4, 0], [(10429919, 1), [['tableView'], ['Your example']], [[' def matPlotSelected(self, qStandardItems):\n\n    selModel = self.selectionModel()\n    model = self.model()\n\n    for item in qStandardItems:\n        idx = model.indexFromItem(item)\n        selModel.select(idx, selModel.Select)\n']], ['QTableView item selection based on a QStandardItem data attribute'], 4, 0], [(10429919, 2), [['Your example'], ['If this is your actual situation, then what I suggested above fits in like this:']], [[" def __init__(self):\n    super(myDialog, self).__init__()\n    self.t = QtGui.QTreeView()\n    self.m = QtGui.QStandardItemModel()\n    self.t.setModel(self.m)\n    layout = QtGui.QVBoxLayout()\n    layout.addWidget(self.t)\n    self.setLayout(layout)\n    self.l = [\n        ['one', False], ['two', True], \n        ['three', False], ['four', True], \n        ['five', False]]\n    self.populate()\n\ndef populate(self):\n    self.m.clear()\n    root = self.m.invisibleRootItem()\n    for item in self.l:\n        e = QtGui.QStandardItem()\n        e.setText(item[0])\n        root.appendRow(e)\n"]], ['QTableView item selection based on a QStandardItem data attribute'], 4, 0], [(10429919, 3), [['If this is your actual situation, then what I suggested above fits in like this:'], ['-10000']], [[' def populate(self):\n    self.m.clear()\n    root = self.m.invisibleRootItem()\n    selModel = self.t.selectionModel()\n    for item in self.l:\n        e = QtGui.QStandardItem()\n        e.setText(item[0])\n        root.appendRow(e)\n\n        if item[1]:\n            idx = self.m.indexFromItem(e)\n            selModel.select(idx, selModel.Select)\n']], ['QTableView item selection based on a QStandardItem data attribute'], 4, 0], [(10437805, 0), [["Do you just want this? I tried on the free ScraperWiki test page and seems to do what you want. If you're looking for something more complicated, let me know."], ['Outputs:']], [[' import scraperwiki\nimport simplejson\nimport urllib2\n\nQUERY = \'meetup\'\nRESULTS_PER_PAGE = \'100\'\nNUM_PAGES = 10\n\nfor page in range(1, NUM_PAGES+1):\n    base_url = \'http://search.twitter.com/search.json?q=%s&rpp=%s&page=%s\' \\\n         % (urllib2.quote(QUERY), RESULTS_PER_PAGE, page)\n    try:\n        results_json = simplejson.loads(scraperwiki.scrape(base_url))\n        for result in results_json[\'results\']:\n            #print result\n            data = {}\n            data[\'id\'] = result[\'id\']\n            data[\'text\'] = result[\'text\']\n            data[\'location\'] = scraperwiki.geo.extract_gb_postcode(result[\'text\'])\n            data[\'from_user\'] = result[\'from_user\']\n            data[\'created_at\'] = result[\'created_at\']\n            if data[\'location\']:\n                print data[\'location\'], data[\'from_user\']\n                scraperwiki.sqlite.save(["id"], data)\n    except:\n        print \'Oh dear, failed to scrape %s\' % base_url\n        break\n']], ['ScraperWiki/Python: filtering out records when property is false'], 3, 1], [(10437805, 1), [['Outputs:'], ["I've refined it a bit so it's a bit picker than the scraperwiki check for extracting gb postcodes, which lets though quite a few false positives. Basically I took the accepted answer from  here , and added some negative lookbehind/lookahead to filter out a few more. It looks like the scraper wiki check does the regex without the negative lookbehind/lookahead. Hope that helps a bit."]], [[' P93JX VSDC\nFV36RL Bootstrappers\nCi76fP Eli_Regalado\nUN56fn JasonPalmer1971\niQ3H6zR GNOTP\nQr04eB fcnewtech\nsE79dW melindaveee\nud08GT MariaPanlilio\nc9B8EE akibantech\nay26th Thepinkleash\n']], ['ScraperWiki/Python: filtering out records when property is false'], 3, 0], [(10437805, 2), [["I've refined it a bit so it's a bit picker than the scraperwiki check for extracting gb postcodes, which lets though quite a few false positives. Basically I took the accepted answer from  here , and added some negative lookbehind/lookahead to filter out a few more. It looks like the scraper wiki check does the regex without the negative lookbehind/lookahead. Hope that helps a bit."], ['-10000']], [[' import scraperwiki\nimport simplejson\nimport urllib2\nimport re\n\nQUERY = \'sw4\'\nRESULTS_PER_PAGE = \'100\'\nNUM_PAGES = 10\n\npostcode_match = re.compile(\'(?<![0-9A-Z])([A-PR-UWYZ0-9][A-HK-Y0-9][AEHMNPRTVXY0-9]?[ABEHMNPRVWXY0-9]? {0,2}[0-9][ABD-HJLN-UW-Z]{2}|GIR 0AA)(?![0-9A-Z])\', re.I)\n\nfor page in range(1, NUM_PAGES+1):\n    base_url = \'http://search.twitter.com/search.json?q=%s&rpp=%s&page=%s\' \\\n         % (urllib2.quote(QUERY), RESULTS_PER_PAGE, page)\n    try:\n        results_json = simplejson.loads(scraperwiki.scrape(base_url))\n        for result in results_json[\'results\']:\n            #print result\n            data = {}\n            data[\'id\'] = result[\'id\']\n            data[\'text\'] = result[\'text\']\n            data[\'location\'] = scraperwiki.geo.extract_gb_postcode(result[\'text\'])\n            data[\'from_user\'] = result[\'from_user\']\n            data[\'created_at\'] = result[\'created_at\']\n            if data[\'location\'] and postcode_match.search(data[\'text\']):\n                print data[\'location\'], data[\'text\']\n                scraperwiki.sqlite.save(["id"], data)\n    except:\n        print \'Oh dear, failed to scrape %s\' % base_url\n        break\n']], ['ScraperWiki/Python: filtering out records when property is false'], 3, 1], [(10460286, 0), [['-10000'], ['Using  starmap']], [[" >>> data = ['192', '168', '0', '1', '80', '192', '168', '0', '2', '8080']\n>>> ['{}.{}.{}.{}:{}'.format(*x) for x in zip(*[iter(data)]*5)]\n['192.168.0.1:80', '192.168.0.2:8080']\n"]], ['Concat every 4 strings from a list?'], 2, 1], [(10460286, 1), [['Using  starmap'], ['-10000']], [[" >>> from itertools import starmap\n>>> list(starmap('{}.{}.{}.{}:{}'.format,zip(*[iter(data)]*5)))\n['192.168.0.1:80', '192.168.0.2:8080']\n"]], ['Concat every 4 strings from a list?'], 2, 1], [(10472907, 0), [['To convert from the dict to the string in the format you want:'], ['if you want them alphabetically ordered by key:']], [[" ''.join('{}{}'.format(key, val) for key, val in adict.items())\n"]], ['How to convert dictionary into string'], 2, 1], [(10472907, 1), [['if you want them alphabetically ordered by key:'], ['-10000']], [[" ''.join('{}{}'.format(key, val) for key, val in sorted(adict.items()))\n"]], ['How to convert dictionary into string'], 2, 1], [(10500834, 0), [['You should use  capitalize()  and  lower()'], ['Alternatively, you can save a few more CPU cycles if you reuse results, as mentioned by rubik below.']], [[' while response[0] != \'quit\': \n    response = raw_input("Please enter who you\'re looking for, or type \'exit\' to quit the program: ").split() \n    try:\n        print "%s\'s %s is %s" % (response[0].capitalize(), response[1].lower(), people[response[0].capitalize()][response[1].lower()])  \n    except KeyError: \n        print wrong,\n']], ['Able to use any case in input to generate the same dict values in output'], 2, 1], [(10500834, 1), [['Alternatively, you can save a few more CPU cycles if you reuse results, as mentioned by rubik below.'], ['-10000']], [[' while response[0] != \'quit\': \n    response = raw_input("Please enter who you\'re looking for, or type \'exit\' to quit the program: ").split() \n    try:\n        fn, thing = response[0].capitalize(), response[1].lower()\n        print "%s\'s %s is %s" % (fn, thing, people[fn][thing])  \n    except KeyError: \n        print wrong,\n']], ['Able to use any case in input to generate the same dict values in output'], 2, 1], [(10507011, 0), [["One potential way around this is to construct your own dictionary object based on the returns of a queryset. You'd do something like this:"], ['You need to import json for this to work.']], [[" queryset = Model.objects.all()\nlist = [] #create list\nfor row in queryset: #populate list\n    list.append({'title':row.title, 'body': row.body, 'name': row.user.username})\nrecipe_list_json = json.dumps(list) #dump list as JSON\nreturn HttpResponse(recipe_list_json, 'application/javascript')\n"]], ['django serialize foreign key objects'], 2, 1], [(10507011, 1), [['You need to import json for this to work.'], ['-10000']], [[' import json\n']], ['django serialize foreign key objects'], 2, 0], [(10526579, 0), [['The following works for me:'], ['For me, this produces the output:']], [[' import numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.multiclass import OneVsRestClassifier\n\nX_train = np.array(["new york is a hell of a town",\n                    "new york was originally dutch",\n                    "the big apple is great",\n                    "new york is also called the big apple",\n                    "nyc is nice",\n                    "people abbreviate new york city as nyc",\n                    "the capital of great britain is london",\n                    "london is in the uk",\n                    "london is in england",\n                    "london is in great britain",\n                    "it rains a lot in london",\n                    "london hosts the british museum",\n                    "new york is great and so is london",\n                    "i like london better than new york"])\ny_train = [[0],[0],[0],[0],[0],[0],[1],[1],[1],[1],[1],[1],[0,1],[0,1]]\nX_test = np.array([\'nice day in nyc\',\n                   \'welcome to london\',\n                   \'hello welcome to new york. enjoy it here and london too\'])   \ntarget_names = [\'New York\', \'London\']\n\nclassifier = Pipeline([\n    (\'vectorizer\', CountVectorizer(min_n=1,max_n=2)),\n    (\'tfidf\', TfidfTransformer()),\n    (\'clf\', OneVsRestClassifier(LinearSVC()))])\nclassifier.fit(X_train, y_train)\npredicted = classifier.predict(X_test)\nfor item, labels in zip(X_test, predicted):\n    print \'%s => %s\' % (item, \', \'.join(target_names[x] for x in labels))\n']], ['use scikit-learn to classify into multiple categories'], 2, 1], [(10526579, 1), [['For me, this produces the output:'], ['Hope this helps.']], [[' nice day in nyc => New York\nwelcome to london => London\nhello welcome to new york. enjoy it here and london too => New York, London\n']], ['use scikit-learn to classify into multiple categories'], 2, 0], [(10562180, 1), [['Gives us'], ['-10000']], [[' Python Programming Language – Official Website (http://www.python.org/)\nPython - Image Results (http://images.search.yahoo.com/search/images?_adv_prop=image&va=python)\nPython (programming language) - Wikipedia, the free encyclopedia (http://en.wikipedia.org/wiki/Python_(programming_language))\n']], ['How to do a basic query on yahoo search engine using Python without using any yahoo api?'], 2, 0], [(10586471, 0), [['Simply now you should move all your custom functions to a module inside your  .ipython  directory. Since what I was doing was a simple function that returns the git branch and status for the current directory, I created a file called  gitprompt.py  and then I included the filename in the  exec_file  configuration option:'], ['All definitions in such files are placed into the user namespace. So now I can use it inside my prompt:']], [[" c.InteractiveShellApp.exec_files = [b'gitprompt.py']\n"]], ["How do I define custom function to be called from IPython's prompts?"], 2, 0], [(10586471, 1), [['All definitions in such files are placed into the user namespace. So now I can use it inside my prompt:'], ['Notice that in order for the function to behave as such (i.e called each time the prompt is printed) you need to use the  IPython.core.prompts.LazyEvaluation  class. You may use it as a decorator for your function. The  gitprompt.py  has being placed in the public domain as the gist:  https://gist.github.com/2719419']], [[" # Input prompt.  '\\#' will be transformed to the prompt number\nc.PromptManager.in_template = br'{color.Green}\\# {color.LightBlue}~\\u{color.Green}:\\w{color.LightBlue} {git_branch_and_st} \\$\\n>>> '\n\n# Continuation prompt.\nc.PromptManager.in2_template = br'... '\n"]], ["How do I define custom function to be called from IPython's prompts?"], 2, 0], [(10599771, 0), [['create a tk.Button in  __init__  like this:  '], ["Another side note, you can use a widget's config method to update a widget on the fly (instead of recreating it all the time).  In other words, move all the widget creation into  __init__  and then in  display_next  just update the widget using  config .  Also, it's probably better to inherit from Tkinter.Frame..."]], [[' self.Button = Tkinter.Button(self,text="Next",command=self.display_next)\n']], ['How to loop through subfolders showing jpg in Tkinter?'], 2, 0], [(10602071, 0), [["Then, you could use an M2M field, assuming you'd use  django-annoying , you could define your user profile model as such:"], ['And use it as such:']], [[" from django.db import models\n\nfrom annoying.fields import AutoOneToOneField\n\nclass UserProfile(models.Model):\n    user = AutoOneToOneField('auth.user')\n    follows = models.ManyToManyField('UserProfile', related_name='followed_by')\n\n    def __unicode__(self):\n        return self.user.username\n"]], ['Following users like twitter in Django, how would you do it?'], 2, 0], [(10602071, 1), [['And use it as such:'], ['Also, note that you could check / reuse apps like  django-subscription ,  django-actstream ,  django-social  (harder to use probably)... ']], [[" In [1]: tim, c = User.objects.get_or_create(username='tim')\n\nIn [2]: chris, c = User.objects.get_or_create(username='chris')\n\nIn [3]: tim.userprofile.follows.add(chris.userprofile) # chris follows tim\n\nIn [4]: tim.userprofile.follows.all() # list of userprofiles of users that tim follows\nOut[4]: [<UserProfile: chris>]\n\nIn [5]: chris.userprofile.followed_by.all() # list of userprofiles of users that follow chris\nOut[5]: [<UserProfile: tim>]\n"]], ['Following users like twitter in Django, how would you do it?'], 2, 0], [(10610592, 0), [['You could use the  type  argument to  add_argument(...)  instead. For example:'], ['When I run this I get:']], [[' import os\nimport argparse\n\ndef intOrUnderscore(s):\n    if s != \'_\':\n        return int(s)\n    cases = (n for n in os.listdir(".") if n.startswith("file."))\n    return max(int(c[c.rindex(".")+1:]) for c in cases)\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'case\', type=intOrUnderscore)\n\nargs = parser.parse_args()\nprint args.case\n']], ['Specifying types and patterns using argparse choices'], 3, 1], [(10610592, 1), [['When I run this I get:'], ['Alternately, you could build the choices list in code:']], [[' $ ls\nfile.1  file.2  file.3  s.py\n$ python s.py 2\n2\n$ python s.py _\n3\n']], ['Specifying types and patterns using argparse choices'], 3, 0], [(10610592, 2), [['Alternately, you could build the choices list in code:'], ['-10000']], [[' import os\nimport argparse\n\ncases = [n[n.rindex(".")+1:] for n in os.listdir(".") if n.startswith("file.")]\ncases.append("_")\nparser = argparse.ArgumentParser()\nparser.add_argument(\'case\', choices = cases)\n\nargs = parser.parse_args()\nprint args.case\n']], ['Specifying types and patterns using argparse choices'], 3, 1], [(10636203, 0), [['The problem you are facing is that you are not visiting all nodes in the file. You are only visiting the children of the  elem  element, but you are not visiting the children of these elements. To illustrate this, running the following (I have edited your XML to be valid):'], ['results in']], [[' from xml.etree.ElementTree as etree\n\nxml_string = """<elem>\n    <variable id="getthis" />\n    <if>\n        <variable id="alsoGetThis" />\n    </if>\n    </elem>"""\n\ne = etree.fromstring(xml_string)\n\nfor node in e:\n    print node\n']], ['Simple loop for all elements of an etree object?'], 4, 0], [(10636203, 1), [['results in'], ['Edit:  As promised, some code to get all  id  attributes from your element tree. Rather than using an accumulator as Niek de Klein has I have used a generator. This has a number of advantages. For example, this returns the  id s one at a time, so you can stop processing at any point, if, for example, a certain  id  is encountered, which saves reading the entire XML file.']], [[' <Element variable at 7f53fbdf1cb0>\n<Element if at 7f53fbdf1cf8>\n']], ['Simple loop for all elements of an etree object?'], 4, 0], [(10636203, 2), [['Edit:  As promised, some code to get all  id  attributes from your element tree. Rather than using an accumulator as Niek de Klein has I have used a generator. This has a number of advantages. For example, this returns the  id s one at a time, so you can stop processing at any point, if, for example, a certain  id  is encountered, which saves reading the entire XML file.'], ['This  yields  the result']], [[' def get_attrs(element, tag, attr):\n    """Return attribute `attr` of `tag` child elements of `element`."""\n\n    # If an element has any cildren (nested elements) loop through them:\n    if len(element):\n         for node in element:\n            # Recursively call this function, yielding each result:\n            for attribute in get_attrs(node, tag, attr):\n                yield attribute\n\n    # Otherwise, check if element is of type `tag` with attribute `attr`, if so\n    # yield the value of that attribute.\n    if element.tag == \'variable\':\n        if attr in element.attrib:\n            yield element.attrib[attr]\n\nids = [id for id in get_attrs(e, \'variable\', \'id\')]\n\nprint ids\n']], ['Simple loop for all elements of an etree object?'], 4, 1], [(10636203, 3), [['This  yields  the result'], ['-10000']], [["  ['getthis', 'alsoGetThis']\n"]], ['Simple loop for all elements of an etree object?'], 4, 0], [(10645986, 0), [['Your first link more or less solves the problem.  You just need to have the lambda function only look at the first item in your list:'], ["One modification I might suggest, if you're sorting a reasonably large list, is to change the alphabet structure into a dict first, so that index lookup is faster:"]], [[' alphabet = "zyxwvutsrqpomnlkjihgfedcba"\n\nnew_list = sorted(inputList, key=lambda word: [alphabet.index(c) for c in word[0]])\n']], ['Custom sort python'], 2, 1], [(10645986, 1), [["One modification I might suggest, if you're sorting a reasonably large list, is to change the alphabet structure into a dict first, so that index lookup is faster:"], ['-10000']], [[' alphabet_dict = dict([(x, alphabet.index(x)) for x in alphabet)\nnew_list = sorted(inputList, key=lambda word: [alphabet_dict[c] for c in word[0]])\n']], ['Custom sort python'], 2, 1], [(10647449, 1), [["Watch out for quotes, though.  You can't do:"], ['because extract_javascript will not read it.  But, you can just put the quotes inside, as long as you render them safely:']], [[' \'{{gettext("message")}}\'\n']], ['serving i18n js using babel, django, & jinja2'], 3, 0], [(10683659, 0), [['Brute-force using  itertools :'], ['Result:']], [[' import itertools\ndef arrangements(arr):\n    p = itertools.permutations(arr)\n    return set(item for item in p if all(x!=y for x,y in zip(item,arr)))\n']], ['Find the number of ways a sequence can be rearranged'], 2, 1], [(10683659, 1), [['Result:'], ['-10000']], [[' >>> arrangements([0,0,0,1,1,1])\n{(1, 1, 1, 0, 0, 0)}\n>>> arrangements([0,0,0,1,1,1,1])\nset()\n>>> arrangements([1,2,2,14])\n{(2, 14, 1, 2), (2, 1, 14, 2)}\n>>> arrangements([1,1,2,2,14])\n{(2, 14, 1, 1, 2), (2, 2, 1, 14, 1), (14, 2, 1, 1, 2), (2, 2, 14, 1, 1)}\n']], ['Find the number of ways a sequence can be rearranged'], 2, 0], [(10741346, 0), [['http://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html'], ['And then:']], [[' import numpy as np\nx = np.array([1,1,1,2,2,2,5,25,1,1])\ny = np.bincount(x)\nii = np.nonzero(y)[0]\n']], ['numpy: most efficient frequency counts for unique values in an array'], 3, 1], [(10741346, 1), [['And then:'], ['or:']], [[' zip(ii,y[ii]) \n# [(1, 5), (2, 3), (5, 1), (25, 1)]\n']], ['numpy: most efficient frequency counts for unique values in an array'], 3, 0], [(10741346, 2), [['or:'], ['or however you want to combine the counts and the unique values.']], [[' np.vstack((ii,y[ii])).T\n# array([[ 1,  5],\n         [ 2,  3],\n         [ 5,  1],\n         [25,  1]])\n']], ['numpy: most efficient frequency counts for unique values in an array'], 3, 0], [(10805846, 0), [['The right thing to do here is set a timer event using this in the setup code (after the line  HEAD = 0 )'], ['this goes in the  runGame  function after  direction = RIGHT']], [[' SHRINKSNAKE = pygame.USEREVENT+0\n']], ['How to make a Python function sleep some time while the rest of the game continues?'], 3, 0], [(10805846, 1), [['this goes in the  runGame  function after  direction = RIGHT'], ['and this in the event handling loop in  runGame  before the line  elif event.type == KEYDOWN:  the  elif s should line up']], [[' pygame.time.set_timer(SHRINKSNAKE, 4*1000)\n']], ['How to make a Python function sleep some time while the rest of the game continues?'], 3, 0], [(10805846, 2), [['and this in the event handling loop in  runGame  before the line  elif event.type == KEYDOWN:  the  elif s should line up'], ['For more details check the documentation on  pygame.time.set_timer']], [[' elif event.type == SHRINKSNAKE:\n  if len(wormCoords) > 2:\n    del wormCoords[-1]\n']], ['How to make a Python function sleep some time while the rest of the game continues?'], 3, 0], [(10829302, 0), [['I am trying an alternative using  texttable . It produces an identical output to that in the question. This output may be written to a csv file (the records will need massaging for the appropriate csv dialect, and I cannot find a way to still use the  csv.writer  and still get the padded spaces in each field.'], ['-10000']], [["                   Title,                      Release Date,             Director            \nAnd Now For Something Completely Different,       1971,              Ian MacNaughton        \nMonty Python And The Holy Grail,                  1975,       Terry Gilliam and Terry Jones \nMonty Python's Life Of Brian,                     1979,                Terry Jones    \n"]], ['Writing to separate columns instead of comma seperated for csv files in scrapy'], 2, 0], [(10829302, 1), [['-10000'], ['-10000']], [[' from texttable import Texttable\n\n# ----------------------------------------------------------------\n# Imagine data to be generated by Scrapy, for each record:\n# a dictionary of three items. The first set ot functions\n# generate the data for use in the texttable function\n\ndef process_item(item):\n    # This massages each record in preparation for writing to csv\n    item[\'Title\'] = item[\'Title\'].encode(\'utf-8\') + \',\'\n    item[\'Release Date\'] = item[\'Release Date\'].encode(\'utf-8\') + \',\'\n    item[\'Director\'] = item[\'Director\'].encode(\'utf-8\')\n    return item\n\ndef initialise_dataset():\n    data = [{\'Title\' : \'Title\',\n         \'Release Date\' : \'Release Date\',\n         \'Director\' : \'Director\'\n         }, # first item holds the table header\n            {\'Title\' : \'And Now For Something Completely Different\',\n         \'Release Date\' : \'1971\',\n         \'Director\' : \'Ian MacNaughton\'\n         },\n        {\'Title\' : \'Monty Python And The Holy Grail\',\n         \'Release Date\' : \'1975\',\n         \'Director\' : \'Terry Gilliam and Terry Jones\'\n         },\n        {\'Title\' : "Monty Python\'s Life Of Brian",\n         \'Release Date\' : \'1979\',\n         \'Director\' : \'Terry Jones\'\n         }\n        ]\n\n    data = [ process_item(item) for item in data ]\n    return data\n\ndef records(data):\n    for item in data:\n        yield [item[\'Title\'], item[\'Release Date\'], item[\'Director\'] ]\n\n# this ends the data simulation part\n# --------------------------------------------------------\n\ndef create_table(data):\n    # Create the table\n    table = Texttable(max_width=0)\n    table.set_deco(Texttable.HEADER)\n    table.set_cols_align(["l", "c", "c"])\n    table.add_rows( records(data) )\n\n    # split, remove the underlining below the header\n    # and pull together again. Many ways of cleaning this...\n    tt = table.draw().split(\'\\n\')\n    del tt[1] # remove the line under the header\n    tt = \'\\n\'.join(tt)\n    return tt\n\nif __name__ == \'__main__\':\n    data = initialise_dataset()\n    table = create_table(data)\n    print table\n']], ['Writing to separate columns instead of comma seperated for csv files in scrapy'], 2, 1], [(10843549, 0), [['-10000'], ['returns']], [[' import numpy\nimport scipy.linalg\n\nm = numpy.matrix([\n    [1, 1, 1, 1, 1],\n    [16, 8, 4, 2, 1],\n    [81, 27, 9, 3, 1],\n    [256, 64, 16, 4, 1],\n    [625, 125, 25, 5, 1]\n])\n\nres = numpy.matrix([[1],[2],[3],[4],[8]])\n\nprint scipy.linalg.solve(m, res)\n']], ['Solving 5 Linear Equations in Python'], 2, 1], [(10843549, 1), [['returns'], ['(your solution coefficients for a,b,c,d,e)']], [[' [[ 0.125]\n [-1.25 ]\n [ 4.375]\n [-5.25 ]\n [ 3.   ]]\n']], ['Solving 5 Linear Equations in Python'], 2, 0], [(10870736, 0), [['You could try something like this'], ['Alternatively, just for convenience and easier modification, you could use a variable:']], [[' for i,col in enumerate(fields[5:], 5):\n    ....\n']], ['Python: Keep track of current column in text file'], 3, 1], [(10870736, 1), [['Alternatively, just for convenience and easier modification, you could use a variable:'], ['I am still not quite sure I understand your comment, but if the loop you posted is inside a bigger loop you could to keep track of your current columns like this:']], [[' start_col = 5\nfor i,col in enumerate(fields[start_col:], start_col):\n    ....\n']], ['Python: Keep track of current column in text file'], 3, 1], [(10870736, 2), [['I am still not quite sure I understand your comment, but if the loop you posted is inside a bigger loop you could to keep track of your current columns like this:'], ['Posting some simple input/output examples would help if your code is too big to post. Hard to really know how to help without more information. I hope this is helpful.']], [[' cur_column = 5\nfor line in Input:\n    line = line.rstrip() \n    fields = line.split("\\t")   \n    for col in fields[cur_colum:]:\n       ...\n       ...\n\ncur_column += 1 # done processing current column, increment value to next column\n']], ['Python: Keep track of current column in text file'], 3, 1], [(10881852, 0), [['change'], ['to']], [[' s2 = s1[:s.rfind(\'\\n\')]  #This picks up the newline after "everything"\n']], ['Parse multi-line string up until first line with certain character'], 2, 0], [(10881852, 1), [['to'], ['and it will work.  There might be a better way to do this though...']], [[" s2 = s1[:s1.rfind('\\n')]  \n"]], ['Parse multi-line string up until first line with certain character'], 2, 0], [(10889564, 0), [['-10000'], ['This returns a list, and in your example you showed a tuple.  I presume a list will work for you, but of course you can always do:']], [[' pat = re.compile(r\' A(\\d+)\')\nlst = re.findall(pat, "= A1 A2 A3 A4")\n']], ['RegEx for matching multiple substrings using one group?'], 4, 0], [(10889564, 1), [['This returns a list, and in your example you showed a tuple.  I presume a list will work for you, but of course you can always do:'], ["The answer I just gave doesn't actually check for the  =  in the input string.  If you need to do that, you can always use two patterns and two steps:"]], [[' t = tuple(lst)\n']], ['RegEx for matching multiple substrings using one group?'], 4, 0], [(10889564, 2), [["The answer I just gave doesn't actually check for the  =  in the input string.  If you need to do that, you can always use two patterns and two steps:"], ['EDIT: Code that handles your  func()  example:']], [[' pat0 = re.compile(r\'=(?: A\\d+)+\')\npat1 = re.compile(r\' A(\\d+)\')\n\nm = pat0.search("= A1 A2 A3 A4")\nif not m:\n    print("input string not what was expected")\nelse:\n    s = m.group(0)\n    lst = re.findall(pat, s)\n']], ['RegEx for matching multiple substrings using one group?'], 4, 0], [(10920180, 0), [["I'd suggest something like the following:"], ['Example:    ']], [[' import inspect\n\nclass key_memoized(object):\n    def __init__(self, func):\n       self.func = func\n       self.cache = {}\n\n    def __call__(self, *args, **kwargs):\n        key = self.key(args, kwargs)\n        if key not in self.cache:\n            self.cache[key] = self.func(*args, **kwargs)\n        return self.cache[key]\n\n    def normalize_args(self, args, kwargs):\n        spec = inspect.getargs(self.func.__code__).args\n        return dict(kwargs.items() + zip(spec, args))\n\n    def key(self, args, kwargs):\n        a = self.normalize_args(args, kwargs)\n        return tuple(sorted(a.items()))\n']], ['Is there a pythonic way to support keyword arguments for a memoize decorator in Python?'], 3, 1], [(10920180, 1), [['Example:    '], ['Note that you can also extend  key_memoized  and override its  key()  method to provide more specific memoization strategies, e.g. to ignore some of the arguments:']], [[" @key_memoized\ndef foo(bar, baz, spam):\n    print 'calling foo: bar=%r baz=%r spam=%r' % (bar, baz, spam)\n    return bar + baz + spam\n\nprint foo(1, 2, 3)\nprint foo(1, 2, spam=3)         #memoized\nprint foo(spam=3, baz=2, bar=1) #memoized\n"]], ['Is there a pythonic way to support keyword arguments for a memoize decorator in Python?'], 3, 0], [(10920180, 2), [['Note that you can also extend  key_memoized  and override its  key()  method to provide more specific memoization strategies, e.g. to ignore some of the arguments:'], ['-10000']], [[" class memoize_by_bar(key_memoized):\n    def key(self, args, kwargs):\n        return self.normalize_args(args, kwargs)['bar']\n\n@memoize_by_bar\ndef foo(bar, baz, spam):\n    print 'calling foo: bar=%r baz=%r spam=%r' % (bar, baz, spam)\n    return bar\n\nprint foo('x', 'ignore1', 'ignore2')\nprint foo('x', 'ignore3', 'ignore4')\n"]], ['Is there a pythonic way to support keyword arguments for a memoize decorator in Python?'], 3, 0], [(10921316, 0), [["However, I didn't think I needed that much control, and I ended up just using the PAD keyword argument in "], ['The pseudo-code then becomes this:\n']], [[' fig.colorbar()\n']], ['Plot multiple y-axis AND colorbar in matplotlib'], 2, 0], [(10961378, 0), [['To generate the tree you could use a simple recursive function:'], ["To render it as html you could use jinja2's loop  recursive  feature:"]], [[" def make_tree(path):\n    tree = dict(name=os.path.basename(path), children=[])\n    try: lst = os.listdir(path)\n    except OSError:\n        pass #ignore errors\n    else:\n        for name in lst:\n            fn = os.path.join(path, name)\n            if os.path.isdir(fn):\n                tree['children'].append(make_tree(fn))\n            else:\n                tree['children'].append(dict(name=name))\n    return tree\n"]], ['How to generate an html directory list using Python'], 3, 0], [(10961378, 1), [["To render it as html you could use jinja2's loop  recursive  feature:"], ['Put the html into  templates/dirtree.html  file.\nTo test it, run the following code and visit  http://localhost:8888/ :']], [[' <!doctype html>\n<title>Path: {{ tree.name }}</title>\n<h1>{{ tree.name }}</h1>\n<ul>\n{%- for item in tree.children recursive %}\n    <li>{{ item.name }}\n    {%- if item.children -%}\n        <ul>{{ loop(item.children) }}</ul>\n    {%- endif %}</li>\n{%- endfor %}\n</ul>\n']], ['How to generate an html directory list using Python'], 3, 0], [(10961378, 2), [['Put the html into  templates/dirtree.html  file.\nTo test it, run the following code and visit  http://localhost:8888/ :'], ['-10000']], [[' import os\nfrom flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.route(\'/\')\ndef dirtree():\n    path = os.path.expanduser(u\'~\')\n    return render_template(\'dirtree.html\', tree=make_tree(path))\n\nif __name__=="__main__":\n    app.run(host=\'localhost\', port=8888, debug=True)\n']], ['How to generate an html directory list using Python'], 3, 0], [(10963952, 0), [['Either:'], ['Or:']], [[' largest_key = max(my_dict, key=lambda x: x[1])\n']], ['Return the largest value of a given element of tuple keys in a dictionary'], 5, 1], [(10963952, 1), [['Or:'], ['What I think Ms. Zverina is talking about is converting your data structure from a  dict  with  tuple  keys to something like this:']], [[' from operator import itemgetter\nlargest_key = max(my_dict, key=itemgetter(1))\n']], ['Return the largest value of a given element of tuple keys in a dictionary'], 5, 1], [(10963952, 2), [['What I think Ms. Zverina is talking about is converting your data structure from a  dict  with  tuple  keys to something like this:'], ['That way, if you wanted find the max of all values with  a , you could simply do:']], [[" my_dict = {\n    'a': {\n            1: value_1,\n            2: value_3\n         }\n    'b': {\n            1: value_2,\n            2: value_5\n         }\n    'c': {\n            3: value_4\n         }\n}\n"]], ['Return the largest value of a given element of tuple keys in a dictionary'], 5, 0], [(10963952, 3), [['That way, if you wanted find the max of all values with  a , you could simply do:'], ['To restrict your search to a given subset, do something like this:']], [[" largest_key = max(d['a'])\n"]], ['Return the largest value of a given element of tuple keys in a dictionary'], 5, 0], [(10993692, 1), [['For other non-ASCII characters:'], ['Of course, if necessary, you can combine the two:']], [[' >>> "Übeltäter".encode("ascii", "xmlcharrefreplace")\nb\'&#220;belt&#228;ter\'\n']], ['python: convert to HTML special characters'], 3, 1], [(10993692, 2), [['Of course, if necessary, you can combine the two:'], ['-10000']], [[' >>> cgi.escape("<Übeltäter>").encode("ascii", "xmlcharrefreplace")\nb\'&lt;&#220;belt&#228;ter&gt;\'\n']], ['python: convert to HTML special characters'], 3, 1], [(11040604, 0), [['Using your function that determines uniqueness, you can do this:'], ['note that this will modify your dictionaries in place:']], [[' import difflib\n\ndef similar(seq1, seq2):\n    return difflib.SequenceMatcher(a=seq1.lower(), b=seq2.lower()).ratio() > 0.9\n\ndef unique(mylist, keys):\n    temp = mylist[:]\n    for d in mylist:\n        temp.pop(0)\n        [d2.pop(i) for i in keys if d.has_key(i)\n         for d2 in temp if d2.has_key(i) and similar(d[i], d2[i])] \n    return mylist\n']], ['How to uniquefy a list of dicts based on percentage similarity of a value in the dicts'], 3, 1], [(11040604, 1), [['note that this will modify your dictionaries in place:'], ['Output:']], [[' mylist = [{"greeting":"HELLO WORLD!"}, {"greeting":"Hello Mars"}, {"greeting":"Hello World!!!"}, {"greeting":"hello world"}]\nunique(mylist, [\'greeting\'])\n\nprint mylist\n']], ['How to uniquefy a list of dicts based on percentage similarity of a value in the dicts'], 3, 0], [(11040604, 2), [['Output:'], ['-10000']], [[" [{'greeting': 'HELLO WORLD!'}, {'greeting': 'Hello Mars'}, {}, {}]\n"]], ['How to uniquefy a list of dicts based on percentage similarity of a value in the dicts'], 3, 0], [(11052920, 1), [['Edit :  You seem to be actually aiming at  transposing  the list of lists.  This can be done with  zip() :'], ['or, if you really need a list of lists']], [[' def transpose(g):\n    return zip(*g)\n']], ['Creating a 2d Grid in Python'], 3, 1], [(11052920, 2), [['or, if you really need a list of lists'], ['See also the  documentation of  zip() .']], [[' def transpose(g):\n    return map(list, zip(*g))\n']], ['Creating a 2d Grid in Python'], 3, 1], [(11065100, 0), [['For example'], ["a quick 'ps -e' shows"]], [[" >>> print os.getpid()\n3556\n>>> os.execl( '/usr/bin/gvim', 'gvim' )\n"]], ['background process in python with -e option on terminal'], 3, 0], [(11065100, 1), [["a quick 'ps -e' shows"], ["When the launching terminal closes, all processes with the same sid close. So the 'gvim defunct' disappears but the other persists. Programs which do not obtain a new pid/sid will quit when the launching terminal closes. The solution was to just force a new sid on the process."]], [[' 3556 pts/1    00:00:00 gvim <defunct>\n3557 ?        00:00:00 gvim\n']], ['background process in python with -e option on terminal'], 3, 0], [(11065100, 2), [["When the launching terminal closes, all processes with the same sid close. So the 'gvim defunct' disappears but the other persists. Programs which do not obtain a new pid/sid will quit when the launching terminal closes. The solution was to just force a new sid on the process."], ['-10000']], [[" import os\n\nif os.fork():\n    # parent\n    do_stuff()\n\nelse:\n    # child\n    os.setsid()\n    os.execl('prog', 'prog')\n"]], ['background process in python with -e option on terminal'], 3, 1], [(11066400, 0), [['You could use  unicode.translate()  method:'], ["You could also use  r'\\p{P}'  that is supported by  regex module :"]], [[" import unicodedata\nimport sys\n\ntbl = dict.fromkeys(i for i in xrange(sys.maxunicode)\n                      if unicodedata.category(unichr(i)).startswith('P'))\ndef remove_punctuation(text):\n    return text.translate(tbl)\n"]], ['Remove punctuation from Unicode formatted strings'], 2, 1], [(11066400, 1), [["You could also use  r'\\p{P}'  that is supported by  regex module :"], ['-10000']], [[' import regex as re\n\ndef remove_punctuation(text):\n    return re.sub(ur"\\p{P}+", "", text)\n']], ['Remove punctuation from Unicode formatted strings'], 2, 1], [(11078122, 0), [['The following code does what I think you want.'], ["You will likely find that if your letter size multiplied by your big array size is bigger than roughly Nlog(N), where N is corresponding size of the big array in which you're searching (for each dimension), then you will probably get a speed up by using an fft based algorithm like  scipy.signal.fftconvolve  (bearing in mind that you'll need to flip each axis of one of the datasets if you're using a convolution rather than a correlation -  flipud  and  fliplr ). The only modification would be to assigning c:"]], [[" import numpy\nfrom scipy import signal\n\n# Set up the inputs\na = numpy.random.randn(100, 200)\na[a<0] = 0\na[a>0] = 255\n\nb = numpy.random.randn(20, 20)\nb[b<0] = 0\nb[b>0] = 255\n\n# put b somewhere in a\na[37:37+b.shape[0], 84:84+b.shape[1]] = b\n\n# Now the actual solution...\n\n# Set the black values to -1\na[a==0] = -1\nb[b==0] = -1\n\n# and the white values to 1\na[a==255] = 1\nb[b==255] = 1\n\nmax_peak = numpy.prod(b.shape)\n\n# c will contain max_peak where the overlap is perfect\nc = signal.correlate(a, b, 'valid')\n\noverlaps = numpy.where(c == max_peak)\n\nprint overlaps\n"]], ['Finding matching submatrices inside a matrix'], 3, 1], [(11078122, 1), [["You will likely find that if your letter size multiplied by your big array size is bigger than roughly Nlog(N), where N is corresponding size of the big array in which you're searching (for each dimension), then you will probably get a speed up by using an fft based algorithm like  scipy.signal.fftconvolve  (bearing in mind that you'll need to flip each axis of one of the datasets if you're using a convolution rather than a correlation -  flipud  and  fliplr ). The only modification would be to assigning c:"], ['Comparing the timings on the sizes above:']], [[" c = signal.fftconvolve(a, numpy.fliplr(numpy.flipud(b)), 'valid')\n"]], ['Finding matching submatrices inside a matrix'], 3, 0], [(11078122, 2), [['Comparing the timings on the sizes above:'], ['-10000']], [[" In [5]: timeit c = signal.fftconvolve(a, numpy.fliplr(numpy.flipud(b)), 'valid')\n100 loops, best of 3: 6.78 ms per loop\n\nIn [6]: timeit c = signal.correlate(a, b, 'valid')\n10 loops, best of 3: 151 ms per loop\n"]], ['Finding matching submatrices inside a matrix'], 3, 0], [(11102829, 1), [['This is my first time writing Python, ever, so forgive my mistakes.'], ["The  re.escape(delimiter)  is necessary in case your delimiters have special characters in them.  For example, if your delimiter was  * ,  re.escape(...)  returns  \\* , so that your delimiter isn't translated as a regex quantifier."]], [['     # start with an array of delimeters\n    delimeters = [d1, d2, d3]\n\n    # start with a blank string\n    regex_delim = \'\'\n\n    # build the "delimiters regex" using alternation\n    for delimeter in delimeters:\n        regex_delim += re.escape(delimeter) + \'|\'\n\n    # remove the extra \'|\' at the end\n    regex_delim = regex_delim[:-1]\n\n    # compile the regex\n    regex_obj = re.compile(\'(\' + regex_delim + \')(.*?)(?=\' + regex_delim + \')\')\n\n    # and that should be it!\n    for match in regex_obj.finditer(html_str):\n        print match.group(2)\n']], ['Code a loop on a list of delimiters?'], 2, 1], [(11140628, 0), [['should be something like this:'], ['model.py']], [[" from django.db.models import Count\n\nusers = User.objects.annotate(num_followers=Count('to_users')).order_by('-num_followers')\n"]], ['Django - access foreign key data in an annotated query'], 3, 0], [(11140628, 1), [['model.py'], ['test']], [[" from django.contrib.auth.models import User\nfrom django.db import models\n\nclass Relationship(models.Model):\n    from_user = models.ForeignKey(User, related_name='from_users')\n    to_user = models.ForeignKey(User, related_name='to_users')\n"]], ['Django - access foreign key data in an annotated query'], 3, 0], [(11140628, 2), [['test'], ['EDIT2  fixed the typos, added the test']], [[" >>> from so.models import *\n>>> from django.contrib.auth.models import User\n>>> u1 = User()\n>>> u1.username='user1'\n>>> u1.save()\n>>> u2 = User()\n>>> u2.username='user2'\n>>> u2.save()\n>>> u3=User()\n>>> u3.username='user3'\n>>> u3.save()\n>>> # so we have 3 users now\n>>> r1 = Relationship()\n>>> r1.from_user=u1\n>>> r1.to_user=u2\n>>> r1.save()\n>>> r2=Relationship()\n>>> r2.from_user=u1\n>>> r2.to_user=u3\n>>> r2.save()\n>>> r3=Relationship()\n>>> r3.from_user=u2\n>>> r3.to_user=u3\n>>> r3.save()\n>>> rels = Relationship.objects.all()\n>>> rels.count()\n3\n>>> # we have 3 relationships: user1 follows user2, user1 follows user3, user2 follows user3\n>>> users = User.objects.annotate(num_followers=Count('to_users')).order_by('-num_followers')\n>>> for user in users:\n>>>     print user.username, user.num_followers\nuser3 2\nuser2 1\nuser1 0\n"]], ['Django - access foreign key data in an annotated query'], 3, 0], [(11159668, 0), [["You can do this by sorting on location and applying in reverse order.  Is order important in case of ties?  Then sort only by location, not location and sequence, so they will insert in the correct order.  For example, if inserting 999@1 then 888@1, if you sorted on both values you'd get 888@1,999@1."], ['But sorting only by location with a stable sort gives 999@1,888@1']], [[' 12345\n18889992345\n']], ['Insertions algorithm in sequence python'], 4, 0], [(11159668, 1), [['But sorting only by location with a stable sort gives 999@1,888@1'], ["Here's the code:"]], [[' 12345\n1999888345\n']], ['Insertions algorithm in sequence python'], 4, 0], [(11159668, 2), [["Here's the code:"], ['Result:']], [[" import random\nimport operator\n\n# Easier to use a mutable list than an immutable string for insertion.\nsequence = list('123456789123456789')\ninsertions = '999 888 777 666 555 444 333 222 111'.split()\nlocations = [random.randrange(len(sequence)) for i in xrange(10)]\nmodifications = zip(locations,insertions)\nprint modifications\n# sort them by location.\n# Since Python 2.2, sorts are guaranteed to be stable,\n# so if you insert 999 into 1, then 222 into 1, this will keep them\n# in the right order\nmodifications.sort(key=operator.itemgetter(0))\nprint modifications\n# apply in reverse order\nfor i,seq in reversed(modifications):\n    print 'insert {} into {}'.format(seq,i)\n    # Here's where using a mutable list helps\n    sequence[i:i] = list(seq)\n    print ''.join(sequence)\n"]], ['Insertions algorithm in sequence python'], 4, 1], [(11159668, 3), [['Result:'], ['-10000']], [[" [(11, '999'), (8, '888'), (7, '777'), (15, '666'), (12, '555'), (11, '444'), (0, '333'), (0, '222'), (15, '111')]\n[(0, '333'), (0, '222'), (7, '777'), (8, '888'), (11, '999'), (11, '444'), (12, '555'), (15, '666'), (15, '111')]\ninsert 111 into 15\n123456789123456111789\ninsert 666 into 15\n123456789123456666111789\ninsert 555 into 12\n123456789123555456666111789\ninsert 444 into 11\n123456789124443555456666111789\ninsert 999 into 11\n123456789129994443555456666111789\ninsert 888 into 8\n123456788889129994443555456666111789\ninsert 777 into 7\n123456777788889129994443555456666111789\ninsert 222 into 0\n222123456777788889129994443555456666111789\ninsert 333 into 0\n333222123456777788889129994443555456666111789\n"]], ['Insertions algorithm in sequence python'], 4, 0], [(11179879, 0), [['-10000'], ['output:']], [[" lis = []\nclass Object():\n    def __init__(self, var):\n        self.something = var \n        lis.append(self)  #here self is the reference to the instance being created and you can save it in a list to access it later\nxxx = Object('123')\nxx = Object('12')\nx = Object('1')\n\nfor x in lis:\n    print(x.something)\n"]], ['Simple OOP: Python, saving object names via __init__ v2'], 2, 1], [(11179879, 1), [['output:'], ['-10000']], [[' 123\n12\n1\n']], ['Simple OOP: Python, saving object names via __init__ v2'], 2, 0], [(11185516, 0), [["If you don't want to change anything in  func  then the sensible option would be passing a dict of arguments to the function:"], ['or just:']], [[" >>> def func(a=0,b=10):\n...  return a+b\n...\n>>> args = {'a':15,'b':15}\n>>> func(**args)\n30\n>>> args={'a':15}\n>>> func(**args)\n25\n>>> args={'b':6}\n>>> func(**args)\n6\n>>> args = {}\n>>> func(**args)\n10\n"]], ['Pythonic solution for conditional arguments passing'], 2, 1], [(11185516, 1), [['or just:'], ['-10000']], [[" >>>func(**{'a':7})\n17\n"]], ['Pythonic solution for conditional arguments passing'], 2, 0], [(11198718, 0), [['That is because you are opening , writing and closing the file 10 times inside your for loop'], ['You should open and close your file outside for loop.']], [[" myfile = open('xyz.txt', 'w')\nmyfile.writelines(var1)\nmyfile.close()\n"]], ['Writing to a file in a for loop'], 2, 0], [(11198718, 1), [['You should open and close your file outside for loop.'], ['You should also notice to  use write  and  not writelines . ']], [[' myfile = open(\'xyz.txt\', \'w\')\nfor line in lines:\n    var1, var2 = line.split(",");\n    myfile.write("%s\\n" % var1)\n\nmyfile.close()\ntext_file.close()\n']], ['Writing to a file in a for loop'], 2, 1], [(11207302, 0), [['You can simply try to resolve the address to a view:'], ['you can also make the check in a different way:']], [[' from django.core.urlresolvers import resolve\nfrom myapp.views import user_profile_view\n\ntry:\n    my_view = resolve("/%s/" % user_name)\n    if my_view == user_profile_view:\n        # We match the user_profile_view, so that\'s OK.\n    else:\n        # oops, we have another view that is mapped on that URL\n    # you already have something mapped on this address\nexcept:\n    # app doesn\'t have such path\n']], ['How to search a string with the url patterns in django?'], 3, 1], [(11207302, 1), [['you can also make the check in a different way:'], ['and then the check above could be:']], [[' def user_profile_view(request, user_name):\n    # some code here\n\nuser_profile_view.name = "User Profile View"\n']], ['How to search a string with the url patterns in django?'], 3, 0], [(11207302, 2), [['and then the check above could be:'], ['-10000']], [[' if getattr(my_view, "name", None) == "User Profile View":\n    ...\n']], ['How to search a string with the url patterns in django?'], 3, 0], [(11239815, 0), [['-10000'], ['output:']], [[" with open('data.txt') as f:\n    next(f)\n    d=dict()\n    for x in f:\n        if x.split()[0] not in d:\n            d[x.split()[0]]=float(x.split()[2])\n        else:\n            d[x.split()[0]]+=float(x.split()[2])\n"]], ['To sum column with condition'], 2, 1], [(11239815, 1), [['output:'], ['-10000']], [[" {'11': 9.7756, '10': 9.791699999999999, '12': 9.7925}\n"]], ['To sum column with condition'], 2, 0], [(11242667, 0), [['That is indeed rather messed up. A quick fix would be to replace the offending separators with a regular expression:'], ["You'll also need to remove the last comma:"]], [[' line = re.compile(r\'("[^"]*")\\s*=\\s*("[^"]*");\')\nresult = line.sub(r\'\\1: \\2,\', result)\n']], ["How to parse Apple's IAP receipt mal-formatted JSON?"], 3, 0], [(11242667, 1), [["You'll also need to remove the last comma:"], ['With these operations the example loads as json:']], [[" trailingcomma = re.compile(r',(\\s*})')\nresult = trailingcomma.sub(r'\\1', result)\n"]], ["How to parse Apple's IAP receipt mal-formatted JSON?"], 3, 0], [(11255432, 0), [['Sndfile.frames / Sndfile.samplerate  will give you the duration of the file in seconds, you can then use this in conjunction with elapsed time since since sound file start to compute relative current location. To illustrate the principle:'], ['In the parent thread you would then need to check  event.isSet()  accordingly:']], [[' import time\n\nstart_time = time.time()\nduration_s = sndfile.frames / sndfile.samplerate\n\nwhile 1:\n    elapsed_time = time.time() - start_time\n    current_location = elapsed_time / float(duration_s)\n    if current_location >= 1:\n         break\n    time.sleep(.01)\n']], ['Python module for playing sound data with progress bar?'], 2, 0], [(11255432, 1), [['In the parent thread you would then need to check  event.isSet()  accordingly:'], ['-10000']], [[' if current_location >= 1 or fail_event.isSet():\n    break\n']], ['Python module for playing sound data with progress bar?'], 2, 0], [(11265670, 0), [['Just store duration, start and end times in the database. You can always generate time intervals later:'], ['-10000']], [[' def time_range(start, end, duration):\n    dt = start\n    while dt < end: #note: `end` is not included in the range\n        yield dt\n        dt += duration\n']], ['Difference between two time intervals in series'], 2, 1], [(11269104, 0), [['You should turn this:'], ['into this:']], [[" d['dict1'] = [('value1', '1'), ('value2', '2')]\nd['dict2'] = [('value1', '3'), ('value2', '4')]\n"]], ['Loop through dictionary with django'], 3, 0], [(11269104, 1), [['into this:'], ['You can then iterate over the values easily:']], [[" result = [('value1', '1', '3'), ('value2', '2', '4')]\n"]], ['Loop through dictionary with django'], 3, 0], [(11269104, 2), [['You can then iterate over the values easily:'], ['-10000']], [[' {% for name, v1, v2 in result %}\n{{ v1 }}\n{{ v2 }}\n{% endfor %}\n']], ['Loop through dictionary with django'], 3, 0], [(11313599, 0), [["I know you were searching for a library, but as soon as I read this question I thought I'd write my own. So here it is:"], ['And I wrote another script to generate the "test.txt" file:']], [[' import os\n\nclass View:\n    def __init__(self, f, offset, length):\n        self.f = f\n        self.f_offset = offset\n        self.offset = 0\n        self.length = length\n\n    def seek(self, offset, whence=0):\n        if whence == os.SEEK_SET:\n            self.offset = offset\n        elif whence == os.SEEK_CUR:\n            self.offset += offset\n        elif whence == os.SEEK_END:\n            self.offset = self.length+offset\n        else:\n            # Other values of whence should raise an IOError\n            return self.f.seek(offset, whence)\n        return self.f.seek(self.offset+self.f_offset, os.SEEK_SET)\n\n    def tell(self):\n        return self.offset\n\n    def read(self, size=-1):\n        self.seek(self.offset)\n        if size<0:\n            size = self.length-self.offset\n        size = max(0, min(size, self.length-self.offset))\n        self.offset += size\n        return self.f.read(size)\n\nif __name__ == "__main__":\n    f = open(\'test.txt\', \'r\')\n\n    views = []\n    offsets = [i*11 for i in range(10)]\n\n    for o in offsets:\n        f.seek(o+1)\n        length = int(f.read(1))\n        views.append(View(f, o+2, length))\n\n    f.seek(0)\n\n    completes = {}\n    for v in views:\n        completes[v.f_offset] = v.read()\n        v.seek(0)\n\n    import collections\n    strs = collections.defaultdict(str)\n    for i in range(3):\n        for v in views:\n            strs[v.f_offset] += v.read(3)\n    strs = dict(strs) # We want it to raise KeyErrors after that.\n\n    for offset, s in completes.iteritems():\n        print offset, strs[offset], completes[offset]\n        assert strs[offset] == completes[offset], "Something went wrong!"\n']], ["How can I treat a section of a file as though it's a file itself?"], 2, 1], [(11313599, 1), [['And I wrote another script to generate the "test.txt" file:'], ["It worked for me. The files I tested on are not binary files like yours, and they're not as big as yours, but this might be useful, I hope. If not, then thank you, that was a good challenge :D"]], [[' import string, random\n\nf = open(\'test.txt\', \'w\')\n\nfor i in range(10):\n    rand_list = list(string.ascii_letters)\n    random.shuffle(rand_list)\n    rand_str = "".join(rand_list[:9])\n    f.write(".%d%s" % (len(rand_str), rand_str))\n']], ["How can I treat a section of a file as though it's a file itself?"], 2, 0], [(11314980, 0), [['You can use  macros , write a macro for class rendering, and then call it recursively:'], ["This works well, but  doesn't deal with the proper indentation of subclasses , yielding code like this:"]], [[' {% macro render_class(class) -%}\nclass {{ class.name }}\n{\n{% for field in class.fields %}\n    int {{ field }};\n{% endfor %}\n{% for subclass in class.subclasses %}\n{{ render_class(subclass) }}\n{% endfor %}\n}\n{%- endmacro %}\n\n{% for class in classes %}\n{{ render_class(class) }}\n{% endfor %}\n']], ['How to recursively call a macro in jinja2?'], 2, 1], [(11314980, 1), [["This works well, but  doesn't deal with the proper indentation of subclasses , yielding code like this:"], ['-10000']], [[' class Bar\n{\n    int meow;\n    int bark;\n\nclass SubBar\n{\n    int joe;\n    int pete;\n}\n}\n']], ['How to recursively call a macro in jinja2?'], 2, 0], [(11340765, 0), [["Not sure exactly what you're looking for, but will this work?"], ['If you just want to find the current value of the window, and set widgets to use it,  cget  might be what you want:']], [[' import Tkinter\n\nmycolor = \'#%02x%02x%02x\' % (64, 204, 208)  # set your favourite rgb color\nmycolor2 = \'#40E0D0\'  # or use hex if you prefer \nroot = Tkinter.Tk()\nroot.configure(bg=mycolor)\nTkinter.Button(root, text="Press me!", bg=mycolor, fg=\'black\',\n               activebackground=\'black\', activeforeground=mycolor2).pack()\nroot.mainloop()\n']], ['Default window colour Tkinter and hex colour codes'], 3, 1], [(11340765, 1), [['If you just want to find the current value of the window, and set widgets to use it,  cget  might be what you want:'], ['If you want to set the default background color for new widgets, you can use the  tk_setPalette(self, *args, **kw)  method:']], [[' import Tkinter\n\nroot = Tkinter.Tk()\ndefaultbg = root.cget(\'bg\')\nTkinter.Button(root,text="Press me!", bg=defaultbg).pack()\nroot.mainloop()\n']], ['Default window colour Tkinter and hex colour codes'], 3, 1], [(11345160, 0), [['Just pass the folder name as a parameter to your python script:'], ['In  myscript.py :']], [[' python myscript.py FolderName\n']], ['accessing files in a folder using python'], 2, 0], [(11345160, 1), [['In  myscript.py :'], ['sys.argv  gives you all the parameters.']], [[' import sys\nprint sys.argv[1]\n']], ['accessing files in a folder using python'], 2, 0], [(11382536, 0), [["The code takes all of the data in your file and assigns it to the variables as appropriate types (i.e., float and lists). The list parsing isn't particularly pretty, but it is functional."], ['yields:']], [[" import re\nwith open('data.txt') as inf:\n    salary = 0\n    for line in inf:\n        line = line.split('=')\n        line[0] = line[0].strip()\n        if line[0] == 'employee':\n            employee = re.sub(r'[]\\[\\' ]','', line[1].strip()).split(',')\n        elif line[0] == 'salary':\n            salary = float(line[1])\n        elif line[0] == 'managers':\n            managers = re.sub(r'[]\\[\\' ]','', line[1].strip()).split(',')\n\nprint employee\nprint salary\nprint managers\n"]], ['Search for a variable in a file and get its value with python'], 2, 1], [(11382536, 1), [['yields:'], ['-10000']], [[" ['Tom', 'Bob', 'Anny']\n200.0\n['Saly', 'Alice']\n"]], ['Search for a variable in a file and get its value with python'], 2, 0], [(11388032, 0), [['Believe it or not, all characters are already implicitly assigned a number: their ASCII character codes. You can access them by using the  ord()  function, or compare them directly:'], ['Beware though, capital letters are coded 65 - 90, while lowercase letters are coded 97 - 122, so:']], [[' >>> "a" > "b"\nFalse\n\n>>> "b" > "a"\nTrue\n']], ['How to figure out if a word in spelled in alphabetical order in Python'], 3, 0], [(11388032, 1), [['Beware though, capital letters are coded 65 - 90, while lowercase letters are coded 97 - 122, so:'], ["Here's one possible function that uses the above information to check if a given string is in alphabetical order, just to get you started:"]], [[' >>> "C" > "b"\nFalse\n']], ['How to figure out if a word in spelled in alphabetical order in Python'], 3, 0], [(11388032, 2), [["Here's one possible function that uses the above information to check if a given string is in alphabetical order, just to get you started:"], ['-10000']], [[' def isAlphabetical(word):\n    for i in xrange(len(word) - 1):\n        if word[i] > word[i+1]:\n            return False\n    return True\n']], ['How to figure out if a word in spelled in alphabetical order in Python'], 3, 1], [(11390421, 0), [["First, create a dict (a  defaultdict  was even more convenient here) that will gather the files for a date (it's good to use  re , but given the names of your files using  split  was easier):"], ['Then for each date, create a subfolder and copy the corresponding files there:']], [[" >>> import os\n>>> import re\n>>> pat = r'(\\d+)(?:_\\d+)?_(\\w+?)[\\._].*'\n>>> from collections import defaultdict\n>>> dict_date = defaultdict(lambda : defaultdict(list))\n>>> for fil in os.listdir(path):\n    if os.path.isfile(os.path.join(path, fil)):\n        date, animal = re.match(pat, fil).groups()\n        dict_date[date][animal].append(fil)\n\n\n>>> dict_date['20120807']\ndefaultdict(<type 'list'>, {'first': ['20120807_first_day_pic.jpg', '20120807_first_day_sheet.jpg', '20120807_first_day_sheet2.jpg']})\n"]], ['Put all files with same name in a folder'], 2, 0], [(11390421, 1), [['Then for each date, create a subfolder and copy the corresponding files there:'], ["EDIT : took into account OP's new requirements, and Khalid's remark."]], [[' >>> from shutil import copyfile\n>>> for date in dict_date:\n        for animal in dict_date[date]:\n        try:\n            os.makedirs(os.path.join(path, date, animal))\n        except os.error:\n            pass\n        for fil in dict_date[date][animal]:\n            copyfile(os.path.join(path, fil), os.path.join(path, date, animal, fil))\n']], ['Put all files with same name in a folder'], 2, 0], [(11444222, 0), [['The docs (  http://matplotlib.sourceforge.net/api/pyplot_api.html#matplotlib.pyplot.imshow  ) say that you can pass an MxNx4 array of RGBA values to imshow. So, assuming ca_map is MxNx3, you could do something like:'], ['Or if ca_map is MxN, then:']], [[' plt.imshow(np.dstack([ca_map, alpha], ...)\n']], ['How to set the alpha value for each element of a numpy array'], 2, 1], [(11444222, 1), [['Or if ca_map is MxN, then:'], ['-10000']], [[' plt.imshow(np.dstack([ca_map, ca_map, ca_map, alpha], ...)\n']], ['How to set the alpha value for each element of a numpy array'], 2, 1], [(11457839, 0), [['See  populate  method. Also there is some examples in  documentation'], ['Code for your concrete case:']], [[' #!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sys\nfrom PyQt4 import QtCore, QtGui\n\n\nclass MainWindow(QtGui.QWidget):\n\n    def __init__(self, parent=None):\n\n        self.fileheader_fields=(\n            "filetype","fileversion","numframes",\n            "framerate","resolution","numbeams",\n            "samplerate","samplesperchannel","receivergain",\n            "windowstart","winlengthsindex","reverse",\n            "serialnumber","date","idstring","ID1","ID2",\n            "ID3","ID4","framestart","frameend","timelapse",\n            "recordInterval","radioseconds","frameinterval","userassigned"\n        )\n        # just for test\n        self.fileheader = {field: \'value of \' + field \n                           for field in self.fileheader_fields}\n        super(MainWindow, self).__init__(parent)\n        self.table_widget = QtGui.QTableWidget()\n        layout = QtGui.QVBoxLayout()\n        layout.addWidget(self.table_widget)\n        self.setLayout(layout)\n        self.populate()\n\n    def populate(self):\n        self.table_widget.setRowCount(len(self.fileheader_fields))\n        self.table_widget.setColumnCount(2)\n        self.table_widget.setHorizontalHeaderLabels([\'name\', \'value\'])\n        for i, field in enumerate(self.fileheader_fields):\n            name = QtGui.QTableWidgetItem(field)\n            value = QtGui.QTableWidgetItem(self.fileheader[field])\n            self.table_widget.setItem(i, 0, name)\n            self.table_widget.setItem(i, 1, value)\n\n\nif __name__ == "__main__":\n    app = QtGui.QApplication(sys.argv)\n    wnd = MainWindow()\n    wnd.resize(640, 480)\n    wnd.show()\n    sys.exit(app.exec_())\n']], ['Populating a table in PyQt with file attributes'], 2, 1], [(11488877, 0), [['-10000'], ['-10000']], [['The simple solution import threading\n\ndef work (): \n  threading.Timer(0.25, work).start ()\n  print "stackoverflow"\n\nwork ()\n']], ['Periodically execute function in thread in real time, every N seconds'], 2, 1], [(11488877, 1), [['-10000'], ['-10000']], [[' import threading\n\ndef do_every (interval, worker_func, iterations = 0):\n  if iterations != 1:\n    threading.Timer (\n      interval,\n      do_every, [interval, worker_func, 0 if iterations == 0 else iterations-1]\n    ).start ()\n\n  worker_func ()\n\ndef print_hw ():\n  print "hello world"\n\ndef print_so ():\n  print "stackoverflow"\n\n\n# call print_so every second, 5 times total\ndo_every (1, print_so, 5)\n\n# call print_hw two times per second, forever\ndo_every (0.5, print_hw)\n']], ['Periodically execute function in thread in real time, every N seconds'], 2, 1], [(11514277, 0), [['Use Group to create a hierarchy in the parsed tokens. Then you can navigate lists of groups and access named fields within them. Something like this:'], ['Prints:']], [[' from pyparsing import *\n\nLPAR,RPAR,COMMA,HASH,COLON = map(Suppress, \'(),#:\')\nident = Word(alphas+\'_\', alphanums+\'_\')\nfnumber = Regex(r\'[+-]?\\d+\\.\\d*\').setParseAction(lambda t:float(t[0]))\ninumber = Regex(r\'[+-]?\\d+\').setParseAction(lambda t:int(t[0]))\nnumber = fnumber | inumber\nref_name = Combine("$" + delimitedList(ident, delim=oneOf(". ->"), combine=True))\nnamed_ref = Group(ident("name") + COLON + ref_name("ref"))\nunnamed_ref = Group(ref_name("ref"))\n\nIF, ELSE = map(Keyword, "if else".split())\n\nstmt = Forward()\n\ndecl = named_ref | unnamed_ref\n\ndef setType(typ):\n    def parseAction(tokens):\n        tokens[\'type\'] = typ\n    return parseAction\ncond = operatorPrecedence(ref_name | number,\n            [\n            (oneOf("< == > <= >= !="), 2, opAssoc.LEFT),\n            ])\nif_else = Group(HASH + IF + LPAR + cond("condition") + RPAR + \n                    LPAR + stmt("then") + RPAR + \n                    Optional(HASH + ELSE + LPAR + stmt("else") + RPAR))\n\nif_else.setParseAction(setType("IF_ELSE"))\ndecl.setParseAction(setType("DECL"))\n\nstmt << Group(decl | if_else | (HASH + LPAR + delimitedList(stmt) + RPAR))\n\nsection = Group(ident("section_name") + LPAR + Group(ZeroOrMore(stmt))("section_body") + RPAR)\n\nparser = OneOrMore(section)\n\n\nsource = """\npreview \n( \n    #if ($e.d.stateFlags == 0) ( \n        $e.d \n    ) #else ( \n        #( $e.d->scheme, $e.d->host, $e.d->path ) \n    ) \n) \nchildren \n( \n    #( \n        scheme: $c.d->scheme, \n        host: $c.d->host, \n        path: $c.d->path, \n        username: $c.d->userName, \n        password: $c.d->password, \n        encodedOriginal: $c.d->encodedOriginal, \n        query: $c.d->query, \n        fragment: $c.d->fragment \n    ) \n)"""\n\n\ndef dump_stmt(tokens, depth=0):\n    if \'type\' in tokens:\n        print tokens.type\n        print tokens[0].dump(depth=depth)\n    else:\n        for stmt in tokens:\n            dump_stmt(stmt, depth=depth+1)\n\nfor sec in parser.parseString(source):\n    print sec.dump()\n    print sec.section_name\n    for statement in sec.section_body:\n        dump_stmt(statement)\n    print\n']], ['How can I use pyparsing to data from VC++ autoexp.dat?'], 2, 1], [(11514277, 1), [['Prints:'], ['-10000']], [[" ['preview', [[['if', ['$e.d.stateFlags', '==', 0], [['$e.d']], 'else', [[['$e.d->scheme']], [['$e.d->host']], [['$e.d->path']]]]]]]\n- section_body: [[['if', ['$e.d.stateFlags', '==', 0], [['$e.d']], 'else', [[['$e.d->scheme']], [['$e.d->host']], [['$e.d->path']]]]]]\n- section_name: preview\npreview\nIF_ELSE\n['if', ['$e.d.stateFlags', '==', 0], [['$e.d']], 'else', [[['$e.d->scheme']], [['$e.d->host']], [['$e.d->path']]]]\n- condition: ['$e.d.stateFlags', '==', 0]\n- else: [[['$e.d->scheme']], [['$e.d->host']], [['$e.d->path']]]\n- then: [['$e.d']]\n  - type: DECL\n\n['children', [[[['scheme', '$c.d->scheme']], [['host', '$c.d->host']], [['path', '$c.d->path']], [['username', '$c.d->userName']], [['password', '$c.d->password']], [['encodedOriginal', '$c.d->encodedOriginal']], [['query', '$c.d->query']], [['fragment', '$c.d->fragment']]]]]\n- section_body: [[[['scheme', '$c.d->scheme']], [['host', '$c.d->host']], [['path', '$c.d->path']], [['username', '$c.d->userName']], [['password', '$c.d->password']], [['encodedOriginal', '$c.d->encodedOriginal']], [['query', '$c.d->query']], [['fragment', '$c.d->fragment']]]]\n- section_name: children\nchildren\nDECL\n['scheme', '$c.d->scheme']\n  - name: scheme\n  - ref: $c.d->scheme\nDECL\n['host', '$c.d->host']\n  - name: host\n  - ref: $c.d->host\nDECL\n['path', '$c.d->path']\n  - name: path\n  - ref: $c.d->path\nDECL\n['username', '$c.d->userName']\n  - name: username\n  - ref: $c.d->userName\nDECL\n['password', '$c.d->password']\n  - name: password\n  - ref: $c.d->password\nDECL\n['encodedOriginal', '$c.d->encodedOriginal']\n  - name: encodedOriginal\n  - ref: $c.d->encodedOriginal\nDECL\n['query', '$c.d->query']\n  - name: query\n  - ref: $c.d->query\nDECL\n['fragment', '$c.d->fragment']\n  - name: fragment\n  - ref: $c.d->fragment\n"]], ['How can I use pyparsing to data from VC++ autoexp.dat?'], 2, 0], [(11519787, 0), [['max  takes a key argument , with it you can tell max how to calculate the value for each item in an iterable.  sum  will do nicely here:'], ['Demo:']], [[' max(x, key=sum)\n']], ['How to find the list in a list of lists whose sum of elements is the greatest?'], 3, 1], [(11519787, 1), [['Demo:'], ['If you need to use a different method of summing your items, you can specify your own functions too; this is not limited to the python built-in functions:']], [[' >>> x = [[1,2,3], [4,5,6], [7,8,9], [2,2,0]]\n>>> max(x, key=sum)\n[7, 8, 9]\n']], ['How to find the list in a list of lists whose sum of elements is the greatest?'], 3, 1], [(11519787, 2), [['If you need to use a different method of summing your items, you can specify your own functions too; this is not limited to the python built-in functions:'], ['-10000']], [[" >>> def mymaxfunction(item):\n...     return sum(map(int, item))\n...\n>>> max([['1', '2', '3'], ['7', '8', '9']], key=mymaxfunction)\n['7', '8', '9']\n"]], ['How to find the list in a list of lists whose sum of elements is the greatest?'], 3, 1], [(11576779, 0), [['-10000'], ['which you can use with']], [['The code import math\n\n# Build a cost dictionary, assuming Zipf\'s law and cost = -math.log(probability).\nwords = open("words-by-frequency.txt").read().split()\nwordcost = dict((k,math.log((i+1)*math.log(len(words)))) for i,k in enumerate(words))\nmaxword = max(len(x) for x in words)\n\ndef infer_spaces(s):\n    """Uses dynamic programming to infer the location of spaces in a string\n    without spaces."""\n\n    # Find the best match for the i first characters, assuming cost has\n    # been built for the i-1 first characters.\n    # Returns a pair (match_cost, match_length).\n    def best_match(i):\n        candidates = enumerate(reversed(cost[max(0, i-maxword):i]))\n        return min((c + wordcost.get(s[i-k-1:i], 9e999), k+1) for k,c in candidates)\n\n    # Build the cost array.\n    cost = [0]\n    for i in range(1,len(s)+1):\n        c,k = best_match(i)\n        cost.append(c)\n\n    # Backtrack to recover the minimal-cost string.\n    out = []\n    i = len(s)\n    while i>0:\n        c,k = best_match(i)\n        assert c == cost[i]\n        out.append(s[i-k:i])\n        i -= k\n\n    return " ".join(reversed(out))\n']], ['How to extract literal words from a consecutive string efficiently?'], 2, 1], [(11576779, 1), [['which you can use with'], ['-10000']], [[" s = 'thumbgreenappleactiveassignmentweeklymetaphor'\nprint(infer_spaces(s))\n"]], ['How to extract literal words from a consecutive string efficiently?'], 2, 0], [(11611183, 0), [["Based on katrielalex's suggestion, how about this:"], ["and if you're into negative lookbehind assertions, this is the headache inducing pure regex version:"]], [[' >>> import re\n>>> s = "INSERT INTO addresses VALUES (\'1\',\'1\',\'CUCKOO\'S NEST\',\'CUCKOO\'S NEST STREET\');"\n>>> def repl(m):\n    if m.group(1) in (\'(\', \',\') or m.group(2) in (\',\', \')\'):\n        return m.group(0)\n    return m.group(1) + "\'\'" + m.group(2)\n\n>>> re.sub("(.)\'(.)", repl, s)\n"INSERT INTO addresses VALUES (\'1\',\'1\',\'CUCKOO\'\'S NEST\',\'CUCKOO\'\'S NEST STREET\');"\n']], ['Replace single quotes with double quotes in python, for use with insert into database'], 2, 1], [(11611183, 1), [["and if you're into negative lookbehind assertions, this is the headache inducing pure regex version:"], ['-10000']], [[' re.sub("((?<![(,])\'(?![,)]))", "\'\'", s)\n']], ['Replace single quotes with double quotes in python, for use with insert into database'], 2, 0], [(11623769, 0), [['Example for Z only :'], ['If you want to interpolate the actual X and Y coordinates, you do something similar. You will need to interpolate x/z and y/z and relinearize the result by multiplying by z.']], [[' def GetInterpolatedZ(triangle, u, v):\n    z0 = 1.0 / triangle[0].z\n    z1 = 1.0 / triangle[1].z\n    z2 = 1.0 / triangle[2].z\n    z = z0 + u * (z1-z0) + v * (z2-z0)\n    return 1.0/z\n']], ['Retrieving the actual 3D coordinates of a point on a triangle that has been flattened to 2 dimensions'], 2, 0], [(11623769, 1), [['If you want to interpolate the actual X and Y coordinates, you do something similar. You will need to interpolate x/z and y/z and relinearize the result by multiplying by z.'], ['Again,  tri  is a list of the three vectors and  u, v  are the barycentric coordinates for  tri[1], tri[2] .  Vec3  is a regular 3 components Euclidean vector type.']], [[' def GetInterpolatedZ(tri, u, v):\n    t0 = Vec3(tri[0].x/tri[0].z, tri[0].y/tri[0].z, 1.0/tri[0].z)\n    t1 = Vec3(tri[1].x/tri[1].z, tri[1].y/tri[1].z, 1.0/tri[1].z)\n    t2 = Vec3(tri[2].x/tri[2].z, tri[2].y/tri[2].z, 1.0/tri[2].z)\n\n    inter = t0 + u * (t1-t0) + v * (t2-t0)\n    inter.z = 1.0 / inter.z\n    inter.x *= inter.z\n    inter.y *= inter.z\n    return inter\n']], ['Retrieving the actual 3D coordinates of a point on a triangle that has been flattened to 2 dimensions'], 2, 1], [(11624362, 0), [['If your goal is to just compare all the unique combinations of the set, you could make use of  itertools.combinations'], ['Example:']], [[' from itertools import combinations\n\nfor i, j in combinations(self.objects, 2):\n    if pygame.sprite.collide_rect(i, j):\n        grid.collisions.append(Collision(i, j))\n']], ["Python: Iterating through a set so we don't compare the same objects multiple times?"], 2, 1], [(11624362, 1), [['Example:'], ['combinations  produces a generator which is pretty efficient, compared to managing multiple indexs and temporary lists']], [[' aSet = set([1,2,3,4])\nlist(combinations(aSet, 2))\n# [(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n']], ["Python: Iterating through a set so we don't compare the same objects multiple times?"], 2, 0], [(11649577, 1), [['must be all true. Such an  s  is exactly what  np.argsort  returns:'], ['-10000']], [[' >>> p = np.array([3, 2, 0, 1])\n>>> np.argsort(p)\narray([2, 3, 1, 0])\n>>> p[np.argsort(p)]\narray([0, 1, 2, 3])\n']], ['How to invert a permutation array in numpy'], 2, 1], [(11668603, 0), [['With  pandas   groupby  this would be'], ['Using the example of the OP:']], [[' import pandas as pd\n\ndef with_pandas_groupby(func, x, b):\n    grouped = pd.Series(x).groupby(b)\n    return grouped.agg(func)\n']], ['Applying a function by bins on a vector in Numpy'], 7, 1], [(11668603, 1), [['Using the example of the OP:'], ['apply_to_bins_groupby']], [[' >>> x = [1,2,3,4,5,6]\n>>> b = ["a","b","a","a","c","c"]\n>>> with_pandas_groupby(np.prod, x, b)\na    12\nb     2\nc    30\n']], ['Applying a function by bins on a vector in Numpy'], 7, 0], [(11668603, 2), [['apply_to_bins_groupby'], ['-10000']], [['  3 levels,      100 values: 175 us per loop\n 3 levels,     1000 values: 1.16 ms per loop\n 3 levels,  1000000 values: 1.21 s per loop\n\n10 levels,      100 values: 304 us per loop\n10 levels,     1000 values: 1.32 ms per loop\n10 levels,  1000000 values: 1.23 s per loop\n\n26 levels,      100 values: 554 us per loop\n26 levels,     1000 values: 1.59 ms per loop\n26 levels,  1000000 values: 1.27 s per loop\n']], ['Applying a function by bins on a vector in Numpy'], 7, 0], [(11668603, 3), [['-10000'], ['-10000']], [['  3 levels,      100 values: 136 us per loop\n 3 levels,     1000 values: 259 us per loop\n 3 levels,  1000000 values: 205 ms per loop\n\n10 levels,      100 values: 297 us per loop\n10 levels,     1000 values: 447 us per loop\n10 levels,  1000000 values: 262 ms per loop\n\n26 levels,      100 values: 617 us per loop\n26 levels,     1000 values: 795 us per loop\n26 levels,  1000000 values: 299 ms per loop\n']], ['Applying a function by bins on a vector in Numpy'], 7, 0], [(11668603, 4), [['-10000'], ['-10000']], [['  3 levels,      100 values: 365 us per loop\n 3 levels,     1000 values: 443 us per loop\n 3 levels,  1000000 values: 89.4 ms per loop\n\n10 levels,      100 values: 369 us per loop\n10 levels,     1000 values: 453 us per loop\n10 levels,  1000000 values: 88.8 ms per loop\n\n26 levels,      100 values: 382 us per loop\n26 levels,     1000 values: 466 us per loop\n26 levels,  1000000 values: 89.9 ms per loop\n']], ['Applying a function by bins on a vector in Numpy'], 7, 0], [(11668603, 5), [['-10000'], ['And then run the benchmark in  ipython  like this:']], [[" def gen_data(levels, size):\n    choices = 'abcdefghijklmnopqrstuvwxyz'\n    levels = np.asarray([l for l in choices[:nlevels]])\n    index = np.random.random_integers(0, levels.size - 1, size)\n    b = levels[index]\n    x = np.arange(1, size + 1)\n    return x, b\n"]], ['Applying a function by bins on a vector in Numpy'], 7, 0], [(11668603, 6), [['And then run the benchmark in  ipython  like this:'], ['-10000']], [[" In [174]: for nlevels in (3, 10, 26):\n   .....:     for size in (100, 1000, 10e5):\n   .....:         x, b = gen_data(nlevels, size)\n   .....:         print '%2d levels, ' % nlevels, '%7d values:' % size,\n   .....:         %timeit function_to_time(np.prod, x, b)\n   .....:     print\n"]], ['Applying a function by bins on a vector in Numpy'], 7, 0], [(11676649, 0), [["XPath is great for this kind of stuff.  //TYPE[NUMBER='7721' and DATA]  will find all the TYPE nodes that have at least one NUMBER child with text '7721' and at least one DATA child:"], ['Outputs:']], [[' from lxml import etree\n\nxmlstr = """<html>\n  <A>\n    <B>\n      <C>\n        <D>\n          <TYPE>\n            <NUMBER>7297</NUMBER>\n            <DATA />\n          </TYPE>\n          <TYPE>\n            <NUMBER>7721</NUMBER>\n            <DATA>A=1,B=2,C=3,</DATA>\n          </TYPE>\n        </D>\n      </C>\n    </B>\n  </A>\n</html>"""\n\nhtml_element = etree.fromstring(xmlstr)\n\n# find all the TYPE nodes that have NUMBER=7721 and DATA nodes\ntype_nodes = html_element.xpath("//TYPE[NUMBER=\'7721\' and DATA]")\n\n# the for loop is probably superfluous, but who knows, there might be more than one!\nfor t in type_nodes:\n    d = t.find(\'DATA\')\n    # example: append spamandeggs to the end of the data text\n    if d.text is None:\n        d.text = \'spamandeggs\'\n    else:\n        d.text += \'spamandeggs\'\nprint etree.tostring(html_element)\n']], ['Change specific repeating element in .xml using Python'], 2, 1], [(11676649, 1), [['Outputs:'], ['-10000']], [[' <html>\n  <A>\n    <B>\n      <C>\n        <D>\n          <TYPE>\n            <NUMBER>7297</NUMBER>\n            <DATA/>\n          </TYPE>\n          <TYPE>\n            <NUMBER>7721</NUMBER>\n            <DATA>A=1,B=2,C=3,spamandeggs</DATA>\n          </TYPE>\n        </D>\n      </C>\n    </B>\n  </A>\n</html>\n']], ['Change specific repeating element in .xml using Python'], 2, 0], [(11691679, 0), [["First, let's write a function that turns one of your strings (from csv or xml) into a dictionary:"], ['Now we want to get this dictionary for both the csv data and the xml data:']], [[" def string_to_dict(string):\n    # Split the string on commas\n    list_of_entries = string.split(',')\n    # Each of these entries needs to be split on '='\n    # We'll use a list comprehension\n    list_of_split_entries = map(lambda e: e.split('='), list_of_entries)\n    # Now we have a list of (key, value) pairs.  We can pass this\n    # to the dict() function to get a dictionary out of this, and \n    # that's what we want to return\n    return dict(list_of_split_entries)\n"]], ['Update dictionary in xml from csv file in python'], 5, 0], [(11691679, 1), [['Now we want to get this dictionary for both the csv data and the xml data:'], ["Using the  update  function, we can add the values from csv_dict to xml_dict, overwriting where they're the same:"]], [[" csv_dict = string_to_dict(csv_data)\n# csv_dict = {'AAK': '1|2|8', 'AAC': '1|1|1'}\nxml_dict = string_to_dict(d.text)\n# xml_dict = {'ABC': '1|3|5', 'FFK': '33', 'AAC': '7|3|8', 'DAK': '5|1|3'}\n"]], ['Update dictionary in xml from csv file in python'], 5, 0], [(11691679, 2), [["Using the  update  function, we can add the values from csv_dict to xml_dict, overwriting where they're the same:"], ['Now we need to get  xml_dict  back into a string.  The simple way to do this is:']], [[" xml_dict.update(csv_dict)\n# xml_dict = {'ABC': '1|3|5', 'FFK': '33', 'AAC': '1|1|1', 'AAK': '1|2|8', 'DAK': '5|1|3'}\n"]], ['Update dictionary in xml from csv file in python'], 5, 0], [(11691679, 3), [['Now we need to get  xml_dict  back into a string.  The simple way to do this is:'], ['If you want to keep them sorted, you can do it this way:']], [[" # Let's get a list of key=value strings\nlist_of_items = ['%s=%s' % (k, v) for k, v in xml_dict.iteritems()]\n# Now join those items together\nnew_xml_text = ','.join(list_of_items)\nd.text = new_xml_text\n"]], ['Update dictionary in xml from csv file in python'], 5, 0], [(11691679, 4), [['If you want to keep them sorted, you can do it this way:'], ['-10000']], [[" d.text = ','.join('%s=%s' % (k, xml_dict[k]) for k in sorted(xml_dict.keys()))\n"]], ['Update dictionary in xml from csv file in python'], 5, 0], [(11762422, 0), [["Regarding the display of a serie of vectors in 3D, I came with following 'almost working' solution:"], ['Here is the code (cannot use it as such since it refers to class members, but you can build your code based on 3d plot methods from matplotlib I am using)']], [[" def visualizeSignals(self, imin, imax):\n\n    times = self.time[imin:imax]\n    nrows = (int)((times[(len(times)-1)] - times[0])/self.mod) + 1\n\n    fig = plt.figure('2d profiles')\n    ax = fig.gca(projection='3d')\n    for i in range(nrows-1):\n        x = self.mat1[i][0] + self.mod * i\n        y = np.array(self.mat1T[i])\n        z = np.array(self.mat2[i])\n        ax.plot(y, z, zs = x, zdir='z')\n\n    plt.show()\n"]], ['matplotlib wireframe plot / 3d plot howTo'], 2, 0], [(11805535, 0), [['Instead of a regular expression, you might be better off using the  csv  module since what you are dealing with is a CSV string:'], ['This results in the following output:']], [[' from cStringIO import StringIO\nfrom csv import reader\n\nfile_like_object = StringIO("1,,2,\'3,4\'")\ncsv_reader = reader(file_like_object, quotechar="\'")\nfor row in csv_reader:\n    print row\n']], ['Transform comma separated string into a list but ignore comma in quotes'], 2, 1], [(11805535, 1), [['This results in the following output:'], ['-10000']], [[" ['1', '', '2', '3,4']\n"]], ['Transform comma separated string into a list but ignore comma in quotes'], 2, 0], [(11816741, 0), [['-10000'], ['Now define a subclass A2:']], [[' import unittest\nclass TestCaseA(unittest.TestCase):\n    def setUp(self):\n        self.thing = A()\n\n    def test_does_x():\n        self.assertTrue(self.thing.does_x())\n']], ['Test subclass behaviour?'], 3, 0], [(11816741, 1), [['Now define a subclass A2:'], ['So your test subclass would be just:']], [[' class A2(A):\n    ...\n']], ['Test subclass behaviour?'], 3, 0], [(11816741, 2), [['So your test subclass would be just:'], ['-10000']], [[' class TestA2(TestCaseA):\n    def setUp(self):\n        self.thing = A2()\n']], ['Test subclass behaviour?'], 3, 0], [(11827100, 0), [['We can vectorise this by augmenting the arrays with a discriminator index, such that  a  is tagged  0  and  b  is tagged  1 :'], ["Now, let's combine and sort:"]], [[' a_t = np.vstack((a, np.zeros_like(a)))\nb_t = np.vstack((b, np.ones_like(b)))\n']], ['Interleaving two numpy index arrays, one item from each array'], 4, 0], [(11827100, 1), [["Now, let's combine and sort:"], ["So, let's select the first element and each element where the tag changes from  0  (for  a ) to  1  (for  b ) and back again:"]], [[' c = np.hstack((a_t, b_t))[:, np.argsort(np.hstack((a, b)))]\narray([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 13, 14, 15, 17, 19, 21, 23],\n       [ 0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  1,  1,  1,  0,  1,  1,  1]])\n']], ['Interleaving two numpy index arrays, one item from each array'], 4, 0], [(11827100, 2), [["So, let's select the first element and each element where the tag changes from  0  (for  a ) to  1  (for  b ) and back again:"], ['-10000']], [[' c[:, np.concatenate(([True], c[1, 1:] != c[1, :-1]))][0]\narray([ 1,  5,  7, 13, 17, 19])\n']], ['Interleaving two numpy index arrays, one item from each array'], 4, 0], [(11827100, 3), [['-10000'], ['This is slightly more efficient than the above solution; I get an average of 45 as opposed to 90 microseconds, although your conditions may vary.']], [[' ab = np.hstack((a, b))\ns = np.argsort(ab)\nt = np.hstack((np.zeros_like(a), np.ones_like(b)))[s]\nab[s][np.concatenate(([True], t[1:] != t[:-1]))]\narray([ 1,  5,  7, 13, 17, 19])\n']], ['Interleaving two numpy index arrays, one item from each array'], 4, 1], [(11830474, 0), [['You can transpose and flatten the arrays:'], ['An alternative way to combine the arrays is to use  numpy.vstack() :']], [[' d = numpy.array([a, b, c]).T.flatten()\n']], ['Numpy union arrays in order'], 4, 1], [(11830474, 1), [['An alternative way to combine the arrays is to use  numpy.vstack() :'], ['Edit : In response to the  answer by Nicolas Barbey , here is how to make do with copying the data only once:']], [[' d = numpy.vstack((a, b, c)).T.flatten()\n']], ['Numpy union arrays in order'], 4, 1], [(11830474, 2), [['Edit : In response to the  answer by Nicolas Barbey , here is how to make do with copying the data only once:'], ['This code ensures that the data is layed out in a way that  ravel() \ndoes not need to make a copy, and indeed it is quite a bit faster than the original code on my machine:']], [[' d = numpy.empty((len(a), 3), dtype=a.dtype)\nd[:, 0], d[:, 1], d[:, 2] = a, b, c\nd = d.ravel()\n']], ['Numpy union arrays in order'], 4, 1], [(11830474, 3), [['This code ensures that the data is layed out in a way that  ravel() \ndoes not need to make a copy, and indeed it is quite a bit faster than the original code on my machine:'], ['-10000']], [[' In [1]: a = numpy.arange(0, 30000, 3)\nIn [2]: b = numpy.arange(1, 30000, 3)\nIn [3]: c = numpy.arange(2, 30000, 3)\nIn [4]: def f(a, b, c):\n   ...:     d = numpy.empty((len(a), 3), dtype=a.dtype)\n   ...:     d[:, 0], d[:, 1], d[:, 2] = a, b, c\n   ...:     return d.ravel()\n   ...: \nIn [5]: def g(a, b, c):\n   ...:     return numpy.vstack((a, b, c)).T.ravel()\n   ...: \nIn [6]: %timeit f(a, b, c)\n10000 loops, best of 3: 34.4 us per loop\nIn [7]: %timeit g(a, b, c)\n10000 loops, best of 3: 177 us per loop\n']], ['Numpy union arrays in order'], 4, 1], [(11832984, 0), [['-10000'], ['result:']], [[" def remove_cruft(s):\n    return s[4:-4]\n\nsites=['www.hattrick.com', 'www.google.com', 'www.wampum.net', 'www.newcom.com']\n[remove_cruft(s) for s in sites]\n"]], ['removing first four and last four characters of strings in list, OR removing specific character patterns'], 4, 1], [(11832984, 1), [['result:'], ['If you know all of the strings you want to strip out, you can use  replace  to get rid of them. This is useful if you\'re not sure that all of your URLs will start with "www.", or if the TLD isn\'t three characters long.']], [[" ['hattrick', 'google', 'wampum', 'newcom']\n"]], ['removing first four and last four characters of strings in list, OR removing specific character patterns'], 4, 0], [(11832984, 3), [['result:'], ['-10000']], [[" ['hattrick', 'google', 'wampum', 'newcom', 'smithsonian']\n"]], ['removing first four and last four characters of strings in list, OR removing specific character patterns'], 4, 0], [(11897977, 0), [['-10000'], ['Edit:']], [[' import re\n\ns = "foo[bar]baz"\nm = re.search("[\\[\\]]", s)\nprint m.group(0)\n# => \'[\'\n\nt = "foo-bar]baz"\nn = re.search("[\\[\\]]", t)\nprint n.group(0)\n# => \']\'\n']], ['Search for brackets in a case insensitive using regular expressions'], 2, 1], [(11902626, 0), [['To resize automatically, you want the  expand  kwarg:'], ['On the black background, you need to  specify the transparent colour  when saving your GIF image:']], [[' src_im = Image.open("test.gif")\nim = src_im.rotate(30, expand=True)\nim.save("result.gif")\n']], ['Python Django how to rotate image and remove black color?'], 2, 0], [(11902626, 1), [['On the black background, you need to  specify the transparent colour  when saving your GIF image:'], ['-10000']], [[" transparency = im.info['transparency'] \nim.save('icon.gif', transparency=transparency)\n"]], ['Python Django how to rotate image and remove black color?'], 2, 0], [(11939631, 0), [['You could use  lxml  library  in Python:'], ['If you are familiar with jQuery; you could use  pyquery . It adds jQuery interface on top of lxml:']], [[" #!/usr/bin/env python\nimport urllib2\nfrom lxml import html # $ apt-get install python-lxml or $ pip install lxml\n\npage = urllib2.urlopen('http://stackoverflow.com/q/11939631')\ndoc = html.parse(page).getroot()\n\ndiv = doc.get_element_by_id('question')\nfor tr in div.find('table').iterchildren('tr'):\n    for td in tr.iterchildren('td'):\n        print(td.text_content()) # process td\n"]], ['Is there an easy way to parse an HTML document and remove everything except a particular table?'], 3, 1], [(11939631, 1), [['If you are familiar with jQuery; you could use  pyquery . It adds jQuery interface on top of lxml:'], ["Though in this case  pyquery  doesn't add enough. Here's the same using only  lxml :"]], [[' #!/usr/bin/env python\nfrom pyquery import PyQuery # $ apt-get install python-pyquery or\n                            # $ pip install pyquery\n\n# d is like the $ in jquery\nd = PyQuery(url=\'http://stackoverflow.com/q/11939631\', parser=\'html\')\nfor tr in d("#question table > tr"):\n    for td in tr.iterchildren(\'td\'):\n        print(td.text_content())\n']], ['Is there an easy way to parse an HTML document and remove everything except a particular table?'], 3, 1], [(11939631, 2), [["Though in this case  pyquery  doesn't add enough. Here's the same using only  lxml :"], ['Note: the last two examples enumerate rows in  all  tables (not just the first one) inside  #question  element.']], [[" #!/usr/bin/env python\nimport urllib2\nfrom lxml import html\n\npage = urllib2.urlopen('http://stackoverflow.com/q/11939631')\ndoc = html.parse(page).getroot()\nfor tr in doc.cssselect('#question table > tr'):\n    for td in tr.iterchildren('td'):\n        print(td.text_content()) # process td\n"]], ['Is there an easy way to parse an HTML document and remove everything except a particular table?'], 3, 1], [(11943980, 0), [['Here is a fairly straight forward way using a dictionary comprehension:'], ['Or on Python 2.6 and below:']], [[' sums = {k: sum(i for i in v if isinstance(i, int)) for k, v in d.items()}\n']], ['Python how to get sum of numbers in a list that has strings in it as well'], 3, 1], [(11943980, 1), [['Or on Python 2.6 and below:'], ['Example:']], [[' sums = dict((k, sum(i for i in v if isinstance(i, int))) for k, v in d.items())\n']], ['Python how to get sum of numbers in a list that has strings in it as well'], 3, 1], [(11944826, 0), [['So you can have a function like this:'], ['With usage like this:']], [[' def week_difference(start, end):\n    assert start <= end\n    start_year, start_week, start_dayofweek = start.isocalendar()\n    end_year, end_week, end_dayofweek = end.isocalendar()\n\n    return ((end_year - start_year) * 52) - start_week + end_week\n']], ['python count business weeks'], 2, 1], [(11944826, 1), [['With usage like this:'], ['You can add  1  to your week output depending on your chosen semantic of what a week difference should be.']], [[' import datetime as dt\n# same week\nIn [1]: week_difference(dt.datetime(2012, 8, 1),  dt.datetime(2012, 8, 1))\nOut[1]: 0\n\n# your example (see note below) \nIn [2]: week_difference(dt.datetime(2012, 8, 1),  dt.datetime(2012, 8, 13))\nOut[2]: 2\n\n# across years\nIn [3]: week_difference(dt.datetime(2011, 8, 1),  dt.datetime(2012, 8, 13))\nOut[3]: 54\n\n# year boundary: second last business week of 2011, to first business week of 2012\n# which is the same business week as the last business week of 2011\nIn [4]: week_difference(dt.datetime(2011, 12, 20),  dt.datetime(2012, 1, 1))\nOut[4]: 1\n\nIn [5]: week_difference(dt.datetime(2011, 12, 18),  dt.datetime(2012, 1, 1))\nOut[5]: 2\n']], ['python count business weeks'], 2, 0], [(11968976, 0), [['Example:'], ['-10000']], [[" files = [f for f in os.listdir('.') if os.path.isfile(f)]\nfor f in files:\n    # do something\n"]], ['List files in ONLY the current directory'], 2, 1], [(11968976, 1), [['-10000'], ['which would not work because  f  is not a full path but relative to the current dir. ']], [[' files = [f for f in os.listdir(somedir) if os.path.isfile(f)].\n']], ['List files in ONLY the current directory'], 2, 0], [(11984684, 0), [['On unix-like terminals, you can try prepending  ANSI escape sequences  to the text;'], ['Edit:  For combinging this with logging, wrap it in a simple function:']], [[" import time\nimport sys\n\nprint 'this is a text',\nsys.stdout.flush()\n\ntime.sleep(1)\nprint '\\x1b[80D'+'\\x1b[K'+'Second text',\nsys.stdout.flush()\n"]], ['display only one logging line'], 3, 1], [(11984684, 1), [['Edit:  For combinging this with logging, wrap it in a simple function:'], ['EDIT 2:  Integrating this into the standard logging;']], [[" def mylog(text):\n    logging.info(text)\n    print '\\x1b[80D' + '\\x1b[K'+ text,\n    sys.stdout.flush()\n"]], ['display only one logging line'], 3, 1], [(11984684, 2), [['EDIT 2:  Integrating this into the standard logging;'], ["Since the logging module seems to add newlines by itself, I've added an ANSI sequense (\\x1b[1A) to go up one line."]], [[" import logging\n# create console handler\nch = logging.StreamHandler()\n# create formatter\nformatter = logging.Formatter('\\x1b[80D\\x1b[1A\\x1b[K%(message)s')\n# add formatter to console handler\nch.setFormatter(formatter)\n# add console handler to logger\nlogger.addHandler(ch)\n"]], ['display only one logging line'], 3, 1], [(12012818, 0), [['As per the  documentation , the attachments field is a list of tuples in which the first element is the filename and the second the byte string representing the file. So you just need to read the pdf:'], ['this assumes that your pdf and the python file are in the same folder. And then ']], [[" pdf_contents = open(os.path.join(os.path.dirname(__file__), 'yourpdf.pdf')).read()\n"]], ['Attaching a PDF to an email in Appengine (Python)'], 2, 0], [(12012818, 1), [['this assumes that your pdf and the python file are in the same folder. And then '], ['-10000']], [[" attachments = [('yourpdf.pdf', pdf_contents)]\n"]], ['Attaching a PDF to an email in Appengine (Python)'], 2, 0], [(12014704, 0), [['view'], ['template']], [[" newsletters = Newsletter.objects.prefetch_related('article_set').all()\\\n                    .order_by('-year', '-number')\n\nreturn render_to_response('newsletter/newsletter_list.html',\n                          {'newsletter_list': newsletters})\n"]], ['Iterating over related objects in Django: loop over query set or use one-liner select_related (or prefetch_related)'], 2, 0], [(12014704, 1), [['template'], ['-10000']], [[' {% block content %}\n  {% for newsletter in newsletter_list %}\n    <h2>{{ newsletter.label }}</h2>\n    <p>Volume {{ newsletter.volume }}, Number {{ newsletter.number }}</p>\n    <p>{{ newsletter.article }}</p>\n    <ul>\n    {% for a in newsletter.article_set.all %}\n      <li>{{ a.title }}</li>\n    {% endfor %}\n    </ul>\n  {% endfor %}\n{% endblock %}\n']], ['Iterating over related objects in Django: loop over query set or use one-liner select_related (or prefetch_related)'], 2, 0], [(12059634, 0), [['You can extract all the text between pairs of  "  characters using regular expressions:'], ['or, easier:']], [[' import re\ninputString=\'type="NN" span="123..145" confidence="1.0" \'\npat=re.compile(\'"([^"]*)"\')\nwhile True:\n        mat=pat.search(inputString)\n        if mat is None:\n                break\n        strings.append(mat.group(1))\n        inputString=inputString[mat.end():]\nprint strings\n']], ['Breaking up substrings in Python based on characters'], 3, 1], [(12059634, 1), [['or, easier:'], ['Output for both versions:']], [[' import re\ninputString=\'type="NN" span="123..145" confidence="1.0" \'\nstrings=re.findall(\'"([^"]*)"\', inputString)\nprint strings\n']], ['Breaking up substrings in Python based on characters'], 3, 1], [(12059634, 2), [['Output for both versions:'], ['-10000']], [[" ['NN', '123..145', '1.0']\n"]], ['Breaking up substrings in Python based on characters'], 3, 0], [(12081704, 0), [["Here's an approach to the problem (that doesn't use any regular expressions, although there's one place where it could).  We split up the problem into two functions: one function which splits a string into comma-separated pieces and handles each piece ( parseTags ), and one function which takes a string and processes it into a valid tag ( sanitizeTag ).  The annotated code is as follows:"], ['And indeed, if we run this code, we get:']], [[" # This function takes a string with commas separating raw user input, and\n# returns a list of valid tags made by sanitizing the strings between the\n# commas.\ndef parseTags(str):\n    # First, we split the string on commas.\n    rawTags = str.split(',')\n\n    # Then, we sanitize each of the tags.  If sanitizing gives us back None,\n    # then the tag was invalid, so we leave those cases out of our final\n    # list of tags.  We can use None as the predicate because sanitizeTag\n    # will never return '', which is the only falsy string.\n    return filter(None, map(sanitizeTag, rawTags))\n\n# This function takes a single proto-tag---the string in between the commas\n# that will be turned into a valid tag---and sanitizes it.  It either\n# returns an alphanumeric string (if the argument can be made into a valid\n# tag) or None (if the argument cannot be made into a valid tag; i.e., if\n# the argument contains only whitespace and/or punctuation).\ndef sanitizeTag(str):\n    # First, we turn non-alphanumeric characters into whitespace.  You could\n    # also use a regular expression here; see below.\n    str = ''.join(c if c.isalnum() else ' ' for c in str)\n\n    # Next, we split the string on spaces, ignoring leading and trailing\n    # whitespace.\n    words = str.split()\n\n    # There are now three possibilities: there are no words, there was one\n    # word, or there were multiple words.\n    numWords = len(words)\n    if numWords == 0:\n        # If there were no words, the string contained only spaces (and/or\n        # punctuation).  This can't be made into a valid tag, so we return\n        # None.\n        return None\n    elif numWords == 1:\n        # If there was only one word, that word is the tag, no\n        # post-processing required.\n        return words[0]\n    else:\n        # Finally, if there were multiple words, we camel-case the string:\n        # we lowercase the first word, capitalize the first letter of all\n        # the other words and lowercase the rest, and finally stick all\n        # these words together without spaces.\n        return words[0].lower() + ''.join(w.capitalize() for w in words[1:])\n"]], ['Python regular expression to remove space and capitalize letters where the space was?'], 8, 0], [(12081704, 1), [['And indeed, if we run this code, we get:'], ["Finally, there's the non-use of regular expressions, and instead the use of  str = ''.join(c if c.isalnum() else ' ' for c in str) .  You can, if  you want, replace this with a regular expression.  ( Edit:  I removed some inaccuracies about Unicode and regular expressions here.)  Ignoring Unicode, you could replace this line with"]], [[' >>> parseTags("tHiS iS a tAg, \\t\\n!&#^ , secondcomment , no!punc$$, ifNOSPACESthenPRESERVEcaps")\n[\'thisIsATag\', \'secondcomment\', \'noPunc\', \'ifNOSPACESthenPRESERVEcaps\']\n']], ['Python regular expression to remove space and capitalize letters where the space was?'], 8, 0], [(12081704, 2), [["Finally, there's the non-use of regular expressions, and instead the use of  str = ''.join(c if c.isalnum() else ' ' for c in str) .  You can, if  you want, replace this with a regular expression.  ( Edit:  I removed some inaccuracies about Unicode and regular expressions here.)  Ignoring Unicode, you could replace this line with"], ["This uses  [^...]  to match everything  but  the listed characters: ASCII letters and numbers.  However, it's better to support Unicode, and it's easy, too.  The simplest such approach is"]], [[" str = re.sub(r'[^A-Za-z0-9]', ' ', str)\n"]], ['Python regular expression to remove space and capitalize letters where the space was?'], 8, 0], [(12081704, 3), [["This uses  [^...]  to match everything  but  the listed characters: ASCII letters and numbers.  However, it's better to support Unicode, and it's easy, too.  The simplest such approach is"], ["Here,  \\W  matches non-word characters; a word character is a letter, a number, or the underscore.  With  flags=re.UNICODE  specified (not available before Python 2.7; you can instead use  r'(?u)\\W'  for earlier versions  and  2.7), letters and numbers are both any appropriate Unicode characters; without it, they're just ASCII.  If you don't want the underscore, you can add  |_  to the regex to match underscores as well, replacing them with spaces too:"]], [[" str = re.sub(r'\\W', ' ', str, flags=re.UNICODE)\n"]], ['Python regular expression to remove space and capitalize letters where the space was?'], 8, 0], [(12081704, 4), [["Here,  \\W  matches non-word characters; a word character is a letter, a number, or the underscore.  With  flags=re.UNICODE  specified (not available before Python 2.7; you can instead use  r'(?u)\\W'  for earlier versions  and  2.7), letters and numbers are both any appropriate Unicode characters; without it, they're just ASCII.  If you don't want the underscore, you can add  |_  to the regex to match underscores as well, replacing them with spaces too:"], ["Also, here's how I'd write the same code without those comments; this also allows me to eliminate some temporary variables.  You might prefer the code with the variables present; it's just a matter of taste."]], [[" str = re.sub(r'\\W|_', ' ', str, flags=re.UNICODE)\n"]], ['Python regular expression to remove space and capitalize letters where the space was?'], 8, 0], [(12081704, 5), [["Also, here's how I'd write the same code without those comments; this also allows me to eliminate some temporary variables.  You might prefer the code with the variables present; it's just a matter of taste."], ['-10000']], [[" def parseTags(str):\n    return filter(None, map(sanitizeTag, str.split(',')))\n\ndef sanitizeTag(str):\n    words    = ''.join(c if c.isalnum() else ' ' for c in str).split()\n    numWords = len(words)\n    if numWords == 0:\n        return None\n    elif numWords == 1:\n        return words[0]\n    else:\n        return words[0].lower() + ''.join(w.capitalize() for w in words[1:])\n"]], ['Python regular expression to remove space and capitalize letters where the space was?'], 8, 0], [(12081704, 6), [['-10000'], ['Running this code gives us the following output']], [[" def parseTags(str):\n    return filter(None, map(sanitizeTag, str.split(',')))\n\ndef sanitizeTag(str):\n    words    = filter(lambda c: c.isalnum() or c.isspace(), str).split()\n    numWords = len(words)\n    if numWords == 0:\n        return None\n    elif numWords == 1:\n        return words[0]\n    else:\n        words0 = words[0].lower() if words[0][0].islower() else words[0].capitalize()\n        return words0 + ''.join(w.capitalize() for w in words[1:])\n"]], ['Python regular expression to remove space and capitalize letters where the space was?'], 8, 1], [(12081704, 7), [['Running this code gives us the following output'], ['-10000']], [[' >>> parseTags("tHiS iS a tAg, AnD tHIs, \\t\\n!&#^ , se@%condcomment$ , No!pUnc$$, ifNOSPACESthenPRESERVEcaps")\n[\'thisIsATag\', \'AndThis\', \'secondcomment\', \'NopUnc\', \'ifNOSPACESthenPRESERVEcaps\']\n']], ['Python regular expression to remove space and capitalize letters where the space was?'], 8, 0], [(12102342, 0), [['and add following code to it:'], ['Also, using this technique, you can set different color schemes for different languages using the  color_scheme  attribute.']], [[' {\n    "font_face": "Source Code Pro"\n}\n']], ['Specific font_face based on syntax in Sublime Text 2'], 2, 0], [(12102342, 1), [['Also, using this technique, you can set different color schemes for different languages using the  color_scheme  attribute.'], ['Alternatively, if the file with targeted language is open, you can go to  Preferences > Settings - More > Syntax Specific - User , and add the  font_face  setting.']], [[' {\n    "font_face": "Source Code Pro",\n    "color_scheme": "Packages/Theme - Flatland/Flatland Monokai.tmTheme"\n}\n']], ['Specific font_face based on syntax in Sublime Text 2'], 2, 0], [(12151674, 1), [['Now call it:'], ["The only way to know what a function will return is to 1) read the source or 2) (If you're a trusting sort of person) read the documentation for the function :-)."]], [[' foo(1) # (1,2)\nfoo(0) # ("foo","bar","baz")\n']], ['How to get the number of elements returned from a function in Python'], 2, 0], [(12175964, 0), [["Solution:  using  ord() -function to first turn the  getch()  into an integer (I guess they're virtual key codes, but not too sure) works fine, and then comparing the result to the actual number representing the wanted key. Also, if I needed to, I could add an extra  chr()  around the number returned so that it would convert it to a character. However, I'm using mostly down arrow, esc, etc. so converting those to a character would be stupid. Here's the final code:"], ['Also if someone else needs to, you can easily find out the keycodes from google, or by using python and just pressing the key:']], [[' from msvcrt import getch\nwhile True:\n    key = ord(getch())\n    if key == 27: #ESC\n        break\n    elif key == 13: #Enter\n        select()\n    elif key == 224: #Special keys (arrows, f keys, ins, del, etc.)\n        key = ord(getch())\n        if key == 80: #Down arrow\n            moveDown()\n        elif key == 72: #Up arrow\n            moveUp()\n']], ['Python method for reading keypress?'], 2, 1], [(12184015, 0), [['-10000'], ['Edit:  I decided to revisit this question and see if it would be possible to handle the bonus case. It requires being more sophisticated in the tie-breaker portion of the key. To match the desired results, the alpha parts of the key must be considered before the numeric parts. I also added a marker between the natural section of the key and the tie-breaker so that short keys always come before long ones.']], [[" re_natural = re.compile('[0-9]+|[^0-9]+')\n\ndef natural_key(s):\n    return [(1, int(c)) if c.isdigit() else (0, c.lower()) for c in re_natural.findall(s)] + [s]\n\nfor case in test_cases:\n    print case[1]\n    print sorted(case[0], key=natural_key)\n\n['a', 'b', 'c']\n['a', 'b', 'c']\n['A', 'b', 'C']\n['A', 'b', 'C']\n['a', 'B', 'r', '0', '9']\n['a', 'B', 'r', '0', '9']\n['a1', 'a2', 'a100', '1a', '10a']\n['a1', 'a2', 'a100', '1a', '10a']\n['alp1', 'alp2', 'alp10', 'ALP11', 'alp100', 'GAM', '1', '2', '100']\n['alp1', 'alp2', 'alp10', 'ALP11', 'alp100', 'GAM', '1', '2', '100']\n['A', 'a', 'b', 'r', '0', '9']\n['A', 'a', 'b', 'r', '0', '9']\n['ABc', 'Abc', 'abc']\n['ABc', 'Abc', 'abc']\n"]], ['In Python, how can I naturally sort a list of alphanumeric strings such that alpha characters sort ahead of numeric characters?'], 3, 1], [(12184015, 1), [['Edit:  I decided to revisit this question and see if it would be possible to handle the bonus case. It requires being more sophisticated in the tie-breaker portion of the key. To match the desired results, the alpha parts of the key must be considered before the numeric parts. I also added a marker between the natural section of the key and the tie-breaker so that short keys always come before long ones.'], ['This generates identical results for the test cases above, plus the desired output for the bonus case:']], [[' def natural_key2(s):\n    parts = re_natural.findall(s)\n    natural = [(1, int(c)) if c.isdigit() else (0, c.lower()) for c in parts]\n    ties_alpha = [c for c in parts if not c.isdigit()]\n    ties_numeric = [c for c in parts if c.isdigit()]\n    return natural + [(-1,)] + ties_alpha + ties_numeric\n']], ['In Python, how can I naturally sort a list of alphanumeric strings such that alpha characters sort ahead of numeric characters?'], 3, 1], [(12184015, 2), [['This generates identical results for the test cases above, plus the desired output for the bonus case:'], ['-10000']], [[" ['A', 'a', 'A0', 'a0', '0', '00', '0A', '00A', '0a', '00a']\n"]], ['In Python, how can I naturally sort a list of alphanumeric strings such that alpha characters sort ahead of numeric characters?'], 3, 0], [(12227084, 0), [["You'd basically need the following definitions and two functions:"], ["You can cut the long function down to just the branch you need for your platform, of course; for OS X that'd be:"]], [[' import os\nimport sys\nfrom distutils.errors import DistutilsPlatformError\n\n\nPREFIX = os.path.normpath(sys.prefix)\nEXEC_PREFIX = os.path.normpath(sys.exec_prefix)\n\n\ndef get_python_version():\n    """Return a string containing the major and minor Python version,\n    leaving off the patchlevel.  Sample return values could be \'1.5\'\n    or \'2.2\'.\n    """\n    return sys.version[:3]\n\ndef get_python_lib(plat_specific=0, standard_lib=0, prefix=None):\n    """Return the directory containing the Python library (standard or\n    site additions).\n\n    If \'plat_specific\' is true, return the directory containing\n    platform-specific modules, i.e. any module from a non-pure-Python\n    module distribution; otherwise, return the platform-shared library\n    directory.  If \'standard_lib\' is true, return the directory\n    containing standard Python library modules; otherwise, return the\n    directory for site-specific modules.\n\n    If \'prefix\' is supplied, use it instead of sys.prefix or\n    sys.exec_prefix -- i.e., ignore \'plat_specific\'.\n    """\n    if prefix is None:\n        prefix = plat_specific and EXEC_PREFIX or PREFIX\n\n    if os.name == "posix":\n        libpython = os.path.join(prefix,\n                                 "lib", "python" + get_python_version())\n        if standard_lib:\n            return libpython\n        else:\n            return os.path.join(libpython, "site-packages")\n\n    elif os.name == "nt":\n        if standard_lib:\n            return os.path.join(prefix, "Lib")\n        else:\n            if get_python_version() < "2.2":\n                return prefix\n            else:\n                return os.path.join(prefix, "Lib", "site-packages")\n\n    elif os.name == "os2":\n        if standard_lib:\n            return os.path.join(prefix, "Lib")\n        else:\n            return os.path.join(prefix, "Lib", "site-packages")\n\n    else:\n        raise DistutilsPlatformError(\n            "I don\'t know where Python installs its library "\n            "on platform \'%s\'" % os.name)\n']], ['A way to get the path to the user installed packages on Linux and OS X operating systems? (Usable for Python versions between 2.5 - 2.7)'], 2, 1], [(12227084, 1), [["You can cut the long function down to just the branch you need for your platform, of course; for OS X that'd be:"], ["Note that Debian  patches this function  to return  dist-packages  in the default case, this doesn't apply to OS X."]], [[' def get_python_lib(plat_specific=0, standard_lib=0, prefix=None):\n    if prefix is None:\n        prefix = plat_specific and EXEC_PREFIX or PREFIX\n\n    libpython = os.path.join(prefix,\n                             "lib", "python" + get_python_version())\n    if standard_lib:\n        return libpython\n    else:\n        return os.path.join(libpython, "site-packages")\n']], ['A way to get the path to the user installed packages on Linux and OS X operating systems? (Usable for Python versions between 2.5 - 2.7)'], 2, 0], [(12231891, 1), [['You can however  get  a reference to the data with'], ['In this case,  mylist.index(value)  gets the index of the first occurrence of  value  without "iterating over the list".  However, you should know that even this way Python is "iterating over the list" under the hood (depending on the implementation of Python).  It\'s simply how arrays work on a binary level; you must iterate at some point.  (See  http://docs.python.org/py3k/library/stdtypes.html#sequence-types-str-bytes-bytearray-list-tuple-range )']], [[' mylist[mylist.index(value)]\n']], ['referencing list object by data python'], 2, 0], [(12307099, 0), [['Try this:'], ["the  df.A==0  expression creates a boolean series that indexes the rows,  'B'  selects the column. You can also use this to transform a subset of a column, e.g.:"]], [[" df.ix[df.A==0, 'B'] = np.nan\n"]], ['Modifying a subset of rows in a pandas dataframe'], 3, 1], [(12309693, 0), [['Do something like this, on client side:'], ['Function  get_form_args()  is abstraction. You can implement it any way. Javascript objects are JSONs by default. \nSo on client side you must create dictionary from form fields. \nThink this way: ']], [[" var data = {'packed_arg':get_form_args(); } \n"]], ['Sending non-string argument in a POST request to a Tornado server'], 3, 0], [(12309693, 1), [['Function  get_form_args()  is abstraction. You can implement it any way. Javascript objects are JSONs by default. \nSo on client side you must create dictionary from form fields. \nThink this way: '], ['And then on server side: ']], [[" var data = {};\nvar names_to_pack = ['packed1', 'packed2']\n$(form).find('input, select').each(function (i, x) {\n    var name = $(x).attr('name')\n    if(names_to_pack.indexOf(name) != -1) { \n        if(!data.packed) {\n            data.packed = {};  \n        }\n        data['packed'][name] = $(x).val(); \n    } else { \n        data[name] = $(x).val(); \n    }\n});\n$.post('/', data); \n"]], ['Sending non-string argument in a POST request to a Tornado server'], 3, 0], [(12309693, 2), [['And then on server side: '], ['Also you can access all POST args in  self.request.arguments . ']], [[" raw_packed = self.get_argument('packed_arg', None)\npacked = {}\nif raw_packed: \n    packed = tornado.escape.json_decode(raw_packed)\narg1 = packed.get('arg1')\narg2 = packed.get('arg2')\n"]], ['Sending non-string argument in a POST request to a Tornado server'], 3, 0], [(12329807, 0), [['STEP 1.  Create a file say uwsgi.ini in your Django Project Directory. i.e besides manage.py'], ['STEP 2.  Under  /etc/nginx/sites-available  add .conf file']], [[' [uwsgi]\n# set the http port\nhttp = :<port_no>\n\n# change to django project directory\nchdir = <project directory>\n\n# add /var/www to the pythonpath, in this way we can use the project.app format\npythonpath = /var/www\n\n# set the project settings name\nenv = DJANGO_SETTINGS_MODULE=<project_name>.settings\n\n# load django\nmodule = django.core.handlers.wsgi:WSGIHandler()\n']], ['Django app deployment on nGINX'], 4, 0], [(12329807, 1), [['STEP 2.  Under  /etc/nginx/sites-available  add .conf file'], ['Under the server { } block, ']], [[' server {\nlisten 84;\nserver_name example.com;\naccess_log /var/log/nginx/sample_project.access.log;\nerror_log /var/log/nginx/sample_project.error.log;\n\n# https://docs.djangoproject.com/en/dev/howto/static-files/#serving-static-files-in-production\nlocation /static/ { # STATIC_URL\n    alias /home/www/myhostname.com/static/; # STATIC_ROOT\n    expires 30d;\n                  }\n\n       }\n']], ['Django app deployment on nGINX'], 4, 0], [(12329807, 2), [['Under the server { } block, '], ['STEP 4.  Run the uwsgi.ini']], [[' location /yourapp {\n           include uwsgi_params;\n           uwsgi_pass <your app address, eg.localhost>:<portno>;\n                   }\n']], ['Django app deployment on nGINX'], 4, 0], [(12329807, 3), [['STEP 4.  Run the uwsgi.ini'], ['Now any request to your nGINX will pass the request to your Django App via uwsgi.. Enjoy :)']], [[' > uwsgi --ini uwsgi.ini\n']], ['Django app deployment on nGINX'], 4, 0], [(12379529, 0), [['For example:'], ['Then in SQLAlchemy you can use the following query:']], [[" class Post(Base):\n    __tablename__ = 'post'\n\n    id = Column(Integer, primary_key=True)\n    text = Column(Unicode)\n\nclass Like(Base):\n    __tablename__ = 'like'\n\n    id = Column(Integer, primary_key=True)\n    post_id = Column(Integer, ForeignKey(Post.id), nullable=False)\n\nclass Alert(Base):\n    __tablename__ = 'alert'\n\n    id = Column(Integer, primary_key=True)\n    like_id = Column(Integer, ForeignKey(Like.id))\n"]], ['Sqlalchemy "double layer" query'], 2, 0], [(12379529, 1), [['Then in SQLAlchemy you can use the following query:'], ['-10000']], [[' DBSession.query(Alert.id).join(Like).join(Post).filter(Post.id==2).all()\n']], ['Sqlalchemy "double layer" query'], 2, 0], [(12389570, 0), [['With regex pattern  ^TestVar\\s+(\\d{8})\\s+(\\S+)  you can get that as >>'], ['To find all occurrences in multiline  input  string use:']], [[" import re\np = re.compile('^TestVar\\s+(\\d{8})\\s+(\\S+)')\nm = p.match('TestVar 00000000  WWWWWW 222.222 222.222 222.222')\nif m:\n    print 'Match found: ', m.group(2) + '_' + m.group(1)\nelse:\n    print 'No match'\n"]], ['get characters from string in python'], 2, 1], [(12413317, 0), [['Why split in the first place when you could do:'], ['and then:']], [[' attendees = [(a.profile, a.verified, a.from_user)\n                 for a in Attendee.objects.filter(event=event)]\n']], ['Combining lists and performing a check'], 3, 0], [(12413317, 1), [['and then:'], ['Alternatively, you can just do:']], [[' {% for attendee, verified, from_user in attendees_list %}\n']], ['Combining lists and performing a check'], 3, 0], [(12494277, 0), [["I'm sure my solution is far too simple to cover all cases, but it should be able to cover simple cases when closing tags are missing:"], ['This seems to add correctly missing tags B and C:']], [[' >>> def fix_xml(string):\n    """\n    Tries to insert missing closing XML tags\n    """\n    error = True\n    while error:\n        try:\n            # Put one tag per line\n            string = string.replace(\'>\', \'>\\n\').replace(\'\\n\\n\', \'\\n\')\n            root = etree.fromstring(string)\n            error = False\n        except etree.XMLSyntaxError as exc:\n            text = str(exc)\n            pattern = "Opening and ending tag mismatch: (\\w+) line (\\d+) and (\\w+), line (\\d+), column (\\d+)"\n            m = re.match(pattern, text)\n            if m:\n                # Retrieve where error took place\n                missing, l1, closing, l2, c2 = m.groups()\n                l1, l2, c2 = int(l1), int(l2), int(c2)\n                lines = string.split(\'\\n\')\n                print \'Adding closing tag <{0}> at line {1}\'.format(missing, l2)\n                missing_line = lines[l2 - 1]\n                # Modified line goes back to where it was\n                lines[l2 - 1] = missing_line.replace(\'</{0}>\'.format(closing), \'</{0}></{1}>\'.format(missing, closing))\n                string = \'\\n\'.join(lines)\n            else:\n                raise\n    print string\n']], ['Broken XML file parsing and using XPATH'], 2, 1], [(12494277, 1), [['This seems to add correctly missing tags B and C:'], ['-10000']], [[' >>> s = """<A>\n  <B>\n    <C>\n  </B>\n  <B></A>"""\n>>> fix_xml(s)\nAdding closing tag <C> at line 4\nAdding closing tag <B> at line 7\n<A>\n  <B>\n    <C>\n  </C>\n</B>\n  <B>\n</B>\n</A>\n']], ['Broken XML file parsing and using XPATH'], 2, 0], [(12494930, 0), [['The result of  p4.run_opened  is an array that has a map for each opened file.\nThis map has the following keys:'], ["In order to find out the type of change, iterate over the array and ask each item for the 'action'. In one of my current changelists, the first file is opened for 'edit':"]], [[" 'haveRev'\n'rev'\n'clientFile'\n'client'\n'user'\n'action'\n'type'\n'depotFile'\n'change'\n"]], ['How to get the type of change in P4Python'], 2, 0], [(12494930, 1), [["In order to find out the type of change, iterate over the array and ask each item for the 'action'. In one of my current changelists, the first file is opened for 'edit':"], ["will return: 'edit'"]], [[" import P4\np4 = P4.P4()\np4.connect()\np4.run_opened()[0]['action']\np4.disconnect()\n"]], ['How to get the type of change in P4Python'], 2, 1], [(12496531, 0), [['numpy.lexsort  will work here:'], ['The alternative possibly slightly clearer way is to pass the columns explicitly:']], [[' A[np.lexsort(A.T)]\n']], ['Sort NumPy float array column by column'], 2, 1], [(12496531, 1), [['The alternative possibly slightly clearer way is to pass the columns explicitly:'], ["You still need to remember that lexsort sorts by the last key first (there's probably some good reason for this; it's the same as performing a stable sort on successive keys)."]], [[' A[np.lexsort((A[:, 0], A[:, 1]))]\n']], ['Sort NumPy float array column by column'], 2, 1], [(12501761, 0), [["Windows' command interpreter does not expand wildcards as UNIX shells do before passing them to the executed program or script."], ['Result:']], [[' python.exe -c "import sys; print sys.argv[1:]" *.txt\n']], ['Passing multple files with asterisk to python shell in Windows'], 3, 0], [(12501761, 1), [['Result:'], ['Solution: Use the  glob  module.']], [[" ['*.txt']\n"]], ['Passing multple files with asterisk to python shell in Windows'], 3, 0], [(12501761, 2), [['Solution: Use the  glob  module.'], ['-10000']], [[' from glob import glob\nfrom sys import argv\n\nfor filename in glob(argv[1]):\n    print filename\n']], ['Passing multple files with asterisk to python shell in Windows'], 3, 1], [(12504976, 0), [['You could use the  tolist  method as an intermediary:'], ['From which you could make a new DataFrame:']], [[" In [99]: import pandas as pd\n\nIn [100]: d1 = pd.DataFrame({'ticker' : ['spx 5/25/2001 p500', 'spx 5/25/2001 p600', 'spx 5/25/2001 p700']})\n\nIn [101]: d1.ticker.str.split().tolist()\nOut[101]: \n[['spx', '5/25/2001', 'p500'],\n ['spx', '5/25/2001', 'p600'],\n ['spx', '5/25/2001', 'p700']]\n"]], ['Get last "column" after .str.split() operation on column in pandas DataFrame'], 4, 0], [(12504976, 1), [['From which you could make a new DataFrame:'], ['For good measure, you could fix the price:']], [[' In [102]: d2 = pd.DataFrame(d1.ticker.str.split().tolist(), \n   .....:                   columns="symbol date price".split())\n\nIn [103]: d2\nOut[103]: \n  symbol       date price\n0    spx  5/25/2001  p500\n1    spx  5/25/2001  p600\n2    spx  5/25/2001  p700\n']], ['Get last "column" after .str.split() operation on column in pandas DataFrame'], 4, 0], [(12504976, 2), [['For good measure, you could fix the price:'], ['PS: but if you  really  just want the last column,  apply  would suffice:']], [[' In [104]: d2["price"] = d2["price"].str.replace("p","").astype(float)\n\nIn [105]: d2\nOut[105]: \n  symbol       date  price\n0    spx  5/25/2001    500\n1    spx  5/25/2001    600\n2    spx  5/25/2001    700\n']], ['Get last "column" after .str.split() operation on column in pandas DataFrame'], 4, 0], [(12504976, 3), [['PS: but if you  really  just want the last column,  apply  would suffice:'], ['-10000']], [[' In [113]: temp2.apply(lambda x: x[2])\nOut[113]: \n0    p500\n1    p600\n2    p700\nName: ticker\n']], ['Get last "column" after .str.split() operation on column in pandas DataFrame'], 4, 0], [(12573992, 0), [['First, create the forms for your objects. One of the forms will be repeated. Nothing special to be done here. '], ['Then, create your  formset :']], [[' class SonInline(ModelForm):\n    model = Son\n\nclass FatherForm(ModelForm):\n    model = Father\n']], ['Multiple Forms and Formsets in CreateView'], 4, 0], [(12573992, 1), [['Then, create your  formset :'], ['Now, to integrate it with your  CreateView :']], [[' FatherInlineFormSet = inlineformset_factory(Father,\n    Son,\n    form=SonInline,\n    extra=1,\n    can_delete=False,\n    can_order=False\n)\n']], ['Multiple Forms and Formsets in CreateView'], 4, 0], [(12573992, 2), [['Now, to integrate it with your  CreateView :'], ['The key part is the jquery  django-dynamic-formset  plugin that keeps adding new inline forms:']], [[" class CreateFatherView(CreateView):\n    template_name = 'father_create.html'\n    model = Father\n    form_class = FatherForm # the parent object's form\n\n    # On successful form submission\n    def get_success_url(self):\n        return reverse('father-created')\n\n    # Validate forms\n    def form_valid(self, form):\n        ctx = self.get_context_data()\n        inlines = ctx['inlines']\n        if inlines.is_valid() and form.is_valid():\n            self.object = form.save() # saves Father and Children\n            return redirect(self.get_success_url())\n        else:\n            return self.render_to_response(self.get_context_data(form=form))\n\n    def form_invalid(self, form):\n        return self.render_to_response(self.get_context_data(form=form))\n\n    # We populate the context with the forms. Here I'm sending\n    # the inline forms in `inlines`\n    def get_context_data(self, **kwargs):\n        ctx = super(CreateFatherView, self).get_context_data(**kwargs)\n        if self.request.POST:\n            ctx['form'] = FatherForm(self.request.POST)\n            ctx['inlines'] = FatherInlineFormSet(self.request.POST)\n        else:\n            ctx['form'] = Father()\n            ctx['inlines'] = FatherInlineFormSet()\n        return ctx\n"]], ['Multiple Forms and Formsets in CreateView'], 4, 0], [(12573992, 3), [['The key part is the jquery  django-dynamic-formset  plugin that keeps adding new inline forms:'], ['-10000']], [[' <form id="father-form" method="POST" enctype="multipart/form-data" action=".">\n{% csrf_token %}\n<div class="row">\n  {% for f in form %}\n    <div class="span3">{{ f.label }}<br />{{ f }}\n      {% if f.errors %}\n          {% for v in f.errors %}\n            <br /><span style="color:red;">{{ v }}</span>\n          {% endfor %}\n      {% endif %}\n    </div>\n {% endfor %}\n</div>\n<hr />\n<h2>Sons:</h2>\n<table class="table-striped">\n <table>\n {%  for f2 in inlines %}\n   <tr id="{{ f2.prefix }}-row">\n      {% for i in f2 %}\n        <td>\n           {{ i }}{% if i.errors %}<span style="color:red;">{{ i.errors }}</span>{% endif %}\n        </td>\n      {% endfor %}\n   </tr>\n {% endfor %}\n</table>\n{{ inlines.management_form }}\n<input type="submit" class="btn btn-primary" value="Go Go Gadget &rarr;">\n</form>\n<script type="text/javascript">\n    $(function() {\n        $(\'#father-form tr\').formset({\n            prefix: \'{{ inlines.prefix }}\'\n        });\n    })\n</script>\n']], ['Multiple Forms and Formsets in CreateView'], 4, 0], [(12576313, 0), [['Looks like your file has fixed width columns, for which read_fwf() can be used.'], ['Ok, now we have the data, just a little bit of extra work and you have a frame on which you can use set_index() to create a MultiLevel index.']], [[' In [145]: data = """\\\nSampleID    OtherInfo    Measurements    Error    Notes                   \nsample1     stuff                                 more stuff              \n                         36              6\n                         26              7\n                         37              8\nsample2     newstuff                              lots of stuff           \n                         25              6\n                         27              7\n"""\n\nIn [146]: df = pandas.read_fwf(StringIO(data), widths=[12, 13, 14, 9, 15])\n']], ['Convert excel or csv file to pandas multilevel dataframe'], 2, 0], [(12576313, 1), [['Ok, now we have the data, just a little bit of extra work and you have a frame on which you can use set_index() to create a MultiLevel index.'], ['-10000']], [[" In [147]: df[['Measurements', 'Error']] = df[['Measurements', 'Error']].shift(-1)\n\nIn [148]: df[['SampleID', 'OtherInfo', 'Notes']] = df[['SampleID', 'OtherInfo', 'Notes']].fillna()\n\nIn [150]: df = df.dropna()\n\nIn [151]: df\nOut[151]:\n  SampleID OtherInfo  Measurements  Error          Notes\n0  sample1     stuff            36      6     more stuff\n1  sample1     stuff            26      7     more stuff\n2  sample1     stuff            37      8     more stuff\n4  sample2  newstuff            25      6  lots of stuff\n5  sample2  newstuff            27      7  lots of stuff\n"]], ['Convert excel or csv file to pandas multilevel dataframe'], 2, 0], [(12667537, 0), [['The easiest way is to use  globals'], ['You can also get the current module object by looking it up in  sys.modules .']], [[' globals()[func_name]()\n']], ['Invoking top-level function by name in Python'], 2, 1], [(12667537, 1), [['You can also get the current module object by looking it up in  sys.modules .'], ['-10000']], [[' getattr(sys.modules[__name__], func_name)()\n']], ['Invoking top-level function by name in Python'], 2, 1], [(12674794, 1), [['Those have to be of the format described in this  MSDN link  with the relevant parts copied below for convenience:'], ['-10000']], [[' wFatDate [in]\nThe MS-DOS date. The date is a packed value with the following format.\n    Bits    Description\n    0-4     Day of the month (1–31)\n    5-8     Month (1 = January, 2 = February, and so on)\n    9-15    Year offset from 1980 (add 1980 to get actual year)\n\nwFatTime [in]\nThe MS-DOS time. The time is a packed value with the following format.\n    Bits    Description\n    0-4     Second divided by 2\n    5-10    Minute (0–59)\n   11-15    Hour (0–23 on a 24-hour clock)\n']], ['Using pywin32 DosDateTimeToTime to unpack DOS packed time'], 2, 0], [(12713743, 0), [['bar.py:'], ['-10000']], [[" def get_data():\n    return 'bar'\n"]], ['in python, how to manipulate namespace of an instance'], 3, 0], [(12713743, 1), [['-10000'], ['-10000']], [[" import bar\n\nclass Data(object):\n    def __init__(self):\n        self.val = bar.get_data()\n\nif __name__ == '__main__':\n    d = Data()\n    print d.val    # prints 'bar'\n"]], ['in python, how to manipulate namespace of an instance'], 3, 0], [(12713743, 2), [['-10000'], ['-10000']], [[" import foo\n\nclass bar_mock(object):\n    @staticmethod\n    def get_data():\n        return 'test'\n\nif __name__ == '__main__':\n    foo.bar = bar_mock\n    d = foo.Data()\n    print d.val    # prints 'test'\n"]], ['in python, how to manipulate namespace of an instance'], 3, 0], [(12744136, 0), [['in the view:'], ['And in the form:']], [[" channel_obj = db.TVChannel().get_id(channel_id) #load a channel's infos into an object\nchannel     = ChannelForm(request.form, obj=channel_obj) #load channel form\nchannel.CITY1adapt.process_data(channel_obj.streams['City1']['adapt'])\n#and others links\n"]], ['Flask-WTF: how pass structered object to form'], 2, 0], [(12744136, 1), [['And in the form:'], ['Now i\'m working on when i "save" them.']], [[" class ChannelForm(Form):    \n    _id         = HiddenField()\n    name        = TextField(_('channel name'))    \n    CITY1adapt  = TextField(_('adapt link')) \n    CITY2adapt  = TextField(_('adapt link'))\n    #and so on\n\n    submit      = SubmitField(_('Save'))\n"]], ['Flask-WTF: how pass structered object to form'], 2, 0], [(12785573, 0), [['Then number of sequences of length  n  (for  n>1 ) is:'], ['Same argument gives:']], [[' U_k(n) + D_k(n) = 2*U_k(n) = 2*( sum U_k(n, f) for f in 1 ... k ).\n']], ['counting zigzag sequences'], 3, 0], [(12785573, 1), [['Same argument gives:'], ["Slightly simpler implementation.  M(n,k)  returns n'th row (from back), and  C(n,k)  counts number of sequences."]], [[' U_k(n, f) = sum D_k(n-1, s) for s = f+1 ... k\n          = sum U_k(n-1, s) for s = 1 ... k-f\nU_k(1, f) = 1\n']], ['counting zigzag sequences'], 3, 0], [(12824228, 0), [['Since the files can be copied within the poll interval, just process the new files found by the  last  poll before checking for new files. In other words, instead of this:'], ['Do this:']], [[' while True:\n    newfiles = check_for_new_files()\n    process(newfiles)\n    time.sleep(pollinterval)\n']], ['How do you check when a file is done being copied in Python?'], 3, 0], [(12824228, 1), [['Do this:'], ['Or just put the wait in the middle of the loop (same effect really):']], [[' newfiles = []\n\nwhile True:\n    process(newfiles)\n    newfiles = check_for_new_files()\n    time.sleep(pollinterval)\n']], ['How do you check when a file is done being copied in Python?'], 3, 1], [(12824228, 2), [['Or just put the wait in the middle of the loop (same effect really):'], ['-10000']], [[' while True:\n    newfiles = check_for_new_files()\n    time.sleep(pollinterval)\n    process(newfiles)\n']], ['How do you check when a file is done being copied in Python?'], 3, 1], [(12901066, 0), [['Would something like this work:'], ['This outputs the following:']], [[" rows = soup.find('tbody').findAll('tr')\n\nfor row in rows:\n    cells = row.findAll('td')\n\n    output = []\n\n    for i, cell in enumerate(cells):\n        if i == 0:\n            output.append(cell.text.strip())\n        elif cell.find('img'):\n            output.append(cell.find('img')['title'])\n        elif cell.find('input'):\n            output.append(cell.find('input')['value'])\n    print output\n"]], ['Beautiful soup, html table parsing'], 2, 1], [(12901066, 1), [['This outputs the following:'], ['-10000']], [[" [u'Logged-in users', u'True', u'True', u'True', u'True']\n[u'User 1', u'Confirm', u'Confirm', u'Site', u'Confirm']\n[u'User 2', u'Confirm', u'Confirm', u'Confirm', u'Confirm']\n[u'User 3', u'Confirm', u'Confirm', u'Confirm', u'Confirm']\n[u'User 4', u'Confirm', u'Site', u'Site', u'Confirm']\n"]], ['Beautiful soup, html table parsing'], 2, 0], [(12923835, 0), [['You\'ll want to use Python\'s standard library  datetime  module to parse and convert the "date given by the user" to a  datetime.date  instance and then subtract that from the current date,  datetime.date.today() . For example:'], ['To get their age in years, you could do something like this:']], [[" >>> birthdate_str = raw_input('Enter your birthday (yyyy-mm-dd): ')\nEnter your birthday (yyyy-mm-dd): 1981-08-04\n>>> birthdatetime = datetime.datetime.strptime(birthdate_str, '%Y-%m-%d')\n>>> birthdate = birthdatetime.date()  # convert from datetime to just date\n>>> age = datetime.date.today() - birthdate\n>>> age\ndatetime.timedelta(11397)\n"]], ['How can I compare dates using Python?'], 2, 1], [(12923835, 1), [['To get their age in years, you could do something like this:'], ['-10000']], [[' >>> int(age.days / 365.24)\n31\n']], ['How can I compare dates using Python?'], 2, 0], [(12972595, 0), [['You should look into the regular expressions module of python. Simply "import re" in your script to provide regex capabilities.\nBy the way if you only want the numbers following the string "vg" then the following script should do the trick.'], ["Extending the answer to match OP's requirement:"]], [[' import re\nurString = "/dev/vg10/lv10:cp:99"\nMatches = re.findall("vg[0-9]*", mv)\nprint Matches\n']], ['Extract a particular number followed by a command line argument variable from a string in python'], 2, 1], [(12972595, 1), [["Extending the answer to match OP's requirement:"], ['-10000']], [[" In [445]: Matches\nOut[445]: ['vg10']\n\nIn [446]: int(*re.findall(r'[0-9]+', Matches[0]))\nOut[446]: 10\n"]], ['Extract a particular number followed by a command line argument variable from a string in python'], 2, 1], [(12986272, 0), [['In Python, use  itertools  for stuff like this'], ['Yields:']], [[' from itertools import product\nfor i in product([0,1], repeat=5): \n    print i\n']], ['How do I compute all possibilities for an array of numbers/bits (in python, or any language for that matter)'], 2, 1], [(12986272, 1), [['Yields:'], ['-10000']], [[' (0, 0, 0, 0, 0)\n(0, 0, 0, 0, 1)\n(0, 0, 0, 1, 0)\n(0, 0, 0, 1, 1)\n(0, 0, 1, 0, 0)\netc...\n']], ['How do I compute all possibilities for an array of numbers/bits (in python, or any language for that matter)'], 2, 0], [(13031989, 0), [['The easiest way would be to filter the glob results yourself. Here is how to do it using a simple loop comprehension:'], ['You could also use a regexp and no  glob :']], [[' import glob\nres = [f for f in glob.glob("*.txt") if "abc" in f or "123" in f or "a1b" in f]\nfor f in res:\n    print f\n']], ['regular expression using in glob.glob of python'], 2, 1], [(13031989, 1), [['You could also use a regexp and no  glob :'], ['(By the way, naming a variable  list  is a bad idea since  list  is a Python type...)']], [[" import os\nimport re\nres = [f for f in os.listdir(path) if re.search(r'(abc|123|a1b).*\\.txt$', f)]\nfor f in res:\n    print f\n"]], ['regular expression using in glob.glob of python'], 2, 1], [(13047895, 1), [['Results:'], ["Here's the byte code comparison of the two:"]], [[' copy(a) 3.98940896988\nlist(a) 2.54542589188\na[:] 1.96630120277                   #winner\na[0:len(a)] 10.5431251526\n']], ['Efficient ways to duplicate array/list in Python'], 3, 0], [(13047895, 2), [["Here's the byte code comparison of the two:"], ['-10000']], [[' In [19]: dis.dis(func1)\n  2           0 LOAD_GLOBAL              0 (range)\n              3 LOAD_CONST               1 (100000)\n              6 CALL_FUNCTION            1\n              9 STORE_FAST               0 (a)\n\n  3          12 LOAD_FAST                0 (a)\n             15 SLICE+0             \n             16 STORE_FAST               1 (b)\n             19 LOAD_CONST               0 (None)\n             22 RETURN_VALUE        \n\nIn [20]: dis.dis(func2)\n  2           0 LOAD_GLOBAL              0 (range)\n              3 LOAD_CONST               1 (100000)\n              6 CALL_FUNCTION            1\n              9 STORE_FAST               0 (a)\n\n  3          12 LOAD_FAST                0 (a)    #same up to here\n             15 LOAD_CONST               2 (0)    #loads 0\n             18 LOAD_GLOBAL              1 (len) # loads the builtin len(),\n                                                 # so it might take some lookup time\n             21 LOAD_FAST                0 (a)\n             24 CALL_FUNCTION            1         \n             27 SLICE+3             \n             28 STORE_FAST               1 (b)\n             31 LOAD_CONST               0 (None)\n             34 RETURN_VALUE        \n']], ['Efficient ways to duplicate array/list in Python'], 3, 0], [(13097764, 0), [['You could use  kwargs :'], ["If you're specifically looking for keys  var1  etc instead of  varone  you just modify the function call:"]], [[' def function(*args, **kwargs):\n    values = {}\n    for k in kwargs:\n        if kwargs[k] is not None:\n            values[k] = kwargs[k]\n    if not values:\n        raise Exception("No values provided")\n    return values\n\n>>> function(varone=None, vartwo="fish", varthree=None)\n{\'vartwo\': \'fish\'}\n']], ['What is an elegant way to select all non-None elements from parameters and place them in a python dictionary?'], 3, 1], [(13097764, 1), [["If you're specifically looking for keys  var1  etc instead of  varone  you just modify the function call:"], ['If you want to be REALLY slick, you can use list comprehensions:']], [[' >>> function(var1=None, var2="fish", var3=None)\n{\'var2\': \'fish\'}\n']], ['What is an elegant way to select all non-None elements from parameters and place them in a python dictionary?'], 3, 0], [(13097764, 2), [['If you want to be REALLY slick, you can use list comprehensions:'], ["Again, you'll have to alter your parameter names to be consistent with your output keys."]], [[' def function(**kwargs):\n    values = dict([i for i in kwargs.iteritems() if i[1] != None])\n    if not values:\n        raise Exception("foo")\n    return values\n']], ['What is an elegant way to select all non-None elements from parameters and place them in a python dictionary?'], 3, 1], [(13098173, 2), [["And if you want to omit  day  completely in the case where a value doesn't exist:"], ['And in the odd case where you know the date but not the month, iterating through the set of the keys (as @KayZhu suggested) with a  defaultdict  may be the easiest solution:']], [[" In [8]: results = {}\n\nIn [9]: for k, v in names.iteritems():\n   ...:     results[k] = {'month': v}\n   ...:     if dates.has_key(k):\n   ...:         results[k]['day'] = dates[k]\n   ...:\n   ...:\n\nIn [10]: results\nOut[10]:\n{'George': {'day': '21/03', 'month': 'march'},\n 'Mary': {'day': '2/02', 'month': 'february'},\n 'Peter': {'month': 'may'},\n 'Steven': {'day': '14/03', 'month': 'april'},\n 'Will': {'day': '7/01', 'month': 'january'}}\n"]], ['How to create a double dictionary in Python?'], 4, 0], [(13098173, 3), [['And in the odd case where you know the date but not the month, iterating through the set of the keys (as @KayZhu suggested) with a  defaultdict  may be the easiest solution:'], ['-10000']], [[" In [1]: from collections import defaultdict\n\nIn [2]: names = {'Will': 'january', 'Mary': 'february', 'George': 'march', 'Steven': 'april', 'Peter': 'may'}\n\nIn [3]: dates = {'Will': '7/01', 'George': '21/03', 'Steven': '14/03', 'Mary': '2/02', 'Marat': '27/03'}\n\nIn [4]: results = defaultdict(dict)\n\nIn [5]: for name in set(names.keys() + dates.keys()):\n   ...:     if name in names:\n   ...:         results[name]['month'] = names[name]\n   ...:     if name in dates:\n   ...:         results[name]['day'] = dates[name]\n   ...:\n   ...:\n\nIn [6]: for k, v in results.iteritems():\n   ...:     print k, v\n   ...:\n   ...:\nGeorge {'day': '21/03', 'month': 'march'}\nWill {'day': '7/01', 'month': 'january'}\nMarat {'day': '27/03'}\nSteven {'day': '14/03', 'month': 'april'}\nPeter {'month': 'may'}\nMary {'day': '2/02', 'month': 'february'}\n"]], ['How to create a double dictionary in Python?'], 4, 0], [(13103195, 0), [['so just try:'], ['or if you find with findNext try:']], [[' from BeautifulSoup import BeautifulSoup\n\ntext = """\n<dt>PLZ:</dt>\n<dd>\n8047\n</dd>"""\n\nnumber = BeautifulSoup(text).find("dt",text="PLZ:").parent.findNextSiblings("dd")\nprint BeautifulSoup(\'\'.join(number[0]))\n']], ['Using beautifulsoup to parse tag with some text'], 2, 1], [(13103195, 1), [['or if you find with findNext try:'], ['-10000']], [[' number = BeautifulSoup(text).find("dt",text="PLZ:").parent.findNext("dd").contents[0]\n']], ['Using beautifulsoup to parse tag with some text'], 2, 1], [(13208212, 0), [['Use  "formatstring".format :'], ['If you find yourself substituting a large number of variables, you can use']], [[' code = "We Says Thanks!"\nhtml = """\\\n<html>\n  <head></head>\n  <body>\n    <p>Thank you for being a loyal customer.<br>\n       Here is your unique code to unlock exclusive content:<br>\n       <br><br><h1>{code}</h1><br>\n       <img src="http://domain.com/footer.jpg">\n    </p>\n  </body>\n</html>\n""".format(code=code)\n']], ['Python Variable in an HTML email in Python'], 2, 1], [(13247749, 0), [['First, the example is not valid xml. You can use  xml.etree  that comes included:'], ['output:']], [[' from xml.etree import ElementTree as et\nxmlstr="""\\\n<?xml version="1.0"?>\n<area>\n  <media>\n    <options>\n         <name>Jaipur</name>\n    </options>\n </media>\n</area>"""\ndoc=et.fromstring(xmlstr)\ndoc.find(\'.//name\').text=\'Mumbai\'\nprint et.tostring(doc)\n']], ['how to change a node value in python'], 2, 1], [(13247749, 1), [['output:'], ['-10000']], [[' <area>\n  <media>\n    <options>\n         <name>Mumbai</name>\n    </options>\n </media>\n</area>\n']], ['how to change a node value in python'], 2, 0], [(13276796, 0), [['In Python 2.x you can use  str.join :'], ["If you are using Python 3.x then it's even easier because there's a  print  function:"]], [[" def my_print(*args):\n    print ' '.join(map(str, args))\n"]], ['print tuple as number of arguments'], 2, 1], [(13276796, 1), [["If you are using Python 3.x then it's even easier because there's a  print  function:"], ['Other answers also mention that you can  from __future__ import print_function , but this has the disadvantage that all your existing code that uses the  print  statement will break.']], [[' def my_print(*args):\n    print(*args)\n']], ['print tuple as number of arguments'], 2, 1], [(13279399, 0), [['You can get posted form data from  request.form  and query string data from  request.args .'], ['-10000']], [[' myvar =  request.form["myvar"]\n']], ['How to obtain values of request variables using Python and Flask'], 2, 0], [(13279399, 1), [['-10000'], ['-10000']], [[' myvar = request.args["myvar"]\n']], ['How to obtain values of request variables using Python and Flask'], 2, 0], [(13374028, 0), [['Suppose you are having a button with id="resume", then you can invoke a particular Django view using the following sample code:'], ['And the example view function in views.py:']], [[' $("#resume").bind("click",function() {\n    $.post("/resume/",\n    {\n        name: "Resume" //Any example parameter that is to be passed to the view function.\n    },\n    function(data,textStatus)\n    {\n    //Callback function on success\n    });\n});\n']], ['how to Perform search operation in Django?'], 2, 0], [(13374028, 1), [['And the example view function in views.py:'], ['The above code also needs jQuery library in your HTML code.']], [[' @csrf_exempt\ndef resume(request):\n    //Do your search operation.\n    return HttpResponse(status=200)\n']], ['how to Perform search operation in Django?'], 2, 0], [(13382774, 0), [['You can do it like this: -'], ['NOTE: - \nNote that, you should never do this with a  list  of  mutable types  with same value, else you will see surprising behaviour like the one in below example: -']], [[' >>> [False] * 10\n[False, False, False, False, False, False, False, False, False, False]\n']], ['Initialize list with same bool value'], 2, 1], [(13382774, 1), [['NOTE: - \nNote that, you should never do this with a  list  of  mutable types  with same value, else you will see surprising behaviour like the one in below example: -'], ['As you can see, changes you made in one inner list, is reflected in all of them.']], [[' >>> my_list = [[10]] * 3\n>>> my_list\n[[10], [10], [10]]\n>>> my_list[0][0] = 5\n>>> my_list\n[[5], [5], [5]]\n']], ['Initialize list with same bool value'], 2, 0], [(13390315, 0), [['-10000'], ['Get the the users participating in a specific project:']], [[" class Project(models.Model):\n    name = models.CharField(max_length=100)\n    users = models.ManyToManyField(User)\n\nclass Task(models.Model):\n    project = models.ForeignKey(Project, related_name='project_tasks')\n    name = models.CharField(max_length=300)\n    assignee = models.ForeignKey(User, related_name='tasks')\n"]], ['have multiple users as one model field in many to one format django models'], 4, 0], [(13390315, 1), [['Get the the users participating in a specific project:'], ["Get a project's tasks:"]], [[" p = Project.objects.get(name='myproject')\nusers = p.users.all()\n"]], ['have multiple users as one model field in many to one format django models'], 4, 0], [(13390315, 2), [["Get a project's tasks:"], ['Get All the tasks a user has, of all the projects:']], [[' users = p.project_tasks.all()  # Because of `related_name` in Task.project\n']], ['have multiple users as one model field in many to one format django models'], 4, 0], [(13390315, 3), [['Get All the tasks a user has, of all the projects:'], ['Notes:']], [[" u = User.objects.get(username='someuser')\nu.tasks.all()  # Because of `related_name` in Task.assignee\n"]], ['have multiple users as one model field in many to one format django models'], 4, 0], [(13405223, 0), [['-10000'], ['OUTPUT']], [[' import re\n\ndef get_matcher(word, minchars):\n    reg = \'|\'.join([word[0:i] for i in range(len(word), minchars - 1, -1)])\n    return re.compile(\'(%s)$\' % (reg))\n\nmatcher = get_matcher(\'potato\', 4)\nfor s in ["this is a sentence about a potato", "this is a sentence about a potat", "this is another sentence about a pota"]:\n    print matcher.search(s).groups()\n']], ['Regex? Match part of or whole word'], 2, 1], [(13405223, 1), [['OUTPUT'], ['-10000']], [[" ('potato',)\n('potat',)\n('pota',)\n"]], ['Regex? Match part of or whole word'], 2, 0], [(13407560, 0), [['This should work:'], ['You could also reduce the number of times you call  log10  and number of math operations by using a nested recursive function:']], [[' from math import log10\ndef rev(num):\n    if num < 10:\n        return num\n    else:\n        ones = num % 10\n        rest = num // 10\n        #print ones, rest, int(log10(rest) + 1), ones * 10 ** int(log10(rest) + 1)\n        return ones * 10 ** int(log10(rest) + 1) + rev(rest)\nprint rev(9000), rev(1234), rev(1234567890123456789)\n']], ['Python reverse integer using recursion'], 2, 1], [(13407560, 1), [['You could also reduce the number of times you call  log10  and number of math operations by using a nested recursive function:'], ['-10000']], [[' def rev(num):\n    def rec(num, tens):\n        if num < 10:\n            return num        \n        else:\n            return num % 10 * tens + rec(num // 10, tens // 10)\n    return rec(num, 10 ** int(log10(num)))\n']], ['Python reverse integer using recursion'], 2, 1], [(13416327, 0), [['Have a look at the  requests documentation  on how to send multipart requests. Basically you just need to do:'], ['Or in your case:']], [[" >>> url = 'http://httpbin.org/post'\n>>> files = {'file': open('report.xls', 'rb')}   \n>>> r = requests.post(url, files=files)\n"]], ['How to post an image in Python just like byte array in Java?'], 2, 1], [(13416327, 1), [['Or in your case:'], ['-10000']], [[" >>> r = requests.get(url1)\n>>> files = {'image': r.content}   \n>>> r = requests.post(url2, files=files)\n"]], ['How to post an image in Python just like byte array in Java?'], 2, 1], [(13454695, 0), [["Assuming it's a null-terminated string, you can cast the array to a  char *  and use its  value . Here's an example where that's not the case. "], ['Instead you can iterate the array with  join :']], [[' >>> class Person(Structure): _fields_ = [("name", c_ubyte * 8), (\'age\', c_ubyte)]\n... \n>>> smith = Person((c_ubyte * 8)(*bytearray(\'Mr Smith\')), 9)\n>>> smith.age\n9\n>>> cast(smith.name, c_char_p).value\n\'Mr Smith\\t\'\n']], ['How to print c_ubyte_Array object in Python'], 4, 0], [(13471083, 0), [["First, create a view that will return the MenuItemComponent instances that you're interested in."], ["Then you need to create a serializer to give you the representation you want.  Your example is a bit more interesting/involved than the typical case, so it'd look something like this... "]], [[' class ListComponents(generics.ListAPIView):\n    serializer_class = MenuItemComponentSerializer\n\n    def get_queryset(self):\n        """\n        Override .get_queryset() to filter the items returned by the list.\n        """\n        menuitem = self.kwargs[\'menuitem\']\n        return MenuItemComponent.objects.filter(menuItem=menuitem)\n']], ['How to extend model on serializer level with django-rest-framework'], 3, 0], [(13471083, 1), [["Then you need to create a serializer to give you the representation you want.  Your example is a bit more interesting/involved than the typical case, so it'd look something like this... "], ["There's no field that quite meets your 'url' case here, so we'll create a custom field for that:"]], [[" class MenuItemComponentSerializer(serializers.Serializer):\n    url = ComponentURLField(source='component')\n    name = Field(source='component.name')\n    isReplaceable = Field()\n"]], ['How to extend model on serializer level with django-rest-framework'], 3, 0], [(13471083, 2), [["There's no field that quite meets your 'url' case here, so we'll create a custom field for that:"], ['I think that should all be about right.']], [[' class ComponentURLField(serializers.Field):\n    def to_native(self, obj):\n        """\n        Return a URL, given a component instance, \'obj\'.\n        """\n\n        # Something like this...\n        request = self.context[\'request\']\n        return reverse(\'component-detail\', kwargs=kwargs, request=request)\n']], ['How to extend model on serializer level with django-rest-framework'], 3, 0], [(13497170, 1), [['You can then check if b is a cycle of a with:'], ['If the length of the list is long, or if want to make multiple comparison to the same cycles, it may be beneficial (performance wise) to embed the results in a set.']], [[' b in cycles(a)\n']], ['clean way to accomplish -- if x in [(0, 1, 2), (2, 0, 1), (1, 2, 0)]:?'], 4, 0], [(13497170, 2), [['If the length of the list is long, or if want to make multiple comparison to the same cycles, it may be beneficial (performance wise) to embed the results in a set.'], ['You can prevent necessarily constructing all the cycles by embedding the equality check in the list and using any:']], [[' set_cycles = set(cycles(a))\nb in set_cycles\n']], ['clean way to accomplish -- if x in [(0, 1, 2), (2, 0, 1), (1, 2, 0)]:?'], 4, 0], [(13497170, 3), [['You can prevent necessarily constructing all the cycles by embedding the equality check in the list and using any:'], ['You could also achieve this effect by turning the  cycles  function into a generator.']], [[' any( b == a[i:]+a[:i] for i in range(len(a)))\n']], ['clean way to accomplish -- if x in [(0, 1, 2), (2, 0, 1), (1, 2, 0)]:?'], 4, 0], [(13539339, 0), [['To make  abc_  optional, you could use the  question mark operator :'], ['Thus, the entire regex becomes:']], [[' (abc_)?\n']], ['Python regex: How to specify an optional match (for potentially empty sub expression)?'], 3, 0], [(13548996, 0), [["The way I'd do this is something like this:"], ["Update:   \nI'm not sure why you wouldn't be able to  import  standard modules, but if for whatever reason you're forbidden from using the  import  statement, here's a version with only built-in functions:"]], [[" import operator\nfrom collections import defaultdict\nlistoflists = [['A', 'B', 'C', 'D'], ['B', 'A', 'C', 'D'], ['B', 'C', 'D', 'A']]\n\ndef borda(listoflists):\n   outdict = defaultdict(int)\n   for item in listoflists:\n      outdict[item[0]] += 3\n      outdict[item[1]] += 2\n      outdict[item[2]] += 1\n\n   highestitem = max(outdict.iteritems(), key=operator.itemgetter(1))[0]\n   outlist = [outdict[item[0]] for item in sorted(outdict.keys())]\n\n   return (highestitem, outlist)\n"]], ['Reiterating over lists and dictionaries'], 2, 1], [(13548996, 1), [["Update:   \nI'm not sure why you wouldn't be able to  import  standard modules, but if for whatever reason you're forbidden from using the  import  statement, here's a version with only built-in functions:"], ['-10000']], [[" listoflists = [['A', 'B', 'C', 'D'], ['B', 'A', 'C', 'D'], ['B', 'C', 'D', 'A']]\n\ndef borda(listoflists):\n    outdict = {}\n    for singlelist in listoflists:\n        # Below, we're just turning singlelist around in order to\n        # make use of index numbers from enumerate to add to the scores\n        for index, item in enumerate(singlelist[2::-1]):\n            if item not in outdict:\n                outdict[item] = index + 1\n            else:\n                outdict[item] += index + 1\n\n    highestitem = max(outdict.iteritems(), key=lambda i: i[1])[0]\n    outlist = [outdict[item[0]] for item in sorted(outdict.keys())]\n\n    return (highestitem, outlist)\n"]], ['Reiterating over lists and dictionaries'], 2, 1], [(13562613, 0), [['Your  combinations  approach was correct, you just need to turn the results of each combination into a dict again:'], ['This version is a generator, yielding pairs efficiently, nothing is held in memory any longer than absolutely necessary. If you need a list, just call  list()  on the generator:']], [[' import itertools\n\ndef pairwise(input):\n    for values in input.itervalues():\n        for pair in itertools.combinations(values.iteritems(), 2):\n            yield dict(pair)\n']], ['Pair combinations of elements in dictionary without repetition'], 5, 1], [(13562613, 1), [['This version is a generator, yielding pairs efficiently, nothing is held in memory any longer than absolutely necessary. If you need a list, just call  list()  on the generator:'], ['Output:']], [[' list(pairwise(pleio))\n']], ['Pair combinations of elements in dictionary without repetition'], 5, 0], [(13562613, 2), [['Output:'], ['You can even combine the whole thing into a one-liner generator:']], [[" >>> from pprint import pprint\n>>> pprint(list(pairwise(pleio)))\n[{'enf2': ['48', 'free'], 'enf3': ['34', 'set']},\n {'enf1': ['54', 'set'], 'enf3': ['34', 'set']},\n {'enf3': ['34', 'set'], 'enf4': ['12', 'free']},\n {'enf1': ['54', 'set'], 'enf2': ['48', 'free']},\n {'enf2': ['48', 'free'], 'enf4': ['12', 'free']},\n {'enf1': ['54', 'set'], 'enf4': ['12', 'free']}]\n"]], ['Pair combinations of elements in dictionary without repetition'], 5, 0], [(13562613, 4), [['Which outputs:'], ['If you are on Python 3, replace  .itervalues()  and  .iteritems()  by  .values()  and  .items()  respectively.']], [[" >>> for paired in (dict(p) for v in pleio.itervalues() for p in combinations(v.iteritems(), 2)):\n...     print paired\n... \n{'enf3': ['34', 'set'], 'enf2': ['48', 'free']}\n{'enf3': ['34', 'set'], 'enf1': ['54', 'set']}\n{'enf3': ['34', 'set'], 'enf4': ['12', 'free']}\n{'enf2': ['48', 'free'], 'enf1': ['54', 'set']}\n{'enf2': ['48', 'free'], 'enf4': ['12', 'free']}\n{'enf1': ['54', 'set'], 'enf4': ['12', 'free']}\n"]], ['Pair combinations of elements in dictionary without repetition'], 5, 0], [(13584299, 0), [['It seems that a "person" and a "tweet" are going to be  objects  that have their own  data , and  functions . You can logically associate this idea by wrapping things up in a class. For example:'], ['Would give:']], [[' class tweet(object):\n    def __init__(self, text):\n        self.text = text\n        self.retweets = 0\n    def retweet(self):\n        self.retweets += 1\n    def __repr__(self):\n        return "(%i)" % (self.retweets)\n    def __hash__(self):\n        return hash(self.text)\n\nclass person(object):\n    def __init__(self, name):\n        self.name = name\n        self.tweets = dict()\n\n    def __repr__(self):\n        return "%s : %s" % (self.name, self.tweets)\n\n    def new_tweet(self, text):\n        self.tweets[text] = tweet(text)\n\n    def retweet(self, text):\n        self.tweets[text].retweet()\n\nM = person("mac389")\nM.new_tweet(\'foo\')\nM.new_tweet(\'bar\')\nM.retweet(\'foo\')\nM.retweet(\'foo\')\n\nprint M\n']], ['Generate nested dictionary with list and dict comprehensions'], 2, 1], [(13584299, 1), [['Would give:'], ["The advantage here is twofold. One, is that new data associated with a person or tweet is added in an obvious  and  logical  way. The second is that you've created a nice user interface (even if you're the only one using it!) that will make life easier in the long run."]], [[" mac389 : {'foo': (2), 'bar': (0)}\n"]], ['Generate nested dictionary with list and dict comprehensions'], 2, 0], [(13612437, 0), [['Look at the code for  pydoc , i.e.:'], ["Helper class's  help  member function calls  doc  function calls  render_doc , which is probably the function you want."]], [['     Python27\\Lib\\pydoc.py\n']], ['How to implement man-like help page in python(python shell already has it)'], 3, 0], [(13612437, 1), [["Helper class's  help  member function calls  doc  function calls  render_doc , which is probably the function you want."], ['As a side note, while fact checking this answer I learned that pydoc can be called from the command line:']], [[' import sys\nimport pydoc\n\nplainSysDoc = pydoc.plain((pydoc.render_doc(sys)))\nprint plainSysDoc\n']], ['How to implement man-like help page in python(python shell already has it)'], 3, 1], [(13669642, 0), [['code'], ['style.css']], [[" from gi.repository import Gtk, Gdk\n\ndef focus_in(*args):\n    print 'focus_in called'\n\ndef focus_out(*args):\n    print 'focus_out called'\n\nwindow = Gtk.Window()\nwindow.connect('destroy', Gtk.main_quit)\nscreen = Gdk.Screen.get_default()\ncss_provider = Gtk.CssProvider()\ncss_provider.load_from_path('style.css')\npriority = Gtk.STYLE_PROVIDER_PRIORITY_USER\ncontext = Gtk.StyleContext()\ncontext.add_provider_for_screen(screen, css_provider, priority)\nfname = Gtk.Entry(text='First Name')\nlname = Gtk.Entry(text='Last Name')\nbutton = Gtk.Button('Submit')\nfname.connect('focus-in-event', focus_in)\nfname.connect('focus-out-event', focus_out)\nvbox = Gtk.VBox()\nvbox.add(fname)\nvbox.add(lname)\nvbox.add(button)\nwindow.add(vbox)\nwindow.show_all()\nGtk.main()\n"]], ['Gtk 3 python entry color'], 2, 0], [(13669642, 1), [['style.css'], ['screenshot']], [[' GtkEntry {\n    color: darkgrey;\n}\n\nGtkEntry:focused {\n    color: black;\n}\n']], ['Gtk 3 python entry color'], 2, 0], [(13695181, 0), [['You could use a  logging.Filter :'], ['yields']], [[" import logging\n\nclass ContextFilter(logging.Filter):\n    def filter(self, record):\n        record.count = counter\n        return True\n\nlogging.basicConfig(\n    level = logging.DEBUG,\n    format = '%(levelname)-8s: %(count)s: %(message)s')\nlogger = logging.getLogger(__name__)\nlogger.addFilter(ContextFilter())\n\ncounter = 5\nlogger.debug('First Event')\ncounter += 2\nlogger.warning('Second Event')\n"]], ['Pass a counter to every python logging method'], 2, 1], [(13695181, 1), [['yields'], ['-10000']], [[' DEBUG   : 5: First Event\nWARNING : 7: Second Event\n']], ['Pass a counter to every python logging method'], 2, 0], [(13701374, 0), [['I found a neat solution (better ones are welcomed) using a decorator which saves the last value returned by the decorated function in the  last  attribute. My construct becomes:'], ["Of course you must remember to decorate the functions which you want to ' enable ' the  last  attribute for, using (assumed that the decorator name is  save_last ):"]], [[' if my_func(x) == some_value:\n    # do anything with the value returned by my_func, saved in my_func.last\n    # such as\n    print my_func.last\n    return my_func.last\n']], ['How to avoid defining a variable to hold a function result which might be needed only once'], 3, 0], [(13701374, 1), [["Of course you must remember to decorate the functions which you want to ' enable ' the  last  attribute for, using (assumed that the decorator name is  save_last ):"], ['The decorator is defined as:']], [[' @save_last\ndef my_func(...):\n    # function definition\n']], ['How to avoid defining a variable to hold a function result which might be needed only once'], 3, 0], [(13701374, 2), [['The decorator is defined as:'], ['-10000']], [[" # last value returned by decorated function is accessible as 'last' attribute\ndef save_last(f):\n    def w(*args, **kwargs): # w is the 'wrapper' function\n        w.last=f(*args, **kwargs)\n        return w.last\n    return w\n"]], ['How to avoid defining a variable to hold a function result which might be needed only once'], 3, 0], [(13715594, 1), [['Use like this:'], ['-10000']], [[" @conditional(cache_region('long_term'))\ndef get(self, arg):\n    return arg + 1\n"]], ['Conditionally disable caching decorator based on instance variable'], 2, 0], [(13728878, 0), [['Set the  indent  option to  0  or more:'], ['Your example would be output as:']], [[" with open(p_out, 'wb') as fp:\n    json.dump(my_dictionary, fp, indent=0)\n"]], ['Dumping multiple variables to disk in Json. One variable per line'], 2, 1], [(13728878, 1), [['Your example would be output as:'], ['-10000']], [[' {\n"variable_2": "something_else", \n"variable_1": "something"\n}\n']], ['Dumping multiple variables to disk in Json. One variable per line'], 2, 0], [(13793694, 0), [["You're very close!  The usual approach is to use a dictionary, and to use the names you want as dictionary keys.  For example:"], ['This way you can iterate over the rooms in several ways, for example:']], [[" >>> class Room(object):\n...     def __init__(self, x, y):\n...         self.x = x\n...         self.y = y\n...         \n>>> rooms = {}\n>>> names = ['a', 'b', 'c', 'd']\n>>> locations = [[1,1], [1,2], [2,1], [2,2]]\n>>> for name, loc in zip(names, locations):\n...     rooms[name] = Room(*loc)\n...     \n>>> rooms\n{'a': <__main__.Room object at 0x8a0030c>, 'c': <__main__.Room object at 0x89b01cc>, 'b': <__main__.Room object at 0x89b074c>, 'd': <__main__.Room object at 0x89b02ec>}\n>>> rooms['c']\n<__main__.Room object at 0x89b01cc>\n>>> rooms['c'].x\n2\n>>> rooms['c'].y\n1\n"]], ['Can you make a function that would create several instances of a class for you in Python?'], 2, 1], [(13793694, 1), [['This way you can iterate over the rooms in several ways, for example:'], ['-10000']], [[' >>> for roomname, room in rooms.items():\n...     print roomname, room.x, room.y\n...     \na 1 1\nc 2 1\nb 1 2\nd 2 2\n']], ['Can you make a function that would create several instances of a class for you in Python?'], 2, 0], [(13794620, 0), [["Here's one way using  GNU awk . Run like:"], ['Contents of  script.awk']], [[' awk -f script.awk file{,}\n']], ['calculate distance between two chains in PDB file'], 5, 0], [(13794620, 2), [['Tab separated results:'], ["Alternatively, here's the one-liner:"]], [[' N-C 51.70\nN-O 52.83\nN-N 51.30\nC-C 51.14\nC-O 52.29\nC-N 50.71\nC-C 50.00\nC-O 51.14\nC-N 49.56\n']], ['calculate distance between two chains in PDB file'], 5, 0], [(13839905, 0), [['-10000'], ["Here's the o/p :-"]], [[' import sys\ndef programs_info_comb(fileName1, fileName2):\n    my_file1 = open(fileName1, "r")\n    my_line1=my_file1.readlines()\n    my_file1.close()\n\n    my_file2 = open(fileName2, "r")\n    my_line2=my_file2.readlines() \n    my_file2.close()\n\n    # load file1 into a dict for lookup later\n    infoFor = dict()\n    for line1 in my_line1: \n        parts = line1.strip().split("\\t")\n        infoFor[parts[0]] = parts[1:] \n\n    # iterate over line numbers to be able to refer previous line numbers\n    for line2 in range(len(my_line2)):\n        if my_line2[line2].startswith("# Q"):\n            name2 = my_line2[line2][9:-1]\n            # lookup\n            if infoFor.has_key(name2):\n                print \'# \' + name2\n        for info in infoFor[name2]:\n                    print info\n            # print programinfo and query lines\n                print my_line2[line2-1],\n                print my_line2[line2],\n    # skip program info always\n        elif my_line2[line2].startswith("# ProgramInfo"):\n            pass\n    # otherwise just print as is\n        else:\n            print my_line2[line2],\n\nif __name__== "__main__":\n    programs_info_comb(sys.argv[1], sys.argv[2])\n']], ['Adding information from one file to another, after a specific action'], 2, 1], [(13839905, 1), [["Here's the o/p :-"], ['-10000']], [[' C:\\>python st.py f1.txt f2.txt\n# IdName1 Info1 Info2 Info3\n#Info: from program1 for name1\n#Info: from program2 for name1\n# ProgramInfo\n# Query: IdName1 Info1 Info2 Info3\n# DatabaseInfo\n# FiledInfo\nline1\nline2\n# IdName2 Info1 Info2 Info3\n#Info: from program1 for name2\n#Info: from program2 for name2\n# ProgramInfo\n# Query: IdName2 Info1 Info2 Info3\n# DatabaseInfo\n# FiledInfo\n# IdName4 Info1 Info2 Info3\n#Info: from program1 for name4\n# ProgramInfo\n# Query: IdName4 Info1 Info2 Info3\n# DatabaseInfo\n# FiledInfo\nline1\nline2\nline3\nline4\n']], ['Adding information from one file to another, after a specific action'], 2, 0], [(13882808, 0), [['So, the only way to create a proper layer group in GIMP 2.8 is to use the pdb call:'], ['Once you have your group, you can insert it anywhere on the image using a']], [[' group = pdb.gimp_layer_group_new(img)\ngroup.name = "my group"\n']], ['GIMP Python-fu nested group layers'], 4, 0], [(13882808, 1), [['Once you have your group, you can insert it anywhere on the image using a'], ['Like in:']], [[' pdb.gimp_image_insert_layer(<img>, <layer>, <parent>, <position>)\n']], ['GIMP Python-fu nested group layers'], 4, 0], [(13882808, 2), [['Like in:'], ["update   (Feb/2015) - The bug for gimp.GroupLayer() is fixed in GIMP's git and it will work properly from GIMP 2.8.16 onward. Now all one has to do to add a new group layer is:"]], [[' >>> img = gimp.Image(640, 480, RGB)\n>>> pdb.gimp_display_new(img)\n<display>\n>>> parent_group = pdb.gimp_layer_group_new(img)\n>>> child_group_1 = pdb.gimp_layer_group_new(img)\n>>> child_group_2 = pdb.gimp_layer_group_new(img)\n>>> grand_child_group = pdb.gimp_layer_group_new(img)\n>>> img.add_layer(parent_group, 0)\n>>> pdb.gimp_image_insert_layer(img, child_group_1, parent_group,0)\n>>> pdb.gimp_image_insert_layer(img, child_group_2, parent_group,1)\n>>> pdb.gimp_image_insert_layer(img, grand_child_group, child_group_1,0)\n>>> l1 = gimp.Layer(img, "test", 320,240)\n>>> pdb.gimp_image_insert_layer(img,l1, grand_child_group,0)\n']], ['GIMP Python-fu nested group layers'], 4, 0], [(13913530, 1), [['The best way to accomplish what you want is to extract all alphanumeric characters in your sentence first and then search this list for the words you need to find:'], ['-10000']], [[" In [51]: def find_all_words(words, sentence):\n....:     all_words = re.findall(r'\\w+', sentence)\n....:     words_found = []\n....:     for word in words:\n....:         if word in all_words:\n....:             words_found.append(word)\n....:     return words_found\n\nIn [52]: print find_all_words(['total', 'staff'], 'The total number of staff in 30?')\n['total', 'staff'] \n\nIn [53]: print find_all_words(['total', 'staff'], 'My staff is totally overworked.')\n['staff']\n"]], ['Python regular expression to search for words in a sentence'], 2, 1], [(13920235, 0), [['-10000'], ['In a quick timeit test the  zip()  version outperforms a looping approach when I tested with 1,000,000 pairs:']], [[" >>> catalog = [('abc', '123'), ('foo', '456'), ('bar', '789'), ('test', '1337')]\n>>> names, vals = zip(*catalog)\n>>> names\n('abc', 'foo', 'bar', 'test')\n>>> vals\n('123', '456', '789', '1337')\n"]], ['Splitting a list of sequences into two lists efficiently'], 2, 1], [(13920235, 1), [['In a quick timeit test the  zip()  version outperforms a looping approach when I tested with 1,000,000 pairs:'], ['-10000']], [[' In [1]: catalog = [(i, i+1) for i in range(1000000)]\n\nIn [2]: def with_zip():\n   ...:     return zip(*catalog)\n   ...: \n\nIn [3]: def without_zip():\n   ...:     names, vals = [], []\n   ...:     for name, val in catalog:\n   ...:         names.append(name)\n   ...:         vals.append(val)\n   ...:     return names, vals\n   ...: \n\nIn [4]: %timeit with_zip()\n1 loops, best of 3: 176 ms per loop\n\nIn [5]: %timeit without_zip()\n1 loops, best of 3: 250 ms per loop\n']], ['Splitting a list of sequences into two lists efficiently'], 2, 1], [(13936068, 0), [['I used a  PyByteArrayObject  (docs  here ) like this:'], ['And then in the extension code:']], [[" from authbind import authenticate\n\ncreds = 'foo\\x00bar\\x00'\nauthenticate(bytearray(creds))\n"]], ['Passing binary data from Python to C API extension'], 2, 0], [(13936068, 1), [['And then in the extension code:'], ['credsCopy  now holds the string of bytes, exactly as they are needed.']], [[' static PyObject* authenticate(PyObject *self, PyObject *args) {\n\n    PyByteArrayObject *creds;\n\n    if (!PyArg_ParseTuple(args, "O", &creds))\n        return NULL;\n\n    char* credsCopy;\n    credsCopy = PyByteArray_AsString((PyObject*) creds);\n}\n']], ['Passing binary data from Python to C API extension'], 2, 0], [(13953964, 0), [['The only way I found I can do it is with  emitter .\nBelow example consists of 3 files:'], ['SConstruct']], [[' ./\n|-SConstruct\n|-src/\n| |-SConscript\n| |-source.txt\n|-build/\n']], ['SCons to generate variable number of targets'], 5, 0], [(13953964, 1), [['SConstruct'], ['src/SConscript']], [[" env = Environment()\n\ndirname = 'build'\nVariantDir(dirname, 'src', duplicate=0)\n\nExport('env')\n\nSConscript(dirname+'/SConscript')\n"]], ['SCons to generate variable number of targets'], 5, 0], [(13953964, 2), [['src/SConscript'], ['src/source.txt']], [[' Import(\'env\')\n\ndef my_emitter( env, target, source ):\n    data = str(source[0])\n    target = []\n    with open( data, \'r\' ) as lines:\n        for line in lines:\n           line = line.strip()\n           name, contents = line.split(\' \', 1)\n           if not name: continue\n\n           generated_source  = env.Command( name, [], \'echo "{0}" > $TARGET\'.format(contents) )\n           source.extend( generated_source )\n           target.append( name+\'.c\' )\n\n    return target, source\n\ndef my_action( env, target, source ):\n    for t,s in zip(target, source[1:]):\n        with open(t.abspath, \'w\') as tf:\n            with open(s.abspath, \'r\') as sf:\n                tf.write( sf.read() )\n\nSourcesGenerator = env.Builder( action = my_action, emitter = my_emitter )\ngenerated_sources = SourcesGenerator( env, source = \'source.txt\' )\n\nlib = env.Library( \'functions\', generated_sources )\n']], ['SCons to generate variable number of targets'], 5, 0], [(13953964, 3), [['src/source.txt'], ['Output :']], [[' a int a(){}\nb int b(){}\nc int c(){}\nd int d(){}\ng int g(){}\n']], ['SCons to generate variable number of targets'], 5, 0], [(13953964, 4), [['Output :'], ["Also this has one thing I don't really like, which is parsing of  headers_list.txt  with each  scons  execution. I feel like there should be a way to parse it only if the file changed. I could cache it by hand, but I still hope there is some trick to make SCons handle that caching for me. "]], [[' $ scons\nscons: Reading SConscript files ...\nscons: done reading SConscript files.\nscons: Building targets ...\necho "int a(){}" > build/a\necho "int b(){}" > build/b\necho "int c(){}" > build/c\necho "int d(){}" > build/d\necho "int g(){}" > build/g\nmy_action(["build/a.c", "build/b.c", "build/c.c", "build/d.c", "build/g.c"], ["src/source.txt", "build/a", "build/b", "build/c", "build/d", "build/g"])\ngcc -o build/a.o -c build/a.c\ngcc -o build/b.o -c build/b.c\ngcc -o build/c.o -c build/c.c\ngcc -o build/d.o -c build/d.c\ngcc -o build/g.o -c build/g.c\nar rc build/libfunctions.a build/a.o build/b.o build/c.o build/d.o build/g.o\nranlib build/libfunctions.a\nscons: done building targets.\n']], ['SCons to generate variable number of targets'], 5, 0], [(13983620, 0), [['collections.Counter'], ['-10000']], [[" >>> from collections import Counter\n>>> c = Counter([thing['count'] for thing in things])\n>>> c[1]               # Number of elements with count==1\n100\n>>> c[2]               # Number of elements with count==2\n100\n>>> c.most_common()    # Most common elements\n[(1, 100), (2, 100)]\n>>> sum(c.values())    # Number of elements\n200\n>>> list(c)            # List of unique counts\n[1, 2]\n>>> dict(c)            # Converted to a dict \n{1: 100, 2: 100}\n"]], ['What is a Pythonic way to count dictionary values in list of dictionaries'], 3, 1], [(13983620, 1), [['-10000'], ['Extended DictCounter to handle missing keys:']], [[" class DictCounter(object):\n    def __init__(self, list_of_ds):\n        for k,v in list_of_ds[0].items():\n            self.__dict__[k] = collections.Counter([d[k] for d in list_of_ds])\n\n>>> new_things = [{'test': 1, 'count': 1} for i in range(10)]\n>>> for i in new_things[0:5]: i['count']=2\n\n>>> d = DictCounter(new_things)\n>>> d.count\nCounter({1: 5, 2: 5})\n>>> d.test\nCounter({1: 10})\n"]], ['What is a Pythonic way to count dictionary values in list of dictionaries'], 3, 1], [(13983620, 2), [['Extended DictCounter to handle missing keys:'], ['-10000']], [[" >>> class DictCounter(object):\n    def __init__(self, list_of_ds):\n        keys = set(itertools.chain(*(i.keys() for i in list_of_ds)))\n        for k in keys:\n            self.__dict__[k] = collections.Counter([d.get(k) for d in list_of_ds])\n\n>>> a = [{'test': 5, 'count': 4}, {'test': 3, 'other': 5}, {'test':3}, {'test':5}]\n>>> d = DictCounter(a)\n>>> d.test\nCounter({3: 2, 5: 2})\n>>> d.count\nCounter({None: 3, 4: 1})\n>>> d.other\nCounter({None: 3, 5: 1})\n"]], ['What is a Pythonic way to count dictionary values in list of dictionaries'], 3, 1], [(14001382, 0), [['See if this works for you, the lines that you want start with digits followed by a plus sign:'], ['This will match the expected output:']], [[' ^[0-9]*\\+.*$\n']], ['Regex Parse Email Python'], 5, 0], [(14001382, 1), [['This will match the expected output:'], ['-10000']], [[' \\*{3}[^\\*]*(?:(?=\\*{3})|(?=^-*$))\n']], ['Regex Parse Email Python'], 5, 0], [(14001382, 2), [['-10000'], ['Updated to meet new requirements:']], [[' #!/usr/bin/env python\n#-*- coding:utf-8 -*-\nimport re\nwith open("/path/to/file", "r") as fileInput:\n    listLines = [   line.strip()\n                    for line in fileInput.readlines()\n                    if re.match("^[0-9]*\\+.*$", line)\n                    ] \n\n\nfor line in listLines:\n    print line\n\n>>> 10+BB {MYXV ABC 4116    SM  MYXV YA 102-15 <DO>} | 2010/11 4.0s             4.0s\n>>> 6+ BB {MYXV ABC 4132    NS  MYXV YT 102-22 <DO>} | 2010 4.5s                4.5s\n>>> 10+BB  {NXTW VXA 4061   SL  MYXV YA 103-22 <DO>} | 11 wala 3.5s             3.5s\n>>> 10+BB  {NXTW VXA 12-47  SP  MYXV YA 106-20 <DO>} | 22 wala 4.0s             4.0s\n']], ['Regex Parse Email Python'], 5, 0], [(14014292, 0), [['Perhaps you are looking for the  __subclasses__  method : '], ['yields']], [[' class Alpha(object):\n    @classmethod\n    def get_derivatives(cls):\n        return cls.__subclasses__() \n\nclass Beta(Alpha):\n    pass\n\nprint(Alpha.get_derivatives())\nprint(Beta.get_derivatives())\n']], ['Python inheritance - going from base class to derived one'], 2, 1], [(14014292, 1), [['yields'], ['-10000']], [[" [<class '__main__.Beta'>]\n[]\n"]], ['Python inheritance - going from base class to derived one'], 2, 0], [(14017199, 0), [['Just store the class itself: '], ['Better is to use this:']], [[' class_register[self.__class__.__name__] = self.__class__\n']], ['Python create instance from list of classes'], 3, 1], [(14047979, 0), [['PHP:'], ['Python:']], [[" // This is the data you want to pass to Python\n$data = array('as', 'df', 'gh');\n\n// Execute the python script with the JSON data\n$result = shell_exec('python /path/to/myScript.py ' . escapeshellarg(json_encode($data)));\n\n// Decode the result\n$resultData = json_decode($result, true);\n\n// This will contain: array('status' => 'Yes!')\nvar_dump($resultData);\n"]], ['executing Python script in PHP and exchanging data between the two'], 2, 0], [(14076207, 0), [['I wrote this code more than 1 year ago so it is not perfect but it works:'], ['Example:']], [[' from win32api import keybd_event\nimport time\nimport random\n\n\nCombs = {\n    \'A\': [\n        \'SHIFT\',\n        \'a\'],\n    \'B\': [\n        \'SHIFT\',\n        \'b\'],\n    \'C\': [\n        \'SHIFT\',\n        \'c\'],\n    \'D\': [\n        \'SHIFT\',\n        \'d\'],\n    \'E\': [\n        \'SHIFT\',\n        \'e\'],\n    \'F\': [\n        \'SHIFT\',\n        \'f\'],\n    \'G\': [\n        \'SHIFT\',\n        \'g\'],\n    \'H\': [\n        \'SHIFT\',\n        \'h\'],\n    \'I\': [\n        \'SHIFT\',\n        \'i\'],\n    \'J\': [\n        \'SHIFT\',\n        \'j\'],\n    \'K\': [\n        \'SHIFT\',\n        \'k\'],\n    \'L\': [\n        \'SHIFT\',\n        \'l\'],\n    \'M\': [\n        \'SHIFT\',\n        \'m\'],\n    \'N\': [\n        \'SHIFT\',\n        \'n\'],\n    \'O\': [\n        \'SHIFT\',\n        \'o\'],\n    \'P\': [\n        \'SHIFT\',\n        \'p\'],\n    \'R\': [\n        \'SHIFT\',\n        \'r\'],\n    \'S\': [\n        \'SHIFT\',\n        \'s\'],\n    \'T\': [\n        \'SHIFT\',\n        \'t\'],\n    \'U\': [\n        \'SHIFT\',\n        \'u\'],\n    \'W\': [\n        \'SHIFT\',\n        \'w\'],\n    \'X\': [\n        \'SHIFT\',\n        \'x\'],\n    \'Y\': [\n        \'SHIFT\',\n        \'y\'],\n    \'Z\': [\n        \'SHIFT\',\n        \'z\'],\n    \'V\': [\n        \'SHIFT\',\n        \'v\'],\n    \'Q\': [\n        \'SHIFT\',\n        \'q\'],\n    \'?\': [\n        \'SHIFT\',\n        \'/\'],\n    \'>\': [\n        \'SHIFT\',\n        \'.\'],\n    \'<\': [\n        \'SHIFT\',\n        \',\'],\n    \'"\': [\n        \'SHIFT\',\n        "\'"],\n    \':\': [\n        \'SHIFT\',\n        \';\'],\n    \'|\': [\n        \'SHIFT\',\n        \'\\\\\'],\n    \'}\': [\n        \'SHIFT\',\n        \']\'],\n    \'{\': [\n        \'SHIFT\',\n        \'[\'],\n    \'+\': [\n        \'SHIFT\',\n        \'=\'],\n    \'_\': [\n        \'SHIFT\',\n        \'-\'],\n    \'!\': [\n        \'SHIFT\',\n        \'1\'],\n    \'@\': [\n        \'SHIFT\',\n        \'2\'],\n    \'#\': [\n        \'SHIFT\',\n        \'3\'],\n    \'$\': [\n        \'SHIFT\',\n        \'4\'],\n    \'%\': [\n        \'SHIFT\',\n        \'5\'],\n    \'^\': [\n        \'SHIFT\',\n        \'6\'],\n    \'&\': [\n        \'SHIFT\',\n        \'7\'],\n    \'*\': [\n        \'SHIFT\',\n        \'8\'],\n    \'(\': [\n        \'SHIFT\',\n        \'9\'],\n    \')\': [\n        \'SHIFT\',\n        \'0\'] }\nBase = {\n    \'0\': 48,\n    \'1\': 49,\n    \'2\': 50,\n    \'3\': 51,\n    \'4\': 52,\n    \'5\': 53,\n    \'6\': 54,\n    \'7\': 55,\n    \'8\': 56,\n    \'9\': 57,\n    \'a\': 65,\n    \'b\': 66,\n    \'c\': 67,\n    \'d\': 68,\n    \'e\': 69,\n    \'f\': 70,\n    \'g\': 71,\n    \'h\': 72,\n    \'i\': 73,\n    \'j\': 74,\n    \'k\': 75,\n    \'l\': 76,\n    \'m\': 77,\n    \'n\': 78,\n    \'o\': 79,\n    \'p\': 80,\n    \'q\': 81,\n    \'r\': 82,\n    \'s\': 83,\n    \'t\': 84,\n    \'u\': 85,\n    \'v\': 86,\n    \'w\': 87,\n    \'x\': 88,\n    \'y\': 89,\n    \'z\': 90,\n    \'.\': 190,\n    \'-\': 189,\n    \',\': 188,\n    \'=\': 187,\n    \'/\': 191,\n    \';\': 186,\n    \'[\': 219,\n    \']\': 221,\n    \'\\\\\': 220,\n    "\'": 222,\n    \'ALT\': 18,\n    \'TAB\': 9,\n    \'CAPSLOCK\': 20,\n    \'ENTER\': 13,\n    \'BS\': 8,\n    \'CTRL\': 17,\n    \'ESC\': 27,\n    \' \': 32,\n    \'END\': 35,\n    \'DOWN\': 40,\n    \'LEFT\': 37,\n    \'UP\': 38,\n    \'RIGHT\': 39,\n    \'SELECT\': 41,\n    \'PRINTSCR\': 44,\n    \'INS\': 45,\n    \'DEL\': 46,\n    \'LWIN\': 91,\n    \'RWIN\': 92,\n    \'LSHIFT\': 160,\n    \'SHIFT\': 161,\n    \'LCTRL\': 162,\n    \'RCTRL\': 163,\n    \'VOLUP\': 175,\n    \'DOLDOWN\': 174,\n    \'NUMLOCK\': 144,\n    \'SCROLL\': 145 }\n\ndef KeyUp(Key):\n    keybd_event(Key, 0, 2, 0)\n\n\ndef KeyDown(Key):\n    keybd_event(Key, 0, 1, 0)\n\n\ndef Press(Key, speed=1):\n    rest_time = 0.05/speed\n    if Key in Base:\n        Key = Base[Key]\n        KeyDown(Key)\n        time.sleep(rest_time)\n        KeyUp(Key)\n        return True\n    if Key in Combs:\n        KeyDown(Base[Combs[Key][0]])\n        time.sleep(rest_time)\n        KeyDown(Base[Combs[Key][1]])\n        time.sleep(rest_time)\n        KeyUp(Base[Combs[Key][1]])\n        time.sleep(rest_time)\n        KeyUp(Base[Combs[Key][0]])\n        return True\n    return False\n\n\ndef Write(Str, speed = 1):\n    for s in Str:\n        Press(s, speed)\n        time.sleep((0.1 + random.random()/10.0) / float(speed))\n']], ['Simulating a key press event in Python 2.7'], 2, 1], [(14076207, 1), [['Example:'], ['If you want to implement some more keys then you can find their codes  here . And just add these keys to the Base dictionary.']], [[" >>> Write('Hello, World!', speed=3)\nHello, World!\n>>> Press('ENTER')\n"]], ['Simulating a key press event in Python 2.7'], 2, 0], [(14144315, 0), [['With this CSV:'], ['And this Python:']], [[' 1,`Flat 5, Park Street`\n']], ['Remove unwanted commas from CSV using Python'], 3, 0], [(14144315, 1), [['And this Python:'], ['You will see this output:']], [[" import csv\n\nwith open('14144315.csv', 'rb') as csvfile:\n    rowreader = csv.reader(csvfile, delimiter=',', quotechar='`')\n    for row in rowreader:\n        print row\n"]], ['Remove unwanted commas from CSV using Python'], 3, 1], [(14144315, 2), [['You will see this output:'], ['This would use commas to separate values but inverted commas for quoted commas']], [[" ['1', 'Flat 5, Park Street']\n"]], ['Remove unwanted commas from CSV using Python'], 3, 0], [(14154851, 0), [['Using  collections.defaultdict :'], ['Out:']], [[' d=collections.defaultdict(list)\nfor item in lst:\n    d[item[1]].append(item)\nd[min(key for key in d.keys() if key!=0)]\n']], ['any python min like function which gives a list as result'], 5, 1], [(14154851, 1), [['Out:'], ['Test :']], [[" [('NORTHLANDER', 3), ('VOLT', 3)]\n"]], ['any python min like function which gives a list as result'], 5, 0], [(14154851, 2), [['Test :'], ['edit \n@martineau optimization:']], [[" #unwind's solution\n\ndef f(lst):\n    return [y for y in lst if y[1] == min([x for x in lst if x[1] > 0],\n                                             key = lambda x: x[1])[1]]\n\ndef f2(lst):\n    d=collections.defaultdict(list)\n    for item in lst:\n        d[item[1]].append(item)\n    return d[min(key for key in d.keys() if key!=0)]\n\n%timeit f(lst)\n100000 loops, best of 3: 12.1 us per loop\n%timeit f2(lst)\n100000 loops, best of 3: 5.42 us per loop\n"]], ['any python min like function which gives a list as result'], 5, 1], [(14154851, 3), [['edit \n@martineau optimization:'], ['And another  dict  based solution using  set.default  is even a bit faster:']], [[' def f3(lst):\n    lstm = min((x for x in lst if x[1]), key = lambda x: x[1])[1]\n    return [y for y in lst if y[1] == lstm]\n\n%timeit f3(lst)\n100000 loops, best of 3: 4.19 us per loop\n']], ['any python min like function which gives a list as result'], 5, 1], [(14154851, 4), [['And another  dict  based solution using  set.default  is even a bit faster:'], ['-10000']], [[' def f4(lst):\n    d={}\n    for item in lst:\n        if item[1] != 0:\n            d.setdefault(item[1],{})[item]=0\n    return d[min(d.keys())].keys()\n\n%timeit f4(lst)\n100000 loops, best of 3: 3.76 us per loop\n']], ['any python min like function which gives a list as result'], 5, 1], [(14208280, 0), [['You can read the subsequent sibling of each  p  tag (note this is very specific to this text, so hopefully it can be expanded to your situation):'], ['This picks up the trailing newline, so you can strip it off if need be:']], [[' In [1]: from bs4 import BeautifulSoup\n\nIn [2]: html = """\\\n   ...: <p>aaa</p>bbb\n   ...: <p>ccc</p>ddd"""\n\nIn [3]: soup = BeautifulSoup(html)\n\nIn [4]: [p.next_sibling for p in soup.findAll(\'p\')]\nOut[4]: [u\'bbb\\n\', u\'ddd\']\n']], ['Python BeautifulSoup get text from HTML'], 2, 1], [(14208280, 1), [['This picks up the trailing newline, so you can strip it off if need be:'], ['The general idea is that you locate the tag(s) before your target text and then find the next sibling element, which should be your text.']], [[" In [5]: [p.next_sibling.strip() for p in soup.findAll('p')]\nOut[5]: [u'bbb', u'ddd']\n"]], ['Python BeautifulSoup get text from HTML'], 2, 0], [(14211597, 0), [["Let's name your list  a  and not  list  ( list  is a very useful function in Python and we don't want to mask it):"], ['b  is now:']], [[" import itertools as it\n\na = [('2013-01-04', u'crid2557171372', 1),\n     ('2013-01-04', u'crid9904536154', 719677),\n     ('2013-01-04', u'crid7990924609', 577352),\n     ('2013-01-04', u'crid7990924609', 399058),\n     ('2013-01-04', u'crid9904536154', 385260),\n     ('2013-01-04', u'crid2557171372', 78873)]\n\nb = []\nfor k,v in it.groupby(sorted(a, key=lambda x: x[:2]), key=lambda x: x[:2]):\n    b.append(k + (sum(x[2] for x in v),))\n"]], ['How to do a groupby of a list of lists'], 2, 1], [(14211597, 1), [['b  is now:'], ['-10000']], [[" [('2013-01-04', u'crid2557171372', 78874),\n\xa0('2013-01-04', u'crid7990924609', 976410),\n\xa0('2013-01-04', u'crid9904536154', 1104937)]\n"]], ['How to do a groupby of a list of lists'], 2, 0], [(14258317, 0), [["First, let's look at our addition tables:"], ['We can find out the indices associated with that order using  np.argsort :']], [[' import numpy as np\ngrid_shape = (4,5)\nN = np.prod(grid_shape)\n\ny = np.add.outer(np.arange(grid_shape[0]),np.arange(grid_shape[1]))\nprint(y)\n\n# [[0 1 2 3 4]\n#  [1 2 3 4 5]\n#  [2 3 4 5 6]\n#  [3 4 5 6 7]]\n']], ["More numpy way of iterating through the 'orthogonal' diagonals of a 2D array"], 5, 0], [(14258317, 1), [['We can find out the indices associated with that order using  np.argsort :'], ['If your ultimate goal is to generate the array  A  that you show above at the end of your post, then you could use  argsort  again:']], [[' idx = np.argsort(y.ravel())\nprint(idx)\n# [ 0  1  5  2  6 10  3  7 11 15  4  8 12 16  9 13 17 14 18 19]\n']], ["More numpy way of iterating through the 'orthogonal' diagonals of a 2D array"], 5, 0], [(14258317, 2), [['If your ultimate goal is to generate the array  A  that you show above at the end of your post, then you could use  argsort  again:'], ['Or, alternatively, if you need to assign other values to  A , perhaps this would be more useful:']], [[' print(np.argsort(idx).reshape(grid_shape[0],-1))\n# [[ 0  1  3  6 10]\n#  [ 2  4  7 11 14]\n#  [ 5  8 12 15 17]\n#  [ 9 13 16 18 19]]\n']], ["More numpy way of iterating through the 'orthogonal' diagonals of a 2D array"], 5, 0], [(14258317, 3), [['Or, alternatively, if you need to assign other values to  A , perhaps this would be more useful:'], ['I know you asked for a way to  iterate  through your array, but I wanted to show the above because generating arrays through whole-array assignment or numpy function calls (like np.argsort) as done above will probably be faster than using a Python loop. But if you need to use a Python loop, then:']], [[' A = np.zeros(grid_shape)\nA1d = A.ravel()\nA1d[idx] = np.arange(N)  # you can change np.arange(N) to any 1D array of shape (N,)\nprint(A)\n# [[  0.   1.   3.   6.  10.]\n#  [  2.   4.   7.  11.  15.]\n#  [  5.   8.  12.  16.  18.]\n#  [  9.  13.  14.  17.  19.]]\n']], ["More numpy way of iterating through the 'orthogonal' diagonals of a 2D array"], 5, 0], [(14258317, 4), [['I know you asked for a way to  iterate  through your array, but I wanted to show the above because generating arrays through whole-array assignment or numpy function calls (like np.argsort) as done above will probably be faster than using a Python loop. But if you need to use a Python loop, then:'], ['-10000']], [[' for i, j in enumerate(idx):\n   A1d[j] = i\n\nprint(A)\n# [[  0.   1.   3.   6.  10.]\n#  [  2.   4.   7.  11.  15.]\n#  [  5.   8.  12.  16.  18.]\n#  [  9.  13.  14.  17.  19.]]\n']], ["More numpy way of iterating through the 'orthogonal' diagonals of a 2D array"], 5, 1], [(14275975, 0), [['IMHO - the following is completely redundant:'], ["There's absolutely no need to use  struct.pack , just do something like:"]], [[' f.write(struct.pack("=I",random.randint(0,sys.maxint*2+1)))\n']], ['Creating random binary files'], 2, 0], [(14275975, 1), [["There's absolutely no need to use  struct.pack , just do something like:"], ['Then, if you need to re-use the file for reading integers, then  struct.unpack  then.']], [[" import os\n\nwith open('output_file', 'wb') as fout:\n    fout.write(os.urandom(1024)) # replace 1024 with size_kb if not unreasonably large\n"]], ['Creating random binary files'], 2, 1], [(14285049, 0), [['-10000'], ['or without imports:']], [[' from numpy import take,argsort\n\ntake(opt,argsort(argsort(perc)[::-1]))\n']], ['Sort a list based on a given distribution'], 3, 1], [(14285049, 1), [['or without imports:'], ['-10000']], [[' zip(*sorted(zip(sorted(range(len(perc)), key=perc.__getitem__)[::-1],opt)))[1]\n']], ['Sort a list based on a given distribution'], 3, 1], [(14285049, 2), [['-10000'], ['-10000']], [[' #Test\n\nl=[([0.23, 0.27, 0.4, 0.1],[3, 2, 2, 1]),\n   ([0.25, 0.25, 0.4, 0.1],[3, 2, 2, 1]),\n   ([0.2,  0.2,  0.4, 0.2],[3, 2, 2, 1])]\n\ndef f1(perc,opt):\n    return take(opt,argsort(argsort(perc)[::-1]))\n\ndef f2(perc,opt):\n    return zip(*sorted(zip(sorted(range(len(perc)),\n             key=perc.__getitem__)[::-1],opt)))[1]       \n\nfor i in l:\n    perc, opt = i\n    print f1(perc,opt), f2(perc,opt)\n\n# output:\n# [2 2 3 1] (2, 2, 3, 1)\n# [2 2 3 1] (2, 2, 3, 1)\n# [1 2 3 2] (1, 2, 3, 2)\n']], ['Sort a list based on a given distribution'], 3, 0], [(14363016, 0), [["We are given a list of strings, but what we'd really like -- what would be more useful -- is a list of sets:"], ["The reason for frozensets will become apparent shortly. I'll explain why, below. The reason why we want sets at all is because that have a convenient superset comparison operator:"]], [[" In [20]: strings = [frozenset(s.split()) for s in strings]    \nIn [21]: strings\nOut[21]: \n[frozenset(['24']),\n frozenset(['277']),\n ...\n frozenset(['136', '139']),\n frozenset(['246'])]\n"]], ['Finding superstrings in a set of strings in python'], 6, 0], [(14363016, 1), [["The reason for frozensets will become apparent shortly. I'll explain why, below. The reason why we want sets at all is because that have a convenient superset comparison operator:"], ['Because we are removing items from  superstrings , we can not also\niterate over  superstrings  itself. So, instead, iterate over a copy:']], [[" In [22]: frozenset(['136']) <= frozenset(['136', '139', '24'])\nOut[22]: True\n\nIn [23]: frozenset(['136']) <= frozenset(['24', '277'])\nOut[23]: False\n"]], ['Finding superstrings in a set of strings in python'], 6, 0], [(14363016, 2), [['Because we are removing items from  superstrings , we can not also\niterate over  superstrings  itself. So, instead, iterate over a copy:'], ['-10000']], [[' for sup in superstrings.copy():\n']], ['Finding superstrings in a set of strings in python'], 6, 0], [(14363016, 3), [['-10000'], ['yields']], [[" strings = [\n    '24', '277', '277 24', '139 24', '139 277 24', '139 277', '139', '136 24',\n    '136 277 24', '136 277', '136', '136 139 24', '136 139 277 24', '136 139 277',\n    '136 139', '246']\n\ndef find_supersets(strings):\n    superstrings = set()\n    set_to_string = dict(zip([frozenset(s.split()) for s in strings], strings))\n    for s in set_to_string.keys():\n        for sup in superstrings.copy():\n            if s <= sup:\n                # print('{s!r} <= {sup!r}'.format(s = s, sup = sup))\n                break\n            elif sup < s:\n                # print('{sup!r} <= {s!r}'.format(s = s, sup = sup))\n                superstrings.remove(sup)\n        else:\n            superstrings.add(s)\n    return [set_to_string[sup] for sup in superstrings]\n\nprint(find_supersets(strings))\n"]], ['Finding superstrings in a set of strings in python'], 6, 1], [(14363016, 4), [['yields'], ['-10000']], [[" ['136 139 277 24', '246']\n"]], ['Finding superstrings in a set of strings in python'], 6, 0], [(14366713, 0), [['Use regular expressions with  re :'], ["?  sign is for making you regex  lazy . Without it you'll get:"]], [[" >>> import re\n>>> s = 'N1B N 1.2620(4) 0.3320(4) 0.0049(7)'\n>>> re.sub('\\(.*?\\)', '', s)\n'N1B N 1.2620 0.3320 0.0049'\n"]], ['removing "()" using python'], 3, 1], [(14366713, 1), [["?  sign is for making you regex  lazy . Without it you'll get:"], ['If you want to delete  only  digits, use  \\d  insted of  . :']], [[" >>> re.sub('\\(.*\\)', '', s)\n'N1B N 1.2620'\n"]], ['removing "()" using python'], 3, 0], [(14383937, 0), [['You are looking for a test for a range of codepoints, so you need a regular expression:'], ['This will return  False  for any unicode text that has codepoints past  \\u00BE  ("¾").']], [[" import re\n# match characters from ¿ to the end of the JSON-encodable range\nexclude = re.compile(ur'[\\u00bf-\\uffff]')\n\ndef isprintable(s):\n    return not bool(exclude.search(s))\n"]], ['Check printable for Unicode'], 2, 1], [(14383937, 1), [['This will return  False  for any unicode text that has codepoints past  \\u00BE  ("¾").'], ['-10000']], [[" >>> isprintable(u'Hello World!')\nTrue\n>>> isprintable(u'Jeg \\u00f8ve mit Norsk.')\nFalse\n"]], ['Check printable for Unicode'], 2, 0], [(14407563, 1), [['To give you this:'], ["Any of these are very easy to parse, and give you a parse tree that's very easy to use. I'd probably go with #2, but since I already explained how to do that in a comment above, let's do #3 here:"]], [[" [[['a', ':', 'b'], '->', ['c', ':', ['d', 'e']]]]\n"]], ["syntactic whitespaces with pyparsing's operatorPrecedence"], 3, 0], [(14421133, 0), [["Here's a complete code example:"], ['You could try to allow the interpreter to run the main thread:']], [[" #!/usr/bin/env python3\nimport threading\n\ndef f(event):\n    while True:\n        pass\n    # never reached, otherwise event.set() would be here\n\nevent = threading.Event()\nthreading.Thread(target=f, args=[event], daemon=True).start()\ntry:\n    print('Press Ctrl+C to exit')\n    event.wait()\nexcept KeyboardInterrupt:\n    print('got Ctrl+C')\n"]], ['Catch Keyboard Interrupt in program that is waiting on an Event'], 3, 1], [(14421133, 1), [['You could try to allow the interpreter to run the main thread:'], ['If you just want to wait until the child thread is done:']], [[' while not finished_event.wait(.1): # timeout in seconds\n    pass\n']], ['Catch Keyboard Interrupt in program that is waiting on an Event'], 3, 1], [(14421630, 0), [["I think  itertools.product  is what you're looking for."], ['Note that  itertools.product  itself returns an  itertools.product  object, not a list.']], [[' # A simple example\nimport itertools\nlst = [0, 1]\nprint(list(itertools.product(lst, repeat=2)))\n# [(0, 0), (0, 1), (1, 0), (1, 1)]\n']], ['Create a list with all possible permutations from a know list of objects, but make the final list x in size'], 2, 1], [(14436970, 0), [['forms.py: '], ['views.py:']], [[' # File: forms.py\nfrom django import forms\nfrom django.forms.formsets import BaseFormSet\n\n\n# What you\'ve called \'GetMachine\'\nclass MachineForm(forms.Form):\n    no_of_lines = forms.IntegerField(max_value=4)\n\n\n# What you\'ve called \'GetLine\'\nclass LineForm(forms.Form):\n    beamline_name = forms.CharField(max_length=15, label=\'Name of Beamline\')\n\n\n# Create a custom formset and override __init__\nclass BaseLineFormSet(BaseFormSet):\n    def __init__(self, *args, **kwargs):\n        super(BaseLineFormSet, self).__init__(*args, **kwargs)\n        no_of_forms = len(self)\n        for i in range(0, no_of_forms):\n            self[i].fields[\'beamline_name\'].label += "-%d" % (i + 1)\n']], ['Django: how to change label using formset extra?'], 5, 0], [(14436970, 1), [['views.py:'], ['urls.py:']], [[' # File: views.py\nfrom django.forms.formsets import formset_factory\nfrom django.shortcuts import render_to_response\nfrom django.template import RequestContext\nfrom django.http import HttpResponseRedirect\nfrom django.core.urlresolvers import reverse\nfrom forms import MachineForm, LineForm, BaseLineFormSet\n\n\ndef get_no_of_lines(request):\n    if request.method == \'POST\':\n        machine_form = MachineForm(request.POST)\n        if machine_form.is_valid():\n            # At this point, form fields have already been \n            # converted to Python data types :)\n            # so no need to convert `line_no` to an integer\n            no_of_lines = machine_form.cleaned_data[\'no_of_lines\']\n            return HttpResponseRedirect(reverse(\'line_form\', kwargs={\'no_of_lines\': no_of_lines}))\n    else:\n        # It looks to me like you probably don\'t mean to\n        # use formsets here (but a form instead)\n        machine_form = MachineForm()\n\n    c = RequestContext(request, {\n        \'machine_form\': machine_form,\n    })\n    return render_to_response(\'get_no_of_lines.html\', c)\n\n\ndef line_form(request, no_of_lines):\n    # You probably should validate this number (again).\n    # In fact, you probably need to validate first form (MachineForm).\n    # ...But I\'m assuming it\'ll be valid in this example.\n    no_of_lines = int(no_of_lines)\n    LineFormSet = formset_factory(LineForm, extra=no_of_lines, formset=BaseLineFormSet)\n    if request.method == "POST":\n        formset = LineFormSet(request.POST, request.FILES)\n        if formset.is_valid():\n            pass\n            # Do stuff with form submission\n            # Redirect\n\n    else:\n        formset = LineFormSet()\n\n    c = RequestContext(request, {\n        \'formset\': formset,\n    })\n    return render_to_response(\'line_form.html\', c)\n']], ['Django: how to change label using formset extra?'], 5, 0], [(14436970, 2), [['urls.py:'], ['get_no_of_lines.html:']], [[" from django.conf.urls import url, patterns\nfrom views import get_no_of_lines, line_form\n\n\nurlpatterns = patterns('',\n     url(r'^$', get_no_of_lines, name='get_no_of_lines'),\n     url(r'^line_form/(?P<no_of_lines>\\d{1})$', line_form, name='line_form'),\n)\n"]], ['Django: how to change label using formset extra?'], 5, 0], [(14436970, 3), [['get_no_of_lines.html:'], ['line_form.html:']], [[' <form method="POST">\n{% csrf_token %}\n{{ machine_form }}\n</form>\n']], ['Django: how to change label using formset extra?'], 5, 0], [(14436970, 4), [['line_form.html:'], ['-10000']], [[' <form method="POST">\n{% csrf_token %}\n{{ formset.as_p }}\n']], ['Django: how to change label using formset extra?'], 5, 0], [(14462993, 0), [["Declare the  company_id  field as a regular  many2one  towards  res.company . The default  security record rules  (defined  here ) will take care of dynamically showing only the companies that are subsidiaries of the user's current company. The user can change their current company to any of their  allowed companies  at any time in the preferences, to work in a different company context. And since  security record rules  do not apply for the special admin user, it will always be possible to choose any company when logged in as admin."], ['-10000']], [[" 'company_id': fields.many2one('res.company', 'Company', required=False)\n"]], ['How to define multi-company-aware models in OpenERP'], 3, 0], [(14462993, 1), [['-10000'], ['-10000']], [[" 'company_id': lambda self,cr,uid,ctx: self.pool['res.company']._company_default_get(cr,uid,object='<your_model>',context=ctx)\n"]], ['How to define multi-company-aware models in OpenERP'], 3, 0], [(14462993, 2), [['-10000'], ['-10000']], [[' <field name="company_id" groups="base.group_multi_company"/>\n']], ['How to define multi-company-aware models in OpenERP'], 3, 0], [(14494101, 0), [["For example, if you want to trigger 'a' key press, do as follows :"], ['To find the key value for any key is to print the key value using a simple script as follows :']], [[' if cv2.waitKey(33) == ord(\'a\'):\n   print "pressed a"\n']], ['Using other keys for the waitKey() function of opencv'], 3, 1], [(14494101, 1), [['To find the key value for any key is to print the key value using a simple script as follows :'], ['With this code, I got following values :']], [[" import cv2\nimg = cv2.imread('sof.jpg') # load a dummy image\nwhile(1):\n    cv2.imshow('img',img)\n    k = cv2.waitKey(33)\n    if k==27:    # Esc key to stop\n        break\n    elif k==-1:  # normally -1 returned,so don't print it\n        continue\n    else:\n        print k # else print its value\n"]], ['Using other keys for the waitKey() function of opencv'], 3, 1], [(14494101, 2), [['With this code, I got following values :'], ['-10000']], [[' Upkey : 2490368\nDownKey : 2621440\nLeftKey : 2424832\nRightKey: 2555904\nSpace : 32\nDelete : 3014656\n...... # Continue yourself :)\n']], ['Using other keys for the waitKey() function of opencv'], 3, 0], [(14508570, 0), [['In a single line:'], ['You can test it with:']], [[' np.average(a.reshape(48, -1), weights=b.ravel()), axis=1)\n']], ['Numpy averaging with multi-dimensional weights along an axis'], 2, 1], [(14536778, 0), [['The  isoformat()  method  gives you that:'], ['but might include microsends; you could use the  .strftime()  method  for some more control:']], [[" d.isoformat(' ')\n"]], ['Date formate conversion in Python'], 3, 1], [(14536778, 2), [['Output'], ['-10000']], [[" >>> import datetime\n>>> d = datetime.datetime.today()\n>>> d.isoformat(' ')\n'2013-01-26 13:12:08.628580'\n>>> d.strftime('%Y-%m-%d %H:%M:%S')\n'2013-01-26 13:12:08'\n"]], ['Date formate conversion in Python'], 3, 1], [(14555771, 0), [["Assuming that by cumulative sum you mean total (there's a cumulative sum function which returns something else), then you can do this both using the standard sort:"], ['and in numpy using  argsort :']], [[' >>> v = [[1,2,3,4], [2,3,4,5], [11,21,3,4], [4,33,21,1], [2,4,6,5]]\n>>> sorted(v, key=sum, reverse=True)\n[[4, 33, 21, 1], [11, 21, 3, 4], [2, 4, 6, 5], [2, 3, 4, 5], [1, 2, 3, 4]]\n']], ['Order a NXM Numpy Array according to cumulative sums of each sub-array'], 2, 0], [(14555771, 1), [['and in numpy using  argsort :'], ['But I may be misunderstanding you.']], [[' >>> a = np.array(v)\n>>> a.sum(axis=1)\narray([10, 14, 39, 59, 17])\n>>> a.sum(axis=1).argsort()\narray([0, 1, 4, 2, 3])\n>>> a[a.sum(axis=1).argsort()[::-1]]\narray([[ 4, 33, 21,  1],\n       [11, 21,  3,  4],\n       [ 2,  4,  6,  5],\n       [ 2,  3,  4,  5],\n       [ 1,  2,  3,  4]])\n']], ['Order a NXM Numpy Array according to cumulative sums of each sub-array'], 2, 0], [(14572495, 0), [['How about:'], ['or, if you prefer a more general solution:']], [[" In [8]: [{'location':l, 'name':n, 'value':v} for (n, l, v) in all_values]\nOut[8]: \n[{'location': 0, 'name': 'a', 'value': 0.1},\n {'location': 1, 'name': 'b', 'value': 0.5},\n {'location': 2, 'name': 'c', 'value': 1.0}]\n"]], ['Creating an iterable of dictionaries from an iterable of tuples'], 2, 1], [(14572495, 1), [['or, if you prefer a more general solution:'], ['-10000']], [[" In [12]: keys = ('name', 'location', 'value')\n\nIn [13]: [dict(zip(keys, values)) for values in all_values]\nOut[13]: \n[{'location': 0, 'name': 'a', 'value': 0.1},\n {'location': 1, 'name': 'b', 'value': 0.5},\n {'location': 2, 'name': 'c', 'value': 1.0}]\n"]], ['Creating an iterable of dictionaries from an iterable of tuples'], 2, 1], [(14582852, 0), [['You should be adding the dictionary into an array like :'], ['to loop again, you can do it this way :']], [[' friends = []\nfor message in messages:\n  dict = {"message" : message.message, "phone" : message.phone }\n  friends.append(dict)\n']], ['Named dictionary in python'], 2, 1], [(14582852, 1), [['to loop again, you can do it this way :'], ['-10000']], [[' for friend in friends:\n  print "%s - %s" % (friend["message"], friend["phone"])\n']], ['Named dictionary in python'], 2, 0], [(14583576, 1), [['As in the comment, my solution would be '], ["I can't think of anything else, sorry. Maybe others will have a different perspective.."]], [[" data['ranking'] = data.groupby('Cat1')['Counter'].rank(ascending=0)\n"]], ['Sorting panda DataFrames based on criteria'], 2, 1], [(14601544, 0), [['First, provide your customized interface by extending the interface you want to customize:'], ['Then, create the settings adapter that is used to store and retrieve the settings of the schema::']], [[' class IEnhancedDocumentViewerSchema(IGlobalDocumentViewerSettings):\n    """ \n    Use all the fields from the default schema, and add various extra fields.\n    """\n\n    folder_location = schema.TextLine(\n        title=u"Default folder location",\n        description=u\'This folder will be created in the Plone root folder. \'\n                    u\'Plone client must have write access to directory.\',\n        default=u"files_folder")\n']], ['Plone - Override Zope Schema fields'], 7, 0], [(14601544, 1), [['Then, create the settings adapter that is used to store and retrieve the settings of the schema::'], ['Then, register your adapter::']], [[' from collective.documentviewer.settings import Base\nclass CustomSettings(Base):\n    implements(IEnhancedDocumentViewerSchema)\n    use_interface = IEnhancedDocumentViewerSchema\n']], ['Plone - Override Zope Schema fields'], 7, 0], [(14601544, 2), [['Then, register your adapter::'], ['Then, create a form using your custom schema::']], [[' <adapter \n    for="Products.CMFPlone.interfaces.IPloneSiteRoot"\n    provides="my.product.interfaces.IEnhancedDocumentViewerSchema"\n    factory=".somewhere.CustomSettings" />\n']], ['Plone - Override Zope Schema fields'], 7, 0], [(14601544, 3), [['Then, create a form using your custom schema::'], ['Then, create a customization layer for your product, extending the documentviewer layer. This will require 2 steps. First, add the layer interface::']], [[' from z3c.form import field\nfrom plone.app.z3cform.layout import wrap_form\nfrom collective.documentviewer.views import GlobalSettingsForm\nclass CustomGlobalSettingsForm(GlobalSettingsForm):\n    fields = field.Fields(IEnhancedDocumentViewerSchema)\nCustomGlobalSettingsFormView = wrap_form(CustomGlobalSettingsForm)\n']], ['Plone - Override Zope Schema fields'], 7, 0], [(14601544, 4), [['Then, create a customization layer for your product, extending the documentviewer layer. This will require 2 steps. First, add the layer interface::'], ['And register your layer with generic setup. Add the the xml file, browserlayer.xml, to your profile with the following contents(make sure to reinstall the product so the layer gets registered)::']], [[' from collective.documentviewer.interfaces import ILayer as IDocumentViewerLayer\nclass ICustomLayer(IDocumentViewerLayer):\n    """\n    custom layer class\n    """\n']], ['Plone - Override Zope Schema fields'], 7, 0], [(14601544, 5), [['And register your layer with generic setup. Add the the xml file, browserlayer.xml, to your profile with the following contents(make sure to reinstall the product so the layer gets registered)::'], ['Finally, override the global settings view with your custom form just for the layer you have registered for your product::']], [[' <?xml version="1.0"?>\n<layers name="" meta_type="ComponentRegistry">\n    <layer name="my.product" \n           interface="my.product.interfaces.ICustomLayer" />\n</layers>\n']], ['Plone - Override Zope Schema fields'], 7, 0], [(14601544, 6), [['Finally, override the global settings view with your custom form just for the layer you have registered for your product::'], ['Wow, that was way too difficult.']], [[' <browser:page\n    name="global-documentviewer-settings"\n    for="Products.CMFPlone.interfaces.IPloneSiteRoot"\n    class=".somewhere.CustomGlobalSettingsFormView"\n    layer=".interfaces.ICustomLayer"\n    permission="cmf.ManagePortal" />\n']], ['Plone - Override Zope Schema fields'], 7, 0], [(14622698, 0), [['All I wanted is to add  ReST strikethrough  in my sphinx doc. Here is how I did it:'], ['In  theme/theme.conf :']], [[' $ cd my-sphinx-dir\n$ mkdir -p theme/static\n$ touch theme/theme.conf\n$ touch theme/static/style.css\n']], ['Customize sphinxdoc theme'], 6, 0], [(14622698, 1), [['In  theme/theme.conf :'], ['In  theme/static/style.css :']], [[' [theme]\ninherit = default\nstylesheet = style.css\npygments_style = pygments.css\n']], ['Customize sphinxdoc theme'], 6, 0], [(14622698, 2), [['In  theme/static/style.css :'], ['Then, in your conf.py:']], [[' @import url("default.css"); /* make sure to sync this with the base theme\'s css filename */\n\n.strike {\n    text-decoration: line-through;\n}\n']], ['Customize sphinxdoc theme'], 6, 0], [(14622698, 3), [['Then, in your conf.py:'], ['(Optional) In global.rst:']], [[" html_theme = 'theme' # use the theme in subdir 'theme'\nhtml_theme_path = ['.'] # make sphinx search for themes in current dir\n"]], ['Customize sphinxdoc theme'], 6, 0], [(14622698, 4), [['(Optional) In global.rst:'], ['and in a example.rst:']], [[' .. role:: strike\n   :class: strike\n']], ['Customize sphinxdoc theme'], 6, 0], [(14622698, 5), [['and in a example.rst:'], ['-10000']], [[' .. include:: global.rst\n\n:strike:`This looks like it is outdated.`\n']], ['Customize sphinxdoc theme'], 6, 0], [(14677341, 0), [['I ended up using command line arguments for the author scraper:'], ['Then, I added the duplicates pipeline outlined in the  Scrapy documentation :']], [[" class AuthorSpider(BaseSpider):\n    ...\n\n    def __init__(self, articles):\n        self.start_urls = []\n\n        for line in articles:\n            article = json.loads(line)\n            self.start_urls.append(data['author_url'])\n"]], ['Writing to multiple files with Scrapy'], 3, 0], [(14677341, 1), [['Then, I added the duplicates pipeline outlined in the  Scrapy documentation :'], ['Finally, I passed the article JSON lines file into the command:']], [[' from scrapy import signals\nfrom scrapy.exceptions import DropItem\n\nclass DuplicatesPipeline(object):\n    def __init__(self):\n        self.ids_seen = set()\n\n    def process_item(self, item, spider):\n        if item[\'id\'] in self.ids_seen:\n            raise DropItem("Duplicate item found: %s" % item)\n        else:\n            self.ids_seen.add(item[\'id\'])\n            return item\n']], ['Writing to multiple files with Scrapy'], 3, 0], [(14677341, 2), [['Finally, I passed the article JSON lines file into the command:'], ["It's not a great solution, but it works."]], [[' $ scrapy crawl authors -o authors.json -a articles=articles.json\n']], ['Writing to multiple files with Scrapy'], 3, 0], [(14686212, 0), [['Use the  itertools.groupby()  tool :'], ['This does rely on the rows being sorted already. If your rows alternate between first letters:']], [[" from itertools import groupby\n\nfor letter, rows in groupby(cur, key=lambda r: r[0][0]):\n    print ' '.join([r[0] for r in rows])\n"]], ['SQLite Python printing in rows?'], 4, 1], [(14686212, 1), [['This does rely on the rows being sorted already. If your rows alternate between first letters:'], ["it'll print those as separate groups:"]], [[' A1\nA2\nB1\nB2\nA3\nA4\n']], ['SQLite Python printing in rows?'], 4, 0], [(14686212, 2), [["it'll print those as separate groups:"], ['This is what I see when I create a test db:']], [[' A1 A2\nB1 B2\nA3 A4\n']], ['SQLite Python printing in rows?'], 4, 0], [(14686212, 3), [['This is what I see when I create a test db:'], ['-10000']], [[' >>> cur.execute("SELECT * FROM seats ORDER BY code")\n<sqlite3.Cursor object at 0x10b1a8730>\n>>> for letter, rows in groupby(cur, key=lambda r: r[0][0]):\n...     print \' \'.join([r[0] for r in rows])\n... \nA1 A2 A3 A4 A5 A6 A7 A8\nB1 B2 B3 B4 B5 B6 B7 B8\nC1 C2 C3 C4 C5 C6 C7 C8\n']], ['SQLite Python printing in rows?'], 4, 0], [(14692029, 0), [['Use  itertools.product() :'], ['or:']], [[' for combo in itertools.product(self.data1, self.data2, self.data3, self.data4):\n    # combo is a tuple of 4 characters.\n']], ['Find all combinations of letters, selecting each letter from a different key in a dictionary'], 3, 1], [(14692029, 1), [['or:'], ['Demo:']], [[' for combo in itertools.product(*[d[k] for k in sorted(d.keys())]):\n    # combo is a tuple of 4 characters.\n']], ['Find all combinations of letters, selecting each letter from a different key in a dictionary'], 3, 1], [(14692029, 2), [['Demo:'], ['-10000']], [[" >>> import itertools                                                                                                                >>> d = {'1': ['a', 'd', 'e', 'l', 's'], '2': ['s', 'i', 'r', 't', 'n'], '3': ['b', 'o', 'e', 'm', 'k'], '4': ['f', 'y', 'u', 'n', 'g'] }\n>>> for combo in itertools.product(*[d[k] for k in sorted(d.keys())]):\n...     print ''.join(combo)\n... \nasbf\nasby\nasbu\nasbn\nasbg\nasof\nasoy\nasou\nason\nasog\nasef\n\n...\n\nsnkf\nsnky\nsnku\nsnkn\nsnkg\n"]], ['Find all combinations of letters, selecting each letter from a different key in a dictionary'], 3, 1], [(14710221, 0), [['You can define  custom dashes :'], ['@Achim noted you can also specify the  dashes  parameter:']], [[" import matplotlib.pyplot as plt\n\nline, = plt.plot([1,5,2,4], '-')\nline.set_dashes([8, 4, 2, 4, 2, 4]) \nplt.show()\n"]], ['python matplotlib dash-dot-dot - how to?'], 2, 1], [(14710221, 1), [['@Achim noted you can also specify the  dashes  parameter:'], ['produces the same result shown above.']], [[" plt.plot([1,5,2,4], '-', dashes=[8, 4, 2, 4, 2, 4])\nplt.show()\n"]], ['python matplotlib dash-dot-dot - how to?'], 2, 1], [(14711669, 0), [['Python comes with batteries included! If you need to read csv files, just use the  csv module :'], ['Note that this creates a list of lists, if you want tuples for some reason, then']], [[' import sys, csv\n\nwith open(sys.argv[1]) as f:\n    lst = list(csv.reader(f))\n']], ['Create list of tuples (in a more elegant way)'], 2, 1], [(14711669, 1), [['Note that this creates a list of lists, if you want tuples for some reason, then'], ['-10000']], [[' with open(sys.argv[1]) as f:\n    lst = [tuple(row) for row in csv.reader(f)]\n']], ['Create list of tuples (in a more elegant way)'], 2, 1], [(14720912, 0), [['The regex solution (to me) seems like it would be pretty easy:'], ['example:']], [[" import re\ndef split_string(source,separators):\n    return re.split('[{0}]'.format(re.escape(separators)),source)\n"]], ['Splitting Strings in Python with Separator variable'], 6, 1], [(14720912, 1), [['example:'], ['An alternative (which I think I prefer), where you could have multi-character separators is:']], [[' >>> import re\n>>> def split_string(source,separators):\n...     return re.split(\'[{0}]\'.format(re.escape(separators)),source)\n... \n>>> split_string("the;foo: went to the store",\':;\')\n[\'the\', \'foo\', \' went to the store\']\n']], ['Splitting Strings in Python with Separator variable'], 6, 1], [(14720912, 2), [['An alternative (which I think I prefer), where you could have multi-character separators is:'], ['In this case, the multi-character separators  things get passed in as some sort of non-string iterable (e.g. a tuple or a list), but single character separators can still be passed in as a single string.']], [[" def split_string(source,separators):\n    return re.split('|'.join(re.escape(x) for x in separators),source)\n"]], ['Splitting Strings in Python with Separator variable'], 6, 1], [(14720912, 3), [['In this case, the multi-character separators  things get passed in as some sort of non-string iterable (e.g. a tuple or a list), but single character separators can still be passed in as a single string.'], ['-10000']], [[' >>> def split_string(source,separators):\n...     return re.split(\'|\'.join(re.escape(x) for x in separators),source)\n... \n>>> split_string("the;foo: went to the store",\':;\')\n[\'the\', \'foo\', \' went to the store\']\n>>> split_string("the;foo: went to the store",[\'foo\',\'st\'])\n[\'the;\', \': went to the \', \'ore\']\n']], ['Splitting Strings in Python with Separator variable'], 6, 1], [(14720912, 4), [['-10000'], ['which gives:']], [[" def split_string(source,separators):\n    return re.split('(?:'+'|'.join(re.escape(x) for x in separators)+')+',source)\n"]], ['Splitting Strings in Python with Separator variable'], 6, 1], [(14720912, 5), [['which gives:'], ['-10000']], [[' >>> split_string("Before the rain ... there was lightning and thunder.", " .")\n[\'Before\', \'the\', \'rain\', \'there\', \'was\', \'lightning\', \'and\', \'thunder\', \'\']\n']], ['Splitting Strings in Python with Separator variable'], 6, 0], [(14783438, 0), [['Not tested but the filter should be something like:'], ['To be used as:']], [[" def debug(text):\n  print text\n  return ''\n\nenvironment.filters['debug']=debug\n"]], ['jinja2 print to console or logging'], 2, 1], [(14783438, 1), [['To be used as:'], ['Remember to remove the debug on production code!']], [[' ...<p>Hello world!</p> {{"debug text!"|debug}}...\n']], ['jinja2 print to console or logging'], 2, 0], [(14799223, 1), [['If you don not use JSON, you can use a string to send the list :'], ['-10000']], [[" my_list = ['one', 'two', 'three', 'four']\nself.response.write(','.join(my_list))\n"]], ['Get list from server and print each element surrounded by span tag'], 2, 0], [(14808945, 0), [['PEP8  says explicitly that  isinstance  is the preferred way to check types'], ["And don't even think about"]], [[' Yes: if isinstance(obj, int):\nNo:  if type(obj) is type(1):\n']], ['check if variable is dataframe'], 3, 1], [(14808945, 1), [["And don't even think about"], ['isinstance  handles inheritance (see  Differences between isinstance() and type() in python ). For example, it will tell you if a variable is a string (either  str  or  unicode ), because they derive from  basestring )']], [[' if obj.__class__.__name__ = "MyInheritedClass":\n    expect_problems_some_day()\n']], ['check if variable is dataframe'], 3, 0], [(14808945, 2), [['isinstance  handles inheritance (see  Differences between isinstance() and type() in python ). For example, it will tell you if a variable is a string (either  str  or  unicode ), because they derive from  basestring )'], ['-10000']], [[' if isinstance(obj, basestring):\n    i_am_string(obj)\n']], ['check if variable is dataframe'], 3, 0], [(14812510, 0), [["I'm not sure how or if this would work on windows, but under unix, you could do something like:"], ["The use of global data here is merely for demonstration purposes -- Out in the wild, I'd use a class and pass an instance-method to the signal handler in order to maintain state between calls.  -- e.g., something like:"]], [[' import signal\nimport sys\n\ncount = 0\n\ndef handler(signum,frame):\n    global count\n    print "Value of \'i\' is",i\n    count += 1\n    if count >= 2:\n        sys.exit(0)\n\nsignal.signal(signal.SIGINT,handler)\ni = 0\nwhile True:\n    i += 1\n']], ['Python - Print a value without intterupting a loop/function'], 4, 1], [(14812510, 1), [["The use of global data here is merely for demonstration purposes -- Out in the wild, I'd use a class and pass an instance-method to the signal handler in order to maintain state between calls.  -- e.g., something like:"], ['And then you can just re-bind  self.retval  whenever you enter/exit your function:']], [[' import signal\n\nclass Reporter(object):\n    def __init__(self):\n        self.retval = []\n\n    def handler(self,signum,frame):\n        print self.retval\n\nr = Reporter()\nsignal.signal(signal.SIGINT,r.handler)\n']], ['Python - Print a value without intterupting a loop/function'], 4, 0], [(14815365, 0), [['scipy.stats.spearmanr  will take care of computing the ranks for you, you simply have to give it the data in the correct order:'], ['If you have the ranked data, you can call  scipy.stats.pearsonr  on it to get the same result. And as the examples below show, either of the ways you have tried will work, although I think  [1, 2.5, 2.5]  is more common. Also, scipy uses zero-based indexing, so the ranks internally used will be more like  [0, 1.5, 1.5] :']], [[' >>> scipy.stats.spearmanr([0.3, 0.2, 0.2], [0.5, 0.6, 0.4])\n(0.0, 1.0)\n']], ['Spearman rank correlation in Python with ties'], 2, 1], [(14815365, 1), [['If you have the ranked data, you can call  scipy.stats.pearsonr  on it to get the same result. And as the examples below show, either of the ways you have tried will work, although I think  [1, 2.5, 2.5]  is more common. Also, scipy uses zero-based indexing, so the ranks internally used will be more like  [0, 1.5, 1.5] :'], ['-10000']], [[' >>> scipy.stats.pearsonr([1, 2, 2], [2, 1, 3])\n(0.0, 1.0)\n>>> scipy.stats.pearsonr([1, 2.5, 2.5], [2, 1, 3])\n(0.0, 1.0)\n']], ['Spearman rank correlation in Python with ties'], 2, 1], [(14837231, 0), [['Here is a way:'], ['I had to group the  ROOT  nodes, but it seems to be working:']], [[" >>> from collections import defaultdict\n>>> def  combine(item):\n    # Easy return if not a list: element itself\n    if type(item) != type([]):\n        return item\n    # else call recursion\n    first_ret = [(i.items()[0][0], combine(i.items()[0][1])) for i in item]\n\n    # Here we group by same keys if any ('ROOT', for instance)\n    count_keys = defaultdict(list)\n    for couple in first_ret:\n        count_keys[couple[0]].append(couple[1])\n    return dict((k, v if len(v) > 1 else v[0]) for k, v in count_keys.iteritems())\n"]], ['Converting list of dictionaries to unique list of dictionaries'], 2, 1], [(14837231, 1), [['I had to group the  ROOT  nodes, but it seems to be working:'], ['-10000']], [[" >>> pprint(combine(l))\n{'ROOT': [{'SecondElem': '5.0.0.1',\n           'ThirdElem': '127.3.15.1',\n           'firstElem': 'gc-3/1/0',\n           'function': 'session',\n           'hw': '0.0.0.0',\n           'index': 16,\n           'resources': {'cpu-info': {'cpu-avg-load': 1,\n                                      'cpu-peak-load': 1},\n                         'memory-total': 1,\n                         'memory-used': 2},\n           'sw': '1.50.1.3'},\n          {'SecondElem': '5.0.0.2',\n           'ThirdElem': '127.3.4.1',\n           'firstElem': 'gc-4/1/0',\n           'function': 'stand',\n           'hw': '0.0.0.0',\n           'index': 5,\n           'resources': {'cpu-info': {'cpu-avg-load': 1,\n                                      'cpu-peak-load': 1},\n                         'memory-total': 1,\n                         'memory-used': 2},\n           'sw': '1.50.1.3'}]}\n>>> \n"]], ['Converting list of dictionaries to unique list of dictionaries'], 2, 0], [(14856385, 0), [['A regular expression to match those would be:'], ['Results:']], [[" r'\\(\\s*passengers:\\s*(\\d{1,3}|\\?)\\s+ crew:\\s*(\\d{1,3}|\\?)\\s*\\)'\n"]], ['splitting string in Python (2.7)'], 2, 0], [(14856385, 1), [['Results:'], ['-10000']], [[" >>> import re\n>>> numbers = re.compile(r'\\(\\s*passengers:\\s*(\\d{1,3}|\\?)\\s+ crew:\\s*(\\d{1,3}|\\?)\\s*\\)')\n>>> numbers.search('26   (passengers:22  crew:4)').groups()\n('22', '4')\n>>> numbers.search('32   (passengers:?  crew: ?)').groups()\n('?', '?')\n"]], ['splitting string in Python (2.7)'], 2, 1], [(14873181, 0), [['Using  simple_tag , just set  takes_context=True :'], ['-10000']], [[" @register.simple_tag(takes_context=True)\ndef current_time(context, format_string):\n    timezone = context['timezone']\n    return your_get_current_time_method(timezone, format_string)\n"]], ['Inheriting context variables inside custom template tags'], 3, 1], [(14891190, 0), [['You can use built-in template tags:'], ['or']], [[' {{ lines|linebreaks }}\n']], ['How can display the lines from linux log file in browser'], 2, 1], [(14891190, 1), [['or'], ['-10000']], [[' {{ lines|linebreaksbr }}\n']], ['How can display the lines from linux log file in browser'], 2, 1], [(14940338, 0), [['You could use  functools.partial() :'], ['or you could use a  lambda  (an anonymous, in-line function):']], [[' from functools import partial\nmap(partial(add_x_to_input, some_value_for_x), myList)\n']], ['Map function and input function parameters'], 4, 1], [(14940338, 1), [['or you could use a  lambda  (an anonymous, in-line function):'], ['or you could define an explicit new function:']], [[' map(lambda k: add_x_to_input(some_value_for_x, k), myList)\n']], ['Map function and input function parameters'], 4, 1], [(14940338, 2), [['or you could define an explicit new function:'], ['If you are after sheer speed, the  functools.partial()  approach wins that hands-down; it is implemented in C code and avoids an extra Python stack push:']], [[' def wrapping_function(k):\n    return add_x_to_input(some_value_for_x, k)\n\nmap(wrapping_function, myList)\n']], ['Map function and input function parameters'], 4, 1], [(14940338, 3), [['If you are after sheer speed, the  functools.partial()  approach wins that hands-down; it is implemented in C code and avoids an extra Python stack push:'], ['-10000']], [[" >>> import timeit\n>>> L = range(10)\n>>> def foo(a, b): pass\n... \n>>> def p(b): return foo(1, b)\n... \n>>> timeit.timeit('map(p, L)', 'from __main__ import foo, L; from functools import partial; p = partial(foo, 1)')\n3.0008959770202637\n>>> timeit.timeit('map(p, L)', 'from __main__ import foo, L; p = lambda b: foo(1, b)')\n3.8707590103149414\n>>> timeit.timeit('map(p, L)', 'from __main__ import foo, L, p')\n3.9136409759521484\n"]], ['Map function and input function parameters'], 4, 0], [(14972601, 0), [['You can use IN clause. '], ['From django soruce code of DateField:']], [[' Sample.objects.filter(date__month=month).exclude(date__day__in = weekends)\n']], ['Exclude weekends in python django query set'], 2, 1], [(14972601, 1), [['From django soruce code of DateField:'], ['So ideally  __day  should work. Can you also try to change your field name from  date  to something like  created_date  to avoid namespace clashes?']], [[' def get_prep_lookup(self, lookup_type, value):\n    # For "__month", "__day", and "__week_day" lookups, convert the value\n    # to an int so the database backend always sees a consistent type.\n    if lookup_type in (\'month\', \'day\', \'week_day\'):\n        return int(value)\n']], ['Exclude weekends in python django query set'], 2, 1], [(15009180, 0), [['I suppose you could use:'], ['Or, if you only want 1 key:']], [[" for eachitem in dicta:\n    for k in ['NAME','STATE','COUNTRY','REGION','LNAME']:\n        del eachitem[k]\n"]], ['deleting element from python dictionary'], 3, 1], [(15009180, 1), [['Or, if you only want 1 key:'], ['This does everything in place which I assume you want -- Otherwise, you can do it out of place simply by:']], [[" for eachitem in dicta:\n    salary = eachitem['SALARY']\n    eachitem.clear()\n    eachitem['SALARY'] = salary\n"]], ['deleting element from python dictionary'], 3, 1], [(15009180, 2), [['This does everything in place which I assume you want -- Otherwise, you can do it out of place simply by:'], ['-10000']], [[" eachitem = {'SALARY':eachitem['SALARY']}\n"]], ['deleting element from python dictionary'], 3, 1], [(15014326, 0), [['-10000'], ['Will give you:']], [[' def options(opt):\n    opt.load(\'compiler_c\')\n    opt.load(\'compiler_cxx\')\n\ndef configure(cfg):\n    cfg.load(\'compiler_c\')\n    cfg.load(\'compiler_cxx\')\n\ndef build(bld):\n    print "Compiler is CC_NAME  %s  CC  %s"%(bld.env.CC_NAME,bld.env.CC)\n    print "Compiler is CXX_NAME %s  CXX %s"%(bld.env.CXX_NAME,bld.env.CXX)\n']], ['How to determine tools chosen by waf?'], 2, 1], [(15014326, 1), [['Will give you:'], ['-10000']], [[" D:\\temp>waf.bat configure build --check-c-compiler=gcc --check-cxx-compiler=g++\nSetting top to                           : D:\\temp\nSetting out to                           : D:\\temp\\build\nChecking for 'gcc' (c compiler)          : c:\\tools\\gcc\\bin\\gcc.exe\nChecking for 'g++' (c++ compiler)        : c:\\tools\\gcc\\bin\\g++.exe\n'configure' finished successfully (0.191s)\nWaf: Entering directory `D:\\temp\\build'\nCompiler is CC_NAME  gcc  CC  ['c:\\\\tools\\\\gcc\\\\bin\\\\gcc.exe']\nCompiler is CXX_NAME gcc  CXX ['c:\\\\tools\\\\gcc\\\\bin\\\\g++.exe']\nWaf: Leaving directory `D:\\temp\\build'\n'build' finished successfully (0.008s)\n"]], ['How to determine tools chosen by waf?'], 2, 0], [(15062205, 0), [['Below a numpy-based implementation for any dimensionnality (ndim = 2 or more) :'], ['So that :']], [[' def get_nans_blocks_length(a):\n    """\n    Returns 1D length of np.nan s block in sequence depth wise (last axis).\n    """\n    nan_mask = np.isnan(a)\n    start_nans_mask = np.concatenate((np.resize(nan_mask[...,0],a.shape[:-1]+(1,)),\n                                 np.logical_and(np.logical_not(nan_mask[...,:-1]), nan_mask[...,1:])\n                                 ), axis=a.ndim-1)\n    stop_nans_mask = np.concatenate((np.logical_and(nan_mask[...,:-1], np.logical_not(nan_mask[...,1:])),\n                                np.resize(nan_mask[...,-1], a.shape[:-1]+(1,))\n                                ), axis=a.ndim-1)\n\n    start_idxs = np.where(start_nans_mask)\n    stop_idxs = np.where(stop_nans_mask)\n    return stop_idxs[-1] - start_idxs[-1] + 1\n']], ['Finding start and stops of consecutive values block in Python/Numpy/Pandas'], 3, 0], [(15062205, 1), [['So that :'], ['And :']], [[' a = np.array([\n        [1, np.nan, np.nan, np.nan],\n        [np.nan, 1, np.nan, 2], \n        [np.nan, np.nan, np.nan, np.nan]\n    ])\nget_nans_blocks_length(a)\narray([3, 1, 1, 4], dtype=int64)\n']], ['Finding start and stops of consecutive values block in Python/Numpy/Pandas'], 3, 0], [(15062205, 2), [['And :'], ['-10000']], [[' a = np.array([\n        [[1, np.nan], [np.nan, np.nan]],\n        [[np.nan, 1], [np.nan, 2]], \n        [[np.nan, np.nan], [np.nan, np.nan]]\n    ])\nget_nans_blocks_length(a)\narray([1, 2, 1, 1, 2, 2], dtype=int64)\n']], ['Finding start and stops of consecutive values block in Python/Numpy/Pandas'], 3, 0], [(15066913, 0), [['Use an  eventFilter :'], ['And in your window:']], [[" class Filter(QtCore.QObject):\n    def eventFilter(self, widget, event):\n        # FocusOut event\n        if event.type() == QtCore.QEvent.FocusOut:\n            # do custom stuff\n            print 'focus out'\n            # return False so that the widget will also handle the event\n            # otherwise it won't focus out\n            return False\n        else:\n            # we don't care about other events\n            return False\n"]], ['How to connect QLineEdit focusOutEvent'], 2, 0], [(15066913, 1), [['And in your window:'], ['-10000']], [[' # ...\nself._filter = Filter()\n# adjust for your QLineEdit\nself.ui.lineEdit.installEventFilter(self._filter)\n']], ['How to connect QLineEdit focusOutEvent'], 2, 0], [(15089310, 0), [['There are definitely more numpythonic ways of doing things. One possibility could be something like this:'], ["If you are concatenating only a few ranges, then probably Mr. E's pure python solution is your best choice, but if you have even as few as a hundred ranges to concatenate, this stars being noticeably faster. For comparison I have used this two functions extracted from the other answers:"]], [[' import numpy as np\nfrom numpy.lib.stride_tricks import as_strided\n\ndef concatenated_ranges(ranges_list) :\n    ranges_list = np.array(ranges_list, copy=False)\n    base_range = np.arange(ranges_list.max())\n    base_range =  as_strided(base_range,\n                             shape=ranges_list.shape + base_range.shape,\n                             strides=(0,) + base_range.strides)\n    return base_range[base_range < ranges_list[:, None]]\n']], ['repeat arange with numpy'], 3, 1], [(15089310, 1), [["If you are concatenating only a few ranges, then probably Mr. E's pure python solution is your best choice, but if you have even as few as a hundred ranges to concatenate, this stars being noticeably faster. For comparison I have used this two functions extracted from the other answers:"], ['And here are some timings:']], [[' def junuxx(a) :\n    b = np.array([], dtype=np.uint8)\n    for x in a:\n        b = np.append(b, np.arange(x))\n    return b\n\ndef mr_e(a) :\n    return reduce(lambda x, y: x + range(y), a, [])\n']], ['repeat arange with numpy'], 3, 1], [(15089310, 2), [['And here are some timings:'], ['-10000']], [[" In [2]: a = [2, 1, 4, 0 ,2] # the OP's original example\n\nIn [3]: concatenated_ranges(a) # show it works!\nOut[3]: array([0, 1, 0, 0, 1, 2, 3, 0, 1])\n\nIn [4]: %timeit concatenated_ranges(a)\n10000 loops, best of 3: 31.6 us per loop\n\nIn [5]: %timeit junuxx(a)\n10000 loops, best of 3: 34 us per loop\n\nIn [6]: %timeit mr_e(a)\n100000 loops, best of 3: 2.58 us per loop\n\nIn [7]: a = np.random.randint(1, 10, size=(10,))\n\nIn [8]: %timeit concatenated_ranges(a)\n10000 loops, best of 3: 27.1 us per loop\n\nIn [9]: %timeit junuxx(a)\n10000 loops, best of 3: 79.8 us per loop\n\nIn [10]: %timeit mr_e(a)\n100000 loops, best of 3: 7.82 us per loop\n\nIn [11]: a = np.random.randint(1, 10, size=(100,))\n\nIn [12]: %timeit concatenated_ranges(a)\n10000 loops, best of 3: 57.4 us per loop\n\nIn [13]: %timeit junuxx(a)\n1000 loops, best of 3: 756 us per loop\n\nIn [14]: %timeit mr_e(a)\n10000 loops, best of 3: 149 us per loop\n\nIn [15]: a = np.random.randint(1, 10, size=(1000,))\n\nIn [16]: %timeit concatenated_ranges(a)\n1000 loops, best of 3: 358 us per loop\n\nIn [17]: %timeit junuxx(a)\n100 loops, best of 3: 9.38 ms per loop\n\nIn [18]: %timeit mr_e(a)\n100 loops, best of 3: 8.93 ms per loop\n"]], ['repeat arange with numpy'], 3, 0], [(15104415, 0), [['The  stdout=subprocess.PIPE  prevents the subprocess from printing to stdout and instead passes it to  result  using  communicate  similar to how in bash'], ['will print progress but ']], [[' sshpass -[args] rsync [source] [dest]\n']], ['How to print progress from this code as the subprocess is running?'], 3, 0], [(15104415, 1), [['will print progress but '], ['What you want is to  tee  the  stdout . look  here . Based on those answers you could do something like:']], [[' sshpass -[args] rsync [source] [dest] | sort\n']], ['How to print progress from this code as the subprocess is running?'], 3, 0], [(15104415, 2), [['What you want is to  tee  the  stdout . look  here . Based on those answers you could do something like:'], ['-10000']], [[" # Caution! untested code\nresult = []\nprocess = subprocess.Popen(['sshpass', '-p', password, 'rsync', '-avz',\n                            '--info=progress2', source12, destination], \n                           stdout=subprocess.PIPE)\nwhile process.poll() is None:\n    line = process.stdout.readline()\n    print line\n    result.append(line)\nprint sort(result)\n"]], ['How to print progress from this code as the subprocess is running?'], 3, 1], [(15109165, 1), [['It will be much easier with the excellent Pandas library ( http://pandas.pydata.org/ )'], ['-10000']], [[' import pandas as pd\nmydata = pd.read_csv(filename)\ntarget = mydata["Label"]  #provided your csv has header row, and the label column is named "Label"\n\n#select all but the last column as data\ndata = mydata.ix[:,:-1]\n']], ['Loading a dataset from file, to use with sklearn'], 2, 1], [(15114761, 0), [['Lets say you read your whole array into memory as an array  data  of shape  (Nx1 * Nx2 * Nx3, 6) .'], ['If, as your, example suggests, the points are generated in lexicographical order, you only need to grab the columns to  f ,  g  and  h  and reshape them:']], [[" data = np.loadtxt('data.txt', dtype=float, delimiter=',')\n"]], ['Converting coordinate tuple information to numpy arrays'], 4, 0], [(15114761, 1), [['If, as your, example suggests, the points are generated in lexicographical order, you only need to grab the columns to  f ,  g  and  h  and reshape them:'], ['If you need to figure out what  Nx1 ,  Nx2  and  Nx3  are, you can use  np.unique :']], [[' f = data[:, 3].reshape(Nx1, Nx2, Nx3)\ng = data[:, 4].reshape(Nx1, Nx2, Nx3)\nh = data[:, 5].reshape(Nx1, Nx2, Nx3)\n']], ['Converting coordinate tuple information to numpy arrays'], 4, 0], [(15114761, 2), [['If you need to figure out what  Nx1 ,  Nx2  and  Nx3  are, you can use  np.unique :'], ['A more robust solution in case the order of the points is not guaranteed, would be to use  np.unique  to extract indices to the grid values:']], [[' Nx1 = np.unique(data[:, 0]).shape[0]\nNx2 = np.unique(data[:, 1]).shape[0]\nNx3 = np.unique(data[:, 2]).shape[0]\n']], ['Converting coordinate tuple information to numpy arrays'], 4, 0], [(15133537, 1), [['\xa0'], ['In python 3  pydoc.render_doc  accepts a  renderer :']], [[' >>> help(pydoc.plain)\nHelp on function plain in module pydoc:\n\nplain(text)\n    Remove boldface formatting from text.\n']], ['pydoc.render_doc() adds characters - how to avoid that?'], 3, 0], [(15148202, 0), [['You could use two lists, one for evens and one for odds:'], ['or you could end with:']], [[' evens = []\nodds = []\nout = [evens,odds]\nfor elem in numbers:\n    out[elem%2].append(elem)\n\nprint evens\n']], ['Even number check without: if'], 2, 1], [(15183718, 0), [['You can call  One.get()  directly if you turn it into a static method:'], ['Without the  @staticmethod , you need an instance of  One  in order to be able to call  get() :']], [[' class One:\n    @staticmethod\n    def get():\n        return 1\n\nclass Two:\n    def __init__(self):\n        val = One.get()\n']], ['Python: How to call a class in the same file'], 2, 1], [(15183718, 1), [['Without the  @staticmethod , you need an instance of  One  in order to be able to call  get() :'], ['-10000']], [[' class One:\n    def get(self):\n        return 1\n\nclass Two:\n    def __init__(self):\n        one = One()\n        val = one.get()\n']], ['Python: How to call a class in the same file'], 2, 1], [(15211991, 0), [['This code is a working translation. It certainly can be improved and your comments are welcome but it works fine and does exactly what the Python code did.'], ['And the socket part :']], [[' NSString * src = @"X.X.X.X";\nNSString * mac = @"XX-XX-XX-XX-XX-XX";\n\n\nconst unsigned char byte64[] = {0x64};\nconst unsigned char byte00[] = {0x00};\n\nNSString * srcString = [src base64EncodedString];\nint srcDataLength = [srcString length];\nchar* srcDataLengthAsByte = (char*) &srcDataLength;\n\nNSString * macString = [mac base64EncodedString];\nint macDataLength = [macString length];\nchar* macDataLengthAsByte = (char*) &macDataLength;\n\nNSString * remoteString = [remote base64EncodedString];\nint remoteDataLength = [remoteString length];\nchar* remoteDataLengthAsByte = (char*) &remoteDataLength;\n\nNSString * appString = [app base64EncodedString];\nint appDataLength = [appString length];\nchar* appDataLengthAsByte = (char*) &appDataLength;\n\nNSMutableData * msgData = [NSMutableData data];\n[msgData appendBytes:byte64 length:1];\n[msgData appendBytes:byte00 length:1];\n[msgData appendBytes:srcDataLengthAsByte length:1];\n[msgData appendBytes:byte00 length:1];\n[msgData appendData:[srcString dataUsingEncoding:NSASCIIStringEncoding]];\n[msgData appendBytes:macDataLengthAsByte length:1];\n[msgData appendBytes:byte00 length:1];\n[msgData appendData:[macString dataUsingEncoding:NSASCIIStringEncoding]];\n[msgData appendBytes:remoteDataLengthAsByte length:1];\n[msgData appendBytes:byte00 length:1];\n[msgData appendData:[remoteString dataUsingEncoding:NSASCIIStringEncoding]];\nint msgDataLength = [msgData length];\nchar* msgDataLengthAsByte = (char*) &msgDataLength;\n\nNSMutableData * packet = [NSMutableData data];\n[packet appendBytes:byte00 length:1];\n[packet appendBytes:appDataLengthAsByte length:1];\n[packet appendBytes:byte00 length:1];\n[packet appendData:[appString dataUsingEncoding:NSASCIIStringEncoding]];\n[packet appendBytes:msgDataLengthAsByte length:1];\n[packet appendBytes:byte00 length:1];\n[packet appendData:msgData];\n[self send:packet];\n']], ['Socket code from python to Objective C'], 3, 0], [(15211991, 1), [['And the socket part :'], ['And the include with base64 from :   https://github.com/nicklockwood/Base64']], [[' - (BOOL)connect\n{\n    struct sockaddr_in addr;\n    sockfd = socket( AF_INET, SOCK_STREAM, 0 );\n    addr.sin_family = AF_INET;\n    addr.sin_addr.s_addr = inet_addr([TV_IP UTF8String]);\n    addr.sin_port = htons(TV_PORT);\n    return connect(sockfd, (struct sockaddr*)&addr, sizeof(addr))==0;\n}\n\n- (long)send:(NSData*)data\n{\n    long sent = send(sockfd, [data bytes], [data length], 0);\n\n    VADebugLog(@"sent data:(%ld bytes) = [%@]",sent,[data description]);\n\n    return sent;\n}\n\n-(void)close\n{\n    close(sockfd);\n}\n']], ['Socket code from python to Objective C'], 3, 0], [(15211991, 2), [['And the include with base64 from :   https://github.com/nicklockwood/Base64'], ['-10000']], [[' #include <netinet/in.h>\n#include <arpa/inet.h>\n#import "Base64.h"\n']], ['Socket code from python to Objective C'], 3, 0], [(15238389, 0), [['Have you tried something like this?:'], ['If you need to edit diff number of lines you can update code above this way:']], [[" exp = 20 # the line where text need to be added or exp that calculates it for ex %2\n\nwith open(filename, 'r') as f:\n    lines = f.readlines()\n\nwith open(filename, 'w') as f:\n    for i,line in enumerate(lines):\n        if i == exp:\n            f.write('------')\n        f.write(line)\n"]], ['How to add a string to a specific line'], 2, 1], [(15238389, 1), [['If you need to edit diff number of lines you can update code above this way:'], ['-10000']], [[" def update_file(filename, ln):\n    with open(filename, 'r') as f:\n        lines = f.readlines()\n\n    with open(filename, 'w') as f:\n        for idx,line in enumerate(lines):\n            (idx in ln and f.write('------'))\n            f.write(line)\n"]], ['How to add a string to a specific line'], 2, 1], [(15283478, 1), [['And in the template:'], ['-10000']], [[' {% for key, values in result.items() %}\n    <span>{{key}}</span>\n    <ul>\n    {% for item in values %}\n        <li>{{item}}</li>\n    {% endfor %}\n    </ul>\n{% endfor %}\n']], ['having category headings for list dictionaries in python/django'], 2, 0], [(15304076, 0), [['In echo.py:'], ['Then in your terminal call it like this:']], [[' import sys\nprint sys.stdin.read()\n']], ['Making use of piped data in python'], 2, 1], [(15304076, 1), [['Then in your terminal call it like this:'], ['This should echo the contents of test.txt on your terminal.']], [[' python echo.py < test.txt\n']], ['Making use of piped data in python'], 2, 0], [(15312953, 0), [['Try using  os.listdir , os.path.join  and  os.path.isfile . \nIn long form (with for loops),'], ['Code, with list-comprehensions is']], [[" import os\npath = 'C:/'\nfiles = []\nfor i in os.listdir(path):\n    if os.path.isfile(os.path.join(path,i)) and '001_MN_DX' in i:\n        files.append(i)\n"]], ['Choose a file starting with a given string'], 2, 1], [(15312953, 1), [['Code, with list-comprehensions is'], ['Check  here  for the long explanation...']], [[" import os\npath = 'C:/'\nfiles = [i for i in os.listdir(path) if os.path.isfile(os.path.join(path,i)) and \\\n         '001_MN_DX' in i]\n"]], ['Choose a file starting with a given string'], 2, 1], [(15326069, 0), [['As a quick example:'], ['E.g.']], [[' import matplotlib.pyplot as plt\nfrom matplotlib.patches import Wedge\n\ndef main():\n    fig, ax = plt.subplots()\n    dual_half_circle((0.5, 0.5), radius=0.3, angle=90, ax=ax)\n    ax.axis(\'equal\')\n    plt.show()\n\ndef dual_half_circle(center, radius, angle=0, ax=None, colors=(\'w\',\'k\'),\n                     **kwargs):\n    """\n    Add two half circles to the axes *ax* (or the current axes) with the \n    specified facecolors *colors* rotated at *angle* (in degrees).\n    """\n    if ax is None:\n        ax = plt.gca()\n    theta1, theta2 = angle, angle + 180\n    w1 = Wedge(center, radius, theta1, theta2, fc=colors[0], **kwargs)\n    w2 = Wedge(center, radius, theta2, theta1, fc=colors[1], **kwargs)\n    for wedge in [w1, w2]:\n        ax.add_artist(wedge)\n    return [w1, w2]\n\nmain()\n']], ['Matplotlib half black and half white circle'], 2, 1], [(15326069, 1), [['E.g.'], ['However, this will make the "circularity" of the circle depend on aspect ratio of the outline of the axes. (You can get around that in a couple of ways, but it gets more complex. Let me know if that\'s what you had in mind and I can show a more elaborate example.) I also may have misunderstood what you meant "at the origin".']], [[' import matplotlib.pyplot as plt\nfrom matplotlib.patches import Wedge\n\ndef main():\n    fig, ax = plt.subplots()\n    dual_half_circle(radius=0.1, angle=90, ax=ax)\n    ax.axis(\'equal\')\n    plt.show()\n\ndef dual_half_circle(radius, angle=0, ax=None, colors=(\'w\',\'k\'), **kwargs):\n    """\n    Add two half circles to the axes *ax* (or the current axes) at the lower\n    left corner of the axes with the specified facecolors *colors* rotated at\n    *angle* (in degrees).\n    """\n    if ax is None:\n        ax = plt.gca()\n    kwargs.update(transform=ax.transAxes, clip_on=False)\n    center = (0, 0)\n    theta1, theta2 = angle, angle + 180\n    w1 = Wedge(center, radius, theta1, theta2, fc=colors[0], **kwargs)\n    w2 = Wedge(center, radius, theta2, theta1, fc=colors[1], **kwargs)\n    for wedge in [w1, w2]:\n        ax.add_artist(wedge)\n    return [w1, w2]\n\nmain()\n']], ['Matplotlib half black and half white circle'], 2, 1], [(15329797, 0), [['Sounds like you are looking for  zip ? It takes a pair of lists and turns it into a list of pairs.'], ['-- Edit. Requirements changed:']], [[' [\n    [my_operation(x,y) for x,y in zip(xs, ys)]\n    for xs, ys in zip(a, b)\n]\n']], ['list comprehension on multiple lists of lists'], 2, 1], [(15329797, 1), [['-- Edit. Requirements changed:'], ['-10000']], [[' [\n    [[regex(p, s) for p in patterns] for s in strings]\n    for strings, patterns in zip(a, b)\n]\n']], ['list comprehension on multiple lists of lists'], 2, 1], [(15340713, 0), [['You can use a callback function inside the sub part of the regex:'], ['Prints:']], [[' import re\n\ndef callback(match):\n    return match.group(0).replace(\'17\', \'19\')\n\ns = "[ 17 plane_17 \\ 23 25 17 99 150 248 \\ noname ]"\n\ns = re.compile(r\'\\\\.+?\\\\\').sub(callback, s)\n\nprint s\n']], ['regex/python to find and replace specific number within string'], 2, 1], [(15340713, 1), [['Prints:'], ['-10000']], [[' [ 17 plane_17 \\ 23 25 19 99 150 248 \\ noname ]\n']], ['regex/python to find and replace specific number within string'], 2, 0], [(15353972, 1), [['Then you use this class instead of  QDirModel :'], ['-10000']], [[' model = CheckableDirModel()\ntree = QtGui.QTreeView()\ntree.setModel(model)\n']], ['PyQt4 Local Directory view with option to select folders'], 2, 0], [(15398904, 0), [['Using list comprehensions:'], ['Or without the map:']], [[' >>> [[tuple(map(int, pair)) + (2,) for pair in pairs] for pairs in l]\n[[(100, 200, 2), (300, 400, 2), (500, 600, 2)], [(100, 200, 2)], [(100, 200, 2)]]\n']], ['Iterate over Python list, preserving structure of embedded lists'], 4, 1], [(15398904, 1), [['Or without the map:'], ['-10000']], [[' >>> [[(int(a), int(b), 2) for a, b in pairs] for pairs in l]\n[[(100, 200, 2), (300, 400, 2), (500, 600, 2)], [(100, 200, 2)], [(100, 200, 2)]]\n']], ['Iterate over Python list, preserving structure of embedded lists'], 4, 1], [(15398904, 3), [['That being said, when you have said function, you can then use list comprehensions again, to get your output. Of course with your example  l , this is a bit boring:'], ['-10000']], [[' >>> [[processPair(*pair) for pair in pairs] for pairs in l]\n[[(100, 202, 2), (300, 402, 2), (500, 602, 2)], [(100, 202, 2)], [(100, 202, 2)]]\n']], ['Iterate over Python list, preserving structure of embedded lists'], 4, 0], [(15401415, 0), [['If the possible  [AG]..  should be included in the length requirement you can use:'], ["Or if you don't want to include  [AG]..  in the match you could use lookarounds:"]], [[" r'(?x) (?: [AG].. ATG | ATG G.. )  (?:...){7,}? (?:TAA|TAG|TGA)'\n"]], ['Regex Python findall. Making things nonredundant'], 2, 1], [(15401415, 1), [["Or if you don't want to include  [AG]..  in the match you could use lookarounds:"], ['-10000']], [[" r'(?x) ATG (?: (?<=[AG].. ATG) | (?=G) ) (?:...){8,}? (?:TAA|TAG|TGA)'\n"]], ['Regex Python findall. Making things nonredundant'], 2, 1], [(15418751, 0), [['-10000'], ['-10000']], [[" >>> chained = itertools.chain.from_iterable(sixbit)\n>>> [''.join(bits) for bits in itertools.izip(*[chained]*8)]\n['00001100', '00010101', '00100001']\n"]], ['iterating over list of string and combining string values Python'], 4, 1], [(15418751, 1), [['-10000'], ['Most importantly, the letters are taken from each iterator, but it is in fact 8 instances of the same iterator. And it is consumed by each call. So the first tuple contains the first 8 letters of the chained iterator.']], [[" >>> chained = itertools.chain.from_iterable(sixbit)\n>>> list(chained)\n['0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1']\n"]], ['iterating over list of string and combining string values Python'], 4, 0], [(15418751, 2), [['Most importantly, the letters are taken from each iterator, but it is in fact 8 instances of the same iterator. And it is consumed by each call. So the first tuple contains the first 8 letters of the chained iterator.'], ['At the last step, we join them in list comprehension:']], [[" >>> chained = itertools.chain.from_iterable(sixbit)\n>>> list(itertools.izip(*[chained]*8))\n[('0', '0', '0', '0', '1', '1', '0', '0'), ('0', '0', '0', '1', '0', '1', '0', '1'), ('0', '0', '1', '0', '0', '0', '0', '1')]\n"]], ['iterating over list of string and combining string values Python'], 4, 0], [(15418751, 3), [['At the last step, we join them in list comprehension:'], ['-10000']], [[" >>> chained = itertools.chain.from_iterable(sixbit)\n>>> [''.join(bits) for bits in itertools.izip(*[chained]*8)]\n['00001100', '00010101', '00100001']\n"]], ['iterating over list of string and combining string values Python'], 4, 0], [(15425455, 0), [["The problem is that you can't directly see the nodes for the second level after you insert them. Try this:"], ["By keeping each component's map of subcomponents in  cmap , I can always reach each parent's map to add the next component to it. I tried it with the following test data:"]], [[" conx = sqlite3.connect( 'nameofdatabase.db' )\ncurs = conx.cursor()\ncurs.execute( 'SELECT COMPONENT_ID, LEVEL, COMPONENT_NAME, PARENT ' +\n              'FROM DOMAIN_HIERARCHY' )\nrows = curs.fetchall()\ncmap = {}\nhrcy = None\nfor row in rows:\n    entry = (row[2], {})\n    cmap[row[0]] = entry\n    if row[1] == 1:\n        hrcy = {entry[0]: entry[1]}\n\n# raise if hrcy is None\n\nfor row in rows:\n    item = cmap[row[0]]\n    parent = cmap.get(row[3], None)\n    if parent is not None:\n        parent[1][row[2]] = item[1]\n\nprint hrcy\n"]], ['Insert tree kind of data taken from a database into a python dictionary'], 3, 1], [(15425455, 1), [["By keeping each component's map of subcomponents in  cmap , I can always reach each parent's map to add the next component to it. I tried it with the following test data:"], ['The output was this:']], [[" rows = [(1,1,'A',0),\n        (2,2,'AA',1),\n        (3,2,'AB',1),\n        (4,3,'AAA',2),\n        (5,3,'AAB',2),\n        (6,3,'ABA',3),\n        (7,3,'ABB',3)]       \n"]], ['Insert tree kind of data taken from a database into a python dictionary'], 3, 0], [(15425455, 2), [['The output was this:'], ['-10000']], [[" {'A': {'AA': {'AAA': {}, 'AAB': {}}, 'AB': {'ABA': {}, 'ABB': {}}}}\n"]], ['Insert tree kind of data taken from a database into a python dictionary'], 3, 0], [(15432775, 0), [['-10000'], ['or']], [[" import lxml.html\nfrom lxml.cssselect import CSSSelector\ncontent = result.read()\npage_html = lxml.html.fromstring(content)\n\nelements = page_html.xpath('//*[self::div or self::span]')\n"]], ['lxml findall div and span tags'], 2, 1], [(15432775, 1), [['or'], ['-10000']], [[" sd_selector = CSSSelector('span,div')\nelements = sd_selector(page_html)\n"]], ['lxml findall div and span tags'], 2, 1], [(15456166, 0), [["Your code is fine actually (making sure you don't pass negative times to sleep is still a good idea though):"], ['I personally would make a generator of 60-second-spaced timestamps and use it:']], [[' import time\n\nminute = 60\nnext_time = time.time()\nwhile True:\n    doSomeWork()\n    next_time += minute\n    sleep_time = next_time - time.time()\n    if sleep_time > 0:\n        time.sleep(sleep_time)\n']], ['python periodic looping idiom?'], 2, 1], [(15456166, 1), [['I personally would make a generator of 60-second-spaced timestamps and use it:'], ['-10000']], [[' import time\nimport itertools\n\nminute = 60\n\nfor next_time in itertools.count(time.time() + minute, minute):\n    doSomeWork()\n    sleep_time = next_time - time.time()\n    if sleep_time > 0:\n        time.sleep(sleep_time)\n']], ['python periodic looping idiom?'], 2, 1], [(15459675, 0), [['use  DataFrame.from_dict :'], ['output:']], [[' import pandas as pd\nimport datetime\ntimeseries = {datetime.datetime(2013, 3, 17, 18, 19): {\'t2\': 400, \'t1\': 1000},\n                 datetime.datetime(2013, 3, 17, 18, 20): {\'t2\': 300, \'t1\': 3000}\n                }\nprint pd.DataFrame.from_dict(timeseries, orient="index")\n']], ['How to get python dictionaries into a pandas time series dataframe where key is date object'], 2, 1], [(15459675, 1), [['output:'], ['-10000']], [['                       t2    t1\n2013-03-17 18:19:00  400  1000\n2013-03-17 18:20:00  300  3000\n']], ['How to get python dictionaries into a pandas time series dataframe where key is date object'], 2, 0], [(15462548, 0), [["You almost got it; you just need to not call  bear_room  when you're passing it as an argument:"], ['Conversely, you need to call  stage  as a function:']], [["     elif next == 'exit':\n        exit_game(bear_room)\n"]], ['How do I make a function to accept an argument that is another function?'], 2, 0], [(15462548, 1), [['Conversely, you need to call  stage  as a function:'], ['-10000']], [["     elif con_ext == 'no':\n        stage()\n"]], ['How do I make a function to accept an argument that is another function?'], 2, 0], [(15489749, 0), [["Use a list comprehension over the dict's  items :"], ['\xa0']], [[' [k for k, v in child_parent.items() if v == 0]\n']], ['Create a list of keys given a value in a dictionary'], 2, 1], [(15508970, 0), [["I'm assuming  User  is some custom model that inherits from  EndpointsModel . If not, this will fail. In other words, you've done something like this:"], ['Instead of doing a full-on query, you could do a  simple get .']], [[' from google.appengine.ext import ndb\nfrom endpoints_proto_datastore.ndb import EndpointsModel\n\nclass User(EndpointsModel):\n    email = ndb.StringProperty()\n    ...\n']], ['Query endpoint user by email'], 4, 0], [(15508970, 1), [['Instead of doing a full-on query, you could do a  simple get .'], ['by using the email as the datastore key for each entity, as is done in the  custom alias properties sample . For example:']], [[" from google.appengine.ext import endpoints\n\n@endpoints.api(...)\nclass SomeClass(...):\n\n    @User.method(request_fields=('email',),\n                 path='get_by_mail/{email}',\n                 http_method='GET', name='user.get_by_email')\n    def get_by_email(self, user):\n        if not user.from_datastore:\n            raise endpoints.NotFoundException('User not found.')\n        return user\n"]], ['Query endpoint user by email'], 4, 1], [(15508970, 3), [['-10000'], ['-10000']], [["     @User.method(request_fields=('email',),\n                 path='get_by_mail/{email}',\n                 http_method='GET', name='user.get_by_email')\n    def get_by_email(self, user):\n        query = User.query(User.email == user.email)\n        # We fetch 2 to make sure we have\n        matched_users = query.fetch(2)\n        if len(matched_users == 0):\n            raise endpoints.NotFoundException('User not found.')\n        elif len(matched_users == 2):\n            raise endpoints.BadRequestException('User not unique.')\n        else:\n            return matched_users[0]\n"]], ['Query endpoint user by email'], 4, 1], [(15510367, 0), [['Excerpt from the above:\nLogfile looks like:'], ['regex looks like:']], [[' [1242248375] SERVICE ALERT: myhostname.com;DNS: Recursive;CRITICAL\n']], ['Return All Matching Lines in a Logfile'], 7, 0], [(15510367, 1), [['regex looks like:'], ['I made a short regex to start with your logfile format. Assuming your log from above is saved as log.txt. ']], [[" regexp = re.compile(r'\\[(\\d+)\\] SERVICE NOTIFICATION: (.+)')\n"]], ['Return All Matching Lines in a Logfile'], 7, 0], [(15510367, 2), [['I made a short regex to start with your logfile format. Assuming your log from above is saved as log.txt. '], ['Outpus this for me:']], [[' import re\nregexp = re.compile(r\'\\[(\\d{2}:\\d{2}:\\d{2}\\.xxx\\d{3})\\][\\s]+status[\\s]+XYZ[\\s]+ID:([0-9A-Zx]+)(.+)\')\n\nf = open("log.txt", "r")\nfor line in f.readlines():\n    print line\n    m = re.match(regexp, line)\n    #print m\n    if m:\n        print m.groups()\n']], ['Return All Matching Lines in a Logfile'], 7, 0], [(15510367, 3), [['Outpus this for me:'], ['If you add this to the programm above:']], [[" [13:40:19.xxx021] status    XYZ  ID:22P00935xxx -4  3.92     quote:    0.98/   1.02  avg:   -0.98   -0.16\n\n('13:40:19.xxx021', '22P00935xxx', ' -4  3.92     quote:    0.98/   1.02  avg:   -0.98   -0.16')\n[13:40:19.xxx024] status    XYZ  ID:22C0099xxx0 -2  26.4     quote:   11.60/  11.85  avg:  -13.20    2.70\n\n('13:40:19.xxx024', '22C0099xxx0', ' -2  26.4     quote:   11.60/  11.85  avg:  -13.20    2.70')\n[13:40:19.xxx027] status    XYZ  ID:22P0099xxx0 10  -17.18   quote:    1.86/   1.90  avg:   -1.72    1.42\n\n('13:40:19.xxx027', '22P0099xxx0', ' 10  -17.18   quote:    1.86/   1.90  avg:   -1.72    1.42')\n[13:40:19.xxx029] status    XYZ  ID:22C00995xxx 4   -42.5    quote:    8.20/   8.30  avg:  -10.62   -9.70\n\n('13:40:19.xxx029', '22C00995xxx', ' 4   -42.5    quote:    8.20/   8.30  avg:  -10.62   -9.70')\n[13:40:19.xxx031] status    XYZ  ID:22P00995xxx 2   9.66     quote:    3.30/   3.40  avg:    4.83   16.26\n('13:40:19.xxx031', '22P00995xxx', ' 2   9.66     quote:    3.30/   3.40  avg:    4.83   16.26')\n"]], ['Return All Matching Lines in a Logfile'], 7, 0], [(15510367, 4), [['If you add this to the programm above:'], ['the output is:']], [[' print "ID is : ", m.groups()[1]\n']], ['Return All Matching Lines in a Logfile'], 7, 0], [(15510367, 5), [['the output is:'], ["import re\nregexp = re.compile(r'[(\\d{2}:\\d{2}:\\d{2}.xxx\\d{3})][\\s]+status[\\s]+XYZ[\\s]+ID:([0-9A-Zx]+)(.+)')"]], [[' [13:40:19.xxx021] status    XYZ  ID:22P00935xxx -4  3.92     quote:    0.98/   1.02  avg:   -0.98   -0.16\n\nID is :  22P00935xxx\n\n[13:40:19.xxx024] status    XYZ  ID:22C0099xxx0 -2  26.4     quote:   11.60/  11.85  avg:  -13.20    2.70\n\nID is :  22C0099xxx0\n']], ['Return All Matching Lines in a Logfile'], 7, 0], [(15516876, 0), [['You could use either list comprehension:'], ['or the built-in  filter  function:']], [[' matching_results = [t for t in list_ if t[0] == c_code]\n']], ['How can I get a Tuple from a list in python (3.3)'], 3, 1], [(15516876, 1), [['or the built-in  filter  function:'], ['If you have a list of company codes,  c_codes , you can do']], [[' matching_results = filter(lambda t: t[0]==c_code, list_)\n']], ['How can I get a Tuple from a list in python (3.3)'], 3, 1], [(15516876, 2), [['If you have a list of company codes,  c_codes , you can do'], ['This should be the easiest possible way.']], [[' matching_results = [t for t in list_ if t[0] in c_codes]\n']], ['How can I get a Tuple from a list in python (3.3)'], 3, 1], [(15547217, 0), [['Use a  timedelta(days=1)  offset of the beginning of  this  month:'], ['Demo (on Python 2.4 to be sure):']], [[" import datetime\n\ndef get_start_of_previous_month(dt):\n    '''\n    Return the datetime corresponding to the start of the month\n    before the provided datetime.\n    '''\n    previous = dt.date().replace(day=1) - datetime.timedelta(days=1)\n    return datetime.datetime.combine(previous.replace(day=1), datetime.time.min)\n"]], ['Handling months in python datetimes'], 2, 1], [(15547217, 1), [['Demo (on Python 2.4 to be sure):'], ['-10000']], [[' >>> get_start_of_previous_month(datetime.datetime.now())\ndatetime.datetime(2013, 2, 1, 0, 0)\n>>> get_start_of_previous_month(datetime.datetime(2013, 1, 21, 12, 23))\ndatetime.datetime(2012, 12, 1, 0, 0)\n']], ['Handling months in python datetimes'], 2, 0], [(15580917, 0), [['In a regex, the metacharacters  ^  and  $  mean "start-of-string" and "end-of-string" (respectively); so, rather than seeing  what  matches, and comparing it to the whole string, you can simply require that the regex match the whole string to begin with:'], ["In addition, since you're only using the regex once — you compile it and immediately use it — you can use the convenience method  re.match  to handle that as a single step:"]], [[' import re\ndata = "asdsaq2323-asds"\nif re.compile("^[a-zA-Z0-9*]+$").match(data):\n    print "match"\nelse:\n    print "no match"\n']], ['Python: Data validation using regular expression'], 2, 1], [(15580917, 1), [["In addition, since you're only using the regex once — you compile it and immediately use it — you can use the convenience method  re.match  to handle that as a single step:"], ['-10000']], [[' import re\ndata = "asdsaq2323-asds"\nif re.match("^[a-zA-Z0-9*]+$", data):\n    print "match"\nelse:\n    print "no match"\n']], ['Python: Data validation using regular expression'], 2, 1], [(15620039, 0), [['Here is a trivial example:'], ['Prints:']], [[" import threading, time, random\n\nclass Key(object):\n    results={}\n    def __init__(self,refresh,name):\n        self.refresh=refresh\n        self.name=name\n        self.t0=time.time()\n        self.t=threading.Timer(refresh,self.now_what)\n        self.t.start()\n\n    def now_what(self):\n        s='{}: {:6.4f}'.format(self.name,time.time()-self.t0)\n        Key.results.setdefault(self.refresh,[]).append(s)\n        # do the thing you want at this time ref with the Key...\n\n    def time_left(self):\n        return max(self.t0+self.refresh-time.time(),0)\n\nkeys=[Key(random.randint(2,15),'Key {}'.format(i)) for i in range(1,1001)]\nt=time.time()\nwhile any(key.time_left() for key in keys):\n    if time.time()-t > 1:\n        kc=filter(lambda x: x, (key.time_left() for key in keys))\n        if kc:\n            tmpl='{} keys; max life: {:.2f}; average life: {:.2f}'\n            print tmpl.format(len(kc),max(kc),sum(kc)/len(kc))\n            t=time.time()\n\nfor k in sorted(Key.results):\n    print '\\nKeys with {} secs life:'.format(k)\n    for e in Key.results[k]:\n        print '\\t{}'.format(e)\n"]], ['Best way to reset keys which expires in few minutes in python'], 2, 1], [(15620039, 1), [['Prints:'], ['You can see that there is some variability in accuracy, but it is with 1/100 sec for most purposes. ']], [[' 1000 keys; max life: 13.98; average life: 7.38\n933 keys; max life: 12.98; average life: 6.85\n870 keys; max life: 11.97; average life: 6.29\n796 keys; max life: 10.97; average life: 5.80\n729 keys; max life: 9.97; average life: 5.26\n666 keys; max life: 8.96; average life: 4.68\n594 keys; max life: 7.96; average life: 4.16\n504 keys; max life: 6.96; average life: 3.77\n427 keys; max life: 5.96; average life: 3.32\n367 keys; max life: 4.95; average life: 2.74\n304 keys; max life: 3.95; average life: 2.16\n215 keys; max life: 2.95; average life: 1.76\n138 keys; max life: 1.95; average life: 1.32\n84 keys; max life: 0.95; average life: 0.72\n\nKeys with 2 secs life:\n    Key 26: 2.0052\n    Key 27: 2.0053\n    Key 41: 2.0048\n    ...\nKeys with 3 secs life:\n    Key 4: 3.0040\n    Key 31: 3.0065\n    Key 32: 3.0111\n    ...\nKeys with 4 secs life:\n...\n']], ['Best way to reset keys which expires in few minutes in python'], 2, 0], [(15635341, 0), [['What I usually do in these scenarios is wrap the important cells as functions (you don\'t have to merge any of them) and have a certain master cell that iterates over a list of parameters and calls these functions. E.g. this is what a "master cell" looks like in one of my notebooks:'], ['You can still have some data dragging throughout the notebook (i.e. calling each function at the bottom of the cell with your data) to be able to test stuff live for individual cells. For example some cell might state:']], [[' import itertools\n# parameters\nP_peak_all = [100, 200]\nidle_ratio_all = [0., 0.3, 0.6]\n# iterate through these parameters and call the notebook\'s logic\nfor P_peak, idle_ratio in itertools.product(P_peak_all, idle_ratio_all):\n    print(P_peak, idle_ratio, P_peak*idle_ratio)\n    print(\'========================\')\n    m_synth, m_synth_ns = build_synth_measurement(P_peak, idle_ratio)\n    compare_measurements(m_synth, m_synth_ns, "Peak pauser", "No scheduler", file_note="-%d-%d" % (P_peak, int(idle_ratio*100)))\n']], ['Run parts of a ipython notebook in a loop / with different input parameter'], 2, 1], [(15635341, 1), [['You can still have some data dragging throughout the notebook (i.e. calling each function at the bottom of the cell with your data) to be able to test stuff live for individual cells. For example some cell might state:'], ['Which lets you experiment live and still call the generic functionality from the master cell.']], [[' def square(x):\n    y = x**2\n    return y\nsquare(x) # where x is your data running from the prior cells \n']], ['Run parts of a ipython notebook in a loop / with different input parameter'], 2, 0], [(15649257, 3), [['and then the following one-liner used for queries:'], ['Another approach is to write a  custom manager  which allows you to use your own functions for filtering.   With a custom manager you could implement code to allow queries like this, where you provide a function for  all_or_filtered  to apply the correct filtering:']], [[" order_items = OrderItem.objects.filter(**all_or_filter_args(request, 'provider'))\n"]], ['Django wildcard query'], 5, 0], [(15649257, 4), [['Another approach is to write a  custom manager  which allows you to use your own functions for filtering.   With a custom manager you could implement code to allow queries like this, where you provide a function for  all_or_filtered  to apply the correct filtering:'], ['-10000']], [[" order_items = OrderItem.objects.all_or_filtered('provider', request.POST.get('provider'))\n"]], ['Django wildcard query'], 5, 0], [(15668416, 0), [['First, it\'s probably reasonable to consider  [1,]  to mean "row 1", just like  [1] . ( numpy  does this.) That means you don\'t need the tuple-vs.-int thing; just treat an int as a 1-element tuple. In other words:'], ["At any rate, here's an example that does all the simplification and pre/postprocessing I could think of (possibly more than you want) so that ultimately you're always looking up a pair of slices:"]], [[' def __getitem__(self, idx):\n    if isinstance(idx, numbers.Integral):\n        idx = (idx, slice(None, None, None))\n    # now the rest of your code only needs to handle tuples\n']], ['Implementing 2D slicing in Python'], 4, 0], [(15668416, 3), [['If you\'re objecting to the need to type-switch on the index parameter, yes, that does seem generally unpythonic, but unfortunately it\'s how  __getitem__  generally works. If you want to use the usual EAFTP  try  logic, you can, but I don\'t think it\'s more readable when you have to try two different APIs (e.g.,  [0]  for tuples, and  .start  for slices) in multiple places. You end up doing "duck-type-switching" up at the top, like this:'], ['… and so on, and this is just twice as much code as normal type-switching without any of the usual benefits.']], [[' try:\n    idx[0]\nexcept AttributeError:\n    idx = (idx, slice(None, None, None))\n']], ['Implementing 2D slicing in Python'], 4, 0], [(15688462, 1), [['However,  myList   must  be a sequence of tuples here. If it is not, a generator expression will do to create these tuples:'], ['Demonstration (with insertions):']], [[" curr.executemany('UPDATE test SET myCol= ?', ((val,) for val in myList))\n"]], ['How to update entire column with values in list using Sqlite3'], 4, 1], [(15688462, 2), [['Demonstration (with insertions):'], ['Make sure your data has a row identifier to go with it; in this case it may be easier to use named parameters instead:']], [[" >>> import sqlite3\n>>> conn=sqlite3.connect(':memory:')\n>>> conn.execute('CREATE TABLE test (myCol)')\n<sqlite3.Cursor object at 0x10542f1f0>\n>>> conn.commit()\n>>> myList = ('foo', 'bar', 'spam')\n>>> conn.executemany('INSERT into test values (?)', ((val,) for val in myList))\n<sqlite3.Cursor object at 0x10542f180>\n>>> list(conn.execute('select * from test'))\n[(u'foo',), (u'bar',), (u'spam',)]\n"]], ['How to update entire column with values in list using Sqlite3'], 4, 1], [(15688462, 3), [['Make sure your data has a row identifier to go with it; in this case it may be easier to use named parameters instead:'], ['-10000']], [[" my_data = ({id=1, value='foo'}, {id=2, value='bar'})\ncursor.executemany('UPDATE test SET myCol=:value WHERE rowId=:id', my_data)\n"]], ['How to update entire column with values in list using Sqlite3'], 4, 1], [(15702753, 2), [['yields'], ['-10000']], [[' Ishida Co., Ltd. (Kyoto, JP )\n']], ['Python BeautifulSoup how to get the index or of the HTML table'], 3, 0], [(15708416, 0), [['I think regex lookup can help you:'], ['or you can always perform raw SQL queries on Django model:']], [[" ModelWithTextField.objects.filter(text_field__iregex=r'^.{7,}$')\n"]], ['Django: Lookup by length of text field'], 2, 1], [(15708416, 1), [['or you can always perform raw SQL queries on Django model:'], ['where len_func_name is the name of "string length" function for your DBMS. For example in mysql it\'s named "length".']], [[" ModelWithTextField.objects.raw('SELECT * FROM model_with_text_field WHERE LEN_FUNC_NAME(text_field) > 7')\n"]], ['Django: Lookup by length of text field'], 2, 1], [(15711845, 0), [['The method  gtk.Assistant.add_action_widget()  adds a widget to the so-called "action area". It turns out this is the  HBox  containing the relevant buttons. The following function will produce a reference to the  HBox :'], ['Then the buttons are retrieved using  get_buttons_hbox(a).get_children() .']], [[" def get_buttons_hbox(assistant):\n    # temporarily add a widget to the action area and get its parent\n    label = gtk.Label('')\n    assistant.add_action_widget(label)\n    hbox = label.get_parent()\n    hbox.remove(label)\n    return hbox\n"]], ['How do I change the built-in button labels on a gtk.Assistant?'], 4, 0], [(15711845, 1), [['Then the buttons are retrieved using  get_buttons_hbox(a).get_children() .'], ['This prints:']], [[' for child in get_buttons_hbox(a).get_children():\n    print child.get_label()\n']], ['How do I change the built-in button labels on a gtk.Assistant?'], 4, 0], [(15711845, 2), [['This prints:'], ['So the following code solves the problem (using  get_buttons_hbox()  defined above):']], [[' gtk-goto-last\ngtk-go-back\ngtk-go-forward\ngtk-apply\ngtk-cancel\ngtk-close\n']], ['How do I change the built-in button labels on a gtk.Assistant?'], 4, 0], [(15721679, 0), [['Python'], ['Javascript  ']], [[" @app.route('/_stuff', methods= ['GET'])\ndef stuff():\n    cpu=round(getCpuLoad())\n    ram=round(getVmem())\n    disk=round(getDisk())\n    return jsonify(cpu=cpu, ram=ram, disk=disk)\n"]], ['Update and render a value from Flask periodically'], 5, 0], [(15721679, 1), [['Javascript  '], ['-10000']], [[' function update_values() {\n            $SCRIPT_ROOT = {{ request.script_root|tojson|safe }};\n            $.getJSON($SCRIPT_ROOT+"/_stuff",\n                function(data) {\n                    $("#cpuload").text(data.cpu+" %")\n                    $("#ram").text(data.ram+" %")\n                    $("#disk").text(data.disk+" %")\n                });\n        }\n']], ['Update and render a value from Flask periodically'], 5, 0], [(15721679, 2), [['-10000'], ['project/app/__init__.py']], [[' # -*- coding: utf-8 -*-\n\n# OS Imports\nimport json\n\n# Local Imports\nfrom app import sockets\nfrom app.functions import get_cpu_load, get_disk_usage, get_vmem\n\n@sockets.route(\'/_socket_system\')\ndef socket_system(ws):\n    """\n    Returns the system informations, JSON Format\n    CPU, RAM, and Disk Usage\n    """\n    while True:\n        message = ws.receive()\n        if message == "update":\n            cpu = round(get_cpu_load())\n            ram = round(get_vmem())\n            disk = round(get_disk_usage())\n            ws.send(json.dumps(dict(received=message, cpu=cpu, ram=ram, disk=disk)))\n        else:\n            ws.send(json.dumps(dict(received=message)))\n']], ['Update and render a value from Flask periodically'], 5, 0], [(15721679, 3), [['project/app/__init__.py'], ['Using Flask-Websockets made my life a lot easier. Here is the launcher :\n launchwithsockets.sh']], [[" # -*- coding: utf-8 -*-\nfrom flask import Flask\nfrom flask_sockets import Sockets\n\n\napp = Flask(__name__)\nsockets = Sockets(app)\napp.config.from_object('config')\nfrom app import views\n"]], ['Update and render a value from Flask periodically'], 5, 0], [(15721679, 4), [['Using Flask-Websockets made my life a lot easier. Here is the launcher :\n launchwithsockets.sh'], ["Finally, here is the client code : \n custom.js \n The code is a bit too long, so here it is. \nNote that I'm NOT using things like socket.io, that's why the code is long. This code also tries to reconnect to the server periodically, and can stop trying to reconnect on a user action. I use the Messenger lib to notify the user that something went wrong. Of course it's a bit more complicated than using socket.io but I really enjoyed coding the client side. "]], [[' #!/bin/sh\n\ngunicorn -k flask_sockets.worker app:app\n']], ['Update and render a value from Flask periodically'], 5, 0], [(15782606, 1), [['Changing the path to where your local IPython is installed. If you associate the .ipy file extension with the pylauncher executable ( typically C:\\Windows\\py.exe and you can save the py.ini file to the same path ) and use the shebang below at the top of your .py/.ipy files they should run with ipython and the options specified in the py.ini file'], ['You can also associate the ipython.exe with .ipy files on Windows and it will run the .ipy files. ']], [[' #! ipython\n']], ['Executing Ipython Script from System Shell'], 2, 0], [(15793715, 0), [['The tester source code was:'], ["And it's the result:"]], [[" import __main__\nfrom itertools import permutations\nfrom time import time\n\ndef replace1(txt, pos, new_char):\n    return txt[:pos] + new_char + txt[pos+1:]\n\ndef replace2(txt, pos, new_char):\n    return '{0}{1}{2}'.format(txt[:pos], new_char, txt[pos+1:])\n\ndef replace3(txt, pos, new_char):\n    return ''.join({pos: new_char}.get(idx, c) for idx, c in enumerate(txt))\n\ndef replace4(txt, pos, new_char):    \n    txt = list('12345')\n    txt[pos] = new_char\n    ''.join(txt)\n\ndef replace5(txt, pos, new_char):\n    return '%s%s%s' % (txt[:pos], new_char, txt[pos+1:])\n\n\nwords = [''.join(x) for x in permutations('abcdefgij')]\n\nfor i in range(1, 6):\n    func = getattr(__main__, 'replace{}'.format(i))\n\n    start = time()\n    for word in words:\n        result = func(word, 2, 'X')\n    print time() - start\n"]], ['Other ways to replace single character'], 2, 1], [(15793715, 1), [["And it's the result:"], ['-10000']], [[' 0.233116149902\n0.409259080887\n2.64006495476\n0.612321138382\n0.302225828171\n']], ['Other ways to replace single character'], 2, 0], [(15795416, 0), [['In the site settings file, set '], ['In the resource Meta class that you want to disable pagination for, set:']], [[' API_LIMIT_PER_PAGE = 0\n']], ['Disable pagination in Django tastypie?'], 2, 0], [(15795416, 1), [['In the resource Meta class that you want to disable pagination for, set:'], ['Then if you navigate to the list view of the resource, the returned content should show a limit of 0.']], [[' class MyResource(ModelResource):\n    ...\n    class Meta:\n        ...\n        max_limit = None\n']], ['Disable pagination in Django tastypie?'], 2, 0], [(15815999, 0), [['All you need to do to make your numpy array a "structured" one is to give it the  dtype  argument.  This gives each "field" a name and type.  They can even have more complex shapes and hierarchies if you wish, but here\'s how I keep my x-y data:'], ['For example:']], [[" In [175]: import numpy as np\n\nIn [176]: x = np.random.random(10)\n\nIn [177]: y = np.random.random(10)\n\nIn [179]: zip(x,y)\nOut[179]: \n[(0.27432965895978034, 0.034808254176554643),\n (0.10231729328413885, 0.3311112896885462),\n (0.87724361175443311, 0.47852682944121905),\n (0.24291769332378499, 0.50691735432715967),\n (0.47583427680221879, 0.04048957803763753),\n (0.70710641602121627, 0.27331443495117813),\n (0.85878694702522784, 0.61993945461613498),\n (0.28840423235739054, 0.11954319357707233),\n (0.22084849730366296, 0.39880927226467255),\n (0.42915612628398903, 0.19197320645915561)]\n\nIn [180]: data = np.array( zip(x,y), dtype=[('x',float),('y',float)])\n\nIn [181]: data['x']\nOut[181]: \narray([ 0.27432966,  0.10231729,  0.87724361,  0.24291769,  0.47583428,\n        0.70710642,  0.85878695,  0.28840423,  0.2208485 ,  0.42915613])\n\nIn [182]: data['y']\nOut[182]: \narray([ 0.03480825,  0.33111129,  0.47852683,  0.50691735,  0.04048958,\n        0.27331443,  0.61993945,  0.11954319,  0.39880927,  0.19197321])\n\nIn [183]: data[0]\nOut[183]: (0.27432965895978034, 0.03480825417655464)\n"]], ['Is there a standard way to store XY data in python?'], 2, 1], [(15815999, 1), [['For example:'], ['-10000']], [[" In [200]: t = np.arange(10)\n\nIn [202]: dt = np.dtype([('t',int),('pos',[('x',float),('y',float)])])\n\nIn [203]: alldata = np.array(zip(t, zip(x,y)), dtype=dt)\n\nIn [204]: alldata\nOut[204]: \narray([(0, (0.27432965895978034, 0.03480825417655464)),\n       (1, (0.10231729328413885, 0.3311112896885462)),\n       (2, (0.8772436117544331, 0.47852682944121905)),\n       (3, (0.242917693323785, 0.5069173543271597)),\n       (4, (0.4758342768022188, 0.04048957803763753)),\n       (5, (0.7071064160212163, 0.27331443495117813)),\n       (6, (0.8587869470252278, 0.619939454616135)),\n       (7, (0.28840423235739054, 0.11954319357707233)),\n       (8, (0.22084849730366296, 0.39880927226467255)),\n       (9, (0.429156126283989, 0.1919732064591556))], \n      dtype=[('t', '<i8'), ('pos', [('x', '<f8'), ('y', '<f8')])])\n\nIn [205]: alldata['t']\nOut[205]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nIn [206]: alldata['pos']\nOut[206]: \narray([(0.27432965895978034, 0.03480825417655464),\n       (0.10231729328413885, 0.3311112896885462),\n       (0.8772436117544331, 0.47852682944121905),\n       (0.242917693323785, 0.5069173543271597),\n       (0.4758342768022188, 0.04048957803763753),\n       (0.7071064160212163, 0.27331443495117813),\n       (0.8587869470252278, 0.619939454616135),\n       (0.28840423235739054, 0.11954319357707233),\n       (0.22084849730366296, 0.39880927226467255),\n       (0.429156126283989, 0.1919732064591556)], \n      dtype=[('x', '<f8'), ('y', '<f8')])\n\nIn [207]: alldata['pos']['x']\nOut[207]: \narray([ 0.27432966,  0.10231729,  0.87724361,  0.24291769,  0.47583428,\n        0.70710642,  0.85878695,  0.28840423,  0.2208485 ,  0.42915613])\n"]], ['Is there a standard way to store XY data in python?'], 2, 1], [(15820788, 0), [["If you have big sets of similar controls — best way to use loops for them. Let's imagine we use list for storing all button names, and other list of buttons that are acive. This will give us some controller:"], ["So, in template we'll have something like: "]], [[" from flask import render_template\n\n@app.route('/form/')\ndef hello(name=None):\n    return render_template('hello.html', buttons=['A', 'B', 'C'], active_btns=['A', 'C'])\n"]], ['Using Twitter Bootstrap radio buttons with Flask'], 3, 0], [(15820788, 1), [["So, in template we'll have something like: "], ["Actually, expression inside for loop can be simplified, using Jinja's If expression, and should look like:"]], [[' <div id="radios1" class="btn-group view-opt-btn-group" data-toggle="buttons-radio">\n{% for button in buttons %}\n    {% if button in active_btns %}\n        <button type="button" class="btn active" name="choice1" value="{{ button }}">{{ button }}</button>\n    {% else %}\n        <button type="button" class="btn" name="choice1" value="{{ button }}">{{ button }}</button>\n    {% endif %}\n{% endfor %}\n</div>\n']], ['Using Twitter Bootstrap radio buttons with Flask'], 3, 0], [(15820788, 2), [["Actually, expression inside for loop can be simplified, using Jinja's If expression, and should look like:"], ["But I don't have Jinja2 now, and could be wrong in syntax. "]], [[' <button type="button" class="btn{{" active" if button in active_btns}}" name="choice1" value="{{ button }}">{{ button }}</button>\n']], ['Using Twitter Bootstrap radio buttons with Flask'], 3, 0], [(15869158, 1), [['The above answer will not work for more than a single connection. I have updated it by adding another thread for taking connections. It it now possible to have more than a single user connect.'], ['Clients are not able to see what other clients say, messages from the server will be sent to all clients. I will leave that as an exercise for the reader.']], [[' import socket\nimport threading\nimport sys\nhost = \'\'\nport = 50000\n\nclass client(threading.Thread):\n    def __init__(self, conn):\n        super(client, self).__init__()\n        self.conn = conn\n        self.data = ""\n\n    def run(self):\n        while True:\n            self.data = self.data + self.conn.recv(1024)\n            if self.data.endswith(u"\\r\\n"):\n                print self.data\n                self.data = ""\n\n    def send_msg(self,msg):\n        self.conn.send(msg)\n\n    def close(self):\n        self.conn.close()\n\nclass connectionThread(threading.Thread):\n    def __init__(self, host, port):\n        super(connectionThread, self).__init__()\n        try:\n            self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.s.bind((host,port))\n            self.s.listen(5)\n        except socket.error:\n            print \'Failed to create socket\'\n            sys.exit()\n        self.clients = []\n\n    def run(self):\n        while True:\n            conn, address = self.s.accept()\n            c = client(conn)\n            c.start()\n            c.send_msg(u"\\r\\n")\n            self.clients.append(c)\n            print \'[+] Client connected: {0}\'.format(address[0])\n\n\n\ndef main():\n    get_conns = connectionThread(host, port)\n    get_conns.start()\n    while True:\n        try:\n            response = raw_input() \n            for c in get_conns.clients:\n                c.send_msg(response + u"\\r\\n")\n        except KeyboardInterrupt:\n            sys.exit()\n\nif __name__ == \'__main__\':\n    main()\n']], ['Python Socket Listening'], 2, 1], [(15892598, 1), [['As DSM noted in his (now deleted) answer, you can do this with a list comprehension or generator:'], ['-10000']], [[' (k for k in set(sourceDict).intersection(targetDict) if sourceDict[key] != targetDict[key])\n']], ['Compare values from two different dictionaries in Python?'], 2, 1], [(15905215, 0), [['You can use recursion for this task:'], ["This probably isn't the most pythonic code, but this shows how to think about it."]], [[" def next_string(s):\n    if len(s) == 0:\n        return '1'\n    head = s[0:-1]\n    tail = s[-1]\n    if tail == 'Z':\n        return next_string(head) + '1'\n    if tail == '9':\n        return head+'A'\n    if tail == 'H':\n        return head+'J'\n    if tail == 'N':\n        return head+'P'\n    return head + chr(ord(tail)+1)\n"]], ['Python: Alphanumeric Serial Number with some rules'], 2, 1], [(15905215, 1), [["This probably isn't the most pythonic code, but this shows how to think about it."], ['-10000']], [[" >>> next_string('11A')\n'11B'\n>>> next_string('11A')\n'11B'\n>>> next_string('11Z')\n'121'\n>>> next_string('119')\n'11A'\n>>> next_string('1')\n'2'\n>>> next_string('ZZ')\n'111'\n>>> next_string('ZZ1')\n'ZZ2'\n>>> next_string('ZZ9')\n'ZZA'\n>>> next_string('ZZH')\n'ZZJ'\n"]], ['Python: Alphanumeric Serial Number with some rules'], 2, 0], [(15926531, 0), [['If the files are rather small, then the following simple solution would be adequate:'], ["If the files are very large and you don't want to load them entirely into memory (especially if you expect that search text to occur early in the file), replace the above  with  block with the following:"]], [[' if os.path.isfile(file_path): # or some other condition\n    delete = True             # Standard action: delete\n    try:\n        with open(file_path) as infile:\n            if "dollar" in infile.read(): # don\'t delete if "dollar" is found\n                delete = False \n    except IOError:\n        print("Could not access file {}".format(file_path))\n    if delete: \n        os.unlink(file_path)\n']], ['Deleting specific text files'], 2, 1], [(15971308, 0), [['It is better to make a single call to a function that returns the current date/time:'], ['Or does']], [[' from datetime import datetime\n\nnow = datetime.now()\nseconds_since_midnight = (now - now.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n']], ['Get seconds since midnight in python'], 2, 1], [(15971308, 1), [['Or does'], ['return zero timedelta for anyone here?']], [[' datetime.now() - datetime.now()\n']], ['Get seconds since midnight in python'], 2, 0], [(16019624, 0), [['maybe using  itertools.groupby ?'], ['Results in:']], [[" from itertools import groupby\ndef key(item):\n    return [int(x) for x in item[1].split()[:3]]\n\nmaster_lst = [['Introduction', '0 11 0 1 0'],\n              ['Floating', '0 11 33 1 0'],\n              ['point', '0 11 33 1 1'],\n              ['numbers', '0 11 33 1 2'],\n              ['IEEE', '0 11 58 1 0'],\n              ['Standard', '0 11 58 1 1'], \n              ['754', '0 11 58 1 2']]\n\nfor k,v in groupby(master_lst,key=key):\n    print ' '.join(x[0] for x in v) +' ' + ' '.join(str(x) for x in k)\n"]], ['How can I cluster a list of lists in Python based on string indices? Need insight'], 2, 1], [(16019624, 1), [['Results in:'], ['-10000']], [[' Introduction 0 11 0\nFloating point numbers 0 11 33\nIEEE Standard 754 0 11 58\n']], ['How can I cluster a list of lists in Python based on string indices? Need insight'], 2, 0], [(16021184, 1), [["and in order to display Russian text correctly in developer's admin console (under Windows 7):"], ['-10000']], [[" def logging_debug(what):\n    ''' Function to support cp866 encoding in developers admin console\n    '''\n    if os.environ.get('SERVER_SOFTWARE','').startswith('Devel'):\n        logging.debug(what.encode('cp866'))\n    else:\n        logging.debug(what)\n"]], ['How to log e-mail details in AppEngine Admin console?'], 2, 0], [(16056574, 0), [['To do this for custom Python classes, use a metaclass:'], ['gives:']], [[' class Final(type):\n    def __new__(cls, name, bases, classdict):\n        for b in bases:\n            if isinstance(b, Final):\n                raise TypeError("type \'{0}\' is not an acceptable base type".format(b.__name__))\n        return type.__new__(cls, name, bases, dict(classdict))\n\nclass Foo:\n    __metaclass__ = Final\n\nclass Bar(Foo):\n    pass\n']], ['How does python prevent a class from being subclassed?'], 2, 1], [(16056574, 1), [['gives:'], ['-10000']], [[' >>> class Bar(Foo):\n...     pass\n... \nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\n  File "<stdin>", line 5, in __new__\nTypeError: type \'Foo\' is not an acceptable base type\n']], ['How does python prevent a class from being subclassed?'], 2, 0], [(16057689, 0), [['Using a dict:'], ['Using a list:']], [[" arraysDict = {}\nfor i in range(0,3):\n    arraysDict['x{0}'.format(i)] = [1,2,3]\n\nprint arraysDict\n# {'x2': [1, 2, 3], 'x0': [1, 2, 3], 'x1': [1, 2, 3]}\nprint arraysDict['x1']\n# [1,2,3]\n"]], ['How to rename variables in a loop in Python'], 2, 1], [(16057689, 1), [['Using a list:'], ['-10000']], [[' arraysList = []\nfor i in range(0,3):\n    arraysList.append([1,2,3])\n\nprint arraysList\n# [[1, 2, 3], [1, 2, 3], [1, 2, 3]]\nprint arraysList[1]\n# [1, 2, 3]\n']], ['How to rename variables in a loop in Python'], 2, 1], [(16070219, 0), [['You can create a function using  scipy.interp1d :'], ['If you want to  smooth  your data, you can use the  univariatespline , just replace the  f = interpolate...  line with:']], [[' import numpy as np\nfrom scipy import interpolate\n\ndata = np.genfromtxt(\'data.txt\')\n\nx = data[:,0]  #first column\ny = data[:,1]  #second column\n\nf = interpolate.interp1d(x, y)\n\nxnew = np.arange(1, 5.1, 0.1) # this could be over the entire range, depending on what your data is\nynew = f(xnew)   # use interpolation function returned by `interp1d`\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\nax1.set_title("Plot B vs H")    \nax1.set_xlabel(\'B\')\nax1.set_ylabel(\'H\')\n\nax1.plot(x,y, c=\'r\', label=\'the data\')\nax1.plot(xnew, ynew, \'o\', label=\'the interpolation\')\n\nleg = ax1.legend()\nplt.show()\n']], ['how to interpolate points in a specific interval on a plot formed by loading a txt file in to scipy program?'], 3, 1], [(16070219, 1), [['If you want to  smooth  your data, you can use the  univariatespline , just replace the  f = interpolate...  line with:'], ['To change how much it smooths, you can fiddle with the  s  and  k  options:']], [[' f = interpolate.UnivariateSpline(x, y)\n']], ['how to interpolate points in a specific interval on a plot formed by loading a txt file in to scipy program?'], 3, 0], [(16070219, 2), [['To change how much it smooths, you can fiddle with the  s  and  k  options:'], ['As described at the  documentation']], [[' f = interpolate.UnivariateSpline(x, y, k=3, s=1)\n']], ['how to interpolate points in a specific interval on a plot formed by loading a txt file in to scipy program?'], 3, 0], [(16090146, 0), [['First of all, if it was not for the relative complexity of the expressions here, scipy would have been definitely the better option over sympy. But the expression is rather complicated, so we can first simplify it in  sympy  and only then feed it to  scipy :'], ['Now given that you are not interested in symbolics and that the simplification was not that good, it would be useless to continue using sympy instead of scipy, but if you insist you can do it.']], [[' >>> C_b\n38.0∗C0\n+3.0∗((0.17∗C0+0.076)∗∗2+(2.0∗C0+0.0066)∗∗2)∗∗0.5\n+3.0∗((0.35∗C0+0.076)∗∗2+(2.0∗C0+0.0066)∗∗2)∗∗0.5\n+3.0∗((2.0∗C0+0.0066)∗∗2+0.0058)∗∗0.5\n+9.4\n\n>>> simplify(C_b)\n38.0∗C0\n+3.0∗(4.0∗C0∗∗2+0.027∗C0+0.0058)∗∗0.5\n+3.0∗(4.1∗C0∗∗2+0.053∗C0+0.0058)∗∗0.5\n+3.0∗(4.2∗C0∗∗2+0.08∗C0+0.0058)∗∗0.5\n+9.4\n']], ['Sympy library solve to an unknown variable'], 2, 0], [(16090146, 1), [['Now given that you are not interested in symbolics and that the simplification was not that good, it would be useless to continue using sympy instead of scipy, but if you insist you can do it.'], ['If you try to use  solve  instead of  nsolve  you will just waste a lot of resources in searching for a symbolic solution (that may not even exist in elementary terms) when a numeric one is instantaneous. ']], [[' >>> nsolve(C_b - 10.4866, C0, 1) # for numerical solution\n0.00970963412692139\n']], ['Sympy library solve to an unknown variable'], 2, 0], [(16107526, 0), [['Well, there\'s no "equivalent option" in Python as far as I\'m aware, but any Unix-like shell will let you set/override it on a per-process basis, if you were to run Python like this...'], ['...a syntax which you could also use for Java with...']], [[' $ PYTHONPATH=/put/path/here python myscript.py\n']], ['How to flexibly change PYTHONPATH'], 3, 1], [(16107526, 1), [['...a syntax which you could also use for Java with...'], ['The closest Windows equivalent to this would be...']], [[' $ CLASSPATH=/put/path/here java MyMainClass\n']], ['How to flexibly change PYTHONPATH'], 3, 0], [(16107526, 2), [['The closest Windows equivalent to this would be...'], ["...if you don't want the environment variable to be set in the calling  cmd.exe ."]], [[' > cmd /c "set PYTHONPATH=\\put\\path\\here && python myscript.py"\n']], ['How to flexibly change PYTHONPATH'], 3, 1], [(16110307, 0), [['Take a look at  itertools.groupby :'], ["It basically splits items in your list into groups based on a criteria ( item != ',' ) and the comprehension check  if k  filters out the groups that are  False   –  that is the items that are equal to  ',' ."]], [[" In [1]: from itertools import groupby\n\nIn [2]: lst = [[ 'something', ',', 'eh' ], ',', ['more'], ',', 'yet more', '|', 'even more' ]\n\nIn [3]: [list(group) for key, group in groupby(lst, lambda x: x!=',') if key]\nOut[3]: [[['something', ',', 'eh']], [['more']], ['yet more', '|', 'even more']]\n"]], ['Splitting a list of lists and strings by a string'], 2, 1], [(16110307, 1), [["It basically splits items in your list into groups based on a criteria ( item != ',' ) and the comprehension check  if k  filters out the groups that are  False   –  that is the items that are equal to  ',' ."], ['-10000']], [[" In [4]: for key, group in groupby(lst, lambda x: x!=','):\n   ...:     print key, list(group)\n   ...:     \nTrue [['something', ',', 'eh']]\nFalse [',']\nTrue [['more']]\nFalse [',']\nTrue ['yet more', '|', 'even more']\n"]], ['Splitting a list of lists and strings by a string'], 2, 0], [(16123732, 0), [['You have a custom ASCII-table-like format with fixed-with columns:'], ["To output, I'd still use the  csv  module , because that would make future processing that much easier:"]], [[' *********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n*    Row   * Instance * test_string * test_string * test_string * test_string * test_string * test_string * test_string * string__722 * string__722 * string__722 * string__722 * string__722 * string__722 * string__722 * string__720 * string__720 * string__720 * string__720 * string__720 * string__720 * string__720 * HCAL_SlowDa * HCAL_SlowDa * HCAL_SlowDa * HCAL_SlowDa * HCAL_SlowDa * HCAL_SlowDa * HCAL_SlowDa * string__718 * string__718 * string__718 * string__718 * string__718 * string__718 * string__718 * string__719 * string__719 * string__719 * string__719 * string__719 * string__719 * string__719 * string__723 * string__723 * string__723 * string__723 * string__723 * string__723 * string__723 * string__721 * string__721 * string__721 * string__721 * string__721 * string__721 * string__721 * another_str * another_str * another_str * another_str * another_str * another_str * another_str * another_str * another_str *\n*********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n*        0 *        0 *           0 *    50331648 * test_string *           2 *           1 *          13 * 5.76460e+18 *           0 *    50331648 * string__722 *           2 *           1 *         606 * 5.83666e+18 *           0 *    50331648 * string__720 *           2 *           1 *         575 * 5.83666e+18 *           0 *    50331648 * HCAL_SlowDa *           2 *           1 *          36 * 5.76460e+18 *           0 *    50331648 * string__718 *           2 *           1 *         529 * 5.83666e+18 *           0 *    50331648 * string__719 *           2 *           1 *         529 * 5.83666e+18 *           0 *    50331648 * string__723 *           2 *           1 *         529 * 5.83666e+18 *           0 *    50331648 * string__721 *           2 *           1 *         529 * 5.83666e+18 *           0 *    50331648 *      212135 *       15080 *           1 *           1 *        3340 *        1057 * 1.399999976 *\n*        0 *        1 *           0 *    50331648 *             *           2 *           1 *          13 *           0 *           0 *    50331648 *             *           2 *           1 *         606 *       53440 *           0 *    50331648 *             *           2 *           1 *         575 *       53440 *           0 *    50331648 *             *           2 *           1 *          36 *           0 *           0 *    50331648 *             *           2 *           1 *         529 *       53440 *           0 *    50331648 *             *           2 *           1 *         529 *       53440 *           0 *    50331648 *             *           2 *           1 *         529 *       53440 *           0 *    50331648 *             *           2 *           1 *         529 *       53440 *           0 *    50331648 *      212135 *             *           1 *           1 *        3340 *        1057 * 1.399999976 *\n*        0 *        2 *           0 *    50331648 *             *           2 *           1 *          13 *  4294970636 *           0 *    50331648 *             *           2 *           1 *         606 * 1.09780e+16 *           0 *    50331648 *             *           2 *           1 *         575 * 1.09780e+16 *           0 *    50331648 *             *           2 *           1 *          36 * 2.70217e+16 *           0 *    50331648 *             *           2 *           1 *         529 * 1.09780e+16 *           0 *    50331648 *             *           2 *           1 *         529 * 1.09780e+16 *           0 *    50331648 *             *           2 *           1 *         529 * 1.09780e+16 *           0 *    50331648 *             *           2 *           1 *         529 * 1.09780e+16 *           0 *    50331648 *      212135 *             *           1 *           1 *        3340 *        1057 * 1.399999976 *\n*        0 *        3 *           0 *    50331648 *             *           2 *           1 *          13 *   352321545 *           0 *    50331648 *             *           2 *           1 *         606 * 2.30610e+18 *           0 *    50331648 *             *           2 *           1 *         575 * 2.30610e+18 *           0 *    50331648 *             *           2 *           1 *          36 * 7.30102e+18 *           0 *    50331648 *             *           2 *           1 *         529 * 1.15294e+19 *           0 *    50331648 *             *           2 *           1 *         529 * 1.15294e+19 *           0 *    50331648 *             *           2 *           1 *         529 * 1.15294e+19 *           0 *    50331648 *             *           2 *           1 *         529 * 1.15294e+19 *           0 *    50331648 *      212135 *             *           1 *           1 *        3340 *        1057 * 1.399999976 *\n*        0 *        4 *           0 *    50331648 *             *           2 *           1 *          13 *           0 *           0 *    50331648 *             *           2 *           1 *         606 * 1.15294e+19 *           0 *    50331648 *             *           2 *           1 *         575 * 1.15294e+19 *           0 *    50331648 *             *           2 *           1 *          36 * 2.82590e+16 *           0 *    50331648 *             *           2 *           1 *         529 * 1.15294e+19 *           0 *    50331648 *             *           2 *           1 *         529 * 1.15294e+19 *           0 *    50331648 *             *           2 *           1 *         529 * 1.15294e+19 *           0 *    50331648 *             *           2 *           1 *         529 * 1.15294e+19 *           0 *    50331648 *      212135 *             *           1 *           1 *        3340 *        1057 * 1.399999976 *\n']], ['Python, remove specific columns from file'], 3, 0], [(16123732, 1), [["To output, I'd still use the  csv  module , because that would make future processing that much easier:"], ['The first row thus is:']], [[" import csv\nimport re\nfrom itertools import islice\n\nrow_split = re.compile('\\s*\\*\\s*')\n\nwith open(someinputfile, 'rb') as infile, open(outputfile, 'wb') as outfile:\n    writer = csv.writer(outfile, delimiter='\\t')\n\n    next(islice(infile, 3, 3), None) # skip the first 3 lines in the input file\n\n    for line in infile:\n        row = row_split.split(line)[1:-1]\n        if not row: continue\n        writer.writerow(row[8::7])\n"]], ['Python, remove specific columns from file'], 3, 1], [(16123732, 2), [['The first row thus is:'], ['-10000']], [[" ['5.76460e+18', '5.83666e+18', '5.83666e+18', '5.76460e+18', '5.83666e+18', '5.83666e+18', '5.83666e+18', '5.83666e+18', '3340']\n"]], ['Python, remove specific columns from file'], 3, 0], [(16142829, 0), [['The following does what you want:'], ['C is ']], [[' A = np.array([[0., 1., 0., 2.],\n             [1., 0., 3., 0.],\n             [0., 0., 0., 4.],\n             [2., 0., 4., 0.]]) # quadratic, not symmetric Matrix, shape (i, i)\nB = np.array([2., 4., 2., 1.]) # vector shape (i)\n\nC = A*(B[:,None]-B)\n']], ['numpy: slicing and vectorized looping with 1d and 2d arrays'], 2, 1], [(16142829, 1), [['C is '], ['A little explanation: \n B[:,None]  converts  B  to a column vector of shape  [4,1] .  B[:,None]-B  automatically broadcast the result to a 4x4 matrix that you can simply multiply by  A']], [[' array([[ 0., -2.,  0.,  2.],\n       [ 2.,  0.,  6.,  0.],\n       [ 0., -0.,  0.,  4.],\n       [-2., -0., -4.,  0.]])\n']], ['numpy: slicing and vectorized looping with 1d and 2d arrays'], 2, 0], [(16143648, 0), [['You can use the  unicode_escape  codec ; this produces a  bytes  instance:'], ['To go back to Unicode, simply decode from ASCII:']], [[' >>> example = \'Foo \\\'" \\\\ Bar\'\n>>> print(example)\nFoo \'" \\ Bar\n>>> print(example.encode(\'unicode_escape\'))\nb\'Foo \\\'" \\\\\\\\ Bar\'\n>>> example.encode(\'unicode_escape\')\nb\'Foo \\\'" \\\\\\\\ Bar\'\n']], ['Escape string to be valid python expression'], 4, 1], [(16143648, 1), [['To go back to Unicode, simply decode from ASCII:'], ['Alternatively, use  repr() :']], [[' >>> print(example.encode(\'unicode_escape\').decode(\'ascii\'))\nFoo \'" \\\\ Bar\n>>> example.encode(\'unicode_escape\').decode(\'ascii\')\n\'Foo \\\'" \\\\\\\\ Bar\'\n']], ['Escape string to be valid python expression'], 4, 0], [(16143648, 2), [['Alternatively, use  repr() :'], ['-10000']], [[' >>> repr(example)\n\'\\\'Foo \\\\\\\'" \\\\\\\\ Bar\\\'\'\n>>> print(repr(example))\n\'Foo \\\'" \\\\ Bar\'\n']], ['Escape string to be valid python expression'], 4, 0], [(16143648, 3), [['-10000'], ['-10000']], [[' >>> print(repr(\'\\\'\'))\n"\'"\n>>> print(repr(\'\\"\'))\n\'"\'\n>>> print(repr(\'\\\'"\'))\n\'\\\'"\'\n']], ['Escape string to be valid python expression'], 4, 0], [(16155921, 0), [["I don't know much about  fping , but something like this..."], ["Here's quick one-liner example using  ping  to grab three ping times to localhost..."]], [[" import subprocess\n\nCMD = ['fping', 'param1', 'param2']\n\nresult = subprocess.check_output(CMD)\n"]], ['Using fping to get ping times in Python'], 2, 1], [(16160474, 0), [['Rather than invoking the command line tool, try using the  gconf  module included in the GNOME Python bindings:'], ['For lists, you can introspect the list value type:']], [[" >>> import gconf\n>>> client = gconf.Client()\n>>> # Get a value and introspect its type:\n>>> value = client.get('/apps/gnome-terminal/profiles/Default/background_color')\n>>> value.type\n<enum GCONF_VALUE_STRING of type GConfValueType>\n>>> value.get_string()\n'#FFFFFFFFDDDD'\n"]], ['GNOME configuration database type-inference'], 2, 1], [(16207633, 0), [["Do you mean something like this? If so you have to define a  __iter__  method that yield's key-value pairs:"], ['-10000']], [[' In [1]: class A(object):\n   ...:     def __init__(self):\n   ...:        self.pairs = ((1,2),(2,3))\n   ...:     def __iter__(self):\n   ...:         return iter(self.pairs)\n   ...:     \n\nIn [2]: a = A()\n\nIn [3]: dict(a)\nOut[3]: {1: 2, 2: 3}\n']], ['Represent a class as a dict or list'], 2, 0], [(16207633, 1), [['-10000'], ['-10000']], [[" In [4]: class B(object):\n    ...:     def __init__(self):\n    ...:        self.d = {'key':'value'}\n    ...:        self.l = [1,2,3,4]\n    ...:     def keys(self):\n    ...:         return self.d.keys()\n    ...:     def __getitem__(self, item):\n    ...:         return self.d[item]\n    ...:     def __iter__(self):        \n    ...:         return iter(self.l)\n    ...:     \n\nIn [5]: b = B()\n\nIn [6]: list(b)\nOut[6]: [1, 2, 3, 4]\n\nIn [7]: dict(b)\nOut[7]: {'key': 'value'}\n"]], ['Represent a class as a dict or list'], 2, 1], [(16218482, 0), [['Something like this should work...'], ['...or just call  foo.exe  by its full path...']], [[" import os\n\npsqldir = 'C:/Program Files/PostgreSQL/9.2/bin'\nos.environ['PATH'] = '%s;%s' % (os.environ['PATH'], psqldir)\nos.system('foo')\n"]], ['Setting path in Python'], 2, 1], [(16218482, 1), [['...or just call  foo.exe  by its full path...'], ["However, as kindall's (now-deleted) answer suggested, it's worth noting this paragraph from the  os.system()  documentation..."]], [[" os.system('C:/Program Files/PostgreSQL/9.2/bin/foo')\n"]], ['Setting path in Python'], 2, 0], [(16233528, 0), [['This solution uses interp1d'], ['as well as numpy of course']], [[' from scipy.interpolate import interp1d\n']], ['Average multiple vectors of points of different lengths in python'], 3, 0], [(16233528, 1), [['as well as numpy of course'], ['The following func receives the 3 vecs I described above, a  trialList , which is a list of trials to collapse across and a  kind , which is the type of collapsing you want to do, can be mean or median for now. It will return the collapsed trajectory i.e. the x and y positions of the average or the median of the trialList']], [[' import numpy as np\n']], ['Average multiple vectors of points of different lengths in python'], 3, 0], [(16233528, 2), [['The following func receives the 3 vecs I described above, a  trialList , which is a list of trials to collapse across and a  kind , which is the type of collapsing you want to do, can be mean or median for now. It will return the collapsed trajectory i.e. the x and y positions of the average or the median of the trialList'], ['-10000']], [[" def collapseTrajectories(sx, sy, st, trialList, kind='median'):\n    # find the longest trial to use as template\n    l = 0\n    tr = []\n    for t in trialList:\n        if len(st[st==t]) > l:\n            l = len(st[st==t])\n            tr = t\n\n    # Make all vectors the same length by interpolating the values\n    xnew = np.linspace(0, 640, l)\n    ynew = np.linspace(0, 480, l)\n    sx_new = []\n    sy_new = []\n\n    for t in trialList:\n        if len(st[st==t]) > 3:\n            X = sx[st==t]\n            Y = sy[st==t]\n            x = np.linspace(0,640, len(X))\n            y = np.linspace(0,480,len(Y))\n            fx = interp1d(x, X, kind='cubic')\n            fy = interp1d(y, Y, kind='cubic')\n            sx_new.append(fx(xnew))\n            sy_new.append(fy(ynew))\n\n    # Collapse using the appropriate kind\n    if kind == 'median':\n        out_x = np.median(sx_new, axis=0)\n        out_y = np.median(sy_new, axis=0)\n    elif kind=='mean':\n        out_x = np.mean(sx_new, axis=0)\n        out_y = np.mean(sy_new, axis=0)\n\n    return out_x, out_y\n"]], ['Average multiple vectors of points of different lengths in python'], 3, 0], [(16253958, 0), [['Something like this, considering the data is stored in a text file:'], ['or if the data is stored in a string:']], [[' In [15]: with open("abc") as f:\n   ....:     for line in f:\n   ....:         spl=line.split()\n   ....:         if \'18\' in spl:\n   ....:             print line\n   ....:             break\n   ....:             \n18  :   mp4 [360x640]\n']], ['How can I create a list with the first column?'], 2, 1], [(16253958, 1), [['or if the data is stored in a string:'], ['-10000']], [[' In [16]: strs="""Available formats:\n   ....:     37  :   mp4 [1080x1920]\n   ....:     46  :   webm    [1080x1920]\n   ....:     22  :   mp4 [720x1280]\n   ....:     45  :   webm    [720x1280]\n   ....:     35  :   flv [480x854]\n   ....:     44  :   webm    [480x854]\n   ....:     34  :   flv [360x640]\n   ....:     18  :   mp4 [360x640]\n   ....:     43  :   webm    [360x640]\n   ....:     5   :   flv [240x400]\n   ....:     17  :   mp4 [144x176]"""\n   ....:     \n\nIn [17]: for line in strs.splitlines():\n   ....:     spl=line.split()\n   ....:     if \'18\' in  spl:\n   ....:         print line\n   ....:         break\n   ....:         \n    18  :   mp4 [360x640]\n']], ['How can I create a list with the first column?'], 2, 1], [(16257087, 0), [['Checks whether the connection to the server is working. If the connection has gone down and auto-reconnect is enabled an attempt to reconnect is made. If the connection is down and auto-reconnect is disabled, mysql_ping() returns an error.'], ['-10000']], [[' LOAD DATA INFILE \'data.txt\' INTO TABLE tbl_name\n  FIELDS TERMINATED BY \',\' ENCLOSED BY \'"\'\n  LINES TERMINATED BY \'\\r\\n\'\n  IGNORE 1 LINES;\n']], ['Download a file and push into MySQL without timing out in Python'], 2, 0], [(16257087, 1), [['-10000'], ['-10000']], [[' # Prepare queue and end signaling handler\nq = queue.Queue()\ndone = threading.Event()\n\n# Function that fetches items from q and puts them into db after\n# certain amount is reached\ndef store_db():\n    items=[]\n\n    # Until we set done\n    while not done.is_set():\n        try:\n            # We may have 500 records and thread be done... prevent deadlock\n            items.append(q.get(timeout=5))\n            if len(items) > 1000:\n                insert_into(items)\n                items = []\n            q.task_done()\n         # If you wait longer then 5 seconds < exception\n         except queue.Empty: pass\n\n    if items:\n        insert_into(items)\n\n# Fetch all data in a loop\ndef continous_reading():\n    # Fetch row\n    q.put(row)\n\n# Start storer thread\nt = threading.Thread(target=store_db)\nt.daemon = True\nt.start()\n\ncontinous_reading()\nq.join() # Wait for all task to be processed\ndone.set() # Signal store_db that it can terminate\nt.join() # to make sure the items buffer is stored into the db\n']], ['Download a file and push into MySQL without timing out in Python'], 2, 1], [(16367823, 0), [['Convert the integer to a string, then the individual characters back to integers:'], ['Demo:']], [[' def sum_of_squares_of_digits(value):\n    return sum(int(c) ** 2 for c in str(value))\n']], ['Python Sum of Squares Function'], 2, 1], [(16367823, 1), [['Demo:'], ['-10000']], [[' >>> def sum_of_squares_of_digits(value):\n...     return sum(int(c) ** 2 for c in str(value))\n... \n>>> sum_of_squares_of_digits(987)\n194\n']], ['Python Sum of Squares Function'], 2, 0], [(16391808, 0), [['However, since your sentiment score is a simple lookup, the best approach would be to build a dictionary with the sentiment scores, then lookup each word in the dictionary to calculate the overall sentiment of the tweet:'], ['This line does the calculation:']], [[' import csv\nimport json\n\nscores = {}  # empty dictionary to store scores for each word\n\nwith open(\'sentimentfile.txt\') as f:\n    reader = csv.reader(f, delimiter=\'\\t\')\n    for row in reader:\n        scores[row[0].strip()] = int(row[1].strip()) \n\n\nwith open(\'tweetsfile.txt\') as f:\n    for line in f:\n        tweet = json.loads(line)\n        text = tweet.get(\'text\',\'\').encode(\'utf-8\')\n        if text:\n            total_sentiment = sum(scores.get(word,0) for word in text.split())\n            print("{}: {}".format(text,score))\n']], ['how to properly loop through two files comparing strings in both files against each other'], 3, 1], [(16391808, 1), [['This line does the calculation:'], ['It is a shorter way to write this loop:']], [[' total_sentiment = sum(scores.get(word,0) for word in text.split())\n']], ['how to properly loop through two files comparing strings in both files against each other'], 3, 0], [(16391808, 2), [['It is a shorter way to write this loop:'], ['The  get  method of dictionaries takes a second optional argument to return a custom value when the key cannot be found; if you omit this second argument, it will return  None . In my loop I am using it to return 0 if the word has no score.']], [[' tweet_score = []\nfor word in text.split():\n    if word in scores:\n        tweet_score[word] = scores[word]\n\ntotal_score = sum(tweet_score)\n']], ['how to properly loop through two files comparing strings in both files against each other'], 3, 0], [(16397116, 0), [['For example, here is a complete transcript over HTTP. First, we need to setup the modem and connection information. All these commands should get a response of  OK  from the modem.'], ['Next, we prepare the message:']], [[' AT+CMMSINIT # Initialize the MMS method\nAT+CMMSCURL="some.url.com" # the MMS center URL\nAT+CMMSCID=1 # Set bearer\nAT+CMMSPROTO="1.1.1.1",8080 # MMS Proxy information\nAT+SAPBR=3,1,"Contype","GPRS" # How you are sending\nAT+SAPBR=3,1,"APN","foobar" # Set the APN\nAT+SAPBR=1,1 # Activate the bearer context\n']], ['How can I send an MMS via a GSM/GPRS modem connected to a linux computer?'], 2, 0], [(16397116, 1), [['Next, we prepare the message:'], ['This of course, is specific to the modem that I was using. Your results may vary. I can tell you that this is an exercise in futility. Go with a proper provider if you want to actually send MMS messages.']], [[' > AT+CMMSEDIT=1  # Enter edit mode\nOK\n> AT+CMMSDOWN="PIC",54321,30000 # Download a pic that is 54321 bytes\n                                # and set the latency\n                                # for the download to 30000 ms\nCONNECT                         # This means, ready to receive data\n                                # so send your file\nOK                              # Data received\n> AT+CMMSRECP="123456789"       # Set the recipient\nOK\n> AT+CMMSVIEW                   # View your message\n(your message)\nOK\n> AT+CMMSSEND                   # Send the message\nOK                              # Message sent\n> AT+CMMSEDIT=0                 # Exit edit mode, and clear the buffer\nOK\n']], ['How can I send an MMS via a GSM/GPRS modem connected to a linux computer?'], 2, 0], [(16402525, 0), [["You'd need to create a wrapper function; this is easy enough:"], ['The above method reads the file by lines but yields the result split on whitespace. Use it like:']], [[' def read_by_tokens(fileobj):\n    for line in fileobj:\n        for token in line.split():\n            yield token\n']], ['Python: Read whitespace separated strings from file similar to readline'], 3, 1], [(16402525, 1), [['The above method reads the file by lines but yields the result split on whitespace. Use it like:'], ['Because  read_by_tokens()  is a generator, you either need to loop directly over the function result, or use the  next()  function  to get tokens one by one:']], [[" with open('somefilename') as f:\n    for token in read_by_tokens(f):\n        print(token)\n"]], ['Python: Read whitespace separated strings from file similar to readline'], 3, 0], [(16402525, 2), [['Because  read_by_tokens()  is a generator, you either need to loop directly over the function result, or use the  next()  function  to get tokens one by one:'], ['-10000']], [[" with open('somefilename') as f:\n    tokenized = read_by_tokens(f)\n\n    # read first two tokens separately\n    first_token = next(tokenized)\n    second_token = next(tokenized)\n\n    for token in tokenized:\n        # loops over all tokens *except the first two*\n        print(token)\n"]], ['Python: Read whitespace separated strings from file similar to readline'], 3, 0], [(16421050, 1), [['I think it would be useful to have this in a function:'], ['here is using it to show that it works!']], [[' def customize_string(string,add_on):\n    if "small" in string:\n        line = string.split()\n        line[0] += add_on\n        line[-1] += add_on\n        return "  ".join(line)\n    else:\n        return string\n']], ['Find and replace a string in Python'], 3, 1], [(16421050, 2), [['here is using it to show that it works!'], ['-10000']], [[' In [219]: customize_string(line,"Short")\nOut[219]: \'TeacherShort  =  Small  |1-2|  StudentShort\'\n']], ['Find and replace a string in Python'], 3, 0], [(16500670, 0), [['You could try something like this:'], ['Here is what the  any  piece would look like if we replaced it with a list comprehension and took out the equality comparison:']], [[" In [1]: m = 'college'\n\nIn [2]: s = 'col'\n\nIn [3]: if any(m[i:i+len(s)] == s for i in range(len(m)-len(s)+1)):\n   ...:     print 'Present'\n   ...: else:\n   ...:     print 'Not present'\n   ...:     \nPresent\n"]], ['Method to find substring'], 2, 1], [(16515465, 0), [['I posted another answer because for  the example given here   numpy.memmap  worked:'], ['If the sizes are constant, you can load the data in a 2D array like:']], [[" offset = 0\ndata1 = np.memmap('tmp', dtype='i', mode='r+', order='F',\n                  offset=0, shape=(size1))\noffset += size1*byte_size\ndata2 = np.memmap('tmp', dtype='i', mode='r+', order='F',\n                  offset=offset, shape=(size2))\noffset += size1*byte_size\ndata3 = np.memmap('tmp', dtype='i', mode='r+', order='F',\n                  offset=offset, shape=(size3))\n"]], ['Is it possible to map a discontiuous data on disk to an array with python?'], 2, 1], [(16515465, 1), [['If the sizes are constant, you can load the data in a 2D array like:'], ['You can change the  memmap  object as long as you want. It is even possible to make arrays sharing the same elements. In that case the changes made in one are automatically updated in the other.']], [[" shape = (total_length/size,size)\ndata = np.memmap('tmp', dtype='i', mode='r+', order='F', shape=shape)\n"]], ['Is it possible to map a discontiuous data on disk to an array with python?'], 2, 0], [(16522362, 0), [['Use  str.join() :'], ['The string on which you call this is used as the delimiter between the strings in  l :']], [[" s = ''.join(l)\n"]], ['Concatenate elements of a list'], 3, 1], [(16522362, 1), [['The string on which you call this is used as the delimiter between the strings in  l :'], ['Note that  str.join()  will loop over the input sequence  twice . Once to calculate how big the output string needs to be, and once again to build it. As a side-effect, that means that using a list comprehension instead of a generator expression is faster:']], [[" >>> l=['a', 'b', 'c']\n>>> ''.join(l)\n'abc'\n>>> '-'.join(l)\n'a-b-c'\n>>> ' - spam ham and eggs - '.join(l)\n'a - spam ham and eggs - b - spam ham and eggs - c'\n"]], ['Concatenate elements of a list'], 3, 1], [(16530710, 0), [['Check this out:'], ['To retrieve, ']], [[" >>> tst =  {'taste': ('sweet', 'sour', 'juicy', 'melon-like')}\n>>> tst.get('taste', ()) #default to () if does not exist.  \n('sweet', 'sour', 'juicy', 'melon-like')\n>>> key_list=['yuck!','tasty','smoothie']\n>>> tst['taste'] = tst.get('taste') + tuple(key_list)\n>>> tst\n{'taste': ('sweet', 'sour', 'juicy', 'melon-like', 'yuck!', 'tasty', 'smoothie')}\n"]], ['Python: Append a list to an existing list assigned to a key in a dictionary?'], 2, 1], [(16595299, 1), [['So the solution OP suggested was instead of replacing the string in the line, to simply rewrite the entire line like this:'], ['Another solution would be to use a regular expression ( re.sub()  instead of  line.replace() )']], [[' for line in f1:\n    for i in range(len(KEYWORDS)):\n        if line.startswith("#define") and KEYWORDS[i] in line:\n            line = "#define " + KEYWORDS[i] + " " + str(VALS[i])+"\\n"\n    f2.write(line)\n']], ['Python script to replace #define values in C file'], 2, 1], [(16615630, 0), [['How about?'], ['Or, as you had it']], [[' path2 = \'"C:\\\\Users\\\\bgbesase\\\\Documents\\\\Brent\\\\Code\\\\Visual Studio\' + \'"\'\n']], ['Adding a simple value to a string'], 3, 1], [(16615630, 1), [['Or, as you had it'], ["It's also worth mentioning that you can use raw strings (r'stuff') to avoid having to escape backslashes. Ex."]], [[' final = path2 + w\n']], ['Adding a simple value to a string'], 3, 1], [(16615630, 2), [["It's also worth mentioning that you can use raw strings (r'stuff') to avoid having to escape backslashes. Ex."], ['-10000']], [[' path2 = r\'"C:\\Users\\bgbesase\\Documents\\Brent\\Code\\Visual Studio\'\n']], ['Adding a simple value to a string'], 3, 0], [(16659818, 0), [["Here's a more direct way than @Jeff's answer, telling  loadtxt  to load it in straight to a complex array, using a helper function  parse_pair  that maps  (1.2,0.16)  to  1.20+0.16j :"], ['Or in pandas:']], [[" >>> import re\n>>> import numpy as np\n\n>>> pair = re.compile(r'\\(([^,\\)]+),([^,\\)]+)\\)')\n>>> def parse_pair(s):\n...    return complex(*map(float, pair.match(s).groups()))\n\n>>> s = '''1 (1.2,0.16) (2.8,1.1)\n2 (2.85,6.9) (5.8,2.2)'''\n>>> from cStringIO import StringIO\n>>> f = StringIO(s)\n\n>>> np.loadtxt(f, delimiter=' ', dtype=np.complex,\n...            converters={1: parse_pair, 2: parse_pair})\narray([[ 1.00+0.j  ,  1.20+0.16j,  2.80+1.1j ],\n       [ 2.00+0.j  ,  2.85+6.9j ,  5.80+2.2j ]])\n"]], ['How to read complex numbers from file with numpy?'], 2, 1], [(16659818, 1), [['Or in pandas:'], ['-10000']], [[" >>> import pandas as pd\n>>> f.seek(0)\n>>> pd.read_csv(f, delimiter=' ', index_col=0, names=['a', 'b'],\n...             converters={1: parse_pair, 2: parse_pair})\n             a           b\n1  (1.2+0.16j)  (2.8+1.1j)\n2  (2.85+6.9j)  (5.8+2.2j)\n"]], ['How to read complex numbers from file with numpy?'], 2, 1], [(16661101, 0), [['You could do this:'], ['Result:']], [[' import numpy as np\nfrom scipy.sparse import csr_matrix\n\nx = np.arange(5)+1\n\ny = [1, 0, 0, 1, 2]\ny = csr_matrix(y)\n\nx2 = 1.0 / np.matrix(x)\n\nz = y.multiply(x2)\n']], ['How to do operations with two vectors of different format in python'], 2, 1], [(16661101, 1), [['Result:'], ['-10000']], [[' >>> z\nmatrix([[ 1.  ,  0.  ,  0.  ,  0.25,  0.4 ]])\n']], ['How to do operations with two vectors of different format in python'], 2, 0], [(16689117, 0), [['A membership check on a set will be significantly faster than manually iterating and checking:'], ['Note that it may be worth swapping what data is in the set - if  main_list  is longer, it will be more efficient to make the set of that data.']], [[" children = {child.get('value') for child in xml_data}\nfor item in main_list:\n    if item[4] in children:\n        print(item[4])\n"]], ['Compare two lists in python and print the output'], 4, 1], [(16689117, 1), [['Note that it may be worth swapping what data is in the set - if  main_list  is longer, it will be more efficient to make the set of that data.'], ["Note that a set will  not  handle duplicate values or order on the set side - if that is important, this isn't a valid solution. This version will only use the order/duplicates from the data you are iterating over. If that isn't valid, then you can still process the data beforehand, and use  itertools.product()  to iterate a little quicker."]], [[" items = {item[4] for item in main_list}\nfor child in xml_data:\n    value = child.get('value')\n    if value in items:\n        print(value)\n"]], ['Compare two lists in python and print the output'], 4, 1], [(16689117, 2), [["Note that a set will  not  handle duplicate values or order on the set side - if that is important, this isn't a valid solution. This version will only use the order/duplicates from the data you are iterating over. If that isn't valid, then you can still process the data beforehand, and use  itertools.product()  to iterate a little quicker."], ["As Karl Knechtel points out, if you really don't care about order to duplicates  at all , you can just do a set intersection:"]], [[" items = [item[4] for item in main_list]\nchildren = [child.get('value') for child in xml_data]\n\nfor item, child in itertools.product(items, children):\n    if item == child:\n        print(item)\n"]], ['Compare two lists in python and print the output'], 4, 1], [(16689117, 3), [["As Karl Knechtel points out, if you really don't care about order to duplicates  at all , you can just do a set intersection:"], ['-10000']], [[" for item in ({child.get('value') for child in xml_data} &\n             {item[4] for item in main_list}):\n    print(item)\n"]], ['Compare two lists in python and print the output'], 4, 1], [(16689457, 0), [['try the following:'], ['If you want a list of integers rather than a list of strings you can use a list comprehension by adding the following line:']], [[' import re\n\nnumber_regex = r\'#define\\s+VERSION_M[AJIN]+OR\\s+(\\d+)\'\n\nwith open("guidefs.h") as f:\n    your_text = f.read()\n    all_numbers = re.findall(number_regex, your_text)\n    # This will return [\'2\', \'1\']\n']], ['Read a number in a word from a file in python'], 2, 1], [(16689457, 1), [['If you want a list of integers rather than a list of strings you can use a list comprehension by adding the following line:'], ['-10000']], [[' all_numbers = [int(x) for x in all_numbers]\n# This will return [2, 1]\n']], ['Read a number in a word from a file in python'], 2, 0], [(16750376, 0), [['You can use inheritance:'], ["but it's probably more useful in this case to use composition."]], [[' class FileProxyGetter(ProxyGetter):\n    ...\n    def MakeProxy(self, *args, **kwargs):\n        return Proxy.fromstring(*args, **kwargs)\n    def Get(self):\n        ...\n           proxies.append(self.MakeProxy(l[:-1]))\n        ...\n    ...\nclass FileSecureProxyGetter(FileProxyGetter):\n    def MakeProxy(self, *args, **kwargs):\n        return SecureProxy.fromstring(*args, **kwargs)\n']], ['Universally create Derived class from Base in python'], 5, 1], [(16773583, 0), [['Looks like you forgot to set  self.inLink = False  in  handle_starttag  by default:'], ['prints:']], [[' from HTMLParser import HTMLParser\n\n\nclass AllLanguages(HTMLParser):\n    def __init__(self):\n        HTMLParser.__init__(self)\n        self.inLink = False\n        self.dataArray = []\n        self.countLanguages = 0\n        self.lasttag = None\n        self.lastname = None\n        self.lastvalue = None\n\n    def handle_starttag(self, tag, attrs):\n        self.inLink = False\n        if tag == \'a\':\n            for name, value in attrs:\n                if name == \'class\' and value == \'Vocabulary\':\n                    self.countLanguages += 1\n                    self.inLink = True\n                    self.lasttag = tag\n\n    def handle_endtag(self, tag):\n        if tag == "a":\n            self.inlink = False\n\n    def handle_data(self, data):\n        if self.lasttag == \'a\' and self.inLink and data.strip():\n            print data\n\n\nparser = AllLanguages()\nparser.feed("""\n<html>\n<head><title>Test</title></head>\n<body>\n<a href="http://wold.livingsources.org/vocabulary/1" title="Swahili" class="Vocabulary">Swahili</a>\n<a href="http://wold.livingsources.org/contributor#schadebergthilo" title="Thilo Schadeberg" class="Contributor">Thilo Schadeberg</a>\n<a href="http://wold.livingsources.org/vocabulary/2" title="English" class="Vocabulary">English</a>\n<a href="http://wold.livingsources.org/vocabulary/2" title="Russian" class="Vocabulary">Russian</a>\n</body>\n</html>""")\n']], ['Python: Extracting specific data with html parser'], 2, 1], [(16773583, 1), [['prints:'], ['Also, take a look at:']], [[' Swahili\nEnglish\nRussian\n']], ['Python: Extracting specific data with html parser'], 2, 0], [(16782291, 0), [['A bit string formatting might help:'], ['results in:']], [[" >>> data = [['Knight', '500', '500', '0', '0'],\n            ['Mage', '0', '0', '500', '500'],\n            ['Mage', '0', '0', '500', '500'],\n            ['Mage', '0', '0', '500', '500'],\n            ['Mage', '0', '0', '500', '500']]\n\n>>> frmt = '{:10s}' + 4 * '{:>12s}'\n>>> for line in data::\n        print(frmt.format(*line))\n"]], ['How do I convert data from a list of lists to a readable table (or group of columns)?'], 2, 1], [(16782291, 1), [['results in:'], ['-10000']], [[' Knight             500         500           0           0\nMage                 0           0         500         500\nMage                 0           0         500         500\nMage                 0           0         500         500\nMage                 0           0         500         500\n']], ['How do I convert data from a list of lists to a readable table (or group of columns)?'], 2, 0], [(16862690, 0), [["Well, you'll have to find some way to pass the  engine  variable to your  custom_db_api  module. This might be marginally cleaner..."], ["...or if you can infer the correct engine initialization parameter from some 'global', like  sys.argv , you could use something like this..."]], [[" Base = declarative_base()\n\nclass Something(Base):\n    pass\n\ndef initialize(engine):\n    Something.__table__ = Table('something', Base.metadata, autoload_with=engine)\n"]], ['How to dynamically create classes inside a module-level initialize() method in Python'], 2, 1], [(16862690, 1), [["...or if you can infer the correct engine initialization parameter from some 'global', like  sys.argv , you could use something like this..."], ['It kinda depends on how you intend to tell the program which DB to use.']], [[" import sys\n\nBase = declarative_base()\nif len(sys.argv) > 1 and sys.argv[1] == '--use-alt-db':\n    engine = create_engine('mysql://user:pass@alt_host/db_name')\nelse:\n    engine = create_engine('mysql://user:pass@main_host/db_name')\n\ntable = Table('something', Base.metadata, autoload_with=engine)\n\nclass Something(Base):\n    __table__ = table\n"]], ['How to dynamically create classes inside a module-level initialize() method in Python'], 2, 1], [(16876342, 0), [["If you're on linux, you may try this to get the MAC address:"], ['For general string extraction, you may use the  re  module:']], [[" iface = 'wlan0'\nmac_addr = open('/sys/class/net/%s/address' % iface).read().rstrip()\n"]], ['Python string extraction from Subprocess'], 2, 0], [(16876342, 1), [['For general string extraction, you may use the  re  module:'], ['Note that my version of ifconfig (net-tools 1.60) uses  ether  rather than  HWaddr , illustrating one problem of parsing the output of such programs.']], [[' import subprocess, re\n\nRE_MAC = re.compile(r\'\\bHWaddr\\s+(((?(2):|)[\\dA-Fa-f]{2}){6})\\b\')\nmatch = RE_MAC.search(subprocess.check_output(["ifconfig", "wlan0"]))\nif match:\n    mac_addr = match.group(1)\n']], ['Python string extraction from Subprocess'], 2, 1], [(16897609, 0), [['Yes. You just need to save a reference to the 2nd frame. Something like this should suffice:'], ["Then in the first frame's close method, you can just do something like this:"]], [[' self.secondFrame = MySecondFrame()\n']], ['Wxpython closing windows'], 2, 0], [(16897609, 1), [["Then in the first frame's close method, you can just do something like this:"], ['However, I should note that creating a frame without the usual toolbar goes against most OS GUI guidelines and users will likely be irritated by that design decision.']], [[' self.secondFrame.Close()\n']], ['Wxpython closing windows'], 2, 0], [(16965782, 0), [["I'm a little hazy on what you actually want here, but maybe something like:"], ['Example:']], [[" d = {k:v for k,v in locals().items() if v is not None and not k.startswith('__')}\n"]], ['Dictionary from variables that may not be initialized'], 2, 1], [(16965782, 1), [['Example:'], ['-10000']], [[" >>> x = 1\n>>> y = 3\n>>> z = None\n>>> d = {k:v for k,v in locals().items() if v is not None and not k.startswith('__')}\n>>> d\n{'y': 3, 'x': 1}\n"]], ['Dictionary from variables that may not be initialized'], 2, 1], [(16980554, 0), [['Normally when you are developing a single application your directory structure will be similar to'], ['You can import other modules of your application easily. For example, in  pkg_b/bar.py  you might have']], [[' src/\n   |-myapp/\n          |-pkg_a/\n                 |-__init__.py\n                 |-foo.py\n          |-pkg_b/\n                 |-__init__.py\n                 |-bar.py\n   |-myapp.py\n']], ['Developing Python modules - adding them to the Path'], 3, 0], [(16983863, 0), [['Given:'], ['All of these techniques accomplish your goal:']], [[' x0 = 1\ndef fun2(f1, x):\n    return f1(x)\n']], ['How to pass additional parameters (besides of arguments) to a function in Python'], 2, 0], [(16983863, 1), [['All of these techniques accomplish your goal:'], ["Note that writing  c=  arguments wasn't always strictly required in the calls -- I just put it in all of the usage examples for consistency and because it makes it clearer how it's being passed."]], [[' #### #0 -- function attributes\ndef fun1(x):\n    return x + fun1.c\n\nfun1.c = 1;  y = fun2(fun1, x0);   print(y)   # --> 2\nfun1.c = 2;  y = fun2(fun1, x0);   print(y)   # --> 3\n\n#### #1 -- closure\ndef fun1(c):\n    def wrapper(x):\n        return x + c\n    return wrapper\n\ny = fun2(fun1(c=1), x0);   print(y)   # --> 2\ny = fun2(fun1(c=2), x0);   print(y)   # --> 3\n\n#### #2 -- functools.partial object\nfrom functools import partial\n\ndef fun1(x, c):\n    return x + c\n\ny = fun2(partial(fun1, c=1), x0);   print(y)   # --> 2\ny = fun2(partial(fun1, c=2), x0);   print(y)   # --> 3\n\n#### #3 -- function object (functor)\nclass Fun1(object):\n    def __init__(self, c):\n        self.c = c\n    def __call__(self, x):\n        return x + self.c\n\ny = fun2(Fun1(c=1), x0);   print(y)   # --> 2\ny = fun2(Fun1(c=2), x0);   print(y)   # --> 3\n\n#### #4 -- function decorator\ndef fun1(x, c):\n    return x + c\n\ndef decorate(c):\n    def wrapper(f):\n        def wrapped(x):\n            return f(x, c)\n        return wrapped\n    return wrapper\n\ny = fun2(decorate(c=1)(fun1), x0);   print(y)   # --> 2\ny = fun2(decorate(c=2)(fun1), x0);   print(y)   # --> 3\n']], ['How to pass additional parameters (besides of arguments) to a function in Python'], 2, 1], [(17013381, 0), [['The  datetime  object itself has a  .weekday()  attribute. You can add these in a separate loop:'], ['For your example code, that gives:']], [[' dateList = [(d, d.weekday()) for d in dateList]\n']], ['List of (date, day_of_week) tuples'], 3, 1], [(17013381, 1), [['For your example code, that gives:'], ['You can combine it with your existing list comprehension by creating an extra nested loop with one element:']], [[' [(datetime.datetime(2013, 2, 16, 0, 0), 5), (datetime.datetime(2013, 2, 17, 0, 0), 6), (datetime.datetime(2013, 2, 18, 0, 0), 0), (datetime.datetime(2013, 2, 19, 0, 0), 1), (datetime.datetime(2013, 2, 20, 0, 0), 2), (datetime.datetime(2013, 2, 21, 0, 0), 3), (datetime.datetime(2013, 2, 22, 0, 0), 4), (datetime.datetime(2013, 2, 23, 0, 0), 5), (datetime.datetime(2013, 2, 24, 0, 0), 6), (datetime.datetime(2013, 2, 25, 0, 0), 0), (datetime.datetime(2013, 2, 26, 0, 0), 1), (datetime.datetime(2013, 2, 27, 0, 0), 2), (datetime.datetime(2013, 2, 28, 0, 0), 3), (datetime.datetime(2013, 3, 1, 0, 0), 4), (datetime.datetime(2013, 3, 2, 0, 0), 5), (datetime.datetime(2013, 3, 3, 0, 0), 6), (datetime.datetime(2013, 3, 4, 0, 0), 0), (datetime.datetime(2013, 3, 5, 0, 0), 1), (datetime.datetime(2013, 3, 6, 0, 0), 2), (datetime.datetime(2013, 3, 7, 0, 0), 3), (datetime.datetime(2013, 3, 8, 0, 0), 4), (datetime.datetime(2013, 3, 9, 0, 0), 5), (datetime.datetime(2013, 3, 10, 0, 0), 6), (datetime.datetime(2013, 3, 11, 0, 0), 0), (datetime.datetime(2013, 3, 12, 0, 0), 1), (datetime.datetime(2013, 3, 13, 0, 0), 2), (datetime.datetime(2013, 3, 14, 0, 0), 3), (datetime.datetime(2013, 3, 15, 0, 0), 4), (datetime.datetime(2013, 3, 16, 0, 0), 5), (datetime.datetime(2013, 3, 17, 0, 0), 6), (datetime.datetime(2013, 3, 18, 0, 0), 0), (datetime.datetime(2013, 3, 19, 0, 0), 1), (datetime.datetime(2013, 3, 20, 0, 0), 2), (datetime.datetime(2013, 3, 21, 0, 0), 3), (datetime.datetime(2013, 3, 22, 0, 0), 4), (datetime.datetime(2013, 3, 23, 0, 0), 5), (datetime.datetime(2013, 3, 24, 0, 0), 6), (datetime.datetime(2013, 3, 25, 0, 0), 0), (datetime.datetime(2013, 3, 26, 0, 0), 1), (datetime.datetime(2013, 3, 27, 0, 0), 2), (datetime.datetime(2013, 3, 28, 0, 0), 3), (datetime.datetime(2013, 3, 29, 0, 0), 4), (datetime.datetime(2013, 3, 30, 0, 0), 5), (datetime.datetime(2013, 3, 31, 0, 0), 6), (datetime.datetime(2013, 4, 1, 0, 0), 0), (datetime.datetime(2013, 4, 2, 0, 0), 1), (datetime.datetime(2013, 4, 3, 0, 0), 2), (datetime.datetime(2013, 4, 4, 0, 0), 3), (datetime.datetime(2013, 4, 5, 0, 0), 4), (datetime.datetime(2013, 4, 6, 0, 0), 5), (datetime.datetime(2013, 4, 7, 0, 0), 6), (datetime.datetime(2013, 4, 8, 0, 0), 0), (datetime.datetime(2013, 4, 9, 0, 0), 1), (datetime.datetime(2013, 4, 10, 0, 0), 2), (datetime.datetime(2013, 4, 11, 0, 0), 3), (datetime.datetime(2013, 4, 12, 0, 0), 4), (datetime.datetime(2013, 4, 13, 0, 0), 5), (datetime.datetime(2013, 4, 14, 0, 0), 6), (datetime.datetime(2013, 4, 15, 0, 0), 0), (datetime.datetime(2013, 4, 16, 0, 0), 1), (datetime.datetime(2013, 4, 17, 0, 0), 2), (datetime.datetime(2013, 4, 18, 0, 0), 3), (datetime.datetime(2013, 4, 19, 0, 0), 4), (datetime.datetime(2013, 4, 20, 0, 0), 5), (datetime.datetime(2013, 4, 21, 0, 0), 6), (datetime.datetime(2013, 4, 22, 0, 0), 0), (datetime.datetime(2013, 4, 23, 0, 0), 1), (datetime.datetime(2013, 4, 24, 0, 0), 2), (datetime.datetime(2013, 4, 25, 0, 0), 3), (datetime.datetime(2013, 4, 26, 0, 0), 4), (datetime.datetime(2013, 4, 27, 0, 0), 5), (datetime.datetime(2013, 4, 28, 0, 0), 6), (datetime.datetime(2013, 4, 29, 0, 0), 0), (datetime.datetime(2013, 4, 30, 0, 0), 1), (datetime.datetime(2013, 5, 1, 0, 0), 2), (datetime.datetime(2013, 5, 2, 0, 0), 3), (datetime.datetime(2013, 5, 3, 0, 0), 4), (datetime.datetime(2013, 5, 4, 0, 0), 5), (datetime.datetime(2013, 5, 5, 0, 0), 6), (datetime.datetime(2013, 5, 6, 0, 0), 0), (datetime.datetime(2013, 5, 7, 0, 0), 1), (datetime.datetime(2013, 5, 8, 0, 0), 2), (datetime.datetime(2013, 5, 9, 0, 0), 3), (datetime.datetime(2013, 5, 10, 0, 0), 4), (datetime.datetime(2013, 5, 11, 0, 0), 5), (datetime.datetime(2013, 5, 12, 0, 0), 6), (datetime.datetime(2013, 5, 13, 0, 0), 0), (datetime.datetime(2013, 5, 14, 0, 0), 1), (datetime.datetime(2013, 5, 15, 0, 0), 2), (datetime.datetime(2013, 5, 16, 0, 0), 3), (datetime.datetime(2013, 5, 17, 0, 0), 4), (datetime.datetime(2013, 5, 18, 0, 0), 5), (datetime.datetime(2013, 5, 19, 0, 0), 6), (datetime.datetime(2013, 5, 20, 0, 0), 0), (datetime.datetime(2013, 5, 21, 0, 0), 1), (datetime.datetime(2013, 5, 22, 0, 0), 2), (datetime.datetime(2013, 5, 23, 0, 0), 3), (datetime.datetime(2013, 5, 24, 0, 0), 4), (datetime.datetime(2013, 5, 25, 0, 0), 5), (datetime.datetime(2013, 5, 26, 0, 0), 6), (datetime.datetime(2013, 5, 27, 0, 0), 0), (datetime.datetime(2013, 5, 28, 0, 0), 1), (datetime.datetime(2013, 5, 29, 0, 0), 2), (datetime.datetime(2013, 5, 30, 0, 0), 3), (datetime.datetime(2013, 5, 31, 0, 0), 4), (datetime.datetime(2013, 6, 1, 0, 0), 5), (datetime.datetime(2013, 6, 2, 0, 0), 6), (datetime.datetime(2013, 6, 3, 0, 0), 0), (datetime.datetime(2013, 6, 4, 0, 0), 1), (datetime.datetime(2013, 6, 5, 0, 0), 2), (datetime.datetime(2013, 6, 6, 0, 0), 3), (datetime.datetime(2013, 6, 7, 0, 0), 4), (datetime.datetime(2013, 6, 8, 0, 0), 5), (datetime.datetime(2013, 6, 9, 0, 0), 6), (datetime.datetime(2013, 6, 10, 0, 0), 0), (datetime.datetime(2013, 6, 11, 0, 0), 1), (datetime.datetime(2013, 6, 12, 0, 0), 2), (datetime.datetime(2013, 6, 13, 0, 0), 3), (datetime.datetime(2013, 6, 14, 0, 0), 4), (datetime.datetime(2013, 6, 15, 0, 0), 5), (datetime.datetime(2013, 6, 16, 0, 0), 6), (datetime.datetime(2013, 6, 17, 0, 0), 0), (datetime.datetime(2013, 6, 18, 0, 0), 1), (datetime.datetime(2013, 6, 19, 0, 0), 2), (datetime.datetime(2013, 6, 20, 0, 0), 3), (datetime.datetime(2013, 6, 21, 0, 0), 4), (datetime.datetime(2013, 6, 22, 0, 0), 5), (datetime.datetime(2013, 6, 23, 0, 0), 6), (datetime.datetime(2013, 6, 24, 0, 0), 0), (datetime.datetime(2013, 6, 25, 0, 0), 1), (datetime.datetime(2013, 6, 26, 0, 0), 2), (datetime.datetime(2013, 6, 27, 0, 0), 3), (datetime.datetime(2013, 6, 28, 0, 0), 4), (datetime.datetime(2013, 6, 29, 0, 0), 5), (datetime.datetime(2013, 6, 30, 0, 0), 6), (datetime.datetime(2013, 7, 1, 0, 0), 0), (datetime.datetime(2013, 7, 2, 0, 0), 1), (datetime.datetime(2013, 7, 3, 0, 0), 2), (datetime.datetime(2013, 7, 4, 0, 0), 3), (datetime.datetime(2013, 7, 5, 0, 0), 4), (datetime.datetime(2013, 7, 6, 0, 0), 5), (datetime.datetime(2013, 7, 7, 0, 0), 6), (datetime.datetime(2013, 7, 8, 0, 0), 0), (datetime.datetime(2013, 7, 9, 0, 0), 1), (datetime.datetime(2013, 7, 10, 0, 0), 2), (datetime.datetime(2013, 7, 11, 0, 0), 3), (datetime.datetime(2013, 7, 12, 0, 0), 4), (datetime.datetime(2013, 7, 13, 0, 0), 5), (datetime.datetime(2013, 7, 14, 0, 0), 6), (datetime.datetime(2013, 7, 15, 0, 0), 0), (datetime.datetime(2013, 7, 16, 0, 0), 1), (datetime.datetime(2013, 7, 17, 0, 0), 2), (datetime.datetime(2013, 7, 18, 0, 0), 3), (datetime.datetime(2013, 7, 19, 0, 0), 4), (datetime.datetime(2013, 7, 20, 0, 0), 5), (datetime.datetime(2013, 7, 21, 0, 0), 6), (datetime.datetime(2013, 7, 22, 0, 0), 0), (datetime.datetime(2013, 7, 23, 0, 0), 1), (datetime.datetime(2013, 7, 24, 0, 0), 2), (datetime.datetime(2013, 7, 25, 0, 0), 3), (datetime.datetime(2013, 7, 26, 0, 0), 4), (datetime.datetime(2013, 7, 27, 0, 0), 5), (datetime.datetime(2013, 7, 28, 0, 0), 6), (datetime.datetime(2013, 7, 29, 0, 0), 0), (datetime.datetime(2013, 7, 30, 0, 0), 1), (datetime.datetime(2013, 7, 31, 0, 0), 2), (datetime.datetime(2013, 8, 1, 0, 0), 3), (datetime.datetime(2013, 8, 2, 0, 0), 4), (datetime.datetime(2013, 8, 3, 0, 0), 5), (datetime.datetime(2013, 8, 4, 0, 0), 6), (datetime.datetime(2013, 8, 5, 0, 0), 0), (datetime.datetime(2013, 8, 6, 0, 0), 1), (datetime.datetime(2013, 8, 7, 0, 0), 2), (datetime.datetime(2013, 8, 8, 0, 0), 3), (datetime.datetime(2013, 8, 9, 0, 0), 4), (datetime.datetime(2013, 8, 10, 0, 0), 5)]\n']], ['List of (date, day_of_week) tuples'], 3, 0], [(17023994, 1), [['and then you can use something like'], ['-10000']], [[" product = Product.objects.get(name='Cactus')\nprice = product.pricing_set.get(currency__name='USD')\n"]], ['How to associate some value in model with ForeignKey?'], 2, 0], [(17058504, 0), [['Do something like this:'], ['For example, you want to end the input sequence by an extra newline character, then the code would be:']], [[" text = ''\nwhile True: # change this condition.\n    text += input('''Enter the paragraph :''')+'\\n' #UPDATED. Appended a \\n character.\n"]], ['Accept newline character in python'], 2, 1], [(17065086, 1), [['When invoked:'], ['given the file  test.py :']], [[' ➤ python test.py\nA.a()\nB.b()\n  I was called by __main__.A.a()\n']], ['How to get the caller class name inside a function of another class in python?'], 3, 0], [(17065086, 2), [['given the file  test.py :'], ['Not sure how it will behave when called from something other than an object.']], [[' import inspect\n\nclass A:\n  def a(self):\n    print("A.a()")\n    B().b()\n\nclass B:\n  def b(self):\n    print("B.b()")\n    stack = inspect.stack()\n    the_class = stack[1][0].f_locals["self"].__class__\n    the_method = stack[1][0].f_code.co_name\n    print("  I was called by {}.{}()".format(str(the_class), the_method))\n\nA().a()\n']], ['How to get the caller class name inside a function of another class in python?'], 3, 1], [(17065977, 0), [['Do you want something like:'], ['If everything is lists, you could also do:']], [[' tempArray = [list(reversed(x)) for x in reversed(self.topArea)]\n']], ['Inversing a twodimensional array in python'], 2, 1], [(17065977, 1), [['If everything is lists, you could also do:'], ['for a possible speed boost.']], [[' tempArray = [x[::-1] for x in reversed(self.topArea)]\n']], ['Inversing a twodimensional array in python'], 2, 1], [(17077403, 0), [["Your setter is being called, and it is causing the behavior you don't want. Tearing it down:"], ['since you call']], [[" def IdSet(self, value):\n    if not isinstance(value, basestring):\n        raise TypeError('ID must be a string.')\n    self.caseful_id = value\n    self.UpdateFromKey(ndb.Key(self.__class__, value.lower()))\n"]], ['Making id case-insensitive but case-preserving in endpoints-proto-datastore'], 3, 0], [(17077403, 1), [['since you call'], ["Since you set the  caseful_id  field  before   UpdateFromKey , there is no missing data. Instead, you could do this to set the value if not already set (and so this wouldn't be relevant for your  'GET'  method):"]], [[' self.caseful_id = value\n']], ['Making id case-insensitive but case-preserving in endpoints-proto-datastore'], 3, 0], [(17077403, 2), [["Since you set the  caseful_id  field  before   UpdateFromKey , there is no missing data. Instead, you could do this to set the value if not already set (and so this wouldn't be relevant for your  'GET'  method):"], ['-10000']], [[" def IdSet(self, value):\n    if not isinstance(value, basestring):\n        raise TypeError('ID must be a string.')\n    self.UpdateFromKey(ndb.Key(self.__class__, value.lower()))\n    if self.caseful_id is None:\n        self.caseful_id = value\n"]], ['Making id case-insensitive but case-preserving in endpoints-proto-datastore'], 3, 0], [(17086278, 0), [['Two simple ways might be:'], ['or']], [[' import os\npath = "c:\\\\Python27\\\\test"\n\nfor name in os.listdir(path):\n    if name.endswith(\'.txt\'):\n        fpath = os.path.join(path, name)\n        with open(fpath) as fin:\n            print fpath, \'opened\'\n']], ['how to iterate over all files in path?'], 2, 1], [(17086278, 1), [['or'], ['The reason is that  open()  must get a valid file name. The  *  stuff is syntactic sugar which must be dealt with separately.']], [[' import glob\npath = "c:\\\\Python27\\\\test"\n\nfor fpath in glob.glob(os.path.join(path, \'*.txt\')):\n    with open(fpath) as fin:\n        print fpath, \'opened\'\n']], ['how to iterate over all files in path?'], 2, 1], [(17103701, 0), [['Convert the innermost lists of  b  into a set( s ), and then iterate over  a  to check whether any item in  a  exist in  s  or not.'], ['O(max(len(a), tot_items_b))']], [[' tot_items_b = sum(1 for x in b for y in x) #total items in b\n']], ['Finding common elements from two lists of lists'], 5, 0], [(17103701, 1), [['O(max(len(a), tot_items_b))'], ['Demo:']], [[" def func(a, b):\n   #sets can't contain mutable items, so convert lists to tuple while storing\n\n   s = set(tuple(y) for x in b for y in x)\n   #s is set([(41, 2, 34), (98, 23, 56), (42, 25, 64),...])\n\n   return any(tuple(item) in s for item in a)\n"]], ['Finding common elements from two lists of lists'], 5, 1], [(17103701, 2), [['Demo:'], ['Help on  any :']], [[' >>> a = [[1, 2, 3], [4, 5, 6], [4, 2, 3]]\n>>> b = [[[11, 22, 3], [12, 34, 6], [41, 2, 34], [198, 213, 536], [1198, 1123, 1156]], [[11, 22, 3], [42, 25, 64], [43, 45, 23]], [[3, 532, 23], [4, 5, 6], [98, 23, 56], [918, 231, 526]]]\n>>> func(a,b)\nTrue\n']], ['Finding common elements from two lists of lists'], 5, 0], [(17103701, 3), [['Help on  any :'], ['Use set intersection to get all the common elements:']], [[' >>> print any.__doc__\nany(iterable) -> bool\n\nReturn True if bool(x) is True for any x in the iterable.\nIf the iterable is empty, return False.\n']], ['Finding common elements from two lists of lists'], 5, 0], [(17122268, 0), [['Here is an example that shows some static text in red(that always stays on top):'], ['If you want to change the static text do:']], [[' import sys\nimport curses\n\n\ncurses.initscr()\n\nif not curses.has_colors():\n    curses.endwin()\n    print "no colors"\n    sys.exit()\nelse:\n    curses.start_color()\n\ncurses.noecho()    # don\'t echo the keys on the screen\ncurses.cbreak()    # don\'t wait enter for input\ncurses.curs_set(0) # don\'t show cursor.\n\nRED_TEXT = 1\ncurses.init_pair(RED_TEXT, curses.COLOR_RED, curses.COLOR_BLACK)\n\nwindow = curses.newwin(20, 20, 0, 0)\nwindow.box()\nstaticwin = curses.newwin(5, 10, 1, 1)\nstaticwin.box()\n\nstaticwin.addstr(1, 1, "test", curses.color_pair(RED_TEXT))\n\ncur_x = 10\ncur_y = 10\nwhile True:\n    window.addch(cur_y, cur_x, \'@\')\n    window.refresh()\n    staticwin.box()\n    staticwin.refresh()\n    inchar = window.getch()\n    window.addch(cur_y, cur_x, \' \')\n    # W,A,S,D used to move around the @\n    if inchar == ord(\'w\'):\n        cur_y -= 1\n    elif inchar == ord(\'a\'):\n        cur_x -= 1\n    elif inchar == ord(\'d\'):\n        cur_x += 1\n    elif inchar == ord(\'s\'):\n        cur_y += 1\n    elif inchar == ord(\'q\'):\n        break\ncurses.endwin()\n']], ['(python) How to create static text in curses'], 2, 1], [(17122268, 1), [['If you want to change the static text do:'], ["Where the  1, 1  means to start writing from the  second  character of the  second  line(remember: coordinates start at  0 ). This is needed since the window's box is drawn on the first line and first column."]], [[' staticwin.clear()   #clean the window\nstaticwin.addstr(1, 1, "insert-text-here", curses.color_pair(RED_TEXT))\nstaticwin.box()     #re-draw the box\nstaticwin.refresh()\n']], ['(python) How to create static text in curses'], 2, 0], [(17144809, 0), [["I'd use  finditer()  with a wrapper generator:"], ['Demo:']], [[" import re\nfrom functools import partial\n\ndef _hexrepl(match):\n    return chr(int(match.group(1), 16))\nunescape = partial(re.compile(r'#([0-9A-F]{2})').sub, _hexrepl)\n\ndef pdfnames(inputtext):\n    for match in Name.finditer(inputtext):\n        yield unescape(match.group(0))\n"]], ['Translating regex match groups'], 2, 1], [(17144809, 1), [['Demo:'], ['There is no more clever way that  I  know of; the  re  engine cannot otherwise combine substitution and matching.']], [[' >>> for name in pdfnames(names):\n...     print name\n... \n/Adobe Green\n/PANTONE 5757 CV\n/paired()parentheses\n/The_Key_of_F#_Minor\n/AB\n/Name1\n/ASomewhatLongerName\n/A;Name_With-Various***Characters?\n/1.2\n/$$\n/@pattern\n/.notdef\n']], ['Translating regex match groups'], 2, 0], [(17163234, 0), [["I'll suppose that your edge list is a dictionary of lists or a list of lists, eg."], ['Or']], [[' [[4191, 949], [3002, 4028, 957], [2494, 959, 3011], [4243, 965], [1478], ...]\n']], ['How to find shortest path for raw data'], 3, 0], [(17163234, 1), [['Or'], ["I've written some code to show how the breadth first search works:"]], [[' { 0: [4191, 949],\n  1: [3002, 4028, 957],\n  2: [2494, 959, 3011],\n  3: [4243, 965],\n  4: [1478], ...}\n']], ['How to find shortest path for raw data'], 3, 0], [(17167297, 0), [['You need to first create a structure with the correct format:'], ["Note that the desired json output does not looks valud to me. Here's the output for this code:"]], [[' import json\n\ndict_ = {"20090209.02s1.1_sequence.txt": [645045714, 3559.6422951221466, 206045184], "20090209.02s1.2_sequence.txt": [645045714, 3543.8322949409485, 234618880]}\nvalues = [{"file_name": k, "file_information": v} for k, v in dict_.items()]\njson.dumps(values, indent=4)\n']], ['Convert this python dictionary into JSON format?'], 2, 1], [(17167297, 1), [["Note that the desired json output does not looks valud to me. Here's the output for this code:"], ['-10000']], [[' [\n    {\n        "file_name": "20090209.02s1.1_sequence.txt", \n        "file_information": [\n            645045714, \n            3559.6422951221466, \n            206045184\n        ]\n    }, \n    {\n        "file_name": "20090209.02s1.2_sequence.txt", \n        "file_information": [\n            645045714, \n            3543.8322949409485, \n            234618880\n        ]\n    }\n]\n']], ['Convert this python dictionary into JSON format?'], 2, 0], [(17176270, 0), [['You can use  inspect  module:'], ['prints:']], [[' import inspect\nimport sys\n\n\ndef test():\n    pass\n\nfunctions = [name for name, obj in inspect.getmembers(sys.modules[__name__], inspect.isfunction)]\nprint functions\n']], ['Finding All Defined Functions in Python Environment'], 2, 1], [(17176270, 1), [['prints:'], ['-10000']], [[" ['test']\n"]], ['Finding All Defined Functions in Python Environment'], 2, 0], [(17203403, 0), [["I guess you could use  scipy.stats.t  and it's  interval  method:"], ["Sure, you can make your own function if you like. Let's make it look like in  Mathematica :"]], [[' In [1]: from scipy.stats import t\nIn [2]: t.interval(0.95, 10, loc=1, scale=2)  # 95% confidence interval\nOut[2]: (-3.4562777039298762, 5.4562777039298762)\nIn [3]: t.interval(0.99, 10, loc=1, scale=2)  # 99% confidence interval\nOut[3]: (-5.338545334351676, 7.338545334351676)\n']], ['student t confidence interval in python'], 3, 1], [(17203403, 1), [["Sure, you can make your own function if you like. Let's make it look like in  Mathematica :"], ['Result:']], [[' from scipy.stats import t\n\n\ndef StudentTCI(loc, scale, df, alpha=0.95):\n    return t.interval(alpha, df, loc, scale)\n\nprint StudentTCI(1, 2, 10)\nprint StudentTCI(1, 2, 10, 0.99)\n']], ['student t confidence interval in python'], 3, 1], [(17203403, 2), [['Result:'], ['-10000']], [[' (-3.4562777039298762, 5.4562777039298762)\n(-5.338545334351676, 7.338545334351676)\n']], ['student t confidence interval in python'], 3, 0], [(17211188, 0), [['Due to platform differences, for precision you want to use the  timeit.default_timer  callable :'], ['Demo:']], [[' from timeit import default_timer\n\nstart = default_timer()\n\n# do stuff\n\nduration = default_timer() - start\n']], ['How to create a timer on python'], 2, 1], [(17211188, 1), [['Demo:'], ['-10000']], [[' >>> from timeit import default_timer\n>>> start = default_timer()\n>>> # Martijn reads another post somewhere\n... \n>>> print default_timer() - start\n19.1996181011\n']], ['How to create a timer on python'], 2, 1], [(17243403, 0), [["You can use the  fileinput  module, if you're trying to modify the same file:"], ['Take the advantage of sequence unpacking to store the results in variables after splitting.']], [[' >>> strs = "sample4:15"\n']], ['Replace character in line inside a file'], 3, 0], [(17243403, 1), [['Take the advantage of sequence unpacking to store the results in variables after splitting.'], ['Code:']], [[" >>> sample, value = strs.split(':')\n>>> sample\n'sample4'\n>>> value\n'15'\n"]], ['Replace character in line inside a file'], 3, 0], [(17243403, 2), [['Code:'], ['-10000']], [[' import fileinput\nfor line in fileinput.input(filename, inplace = True):\n    sample, value = line.split(\':\')\n    value = int(value)     #convert value to int for calculation purpose\n    if some_condition: \n           # do some calculations on sample and value\n           # modify sample, value if required \n\n    #now the write the data(either modified or still the old one) to back to file\n    print "{}:{}".format(sample, value)\n']], ['Replace character in line inside a file'], 3, 1], [(17250660, 0), [['You have a namespaced XML file. ElementTree is not too smart about namespaces. You need to give the  .find() ,  findall()  and  iterfind()  methods an explicit namespace dictionary. This is not documented very well:'], ['Demo:']], [[" namespaces = {'ex': 'http://www.ecb.int/vocabulary/2002-08-01/eurofxref'} # add more as needed\n\nfor cube in root.findall('.//ex:Cube[@currency]', namespaces=namespaces):\n    print(cube.attrib['currency'], cube.attrib['rate'])\n"]], ['How to parse XML file from European Central Bank with Python'], 3, 1], [(17250660, 1), [['Demo:'], ['You can use this information to search for the specific rate too; either build a dictionary, or search the XML document directly for matching currencies:']], [[" >>> import requests\n>>> r = requests.get('http://www.ecb.int/stats/eurofxref/eurofxref-daily.xml', stream=True)\n>>> from xml.etree import ElementTree as ET\n>>> tree = ET.parse(r.raw)\n>>> root = tree.getroot()\n>>> namespaces = {'ex': 'http://www.ecb.int/vocabulary/2002-08-01/eurofxref'}\n>>> for cube in root.findall('.//ex:Cube[@currency]', namespaces=namespaces):\n...     print(cube.attrib['currency'], cube.attrib['rate'])\n... \nUSD 1.3180\nJPY 128.66\nBGN 1.9558\nCZK 25.825\nDKK 7.4582\nGBP 0.85330\nHUF 298.87\nLTL 3.4528\nLVL 0.7016\nPLN 4.3289\nRON 4.5350\nSEK 8.6927\nCHF 1.2257\nNOK 7.9090\nHRK 7.4905\nRUB 43.2260\nTRY 2.5515\nAUD 1.4296\nBRL 2.9737\nCAD 1.3705\nCNY 8.0832\nHKD 10.2239\nIDR 13088.24\nILS 4.7891\nINR 78.1200\nKRW 1521.52\nMXN 17.5558\nMYR 4.2222\nNZD 1.7004\nPHP 57.707\nSGD 1.6790\nTHB 41.003\nZAR 13.4906\n"]], ['How to parse XML file from European Central Bank with Python'], 3, 1], [(17252056, 0), [['This should be an example of a nested mainloop in Tkinter:'], ['Whenever you hit the button a new mainloop is executed.']], [[" import Tkinter\n\ndef main():\n    print 'main'\n    t.mainloop()\n    print 'end main'\n\nt = Tkinter.Tk()\nb = Tkinter.Button(t, command = main)\nb.pack()\nt.mainloop()\n"]], ['Tkinter nested mainloop'], 2, 1], [(17252056, 1), [['Whenever you hit the button a new mainloop is executed.'], ['-10000']], [[' main\nmain\nmain\nmain\nmain\n# now close the window\nend main\nend main\nend main\nend main\nend main\n']], ['Tkinter nested mainloop'], 2, 0], [(17254599, 0), [['You can use   collections.defaultdict :'], ['Now iterate over  dic :']], [[' >>> from collections import defaultdict\n>>> lis = [                            \n    (1, "red"),\n    (1, "red,green"),\n    (1, "green,blue"),\n    (2, "green"),\n    (2, "yellow,blue"),\n]\n>>> dic = defaultdict(set)       #sets only contain unique items\nfor k, v in lis:\n    dic[k].update(v.split(\',\'))\n\n>>> dic\ndefaultdict(<type \'set\'>,\n{1: set([\'blue\', \'green\', \'red\']),\n 2: set([\'blue\', \'green\', \'yellow\'])})\n']], ['Can I group / aggregate elements in a list (or dict) comprehension?'], 2, 0], [(17254599, 1), [['Now iterate over  dic :'], ['-10000']], [[" >>> dic2 = defaultdict(list)\nfor k,v in dic.iteritems():\n    for val in v:\n        dic2[val].append(k)\n...         \n>>> dic2\ndefaultdict(<type 'list'>,\n{'blue': [1, 2],\n 'green': [1, 2],\n 'yellow': [2],\n 'red': [1]})\n"]], ['Can I group / aggregate elements in a list (or dict) comprehension?'], 2, 0], [(17260358, 1), [['BTW,  re.sub(..)  return substituted string. It does not replace substitute original string.'], ['Code edited to match edited question:']], [[" >>> import re\n>>> text = '   hello'\n>>> re.sub('\\s+', '', text)\n'hello'\n>>> text\n'   hello'\n"]], ['How to perform re substitutions on <p> tags within a specific class?'], 3, 0], [(17260358, 2), [['Code edited to match edited question:'], ['-10000']], [[' from bs4 import BeautifulSoup\n\nwith open(\'file.html\', \'r\') as f:\n    html_file_as_string = f.read()\nsoup = BeautifulSoup(html_file_as_string, "lxml")\nfor div in soup.find_all(\'div\', {\'class\': \'my_class\'}):\n    for p in div.findAll(\'p\'):\n        new = BeautifulSoup(u\'\\n\'.join(u\'<p>{}</p>\'.format(line.strip()) for line in p.text.splitlines() if line), \'html.parser\')\n        p.replace_with(new)\nwith open(\'file\', \'w\') as f:\n    f.write(soup.renderContents())\n']], ['How to perform re substitutions on <p> tags within a specific class?'], 3, 1], [(17270318, 0), [['-10000'], ['Examples:']], [[' board = [\n    [1,0,1,0,1],\n    [1,0,1,0,1],\n    [1,0,1,0,1],\n    [1,0,1,0,1],\n    [1,0,1,0,1]\n]\n\ndef clamp(minV,maxV,x):\n    if x < minV:\n        return minV \n    elif x > maxV:\n        return maxV\n    else:\n        return x\n\ndef getNeighbour(grid,startx,starty,radius):\n    width = len(grid[starty])\n    height = len(grid)\n    neighbourhood = []\n    for y in range(clamp(0,height,starty-radius),clamp(0,height,starty+radius)+1):\n        row = []\n        for x in range(clamp(0,width,startx-radius),clamp(0,width,startx+radius)+1):\n            if x != startx or (x==startx and  y != starty):\n                row.append(grid[y][x])\n        neighbourhood.append(row)\n    return neighbourhood\n']], ['Iterator for each item in a 2D Python list and its immediate m by n neighbourhood'], 3, 1], [(17270318, 1), [['Examples:'], ['-10000']], [[' >>> pprint(getNeighbour(board, 0, 0, 1))\n[0]\n[1, 0] (expected)\n>>> pprint(getNeighbour(board, 2, 2, 1))\n[0, 1, 0]\n[0, 0]\n[0, 1, 0] (expected)\n>>> \n']], ['Iterator for each item in a 2D Python list and its immediate m by n neighbourhood'], 3, 0], [(17270318, 2), [['-10000'], ['The run time is essentially the same as if the board were 10x10']], [[' board = [[1,0]*2000]*1000\n']], ['Iterator for each item in a 2D Python list and its immediate m by n neighbourhood'], 3, 0], [(17288571, 0), [['The  itertools  module has an  islice()  function which may help you:'], ['So for your problem, you might do:']], [[' >>> s = "abcdefghijklmnopqrstuvwxyz"\n>>> import itertools\n>>> for val in itertools.islice(s, 0, None, 8):\n...   print val\n...\na\ni\nq\ny\n>>> for val in itertools.islice(s, 1, None, 8):\n...   print val\n...\nb\nj\nr\nz\n>>> for val in itertools.islice(s, 2, None, 8):\n...   print val\n...\nc\nk\ns\n']], ['Use Python zip to save data in separate columns from a binary file'], 3, 0], [(17288571, 1), [['So for your problem, you might do:'], ['and so on. Or, better yet:']], [[' import itertools\na = [item for item in itertools.islice(e, 0, None, 8)]\nb = [item for item in itertools.islice(e, 1, None, 8)]\nc = [item for item in itertools.islice(e, 2, None, 8)]\n']], ['Use Python zip to save data in separate columns from a binary file'], 3, 1], [(17288571, 2), [['and so on. Or, better yet:'], ['Hope this helps!']], [[' columns = []\nfor n in range(8):\n    columns.append([item for item in itertools.islice(e, n, None, 8)])\n']], ['Use Python zip to save data in separate columns from a binary file'], 3, 1], [(17307474, 1), [['Pickle example:'], ['For better performance you can also use the  cPickle  module.']], [[' import pickle\ndef update():\n  lis = pickle.load( open( "lis.pkl", "rb" ) ) # Load the list\n  #do something with lis                     #modify it \n  pickle.dump( lis, open( "lis.pkl", "wb" ) )  #save it again\n']], ['how to update global variable in python'], 2, 1], [(17334702, 0), [["First, I'd suggest  defaultdict  so that referencing an index that doesn't exist will initialize it to an empty list."], ["Then when  'x3':[y2,y4]  comes in:"]], [[" from collections import defaultdict\n\ndict1 = defaultdict(list)\ndict1['x1'] = ['y1','y2']\ndict1['x2'] = ['y2','y3','y4']\ndict2 = defaultdict(list)\ndict2['y1'] = ['x1']\ndict2['y2'] = ['x1','x2']\ndict2['y3'] = ['x2']\n"]], ['inserting a new entry into adjacency list'], 2, 0], [(17334702, 1), [["Then when  'x3':[y2,y4]  comes in:"], ['using  set  to eliminate duplicate values. Obviously some of the above values would be a little more dynamic than hard coded values.']], [[" dict1['x3'] = set(dict1['x3']+[y2,y4])\nfor y in dict1['x3']:\n    dict2[y] = set(dict2[y]+'x3')\n"]], ['inserting a new entry into adjacency list'], 2, 0], [(17365289, 0), [['You can create an in-memory file with  StringIO :'], ['If you have file on disk:']], [[" from cStringIO import StringIO\nfrom flask import make_response\n\nfrom somewhere import generate_wav_file  # TODO your code here\n\n@app.route('/path')\ndef view_method():\n\n    buf = StringIO()\n\n    # generate_wav_file should take a file as parameter and write a wav in it\n    generate_wav_file(buf) \n\n    response = make_response(buf.getvalue())\n    buf.close()\n    response.headers['Content-Type'] = 'audio/wav'\n    response.headers['Content-Disposition'] = 'attachment; filename=sound.wav'\n    return response\n"]], ['How to send audio wav file generated at the server to client browser?'], 2, 1], [(17368930, 1), [['But the better way is to modify the getter:'], ['Which gives:']], [[" def __get__(self, obj, objtype):\n    print 'Retrieving', self.name\n    if obj is None:  # accessed as class attribute\n        return self  # return the descriptor itself\n    else:  # accessed as instance attribute\n        return self.val  # return a value\n"]], ['Inspecting data descriptor attributes in python'], 3, 1], [(17368930, 2), [['Which gives:'], ['-10000']], [[' Retrieving var "x"\n(\'__weakref__\', <attribute \'__weakref__\' of \'MyClass\' objects>)\n(\'x\', <__main__.RevealAccess object at 0x7f32ef989890>)\n']], ['Inspecting data descriptor attributes in python'], 3, 0], [(17374553, 0), [['You could do this:'], ['With your data, prints:']], [[" import csv\nfrom itertools import izip_longest\n\nwith open('/tmp/line.csv','r') as fin:\n    cr=csv.reader(fin)\n    n=10\n    data=izip_longest(*[iter(list(cr)[0])]*n,fillvalue='')\n    print '\\n'.join(', '.join(t) for t in data)\n"]], ['How to create a new list or new line after a certain number of iterations'], 3, 1], [(17374553, 1), [['With your data, prints:'], ['-10000']], [[' CLB, HNRG, LPI, MTDR, MVO, NRGY, PSE, PVR, RRC, WES\nACMP, ATLS, ATW, BP, BWP, COG, DGAS, DNR, EPB, EPL\nEXLP, NOV, OIS, PNRG, SEP, APL, ARP, CVX, DMLP, DRQ\nDWSN, EC, ECA, FTI, GLOG, IMO, LINE, NFX, OILT, PNG\nQRE, RGP, RRMS, SDRL, SNP, TLP, VNR, XOM, XTXI, AHGP\n']], ['How to create a new list or new line after a certain number of iterations'], 3, 0], [(17374553, 2), [['-10000'], ['Changes:']], [[" import csv\nfrom itertools import zip_longest\n\nn=10\nwith open('/tmp/rawdata.txt','r') as fin, open('/tmp/out.csv','w') as fout:\n    reader=csv.reader(fin)\n    writer=csv.writer(fout) \n    source=(e for line in reader for e in line)             \n    for t in zip_longest(*[source]*n):\n        writer.writerow(list(e for e in t if e))\n"]], ['How to create a new list or new line after a certain number of iterations'], 3, 1], [(17387219, 2), [['If you have a structured array with named columns:'], ['For your specific case you need  the following  key  function :']], [[' def mysort(data, col_name, key=None):\n    d = data.copy()\n    cols = [i[0] for i in eval(str(d.dtype))]\n    if key:\n        argsort = np.array([key(i) for i in d[col_name]]).argsort()\n    else:\n        argsort = d[col_name].argsort()\n    for col in cols:\n        d[col] = d[col][argsort]\n    return d\n']], ['Sorting numpy matrix for a given column'], 4, 0], [(17426202, 1), [['You can get  just  the current year with the  datetime  module:'], ['Now you only have to ask for a month number:']], [[' import datetime\nyear = datetime.date.today().year\n']], ['Python function that takes an input and spits out a month and how many days it has'], 4, 0], [(17426202, 2), [['Now you only have to ask for a month number:'], ['This prints the abbreviated month and the number of days:']], [[' import datetime\nimport calendar\n\ndef main():\n    year = datetime.date.today().year\n    userin = int(raw_input("Enter a month as number: "))  # Python 3: `int(input(...))` \n    print \'{}, {}\'.format(calendar.month_abbr[userin], calendar.monthrange(year, userin)[1])\n']], ['Python function that takes an input and spits out a month and how many days it has'], 4, 1], [(17426202, 3), [['This prints the abbreviated month and the number of days:'], ['-10000']], [[' Enter a month as number: 2\nFeb, 28\n']], ['Python function that takes an input and spits out a month and how many days it has'], 4, 0], [(17462994, 2), [['Maybe you are looking for something like this,'], ['You may also be wanting to  break  after  print ing - hard to know exactly what this is for.']], [[' def checkCommonNodes(id, rs):\n    id_key, id_value = id.split(\'_\')\n    for r in rs:\n        try:\n            if r[id_key] == id_value:\n                print "".join(\'{}_{}\'.format(k,v) for k,v in r.iteritems())\n        except KeyError:\n            continue\n']], ['Python getting a string (key + value) from Python Dictionary'], 3, 1], [(17471682, 0), [['This could be an enhancement to  droplevel , maybe by passing  uniquify=True'], ['First create some data']], [[" In [77]: MultiIndex.from_tuples(index_3levels.droplevel('l3').unique())\nOut[77]: \nMultiIndex\n[(0, 100), (1, 101)]\n"]], ['Remove a level from a pandas MultiIndex'], 5, 1], [(17471682, 1), [['First create some data'], ['The method shown above']], [[' In [226]: def f(i):\n            return [(i,100,1000),(i,100,1001),(i,100,1002),(i+1,101,1001)]\n\nIn [227]: l = []\n\nIn [228]: for i in range(1000000):\n             l.extend(f(i))\n\nIn [229]: index_3levels=pd.MultiIndex.from_tuples(l,names=["l1","l2","l3"])\n\nIn [230]: len(index_3levels)\nOut[230]: 4000000\n']], ['Remove a level from a pandas MultiIndex'], 5, 0], [(17471682, 2), [['The method shown above'], ["Let's split the index apart to 2 components, l1, and l2 and uniquify, much\nfaster to unique these as these are Int64Index"]], [[" In [238]: %timeit MultiIndex.from_tuples(index_3levels.droplevel(level='l3').unique())\n1 loops, best of 3: 2.26 s per loop\n"]], ['Remove a level from a pandas MultiIndex'], 5, 0], [(17471682, 3), [["Let's split the index apart to 2 components, l1, and l2 and uniquify, much\nfaster to unique these as these are Int64Index"], ['Reassemble']], [[" In [249]: l2 = index_3levels.droplevel(level='l3').droplevel(level='l1').unique()\n\nIn [250]: %timeit index_3levels.droplevel(level='l3').droplevel(level='l1').unique()\n10 loops, best of 3: 35.3 ms per loop\n\nIn [251]: l1 = index_3levels.droplevel(level='l3').droplevel(level='l2').unique()\n\nIn [252]: %timeit index_3levels.droplevel(level='l3').droplevel(level='l2').unique()\n10 loops, best of 3: 52.2 ms per loop\n\nIn [253]: len(l1)\nOut[253]: 1000001\n\nIn [254]: len(l2)\nOut[254]: 2\n"]], ['Remove a level from a pandas MultiIndex'], 5, 0], [(17471682, 4), [['Reassemble'], ['Total time about 270ms, pretty good speedup. Note that I think the ordering may be different, but I think some combination of np.repeate/np.tile will work']], [[' In [255]: %timeit MultiIndex.from_arrays([ np.repeat(l1,len(l2)), np.repeat(l2,len(l1)) ])\n10 loops, best of 3: 183 ms per loop\n']], ['Remove a level from a pandas MultiIndex'], 5, 0], [(17478779, 0), [['You can do:'], ['Or even in an "one-liner":']], [[' x,y = zip(*s)\nplt.scatter(x,y)\n']], ['Make scatter plot from set of points in tuples'], 2, 1], [(17478779, 1), [['Or even in an "one-liner":'], ['zip()  can be used to pack and unpack arrays  and when you call using  method(*list_or_tuple) , each element in the list or tuple is passed as an argument.']], [[' plt.scatter(*zip(*a))\n']], ['Make scatter plot from set of points in tuples'], 2, 1], [(17486578, 0), [["You can automate most of the work with regular python tools. Let's start with clean virtualenv."], ["(Note: don't use --egg option either on command-line or in pip.conf/pip.ini because it will break file layout making it non-importable in zip)"]], [[' [zart@feena ~]$ mkdir ziplib-demo\n[zart@feena ~]$ cd ziplib-demo\n[zart@feena ziplib-demo]$ virtualenv .\nNew python executable in ./bin/python\nInstalling setuptools.............done.\nInstalling pip...............done.\n']], ['How can you bundle all your python code into a single zip file?'], 4, 0], [(17486578, 1), [["(Note: don't use --egg option either on command-line or in pip.conf/pip.ini because it will break file layout making it non-importable in zip)"], ["Now let's pack all of them into one zip"]], [[' [zart@feena ziplib-demo]$ bin/pip install --install-option --install-lib=$PWD/unpacked waitress\nDownloading/unpacking waitress\n  Downloading waitress-0.8.5.tar.gz (112kB): 112kB downloaded\n  Running setup.py egg_info for package waitress\n\nRequirement already satisfied (use --upgrade to upgrade): setuptools in ./lib/python2.7/site-packages/setuptools-0.6c11-py2.7.egg (from waitress)\nInstalling collected packages: waitress\n  Running setup.py install for waitress\n\n    Installing waitress-serve script to /home/zart/ziplib-demo/bin\nSuccessfully installed waitress\nCleaning up...\n']], ['How can you bundle all your python code into a single zip file?'], 4, 0], [(17486578, 2), [["Now let's pack all of them into one zip"], ['Checking the result:']], [[' [zart@feena ziplib-demo]$ cd unpacked\n[zart@feena unpacked]$ ls\nwaitress  waitress-0.8.5-py2.7.egg-info\n[zart@feena unpacked]$ zip -r9 ../library.zip *\n  adding: waitress/ (stored 0%)\n  adding: waitress/receiver.py (deflated 71%)\n  adding: waitress/server.pyc (deflated 64%)\n  adding: waitress/utilities.py (deflated 62%)\n  adding: waitress/trigger.pyc (deflated 63%)\n  adding: waitress/trigger.py (deflated 61%)\n  adding: waitress/receiver.pyc (deflated 60%)\n  adding: waitress/adjustments.pyc (deflated 51%)\n  adding: waitress/compat.pyc (deflated 56%)\n  adding: waitress/adjustments.py (deflated 60%)\n  adding: waitress/server.py (deflated 68%)\n  adding: waitress/channel.py (deflated 72%)\n  adding: waitress/task.pyc (deflated 57%)\n  adding: waitress/tests/ (stored 0%)\n  adding: waitress/tests/test_regression.py (deflated 63%)\n  adding: waitress/tests/test_functional.py (deflated 88%)\n  adding: waitress/tests/test_parser.pyc (deflated 76%)\n  adding: waitress/tests/test_trigger.pyc (deflated 73%)\n  adding: waitress/tests/test_init.py (deflated 72%)\n  adding: waitress/tests/test_utilities.pyc (deflated 78%)\n  adding: waitress/tests/test_buffers.pyc (deflated 79%)\n  adding: waitress/tests/test_trigger.py (deflated 82%)\n  adding: waitress/tests/test_buffers.py (deflated 86%)\n  adding: waitress/tests/test_runner.py (deflated 75%)\n  adding: waitress/tests/test_init.pyc (deflated 69%)\n  adding: waitress/tests/__init__.pyc (deflated 21%)\n  adding: waitress/tests/support.pyc (deflated 48%)\n  adding: waitress/tests/test_utilities.py (deflated 73%)\n  adding: waitress/tests/test_channel.py (deflated 87%)\n  adding: waitress/tests/test_task.py (deflated 87%)\n  adding: waitress/tests/test_functional.pyc (deflated 82%)\n  adding: waitress/tests/__init__.py (deflated 5%)\n  adding: waitress/tests/test_compat.pyc (deflated 53%)\n  adding: waitress/tests/test_receiver.pyc (deflated 79%)\n  adding: waitress/tests/test_adjustments.py (deflated 78%)\n  adding: waitress/tests/test_adjustments.pyc (deflated 74%)\n  adding: waitress/tests/test_server.pyc (deflated 73%)\n  adding: waitress/tests/fixtureapps/ (stored 0%)\n  adding: waitress/tests/fixtureapps/filewrapper.pyc (deflated 59%)\n  adding: waitress/tests/fixtureapps/getline.py (deflated 37%)\n  adding: waitress/tests/fixtureapps/nocl.py (deflated 47%)\n  adding: waitress/tests/fixtureapps/sleepy.pyc (deflated 44%)\n  adding: waitress/tests/fixtureapps/echo.py (deflated 40%)\n  adding: waitress/tests/fixtureapps/error.py (deflated 52%)\n  adding: waitress/tests/fixtureapps/nocl.pyc (deflated 48%)\n  adding: waitress/tests/fixtureapps/getline.pyc (deflated 32%)\n  adding: waitress/tests/fixtureapps/writecb.pyc (deflated 42%)\n  adding: waitress/tests/fixtureapps/toolarge.py (deflated 37%)\n  adding: waitress/tests/fixtureapps/__init__.pyc (deflated 20%)\n  adding: waitress/tests/fixtureapps/writecb.py (deflated 50%)\n  adding: waitress/tests/fixtureapps/badcl.pyc (deflated 44%)\n  adding: waitress/tests/fixtureapps/runner.pyc (deflated 58%)\n  adding: waitress/tests/fixtureapps/__init__.py (stored 0%)\n  adding: waitress/tests/fixtureapps/filewrapper.py (deflated 74%)\n  adding: waitress/tests/fixtureapps/runner.py (deflated 41%)\n  adding: waitress/tests/fixtureapps/echo.pyc (deflated 42%)\n  adding: waitress/tests/fixtureapps/groundhog1.jpg (deflated 24%)\n  adding: waitress/tests/fixtureapps/error.pyc (deflated 48%)\n  adding: waitress/tests/fixtureapps/sleepy.py (deflated 42%)\n  adding: waitress/tests/fixtureapps/toolarge.pyc (deflated 43%)\n  adding: waitress/tests/fixtureapps/badcl.py (deflated 45%)\n  adding: waitress/tests/support.py (deflated 52%)\n  adding: waitress/tests/test_task.pyc (deflated 78%)\n  adding: waitress/tests/test_channel.pyc (deflated 78%)\n  adding: waitress/tests/test_regression.pyc (deflated 68%)\n  adding: waitress/tests/test_parser.py (deflated 80%)\n  adding: waitress/tests/test_server.py (deflated 78%)\n  adding: waitress/tests/test_receiver.py (deflated 87%)\n  adding: waitress/tests/test_compat.py (deflated 51%)\n  adding: waitress/tests/test_runner.pyc (deflated 72%)\n  adding: waitress/__init__.pyc (deflated 50%)\n  adding: waitress/channel.pyc (deflated 58%)\n  adding: waitress/runner.pyc (deflated 54%)\n  adding: waitress/buffers.py (deflated 74%)\n  adding: waitress/__init__.py (deflated 61%)\n  adding: waitress/runner.py (deflated 58%)\n  adding: waitress/parser.py (deflated 69%)\n  adding: waitress/compat.py (deflated 69%)\n  adding: waitress/buffers.pyc (deflated 69%)\n  adding: waitress/utilities.pyc (deflated 60%)\n  adding: waitress/parser.pyc (deflated 53%)\n  adding: waitress/task.py (deflated 72%)\n  adding: waitress-0.8.5-py2.7.egg-info/ (stored 0%)\n  adding: waitress-0.8.5-py2.7.egg-info/dependency_links.txt (stored 0%)\n  adding: waitress-0.8.5-py2.7.egg-info/installed-files.txt (deflated 83%)\n  adding: waitress-0.8.5-py2.7.egg-info/top_level.txt (stored 0%)\n  adding: waitress-0.8.5-py2.7.egg-info/PKG-INFO (deflated 65%)\n  adding: waitress-0.8.5-py2.7.egg-info/not-zip-safe (stored 0%)\n  adding: waitress-0.8.5-py2.7.egg-info/SOURCES.txt (deflated 71%)\n  adding: waitress-0.8.5-py2.7.egg-info/entry_points.txt (deflated 33%)\n  adding: waitress-0.8.5-py2.7.egg-info/requires.txt (deflated 5%)\n[zart@feena unpacked]$ cd ..\n']], ['How can you bundle all your python code into a single zip file?'], 4, 0], [(17486578, 3), [['Checking the result:'], ['Update:  since python 3.5 there is also  zipapp module  which can help with bundling the whole package into .pyz file. For more complex needs  pyinstaller ,  py2exe  or  py2app  might better fit the bill.']], [[' [zart@feena ziplib-demo]$ PYTHONPATH=library.zip python\nPython 2.7.1 (r271:86832, Apr 12 2011, 16:15:16)\n[GCC 4.6.0 20110331 (Red Hat 4.6.0-2)] on linux2\nType "help", "copyright", "credits" or "license" for more information.\n>>> import waitress\n>>> waitress\n<module \'waitress\' from \'/home/zart/ziplib-demo/library.zip/waitress/__init__.pyc\'>\n>>>\n>>> from wsgiref.simple_server import demo_app\n>>> waitress.serve(demo_app)\nserving on http://0.0.0.0:8080\n^C>>>\n']], ['How can you bundle all your python code into a single zip file?'], 4, 0], [(17504995, 0), [['Just use a loop:'], ['Demo:']], [[" for entry in inputlist:\n    entry['r'] = min(mxr, calculateRange(x, entry['x'], y, entry['y']))\n"]], ['Python iterate list of dicts and create a new one'], 2, 1], [(17504995, 1), [['Demo:'], ['-10000']], [[" >>> import math\n>>> def calculateRange (x1, x2, y1, y2):\n...   squareNumber = math.sqrt(math.pow ((x1-x2),2) + math.pow((y1-y2),2))\n...   return round(squareNumber, 1)\n...\n>>> x = 2\n>>> y = 3\n>>> mxr = 30\n>>> inputlist = [\n...    {'town':'A', 'x':12, 'y':13},\n...    {'town':'B', 'x':100, 'y':43},\n...    {'town':'C', 'x':19, 'y':5}\n... ]\n>>> for entry in inputlist:\n...     entry['r'] = min(mxr, calculateRange(x, entry['x'], y, entry['y']))\n... \n>>> inputlist\n[{'town': 'A', 'x': 12, 'r': 14.1, 'y': 13}, {'town': 'B', 'x': 100, 'r': 30, 'y': 43}, {'town': 'C', 'x': 19, 'r': 17.1, 'y': 5}]\n"]], ['Python iterate list of dicts and create a new one'], 2, 1], [(17507325, 0), [['You would simply do:'], ['Or if you have specified a  related_name , ']], [[' {{ request.user.userreferralprofile.y }}\n']], ['Accessing an additional profile from templates'], 3, 1], [(17507325, 1), [['Or if you have specified a  related_name , '], ['In the template, ']], [[" class UserReferralProfile(models.Model):\n    x = models.OneToOneField(User, related_name='referal')\n    y = models.CharField()\n"]], ['Accessing an additional profile from templates'], 3, 1], [(17507325, 2), [['In the template, '], ['-10000']], [[' {{ request.user.referal.y }}\n']], ['Accessing an additional profile from templates'], 3, 0], [(17507841, 2), [['Demos:'], ['-10000']], [[" >>> from itertools import permutations\n>>> yourdictionary = {(1,3,2):'text',(3,1,2):'text'}\n>>> yourlist = [1, 2, 3]\n>>> print any(tuple(perm) in yourdictionary for perm in permutations(yourlist))\nTrue\n>>> yourdictionary = {frozenset([1, 2, 3]): 'text', frozenset([4, 5, 6]): 'othertext'}\n>>> frozenset(yourlist) in yourdictionary\nTrue\n>>> frozenset([2, 3]) in yourdictionary\nFalse\n"]], ['How to find combinations of a list in a Dictionary?'], 3, 1], [(17534484, 1), [['If you do not want to install Pyparsing, there is also  a regex inverter that uses only modules from the standard library  with which you could write:'], ['And there are differences between the two modules:']], [[" import inverse_regex\nprint(''.join(inverse_regex.ipermute('[a-z]')))\n# abcdefghijklmnopqrstuvwxyz\n"]], ['Generate random string from regex character set'], 5, 1], [(17534484, 2), [['And there are differences between the two modules:'], ['yields']], [[" import invRegex\nimport inverse_regex\nprint(repr(''.join(invRegex.invert('.'))))\nprint(repr(''.join(inverse_regex.ipermute('.'))))\n"]], ['Generate random string from regex character set'], 5, 0], [(17534484, 3), [['yields'], ['-10000']], [[' \'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&\\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\'\n\'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&\\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c\'\n']], ['Generate random string from regex character set'], 5, 0], [(17534484, 4), [['-10000'], ['-10000']], [[" x = list(invRegex.invert('[a-z][0-9]?.'))\ny = list(inverse_regex.ipermute('[a-z][0-9]?.'))\nprint(len(x))\n# 26884\nprint(len(y))\n# 1100\n"]], ['Generate random string from regex character set'], 5, 0], [(17555470, 0), [['Use nested  any()  calls:'], ['any()  returns  False  only if  all  of the elements in the iterable passed to it are  False .  not any()  thus is  True  only if all elements are false:']], [[' if not any(any(inner) for inner in x):\n']], ['Check if all elements in nested iterables evaluate to False'], 2, 1], [(17555470, 1), [['any()  returns  False  only if  all  of the elements in the iterable passed to it are  False .  not any()  thus is  True  only if all elements are false:'], ['-10000']], [[' >>> x = [(None, None, None), (None, None, None), (None, None, None)]\n>>> not any(any(inner) for inner in x)\nTrue\n>>> x = [(None, None, None), (None, None, None), (None, None, 1)]\n>>> not any(any(inner) for inner in x)\nFalse\n']], ['Check if all elements in nested iterables evaluate to False'], 2, 1], [(17559933, 0), [["First, you've got this loop:"], ['… followed by this one:']], [[" while currenttime > '23:30:00' and currenttime < '23:40:00':\n"]], ['Complete a task during certain time frames within a python script'], 5, 0], [(17559933, 1), [['… followed by this one:'], ['Next, you repeatedly do this:']], [[" while currenttime > '23:40:00' and currenttime < '23:50:00':\n"]], ['Complete a task during certain time frames within a python script'], 5, 0], [(17559933, 2), [['Next, you repeatedly do this:'], ["Meanwhile, you've got this:"]], [[' currenttime = strftime(\'%H:%M:%S\')\nprint ("""23:40:00 to 23:50:00 | %s""" % (currenttime))\nsleep(1)\n']], ['Complete a task during certain time frames within a python script'], 5, 0], [(17559933, 3), [["Meanwhile, you've got this:"], ["Here's what the first one looks like:"]], [[' global clearscreen\n']], ['Complete a task during certain time frames within a python script'], 5, 0], [(17561901, 0), [['Ex: '], ['would be the list for the sample data in the problem.']], [[' [(1,5.2),\n(2,1.43),\n(3,3.54),\n(4,887),\n(5,0.35)]\n']], ['Pick values only below a certain threshold'], 2, 0], [(17561901, 1), [['would be the list for the sample data in the problem.'], ['The first line of the function sorts the list by the values in the second place of the tuple.']], [[" def cutoff(threshold, data):\n    sortedData = sorted(data, key=lambda x: x[1])\n    finalList = filter(lambda x: x[1] < threshold, sortedData)\n    return finalList if len(finalList) > 2 else 'No values found'\n"]], ['Pick values only below a certain threshold'], 2, 1], [(17598881, 0), [['Create the data'], ['Groupby year and id, then mean']], [[" In [12]: df = DataFrame(randn(10,4),columns=list('ABCD'))\n\nIn [13]: df['year'] = 2003\n\nIn [14]: df['id'] = [12,34,12,34,72,0,38,53,70,70]\nIn [16]: df.loc[:5,'year'] = 2004\n\nIn [17]: df\nOut[17]: \n          A         B         C         D  year  id\n0 -1.917262  0.228599 -0.463695  0.776567  2004  12\n1  2.064658 -0.716104 -1.399685  0.402077  2004  34\n2 -1.282627  0.338368  0.757658 -0.114086  2004  12\n3  1.190319 -1.592282  0.942431 -0.778128  2004  34\n4  1.928094  0.532387 -0.352155 -0.039304  2004  72\n5  0.535093 -1.655569 -0.309651  0.438992  2004   0\n6  0.332428 -0.427696 -1.324072  2.158907  2003  38\n7 -1.343306 -0.288373  0.544344 -1.361189  2003  53\n8  0.959273 -0.420134  0.691108 -0.469833  2003  70\n9  0.692352  0.101226 -0.161140 -0.100968  2003  70\n"]], ['Using df.apply() with a Pandas MuliIndex / carrying out operations on hierarchical index rows?'], 4, 0], [(17598881, 1), [['Groupby year and id, then mean'], ['By year mean']], [[" In [21]: df.groupby(['year','id']).mean()\nOut[21]: \n                A         B         C         D\nyear id                                        \n2003 38  0.332428 -0.427696 -1.324072  2.158907\n     53 -1.343306 -0.288373  0.544344 -1.361189\n     70  0.825812 -0.159454  0.264984 -0.285401\n2004 0   0.535093 -1.655569 -0.309651  0.438992\n     12 -1.599944  0.283483  0.146981  0.331241\n     34  1.627488 -1.154193 -0.228627 -0.188025\n     72  1.928094  0.532387 -0.352155 -0.039304\n"]], ['Using df.apply() with a Pandas MuliIndex / carrying out operations on hierarchical index rows?'], 4, 0], [(17598881, 2), [['By year mean'], ['By id']], [[" In [24]: df.groupby(['year']).mean()\nOut[24]: \n             A         B         C         D         id\nyear                                                   \n2003  0.160187 -0.258744 -0.062440  0.056729  57.750000\n2004  0.419713 -0.477434 -0.137516  0.114353  27.333333\n"]], ['Using df.apply() with a Pandas MuliIndex / carrying out operations on hierarchical index rows?'], 4, 0], [(17598881, 3), [['By id'], ['-10000']], [[" In [25]: df.groupby(['id']).mean()\nOut[25]: \n           A         B         C         D  year\nid                                              \n0   0.535093 -1.655569 -0.309651  0.438992  2004\n12 -1.599944  0.283483  0.146981  0.331241  2004\n34  1.627488 -1.154193 -0.228627 -0.188025  2004\n38  0.332428 -0.427696 -1.324072  2.158907  2003\n53 -1.343306 -0.288373  0.544344 -1.361189  2003\n70  0.825812 -0.159454  0.264984 -0.285401  2003\n72  1.928094  0.532387 -0.352155 -0.039304  2004\n"]], ['Using df.apply() with a Pandas MuliIndex / carrying out operations on hierarchical index rows?'], 4, 0], [(17636790, 0), [['Python datetime objects are very easy to work with. For instance, you could collect your event and datetime information into a list of tuples, like this:'], ['And then you can filter and sort those tuples, using the fact that you can add/subtract datetimes and get timedelta objects. You can simply compare to a timedelta object which represents a difference of 30 days:']], [[" all_events = []\nfor <loop over events from server>:\n    all_events.append((dateutil.parser.parse(event['start']['date']), event['summary']))\n"]], ['How to set a date restriction for returned events in Google Calendar and put them in order - Python'], 2, 0], [(17636790, 1), [['And then you can filter and sort those tuples, using the fact that you can add/subtract datetimes and get timedelta objects. You can simply compare to a timedelta object which represents a difference of 30 days:'], ['-10000']], [[' from datetime import datetime, timedelta\n\nmax_td = timedelta(days=30)\nnow = datetime.now()\n\n# Remove events that are too far into the future\nfiltered_events = filter(lambda e: e[0] - now <= max_td, all_events)\n\n# Sort events in ascending order of start time\nfiltered_events.sort()\n']], ['How to set a date restriction for returned events in Google Calendar and put them in order - Python'], 2, 0], [(17637244, 1), [['You can also create a  region_point  indexing array to figure out multiple  points  from an array of  regions  as:'], ['-10000']], [[' region_point = np.argsort(vor.point_region)\npoints = region_point[regions-1]\n']], ['voronoi and lloyd relaxation using python/scipy'], 2, 1], [(17641195, 0), [['fabfile.py'], ['Result:']], [[" from functools import wraps\nfrom fabric.network import needs_host\nfrom fabric.api import run, env\n\ndef runs_final(func):\n    @wraps(func)\n    def decorated(*args, **kwargs):\n        if env.host_string == env.all_hosts[-1]:\n            return func(*args, **kwargs)\n        else:\n            return None\n    return decorated\n\n@needs_host\ndef hello():\n    run('hostname')\n    atexit()\n\n@runs_final\ndef atexit():\n    print ('this is at exit command.')\n"]], ['fabric cleanup operation with atexit'], 2, 1], [(17641195, 1), [['Result:'], ['-10000']], [[" fabric$ fab hello -H web01,web02\n>[web01] Executing task 'hello'\n>[web01] run: hostname\n>[web01] out: web01\n>[web01] out: \n>[web02] Executing task 'hello'\n>[web02] run: hostname\n>[web02] out: web02\n>[web02] out: \n>\n>this is at exit command.\n>\n>Done.\n"]], ['fabric cleanup operation with atexit'], 2, 0], [(17659626, 0), [["If you use a metaclass,  class A 's metaclass will be inherited by  class B  and  class C , so you will only have to modify  class A :"], ['yields']], [[" class MetaA(type):\n    def __init__(cls, name, bases, clsdict):\n        super(MetaA, cls).__init__(name, bases, clsdict)\n        for base in bases:\n            if hasattr(base, 'array'):\n                cls.array = base.array + cls.array\n                break\n\nclass A(object):\n    __metaclass__ = MetaA\n    array = [1]\n\n    def __init__(self):\n        pass\n\nclass B(A):\n    array = [2, 3]\n\n    def __init__(self):\n        super(B, self).__init__()\n\nclass C(B):\n    array = [4]\n\n    def __init__(self):\n        super(C, self).__init__()\n"]], ['Joining fields values'], 2, 1], [(17659626, 1), [['yields'], ['-10000']], [[' print(A.array)\n# [1]\n\nprint(B.array)\n# [1, 2, 3]\n\nprint(C.array)\n# [1, 2, 3, 4]\n']], ['Joining fields values'], 2, 0], [(17687453, 0), [['-10000'], ['is what you want ... i think']], [[' alphabet =  range(10)\nbase = 10\ndict((x*base**2+y*base+z,(x,y,z)) for x in alphabet \n                                  for y in alphabet \n                                  for z in alphabet )\n']], ['python construct a dictionary {0: [0, 0, 0], 1: [0, 0, 1], 2: [0, 0, 2], 3: [0, 0, 3], ...,999: [9, 9, 9]}'], 3, 1], [(17687453, 1), [['is what you want ... i think'], ['generates']], [[' alphabet =  range(2)\nbase = 2\ndict((x*base**2+y*base+z,(x,y,z)) for x in alphabet \n                                  for y in alphabet \n                                  for z in alphabet )\n']], ['python construct a dictionary {0: [0, 0, 0], 1: [0, 0, 1], 2: [0, 0, 2], 3: [0, 0, 3], ...,999: [9, 9, 9]}'], 3, 0], [(17687453, 2), [['generates'], ['-10000']], [[' {0: (0, 0, 0), 1: (0, 0, 1), 2: (0, 1, 0), 3: (0, 1, 1), 4: (1, 0, 0), 5: (1, 0, 1), 6: (1, 1, 0), 7: (1, 1, 1)}\n']], ['python construct a dictionary {0: [0, 0, 0], 1: [0, 0, 1], 2: [0, 0, 2], 3: [0, 0, 3], ...,999: [9, 9, 9]}'], 3, 0], [(17700964, 1), [['and use it like this:'], ['-10000']], [['     mouse_pos = camera.reverse(pygame.mouse.get_pos())\n    if hit_block:\n        replace_block(mouse_pos)\n']], ['Getting World Coordinates with mouse in pygame'], 2, 0], [(17711212, 0), [["If you're just trying to print that:"], ['Output:']], [[' for k, v in dct.iteritems():\n    print repr(k)+ ":(" + ", ".join("Country{}:{}".format(i,c) for i,c in enumerate(v, start=1)) + ")"\n']], ['Naming each item in a list which is a value of a dictionary'], 2, 1], [(17711212, 1), [['Output:'], ['Note: I\'m abusing the function of  repr()  to get the quotes in there. You could just as well do  "\'" + str(k) + "\'" .']], [[" 'Europe':(Country1:Germany, Country2:France, Country3:Italy)\n'Asia':(Country1:India, Country2:China, Country3:Malaysia)\n"]], ['Naming each item in a list which is a value of a dictionary'], 2, 0], [(17734781, 0), [['-10000'], ['Output file dict.csv:']], [[" import csv\n\nmydict = {('c4:7d:4f:53:24:be', 'ac:81:12:62:91:df'):\n          [5.998999999999998, 0.0013169999, 4.0000000000000972],\n          ('a8:5b:4f:2e:fe:09', 'de:62:ef:4e:21:de'):\n          [7.89899999, 0.15647999999675390, 8.764380000972, 9.200000000]}\n\nwith open('dict.csv', 'wb') as file:\n    writer = csv.writer(file, delimiter='\\t')\n    writer.writerow(mydict.keys())\n    for row in zip(*mydict.values()):\n        writer.writerow(list(row))\n"]], ['Possibility of writing dictionary items in columns'], 2, 1], [(17734781, 1), [['Output file dict.csv:'], ['-10000']], [[" ('c4:7d:4f:53:24:be', 'ac:81:12:62:91:df')  ('a8:5b:4f:2e:fe:09', 'de:62:ef:4e:21:de')\n5.998999999999998   7.89899999\n0.0013169999    0.1564799999967539\n4.000000000000097   8.764380000972\n"]], ['Possibility of writing dictionary items in columns'], 2, 0], [(17762515, 0), [['For example, you could use something like this:'], ['And then after starting it off, all you need to do is write  a()  instead of  a :']], [[' import time\n\ndef make_ticker():\n    start = time.time()\n    def elapsed():\n        now = time.time()\n        return now-start\n    return elapsed\n']], ['Best way to make a counter based on time'], 3, 0], [(17762515, 1), [['And then after starting it off, all you need to do is write  a()  instead of  a :'], ['Similarly, if you want to count the number of 2-second periods that have elapsed:']], [[' >>> a = make_ticker()\n>>> a()\n3.3126659393310547\n>>> a()\n5.144495010375977\n>>> a()\n7.766999006271362\n']], ['Best way to make a counter based on time'], 3, 0], [(17762515, 2), [['Similarly, if you want to count the number of 2-second periods that have elapsed:'], ['(You can trivially modify to start at 1.)']], [[' def make_ticker(seconds):\n    start = time.time()\n    def elapsed():\n        now = time.time()\n        return (now-start)//seconds\n    return elapsed\n\n>>> a = make_ticker(2)\n>>> a()\n0.0\n>>> a()\n1.0\n>>> a()\n1.0\n>>> a()\n2.0\n']], ['Best way to make a counter based on time'], 3, 1], [(17774547, 0), [['Sure!'], ['Alternatively,']], [[' t.value1 = 1\nt.value2 = 2\nt.save()\n']], ['Django how to update more than a row field at once'], 2, 1], [(17774547, 1), [['Alternatively,'], ['(And you could use  **kwargs  here)']], [[' TheForm.objects.filter(id=1).update(value=1, value2=2)\n']], ['Django how to update more than a row field at once'], 2, 1], [(17778394, 0), [['But if you want to do this in pandas, you can  unstack  and  order  the DataFrame:'], ['Here is the output:']], [[' import pandas as pd\nimport numpy as np\n\nshape = (50, 4460)\n\ndata = np.random.normal(size=shape)\n\ndata[:, 1000] += data[:, 2000]\n\ndf = pd.DataFrame(data)\n\nc = df.corr().abs()\n\ns = c.unstack()\nso = s.order(kind="quicksort")\n\nprint so[-4470:-4460]\n']], ['List Highest Correlation Pairs from a Large Correlation Matrix in Pandas?'], 2, 1], [(17778394, 1), [['Here is the output:'], ['-10000']], [[' 2192  1522    0.636198\n1522  2192    0.636198\n3677  2027    0.641817\n2027  3677    0.641817\n242   130     0.646760\n130   242     0.646760\n1171  2733    0.670048\n2733  1171    0.670048\n1000  2000    0.742340\n2000  1000    0.742340\ndtype: float64\n']], ['List Highest Correlation Pairs from a Large Correlation Matrix in Pandas?'], 2, 0], [(17795362, 1), [['Call insert_names with a list that you generate from your html form.'], ['-10000']], [[" names = [\n    {'name': name0, 'qty': qty0, ...}\n    {'name': name1, 'qty': qty1, ...}\n    {'name': name2, 'qty': qty2, ...}\n    ...\n]\ninsert_names(names)\n"]], ['MongoDB data Posting'], 2, 0], [(17799504, 0), [['The builtin  any()  function can help you here:'], ["It's also possible to get the same effect with  all() :"]], [[' black_list = ["ab:", "cd:", "ef:", "gh:"]\n\nfor line in some_file:\n    if ":" in line and not any(x in line for x in black_list):\n        pass\n']], ['How to check if elements of a list are in a string'], 2, 1], [(17799504, 1), [["It's also possible to get the same effect with  all() :"], ['... but I think the first is closer to English, so easier to follow.']], [[' for line in some_file:\n    if ":" in line and all(x not in line for x in black_list):\n        pass\n']], ['How to check if elements of a list are in a string'], 2, 1], [(17809274, 0), [['Options 1  - draw a heatmap of the difference of 2 datasets (or ratio, whatever is more appropriate in your case)'], ['Option 2  - present 1 dataset as pcolor, and another as countour:']], [[' pcolor(D2-D1)\n']], ['Combine multiple heatmaps in matplotlib'], 4, 1], [(17809274, 1), [['Option 2  - present 1 dataset as pcolor, and another as countour:'], ['If you really need to  show N>2 datasets together , I would go with contour or contourf:']], [[' pcolor(D1)\ncontour(D2)\n']], ['Combine multiple heatmaps in matplotlib'], 4, 1], [(17809274, 2), [['If you really need to  show N>2 datasets together , I would go with contour or contourf:'], ['or ']], [[" contourf(D1,cmap='Blues')\ncontourf(D2,cmap='Reds', alpha=0.66)\ncontourf(D2,cmap='Reds', alpha=0.33)\n"]], ['Combine multiple heatmaps in matplotlib'], 4, 1], [(17809274, 3), [['or '], ['']], [[" contour(D1,cmap='Blues')\ncontour(D2,cmap='Reds')\ncontour(D2,cmap='Reds')\n"]], ['Combine multiple heatmaps in matplotlib'], 4, 1], [(17811168, 0), [["This is  Jaime's idea , I just love it:"], ['yields']], [[' import numpy as np\n\ndef asvoid(arr):\n    """View the array as dtype np.void (bytes)\n    This collapses ND-arrays to 1D-arrays, so you can perform 1D operations on them.\n    https://stackoverflow.com/a/16216866/190597 (Jaime)"""    \n    arr = np.ascontiguousarray(arr)\n    return arr.view(np.dtype((np.void, arr.dtype.itemsize * arr.shape[-1])))\n\ndef find_index(arr, x):\n    arr_as1d = asvoid(arr)\n    x = asvoid(x)\n    return np.nonzero(arr_as1d == x)[0]\n\n\narr = np.array([[  1,  15,   0,   0],\n                [ 30,  10,   0,   0],\n                [ 30,  20,   0,   0],\n                [1, 2, 3, 4],\n                [104, 139, 146,  75],\n                [  9,  11, 146,  74],\n                [  9, 138, 146,  75]], dtype=\'uint8\')\n\narr = np.tile(arr,(1221488,1))\nx = np.array([1,2,3,4], dtype=\'uint8\')\n\nprint(find_index(arr, x))\n']], ['Fast way to find index of array in array of arrays'], 5, 1], [(17811168, 1), [['yields'], ['-10000']], [[' [      3      10      17 ..., 8550398 8550405 8550412]\n']], ['Fast way to find index of array in array of arrays'], 5, 0], [(17811168, 2), [['-10000'], ['There is another way  to do it:']], [[" In [15]: x\nOut[15]: \narray([^A^B^C^D], \n      dtype='|V4')\n"]], ['Fast way to find index of array in array of arrays'], 5, 0], [(17811168, 3), [['There is another way  to do it:'], ['but it turns out to be not as fast:']], [[' def find_index2(arr, x):\n    return np.where((arr == x).all(axis=1))[0]\n']], ['Fast way to find index of array in array of arrays'], 5, 0], [(17811168, 4), [['but it turns out to be not as fast:'], ['-10000']], [[' In [34]: %timeit find_index(arr, x)\n1 loops, best of 3: 209 ms per loop\n\nIn [35]: %timeit find_index2(arr, x)\n1 loops, best of 3: 370 ms per loop\n']], ['Fast way to find index of array in array of arrays'], 5, 0], [(17866724, 1), [['If you want the option of printing to  stdout  and a file, you can try this:'], ['To revert to just printing to console, just restore the "backup"']], [[' class Tee(object):\n    def __init__(self, *files):\n        self.files = files\n    def write(self, obj):\n        for f in self.files:\n            f.write(obj)\n\nf = open(\'logfile\', \'w\')\nbackup = sys.stdout\nsys.stdout = Tee(sys.stdout, f)\n\nprint "hello world"  # this should appear in stdout and in file\n']], ['Python, logging print statements while having them print to stdout'], 3, 1], [(17866724, 2), [['To revert to just printing to console, just restore the "backup"'], ['-10000']], [[' sys.stdout = backup\n']], ['Python, logging print statements while having them print to stdout'], 3, 0], [(17870242, 0), [['Using  random.choice .'], ['If only the first value of the tuple is wanted:']], [[' >>> import random\n>>> moves = [(\'r\', "rock"), (\'p\', "paper"), (\'s\', "scissors")]\n>>> random.choice(moves)\n(\'s\', \'scissors\')\n']], ['Return random value from list tuple'], 2, 1], [(17870242, 1), [['If only the first value of the tuple is wanted:'], ['-10000']], [[' random.choice(moves)[0]\n']], ['Return random value from list tuple'], 2, 1], [(17910014, 1), [["Since you're on Python 3, use the  translate()  method like this."], ['Just doing this works. (Here you make a copy, iterate over it, while removing the element from the original list)']], [[" >>> test = 'Today it is Tuesday'\n>>> removeText = 'pqrst'\n>>> test.translate(dict.fromkeys(ord(elem) for elem in removeText+removeText.upper()))\n'oday i i ueday'\n"]], ['Removing certain letters from a string'], 3, 1], [(17910014, 2), [['Just doing this works. (Here you make a copy, iterate over it, while removing the element from the original list)'], ['P.S  - Instead of using  string = \'\'  and iterating over the list and joining the characters, just use  "".join(...) .']], [[' >>> testList = list(test)\n>>> for i in testList[:]:\n        if i in \'pqrstPQRST\':\n            testList.remove(i)\n\n\n>>> "".join(testList)\n\'oday i i ueday\'\n']], ['Removing certain letters from a string'], 3, 1], [(17910359, 0), [["You're looking for  itertools.product(...) ."], ['If you want to convert the inner elements to  list  type, use a list comprehension']], [[' >>> from itertools import product\n>>> list(product([1, 0], repeat=2))\n[(1, 1), (1, 0), (0, 1), (0, 0)]\n']], ['How to generate list combinations?'], 3, 1], [(17910359, 1), [['If you want to convert the inner elements to  list  type, use a list comprehension'], ['Or by using  map()']], [[' >>> [list(elem) for elem in product([1, 0], repeat =2)]\n[[1, 1], [1, 0], [0, 1], [0, 0]]\n']], ['How to generate list combinations?'], 3, 1], [(17910359, 2), [['Or by using  map()'], ['-10000']], [[' >>> map(list, product([1, 0], repeat=2))\n[[1, 1], [1, 0], [0, 1], [0, 0]]\n']], ['How to generate list combinations?'], 3, 1], [(17911276, 1), [['This will give you a list of entries that look like'], ['Add  sorted  to get it sorted:']], [[" {'user': '<user1>', 'negative': 8, 'positive': 32, 'rating': 80.0}\n"]], ['flask/jinja: creating a leaderboard out of an unordered dict object'], 3, 0], [(17911276, 2), [['Add  sorted  to get it sorted:'], ['and just iterate through the sorted list with  for ... in . To sort reverse, use  reverse=True  in  sorted']], [[" sorted([dict([('user', k)] + list(v.items())) for k, v in a['users'].items()], key=lambda x: x['rating'])\n"]], ['flask/jinja: creating a leaderboard out of an unordered dict object'], 3, 1], [(17921455, 0), [['So to be specific, all I needed to do was to create file noo.pxd containing:'], ['and than we can simply cimport this function from foo.pyx by calling']], [[' cdef trol(int * i)\n']], ['How to import cython function to cython script'], 2, 0], [(17921455, 1), [['and than we can simply cimport this function from foo.pyx by calling'], ['-10000']], [[' from noo cimport trol\n']], ['How to import cython function to cython script'], 2, 0], [(17958069, 0), [['Windows:'], ['Unix:']], [[' import msvcrt\none_character= msvcrt.getch()\n']], ['How can I determine when a user is in the process of entering something as an input in Python?'], 4, 0], [(17958069, 1), [['Unix:'], ["In the later case you will most probably want to save and restore  sys.stdin 's mode with"]], [[' import sys, tty\ntty.setraw(sys.stdin.fileno())\none_character= sys.stdin.read(1)\n']], ['How can I determine when a user is in the process of entering something as an input in Python?'], 4, 0], [(17958069, 2), [["In the later case you will most probably want to save and restore  sys.stdin 's mode with"], ['and']], [[' import sys, termios\nprevious_mode= termios.tcgetattr( sys.stdin.fileno() )\n']], ['How can I determine when a user is in the process of entering something as an input in Python?'], 4, 0], [(17958069, 3), [['and'], [', respectively.']], [[' import sys, termios\ntermios.tcsetattr(sys.stdin.fileno(),termios.TCSADRAIN, previous_mode )\n']], ['How can I determine when a user is in the process of entering something as an input in Python?'], 4, 0], [(17972025, 0), [['You can use a list comprehension:'], ['This returns:']], [[' [i for i in a if not any(x in i for x in b)]\n']], ['How to remove an array containing certain strings from another array in Python'], 2, 1], [(17972025, 1), [['This returns:'], ['-10000']], [[" ['blah', 'tete', 'head']\n"]], ['How to remove an array containing certain strings from another array in Python'], 2, 0], [(18016779, 0), [['We wrote a custom middleware and registered it as an middleware class inside our settings.py file.'], ['The next step was creating a  Database Router  and registering it as such.']], [[" MIDDLEWARE_CLASSES = (\n    'django.middleware.common.CommonMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'our.custom.middleware.Class',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n)\n"]], ['Different databases with the same models on Django'], 2, 0], [(18016779, 1), [['The next step was creating a  Database Router  and registering it as such.'], ["Attention: The default  settings.py  doesn't have a  DATABASE_ROUTERS  variable. You'll have to create it."]], [[" DATABASE_ROUTERS = ('our.custom.database.Router',)\n"]], ['Different databases with the same models on Django'], 2, 0], [(18024402, 0), [['fasta:'], ['fastq (based on yours but not identical because your output was badly formatted):']], [[' AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAG\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGG\n']], ['find unique first top and bottom lines of fastq file from fasta file'], 4, 0], [(18024402, 1), [['fastq (based on yours but not identical because your output was badly formatted):'], ['Code:']], [[' @DH1DQQN1:269:C1UKCACXX:1:1107:20386:6577 1:N:0:TTAGGC\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC\n+\nCCCFFFFFHGHHHJIJHFDDDB173@8815BDDB###############\n@DH1DQQN1:269:C1UKCACXX:1:1114:5718:53821 1:N:0:TTAGGC\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n+\nCCCFFFFFHGHHHJIJHFDDDB173@8815BDDB###############\n@DH1DQQN1:269:C1UKCACXX:1:1209:10703:35361 1:N:0:TTAGGC\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n+\n@@@FFFFFHGHHHGIJHFDDDDDBDD69@6B-707537BDDDB75@@85\n@DH1DQQN1:269:C1UKCACXX:1:1210:18926:75163 1:N:0:TTAGGC\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAG\n+\n@CCFFFFFHHHHHJJJHFDDD@77BDDDDB077007@B###########\n']], ['find unique first top and bottom lines of fastq file from fasta file'], 4, 0], [(18024402, 3), [['-10000'], ['(Here I also use  sys.stdout.write  instead of  print , to avoid the extra newlines.)']], [[' from Bio import SeqIO\nimport sys\n\nwith open("fasta") as fh:\n    fasta = fh.read().splitlines()\n\nseen = set()\nrecords = {}\n\nfor record in SeqIO.parse(open(\'fastq\'), \'fastq\'):\n    seq = str(record.seq)\n    if seq in fasta and seq not in seen:\n        seen.add(seq)\n        records[fasta.index(seq)] = record\n\nfor record in sorted(records):\n    sys.stdout.write(records[record].format(\'fastq\'))\n']], ['find unique first top and bottom lines of fastq file from fasta file'], 4, 1], [(18040702, 0), [['Use'], ['or']], [[' tables = root.xpath(\'.//table[preceding-sibling::h3[text()="Impact"]]\')\n']], ['How to find and select a table in html code with xpath'], 4, 1], [(18040702, 1), [['or'], ['or']], [[' tables = root.xpath(\'.//h3[text()="Impact"]/following-sibling::table\')\n']], ['How to find and select a table in html code with xpath'], 4, 1], [(18040702, 2), [['or'], ['-10000']], [[" tables = root.cssselect('h3:contains(Impact) ~ table')\n"]], ['How to find and select a table in html code with xpath'], 4, 1], [(18040702, 3), [['-10000'], ['-10000']], [['Complete solution root = tree.getroot()\ntables = root.xpath(\'.//h3[text()="Impact"]/following-sibling::table\')\nfor table in tables:\n    print str\n']], ['How to find and select a table in html code with xpath'], 4, 1], [(18049531, 0), [['All you have to do is to set the stylesheet either with  QtDesigner  or in python itself, like this:'], ['Here is a sample stylesheet (the third example from  Qtabwidget )']], [[' self.tabWidget.setStyleSheet("background-color: rgb(255, 255, 255);\\n"\n                                    "border:1px solid rgb(255, 170, 255);")\n']], ['PySide custom Tab'], 2, 1], [(18049531, 1), [['Here is a sample stylesheet (the third example from  Qtabwidget )'], ['-10000']], [['  QTabWidget::pane { /* The tab widget frame */\n     border-top: 2px solid #C2C7CB;\n     position: absolute;\n     top: -0.5em;\n }\n\n QTabWidget::tab-bar {\n     alignment: center;\n }\n\n /* Style the tab using the tab sub-control. Note that\n     it reads QTabBar _not_ QTabWidget */\n QTabBar::tab {\n     background: qlineargradient(x1: 0, y1: 0, x2: 0, y2: 1,\n                                 stop: 0 #E1E1E1, stop: 0.4 #DDDDDD,\n                                 stop: 0.5 #D8D8D8, stop: 1.0 #D3D3D3);\n     border: 2px solid #C4C4C3;\n     border-bottom-color: #C2C7CB; /* same as the pane color */\n     border-top-left-radius: 4px;\n     border-top-right-radius: 4px;\n     min-width: 8ex;\n     padding: 2px;\n }\n\n QTabBar::tab:selected, QTabBar::tab:hover {\n     background: qlineargradient(x1: 0, y1: 0, x2: 0, y2: 1,\n                                 stop: 0 #fafafa, stop: 0.4 #f4f4f4,\n                                 stop: 0.5 #e7e7e7, stop: 1.0 #fafafa);\n }\n\n QTabBar::tab:selected {\n     border-color: #9B9B9B;\n     border-bottom-color: #C2C7CB; /* same as pane color */\n }\n']], ['PySide custom Tab'], 2, 0], [(18050937, 0), [['Call with  shell=True  argument. For example,'], ['-10000']], [[" import subprocess\n\nsubprocess.call('grep -r PASSED *.log | sort -u | wc -l', shell=True)\n"]], ['How can I execute shell command with a | pipe in it'], 2, 1], [(18050937, 1), [['-10000'], ['See  Replacing shell pipeline .']], [["Hard way import glob\nimport subprocess\n\ngrep = subprocess.Popen(['grep', '-r', 'PASSED'] + glob.glob('*.log'), stdout=subprocess.PIPE)\nsort = subprocess.Popen(['sort', '-u'], stdin=grep.stdout, stdout=subprocess.PIPE)\nexit_status = subprocess.call(['wc', '-l'], stdin=sort.stdout)\n"]], ['How can I execute shell command with a | pipe in it'], 2, 1], [(18062466, 0), [['Try this, for adding new set elements as values for a given key:'], ['Alternatively, use a  defaultdict :']], [[' d = {}\nd.setdefault(key, set()).add(value)\n']], ['Creating a dictionary and adding a set as its value'], 4, 1], [(18062466, 1), [['Alternatively, use a  defaultdict :'], ["Either solution will effectively create a  multimap : a data structure that for a given key can hold multiple values - in this case, inside a  set . For your example in particular, this is how you'd use it:"]], [[' from collections import defaultdict\nd = defaultdict(set)\nd[key].add(value)\n']], ['Creating a dictionary and adding a set as its value'], 4, 1], [(18062466, 2), [["Either solution will effectively create a  multimap : a data structure that for a given key can hold multiple values - in this case, inside a  set . For your example in particular, this is how you'd use it:"], ['Alternatively:']], [[' d = {}\nfor num in datasource:\n    d.setdefault(key, set()).add(num)\n']], ['Creating a dictionary and adding a set as its value'], 4, 1], [(18062466, 3), [['Alternatively:'], ['-10000']], [[' from collections import defaultdict\nd = defaultdict(set)\nfor num in datasource:\n    d[key].add(num)\n']], ['Creating a dictionary and adding a set as its value'], 4, 1], [(18082130, 0), [['Do you need a regex? You can do something like'], ['If you really want to use regex, you can try  \\w*\\d\\w* :']], [[' >>> words = "ABCD abcd AB55 55CD A55D 5555"\n>>> \' \'.join(s for s in words.split() if not any(c.isdigit() for c in s))\n\'ABCD abcd\'\n']], ['Python regex to remove all words which contains number'], 2, 1], [(18082130, 1), [['If you really want to use regex, you can try  \\w*\\d\\w* :'], ['-10000']], [[" >>> re.sub(r'\\w*\\d\\w*', '', words).strip()\n'ABCD abcd'\n"]], ['Python regex to remove all words which contains number'], 2, 1], [(18085030, 0), [["I'm not sure I understand this correctly but if you want to create a config file to easily read a list like you've shown then create a section in your configs.ini"], ['and then']], [[' [section]\nkey = value\nkey2 = value2\nkey3 = value3\n']], ['Python argparser. List of dict in INI'], 5, 0], [(18085030, 1), [['and then'], ['If on the other hand what you are saying is that your config file contains:']], [[" >> config = ConfigParser.RawConfigParser()\n>> config.read('configs.ini')\n>> items = config.items('section')\n>> items\n[('key', 'value'), ('key2', 'value2'), ('key3', 'value3')]\n"]], ['Python argparser. List of dict in INI'], 5, 0], [(18085030, 2), [['If on the other hand what you are saying is that your config file contains:'], ['what you could do is extend the config parser like for example so:']], [[' [section]\ncouples = [("somekey1", "somevalue1"), ("somekey2", "somevalue2"), ("somekey3", "somevalue3")]\n']], ['Python argparser. List of dict in INI'], 5, 0], [(18085030, 3), [['what you could do is extend the config parser like for example so:'], ['and then your new parser can get fetch your list for you:']], [[' class MyConfigParser(ConfigParser.RawConfigParser):\n\n    def get_list_of_tups(self, section, option):\n        value = self.get(section, option)\n        import re\n        couples = re.finditer(\'\\("([a-z0-9]*)", "([a-z0-9]*)"\\)\', value)\n        return [(c.group(1), c.group(2)) for c in couples]\n']], ['Python argparser. List of dict in INI'], 5, 0], [(18085030, 4), [['and then your new parser can get fetch your list for you:'], ['The second situation is just making things hard for yourself I think.']], [[" >> my_config = MyConfigParser()\n>> my_config.read('example.cfg')\n>> couples = my_config.get_list_of_tups('section', 'couples')\n>> couples\n[('somekey1', 'somevalue1'), ('somekey2', 'somevalue2'), ('somekey3', 'somevalue3')]\n"]], ['Python argparser. List of dict in INI'], 5, 0], [(18086307, 0), [['You can flatten the two lists of sets into sets:'], ['Then you can compute the intersection:']], [[' l1 = set(s for x in list1 for s in x)\nl2 = set(s for x in list2 for s in x)\n']], ['Python - Comparing two lists of sets'], 3, 0], [(18086307, 1), [['Then you can compute the intersection:'], ['Results:']], [[' common = l1.intersection(l2)  # common will give common elements\nprint len(common) # this will give you the number of elements in common.\n']], ['Python - Comparing two lists of sets'], 3, 0], [(18086307, 2), [['Results:'], ['-10000']], [[" >>> print common\nset(['3123', '3115', '3107', '3126'])\n>>> len(common)\n4\n"]], ['Python - Comparing two lists of sets'], 3, 0], [(18088496, 0), [['Using  regex ,  str.translate  and  str.split  :'], ['You can also create a dict here, which will allow you to access any attribute:']], [[" >>> import re\n>>> from string import whitespace\n>>> strs = re.search(r'List:(.*)(\\s\\S*\\w+):', ph, re.DOTALL).group(1)\n>>> strs.translate(None, ':'+whitespace).split(',')\n['username1', 'username2', 'username3', 'username4', 'username5']\n"]], ['capturing the usernames after List: tag'], 3, 1], [(18088496, 1), [['You can also create a dict here, which will allow you to access any attribute:'], ['Output:']], [[" def func(lis):\n    return ''.join(lis).translate(None, ':'+whitespace)\n\nlis = [x.split() for x in re.split(r'(?<=\\w):',ph.strip(), re.DOTALL)]\ndic = {}\nfor x, y in zip(lis[:-1], lis[1:-1]):\n    dic[x[-1]] = func(y[:-1]).split(',')\ndic[lis[-2][-1]] = func(lis[-1]).split(',')\n\nprint dic['List']\nprint dic['Members']\nprint dic['alias']\n"]], ['capturing the usernames after List: tag'], 3, 1], [(18088496, 2), [['Output:'], ['-10000']], [[" ['username1', 'username2', 'username3', 'username4', 'username5']\n['User1', 'User2', 'User3', 'User4', 'User5']\n['tech.sw.host']\n"]], ['capturing the usernames after List: tag'], 3, 0], [(18108438, 0), [['You could use (Use itervalues() for Py2x)'], ['See the demo - ']], [[" all(elem[2] in ('', None) for elem in test.values())\n"]], ['evaluating values of a dictionary'], 2, 1], [(18108438, 1), [['See the demo - '], ['-10000']], [[" >>> test = {'a': (1, 2, None), 'b':(2, 3, '')}\n>>> all(elem[2] in ('', None) for elem in test.values())\nTrue\n>>> test['c'] = (1, 2, 3)\n>>> all(elem[2] in ('', None) for elem in test.values())\nFalse\n"]], ['evaluating values of a dictionary'], 2, 1], [(18111031, 0), [['Save the dictionary'], ['Load the dictionary']], [[" import pickle\nsome_dict = {'this':1,'is':2,'an':3,'example':4}\n\nwith open('saved_dict.pkl','w') as pickle_out:\n    pickle.dump(some_dict,pickle_out)\n"]], ['Python: Append dictionary in another file'], 2, 0], [(18111031, 1), [['Load the dictionary'], ['-10000']], [[" with open('saved_dict.pkl.'r') as pickle_in:\n    that_dict_again = pickle.load(pickle_in)\n"]], ['Python: Append dictionary in another file'], 2, 0], [(18114415, 0), [['A better solution is to use  itertools.chain  instead of addition. That way, instead of creating the intermediate list  list1 + list2 , and then another intermediate list  list1 + list2 + list3 , you just create the final list with no intermediates:'], ['However, an empty list comprehension like this is pretty silly; just use the  list  function to turn any arbitrary iterable into a list:']], [[' allList = [x for x in itertools.chain(list1, list2, list3)]\n']], ['how do I concatenate 3 lists using a list comprehension?'], 5, 1], [(18114415, 1), [['However, an empty list comprehension like this is pretty silly; just use the  list  function to turn any arbitrary iterable into a list:'], ['Or, even better… if the only reason you need this is to loop over it, just leave it as an iterator:']], [[' allList = list(itertools.chain(list1, list2, list3))\n']], ['how do I concatenate 3 lists using a list comprehension?'], 5, 1], [(18114415, 2), [['Or, even better… if the only reason you need this is to loop over it, just leave it as an iterator:'], ['-10000']], [[' for thing in itertools.chain(list1, list2, list3):\n    do_stuff(thing)\n']], ['how do I concatenate 3 lists using a list comprehension?'], 5, 1], [(18114415, 3), [['-10000'], ['Or, if you want to print it out in the format specified by that question:']], [[' itertools.product(list1, list2, list3)\n']], ['how do I concatenate 3 lists using a list comprehension?'], 5, 0], [(18114415, 4), [['Or, if you want to print it out in the format specified by that question:'], ['-10000']], [[" print('\\n'.join(map(' '.join, itertools.product(list1, list2, list3))))\n"]], ['how do I concatenate 3 lists using a list comprehension?'], 5, 0], [(18141698, 0), [['You can use  mechanize :'], ['Or  urllib2  and  BeautifulSoup']], [[' from mechanize import Browser\n\nbr = Browser()    \nr = br.open("http://www.example.com/")\n\nif r.code == 200:\n    for link in br.links():\n        print link\nelse:\n    print "Error loading page"\n']], ['How can I set a code for users when they enter a valud URL or not with PYTHON/Flask?'], 3, 1], [(18141698, 1), [['Or  urllib2  and  BeautifulSoup'], ['-10000']], [[' from BeautifulSoup import BeautifulSoup\nimport urllib2\n\nhtml_page = urllib2.urlopen("http://www.example.com")\nif html_page.getcode() == 200:\n    soup = BeautifulSoup(html_page)\n    for link in soup.findAll(\'a\'):\n        print link.get(\'href\')\nelse:\n    print "Error loading page"\n']], ['How can I set a code for users when they enter a valud URL or not with PYTHON/Flask?'], 3, 1], [(18157559, 0), [["Here's how I'd do it:"], ["A rather more natural solution though would be to get rid of the list-of-dictionaries data structure and instead go for a single dictionary that maps from  type, obj_id  keys to  actors, extra_fields  values. Here's what that would look like:"]], [[" def merge_dicts(list_of_dicts):\n    lookup = {}\n    results = []\n    for d in list_of_dicts:\n        key = (d['type'], d['obj_id'])\n        try: # it's easier to ask forgiveness than permission\n            lookup[key]['actor'].append(d['actor'])\n        except KeyError:\n            val = {'type': d['type'],\n                   'obj_id': d['obj_id'],\n                   'actor': [d['actor']], # note, extra [] around value to make it a list\n                   'extra_fields': d['extra_fields']}\n            lookup[key] = val\n            results.append(val)\n\n    return results\n"]], ['Grouping data in a list of of dicts'], 3, 1], [(18157559, 1), [["A rather more natural solution though would be to get rid of the list-of-dictionaries data structure and instead go for a single dictionary that maps from  type, obj_id  keys to  actors, extra_fields  values. Here's what that would look like:"], ["If you're going to be iterating over the collection later, this way is much easier, since you can unpack tuples (even nested ones) right in the loop:"]], [[" def merge_dicts2(list_of_dicts):\n    results = {}\n    for d in list_of_dicts:\n        key = (d['type'], d['obj_id'])\n        try:\n            results[key][0].append(d['actor'])\n        except KeyError:\n            results[key] = ([d['actor']], d['extra_fields'])\n\n    return results\n"]], ['Grouping data in a list of of dicts'], 3, 1], [(18157559, 2), [["If you're going to be iterating over the collection later, this way is much easier, since you can unpack tuples (even nested ones) right in the loop:"], ['-10000']], [[' combined_dict = merge_dicts(list_of_dicts)\n\nfor (type, obj_id), (actors, extra_fields) in combined_dict.items():\n    # do stuff with type, obj_id, actors, extra_fields\n']], ['Grouping data in a list of of dicts'], 3, 0], [(18217858, 0), [['Modify  a[0] :'], ['For your updated question:']], [[" >>> a = ['spam', 'eggs', 100, 1234]\n>>> a[0] = [a[0], 'Devon']\n>>> a\n[['spam', 'Devon'], 'eggs', 100, 1234]\n"]], ['Python list manipulation: Add an item to a string element to make it a 2 item list'], 3, 1], [(18233948, 0), [['sys.getsizeof()  return used byte by interpreter to hold that object.'], ['In addition to that, if you are running the program in the Window, you should use binary mode.']], [[" >>> len('asdf')\n4\n>>> import sys\n>>> sys.getsizeof('asdf')\n37\n"]], ['Python line read size in bytes'], 2, 1], [(18233948, 1), [['In addition to that, if you are running the program in the Window, you should use binary mode.'], ['NOTE']], [[" open(myfile, 'rb')\n"]], ['Python line read size in bytes'], 2, 0], [(18244791, 0), [['If you mean the complete string is something looks like: """my_item = [\'maria\',\'jose\']"""\nThen you do something like this below:'], ['Then you can call mydict[key] to pick up the value which you want to lookup.']], [[' inputString = "my_item = [\'maria\',\'jose\']"\n\n# value is a list type \nvalue = eval(inputString.split("=")[1])\n# key is a string type\nkey = inputString.split("=")[0].strip()\n\n# I don\'t think you can define a variable name while the script is running. \n# but you can use dictionary type to call it.\nmydict = {}\nmydict[key] = value\n']], ['Python: how to turn string into a list?'], 2, 1], [(18244791, 1), [['Then you can call mydict[key] to pick up the value which you want to lookup.'], ['-10000']], [[" >>> print mydict['my_item'] \n['maria', 'jose']\n"]], ['Python: how to turn string into a list?'], 2, 0], [(18250516, 0), [['Take the first character of each key, call  .upper()  on that and sum your values by that uppercased letter. The following loop'], ['You can also use a  collections.defaultdict()  object  to simplify that a little:']], [[' out = {}\nfor key, value in original.iteritems():\n    out[key[0].upper()] = out.get(key[0].upper(), 0) + value\n']], ['How to add in a dictionary the values that have similar keys?'], 3, 1], [(18250516, 1), [['You can also use a  collections.defaultdict()  object  to simplify that a little:'], ['or you could use  itertools.groupby() :']], [[' from collections import defaultdict:\n\nout = defaultdict(int)\nfor key, value in original.iteritems():\n    out[key[0].upper()] += value\n']], ['How to add in a dictionary the values that have similar keys?'], 3, 1], [(18250516, 2), [['or you could use  itertools.groupby() :'], ['-10000']], [[' from itertools import groupby\n\nkey = lambda i: i[0][0].upper()\nout = {key: sum(v for k, v in group) for key, group in groupby(sorted(original.items(), key=key), key=key)}\n']], ['How to add in a dictionary the values that have similar keys?'], 3, 1], [(18281342, 0), [['You can just do this in a pretty straightforward way:'], ['prints:']], [[' import re\n\ntext = """\nNovember 5 - December 10\nSeptember 23 - December 16\n"""\n\nmatches = re.findall("\\w+\\s\\d+\\s\\-\\s\\w+\\s\\d+", text)\nprint matches\n']], ['regex to find a specific pattern in python'], 3, 1], [(18281342, 1), [['prints:'], ['But, if these words are just month names, you can improve your regexp by specifying a list of months instead of just  \\w+ :']], [[" ['November 5 - December 10', 'September 23 - December 16']\n"]], ['regex to find a specific pattern in python'], 3, 0], [(18281342, 2), [['But, if these words are just month names, you can improve your regexp by specifying a list of months instead of just  \\w+ :'], ['-10000']], [[' months = "|".join(calendar.month_name)[1:]\nmatches = re.findall("{0}\\s\\d+\\s\\-\\s{0}\\s\\d+".format(months), text)\n']], ['regex to find a specific pattern in python'], 3, 1], [(18286362, 0), [['module for communication  communicate.py :'], ['1.py :']], [[' import sys\nimport subprocess as sp\nimport cPickle\n\nBEGIN = \'pickle_begin\'\n\ndef send_and_exit(x):\n    sys.stdout.write(BEGIN + cPickle.dumps(x))\n    sys.stdout.flush()\n    sys.exit(0)\n\ndef execute_and_receive(filename):\n    p = sp.Popen(["python", filename], stdout=sp.PIPE)\n    (out, err) = p.communicate()\n    return cPickle.loads(out[out.find(BEGIN) + len(BEGIN):])\n']], ['How to Get Variable from another .py'], 3, 0], [(18286362, 1), [['1.py :'], ['2.py :']], [[' from communicate import *\nx = execute_and_receive("2.py")\ny = x + 2\n']], ['How to Get Variable from another .py'], 3, 0], [(18286362, 2), [['2.py :'], ["To make sure, you start unpickling at the correct point of the  stdout  stream I recommend to set a marker, like I did with the  BEGIN  string. Probably there are more elegant solutions, if so, I'm interested as well."]], [[' from communicate import *\nx = 2 + 2\nsend_and_exit(x)\n']], ['How to Get Variable from another .py'], 3, 0], [(18289871, 0), [["Pyramid framework has a very nice decorator called  reify , but it only works at instance level, and you want class level, so let's modify it a bit"], ['Run the program and it prints']], [[' class class_reify(object):\n    def __init__(self, wrapped):\n        self.wrapped = wrapped\n        try:\n            self.__doc__ = wrapped.__doc__\n        except: # pragma: no cover\n            pass\n\n    # original sets the attributes on the instance\n    # def __get__(self, inst, objtype=None):\n    #    if inst is None:\n    #        return self\n    #    val = self.wrapped(inst)\n    #    setattr(inst, self.wrapped.__name__, val)\n    #    return val\n\n    # ignore the instance, and just set them on the class\n    # if called on a class, inst is None and objtype is the class\n    # if called on an instance, inst is the instance, and objtype \n    # the class\n    def __get__(self, inst, objtype=None):\n        # ask the value from the wrapped object, giving it\n        # our class\n        val = self.wrapped(objtype)\n\n        # and set the attribute directly to the class, thereby\n        # avoiding the descriptor to be called multiple times\n        setattr(objtype, self.wrapped.__name__, val)\n\n        # and return the calculated value\n        return val\n\nclass Test(object):\n    @class_reify\n    def foo(cls):\n        print "foo called for class", cls\n        return 42\n\nprint Test.foo\nprint Test.foo\n']], ['Lazy class property decorator'], 2, 1], [(18289871, 1), [['Run the program and it prints'], ['-10000']], [[" foo called for class <class '__main__.Test'>\n42\n42\n"]], ['Lazy class property decorator'], 2, 0], [(18325280, 0), [['Sort the two strings and then compare them:'], ['If the strings might not be the same length, you might want to make sure of that first to save time:']], [[' sorted(str1) == sorted(str2)\n']], ['How can I check if a string has the same characters? Python'], 2, 1], [(18325280, 1), [['If the strings might not be the same length, you might want to make sure of that first to save time:'], ['-10000']], [[' len(str1) == len(str2) and sorted(str1) == sorted(str2)\n']], ['How can I check if a string has the same characters? Python'], 2, 1], [(18340475, 0), [['A non-capturing group for the repeat would work much better here:'], ['Demo:']], [[" m = re.findall(r'TEST\\s\\((?:\\d+\\s?)*\\)', str)\n"]], ['Parenthesized repetitions in Python regular expressions'], 2, 1], [(18340475, 1), [['Demo:'], ['Without the capturing group,  re.findall()  returns the whole match.']], [[" >>> import re\n>>> s = '(((TEST (4 5 17 33 38 45 93 101 104 108 113 116 135 146 148)) (TRAIN (0 1 2 3 6 7 8 9 10 11 12 13 14 15 16 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 34 35 36 37 39 40 41 42 43 44 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 94 95 96 97 98 99 100 102 103 105 106 107 109 110 111 112 114 115 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 136 137 138 139 140 141 142 143 144 145 147 149 150 151))) ((TEST (19 35 46 47 48 56 59 61 65 69 71 84 105 107 130)) (TRAIN (0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45 49 50 51 52 53 54 55 57 58 60 62 63 64 66 67 68 70 72 73 74 75 76 77 78 79 80 81 82 83 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 106 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151)))'\n>>> re.findall(r'TEST\\s\\((?:\\d+\\s?)*\\)', s)\n['TEST (4 5 17 33 38 45 93 101 104 108 113 116 135 146 148)', 'TEST (19 35 46 47 48 56 59 61 65 69 71 84 105 107 130)']\n"]], ['Parenthesized repetitions in Python regular expressions'], 2, 1], [(18353465, 0), [['-10000'], ['For example:']], [[' your_value = 3\nresult = reduce(lambda x, y: y(x), function_list, your_value)\n']], ['How to apply an array of functions to a value using list comprehension?'], 2, 1], [(18353465, 1), [['For example:'], ['-10000']], [[' >>> functions = [lambda x: x + 2, lambda x: x * 2]\n>>> reduce(lambda x, y: y(x), functions, 1)\n6\n']], ['How to apply an array of functions to a value using list comprehension?'], 2, 1], [(18386302, 0), [['From the docstring for  scipy.ndimage.interpolate.zoom :'], ['For example,  if the physical dimensions of  whole  and  flash  can be assumed to be equal , then you could do something like this:']], [[' """\nzoom : float or sequence, optional\n    The zoom factor along the axes. If a float, `zoom` is the same for each\n    axis. If a sequence, `zoom` should contain one value for each axis.\n"""\n']], ['Resizing a 3D image (and resampling)'], 2, 0], [(18386302, 1), [['For example,  if the physical dimensions of  whole  and  flash  can be assumed to be equal , then you could do something like this:'], ['-10000']], [['  dsfactor = [w/float(f) for w,f in zip(whole.shape, flash.shape)]\n downed = nd.interpolation.zoom(flash, zoom=dsfactor)\n']], ['Resizing a 3D image (and resampling)'], 2, 1], [(18443220, 0), [['This creates a reference to MyClass:'], ["This creates a new class based on myObj's class:"]], [[' >>> class MyClass(object):\n...     pass\n... \n>>> myObj = MyClass()\n>>> NewClass = myObj.__class__\n>>> newObj = NewClass()\n>>> myObj, newObj\n(<__main__.MyClass object at 0x102740d90>, <__main__.MyClass object at 0x102740d50>)\n']], ['class name as variable in python'], 2, 1], [(18472262, 0), [["Your first case doesn't even need a regex. You can simply do:"], ['For your 2nd case, you can use:']], [[' "Dogs,Cats".split(",")\n']], ['Python Regex on comma, space'], 2, 0], [(18474538, 0), [['Do you have all the software you need? This is what you need for Ubuntu 12.04:'], ['/etc/odbc.ini']], [[' sudo apt-get install php5-odbc php5-sybase tdsodbc\n']], ['Connect to MSSQL Server 2008 on linux'], 7, 0], [(18474538, 1), [['/etc/odbc.ini'], ['/etc/odbcinst.ini']], [[' # Define a connection to the MSSQL server.\n# The Description can be whatever we want it to be.\n# The Driver value must match what we have defined in /etc/odbcinst.ini\n# The Database name must be the name of the database this connection will connect to.\n# The ServerName is the name we defined in /etc/freetds/freetds.conf\n# The TDS_Version should match what we defined in /etc/freetds/freetds.conf\n[mssql]\nDescription             = MSSQL Server\nDriver                  = freetds\nDatabase                = MyDatabase\nServerName              = mssql\nTDS_Version             = 8.0\n']], ['Connect to MSSQL Server 2008 on linux'], 7, 0], [(18474538, 2), [['/etc/odbcinst.ini'], ['/etc/freetds/freetds.conf']], [[' # Define where to find the driver for the Free TDS connections.\n[freetds]\nDescription     = MS SQL database access with Free TDS\nDriver          = /usr/lib/i386-linux-gnu/odbc/libtdsodbc.so\nSetup           = /usr/lib/i386-linux-gnu/odbc/libtdsS.so\nUsageCount      = 1\n']], ['Connect to MSSQL Server 2008 on linux'], 7, 0], [(18474538, 3), [['/etc/freetds/freetds.conf'], ['Then test your connection:']], [[' # The basics for defining a DSN (Data Source Name)\n# [data_source_name]\n#       host = <hostname or IP address>\n#       port = <port number to connect to - probably 1433>\n#       tds version = <TDS version to use - probably 8.0>\n\n# Define a connection to the MSSQL server.\n[mssql]\n        host = mssql_server_ip_or_domain_name\n        port = 1433\n        tds version = 8.0\n']], ['Connect to MSSQL Server 2008 on linux'], 7, 0], [(18474538, 4), [['Then test your connection:'], ['After issuing the command you should see something like:']], [[' isql mssql username password\n']], ['Connect to MSSQL Server 2008 on linux'], 7, 0], [(18474538, 5), [['After issuing the command you should see something like:'], ["And here's what I think your connect command should look like (NOTE: I don't know Python):"]], [[' +---------------------------------------+\n| Connected!                            |\n|                                       |\n| sql-statement                         |\n| help [tablename]                      |\n| quit                                  |\n|                                       |\n+---------------------------------------+\nSQL>\n']], ['Connect to MSSQL Server 2008 on linux'], 7, 0], [(18474538, 6), [["And here's what I think your connect command should look like (NOTE: I don't know Python):"], ['-10000']], [[" cnxn = pyodbc.connect('DRIVER=freetds;SERVER=FOOBAR;PORT=1433;DATABASE=T2;UID=FOO;PWD=bar;TDS_Version=8.0;')\n"]], ['Connect to MSSQL Server 2008 on linux'], 7, 1], [(18497810, 0), [['-10000'], ["Or if you wan't a fast for loop without side effects use:"]], [[' >>> lis_A = [[], [], []]\n>>> vals = [1,2,3]\n>>> [x.append(y) for x, y in zip(lis_A, vals)]\n>>> lis_A\n[[1], [2], [3]]\n']], ['Append to several lists inside list'], 2, 1], [(18497810, 1), [["Or if you wan't a fast for loop without side effects use:"], ['-10000']], [[' from itertools import izip\n\nfor x, y in izip(lis_A, vals):\n    x.append(y)\n']], ['Append to several lists inside list'], 2, 1], [(18507244, 0), [['Here is a complete example:'], ['And its usage:']], [[' #include <iostream>\n\n#include <boost/python.hpp>\n\n// Mockup classes.\nstruct AgentBase   {};\nstruct MessageBase {};\nstruct QueueBase   {};\nstruct SpamBase    {};\nstruct Agent:   AgentBase   {};\nstruct Message: MessageBase {};\nstruct Queue:   QueueBase   {};\nstruct Spam:    SpamBase    {};\n\n// Class with overloaded operator().\nclass Queuer\n{ \npublic:\n\n  void operator()(const AgentBase&, const MessageBase&) const\n  {\n    std::cout << "Queuer::operator() with Agent." << std::endl;\n  }\n\n  void operator()(const QueueBase&, const MessageBase&) const\n  {\n    std::cout << "Queuer::operator() with Queue." << std::endl;\n  }\n\n  void operator()(const SpamBase&, const MessageBase&) const\n  {\n    std::cout << "Queuer::operator() with Spam." << std::endl;\n  }\n};\n\n/// Depending on the overlaod signatures, helper types may make the\n/// code slightly more readable by reducing pointer-to-member-function syntax.\ntemplate <typename A1>\nstruct queuer_overload\n{\n  typedef void (Queuer::*type)(const A1&, const MessageBase&) const;\n  static type get(type fn) { return fn; }\n};\n\nBOOST_PYTHON_MODULE(example)\n{\n  namespace python = boost::python;\n  // Expose only the base class types.  Do not allow the classes to be\n  // directly initialized in Python.\n  python::class_<AgentBase  >("AgentBase",   python::no_init);\n  python::class_<MessageBase>("MessageBase", python::no_init);\n  python::class_<QueueBase  >("QueueBase",   python::no_init);\n  python::class_<SpamBase   >("SpamBase",    python::no_init);\n\n  // Expose the user types.  These classes inerit from their respective\n  // base classes.\n  python::class_<Agent,   python::bases<AgentBase>   >("Agent");\n  python::class_<Message, python::bases<MessageBase> >("Message");\n  python::class_<Queue,   python::bases<QueueBase>   >("Queue");\n  python::class_<Spam,    python::bases<SpamBase>    >("Spam");\n\n  // Disambiguate via a varaible.\n  queuer_overload<AgentBase>::type queuer_op_agent = &Queuer::operator();\n\n  python::class_<Queuer>("Queuer")\n    // Disambiguate via a variable.\n    .def("__call__", queuer_op_agent)\n    // Disambiguate via a helper type.\n    .def("__call__", queuer_overload<QueueBase>::get(&Queuer::operator()))\n    // Disambiguate via explicit cast.\n    .def("__call__",\n         static_cast<void (Queuer::*)(const SpamBase&, \n                                      const MessageBase&) const>(\n             &Queuer::operator()))\n    ;\n}\n']], ['boost python overload operator ()'], 2, 1], [(18507244, 1), [['And its usage:'], ['-10000']], [[' >>> import example\n>>> queuer = example.Queuer()\n>>> queuer(example.Agent(), example.Message())\nQueuer::operator() with Agent.\n>>> queuer(example.Queue(), example.Message())\nQueuer::operator() with Queue.\n>>> queuer(example.Spam(), example.Message())\nQueuer::operator() with Spam.\n']], ['boost python overload operator ()'], 2, 0], [(18507736, 0), [['You can do something like this:'], ['which in case of your file will print:']], [[" with open ('test.txt', 'r') as infile:\n    data = infile.readlines()\n    for line, content in enumerate(data, start=1):\n            if content.strip() == 'this is my horse':\n                print line\n"]], ['how to find the line number where specific text exists?'], 2, 1], [(18507736, 1), [['which in case of your file will print:'], ['-10000']], [[' 4\n']], ['how to find the line number where specific text exists?'], 2, 0], [(18535645, 0), [['Do you mean you want to load the database into your object and continue to use your "UI" code to edit it after closing the program? If so then you can do something like:'], ['Edit:  Another option to update, if that is the case, if you want to add or update specific items:']], [[" class Update_MyStore(MyStore):\n    def __init__(self, store):\n        db = shelve.open(store)\n        for i in db:\n            setattr(self, i, db[i])\n        self.items()\n        self.store_in_db()\nUpdate_MyStore('store')\n"]], ['How to *append* a text to a database file opened with shelve?'], 2, 1], [(18535645, 1), [['Edit:  Another option to update, if that is the case, if you want to add or update specific items:'], ['-10000']], [[" while True:\n    store = shelve.open('store',writeback = True)\n    Item = input('Enter an item: ').capitalize() #I prefer str(raw_input('Question '))\n    if not Item or Item == 'Break':\n        break\n    store['item_quantity'][Item] = int(input(('Enter the number of {0} available in the store: ').format(Item)))\n    store['item_rate'][Item] = float(input(('Enter the rate of {0}: ').format(Item)))\n    store.sync()\n    store.close()\n"]], ['How to *append* a text to a database file opened with shelve?'], 2, 1], [(18540321, 1), [['For the example list from his comments above:'], ['val  ends up containing']], [[" x = ['1', '1377877381', 'off', '0', \n     '2', '1377886582', 'on', '0', \n     '3', '1376238596', 'off', '0', \n     '4', '1377812526', 'off', '0']\n"]], ['python for loop using lambda syntax'], 6, 0], [(18540321, 2), [['val  ends up containing'], ['An equivalent line using  map()  and  lambda  looks like this:']], [[" [['1', '1377877381', 'off', '0'],\n ['2', '1377886582', 'on', '0'],\n ['3', '1376238596', 'off', '0'],\n ['4', '1377812526', 'off', '0']]\n"]], ['python for loop using lambda syntax'], 6, 0], [(18540321, 4), [['One could now loop over this call to map, assigning to a, b, c, d, and do whatever:'], ["Here's my Python 2.x version:"]], [[' for a, b, c, d in map(lambda y: x[y*4:y*4+4], range(len(x)//4)):\n\n    ...  more code ...\n']], ['python for loop using lambda syntax'], 6, 1], [(18540321, 5), [["Here's my Python 2.x version:"], ['-10000']], [[' from itertools import imap\n\nfor a, b, c, d in imap(lambda y: x[y*4:y*4+4], xrange(len(x)//4)):\n\n    ...  more code  ...\n']], ['python for loop using lambda syntax'], 6, 1], [(18556448, 0), [['You could make a function which tests if the input is a list or a string and returns appropriately and handles the rest as you see fit. Something along the lines of'], ['You could only check for strings too, (Assuming Python 2.x, replace  basestring  with  str  in Py3)']], [[" >>> def convert_to_tuple(elem):\n        if isinstance(elem, list):\n            return tuple(elem)\n        elif isinstance(elem, basestring):\n            return (elem,)\n        else:\n            # Do Something\n            pass\n\n\n>>> convert_to_tuple('abc')\n('abc',)\n>>> convert_to_tuple(['abc', 'def'])\n('abc', 'def')\n"]], ['String of list or strings to a tuple'], 3, 1], [(18580032, 0), [['You are looking for multisets, really. Use  collections.Counter() , the Python implementation of a multiset:'], ['Demo:']], [[' from collections import Counter\n\nacount = Counter(a)\nbcount = Counter(b)\nresult = list((acount - bcount).elements())\n']], ['Remove elements of one list from another, while keeping duplicates'], 2, 1], [(18580032, 1), [['Demo:'], ['You may want to retain the  Counter()  instances however; but if you need it the  Counter.elements()  method generates a sequence of elements times their count to produce your desired output again.']], [[" >>> from collections import Counter\n>>> a = ['a', 'a', 'b', 'c', 'c', 'c', 'd', 'e', 'f']\n>>> b = ['a', 'b', 'c', 'd', 'e', 'f']\n>>> Counter(a) - Counter(b)\nCounter({'c': 2, 'a': 1})\n>>> list((Counter(a) - Counter(b)).elements())\n['a', 'c', 'c']\n"]], ['Remove elements of one list from another, while keeping duplicates'], 2, 1], [(18589821, 0), [['One solution could be to use  get dummies  (which  should  be more efficient that apply):'], ['You could use an apply with a couple of locs:']], [[' In [11]: (pd.get_dummies(useProb) * pred).sum(axis=1)\nOut[11]:\nTimestamp\n2010-12-21 00:00:00    0\n2010-12-20 00:00:00    1\n2010-12-17 00:00:00    1\n2010-12-16 00:00:00    1\n2010-12-15 00:00:00    1\n2010-12-14 00:00:00    1\n2010-12-13 00:00:00    0\n2010-12-10 00:00:00    1\n2010-12-09 00:00:00    1\n2010-12-08 00:00:00    0\ndtype: float64\n']], ['Create a Series from a Pandas DataFrame by choosing an element from different columns on each row'], 2, 1], [(18589821, 1), [['You could use an apply with a couple of locs:'], ['The trick being that you have access to the rows index via the name property.']], [[' In [21]: pred.apply(lambda row: row.loc[useProb.loc[row.name]], axis=1)\nOut[21]:\nTimestamp\n2010-12-21 00:00:00    0\n2010-12-20 00:00:00    1\n2010-12-17 00:00:00    1\n2010-12-16 00:00:00    1\n2010-12-15 00:00:00    1\n2010-12-14 00:00:00    1\n2010-12-13 00:00:00    0\n2010-12-10 00:00:00    1\n2010-12-09 00:00:00    1\n2010-12-08 00:00:00    0\ndtype: int64\n']], ['Create a Series from a Pandas DataFrame by choosing an element from different columns on each row'], 2, 1], [(18590658, 0), [['In your main script, you need to make it accept arguments. A really simple way to do that is do something like this:'], ["Then in your GUI, you would use the subprocess module to call your main script and pass the argument. So in your button's event handler, you'd do something like this:"]], [[' # dd.py\nimport sys\ndef main(arg):\n    # do something here\n    print arg\n\nif __name__ == "__main__":\n    arg = sys.argv[1]\n    main(arg)\n']], ['How to link PyQt4 script button to activate another script?'], 2, 0], [(18590658, 1), [["Then in your GUI, you would use the subprocess module to call your main script and pass the argument. So in your button's event handler, you'd do something like this:"], ["If you need to be able to pass switches or flags along with arguments, you should read up on argparse or optparse, depending on which version of Python you're using."]], [[' subprocess.Popen("/path/to/dd.py", arg)\n']], ['How to link PyQt4 script button to activate another script?'], 2, 0], [(18608160, 0), [['Try datetime module.'], ['Later']], [[' from datetime import datetime\nstart = datetime.now()\n']], ['Python: How to time script from beginning to end?'], 2, 0], [(18608160, 1), [['Later'], ['-10000']], [[' difference = datetime.now() - start\n']], ['Python: How to time script from beginning to end?'], 2, 0], [(18619131, 0), [['Just use  curve_fit  in  scipy.optimize : '], ['This gives something like the plot below. The red points are the (noisy) data, and the blue line is the best fit curve, with the best fitting parameters for that particular data of: ']], [[' import numpy as np\nfrom scipy.optimize import curve_fit\nfrom pylab import *\n\ndef myFunc(t, V, W, k):\n    y = V * t - ((V - W) * (1 - np.exp(-k * t)) / k)\n    return y\n\n# this generates some fake data to fit. For youm just read in the \n# data in CSV or whatever you\'ve\nx = np.linspace(0,4,50)\ny = myFunc(x, 2.5, 1.3, 0.5)\n# add some noise to the fake data to make it more realistic. . .\nyn = y + 0.2*np.random.normal(size=len(x))\n\n#fit the data, return the best fit parameters and the covariance matrix\npopt, pcov = curve_fit(myFunc, x, yn)\nprint popt\nprint pcov\n\n#plot the data\nclf()\nplot(x, yn, "rs")\n#overplot the best fit curve\nplot(x, myFunc(x, popt[0], popt[1], popt[2]))\ngrid(True)\nshow()\n']], ['Solve equation with a set of points'], 2, 1], [(18619131, 1), [['This gives something like the plot below. The red points are the (noisy) data, and the blue line is the best fit curve, with the best fitting parameters for that particular data of: '], ['Which is pretty close to the expected parameters of 2.5, 1.3, 0.5. The difference is due to the noise that I added in to the fake data. ']], [[' [ 2.32751132, 1.27686053, 0.65986596]\n']], ['Solve equation with a set of points'], 2, 0], [(18631669, 0), [['If your broker is configured as  redis://localhost:6379/1 , and your tasks are submitted to the general  celery  queue, then you can get the length by the following means:'], ['Or, from a shell script (good for monitors and such):']], [[' import redis\nqueue_name = "celery"\nclient = redis.Redis(host="localhost", port=6379, db=1)\nlength = client.llen(queue_name)\n']], ['Django Celery get task count'], 2, 1], [(18631669, 1), [['Or, from a shell script (good for monitors and such):'], ['-10000']], [[' $ redis-cli -n 1 -h localhost -p 6379 llen celery\n']], ['Django Celery get task count'], 2, 0], [(18646076, 0), [['-10000'], ['yields']], [[" import numpy as np\nimport pandas as pd\nimport scipy.sparse as sparse\n\ndf = pd.DataFrame(np.arange(1,10).reshape(3,3))\narr = sparse.coo_matrix(([1,1,1], ([0,1,2], [1,2,0])), shape=(3,3))\ndf['newcol'] = arr.toarray().tolist()\nprint(df)\n"]], ['Add numpy array as column to Pandas data frame'], 2, 1], [(18646076, 1), [['yields'], ['-10000']], [['    0  1  2     newcol\n0  1  2  3  [0, 1, 0]\n1  4  5  6  [0, 0, 1]\n2  7  8  9  [1, 0, 0]\n']], ['Add numpy array as column to Pandas data frame'], 2, 0], [(18673420, 0), [['With this setup:'], ['You can produce the desired DataFrame using  groupby  and  agg :']], [[" import pandas as pd\ndata = '''\\\n2013-01-01 01:00\n2013-01-01 05:00\n2013-01-01 14:00\n2013-01-02 01:00\n2013-01-02 05:00\n2013-01-04 14:00'''\ndates = pd.to_datetime(data.splitlines())\ndf = pd.DataFrame({'date': dates, 'val': range(len(dates))})\n\n>>> df\n                 date  val\n0 2013-01-01 01:00:00    0\n1 2013-01-01 05:00:00    1\n2 2013-01-01 14:00:00    2\n3 2013-01-02 01:00:00    3\n4 2013-01-02 05:00:00    4\n5 2013-01-04 14:00:00    5\n"]], ['Indexing pandas dataframe to return first data point from each day'], 3, 0], [(18673420, 2), [['yields'], ['-10000']], [['                         date  val\n20130101 2013-01-01 01:00:00    0\n20130102 2013-01-02 01:00:00    3\n20130104 2013-01-04 14:00:00    5\n']], ['Indexing pandas dataframe to return first data point from each day'], 3, 0], [(18679264, 0), [['You can also create writable arrays of  ctypes  types with the syntax:'], ['-10000']], [[' variable_name = (ctypes_type * length)(initial_values)\n']], ['How to use malloc and free with python ctypes?'], 5, 0], [(18679264, 1), [['-10000'], ['-10000']], [['x.h #ifdef DLL_EXPORTS\n#define DLL_API __declspec(dllexport)\n#else\n#define DLL_API __declspec(dllimport)\n#endif\n\nstruct example {\n    char* data;\n    int len;          // of data buffer\n    double* doubles;\n    int count;        // of doubles\n};\n\nDLL_API void func(struct example* p);\n']], ['How to use malloc and free with python ctypes?'], 5, 0], [(18679264, 2), [['-10000'], ['-10000']], [['x.c #include <stdio.h>\n#define DLL_EXPORTS\n#include "x.h"\n\nvoid func(struct example* p)\n{\n    int i;\n    strcpy_s(p->data,p->len,"hello, world!");\n    for(i = 0; i < p->count; i++)\n        p->doubles[i] = 1.1 * (i + 1);\n}\n']], ['How to use malloc and free with python ctypes?'], 5, 0], [(18679264, 3), [['-10000'], ['-10000']], [["x.py import ctypes\n\nclass Example(ctypes.Structure):\n\n    _fields_ = [\n        ('data',ctypes.POINTER(ctypes.c_char)),\n        ('len',ctypes.c_int),\n        ('doubles',ctypes.POINTER(ctypes.c_double)),\n        ('count',ctypes.c_int)]\n\n    def __init__(self,length,count):\n        self.data = ctypes.cast(ctypes.create_string_buffer(length),ctypes.POINTER(ctypes.c_char))\n        self.len = length\n        self.doubles = (ctypes.c_double * count)()\n        self.count = count\n\n    def __repr__(self):\n        return 'Example({},[{}])'.format(\n            ctypes.string_at(self.data),\n            ','.join(str(self.doubles[i]) for i in range(self.count)))\n\nclass Dll:\n\n    def __init__(self):\n        self.dll = ctypes.CDLL('x')\n        self.dll.func.argtypes = [ctypes.POINTER(Example)]\n        self.dll.func.restype = None\n\n    def func(self,ex):\n        self.dll.func(ctypes.byref(ex))\n\nd = Dll()\ne = Example(20,5)\nprint('before:',e)\nd.func(e)\nprint ('after:',e)\n"]], ['How to use malloc and free with python ctypes?'], 5, 0], [(18679264, 4), [['-10000'], ['-10000']], [["Output before: Example(b'',[0.0,0.0,0.0,0.0,0.0])\nafter: Example(b'hello, world!',[1.1,2.2,3.3000000000000003,4.4,5.5])\n"]], ['How to use malloc and free with python ctypes?'], 5, 0], [(18682304, 0), [['The regex can be shortened by quite a few characters:'], ["And so that it doesn't match  2013-29883  followed by  Dog , use another negative lookahead:"]], [[' (?<!\\d)\\d{4}-\\d{1,5}(?!\\d)\n']], ['regex condition that returns only if a " [word]" does not trail at the end'], 2, 1], [(18682304, 1), [["And so that it doesn't match  2013-29883  followed by  Dog , use another negative lookahead:"], ['-10000']], [[' (?<!\\d)\\d{4}-\\d{1,5}(?!\\d)(?! Dog)\n']], ['regex condition that returns only if a " [word]" does not trail at the end'], 2, 1], [(18689862, 1), [['The parameter passed to  __getitem__  is the "index" of the item, which can be any object:'], ['-10000']], [[' def __getitem__(self, index):\n    if isinstance(index, tuple):\n        # foo[1:2, 3:4]\n    elif isinstance(index, slice)\n        # foo[1:2]\n    else:\n        # foo[1]\n']], ['Implementing fancy indexing in a class'], 2, 0], [(18696264, 0), [['You could use  zip() , applying  sset  using the splat arbitrary arguments syntax  *args :'], ['Demo:']], [[' x, y = zip(*sset)\n']], ['How to get a list of Xth elements from a list of tuples?'], 3, 1], [(18696264, 1), [['Demo:'], ['This creates  tuples , not lists; you can map the  zip()  output to lists as required:']], [[" >>> sset = [('foo',1),('bar',3),('zzz',9)]\n>>> x, y = zip(*sset)\n>>> x\n('foo', 'bar', 'zzz')\n>>> y\n(1, 3, 9)\n"]], ['How to get a list of Xth elements from a list of tuples?'], 3, 1], [(18706785, 0), [['I see, I did not fully grasp the fact that you are trying to make ~1M bars which  is  very memory intensive.  I would suggest something like this:'], ['As a side note, the data parsing could be be further simplified to this:']], [[" import numpy as np\nfrom itertools import izip, cycle\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\nN = 100\n\nfake_data = {}\nfor j in range(97, 104):\n    lab = chr(j)\n    fake_data[lab] = np.cumsum(np.random.rand(N) > np.random.rand(1))\n\ncolors = cycle(['r', 'g', 'b', 'm', 'c', 'Orange', 'Pink'])\n\n# fig, ax = plt.subplots(1, 1, tight_layout=True) # if your mpl is newenough\nfig, ax = plt.subplots(1, 1) # other wise\nax.set_xlabel('time')\nax.set_ylabel('counts')\ncum_array = np.zeros(N*2 - 1) # to keep track of the bottoms\nx = np.vstack([arange(N), arange(N)]).T.ravel()[1:] # [0, 1, 1, 2, 2, ..., N-2, N-2, N-1, N-1]\nhands = []\nlabs = []\nfor k, c in izip(sorted(fake_data.keys()), colors):\n    d = fake_data[k]\n    dd = np.vstack([d, d]).T.ravel()[:-1]  # double up the data to match the x values [x0, x0, x1, x1, ... xN-2, xN-1]\n    ax.fill_between(x, dd + cum_array, cum_array,  facecolor=c, label=k, edgecolor='none') # fill the region\n    cum_array += dd                       # update the base line\n    # make a legend entry\n    hands.append(matplotlib.patches.Rectangle([0, 0], 1, 1, color=c)) # dummy artist\n    labs.append(k)                        # label\n\nax.set_xlim([0, N - 1]) # set the limits \nax.legend(hands, labs, loc=2)             #add legend\nplt.show()                                #make sure it shows\n"]], ['Efficiently displaying a stacked bar graph'], 2, 1], [(18706785, 1), [['As a side note, the data parsing could be be further simplified to this:'], ['not strictly tested, but I think it should work.']], [[' import numpy as np\nfrom itertools import izip\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\n# this requires you to know a head of time how many times you have\nlen = 10\nd = defaultdict(lambda : np.zeros(len, dtype=np.bool)) # save space!\nwith open(\'test.txt\', \'r\') as infile:\n    infile.next() # skip the header line\n    for line in infile:\n        tokens = line.rstrip().split(" ")\n        time = int(tokens[0]) # get the time which is the first token\n        for e in tokens[1:]:  # loop over the rest\n            if len(e) == 0:\n                pass\n            d[e][time] = True\n\nfor k in d:\n    d[k] = np.cumsum(d[k])\n']], ['Efficiently displaying a stacked bar graph'], 2, 1], [(18727686, 0), [['-10000'], ['']], [["Create test data import pandas as pd\nimport numpy as np\n\ntimes = np.random.randint(0,10,size=50)\nvalues = np.sin(times) + np.random.random_sample((len(times),))\ns = pd.Series(values, index=times)\ns.plot(linestyle='.', marker='o')\n"]], ['Numpy: averaging many datapoints at each time step'], 2, 0], [(18765094, 0), [['Every http client lib I know (at least in Python) gives you or can give you a  stream :'], ['Now you have response headers available, maybe Content-Length is present:']], [[" >>> import requests\n>>> r = requests.get('https://example.com/big-file', stream=True)\n>>> r.raw\n<requests.packages.urllib3.response.HTTPResponse object at 0x101194810>\n"]], ['Protection against downloading too big files'], 4, 0], [(18765094, 1), [['Now you have response headers available, maybe Content-Length is present:'], ["It's up to you how you read from the stream:"]], [[' >>> r.headers.get("content-length")\n\'33236\'\n']], ['Protection against downloading too big files'], 4, 0], [(18765094, 2), [["It's up to you how you read from the stream:"], ['If I wanted to limit the download by max time and max size, I would do something like this:']], [[" >>> r.raw.read(10)\n'\\x1f\\x8b\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x03'\n"]], ['Protection against downloading too big files'], 4, 0], [(18765340, 0), [['Just create a new  Surface  and fill it with the right color:'], ["Since you're already using the  Sprite  class, what's the point of the  imprime  function anyway? Just use a  pygame.sprite.Group  to draw your sprites to the screen. That said, the  rect  member of a  Sprite  is used for positioning, so you can simplify your  bola  class to:"]], [[' class raquete(pygame.sprite.Sprite):\n\n    def __init__(self, x, y, l_raquete, a_raquete):\n        pygame.sprite.Sprite.__init__(self)\n        self.image = pygame.Surface((l_raquete, a_raquete))\n        # I guess branco means color\n        self.image.fill(branco) \n        # no need for the x and y members, \n        # since we store the position in self.rect already\n        self.rect = self.image.get_rect(x=x, y=y) \n']], ['Pygame - Getting a rectangle for a dynamically drawn object'], 2, 1], [(18772706, 0), [['You could use  itertools.product :'], ['Possible one liner:']], [[" li = []\nfor i in itertools.product([0,1], repeat=4):\n    li.append(''.join(map(str, i)))\nprint (li)\n\n>>> li\n['0000', '0001', '0010', '0011', '0100', '0101', '0110', '0111', '1000', '1001', '1010', '1011', '1100', '1101', '1110', '1111']\n"]], ['How to generate combination of fix length strings using a set of characters?'], 2, 1], [(18772706, 1), [['Possible one liner:'], ['-10000']], [[" [''.join(map(str, i)) for i in itertools.product([0,1], repeat=4)]\n"]], ['How to generate combination of fix length strings using a set of characters?'], 2, 1], [(18787830, 0), [['Simply use fgrep:'], ['Or grep -f']], [[' fgrep -rlf messages.txt dir\n']], ['Search multiple strings in multiple files'], 4, 1], [(18787830, 1), [['Or grep -f'], ["If you want to search for regex, don't use -F:"]], [[' grep -Frlf messages.txt dir\n']], ['Search multiple strings in multiple files'], 4, 1], [(18787830, 2), [["If you want to search for regex, don't use -F:"], ['Update: If your lines messages.txt contain patterns like foo=bar, you can use cut with process substitution and cut in bash:']], [[' grep -rlf messages.txt dir\n']], ['Search multiple strings in multiple files'], 4, 1], [(18787830, 3), [['Update: If your lines messages.txt contain patterns like foo=bar, you can use cut with process substitution and cut in bash:'], ['-10000']], [[' grep -rlf <(cut -d = -f 2- messages.txt) dir\n']], ['Search multiple strings in multiple files'], 4, 1], [(18802249, 0), [['First, add token definition for english words'], ['Add those new tokens to  tokens']], [[" t_plustext    = r'plus'\n"]], ['How to make a calculator with strings and numbers as mixed input using parser python ply'], 4, 0], [(18802249, 1), [['Add those new tokens to  tokens'], ['Finally, use those new token in you grammar this way :']], [[" tokens = (\n    'NAME','NUMBER', 'times', 'divided_by', 'plus', 'minus', 'plustext', ....\n)\n"]], ['How to make a calculator with strings and numbers as mixed input using parser python ply'], 4, 0], [(18802249, 2), [['Finally, use those new token in you grammar this way :'], ['UPDATE  : here is a working subset of the grammar']], [[" def p_expression_binop(p):\n    '''expression : expression '+' expression\n                  | expression plustext expression\n    '''\n"]], ['How to make a calculator with strings and numbers as mixed input using parser python ply'], 4, 0], [(18802249, 3), [['UPDATE  : here is a working subset of the grammar'], ['-10000']], [[' #!/usr/bin/python\n\nfrom __future__ import print_function\n\nimport sys\nimport ply.lex as lex\nimport ply.yacc as yacc\n\n# ------- Calculator tokenizing rules\n\ntokens = (\n    \'NUMBER\', \'times\', \'divided_by\', \'plus\', \'minus\', \'plustext\',\n    \'one\', \'two\', \'three\',\n)\n\nliterals = [\'=\',\'+\',\'-\',\'*\',\'/\', \'(\',\')\']\n\nt_ignore = " \\t\\n"\n\nt_plustext    = r\'plus\'\nt_plus    = r\'\\+\'\nt_minus   = r\'-\'\nt_times   = r\'\\*\'\nt_divided_by  = r\'/\'\nt_one = \'one\'\nt_two = \'two\'\nt_three = \'three\'\n\ndef t_NUMBER(t):\n    r\'\\d+\'\n    try:\n        t.value = int(t.value)\n    except ValueError:\n        print("Integer value too large %d", t.value)\n        t.value = 0\n    return t\n\nprecedence = (\n    (\'left\',\'+\',\'-\',\'plustext\'),\n    (\'left\',\'times\',\'divided_by\'),\n    (\'left\',\'*\',\'/\'),\n)\n\n\ndef p_statement_expr(p):\n    \'statement : expression\'\n    p[0] = p[1]\n    print(p[1])\n\ndef p_expression_binop(p):\n    \'\'\'expression : expression \'+\' expression\n                  | expression plustext expression\n                  | expression \'-\' expression\n                  | expression \'*\' expression\n                  | expression \'/\' expression\'\'\'\n    if p[2] ==   \'+\'  : p[0] = p[1] + p[3]\n    elif p[2] == \'-\': p[0] = p[1] - p[3]\n    elif p[2] == \'*\': p[0] = p[1] * p[3]\n    elif p[2] == \'/\': p[0] = p[1] / p[3]\n    elif p[2] == \'plus\': p[0] = p[1] + p[3]\n\ndef p_statement_lit(p):\n    \'\'\'expression : NUMBER\n          | TXTNUMBER\n    \'\'\'\n    p[0] = p[1]\n\ndef p_txtnumber(p):\n    \'\'\'TXTNUMBER : one\n         | two\n         | three\n    \'\'\'\n    p[0] = w2n(p[1])\n\ndef w2n(s):\n    if s == \'one\': return 1\n    elif s == \'two\': return 2\n    elif s == \'three\': return 3\n    assert(False)\n    # See http://stackoverflow.com/questions/493174/is-there-a-way-to-convert-number-words-to-integers-python for a complete implementation\n\ndef process(data):\n    lex.lex()\n        yacc.yacc()\n        #yacc.parse(data, debug=1, tracking=True)\n        yacc.parse(data)\n\nif __name__ == "__main__":\n        data = open(sys.argv[1]).read()\n        process(data)\n']], ['How to make a calculator with strings and numbers as mixed input using parser python ply'], 4, 1], [(18802563, 0), [['Import NumPy :'], ["Generate 8000 high-precision floats (128-bits will be enough for your purposes, but note that I'm converting the 64-bits output of  random  to 128 just to fake it. Use your real data here.) :"]], [[' import numpy as np\n']], ['Efficiently Removing Very-Near-Duplicates From Python List'], 4, 0], [(18802563, 1), [["Generate 8000 high-precision floats (128-bits will be enough for your purposes, but note that I'm converting the 64-bits output of  random  to 128 just to fake it. Use your real data here.) :"], ['Find the indexes of the unique elements in the rounded array :']], [[' a = np.float128(np.random.random((8000,)))\n']], ['Efficiently Removing Very-Near-Duplicates From Python List'], 4, 0], [(18802563, 2), [['Find the indexes of the unique elements in the rounded array :'], ['And take those indexes from the original (non-rounded) array :']], [[' _, unique = np.unique(a.round(decimals=14), return_index=True)\n']], ['Efficiently Removing Very-Near-Duplicates From Python List'], 4, 0], [(18802563, 3), [['And take those indexes from the original (non-rounded) array :'], ['-10000']], [[' no_duplicates = a[unique]\n']], ['Efficiently Removing Very-Near-Duplicates From Python List'], 4, 0], [(18817616, 0), [["Normally, I would regex this, but since that has already been suggested, here's a more DIY approach (just for completeness):"], ['Output: ']], [[' def countSpaces(s):\n    answer = []\n    start = None\n    maxCount = 0\n    for i,char in enumerate(s):\n        if char == \' \':\n            if start is None:\n                start = i\n                answer.append(char)\n        else:\n            if start is not None:\n                maxCount = max(i-start-1, maxCount)\n                start = None\n            answer.append(char)\n    print("The whitespace normalized string is", \'\'.join(answer))\n    print("The maximum length of consecutive whitespace is", maxCount)\n']], ['removing excess spaces from a string (and counting them)'], 2, 1], [(18817616, 1), [['Output: '], ['-10000']], [[' >>> s = "foo    bar  baz                        bam"\n>>> countSpaces(s)\nThe whitespace normalized string is foo bar baz bam\nThe maximum length of consecutive whitespace is 23\n']], ['removing excess spaces from a string (and counting them)'], 2, 0], [(18839875, 0), [['Goodness, when did Python programmers become afraid of easy loops?  LOL.'], ['In any spelling of']], [[' result = Counter()\nfor c in counters:\n    result |= c\n']], ['Union of many Counters'], 2, 1], [(18839875, 1), [['In any spelling of'], ['instead, the entire partial result so far keeps getting thrown away when the next partial result is computed.  That may - or may not - be a lot slower.']], [[' counters[0] | counters[1] | counters[2] | ...\n']], ['Union of many Counters'], 2, 0], [(18854425, 0), [["You can improve on @Bill's solution by reducing intermediate storage to the diagonal elements only:"], ['Another option is to use  np.einsum  and have no explicit intermediate storage at all:']], [[' from numpy.core.umath_tests import inner1d\n\nm, n = 1000, 500\n\na = np.random.rand(m, n)\nb = np.random.rand(n, m)\n\n# They all should give the same result\nprint np.trace(a.dot(b))\nprint np.sum(a*b.T)\nprint np.sum(inner1d(a, b.T))\n\n%timeit np.trace(a.dot(b))\n10 loops, best of 3: 34.7 ms per loop\n\n%timeit np.sum(a*b.T)\n100 loops, best of 3: 4.85 ms per loop\n\n%timeit np.sum(inner1d(a, b.T))\n1000 loops, best of 3: 1.83 ms per loop\n']], ['What is the best way to compute the trace of a matrix product in numpy?'], 3, 1], [(18854425, 2), [['On my system it runs slightly slower than using  inner1d , but it may not hold for all systems, see  this question :'], ['-10000']], [[" %timeit np.einsum('ij,ji->', a, b)\n100 loops, best of 3: 1.91 ms per loop\n"]], ['What is the best way to compute the trace of a matrix product in numpy?'], 3, 0], [(18919032, 0), [['For stuff like that I normally use the following construct:    '], ['Then the call would like:']], [[' from threading import Timer\nimport thread\n\ndef run_with_timeout( timeout, func, *args, **kwargs ):\n    """ Function to execute a func for the maximal time of timeout.\n    [IN]timeout        Max execution time for the func\n    [IN]func           Reference of the function/method to be executed\n    [IN]args & kwargs  Will be passed to the func call\n    """\n    try:\n        # Raises a KeyboardInterrupt if timer triggers\n        timeout_timer = Timer( timeout, thread.interrupt_main )\n        timeout_timer.start()\n        return func( *args, **kwargs )\n    except KeyboardInterrupt:\n        print "run_with_timeout timed out, when running \'%s\'" %  func.__name__\n        #Normally I raise here my own exception\n    finally:\n        timeout_timer.cancel()\n']], ['How to see if section of python code completes within a given time'], 2, 1], [(18919032, 1), [['Then the call would like:'], ['-10000']], [[' timeout = 5.2 #Time in sec\nfor i in range(len(arr1)):\n    res1 = run_with_timeout(timeout, foo1,arr1[i]))\n']], ['How to see if section of python code completes within a given time'], 2, 0], [(18921302, 0), [['-10000'], ['usage:']], [[' import random\ndef sample_gen(n, forbid):\n    state = dict()\n    track = dict()\n    for (i, o) in enumerate(forbid):\n        x = track.get(o, o)\n        t = state.get(n-i-1, n-i-1)\n        state[x] = t\n        track[t] = x\n        state.pop(n-i-1, None)\n        track.pop(o, None)\n    del track\n    for remaining in xrange(n-len(forbid), 0, -1):\n        i = random.randrange(remaining)\n        yield state.get(i, i)\n        state[i] = state.get(remaining - 1, remaining - 1)\n        state.pop(remaining - 1, None)\n']], ['How to incrementally sample without replacement?'], 2, 1], [(18921302, 1), [['usage:'], ['-10000']], [[' gen = sample_gen(10, [1, 2, 4, 8])\nprint gen.next()\nprint gen.next()\nprint gen.next()\nprint gen.next()\n']], ['How to incrementally sample without replacement?'], 2, 0], [(18938302, 1), [['Turns this:'], ['Into this:']], [[' A   786 65534 65534 786 786 786 786 10026/AS4637 19151 19151 19151 19151 19151     19151 10796/AS13706\n']], ['Remove duplicate, remove certain letters from line if found'], 3, 0], [(18938302, 2), [['Into this:'], ["Obviously, it's not quite what you want yet, but try to do the rest yourself. :) The  str.replace()  method  might help you getting rid of those  /AS ."]], [[' A 786 10026/AS4637 19151 10796/AS13706\n']], ['Remove duplicate, remove certain letters from line if found'], 3, 0], [(18952977, 1), [['now when you next time read from file use seek() function'], ['Hope This will Help :)']], [[' f = open("test.json" , "w+")\nf.seek(last_position)\nf.read() # now this will start reading from last position\n']], ['Parsing the json file after a specific time interval'], 2, 0], [(18972212, 0), [['One possible solution would be to  flatten  the list:'], ['This will allow you to traverse the list in order:']], [[' def flatten(lst):\n    if not lst:\n        return []\n    elif not isinstance(lst, list):\n        return [lst] \n    else:\n        return flatten(lst[0]) + flatten(lst[1:])\n']], ['recursively (or non-recursively) iterating through python array and get the elements'], 3, 1], [(18972212, 1), [['This will allow you to traverse the list in order:'], ['Or alternatively, using generators:']], [[" ls1 = [[[[1, '1.0.1'], [1, '2.0.1']], [1, '3.0.11']], [1, '4.0.11']]\nflatten(ls1)\n=> [1, '1.0.1', 1, '2.0.1', 1, '3.0.11', 1, '4.0.11']\n"]], ['recursively (or non-recursively) iterating through python array and get the elements'], 3, 0], [(18972212, 2), [['Or alternatively, using generators:'], ['-10000']], [[" def flatten(lst):\n    if not lst:\n        return\n    elif not isinstance(lst, list):\n        yield lst\n    else:\n        for e in flatten(lst[0]):\n            yield e\n        for e in flatten(lst[1:]):\n            yield e\n\nlist(flatten(ls1))\n=> [1, '1.0.1', 1, '2.0.1', 1, '3.0.11', 1, '4.0.11']\n"]], ['recursively (or non-recursively) iterating through python array and get the elements'], 3, 1], [(19031953, 0), [['Using  unittest.TestCase.skipTest :'], ['prints']], [[" import unittest\n\nclass TestFoo(unittest.TestCase):\n    def setUp(self): print('setup')\n    def tearDown(self): print('teardown')\n    def test_spam(self): pass\n    def test_egg(self): pass\n    def test_ham(self): pass\n\nif __name__ == '__main__':\n    import sys\n    loader = unittest.loader.defaultTestLoader\n    runner = unittest.TextTestRunner(verbosity=2)\n    suite = loader.loadTestsFromModule(sys.modules['__main__'])\n    for ts in suite:\n        for t in ts:\n            if t.id().endswith('am'): # To skip `test_spam` and `test_ham`\n                setattr(t, 'setUp', lambda: t.skipTest('criteria'))\n    runner.run(suite)\n"]], ['Skip unittest test without decorator syntax'], 2, 1], [(19031953, 1), [['prints'], ['UPDATE']], [[" test_egg (__main__.TestFoo) ... setup\nteardown\nok\ntest_ham (__main__.TestFoo) ... skipped 'criteria'\ntest_spam (__main__.TestFoo) ... skipped 'criteria'\n\n----------------------------------------------------------------------\nRan 3 tests in 0.001s\n\nOK (skipped=2)\n\n\n----------------------------------------------------------------------\nRan 3 tests in 0.002s\n\nOK (skipped=2)\n"]], ['Skip unittest test without decorator syntax'], 2, 0], [(19043923, 0), [['I think  using datetime.isocalendar is a nice solution. This give the correct outputs for your example:'], ['As an example:']], [[' import datetime\n\ndef iso_year_start(iso_year):\n    "The gregorian calendar date of the first day of the given ISO year"\n    fourth_jan = datetime.date(iso_year, 1, 4)\n    delta = datetime.timedelta(fourth_jan.isoweekday()-1)\n    return fourth_jan - delta \n\ndef iso_to_gregorian(iso_year, iso_week, iso_day):\n    "Gregorian calendar date for the given ISO year, week and day"\n    year_start = iso_year_start(iso_year)\n    return year_start + datetime.timedelta(days=iso_day-1, weeks=iso_week-1)\n\n\ndef week_start_end(date):\n    year = date.isocalendar()[0]\n    week = date.isocalendar()[1]\n    d1 = iso_to_gregorian(year, week, 0)\n    d2 = iso_to_gregorian(year, week, 6)\n    d3 = datetime.datetime(d1.year, d1.month, d1.day, 0,0,0,0)\n    d4 = datetime.datetime(d2.year, d2.month, d2.day, 23,59,59,999999)\n    return (d3,d4)\n']], ['tuple of datetime objects in Python'], 2, 1], [(19043923, 1), [['As an example:'], ['And should help you with your problem.']], [[' >>> d = datetime.datetime(2013, 8, 15, 12, 0, 0)\n>>> print week_start_end(d)\n(datetime.datetime(2013, 8, 11, 0, 0), datetime.datetime(2013, 8, 17, 23, 59, 59, 999999))\n']], ['tuple of datetime objects in Python'], 2, 0], [(19045971, 0), [['To sample with this probability, do  random.random() < x-int(x)'], ['EDIT: adding an optional  prec  argument:']], [[' import random\nimport math\nimport numpy as np\n\ndef prob_round(x):\n    sign = np.sign(x)\n    x = abs(x)\n    is_up = random.random() < x-int(x)\n    round_func = math.ceil if is_up else math.floor\n    return sign * round_func(x)\n\nx = 6.1\nsum( prob_round(x) for i in range(100) ) / 100.\n=> 6.12\n']], ['Random rounding to integer in Python'], 2, 1], [(19045971, 1), [['EDIT: adding an optional  prec  argument:'], ['-10000']], [[' def prob_round(x, prec = 0):\n    fixup = np.sign(x) * 10**prec\n    x *= fixup\n    is_up = random.random() < x-int(x)\n    round_func = math.ceil if is_up else math.floor\n    return round_func(x) / fixup\n\nx = 8.33333333\n[ prob_round(x, prec = 2) for i in range(10) ]\n=> [8.3399999999999999,\n 8.3300000000000001,\n 8.3399999999999999,\n 8.3300000000000001,\n 8.3300000000000001,\n 8.3300000000000001,\n 8.3300000000000001,\n 8.3300000000000001,\n 8.3399999999999999,\n 8.3399999999999999]\n']], ['Random rounding to integer in Python'], 2, 1], [(19079040, 0), [['You can use  WebDriver.execute_script . For example:'], ['-10000']], [[" from selenium import webdriver\n\ndriver = webdriver.Firefox()\ndriver.get('http://jsfiddle.net/falsetru/mLGnB/show/')\nelem = driver.find_element_by_css_selector('div.dijitReset>input[type=hidden]')\ndriver.execute_script('''\n    var elem = arguments[0];\n    var value = arguments[1];\n    elem.value = value;\n''', elem, '2013-11-26')\n"]], ['Selenium (Python): How to insert value on a hidden input?'], 2, 1], [(19079040, 1), [['-10000'], ['-10000']], [[' from selenium import webdriver\n\ndriver = webdriver.Firefox()\ndriver.get(\'http://matrix.itasoftware.com/\')\nelem = driver.find_element_by_xpath(\n    \'.//input[@id="ita_form_date_DateTextBox_0"]\'\n    \'/following-sibling::input[@type="hidden"]\')\n\nvalue = driver.execute_script(\'return arguments[0].value;\', elem)\nprint("Before update, hidden input value = {}".format(value))\n\ndriver.execute_script(\'\'\'\n    var elem = arguments[0];\n    var value = arguments[1];\n    elem.value = value;\n\'\'\', elem, \'2013-11-26\')\n\nvalue = driver.execute_script(\'return arguments[0].value;\', elem)\nprint("After update, hidden input value = {}".format(value))\n']], ['Selenium (Python): How to insert value on a hidden input?'], 2, 1], [(19122988, 0), [['You can use set operations on the  dictionary keys view :'], ['Demo of the different outcomes of the set operation:']], [[" if len(kargs.viewkeys() & {'dollar', 'euro'}) != 1:\n    raise ValueError('One keyword argument is required: dollar=x or euro=x')\n"]], ['Require one out of two keyword arguments'], 5, 1], [(19122988, 2), [['If you do not want to allow any  other  keyword arguments besides  dollar  and  euro , then you can also use proper subset tests. Using  <  with two sets is only True if the left-hand set is strictly smaller than the right-hand set; it only has  fewer  keys than the other set and no extra keys:'], ['On Python 3, that can be spelled as:']], [[" if {}.viewkeys() < kargs.viewkeys() < {'dollar', 'euro'}:\n    raise ValueError('One keyword argument is required: dollar=x or euro=x')\n"]], ['Require one out of two keyword arguments'], 5, 1], [(19124072, 2), [['\nThe output in both cases looks like:'], ["If you know a better way to accomplish this, please don't hesitate to post your solution."]], [[' field1      0  -0.0919\n            1  -1.4634\n            2   1.0818\n            3  -0.2393\nfield2      0  -0.4911\n            1  -1.0023\n            2   0.9188\n            3  -1.1036\n            4   0.6265\n            5  -0.5615\n            6   0.0289\n            7  -0.2308\nfield3      0   0.5878\n            1   0.7523\n            2  -1.0585\n            3   1.0560\n            4   0.7478\n            5   1.0647\n']], ['Access a Numpy Recarray via the C-API'], 3, 0], [(19166610, 0), [['I usually use subqueries for this purpose. Here is the SQL I would generate:'], ['An in SQLAlchemy:']], [[" SELECT foo.name, bar.name, (SELECT COUNT('*') FROM baz WHERE baz.foo_id=foo.id AND baz.bar_id=bar.id) FROM foo, bar\n"]], ['Trying to do left outer joins to two related tables'], 3, 0], [(19166610, 2), [['I am no expert concerning the performance of this query versus a query with cleverly combined OUTER JOINs, so I am not sure if this is any slower. I would have otherwise tried something like:'], ["I am not sure this yields what you need and right now I only have sqlite available which doesn't support  RIGHT OUTER JOIN  so I cannot test this. But I  have  verified tha the above query generates the result you want."]], [[' FROM foo LEFT OUTER JOIN baz ON foo.id=baz.foo_id RIGHT OUTER JOIN bar ON bar.id=baz.bar_id\n']], ['Trying to do left outer joins to two related tables'], 3, 0], [(19179245, 0), [['-10000'], ['-10000']], [[" mask = df[['PhaseA','PhaseB','PhaseC']].isin([415,423,427,432]).all(axis=1)\ndf.ix[mask]\n"]], ['Finding index values in a pandas data frame where columns are the same'], 4, 1], [(19179245, 2), [['yields'], ['-10000']], [[' Out[53]: \n                     PhaseA  PhaseB  PhaseC  DataCol\nIndex                                               \n2013-01-07 00:02:00     415     423     415      1.2\n2013-01-07 00:04:00     415     423     423      1.2\n']], ['Finding index values in a pandas data frame where columns are the same'], 4, 0], [(19199869, 1), [['which produces an output looking something like'], ['The basic idea is that you can read a csv file into an object called a  DataFrame :']], [[' 2013-09-16 09:30:00,0.0\n2013-09-16 09:31:00,3.0\n2013-09-16 15:59:00,-5.0\n2013-09-16 16:00:00,-3.0\n2013-09-17 09:30:00,1.0\n2013-09-17 09:31:00,-1.0\n']], ['Most efficient way to loop through multiple csv files and calculate NYSE tick'], 7, 0], [(19199869, 2), [['The basic idea is that you can read a csv file into an object called a  DataFrame :'], ['We can select a column:']], [[' >>> df\n                         open      high     low       close  volume\ntime                                                               \n2013-09-16 09:30:00  461.0100  461.4900  461.00  453.484089  183507\n2013-09-16 09:31:00  460.8200  461.6099  460.39  474.727508  212774\n2013-09-16 15:59:00  449.7200  450.0774  449.59  436.010403  146399\n2013-09-16 16:00:00  450.1200  450.1200  449.65  455.296584  444594\n2013-09-17 09:30:00  448.0000  448.0000  447.50  447.465545  173624\n2013-09-17 09:31:00  449.2628  449.6800  447.50  477.785506  193186\n']], ['Most efficient way to loop through multiple csv files and calculate NYSE tick'], 7, 0], [(19199869, 3), [['We can select a column:'], ["Take the difference, noting that if we're subtracting from the previous value, then the initial value is undefined:"]], [[' >>> df["close"]\ntime\n2013-09-16 09:30:00    453.484089\n2013-09-16 09:31:00    474.727508\n2013-09-16 15:59:00    436.010403\n2013-09-16 16:00:00    455.296584\n2013-09-17 09:30:00    447.465545\n2013-09-17 09:31:00    477.785506\nName: close, dtype: float64\n']], ['Most efficient way to loop through multiple csv files and calculate NYSE tick'], 7, 0], [(19199869, 4), [["Take the difference, noting that if we're subtracting from the previous value, then the initial value is undefined:"], ['Make this either positive or negative, depending on its sign:']], [[' >>> df["close"].diff()\ntime\n2013-09-16 09:30:00          NaN\n2013-09-16 09:31:00    21.243419\n2013-09-16 15:59:00   -38.717105\n2013-09-16 16:00:00    19.286181\n2013-09-17 09:30:00    -7.831039\n2013-09-17 09:31:00    30.319961\nName: close, dtype: float64\n']], ['Most efficient way to loop through multiple csv files and calculate NYSE tick'], 7, 0], [(19199869, 5), [['Make this either positive or negative, depending on its sign:'], ['And fill the  NaN  with a 0.']], [[' >>> df["close"].diff().apply(np.sign)\ntime\n2013-09-16 09:30:00   NaN\n2013-09-16 09:31:00     1\n2013-09-16 15:59:00    -1\n2013-09-16 16:00:00     1\n2013-09-17 09:30:00    -1\n2013-09-17 09:31:00     1\nName: close, dtype: float64\n']], ['Most efficient way to loop through multiple csv files and calculate NYSE tick'], 7, 0], [(19199869, 6), [['And fill the  NaN  with a 0.'], ['This assumes that the recording times match across all stocks: if not, there are powerful resampling tools available to align them.']], [[' >>> df["close"].diff().apply(np.sign).fillna(0)\ntime\n2013-09-16 09:30:00    0\n2013-09-16 09:31:00    1\n2013-09-16 15:59:00   -1\n2013-09-16 16:00:00    1\n2013-09-17 09:30:00   -1\n2013-09-17 09:31:00    1\ndtype: float64\n']], ['Most efficient way to loop through multiple csv files and calculate NYSE tick'], 7, 0], [(19209860, 0), [["The  documentation  gives a similar example at the beginning using  date_range .  If you have a  Series  object, you can make a  DatetimeIndex  starting at the appropriate time (I'm assuming  1013  was a typo for  2013 ), with a frequency of one second, and of the appropriate length:"], ['and then we can make a new series from the original data using this as the new index:']], [[" >>> x = pd.Series(np.random.randint(8,24,23892344)) # make some random data\n>>> when = pd.date_range(start=pd.datetime(2013,1,1),freq='S',periods=len(x))\n>>> when\n<class 'pandas.tseries.index.DatetimeIndex'>\n[2013-01-01 00:00:00, ..., 2013-10-04 12:45:43]\nLength: 23892344, Freq: S, Timezone: None\n"]], ['How to add date and time information to time series data using python numpy or pandas'], 2, 0], [(19209860, 1), [['and then we can make a new series from the original data using this as the new index:'], ['-10000']], [[' >>> x_with_time = pd.Series(x.values, index=when)\n>>> x_with_time\n2013-01-01 00:00:00    13\n2013-01-01 00:00:01    14\n2013-01-01 00:00:02    15\n2013-01-01 00:00:03    22\n2013-01-01 00:00:04    16\n[...]\n2013-10-04 12:45:41    21\n2013-10-04 12:45:42    16\n2013-10-04 12:45:43    15\nFreq: S, Length: 23892344\n']], ['How to add date and time information to time series data using python numpy or pandas'], 2, 0], [(19215100, 1), [['You could also iterate through the tuple:'], ['This is equivalent to:']], [[' for i in solution():\n    print i,\n']], ['More elegant/Pythonic way of printing elements of tuple?'], 3, 1], [(19215100, 2), [['This is equivalent to:'], ['If you ever use Python 3 or the import statement above.']], [[" for i in solution():\n    print(i, end= ' ')\n"]], ['More elegant/Pythonic way of printing elements of tuple?'], 3, 1], [(19221073, 0), [['The arguments of  main()  are the command-line arguments of the program. So if you do for example this in Python:'], ['then the following will hold in  main() :']], [[" subprocess.Popen(['myCppprogram.exe', 'foo', 'bar'], ...)\n"]], ['Call a C++ project main() in Python in Visual Studio?'], 2, 1], [(19221073, 1), [['then the following will hold in  main() :'], ['-10000']], [[' int main(int argc, char** argv)\n{\n  assert(argc == 3);\n  assert(argv[1] == std::string("foo");\n  assert(argv[2] == std::string("bar");\n}\n']], ['Call a C++ project main() in Python in Visual Studio?'], 2, 0], [(19241166, 0), [['Most of the expression API is based on the SQLAlchemy Table object and the columns. The tables are accessible by the  __table__  property on the mapped class, and the columns are available as the properties on the mapped class. So, even though you are at the declarative level, you can still utilize much of what you have available to you there while using the models you mapped using declarative. So, the  example correlated query ...'], ['...can translate to a declarative ORM model by using the  __table__  attribute and declarative columns...']], [[' >>> stmt = select([addresses.c.email_address]).\\\n...             where(addresses.c.user_id == users.c.id).\\\n...             limit(1)\n>>> conn.execute(users.update().values(fullname=stmt)) \n']], ['Sqlalchemy: bulk correlated update to link tables'], 4, 0], [(19241166, 2), [['Here is what I believe your correlated query would look like..'], ['The resulting SQL:']], [[' stmt = select([Location.id]).\\\n    where(and_(Location.x==Stopover.x, Location.y==Stopover.y)).limit(1)\n\nconn.execute(Stopover.__table__.update().values(location_id=stmt)\n']], ['Sqlalchemy: bulk correlated update to link tables'], 4, 1], [(19241166, 3), [['The resulting SQL:'], ['-10000']], [[' UPDATE stopovers SET location_id=(SELECT locations.id \nFROM locations \nWHERE locations.x = stopovers.x AND locations.y = stopovers.y\nLIMIT ? OFFSET ?)\n']], ['Sqlalchemy: bulk correlated update to link tables'], 4, 0], [(19274492, 0), [['Yesterday, I got the global coverage executing something like this:'], ['In  tox.ini  I added the "p" param:']], [[' coverage erase\ntox\ncoverage combine\ncoveralls\n']], ['How calculate the global coverage?'], 2, 0], [(19274492, 1), [['In  tox.ini  I added the "p" param:'], ['I fixed the problem with these commits:']], [[' python {envbindir}/coverage run -p testing/run_tests.py\npython {envbindir}/coverage run -p testing/run_tests.py testing.settings_no_debug\n']], ['How calculate the global coverage?'], 2, 0], [(19288469, 0), [['With  lxml  you can iterate over all elements and check if it has text to  strip() :'], ['It yields:']], [[" from lxml import etree\n\ntree = etree.parse('xmlfile')\nroot = tree.getroot()\n\nfor elem in root.iter('*'):\n    if elem.text is not None:\n        elem.text = elem.text.strip()\n\nprint(etree.tostring(root))\n"]], ['Python how to strip white-spaces from xml text nodes'], 3, 1], [(19288469, 1), [['It yields:'], ['-10000']], [[' <Person><name>My Name</name>\n<Address>My Address</Address>\n</Person>\n']], ['Python how to strip white-spaces from xml text nodes'], 3, 0], [(19297410, 1), [['To install, at the command line I use:'], ['As for testing, after installing,  I type the following at the command line:']], [[' python setup.py install\npython setup.py clean --all\n']], ['packaging with numpy and test suite'], 3, 0], [(19297410, 2), [['As for testing, after installing,  I type the following at the command line:'], ['Try investigating  python setup.py develop  ( Python setup.py develop vs install ) for not having to install the package after every change.']], [[' nosetests package_name -v\n']], ['packaging with numpy and test suite'], 3, 0], [(19303429, 0), [['Just split the string on whitespace, and get the last element of the array. Or use  rsplit()  to start splitting from end:'], ['As specified in comments, you can just pass  None  as 1st argument, in which case the default delimiter which is whitespace will be used:']], [[" >>> st = 'Hello my name is John'\n>>> st.rsplit(' ', 1)\n['Hello my name is', 'John']\n>>> \n>>> st.rsplit(' ', 1)[1]\n'John'\n"]], ['Select last chars of string until whitespace in Python'], 2, 1], [(19317766, 0), [['It might be helpful to flush your input before you put the request. I.e.,'], ['to read out all bytes which are waiting. Then, hoping that no further bytes are being sent, you can send your command:']], [[' ser.read(ser.inWaiting())\n']], ['How to find first byte of a serial stream with python?'], 3, 0], [(19317766, 1), [['to read out all bytes which are waiting. Then, hoping that no further bytes are being sent, you can send your command:'], ['Then read data until you get your 107:']], [[' ser.write(bytes([0x05, 0x69, 0x02, 0x0A, 0x86]))\n']], ['How to find first byte of a serial stream with python?'], 3, 0], [(19317766, 2), [['Then read data until you get your 107:'], ['-10000']], [[" found = False\nbuffer = '' # what is left from the previous run...\nwhile not found:\n    rd = ser.read(50)\n    buffer += rd\n    sp = buffer.split(chr(107), 1)\n    if len(sp) == 2:\n        pkt = chr(107) + sp[1] # candidate for a valid packet\n        if pkt[1] == chr(105): # \n            while len(pkt) < 107: # TODO add a timeout condition here...\n                rd = ser.read(107 - len(pkt))\n                pkt += rd\n            found = True\n        else:\n            buffer = pkt[1:] # process this further...\n    else: # no 107 found; empty the buffer.\n        buffer = ''\n# Now we have a pkt of 107 bytes and can do whatever we want with it.\n"]], ['How to find first byte of a serial stream with python?'], 3, 0], [(19330415, 0), [['For sorting, define the  admin_order_field  property of the method. Although  list_display  and  readonly_fields  do not support the double underscore related field syntax,  admin_order_field  does. So something like this:'], ["Optionally you can set the  short_description  attribute as well, if you don't want the default choic of the method name:"]], [[" class UniversityContact(models.Model):\n    # as above, plus:\n    def abbrev(self):\n        return self.university.abbrev\n    abbrev.admin_order_field = 'university__abbrev'\n"]], ['Python Django: join view on the admin interface'], 3, 1], [(19330415, 1), [["Optionally you can set the  short_description  attribute as well, if you don't want the default choic of the method name:"], ["You didn't ask about this, but it seems worth knowing -  list_filter  also supports the standard related field name syntax:"]], [["     abbrev.short_description = 'abbreviation'\n"]], ['Python Django: join view on the admin interface'], 3, 0], [(19330415, 2), [["You didn't ask about this, but it seems worth knowing -  list_filter  also supports the standard related field name syntax:"], ["Alternatively, there's a code snippet here that claims to address it:\n http://djangosnippets.org/snippets/2887/"]], [["     list_filter = ('university__region',)\n"]], ['Python Django: join view on the admin interface'], 3, 0], [(19368715, 0), [['On the Python side, convert this to JSON first:'], ['Demo:']], [[' import json\n\njson_value = json.dumps(python_object)\n']], ['Convert utf string ftom python to javascript dictionary'], 2, 1], [(19368715, 1), [['Demo:'], ['The latter you can load into JavaScript with  JSON.parse() .']], [[' >>> import json\n>>> python_object = {\'username\': u\'Tester1\', \'age\': 0L}\n>>> print json.dumps(python_object)\n{"username": "Tester1", "age": 0}\n']], ['Convert utf string ftom python to javascript dictionary'], 2, 1], [(19369025, 0), [['main.py:'], ['hueLayout.kv:']], [[" from kivy.config import Config\nConfig.set('graphics', 'width', '1000')\nConfig.set('graphics', 'height', '500')\nConfig.set('graphics', 'resizable', 0)\nfrom kivy.app import App\nfrom kivy.uix.widget import Widget\nfrom kivy.uix.boxlayout import BoxLayout\nfrom kivy.lang import Builder\nfrom kivy.properties import ObjectProperty\nfrom kivy.graphics import Color, Ellipse, Line\n\nBuilder.load_file('hueLayout.kv')\n\nclass ColorLoopWidget(Widget):\n    xlabel = ObjectProperty()\n    ylabel = ObjectProperty()\n    def on_touch_down(self, touch):\n        with self.canvas:\n            self.canvas.clear()\n            d = 10\n            Ellipse(pos=(touch.x - d/2, touch.y - d/2), size=(d,d))\n            touch.ud['line'] = Line(points=(touch.x, touch.y))\n            self.xlabel.text = 'x: '+str(touch.x)\n            self.ylabel.text = 'y: '+str(touch.y)\n\n##    def on_touch_move(self, touch):\n##        touch.ud['line'].points += [touch.x, touch.y]\n\n\n\nclass HueLayout(Widget):\n    colorloopwidget = ObjectProperty()\n    xlabel = ObjectProperty()\n    ylabel = ObjectProperty()\n\n##    def on_touch_down():\n##        ColorLoopWidget.on_touch_down()\n##\n##    def on_touch_move():\n##        ColorLoopWidget.on_touch_move()\n\n    def clear_canvas(self):\n        self.colorloopwidget.canvas.clear()\n\n\nclass HueApp(App):\n    def build(self):\n        return HueLayout()\n\nif __name__ == '__main__':\n    HueApp().run()\n"]], ['Output touch position from custom kivy widget to labels'], 2, 0], [(19369025, 1), [['hueLayout.kv:'], ['-10000']], [[" <HueLayout>:\n    colorloopwidget: colorloopwidget\n    xlabel: xlabel\n    ylabel: ylabel\n\n    BoxLayout:\n        size: 1000, 500\n        orientation: 'horizontal'\n\n        ColorLoopWidget:\n            xlabel: xlabel\n            ylabel: ylabel\n            id: colorloopwidget\n            size: 500, 500\n\n        BoxLayout:\n            orientation: 'vertical'\n            Button:\n                text: 'Clear'\n                on_release: root.clear_canvas()\n            Label:\n                id: xlabel\n                text: 'x: '\n                size_hint_y: 0.2\n            Label:\n                id: ylabel\n                text: 'y: '\n                size_hint_y: 0.2\n"]], ['Output touch position from custom kivy widget to labels'], 2, 0], [(19382088, 0), [['If I understand your situation correctly, you can just  reshape  it.'], ["It appears to me that your array is ordered in what numpy calls  'F'  ordering:"]], [[' In [132]: p = np.array("p_x1y1z1 p_x2y1z1 p_x3y1z1 p_x4y1z1 p_x1y2z1 p_x2y2z1 p_x3y2z1 p_x4y2z1".split())\n\nIn [133]: p\nOut[133]: \narray([\'p_x1y1z1\', \'p_x2y1z1\', \'p_x3y1z1\', \'p_x4y1z1\', \'p_x1y2z1\', \'p_x2y2z1\', \'p_x3y2z1\', \'p_x4y2z1\'], \n      dtype=\'|S8\')\n']], ['numpy create 3D array from indexed list'], 4, 0], [(19382088, 1), [["It appears to me that your array is ordered in what numpy calls  'F'  ordering:"], ['If you have  z  variance, too, simply reshape to three dimensions:']], [[" In [168]: p.reshape(4, 2, order='F')\nOut[168]: \narray([['p_x1y1z1', 'p_x1y2z1'],\n       ['p_x2y1z1', 'p_x2y2z1'],\n       ['p_x3y1z1', 'p_x3y2z1'],\n       ['p_x4y1z1', 'p_x4y2z1']], \n      dtype='|S8')\n"]], ['numpy create 3D array from indexed list'], 4, 0], [(19382088, 3), [['This assumes  x,y,z  should map to  i+1,j+1,k+1 , as seen here:'], ['-10000']], [[" In [175]: r = q.reshape(4,2,3,order='F')\n\nIn [176]: r[0]   #all x==1\nOut[176]: \narray([['p_x1y1z1', 'p_x1y1z2', 'p_x1y1z3'],\n       ['p_x1y2z1', 'p_x1y2z2', 'p_x1y2z3']], \n      dtype='|S8')\n\nIn [177]: r[:,0]  # all y==1\nOut[177]: \narray([['p_x1y1z1', 'p_x1y1z2', 'p_x1y1z3'],\n       ['p_x2y1z1', 'p_x2y1z2', 'p_x2y1z3'],\n       ['p_x3y1z1', 'p_x3y1z2', 'p_x3y1z3'],\n       ['p_x4y1z1', 'p_x4y1z2', 'p_x4y1z3']], \n      dtype='|S8')\n\nIn [178]: r[:,:,0]  #all z==1\nOut[178]: \narray([['p_x1y1z1', 'p_x1y2z1'],\n       ['p_x2y1z1', 'p_x2y2z1'],\n       ['p_x3y1z1', 'p_x3y2z1'],\n       ['p_x4y1z1', 'p_x4y2z1']], \n      dtype='|S8')\n"]], ['numpy create 3D array from indexed list'], 4, 0], [(19391149, 0), [["You can't pass a known mean to  np.std  or  np.var , you'll have to wait for the  new standard library  statistics  module , but in the meantime you can save a little time by using the formula:"], ["If you really are trying to speed things up, try  np.dot  to do the squaring and summing (since that's what a dot-product is):"]], [[' In [329]: a = np.random.rand(1000)\n\nIn [330]: %%timeit\n   .....: a.mean()\n   .....: a.var()\n   .....: \n10000 loops, best of 3: 80.6 µs per loop\n\nIn [331]: %%timeit\n   .....: m = a.mean()\n   .....: np.mean((a-m)**2)\n   .....: \n10000 loops, best of 3: 60.9 µs per loop\n\nIn [332]: m = a.mean()\n\nIn [333]: a.var()\nOut[333]: 0.078365856465916137\n\nIn [334]: np.mean((a-m)**2)\nOut[334]: 0.078365856465916137\n']], ['Numpy mean AND variance from single function?'], 2, 1], [(19395350, 0), [['-10000'], ['Output with your text file:']], [[' with open(infilepath) as infile:\n  answer = {}\n  name = None\n  for line in infile:\n    line = line.strip()\n    if line.startswith("NGC"):\n      name = line\n      answer[name] = {}\n    else:\n      var, val = line.split(\':\', 1)\n      answer[name][var.strip()] = val.strip()\n']], ['Opening a text file and then storing the contents into a nested dictionary in python 2.7'], 2, 1], [(19395350, 1), [['Output with your text file:'], ['-10000']], [[' >>> with open(infilepath) as infile:\n...   answer = {}\n...   name = None\n...   for line in infile:\n...     line = line.strip()\n...     if line.startswith("NGC"):\n...       name = line\n...       answer[name] = {}\n...     else:\n...       var, val = line.split(\':\', 1)\n...       answer[name][var.strip()] = val.strip()\n... \n>>> answer\n{\'NGC6853\': {\'Messier\': \'M27\', \'Magnitude\': \'7.4\', \'Distance\': \'1.25\', \'Name\': \'Dumbbell Nebula\'}, \'NGC4254\': {\'Brightness\': \'9.9 mag\', \'Messier\': \'M99\', \'Distance\': \'60000\', \'Name\': \'Coma Pinwheel Galaxy\'}, \'NGC4594\': {\'Messier\': \'M104\', \'Distance\': \'50000\', \'Name\': \'Sombrero Galaxy\'}, \'NGC0224\': {\'Messier\': \'M31\', \'Magnitude\': \'3.4\', \'Distance\': \'2900\', \'Name\': \'Andromeda Galaxy\'}, \'NGC4826\': {\'Messier\': \'M64\', \'Magnitude\': \'8.5\', \'Distance\': \'19000\', \'Name\': \'Black Eye Galaxy\'}, \'NGC5457\': {\'Messier\': \'M101\', \'Magnitude\': \'7.9\', \'Distance\': \'27000\', \'Name\': \'Pinwheel Galaxy\'}}\n']], ['Opening a text file and then storing the contents into a nested dictionary in python 2.7'], 2, 0], [(19431099, 0), [['As far as I am aware, there is no documentation for doing this, but I have found a way to do it with only a minimum amount of hacking around.  Here is a minimal example, which might require a little tinkering for different kinds of sources:'], ['It also looks like sometimes you have to ensure that the mapper points to the right thing.  This is not necessary for the above example, but it may be for other sources']], [[' from tvtk.api import tvtk; from mayavi import mlab; import numpy as np\n\nx,y,z=np.random.random((3,nr_points)) #some data\ncolors=np.random.randint(256,size=(100,3)) #some RGB or RGBA colors\n\npts=mlab.points3d(x,y,z)\nsc=tvtk.UnsignedCharArray()\nsc.from_array(colors)\n\npts.mlab_source.dataset.point_data.scalars=sc\npts.mlab_source.dataset.modified()\n']], ['How to directly set RGB/RGBA colors in mayavi'], 3, 1], [(19431099, 1), [['It also looks like sometimes you have to ensure that the mapper points to the right thing.  This is not necessary for the above example, but it may be for other sources'], ['His idea is to create a LUT spanning the entire range of 256x256x256 RGB values. Note that this LUT therefore has 16,777,216 entries. Which, if you wanted to use it in many vtk objects, may waste quite a lot of memory if you are not careful.']], [[' pts.actor.mapper.input=pts.mlab_source.dataset\n']], ['How to directly set RGB/RGBA colors in mayavi'], 3, 0], [(19461747, 1), [['Then:'], ['Or you can change it back to a dict:']], [[" >>> print c\nCounter({'d': 20, 'c': 13, 'b': 8, 'a': 3})\n"]], ['Sum corresponding elements of multiple python dictionaries'], 5, 0], [(19461747, 2), [['Or you can change it back to a dict:'], ["It doesn't matter to  Counter()  whether all the input dicts have same keys.  If you know for sure that they do, you could try ridiculous ;-) one-liners like this:"]], [[" >>> print dict(c)\n{'a': 3, 'c': 13, 'b': 8, 'd': 20}\n"]], ['Sum corresponding elements of multiple python dictionaries'], 5, 0], [(19522263, 0), [['Use  BeautifulSoup4  to get all the  <img> ,  <link> , and  <script>  tags then pull the corresponding attributes.'], ['Example output:']], [[' from bs4 import BeautifulSoup\nimport requests\n\nresp = requests.get("http://www.yahoo.com")\n\nsoup = BeautifulSoup(resp.text)\n\n# Pull the linked images (note: will grab base64 encoded images) \nimages = [img[\'src\'] for img in soup.findAll(\'img\') if img.has_key(\'src\')]\n\n# Checking for src ensures that we don\'t grab the embedded scripts\nscripts = [script[\'src\'] for script in soup.findAll(\'script\') if script.has_key(\'src\')]\n\n# favicon.ico and css\nlinks = [link[\'href\'] for link in soup.findAll(\'link\') if link.has_key(\'href\')]\n']], ['Load all third party scripts using requests or mechanize in Python'], 2, 1], [(19522263, 1), [['Example output:'], ['-10000']], [[" In [30]: images = [img['src'] for img in soup.findAll('img') if img.has_key('src')]\n\nIn [31]: images[:5]\nOut[31]:\n['http://l.yimg.com/dh/ap/default/130925/My_Yahoo_Defatul_HP_ad_300x250.jpeg',\n 'http://l.yimg.com/os/mit/media/m/base/images/transparent-95031.png',\n 'http://l.yimg.com/os/mit/media/m/base/images/transparent-95031.png',\n 'http://l.yimg.com/os/mit/media/m/base/images/transparent-95031.png',\n 'http://l.yimg.com/os/mit/media/m/base/images/transparent-95031.png']\n"]], ['Load all third party scripts using requests or mechanize in Python'], 2, 0], [(19529825, 0), [['You can use  .shift()  to shift a column, and use  any  to check for differences.  For example, given a frame like'], ['-10000']], [[' >>> df\n   Bid  Ask\n1  1.0  1.5\n2  1.0  1.5\n3  1.0  1.5\n4  1.5  2.0\n5  1.5  2.0\n6  2.0  2.5\n7  2.0  2.5\n8  2.0  3.0\n>>> df[(df != df.shift()).any(axis=1)]\n   Bid  Ask\n1  1.0  1.5\n4  1.5  2.0\n6  2.0  2.5\n8  2.0  3.0\n']], ['Drop Duplicate in market data'], 4, 1], [(19529825, 1), [['-10000'], ['We compare the dataframe with its shifted version:']], [[' >>> df.shift()\n   Bid  Ask\n1  NaN  NaN\n2  1.0  1.5\n3  1.0  1.5\n4  1.0  1.5\n5  1.5  2.0\n6  1.5  2.0\n7  2.0  2.5\n8  2.0  2.5\n']], ['Drop Duplicate in market data'], 4, 0], [(19529825, 2), [['We compare the dataframe with its shifted version:'], ['And then we make a series which is True only if either of these are true and a row differs from the next row:']], [[' >>> df != df.shift()\n     Bid    Ask\n1   True   True\n2  False  False\n3  False  False\n4   True   True\n5  False  False\n6   True   True\n7  False  False\n8  False   True\n']], ['Drop Duplicate in market data'], 4, 0], [(19529825, 3), [['And then we make a series which is True only if either of these are true and a row differs from the next row:'], ['-10000']], [[' >>> (df != df.shift()).any(axis=1)\n1     True\n2    False\n3    False\n4     True\n5    False\n6     True\n7    False\n8     True\ndtype: bool\n']], ['Drop Duplicate in market data'], 4, 0], [(19534230, 1), [['Or you could have a simple bash file that contains the environment and the python command you wish to run.'], ['Then:']], [[' #!/bin/sh\n# filename: workon.sh\nexport PYTHONSTARTUP=$HOME/myproject/.pystartup\npython ~/myproject/start.py\n']], ['A PYTHONSTARTUP file for a specific directory'], 3, 0], [(19534230, 2), [['Then:'], ['-10000']], [[' ./workon.sh\n']], ['A PYTHONSTARTUP file for a specific directory'], 3, 0], [(19543636, 0), [['-10000'], ['Then, just filter your input list (named  l  here):']], [[" def is_subtuple(tup1, tup2):\n    '''Return True if all the elements of tup1 are consecutively in tup2.'''\n    if len(tup2) < len(tup1): return False\n    try:\n        offset = tup2.index(tup1[0])\n    except ValueError:\n        return False\n    # This could be wrong if tup1[0] is in tup2, but doesn't start the subtuple.\n    # You could solve this by recurring on the rest of tup2 if this is false, but\n    # it doesn't apply to your input data.\n    return tup1 == tup2[offset:offset+len(tup1)] \n"]], ['Recursively reduce list of tuples'], 2, 0], [(19543636, 1), [['Then, just filter your input list (named  l  here):'], ["Now, this list comprehension assumes that the input list is ordered consistently the way you show it, with the subtuples being earlier than the tuples they're in. It's also a bit expensive ( O(n**2) , I think), but it'll get the job done."]], [[' [t for i, t in enumerate(l) if not any(is_subtuple(t, t2) for t2 in l[i+1:])]\n']], ['Recursively reduce list of tuples'], 2, 0], [(19552183, 0), [['The general way to find out the primary key columns of a table, which should work in any SQL database, is something like:'], ['which returns something like']], [[" SELECT column_name\nFROM information_schema.table_constraints\n     JOIN information_schema.key_column_usage\n         USING (constraint_catalog, constraint_schema, constraint_name,\n                table_catalog, table_schema, table_name)\nWHERE constraint_type = 'PRIMARY KEY'\n  AND (table_schema, table_name) = ('yourschema', 'yourtable')\nORDER BY ordinal_position;\n"]], ['How to check if key is primary psycopg2'], 2, 1], [(19552183, 1), [['which returns something like'], ['-10000']], [[' ┌─────────────┐\n│ column_name │\n├─────────────┤\n│ a           │\n│ b           │\n└─────────────┘\n']], ['How to check if key is primary psycopg2'], 2, 0], [(19562863, 0), [['Wrap your initial node in list or tuple:'], ['Demo:']], [[' exl_set = set([a.node])\n']], ['What is the best practice to add tuples to a set?'], 3, 1], [(19562863, 2), [['Alternatively, create an empty set and use  set.add()  exclusively:'], ['-10000']], [[' exl_set = set()\nexl_set.add(a.node)\nexl_set.add(b.node)\n']], ['What is the best practice to add tuples to a set?'], 3, 1], [(19596424, 0), [['I figured it out by doing this server side:'], ['client side using jquery']], [[' import urlib.parse, json\ncookie_data = urllib.parse.quote(json.dumps(mydict))\n']], ['How to encode a python dictionary and decode in jquery? (via a cookie)'], 2, 0], [(19596424, 1), [['client side using jquery'], ['-10000']], [[" var dict = $.parseJSON($.cookie('MyCookie'));\n"]], ['How to encode a python dictionary and decode in jquery? (via a cookie)'], 2, 0], [(19618514, 0), [['-10000'], ['Splitting based on comma']], [[' s=\'1.25,3.455,3.7\'\nprint sum(float(num) for num in s.split(","))\n']], ['Sum of all numbers inside a string'], 5, 1], [(19618514, 1), [['Splitting based on comma'], ['Output']], [[' print s.split(",")\n']], ['Sum of all numbers inside a string'], 5, 0], [(19618514, 2), [['Output'], ['Looping the values to convert to floats']], [[" ['1.25', '3.455', '3.7']\n"]], ['Sum of all numbers inside a string'], 5, 0], [(19618514, 3), [['Looping the values to convert to floats'], ['Output']], [[' for num in s.split(","):\n    print float(num)\n']], ['Sum of all numbers inside a string'], 5, 0], [(19618514, 4), [['Output'], ['sum  will add all the numbers given to that. So, we just feed all the converted numbers to it, like this  sum(float(num) for num in s.split(","))']], [[' 1.25\n3.455\n3.7\n']], ['Sum of all numbers inside a string'], 5, 0], [(19641162, 0), [['Something like this:'], ['-10000']], [[" def tree(head, stem):\n    #for head\n    for i in xrange(1, head+1, 2):\n        print '{:^{}}'.format('*'*i, head)\n    #for trunk\n    for _ in xrange(3):\n        print '{:^{}}'.format('*'*stem, head)\n...         \n>>> tree(10, 3)\n    *     \n   ***    \n  *****   \n *******  \n********* \n   ***    \n   ***    \n   ***    \n>>> tree(5, 1)\n  *  \n *** \n*****\n  *  \n  *  \n  *  \n"]], ['Making a tree shape.'], 2, 1], [(19641162, 1), [['-10000'], ['-10000']], [[" def tree(head, stem):\n    for i in xrange(1, head+1, 2):\n        print ('*'*i).center(head)\n    x = (head/2) if (head/2)%2 else (head/2)-1\n    for _ in xrange(stem):\n        print ('*'*x).center(head)\n\n>>> tree(12, 2)\n     *      \n    ***     \n   *****    \n  *******   \n *********  \n*********** \n   *****    \n   *****    \n>>> tree(14, 4)\n      *       \n     ***      \n    *****     \n   *******    \n  *********   \n ***********  \n************* \n   *******    \n   *******    \n   *******    \n   *******    \n"]], ['Making a tree shape.'], 2, 1], [(19649791, 1), [['An edit based on your comment that should help. '], ['Things to note:']], [[' from bs4 import BeautifulSoup, CData\nimport urllib\n\nsource_txt = urllib.urlopen("http://voanews.com/api/epiqq")\nsoup = BeautifulSoup.BeautifulSoup(source_txt.read())\nfor cd in soup.findAll(text=True):\n    if isinstance(cd, CData):\n        print \'CData value: %r\' % cd        \n']], ['how to get content inside CDATA of XML tag django'], 2, 0], [(19665491, 1), [['Sample output for the initial data in the question:'], ['-10000']], [[' Q: 0283437893b491218348bf5ff149325e47eb628ce36f73a1a927ae6cb6021c7ac4\nRIPEMD-160(SHA-256(Q)): cbe57ebe20ad59518d14926f8ab47fecc984af49\nSignature verified correctly: True\n']], ['How do I get an ECDSA public key from just a Bitcoin signature? ... SEC1 4.1.6 key recovery for curves over (mod p)-fields'], 3, 0], [(19665491, 2), [['-10000'], ['-10000']], [[' 1Kb76YK9a4mhrif766m321AMocNvzeQxqV\n']], ['How do I get an ECDSA public key from just a Bitcoin signature? ... SEC1 4.1.6 key recovery for curves over (mod p)-fields'], 3, 0], [(19666356, 0), [['If your file contains the fully-qualified names of the files. You can do the following'], ['If your file contains the relative path from the current working directory then:']], [[" import cv\nwith open('textFileOfImages.txt','rb') as f:\n    img = [line.strip() for line in f]\n\n#load the images at you leisure\nfor image in img:\n    loadedImage = cv.LoadImage(image)\n    #manipulate image\n"]], ['Loading multiple images from a text file'], 4, 1], [(19666356, 1), [['If your file contains the relative path from the current working directory then:'], ['Or if your file contains the relative path from directory the current script is running']], [[" import os\nimport cv\nwith open('textFileOfImages.txt','rb') as f:\n    img = ['%s/%s'%(os.getcwd(),line.strip()) for line in f]\n"]], ['Loading multiple images from a text file'], 4, 1], [(19666356, 2), [['Or if your file contains the relative path from directory the current script is running'], ['-10000']], [[" import os\nimport cv\nwith open('textFileOfImages.txt','rb') as f:\n     img = ['%s/%s'%(os.path.dirname(os.path.abspath(__file__)),line.strip()) for line in f]\n"]], ['Loading multiple images from a text file'], 4, 1], [(19666356, 3), [['-10000'], ['-10000']], [[" listOfFilenames = ['filename1.txt','filename2.txt','filename3.txt']\nfor filename in listOfFilenames: \n    with open(filename,'rb') as f:\n    ...\n"]], ['Loading multiple images from a text file'], 4, 1], [(19716770, 0), [['I would get your data into a lookup table like this:'], ['Then just loop over your query in reverse order, stripping off one directory at a time until you get a match:']], [[" lookup = {'/folder1/folder2/folder3/folder4':'include','/folder1/folder2':'exclude','/folder1':'include'}\n"]], ['Best way to work out if a path is in an include or exclude list in python'], 2, 0], [(19716770, 1), [['Then just loop over your query in reverse order, stripping off one directory at a time until you get a match:'], ['-10000']], [[" folder = '/folder1/folder2/folder3/folder4/folder5'.split('/')\nfor i in reversed(range(len(folder) + 1)):\n    check = '/'.join(folder[:i])\n    if lookup.get(check):\n        print('{}: {}'.format(check,lookup.get(check)))\n        break\n\n#/folder1/folder2/folder3/folder4: include\n"]], ['Best way to work out if a path is in an include or exclude list in python'], 2, 0], [(19728214, 0), [['You can use the ordinary  csv.writer :'], ['That will write the columns in arbitrary order, which order may change from run to run. One way to make the order to be consistent is to replace the last two lines with:']], [[" my_data = {'time, s': [0,1,2,3], 'x temp, C':[0,10,20,30],\n 'x pressure, kPa': [0,100,200,300]}\nimport csv\nwith open('outfile.csv', 'w') as outfile:\n   writer = csv.writer(outfile)\n   writer.writerow(my_data.keys())\n   writer.writerows(zip(*my_data.values()))\n"]], ['Syntax - saving a dictionary as a csv file'], 2, 1], [(19728214, 1), [['That will write the columns in arbitrary order, which order may change from run to run. One way to make the order to be consistent is to replace the last two lines with:'], ['-10000']], [['    writer.writerow(sorted(my_data.keys()))\n   writer.writerows(zip(*(my_data[k] for k in sorted(my_data.keys()))))\n']], ['Syntax - saving a dictionary as a csv file'], 2, 0], [(19784235, 0), [["You can use the  subprocess  module's piping features to write the data to the other program."], ['will output (or rather,  tac  will)']], [[' import subprocess\nproc = subprocess.Popen("/usr/bin/tac", stdin=subprocess.PIPE)  # Output will go to stdout\nproc.communicate("hello\\nworld\\n")  # This data goes to the subprocess.\n']], ['Reading netCDF and creating "virtual / pseudo" csv files'], 2, 1], [(19784235, 1), [['will output (or rather,  tac  will)'], ["EDIT:  This is assuming the other program supports reading from standard input. If it doesn't, you could probably simulate this with fifos on UNIX-like systems..."]], [[' world\nhello\n']], ['Reading netCDF and creating "virtual / pseudo" csv files'], 2, 0], [(19793156, 1), [['Suppose that the one  x=31  was actually 20:'], ["Then we'd expect x to use B and y to still use A.  We can amend the last step a bit:"]], [[' In [33]: df.val.iloc[1] = 20\n\nIn [34]: df\nOut[34]: \n   category  val sensitivity_level\n0         x   20                 A\n1         x   20                 B\n2         x   60                 C\n3         x   20                 A\n4         x   25                 B\n5         x   60                 C\n6         y   20                 A\n7         y   40                 B\n8         y   60                 C\n9         y   20                 A\n10        y   24                 B\n11        y   30                 C\n']], ['Assign values to the groups of a groupby in pandas'], 3, 0], [(19793156, 2), [["Then we'd expect x to use B and y to still use A.  We can amend the last step a bit:"], ["There's probably a better way to do the last step."]], [[" In [51]: res = df.groupby(['category', 'sensitivity_level']).max()\nIn [48]: x = res[res.val <= 30]\n\nIn [49]: \n\nIn [49]: x\nOut[49]: \n                            val\ncategory sensitivity_level     \nx        A                   20\n         B                   25\ny        A                   20\n\nIn [71]: x.reset_index('category').sort_index(ascending=False).groupby(level='sensitivity_level').first()\nOut[71]: \n                  category  val\nsensitivity_level              \nA                        y   20\nB                        x   25\n"]], ['Assign values to the groups of a groupby in pandas'], 3, 0], [(19799490, 0), [['First, join each element of  List1  to form a single, space-separated string. Then split that and convert each element of the resulting list to an integer.'], ['You can also use a nested  for  with the list comprehension:']], [[" >>> List1 = ['1 2 3 4 5', '6 7 8 9 10', '11 12 13 14 15']\n>>> [ int(x) for x in ' '.join(List1).split()]\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"]], ['Turn a List of Str into a List of Int (Python)'], 2, 1], [(19799490, 1), [['You can also use a nested  for  with the list comprehension:'], ['You parse each  for  expression in the same order as a regular nested  for  loop.']], [[' >>> [ int(x) for y in List1 for x in y.split() ]\n']], ['Turn a List of Str into a List of Int (Python)'], 2, 1], [(19830594, 0), [['You can considerably improve your code speed creating an 2-D array with ones along the diagonal and then extract the right rows based on the input array:'], ['An even faster solution would be to create the output array with zeros and then populate it according to the indices from  a :']], [[' a = array([[5],\n           [0],\n           [4],\n           ..., \n           [5],\n           [6],\n           [8]], dtype=int8)\n\nnew_y = np.eye(a.max()+1)[a.ravel()]\n']], ['Vectorize this function in Numpy Python'], 2, 1], [(19830594, 1), [['An even faster solution would be to create the output array with zeros and then populate it according to the indices from  a :'], ['-10000']], [[' new_y = np.zeros((a.shape[0], a.max()+1))\nnew_y[np.indices(a.ravel().shape)[0], a.ravel()] = 1.\n']], ['Vectorize this function in Numpy Python'], 2, 1], [(19835824, 0), [['Use  ast.literal_eval()  to interpret strings containing Python literals:'], ['This is safer that using  eval()  as it will refuse to interpret anything that is  not  a literal value:']], [[' >>> import ast\n>>> ast.literal_eval("[\'11\', \'20\', \'0\']")\n[\'11\', \'20\', \'0\']\n']], ['How to convert a string that already looks like a list into a list?'], 2, 1], [(19835824, 1), [['This is safer that using  eval()  as it will refuse to interpret anything that is  not  a literal value:'], ['-10000']], [[' >>> eval("__import__(\'sys\').version")\n\'2.7.5 (default, Oct 28 2013, 20:45:48) \\n[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]\'\n>>> ast.literal_eval("__import__(\'sys\').version")\nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\n  File "/Users/mj/Development/Library/buildout.python/parts/opt/lib/python2.7/ast.py", line 80, in literal_eval\n    return _convert(node_or_string)\n  File "/Users/mj/Development/Library/buildout.python/parts/opt/lib/python2.7/ast.py", line 79, in _convert\n    raise ValueError(\'malformed string\')\nValueError: malformed string\n']], ['How to convert a string that already looks like a list into a list?'], 2, 0], [(19844558, 0), [['Use  enumerate  and a  list comprehension :'], ["Or if string contains just two  '#'  then use  str.rfind :"]], [[' >>> s = "asd#1-2#qwe"\n>>> [i for i, c in enumerate(s) if c==\'#\']\n[3, 7]\n']], ['How to find a index of an item in a string?'], 3, 1], [(19844558, 1), [["Or if string contains just two  '#'  then use  str.rfind :"], ['-10000']], [[" >>> s.rfind('#')\n7\n"]], ['How to find a index of an item in a string?'], 3, 1], [(19844558, 2), [['-10000'], ['-10000']], [[' >>> s = "asd##1-2####qwe"\n>>> import re\n#Find index of all \'##\' in s\n>>> [m.start() for m in re.finditer(r\'(?=##)\', s)]\n[3, 8, 9, 10]\n']], ['How to find a index of an item in a string?'], 3, 1], [(19882621, 0), [['I like to use the standard library where possible to avoid rolling my own code and inadvertently leaving things out (like accidentally misplacing or forgetting a letter.)'], ['and ']], [[" import string\nimport collections\n\ndef vigsquare(printable=False):\n    '''\n    Returns a string like a vigenere square,\n    printable joins each row with a newline so it's literally square\n    printable=False (defaul) joins without newlines for easier \n    searching by row and column index\n    '''\n    alpha = string.ascii_uppercase\n    rotater = collections.deque(alpha)\n    vigsquare_list = []\n    for i in xrange(26):\n        vigsquare_list.append(''.join(rotater))\n        rotater.rotate(-1)\n    if printable:\n        return '\\n'.join(vigsquare_list) \n    else:\n        return ''.join(vigsquare_list)\n"]], ['For Kasiski Test,How to implement 26x26 table in Python'], 6, 0], [(19882621, 1), [['and '], ['gives you:']], [[" def vigenere(row, column):\n    ''' \n    Return a character from a vigenere square by \n    row and column letter.\n    vigenere('L', 'G') returns 'R'\n    '''\n    alpha = string.ascii_uppercase\n    rowindex = alpha.find(row)\n    columnindex = alpha.find(column)\n    return vigsquare()[rowindex*26 + columnindex]\n\nprint vigsquare(printable=True)\nvigenere('L', 'G')\n"]], ['For Kasiski Test,How to implement 26x26 table in Python'], 6, 0], [(19882621, 2), [['gives you:'], ['and ']], [[' ABCDEFGHIJKLMNOPQRSTUVWXYZ\nBCDEFGHIJKLMNOPQRSTUVWXYZA\nCDEFGHIJKLMNOPQRSTUVWXYZAB\nDEFGHIJKLMNOPQRSTUVWXYZABC\nEFGHIJKLMNOPQRSTUVWXYZABCD\nFGHIJKLMNOPQRSTUVWXYZABCDE\nGHIJKLMNOPQRSTUVWXYZABCDEF\nHIJKLMNOPQRSTUVWXYZABCDEFG\nIJKLMNOPQRSTUVWXYZABCDEFGH\nJKLMNOPQRSTUVWXYZABCDEFGHI\nKLMNOPQRSTUVWXYZABCDEFGHIJ\nLMNOPQRSTUVWXYZABCDEFGHIJK\nMNOPQRSTUVWXYZABCDEFGHIJKL\nNOPQRSTUVWXYZABCDEFGHIJKLM\nOPQRSTUVWXYZABCDEFGHIJKLMN\nPQRSTUVWXYZABCDEFGHIJKLMNO\nQRSTUVWXYZABCDEFGHIJKLMNOP\nRSTUVWXYZABCDEFGHIJKLMNOPQ\nSTUVWXYZABCDEFGHIJKLMNOPQR\nTUVWXYZABCDEFGHIJKLMNOPQRS\nUVWXYZABCDEFGHIJKLMNOPQRST\nVWXYZABCDEFGHIJKLMNOPQRSTU\nWXYZABCDEFGHIJKLMNOPQRSTUV\nXYZABCDEFGHIJKLMNOPQRSTUVW\nYZABCDEFGHIJKLMNOPQRSTUVWX\nZABCDEFGHIJKLMNOPQRSTUVWXY\n']], ['For Kasiski Test,How to implement 26x26 table in Python'], 6, 0], [(19882621, 3), [['and '], ["There was another solution that looked interesting here, but I didn't trust it because I didn't understand it, so I'll unittest my code and the other code to see if it's reliable."]], [[" 'R'\n"]], ['For Kasiski Test,How to implement 26x26 table in Python'], 6, 0], [(19882621, 4), [["There was another solution that looked interesting here, but I didn't trust it because I didn't understand it, so I'll unittest my code and the other code to see if it's reliable."], ['And unittested comparing both approaches. The second one (borrowed from NPE, to whom I now owe an upvote) is likely to be more performant if it is correct.:']], [[' def vig_2(row, col):\n    return string.ascii_uppercase[(ord(row) + ord(col)) % 26]\n']], ['For Kasiski Test,How to implement 26x26 table in Python'], 6, 0], [(19882621, 5), [['And unittested comparing both approaches. The second one (borrowed from NPE, to whom I now owe an upvote) is likely to be more performant if it is correct.:'], ['So it looks like NPE had a very good solution!']], [[" import unittest\nclass VigTestCase(unittest.TestCase):\n    def test_vigenere(self):\n        self.assertEqual(vigenere('L', 'G'), 'R')\n    def test_vigsquare(self):\n        self.assertEqual(vigsquare(printable=False), 'ABCDEFGHIJKLMNOPQRSTUVWXYZBCDEFGHIJKLMNOPQRSTUVWXYZACDEFGHIJKLMNOPQRSTUVWXYZABDEFGHIJKLMNOPQRSTUVWXYZABCEFGHIJKLMNOPQRSTUVWXYZABCDFGHIJKLMNOPQRSTUVWXYZABCDEGHIJKLMNOPQRSTUVWXYZABCDEFHIJKLMNOPQRSTUVWXYZABCDEFGIJKLMNOPQRSTUVWXYZABCDEFGHJKLMNOPQRSTUVWXYZABCDEFGHIKLMNOPQRSTUVWXYZABCDEFGHIJLMNOPQRSTUVWXYZABCDEFGHIJKMNOPQRSTUVWXYZABCDEFGHIJKLNOPQRSTUVWXYZABCDEFGHIJKLMOPQRSTUVWXYZABCDEFGHIJKLMNPQRSTUVWXYZABCDEFGHIJKLMNOQRSTUVWXYZABCDEFGHIJKLMNOPRSTUVWXYZABCDEFGHIJKLMNOPQSTUVWXYZABCDEFGHIJKLMNOPQRTUVWXYZABCDEFGHIJKLMNOPQRSUVWXYZABCDEFGHIJKLMNOPQRSTVWXYZABCDEFGHIJKLMNOPQRSTUWXYZABCDEFGHIJKLMNOPQRSTUVXYZABCDEFGHIJKLMNOPQRSTUVWYZABCDEFGHIJKLMNOPQRSTUVWXZABCDEFGHIJKLMNOPQRSTUVWXY')\n    def test_vig2(self):\n        for i in string.ascii_uppercase:\n            for j in string.ascii_uppercase:\n                self.assertEqual(vig_2(i, j), vigenere(i, j))\n\nunittest.main()\n...\n----------------------------------------------------------------------\nRan 3 tests in 0.038s\n\nOK\n"]], ['For Kasiski Test,How to implement 26x26 table in Python'], 6, 0], [(19888255, 0), [['Since you are dealing with CSV data, you can use the CSV module along with dictionaries:'], ['This outputs:']], [[" import csv\n\nuniq = {} #Create an empty dictionary, which we will use as a hashmap as Python dictionaries support key-value pairs.\n\nifile = open('data.csv', 'r') #whatever your CSV file is named.\nreader = csv.reader(ifile)\n\nfor row in reader:\n    joined = row[0] + row[1] #The joined string is simply the first and second columns in each row.\n    #Check to see that the key exists, if it does increment the occurrence by 1\n    if joined in uniq.keys():\n        uniq[joined] += 1\n    else:\n        uniq[joined] = 1 #This means the key doesn't exist, so add the key to the dictionary with an occurrence of 1\n\nprint uniq #Now output the results\n"]], ['Counting how many unique identifiers there are by merging two columns of data?'], 2, 1], [(19888255, 1), [['This outputs:'], ["NOTE: This is assuming that the CSV doesn't have the header row ( uniq1,uniq2,three,four,five,six )."]], [[" {'Class02CD3': 7, 'Class02CD1': 2, 'Class01CD2': 3, 'DClass2DE2': 2}\n"]], ['Counting how many unique identifiers there are by merging two columns of data?'], 2, 0], [(19894715, 0), [['Use  zip :'], ["Your code didn't work because it is actually equivalent to:"]], [[' for a, b, c in zip(a_list, b_list, c_list):\n   pass\n']], ["python multiple 'for' statement in one row"], 2, 1], [(19894715, 1), [["Your code didn't work because it is actually equivalent to:"], ['-10000']], [[' for lis in (a_list, b_list, c_list):\n    a, b, c = lis  #assign the items of list fetched from the `tuple` to a, b ,c\n']], ["python multiple 'for' statement in one row"], 2, 0], [(19908167, 0), [['Then you can use  read()  to read the bytes, something like that:'], ['Why not to use  readline()   at this case  from Docs:']], [[' While True:\n    bytesToRead = ser.inWaiting()\n    ser.read(bytesToRead)\n']], ['Reading serial data in realtime in Python'], 2, 1], [(19908167, 1), [['Why not to use  readline()   at this case  from Docs:'], ['You are waiting for the timeout at each reading since it waits for eol. the serial input Q remains the same it just a lot of time to get to the "end" of the buffer, To understand it better: you are writing to the input Q like a race car, and reading like an old car :)']], [[' Read a line which is terminated with end-of-line (eol) character (\\n by default) or until timeout.\n']], ['Reading serial data in realtime in Python'], 2, 0], [(19917545, 0), [['You also need to be careful to create a copy of the DataFrame, otherwise the csvdata_old will be updated with csvdata (since it points to the same object):'], ['To check whether they are equal, you can  use assert_frame_equal as in this answer :']], [[' csvdata_old = csvdata.copy()\n']], ['Comparing two pandas dataframes for differences'], 3, 0], [(19917545, 1), [['To check whether they are equal, you can  use assert_frame_equal as in this answer :'], ['You can wrap this in a function with something like:']], [[' from pandas.util.testing import assert_frame_equal\nassert_frame_equal(csvdata, csvdata_old)\n']], ['Comparing two pandas dataframes for differences'], 3, 1], [(19917545, 2), [['You can wrap this in a function with something like:'], ['There was discussion of a better way...']], [[" try:\n    assert_frame_equal(csvdata, csvdata_old)\n    return True\nexcept:  # appeantly AssertionError doesn't catch all\n    return False\n"]], ['Comparing two pandas dataframes for differences'], 3, 1], [(19923464, 0), [['Use  reduce  and  operator.getitem :'], ['Update value:']], [[" >>> from operator import getitem\n>>> lis = ['car', 'ford', 'mustang']\n"]], ['How can I change the value of a node in a python dictionary by following a list of keys?'], 3, 0], [(19923464, 1), [['Update value:'], ['Fetch value:']], [[" >>> reduce(getitem, lis[:-1], DictOfVehiclePrices)[lis[-1]] = 'cheap'\n"]], ['How can I change the value of a node in a python dictionary by following a list of keys?'], 3, 0], [(19923464, 2), [['Fetch value:'], ['-10000']], [[" >>> reduce(getitem, lis, DictOfVehiclePrices)\n'cheap'\n"]], ['How can I change the value of a node in a python dictionary by following a list of keys?'], 3, 0], [(19925056, 0), [['myConfig.cfg:'], ['Parsing  in python:']], [[' [info]\n\nWidth = 100\n\nHeight = 200\n\nName = My Game\n']], ['Create a game configuration/options (config.cfg) file in Python'], 2, 0], [(19926534, 0), [['Buttons inside of  Spinner  are of type passed to  option_cls  property. The default one is  SpinnerOption  class, which is actually a subclass of  Button . You can change class passed to this property (it must have  text  property and  on_release  event) or modify  SpinnerOption  class globally:'], ['Using custom buttons:']], [[' from kivy.lang import Builder\nfrom kivy.uix.boxlayout import BoxLayout\nfrom kivy.base import runTouchApp\n\nBuilder.load_string(\'\'\'\n<SpinnerOption>:\n    size_hint: None, None\n    size: 20, 20\n\n<MyWidget>:\n    Spinner:\n        id:some_id\n        text:"some text"\n        values:("1","2","3")\n        size_hint:(None,None)\n        size: root.width/4,root.height/12\n\'\'\')\n\nclass MyWidget(BoxLayout):pass\n\nrunTouchApp(MyWidget())\n']], ['how to set the buttons size inside a spinner in kivy?'], 2, 1], [(19926534, 1), [['Using custom buttons:'], ['-10000']], [[' from kivy.lang import Builder\nfrom kivy.uix.boxlayout import BoxLayout\nfrom kivy.uix.button import Button\nfrom kivy.uix.spinner import Spinner\nfrom kivy.base import runTouchApp\nfrom kivy.properties import ObjectProperty\n\nBuilder.load_string(\'\'\'\n<MyButton>:\n    size_hint: None, None\n    size: 20, 20\n\n<MyWidget>:\n    MySpinner:\n        id:some_id\n        text:"some text"\n        values:("1","2","3")\n        size_hint:(None,None)\n        size: root.width/4,root.height/12\n\'\'\')\n\nclass MyButton(Button):\n    pass\n\nclass MySpinner(Spinner):\n    option_cls = ObjectProperty(MyButton) # setting this property inside kv doesn\'t seem to work\n\nclass MyWidget(BoxLayout):\n    pass    \n\nrunTouchApp(MyWidget())\n']], ['how to set the buttons size inside a spinner in kivy?'], 2, 1], [(19928482, 0), [['You will  have  to pass in a reference to the  Test1  instance:'], ['You could store the  a  reference on the  Test2  instance too:']], [[' class Test1(object):\n    def __init__(self):\n        pass\n    def a(self):\n        print("Running a of Test1")\n        test_instance2 = Test2(self)\n    def z(self):\n        print("Running z of Test1")\n\nclass Test2:\n    def __init__(self, a):\n        self.b(a)\n    def b(self, a):\n        print(\'Running b of Test2\')\n        a.z()\n']], ['Call method in a class which called the current class'], 2, 1], [(19928482, 1), [['You could store the  a  reference on the  Test2  instance too:'], ['-10000']], [[" class Test2:\n    def __init__(self, a):\n        self.a = a\n        self.b()\n    def b(self, a):\n        print('Running b of Test2')\n        self.a.z()\n"]], ['Call method in a class which called the current class'], 2, 0], [(19936790, 0), [['you can either try catch the result ( https://stackoverflow.com/questions/6092992/why-is-it-easier-to-ask-forgiveness-than-permission-in-python-but-not-in-java ):'], ['or use a (great) lib such as  requests  and check before scrapping']], [[' for i in xrange(2500,7000):\n    try:\n        page = urllib2.urlopen("http://bvet.bytix.com/plus/trainer/default.aspx?id={}".format(i))\n    except:\n        continue\n    else:\n        soup = BeautifulSoup(page.read())\n        for eachuniversity in soup.findAll(\'fieldset\',{\'id\':\'ctl00_step2\'}):\n            print re.sub(r\'\\s+\',\' \',\',\'.join(eachuniversity.findAll(text=True)).encode(\'utf-8\'))\n            print \'\\n\'\n            number = number + 1\n']], ['Loop URL to scrape using beautiful soup python'], 2, 1], [(19936790, 1), [['or use a (great) lib such as  requests  and check before scrapping'], ["basically there's no way for you to know if the page with that id exists before calling the url."]], [[' import requests\nfor i in xrange(2500,7000):\n    page = requests.get("http://bvet.bytix.com/plus/trainer/default.aspx?id={}".format(i))\n    if not page.ok:\n        continue\n    soup = BeautifulSoup(requests.text)\n    for eachuniversity in soup.findAll(\'fieldset\',{\'id\':\'ctl00_step2\'}):\n        print re.sub(r\'\\s+\',\' \',\',\'.join(eachuniversity.findAll(text=True)).encode(\'utf-8\'))\n        print \'\\n\'\n        number = number + 1\n']], ['Loop URL to scrape using beautiful soup python'], 2, 1], [(19945525, 0), [['Try this:'], ['To do a colorbar instead of a legend:']], [[" import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nnewvid = asciitable.read('user4.cat') \n\nn_new = newvid['n']\nre_new = newvid['re']\nnumber = newvid['number']\nstd_dev = newvid['standard_deviation']\n\nn_max = float(number.max())  # for coloring later\n\nplt.figure()\nplt.title('sersic parameter vs. standard deviation distribution of noise') \nplt.xlabel('standard deviation')\nplt.ylabel('sersic parameter')\nplt.xlim(0,12)\nplt.ylim(0,5) \nfor n in np.unique(number):\n    n_mask = number == n                 # pick out just where n_new is the current n\n    order = np.argsort(std_dev[n_mask])  # sort by std_dev, so line doesn't zig zag\n    plt.plot(std_dev[n_mask][order], n_new[n_mask][order],\n             label=str(n), color=cm.jet(n/n_max))    # label and color by n\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.title('half-light radius vs. standard deviation distribution of noise') \nplt.xlabel('standard deviation')\nplt.ylabel('half-light radius')\nplt.xlim(0,12)\nplt.ylim(-2,15)\n\n# do one plot per number\nfor n in np.unique(number):\n    n_mask = number == n                 # pick out just where n_new is the current n\n    order = np.argsort(std_dev[n_mask])  # sort by std_dev, so line doesn't zig zag\n    plt.plot(std_dev[n_mask][order], re_new[n_mask][order],\n             label=str(n), color=cm.jet(n/n_max))    # label and color by n\nplt.legend()\nplt.show()\n"]], ['Matching y axis points together'], 2, 1], [(19945525, 1), [['To do a colorbar instead of a legend:'], ['']], [[' m = cm.ScalarMappable(cmap=cm.jet)\nm.set_array(number)\nplt.colorbar(m)\n']], ['Matching y axis points together'], 2, 0], [(19962586, 0), [['This will print out all keys in the dictionary  d  where the value is equal to  searchValue :'], ['-10000']], [[' for k, v in d.items():\n    if v == searchValue:\n        print(k)\n']], ['How to turn a dictionary "inside-out"'], 2, 0], [(19964345, 1), [['Using PIL you can do a resize:'], ['I would advise changing your program so that you can resize the image before printing']], [[' from PIL import Image\nfrom pyscreenshot import grab\n\nimg = grab(bbox=(100, 200, 300, 400))\n\n# to keep the aspect ratio\nw = 300\nh = 400\nmaxheight = 600\nmaxwidth = 800\nratio = min(maxwidth/width, maxheight/height)\n# correct image size is not #oldsize * ratio#\n\n# img.resize(...) returns a resized image and does not effect img unless\n# you assign the return value\nimg = img.resize((h * ratio, width * ratio), Image.ANTIALIAS)\n']], ['How to do a screenshot of a tkinter application?'], 2, 0], [(20023209, 0), [['I have written such a function to use in pygame before. It is kinda self-explanatory but feel free to ask the parts that require clarification. Here is my code:'], ['I also have a function that rotates the given point(x,y) around another one. I share it in case you find it useful (And you can combine these two functions to rotate the polygon around another point rather than the origin):']], [[' import math\ndef rotatePolygon(polygon,theta):\n    """Rotates the given polygon which consists of corners represented as (x,y),\n    around the ORIGIN, clock-wise, theta degrees"""\n    theta = math.radians(theta)\n    rotatedPolygon = []\n    for corner in polygon :\n        rotatedPolygon.append(( corner[0]*math.cos(theta)-corner[1]*math.sin(theta) , corner[0]*math.sin(theta)+corner[1]*math.cos(theta)) )\n    return rotatedPolygon\n\n\nmy_polygon = [(0,0),(1,0),(0,1)]\nprint rotatePolygon(my_polygon,90)\n']], ['Function for rotating 2d objects?'], 2, 1], [(20024490, 0), [['You can use slicing on  byte  objects:'], ["When handling these frames, however, you probably also want to know about  memoryview()  objects ; these let you interpret the bytes as C datatypes without any extra work on your part, simply by casting a 'view' on the underlying bytes:"]], [[" >>> value = b'\\x00\\x01\\x00\\x02\\x00\\x03'\n>>> value[:2]\nb'\\x00\\x01'\n>>> value[2:4]\nb'\\x00\\x02'\n>>> value[-2:]\nb'\\x00\\x03'\n"]], ['How to split a byte string into separate bytes in python'], 2, 1], [(20024490, 1), [["When handling these frames, however, you probably also want to know about  memoryview()  objects ; these let you interpret the bytes as C datatypes without any extra work on your part, simply by casting a 'view' on the underlying bytes:"], ['The  mv  object is now a memory view interpreting every 2 bytes as an unsigned short; so it now has length 3 and each index is an integer value, based on the underlying bytes. ']], [[" >>> mv = memoryview(value).cast('H')\n>>> mv[0], mv[1], mv[2]\n256, 512, 768\n"]], ['How to split a byte string into separate bytes in python'], 2, 0], [(20052327, 0), [['Use a  collections.defaultdict()  object  for ease:'], ['Demo:']], [[' from collections import defaultdict\n\nresult = defaultdict(list)\n\nfor key, *values in data:\n    result[key].extend(values)\n']], ['Merging repeated items in a list into a python dictionary'], 2, 1], [(20052327, 1), [['Demo:'], ['-10000']], [[" >>> from collections import defaultdict\n>>> data = (['aaron distilled ', 'alcohol', '5'], \n... ['aaron distilled ', 'gin', '2'], \n... ['aaron distilled ', 'beer', '6'], \n... ['aaron distilled ', 'vodka', '9'], \n... ['aaron evicted ', 'owner', '1'], \n... ['aaron evicted ', 'bum', '1'], \n... ['aaron evicted ', 'deadbeat', '1'])\n>>> result = defaultdict(list)\n>>> for key, *values in data:\n...    result[key].extend(values)\n... \n>>> result\ndefaultdict(<class 'list'>, {'aaron distilled ': ['alcohol', '5', 'gin', '2', 'beer', '6', 'vodka', '9'], 'aaron evicted ': ['owner', '1', 'bum', '1', 'deadbeat', '1']})\n"]], ['Merging repeated items in a list into a python dictionary'], 2, 1], [(20062672, 0), [['I have the same problem, But context fixed my problem,'], ['Like,']], [[' context="{\'search_default_employee_id\':employee_id}"\n']], ['Search with employee_id in openerp?'], 2, 1], [(20062672, 1), [['Like,'], ['-10000']], [[' <button name="%(hr_holidays.action_your_action_form_test)d" string="Leaves" type="action" context="{\'search_default_employee_id\':employee_id}" />\n']], ['Search with employee_id in openerp?'], 2, 1], [(20062684, 0), [['use  crosstab :'], ['the result is same as:']], [[' import numpy as np\nimport pandas as pd\ndf = pd.DataFrame(np.random.randint(0, 10, size=(100, 2)), columns=["type", "subtype"])\ncounts = pd.crosstab(df.type, df.subtype)\n\nprint counts.loc[0, [2, 3, 5, 6]].sum() + counts.loc[5, [3, 4, 7, 8]].sum()\n']], ['Pandas OR statement ending in series contains'], 2, 1], [(20062684, 1), [['the result is same as:'], ['-10000']], [[' a = (((df.type == 0) & ((df.subtype == 2) | (df.subtype == 3) | \n         (df.subtype == 5) | (df.subtype == 6))) | \n         ((df.type == 5) & ((df.subtype == 3) | (df.subtype == 4) | (df.subtype == 7) | \n         (df.subtype ==  8))))\na.sum()\n']], ['Pandas OR statement ending in series contains'], 2, 0], [(20063721, 0), [['-10000'], ['Output']], [[' from itertools import product\ndef randString(istr):\n    l = [(c, c.upper()) if not c.isdigit() else (c,) for c in istr.lower()]\n    return ["".join(item) for item in product(*l)]\n\nprint randString("aBC1")\nprint randString("A1b2c3")\n']], ['String manipulation in Python (All upper and lower case derivatives of a word)'], 2, 1], [(20063721, 1), [['Output'], ['-10000']], [[" ['abc1', 'abC1', 'aBc1', 'aBC1', 'Abc1', 'AbC1', 'ABc1', 'ABC1']\n['a1b2c3', 'a1b2C3', 'a1B2c3', 'a1B2C3', 'A1b2c3', 'A1b2C3', 'A1B2c3', 'A1B2C3']\n"]], ['String manipulation in Python (All upper and lower case derivatives of a word)'], 2, 0], [(20082507, 0), [['You can simply use a  list comprehension , instead of trying to create a new list via a  for -loop:'], ["If you're dealing with a dictionary, you can still apply something similar:"]], [[" a = [s.replace('1','3') for s in self.test_lockCheck()]\n"]], ['Python; Search and Replace; Lists; Strings'], 2, 1], [(20082507, 1), [["If you're dealing with a dictionary, you can still apply something similar:"], ['-10000']], [[" a = {k.replace('1','3'): v for k,v in self.test_lockCheck().iteritems()}\n"]], ['Python; Search and Replace; Lists; Strings'], 2, 1], [(20147593, 0), [['You could use a  defaultdict , with the default factory set to a  list , then feed the  Counter  to it'], ['As an aside, you should be able to initialize the  Counter  directly, like so']], [[' from collections import defaultdict\nd = defaultdict(list)\nfor key, value in cnt.items():\n     d[value].append(key)     \n\nfor key, value in d.items():                                                \n   print \'{}:{}\'.format(key, " ".join(value))                              \n\n2:windows\n3:android iphone\n5:apple\n....    \n']], ['Group counted words in python'], 2, 1], [(20147593, 1), [['As an aside, you should be able to initialize the  Counter  directly, like so'], ['-10000']], [[' cnt = Counter(keywords)\n']], ['Group counted words in python'], 2, 0], [(20153165, 0), [['Elapsed time should expressed as a  timedelta  type, which is what you get when you perform subtraction on two datetimes.'], ['To round it to the day, we have to jump through some hoops.']], [[" In [43]: datetime.now() - df['Date']\nOut[43]:\n0   38 days, 00:08:44.917269\n1   39 days, 00:08:44.917269\n2   39 days, 05:22:44.917269\n"]], ['Pandas Python: How to create lapse since today column?'], 2, 0], [(20190748, 0), [['I took a different approach.\nOn the main page of CompanyExecutive i added a custom field which is link to the Executive object. This way if user want to change the relation of the CompanyExecutive he can click on the object as usual and if he/she wants to change Executive details he can click on the link.\nIn model i added a custom field'], ['And in Admin panel i displayed this field on the main page.']], [[' def Person_Link(self):\n    return "<a href=\'/admin/sweetspotModel/persons/%s/\' target=\'_blank\'>Person Details<a/>" % self.contactid.contactid\nPerson_Link.allow_tags = True  \n']], ["Django Admin Panel. Display and Edit Parent Fields in Child's Object (ModelAdmin.inlines reverse)"], 2, 0], [(20190748, 1), [['And in Admin panel i displayed this field on the main page.'], ['I hope this approach helps anyone.']], [[" class ExecutiveAdmin(admin.ModelAdmin):\n    list_display = ('Person_Name', 'Person_Link')\n"]], ["Django Admin Panel. Display and Edit Parent Fields in Child's Object (ModelAdmin.inlines reverse)"], 2, 0], [(20198951, 0), [['The trick is passing the right  key  parameter to the  sorted()  function. Try this:'], ['Alternatively:']], [[' sorted(lst, key=lambda x: x[1])\n']], ['How to sort an itertools grouper array in python'], 3, 1], [(20198951, 1), [['Alternatively:'], ["The above is assuming that  lst  is the input data, it doesn't matter where it comes from. Either way, the result will be as expected:"]], [[' import operator as op\nsorted(lst, key=op.itemgetter(1))\n']], ['How to sort an itertools grouper array in python'], 3, 1], [(20198951, 2), [["The above is assuming that  lst  is the input data, it doesn't matter where it comes from. Either way, the result will be as expected:"], ['-10000']], [[" [('a', 1L), ('b', 2L), ('c', 3L)]\n"]], ['How to sort an itertools grouper array in python'], 3, 0], [(20211031, 0), [['Make the list of values using  list comprehension'], ['Then use  itertools.product  which is equivalent to for-loop.']], [[' >>> d = {"a": [1], "b": [2,3], "c": [4,5,6]}\n>>> values = [v for k,v in d.items()]\n>>> values\n[[1], [4, 5, 6], [2, 3]]\n']], ['Obtaining the combination of elements in a dictionary'], 2, 0], [(20211031, 1), [['Then use  itertools.product  which is equivalent to for-loop.'], ['-10000']], [[' >>> for i in itertools.product(*l):\n...     print i\n... \n(1, 4, 2)\n(1, 4, 3)\n(1, 5, 2)\n(1, 5, 3)\n(1, 6, 2)\n(1, 6, 3)\n']], ['Obtaining the combination of elements in a dictionary'], 2, 0], [(20212171, 0), [['You can do this:'], ['or this:']], [[' {% for key, val in d.items %}\n    {% if val.subproduct1 %}\n        {% for value in val.subproduct1 %}\n            {{ value }}\n        {% endfor %}\n    {% endif %}\n    {% if val.subproduct2 %}\n        {% for value in val.subproduct2 %}\n            {{ value }}\n        {% endfor %}\n    {% endif %}\n{% endfor %}\n']], ['Django templates check whether key is existing'], 2, 1], [(20212171, 1), [['or this:'], ['-10000']], [[' {% for key, val in d.items %}\n    {% for key2, val2 in val.items %}\n        {% if val2 %}\n            {% for value in val2 %}\n                {{ value }}\n            {% endfor %}\n        {% endif %}\n    {% endfor %}\n{% endfor %}\n']], ['Django templates check whether key is existing'], 2, 1], [(20215266, 0), [['Make a file  questions.py :'], ['And then make your main module (e. g. the file  quiz.py ):']], [[' sports_questions = ["What sport did michael jordan play?", "blablalba?", "and so on"]\ncomputer_questions = ["Who founded microsoft?", "blabla", "many questions"]\n']], ['Having large lists in main scripts, is there anyway to get it out of the main-script and into another module?'], 2, 0], [(20215266, 1), [['And then make your main module (e. g. the file  quiz.py ):'], ['Does this make it clear how to refactor your questions into another module?']], [[' #!/usr/bin/env python\n\nimport questions\n\nprint "question one is,", questions.sports_questions[0]\n']], ['Having large lists in main scripts, is there anyway to get it out of the main-script and into another module?'], 2, 0], [(20224501, 0), [['Man, this can be quite a process!  I had to update some metadata information for a project at work the other day, so here goes nothing.  It would be helpful to stored all of the metadata information in the excel table as a dictionary list or other data structure of your choosing (I work with csvs and try to stay away from excel spreadsheets for experience reasons).'], ['From there, I would actually export the current metadata feature class using the Export Metadata function to convert your feature class metadata into an xml file using a FGDC schema.  Here is a code example below:']], [[' metaInfo = [{"featureClass":"fc1",\n             "abstract":"text goes here", \n             "description":"text goes here",\n             "tags":["tag1","tag2","tag3"]},\n            {"featureClass":"fc2",\n             "abstract":"text goes here", \n             "description":"text goes here",\n             "tags":["tag1","tag2","tag3"]},...]\n']], ['updating metadata for feature classes programatically using arcpy'], 6, 0], [(20224501, 1), [['From there, I would actually export the current metadata feature class using the Export Metadata function to convert your feature class metadata into an xml file using a FGDC schema.  Here is a code example below:'], ['From there, you can use the xml module to access the ElementTree class.  However, I would recommend using the lxml module ( http://lxml.de/index.html#download ) because it allows you to incorporate html code into your metadata through the CDATA factory if you needed special elements like line breaks in your metadata. From there, assuming that you have imported lxml, parse your local xml document:']], [[' #Directory containing ArcGIS Install files\ninstallDir = arcpy.GetInstallInfo("desktop")["InstallDir"]\n#Path to XML schema for FGDC\ntranslator = os.path.join(installDir, "Metadata/Translator/ARCGIS2FGDC.xml")\n#Export your metadata\narcpy.ExportMetadata_conversion(featureClassPath, translator, tempXmlExportPath)\n']], ['updating metadata for feature classes programatically using arcpy'], 6, 0], [(20224501, 2), [['From there, you can use the xml module to access the ElementTree class.  However, I would recommend using the lxml module ( http://lxml.de/index.html#download ) because it allows you to incorporate html code into your metadata through the CDATA factory if you needed special elements like line breaks in your metadata. From there, assuming that you have imported lxml, parse your local xml document:'], ['If you want to update the tags use the code below:']], [[' import lxml.etree as ET\ntree = ET.parse(tempXmlExportPath)\nroot = tree.getroot()\n']], ['updating metadata for feature classes programatically using arcpy'], 6, 0], [(20224501, 3), [['If you want to update the tags use the code below:'], ['To update the Summary tags, use this code:']], [[' idinfo = root[0]\n\n#Create keyworks element\nkeywords = ET.SubElement(idinfo, "keywords")\ntree.write(tempXmlExportPath)\n\n#Create theme child\ntheme = ET.SubElement(keywords, "theme")\ntree.write(tempXmlExportPath)\n\n#Create themekt and themekey grandchildren/insert tag info\nthemekt = ET.SubElement(theme, "themekt")\ntree.write(tempXmlExportPath)\nfor tag in tags: #tags list from your dictionary\n    themekey = ET.SubElement(theme, "themekey")\n    themekey.text = tag\n    tree.write(tempXmlExportPath)\n']], ['updating metadata for feature classes programatically using arcpy'], 6, 0], [(20224501, 4), [['To update the Summary tags, use this code:'], ['If a tag in the xml already exists, store the tag as an object using the parent.find("child") method, and update the text similar to the code examples above.  Once you have updated your local xml file, use the Import Metadata method to import the xml file back into the feature class and remove the local xml file.']], [[' #Create descript tag\ndescript = ET.SubElement(idinfo, "descript")\ntree.write(tempXmlExportPath)\n\n#Create purpose child from abstract\nabstract = ET.SubElement(descript, "abstract")\ntext = #get abstract string from dictionary\nabstract.text = text\ntree.write(tempXmlExportPath)\n']], ['updating metadata for feature classes programatically using arcpy'], 6, 0], [(20224501, 5), [['If a tag in the xml already exists, store the tag as an object using the parent.find("child") method, and update the text similar to the code examples above.  Once you have updated your local xml file, use the Import Metadata method to import the xml file back into the feature class and remove the local xml file.'], ['Keep in mind that these tools in Arc are only for 32 bit, so if you are scripting through the 64 bit background geoprocessor, this will not work.  I am working off of ArcMap 10.1.  If you have any questions, please let me know or consult the documentation below:']], [[' arcpy.ImportMetadata_conversion(tempXmlExportPath, "FROM_FGDC", featureClassPath)\nshutil.rmtree(tempXmlExportPath)\n']], ['updating metadata for feature classes programatically using arcpy'], 6, 0], [(20234453, 0), [['This snippet works with the example and could be tailored to handle corner cases.'], ['Output:']], [[' import collections\n\nwith open("cpu_text", "r") as f:\n    lines = f.readlines()\n\nlines = [line.strip() for line in lines]\n\ngroup_id = 0\ngroup_member_id = 0\noutput_dict = collections.OrderedDict()\n\nfor line in lines:\n    if line.find("SYS") > -1:\n        group_id += 1\n    elif line.find("Tot") > -1:\n        group_member_id = 0\n    else:\n        group_member_id += 1\n        key = "{0}-{1}".format(group_id, group_member_id)\n        memory = line.split()[7]\n        output_dict[key] = memory\n\nprint(output_dict)\n']], ['Parsing members of a variable length python string'], 2, 1], [(20234453, 1), [['Output:'], ['-10000']], [[" OrderedDict([('1-1', '92'), ('1-2', '2'), ('2-1', '1'), ('3-1', '8'), ('3-2', '200'), ('3-3', '6')])\n"]], ['Parsing members of a variable length python string'], 2, 0], [(20243683, 0), [['You need to manually set the  yticks  as it stands these are automatically calculated resulting in a variation. Adding something like this:'], ['where we set the  ytick  locations using an array of 5 points between the bounds of the axis. Since  you have a histogram you could just set the lower value to zero in each case, and you may want to have the upper bound somewhat larger, so I would instead have']], [[' ax1.set_yticks(np.linspace(ax1.get_ybound()[0], ax1.get_ybound()[1], 5))\nax2.set_yticks(np.linspace(ax2.get_ybound()[0], ax2.get_ybound()[1], 5))\n']], ['matplotlib align twinx tick marks'], 2, 0], [(20249149, 1), [['For example,'], ['yields']], [[' import pandas as pd\n\ndata = pd.Series(range(1, 9))\n\ndata_mean = pd.rolling_mean(data, window=5).shift(-2)\nprint(data_mean)\n']], ['Rolling mean with customized window with Pandas'], 4, 1], [(20249149, 2), [['yields'], ['-10000']], [[' 0   NaN\n1   NaN\n2     3\n3     4\n4     5\n5     6\n6   NaN\n7   NaN\ndtype: float64\n']], ['Rolling mean with customized window with Pandas'], 4, 0], [(20249149, 3), [['-10000'], ['-10000']], [[' pd.rolling_mean(data, window=5, center=True)\n']], ['Rolling mean with customized window with Pandas'], 4, 0], [(20283478, 0), [['Build a key that reflects the structure; split on comma and reverse:'], ['Demo:']], [[" sorted(a, key=lambda p: map(str.strip, p.split(',')[::-1]))\n"]], ['Ordering a list according to hierarchy'], 2, 1], [(20295134, 0), [['Loop over the nested lists and test those; the  any()  function  makes this efficient:'], ['If recursion is required, you could use:']], [[' def nested(x, ys):\n    return any(x in nested for nested in ys)\n']], ['How to check if an element is in a nested list?'], 2, 1], [(20295134, 1), [['If recursion is required, you could use:'], ["I used a simplified test for  list  and  tuple  only to avoid 'flattening' strings."]], [[' def flatten(lst):\n    for elem in lst:\n        if isinstance(elem, (list, tuple)):\n            for nested in flatten(elem):\n                yield nested\n        else:\n            yield elem\n\ndef nested(x, ys):\n    return any(x == nested for nested in flatten(ys))\n']], ['How to check if an element is in a nested list?'], 2, 1], [(20316339, 0), [['You can run that code interactively in the dev shell.'], ['For future reference, though: all you need to do to make a plain  .py  file "Django compatible" is that you set the  DJANGO_SETTINGS_MODULE  environment variable before importing any Django stuff:']], [[' python manage.py shell\n']], ['Django Python Shell'], 2, 1], [(20316339, 1), [['For future reference, though: all you need to do to make a plain  .py  file "Django compatible" is that you set the  DJANGO_SETTINGS_MODULE  environment variable before importing any Django stuff:'], ['-10000']], [[' import os\nos.environ.setdefault("DJANGO_SETTINGS_MODULE", "myproj.settings")\nfrom myapp.models import Stuff\n# ...\n']], ['Django Python Shell'], 2, 1], [(20337561, 1), [['If you need to pass the other color in, you can do it like this'], ['-10000']], [[' from functools import partial\ndef difference_func(test_color, other_color):\n    return ???\n\nresult = min(colors, key=partial(difference_func, test_color))\n']], ['Python find closest match out of list'], 2, 0], [(20339462, 0), [['Use  itertools.product() :'], ['Demo:']], [[" from itertools import product\n\nlsts = [['A', 'G'], ['A', 'C', 'G'], 'T']\noutput = [''.join(combo) for combo in product(*lsts)]\n"]], ['Generate permutations of a list of lists with variable lengths'], 4, 1], [(20339462, 1), [['Demo:'], ['You could reduce your nested lists to strings for the same output:']], [[" >>> from itertools import product\n>>> lsts = [['A','G'],['A','C','G'],'T']\n>>> [''.join(combo) for combo in product(*lsts)]\n['AAT', 'ACT', 'AGT', 'GAT', 'GCT', 'GGT']\n"]], ['Generate permutations of a list of lists with variable lengths'], 4, 1], [(20339462, 2), [['You could reduce your nested lists to strings for the same output:'], ["or, for consistency's sake, make the last element a list:"]], [[" lsts = ['AG', 'ACG','T']\n"]], ['Generate permutations of a list of lists with variable lengths'], 4, 0], [(20339462, 3), [["or, for consistency's sake, make the last element a list:"], ["but it'll work with the mixed sequences too."]], [[" lsts = [['A', 'G'], ['A', 'C', 'G'], ['T']]\n"]], ['Generate permutations of a list of lists with variable lengths'], 4, 0], [(20359968, 0), [['You need to use third table for that task, for example:'], ['and then you can use intermediary table  https://docs.djangoproject.com/en/dev/topics/db/models/#intermediary-manytomany']], [[' class OrderProduct(BaseModel):\n    order = models.ForeignKey(Order)\n    product = models.ForeignKey(Product)\n    quantity = models.IntegerField()\n']], ['Django, m2m with same model'], 3, 0], [(20359968, 1), [['and then you can use intermediary table  https://docs.djangoproject.com/en/dev/topics/db/models/#intermediary-manytomany'], ['Unlike normal many-to-many fields, you can’t use add, create, or assignment (i.e.,  order.products.add(prod) ) to create relationships. You should manually create record in  through  table:']], [[" class Order(BaseModel):\n    company = models.ForeignKey(Company)\n    products = models.ManyToManyField(Product, through='OrderProduct')\n"]], ['Django, m2m with same model'], 3, 0], [(20359968, 2), [['Unlike normal many-to-many fields, you can’t use add, create, or assignment (i.e.,  order.products.add(prod) ) to create relationships. You should manually create record in  through  table:'], ['check this questions:']], [[' prod = Product.objects.get(uuid=product)\n#order.products.add(prod)\nq = product_quantity\norder = order # order record must be created before\n\nOrderProduct.objects.create(order=order, product=prod, quantity=q)\n']], ['Django, m2m with same model'], 3, 0], [(20385957, 0), [['Track a total:'], ['Demo:']], [[' total = 0\nfor key, value in month_dictionary.iteritems():\n    total += value\n    month_dictionary[key] = total\n']], ['accumulating an orderedDict'], 2, 1], [(20385957, 1), [['Demo:'], ['-10000']], [[" >>> from collections import OrderedDict\n>>> month_dictionary = OrderedDict((('012013', 3), ('022013', 1), ('032013', 5)))\n>>> total = 0\n>>> for key, value in month_dictionary.iteritems():\n...     total += value\n...     month_dictionary[key] = total\n... \n>>> month_dictionary\nOrderedDict([('012013', 3), ('022013', 4), ('032013', 9)])\n"]], ['accumulating an orderedDict'], 2, 1], [(20388992, 0), [['you can open a pipe ( see  doc  ):'], ['as in the document this syntax is depreciated and is replaced with more complicated  subprocess.Popen']], [[" import os\n\nwith os.popen('ls') as pipe:\n    for line in pipe:\n        print (line.strip())\n"]], ['Python: Nice way to iterate over shell command result'], 2, 1], [(20414562, 0), [['Something like'], ['produces']], [[" import csv\nfrom collections import OrderedDict\n\nwith open('b.csv', 'rb') as f:\n    r = csv.reader(f)\n    dict2 = {row[0]: row[1:] for row in r}\n\nwith open('a.csv', 'rb') as f:\n    r = csv.reader(f)\n    dict1 = OrderedDict((row[0], row[1:]) for row in r)\n\nresult = OrderedDict()\nfor d in (dict1, dict2):\n    for key, value in d.iteritems():\n        result.setdefault(key, []).extend(value)\n\nwith open('ab_combined.csv', 'wb') as f:\n    w = csv.writer(f)\n    for key, value in result.iteritems():\n        w.writerow([key] + value)\n"]], ['Python Joining csv files where key is first column value'], 2, 1], [(20414562, 1), [['produces'], ["(Note that I didn't bother protecting against the case where  dict2  has a key which isn't in  dict1 -- that's easily added if you like.)"]], [[' john,red,34\nandrew,green,18\ntonny,black,50,driver,new york\njack,yellow,27\nphill,orange,45,scientist,boston\nkurt,blue,29\nmike,pink,61\n']], ['Python Joining csv files where key is first column value'], 2, 0], [(20431617, 0), [["Multi-index has an implicit concept of hierarchy; if your computations tend to break this hierarchy then you may be better off not to use mult-index. As for your example, you may achieve what you want to do with a different order for the indices. That is if the dataframe was indexed by  ['Location','Date','gas']  ( in that order )"], ['you could use  ix  as in:']], [['                                   val1\nLocation Date                gas      \nA        2013-01-01 00:00:00 no2     0\n         2013-01-01 00:00:05 o3      1\n         2013-01-01 00:00:10 so2     2\nB        2013-01-01 00:00:00 no2     3\n         2013-01-01 00:00:05 o3      4\n         2013-01-01 00:00:10 so2     5\n']], ['Truncating multi-indexed dataframe'], 5, 0], [(20431617, 2), [['which outputs:'], ['or for a single column:']], [['                          val1\nDate                gas      \n2013-01-01 00:00:05 o3      1\n2013-01-01 00:00:10 so2     2\n']], ['Truncating multi-indexed dataframe'], 5, 0], [(20431617, 4), [['which outputs:'], ['-10000']], [[' Date                 gas\n2013-01-01 00:00:05  o3     1\n2013-01-01 00:00:10  so2    2\nName: val1, dtype: int64\n']], ['Truncating multi-indexed dataframe'], 5, 0], [(20445470, 1), [['which is training on a  singleton  of observations, if you have multiple ones, for example X1,X2,X3 you can run'], ['in general for HMM implementation in scikit-learn you give it a  sequence  of observations S']], [[' model.fit([X1,X2,X3])\n']], ['Scikit Learn HMM training with set of observation sequences'], 3, 1], [(20445470, 2), [['in general for HMM implementation in scikit-learn you give it a  sequence  of observations S'], ['-10000']], [[' model.fit(S)\n']], ['Scikit Learn HMM training with set of observation sequences'], 3, 1], [(20445672, 0), [['With itertools, generating all the combinations along the line:'], ['Demo:']], [[' def powerprod(iterable):\n    s = list(iterable)\n    for r in itertools.count(1):\n        for c in itertools.product(s, repeat=r):\n            yield c\n']], ['finding nth combination (incremental approach) of letters (list)'], 4, 1], [(20445672, 2), [["AFAIK, @gnibbler approach won't work, as do not distinguish between  001  and  1  and similar combinations. Here is a faster way to get only n'th combination :"], ['Demo:']], [[' from itertools import product, islice\n\ndef max_sum_n_pow_lower_x(x, n):\n    """ returns tuple of number of summand and maximal sum\n        of form `n` + `n`**2 + `n`**3  not greater than `x` """\n    i, c, s = 1, 0, 0\n    while s < x:\n       i *= n\n       c += 1\n       s += i\n    return c-1, s-i\n\ndef get_nth_pow(iterable, n):\n    l = list(iterable)\n    repeat, start_from = max_sum_n_pow_lower_x(n, len(l))\n    prod = itertools.product(l, repeat=repeat+1)\n    return \'\'.join(list(islice(prod, n-start_from))[-1])\n']], ['finding nth combination (incremental approach) of letters (list)'], 4, 1], [(20445672, 3), [['Demo:'], ['-10000']], [[" >>> get_nth_pow('eht', 34)\n'the'\n"]], ['finding nth combination (incremental approach) of letters (list)'], 4, 0], [(20452340, 0), [['Best practice is to run the tests  themselves . Add the  __main__  section there to the  myTests.py  file:'], ["Alternatively, pass in the imported  myTests  module into  unittest.main() . You may want to move the  import myTests  line  down  into  __main__ , because you have a circular import too. That is fine in your case,  myTests  doesn't use any globals from  calc  outside of the test cases, but it is better to be explicit about this."]], [[" import unittest\nimport calc\n\nclass TestSequenceFunctions(unittest.TestCase):\n    def setUp(self):\n        self.testInput = 10\n\n    def test_first(self):\n        output = calc.first(self.testInput)\n        correct = 100\n        assert(output == correct)\n\n    def test_second(self):\n        output = calc.second(self.testInput)\n        correct = 1000\n        assert(output == correct)\n\nif __name__ == '__main__':\n    unittest.main()\n"]], ['Right way to write Unit-Tests in module?'], 2, 1], [(20470749, 0), [['-10000'], ['Output']], [[' a = ["part 1", "part 3" , "part 10", "part 2"]\nprint sorted(a, key=lambda x:int(x.split()[1]))\n']], ["how to sort a list of string by every element's numeric value"], 3, 1], [(20470749, 1), [['Output'], ['If you want to sort in-place,']], [[" ['part 1', 'part 2', 'part 3', 'part 10']\n"]], ["how to sort a list of string by every element's numeric value"], 3, 0], [(20470749, 2), [['If you want to sort in-place,'], ['-10000']], [[' a.sort(key=lambda x:int(x.split()[1]))\nprint a\n']], ["how to sort a list of string by every element's numeric value"], 3, 1], [(20484918, 0), [['Various versions:'], ['-10000']], [[" # straightforward but deep\ndef is_full(self):\n    for row in self.data:\n        for cell in row:\n            if cell == ' ':\n                return False\n    return True\n"]], ['Python Check a 2d list for empty strings?'], 3, 1], [(20484918, 1), [['-10000'], ['-10000']], [[" # combine the last two\ndef is_full(self):  # python functions/methods are usually lower case\n    for row in self.data:  # no need to index everything like c\n        if any(cell == ' ' for cell in row):  # any/all are convenient testers\n            return False  # if you find even one, it's done.\n    return True  # if you couldn't disqualify it, then it looks full\n"]], ['Python Check a 2d list for empty strings?'], 3, 1], [(20484918, 2), [['-10000'], ['-10000']], [[" # one line, not especially readable\ndef is_full(self):\n    return not any(cell == ' ' for row in d for cell in row)\n"]], ['Python Check a 2d list for empty strings?'], 3, 1], [(20511905, 0), [["Here's an example of what I mean:"], ['When its only about plotting, you could just use']], [[" import numpy as np\n\nx = np.array([1,2,3,4,5])\ny = np.array([100,200,300,400,500])\n\n# b contains true when corresponding value of x is outside 2 < x < 4\nb = np.ma.masked_outside(x, 2, 4).mask\n\n# x2 originates from x, but values 2 < x < 4 are stripped (according to the boolean variables contained in b), the same is done with y2\nx2 = x[~b]\ny2 = y[~b]\n\nprint 'x2', x2\nprint 'y2', y2\n"]], ['select a specific range from a numpy 2d array to plot values'], 2, 1], [(20524146, 0), [["It doesn't quite preserve the whitespacing and could probably be made a bit smarter, but it will at least identify Python strings (apostrophes/quotes/multi line) correctly without resorting to a regex or external parser:"], ['Example input:']], [[" import tokenize\nfrom itertools import count\nimport re\n\nwith open('your_file') as fin:\n    output = []\n    tokens = tokenize.generate_tokens(fin.readline)\n    for num, val in (token[:2] for token in tokens):\n        if num == tokenize.STRING:\n            val = re.sub('{}', lambda L, c=count(): '{{{0}}}'.format(next(c)), val)\n        output.append((num, val))\n\nprint tokenize.untokenize(output) # write to file instead...\n"]], ['String formatting without index in python2.6'], 3, 1], [(20524146, 1), [['Example input:'], ['Example output (note slightly iffy whitespacing):']], [[' s = "{} {}".format(\'foo\', \'bar\')\nif something:\n    do_something(\'{} {} {}\'.format(1, 2, 3))\n']], ['String formatting without index in python2.6'], 3, 0], [(20524146, 2), [['Example output (note slightly iffy whitespacing):'], ['-10000']], [[' s ="{0} {1}".format (\'foo\',\'bar\')\nif something :\n    do_something (\'{0} {1} {2}\'.format (1 ,2 ,3 ))\n']], ['String formatting without index in python2.6'], 3, 0], [(20531168, 0), [['In your case:'], ['So you now have a list of 2 immutable objects!\nYour next step:']], [[' inst1 = Test(2)  # create 2 and attach it to inst1.i\ninst2 = Test(5)  # create 5 and attach it to inst2.i\nMyList = [inst1.i,inst2.i]  # list of objects: [2 ,5]\n']], ['Python : How to create a dynamic list of class values'], 4, 0], [(20531168, 1), [['So you now have a list of 2 immutable objects!\nYour next step:'], ['Basically you need to change perspective!  MyList  is NOT an Array, but a collection. So in order not to reinvent your venue of solution i would recommend to keep the  Test  objects in your list, rather than their values!:']], [[' inst1.i = 4\n']], ['Python : How to create a dynamic list of class values'], 4, 0], [(20582840, 0), [["You'd use  abs()  to get the absolute value of a subtraction:"], ['Demo:']], [[' if abs(a - b) > 5:\n']], ['Operators to measure difference in Python'], 2, 1], [(20593215, 0), [['-10000'], ['Call  f  for each item in  L  to generate  fL']], [[' >>> from itertools import product\n>>> L = ["A", "B", "C"]\n>>> def f(c): return c.lower()\n... \n>>> fL = [f(x) for x in L]\n>>> for i in product(*zip(L, fL)):\n...     print i\n... \n(\'A\', \'B\', \'C\')\n(\'A\', \'B\', \'c\')\n(\'A\', \'b\', \'C\')\n(\'A\', \'b\', \'c\')\n(\'a\', \'B\', \'C\')\n(\'a\', \'B\', \'c\')\n(\'a\', \'b\', \'C\')\n(\'a\', \'b\', \'c\')\n']], ['Given an iterable, how to apply a function in every possible combination?'], 6, 1], [(20593215, 1), [['Call  f  for each item in  L  to generate  fL'], ['Use  zip  to zip the two lists into pairs']], [[" >>> fL\n['a', 'b', 'c']\n"]], ['Given an iterable, how to apply a function in every possible combination?'], 6, 0], [(20593215, 2), [['Use  zip  to zip the two lists into pairs'], ['Take the cartesian product of those tuples using  itertools.product']], [[" >>> zip(L, fL)\n[('A', 'a'), ('B', 'b'), ('C', 'c')]\n"]], ['Given an iterable, how to apply a function in every possible combination?'], 6, 0], [(20593215, 3), [['Take the cartesian product of those tuples using  itertools.product'], ['is equivalent to ']], [[' product(*zip(L, fL))\n']], ['Given an iterable, how to apply a function in every possible combination?'], 6, 0], [(20593215, 4), [['is equivalent to '], ['and that is equivalent to ']], [[" product(*[('A', 'a'), ('B', 'b'), ('C', 'c')])\n"]], ['Given an iterable, how to apply a function in every possible combination?'], 6, 0], [(20593215, 5), [['and that is equivalent to '], ['looping over that product, gives exactly the result we need.']], [[" product(('A', 'a'), ('B', 'b'), ('C', 'c'))\n"]], ['Given an iterable, how to apply a function in every possible combination?'], 6, 0], [(20622240, 0), [["You can see 'Selenium2Library'!"], ["a module named '_ALibrary.py'"]], [[' class Selenium2Library(\n_LoggingKeywords, \n_RunOnFailureKeywords, \n_BrowserManagementKeywords, \n_ElementKeywords, \n_TableElementKeywords,\n_FormElementKeywords,\n_SelectElementKeywords,\n_JavaScriptKeywords,\n_CookieKeywords,\n_ScreenshotKeywords,\n_WaitingKeywords\n']], ['Can I use one import and expose keywords from multiple python libraries?'], 4, 0], [(20622240, 1), [["a module named '_ALibrary.py'"], ["a module named '_BLibrary.py'"]], [[" class _ALibrary(object):\ndef __init__(self):\n    pass\ndef fun1(self):\n    print 'fun1'`\n"]], ['Can I use one import and expose keywords from multiple python libraries?'], 4, 0], [(20622240, 2), [["a module named '_BLibrary.py'"], ["a common module named'CommonLibrary.py'"]], [[" class _BLibrary(object):\n\ndef __init__(self):\n    pass\ndef fun2(self):\n    print 'fun2'\ndef fun3(self):\n    print 'fun3'\n"]], ['Can I use one import and expose keywords from multiple python libraries?'], 4, 0], [(20622240, 3), [["a common module named'CommonLibrary.py'"], ["so you just to need import 'CommonLibrary.py'"]], [[' import _ALibrary\nimport _BLibrary\nclass CommonLibrary(_BLibrary._BLibrary,_ALibrary._ALibrary):\ndef __init__(self):\n    for base in CommonLibrary.__bases__:\n        base.__init__(self)\n']], ['Can I use one import and expose keywords from multiple python libraries?'], 4, 0], [(20634691, 1), [['Which indicates that  http  intentionally behaves differently whenever the output is redirected. To obtain the same behavior as for not redirected output you can use'], ['(But also note that pretty-printing behaves differently with redirection.)']], [[' `http --print hb google.com > out.txt`\n']], ['How to print different results to a screen and to a file in python?'], 2, 1], [(20661902, 0), [["If you put your lists in a container then it's actually quite simple:"], ['This create the file  out.csv  which will contain the input lists column wise:']], [[" import csv\n\ncontainer = [[['CD', 'CC', 'CD'], 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n             [['DT', 'CC', 'CD'], 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1],\n             [['EX', 'CC', 'CD'], 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n             [['JJ', 'CC', 'CD'], 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1]]\n\nwith open('out.csv', 'w') as csvfile:\n    csvw = csv.writer(csvfile, delimiter=',')\n    for column in zip(*[s for s in container]):\n        csvw.writerow(column)\n"]], ['Write nested lists column wise to CSV'], 2, 1], [(20661902, 1), [['This create the file  out.csv  which will contain the input lists column wise:'], ['-10000']], [[' "[\'CD\', \'CC\', \'CD\']","[\'DT\', \'CC\', \'CD\']","[\'EX\', \'CC\', \'CD\']","[\'JJ\', \'CC\', \'CD\']"\n1,0,0,0\n1,0,0,0\n1,1,0,1\n1,0,0,0\n1,1,0,1\n1,0,0,0\n1,1,0,1\n1,1,0,1\n1,1,0,0\n1,1,0,1\n1,1,0,1\n1,1,0,1\n']], ['Write nested lists column wise to CSV'], 2, 0], [(20663162, 1), [['then in function  detail , access it this way:'], ['See more details  here  about jobs topic.']], [[" item = response.meta['item']\n"]], ['Scrapy: Passing item between methods'], 2, 0], [(20670334, 0), [['Not everything is done best with a single list comprehension.  While you could do'], ['I really think that']], [[" nouns = [x for key, value in pos_dictionary.iteritems() if key.startswith('NN') for x in value]\n"]], ['how to write a conditional list comprehension, with "extend" functionality'], 2, 1], [(20672238, 0), [['First, flip the dictionary around into a reverse multidict, mapping each value to all of the keys it maps to. Like this:'], ["Now, you're just looking for the keys in the multidict that have more than 1 value. That's easy:"]], [[' >>> some_dict = {"firstname":"Albert","nickname":"Albert","surname":"Likins","username":"Angel"}\n>>> rev_multidict = {}\n>>> for key, value in some_dict.items():\n...     rev_multidict.setdefault(value, set()).add(key)\n']], ['Find dictionary keys with duplicate values'], 4, 0], [(20672238, 1), [["Now, you're just looking for the keys in the multidict that have more than 1 value. That's easy:"], ['Except the multidict keys are the original dict values. So, this is each repeated value, not all of the keys matching each repeated value. But you know what  is  all of the keys matching each repeated value?']], [[" >>> [key for key, values in rev_multidict.items() if len(values) > 1]\n['Albert']\n"]], ['Find dictionary keys with duplicate values'], 4, 0], [(20672238, 2), [['Except the multidict keys are the original dict values. So, this is each repeated value, not all of the keys matching each repeated value. But you know what  is  all of the keys matching each repeated value?'], ["Of course that gives you a list of sets. If you want to flatten that into a single list or set, that's easy. You can use  chain.from_iterable , or a nested comprehension, or any of the other usual tricks. For example:"]], [[" >>> [values for key, values in rev_multidict.items() if len(values) > 1]\n[{'firstname', 'nickname'}]\n"]], ['Find dictionary keys with duplicate values'], 4, 0], [(20672238, 3), [["Of course that gives you a list of sets. If you want to flatten that into a single list or set, that's easy. You can use  chain.from_iterable , or a nested comprehension, or any of the other usual tricks. For example:"], ['-10000']], [[" >>> set(chain.from_iterable(values for key, values in rev_multidict.items() if len(values) > 1))\n{'firstname', 'nickname'}\n"]], ['Find dictionary keys with duplicate values'], 4, 0], [(20695432, 0), [["The most intuitive solution I've got is this. Essentially, you need to treat the  Dr.  and  Mr.  tokens as atoms in their own right."], ['When used on this sample.txt (I added a line):']], [[" patt = r'(?:Dr\\.|Mr\\.|.)*?[.!?]\\s?\\n?'\n"]], ['Python: Extracting Sentences From Line - Regex Needed Based on Criteria'], 3, 1], [(20695432, 1), [['When used on this sample.txt (I added a line):'], ['It gives:']], [[' {Hello there|Hello|Howdy} Dr. Munchauson you {gentleman|fine fellow}! What {will|shall|should} we {eat|have} for lunch? Peas by the {thousand|hundred|1000} said Dr. Munchauson; {that|is} what he said.\n\nBut there are no {misters|doctors} here good sir! Help us if there is an emergency.\n\nI am the {very last|last} sentence for this {instance|example}.\n']], ['Python: Extracting Sentences From Line - Regex Needed Based on Criteria'], 3, 0], [(20695432, 2), [['It gives:'], ['-10000']], [[' {Hello there|Hello|Howdy} Dr. Munchauson you {gentleman|fine fellow}!\nWhat {will|shall|should} we {eat|have} for lunch?\nPeas by the {thousand|hundred|1000} said Dr. Munchauson; {that|is} what he said.\n\nnewline\nBut there are no {misters|doctors} here good sir!\nHelp us if there is an emergency.\n\nnewline\nI am the {very last|last} sentence for this {instance|example}.\n']], ['Python: Extracting Sentences From Line - Regex Needed Based on Criteria'], 3, 0], [(20720521, 0), [['Assuming that you are interpreting the heaviest path as being a path that always begins with the root of the tree and descends down to a single leaf. You could try merging the weight-finding and path-building operations:'], ["Or using a time-honoured technique to speed up this kind of calculation through  Memoization . Once you've used memoization once, you could just keep the pathweight values up to date as you alter your tree."]], [[' def heavy_path(node):\n  if not node\n    return (0,[])\n  [lweight,llist] = heavy_path(node.left)\n  [rweight,rlist] = heavy_path(node.right)\n  if lweight>rweight:\n    return (node.val+lweight,[node.val]+llist)\n  else:\n    return (node.val+rweight,[node.val]+rlist)\n']], ['Finding the heaviest path in a binary tree efficiently - python'], 2, 1], [(20720521, 1), [["Or using a time-honoured technique to speed up this kind of calculation through  Memoization . Once you've used memoization once, you could just keep the pathweight values up to date as you alter your tree."], ['-10000']], [[' def weight(node):\n  if node == None:\n      return 0\n  node.pathweight=node.val+max(weight(node.left),weight(node.right))\n  return node.pathweight\n\ndef heavy_edge(node):\n  if not node.left:\n    lweight=0\n  else:\n    lweight=node.left.pathweight\n  if not node.right:\n    rweight=0\n  else:\n    rweight=node.right.pathweight\n  if lweight>rweight:\n    return [node.val,heavy_edge(node.left)]\n  else:\n    return [node.val,heavy_edge(node.right)]\n\nweight(t) #Precalculate the pathweight of all the nodes in O(n) time\nheavy_edge(T) #Use the precalculated pathweights to efficient find list the heaviest path in O(lg n) time\n']], ['Finding the heaviest path in a binary tree efficiently - python'], 2, 1], [(20725343, 0), [['You could change your handler to read from a file given at the command line instead of  stdin :'], ['Then you could create a named pipe in  main.py , to send the data:']], [[' #!/usr/bin/env python\nimport shutil\nimport sys\nimport time\n\nprint "In handler..."\nwith open(sys.argv[1], \'rb\') as file:\n    shutil.copyfileobj(file, sys.stdout)\nsys.stdout.flush()\ntime.sleep(5)\n']], ['Communication between two gnome-terminal sessions'], 2, 0], [(20725343, 1), [['Then you could create a named pipe in  main.py , to send the data:'], ['-10000']], [[' #!/usr/bin/env python\nimport os\nfrom subprocess import Popen\n\nfifo = "fifo"\nos.mkfifo(fifo)\np = Popen(["gnome-terminal", "-x", "python", "handler.py", fifo])\nwith open(fifo, \'wb\') as file:\n    file.write("Text sent to handler for display")\nos.remove(fifo)\np.wait()\n']], ['Communication between two gnome-terminal sessions'], 2, 0], [(20778951, 0), [['How about using  re.split ?'], ['-10000']], [[" 'London, ENG, United Kingdom or Melbourne, VIC, Australia or Palo Alto, CA USA'\n>>> list(map(str.strip, re.split(',|or', x)))\n['London', 'ENG', 'United Kingdom', 'Melbourne', 'VIC', 'Australia', 'Palo Alto', 'CA USA']\n>>> list(map(str.strip, re.split('or', x)))\n['London, ENG, United Kingdom', 'Melbourne, VIC, Australia', 'Palo Alto, CA USA']\n"]], ['Regex for location matching - Python'], 3, 1], [(20778951, 1), [['-10000'], ['-10000']], [[" >>> list(map(str.strip, x.split('or')))\n['London, ENG, United Kingdom', 'Melbourne, VIC, Australia', 'Palo Alto, CA USA']\n"]], ['Regex for location matching - Python'], 3, 1], [(20778951, 2), [['-10000'], ['-10000']], [[" >>> x = 'London, ENG, United Kingdom / Melbourne, VIC, Australia / Palo Alto, CA USA'\n>>> re.findall(r'(?:\\w+(?:\\s+\\w+)*,\\s)+(?:\\w+(?:\\s\\w+)*)', x)\n['London, ENG, United Kingdom', 'Melbourne, VIC, Australia', 'Palo Alto, CA USA']\n"]], ['Regex for location matching - Python'], 3, 1], [(20789412, 0), [['How about this:'], ['Result:']], [[" A = [1,2,3,4,5,6,7,8,9,0] \n\nB = [4,5,6,7]\nC = [7,8,9,0]\nD = [4,6,7,5]\n\ndef is_slice_in_list(s,l):\n    len_s = len(s) #so we don't recompute length of s on every iteration\n    return any(s == l[i:len_s+i] for i in xrange(len(l) - len_s+1))\n"]], ['Check if all elements of one array is in another array'], 2, 1], [(20789412, 1), [['Result:'], ['-10000']], [[' >>> is_slice_in_list(B,A)\nTrue\n>>> is_slice_in_list(C,A)\nTrue\n>>> is_slice_in_list(D,A)\nFalse\n']], ['Check if all elements of one array is in another array'], 2, 0], [(20821815, 0), [['Have you tried this?'], ['You may call it as:']], [[" import os\ndef addToClipBoard(text):\n    command = 'echo ' + text.strip() + '| clip'\n    os.system(command)\n"]], ['Copying the contents of a variable to the clipboard'], 2, 1], [(20821815, 1), [['You may call it as:'], ['-10000']], [[' addToClipBoard(your_variable)\n']], ['Copying the contents of a variable to the clipboard'], 2, 0], [(20825173, 0), [['Using the notation given in  http://pomax.github.io/bezierinfo/#extremities , a quadratic Bezier curve is given by:'], ['Therefore, (by taking the  derivative  of  B  with respect to  t ) the tangent to the curve is given by']], [[' B(t) = P1*(1-t)**2 + 2*P2*(1-t)*t + P3*t**2\n']], ['How to find a point (if any) on quadratic Bezier with a given tangent direction?'], 7, 0], [(20825173, 1), [['Therefore, (by taking the  derivative  of  B  with respect to  t ) the tangent to the curve is given by'], ['Given some tangent direction  V , solve ']], [[" B'(t) = -2*P1*(1-t) + 2*P2*(1-2*t) + 2*P3*t\n      = 2*(P1 - 2*P2 + P3)*t + 2*(-P1 + P2)\n"]], ['How to find a point (if any) on quadratic Bezier with a given tangent direction?'], 7, 0], [(20825173, 2), [['Given some tangent direction  V , solve '], ['Two vectors,  X  and  Y , are perpendicular if their  dot product  is zero. If  X = (a,b)  and  Y = (c,d)  then the dot product of  X  and  Y  is given by']], [[" B'(t) = V\n"]], ['How to find a point (if any) on quadratic Bezier with a given tangent direction?'], 7, 0], [(20825173, 3), [['Two vectors,  X  and  Y , are perpendicular if their  dot product  is zero. If  X = (a,b)  and  Y = (c,d)  then the dot product of  X  and  Y  is given by'], ['In 2-dimensions, if in coordinates  Y = (a,b)  then  Y_perp = (-b, a) . (There are two perpendicular vectors possible, but this one will do.) Notice that -- using the formula above -- the dot product of  Y  and  Y_perp  is']], [[' a*c + b*d\n']], ['How to find a point (if any) on quadratic Bezier with a given tangent direction?'], 7, 0], [(20825173, 4), [['In 2-dimensions, if in coordinates  Y = (a,b)  then  Y_perp = (-b, a) . (There are two perpendicular vectors possible, but this one will do.) Notice that -- using the formula above -- the dot product of  Y  and  Y_perp  is'], ['Now, to solve our problem: Let']], [[' a*(-b) + b*(a) = 0\n']], ['How to find a point (if any) on quadratic Bezier with a given tangent direction?'], 7, 0], [(20825173, 5), [['Now, to solve our problem: Let'], ["Then  B'(t)  is parallel (or anti-parallel) to  V  if or when\n B'(t)  is perpendicular to  V_perp , which occurs when"]], [[" B'(t) = (a*t+b, c*t+d)\nV = (e, f)\n"]], ['How to find a point (if any) on quadratic Bezier with a given tangent direction?'], 7, 0], [(20825173, 6), [["Then  B'(t)  is parallel (or anti-parallel) to  V  if or when\n B'(t)  is perpendicular to  V_perp , which occurs when"], ['We know  a ,  b ,  c ,  d ,  e  and  f . Solve for  t . If  t  lies between 0 and 1, then  B(t)  is part of the Bezier curve segment between  P1  and  P3 .']], [[' dot product((a*t+b, c*t+d), (-f, e)) = 0\n-(a*t+b)*f + (c*t+d)*e = 0\n']], ['How to find a point (if any) on quadratic Bezier with a given tangent direction?'], 7, 0], [(20846235, 0), [['here is a simple framework I just wrote for you :)'], ['to use it you must first create a schema to validate against']], [[' class SizedInput(object):\n    def __init__(self,label="input",map_fn=str):\n        self.map_fn = map_fn\n        self.label = label\n        self._rval = None\n    def _proc(self,sz,tokens):\n        if len(tokens) < sz:\n            msg = "Insufficient arguments for %s (expected %s got %s)"\n            raise Exception(msg%(self.label,sz,len(tokens) )    )\n\n        return (self.map_fn(x) for x in tokens[:sz]), tokens[sz:]\n    def parse(self,input_tokens):\n        sz = int(input_tokens[0])\n        self._rval,rest = self._proc(sz,input_tokens[1:])\n        return list(self._rval),rest\n    def GetValue():\n        return self._rval\n    def __call__(self,input_tokens):\n        return self.parse(input_tokens)\n\nclass MatrixInput(SizedInput):\n    def _proc(self,sz,tokens):\n        result, rest = SizedInput._proc(self,sz**2,tokens) #call super function with new size\n        result = zip(*[iter(result)]*sz)  #this looks fancy but it just resizes 1d to 2d\n            return result,rest          \n\ndef validateSchema(schema,input_tokens):\n    rest = input_tokens\n    results = {}\n    for schema_item in schema:\n        results[schema_item.label] ,rest = schema_item(rest)\n    if rest:\n        print "Warning : %d unconsumed tokens!"\n    return results\n']], ['Programming contest like input validator'], 4, 0], [(20846235, 1), [['to use it you must first create a schema to validate against'], ['then you need to tokenize your input data']], [[' schema = [ #define a schema\n    SizedInput("ages",int),\n    SizedInput("names",str),\n    MatrixInput("matrix",int),\n]\n']], ['Programming contest like input validator'], 4, 0], [(20846235, 2), [['then you need to tokenize your input data'], ['then you just need to pass it into your validator (first block of code), it will raise an exception if there is insufficient tokens, and print a warning if there are leftover tokens (you could easily change it to raise an exception)']], [[' input_stream = """\n2 \n8 9\n3\nasd dsa fff\n2\n1 2\n3 4\n"""\ntokens = input_stream.split()\n']], ['Programming contest like input validator'], 4, 0], [(20846235, 3), [['then you just need to pass it into your validator (first block of code), it will raise an exception if there is insufficient tokens, and print a warning if there are leftover tokens (you could easily change it to raise an exception)'], ['-10000']], [[' print validateSchema(schema, tokens)\n']], ['Programming contest like input validator'], 4, 0], [(20857188, 2), [['However this fails with small inputs:'], ['An attempt could be:']], [[" In [68]: format_float(0.0001, 4)\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-68-68e3461a51e5> in <module>()\n----> 1 format_float(0.0001, 4)\n\n<ipython-input-64-d4485ac4e1c9> in format_float(value, ndigits)\n      1 def format_float(value, ndigits=4):\n----> 2     j = min(i-1 for i in range(ndigits+1) if value >= 10 ** (ndigits - i))\n      3     return '{:.0{num_digits}f}'.format(value, num_digits=max(0,j))\n\nValueError: min() arg is an empty sequence\n"]], ['Decimal formatting based on number of digits in integer and decimal parts'], 6, 0], [(20857188, 4), [['which seems to work for the inputs provided in the question:'], ["This does not handle negative numbers, but it's quite easy to check for them and work with the absolute value:"]], [[" In [81]: inputs = [11111.1, 111.11, 11.111, 1.1111, 0.00111, 0.000011]\n\nIn [82]: for inp in inputs:\n    ...:     print('Input = {} -- output = {}'.format(inp, format_float(inp, 4)))\nInput = 11111.1 -- output = 11111\nInput = 111.11 -- output = 111.1\nInput = 11.111 -- output = 11.11\nInput = 1.1111 -- output = 1.111\nInput = 0.00111 -- output = 0.0011\nInput = 1.1e-05 -- output = 0.00001\n"]], ['Decimal formatting based on number of digits in integer and decimal parts'], 6, 0], [(20857188, 5), [["This does not handle negative numbers, but it's quite easy to check for them and work with the absolute value:"], ['-10000']], [[" def format_float(value, ndigits):\n    sign = ''\n    if value < 0:\n        value = abs(value)\n        sign = '-'\n\n    if value >= 1:\n        j = min(i-1 for i in range(ndigits+1) if value >= 10 ** (ndigits - i))\n        return '{}{:.0{num_digits}f}'.format(sign, value, num_digits=max(0,j))\n    s = '{:.17f}'.format(value).rstrip('0')\n    _, dec_part = s.split('.')\n    if not dec_part:\n        # Happens only with 0.0\n        return '0'\n    if len(dec_part) < ndigits or set(dec_part[:ndigits]) != {'0'}:\n        # truncate the decimal representation\n        dec_part = dec_part.ljust(ndigits, '0')[:ndigits]\n    elif len(dec_part) > ndigits:\n        # too small. Just find the first decimal place\n        for i, char in enumerate(dec_part):\n            if char != '0':\n                dec_part = dec_part[:i+1]\n                break\n    return '{}{}.{}'.format(sign, 0, dec_part)\n"]], ['Decimal formatting based on number of digits in integer and decimal parts'], 6, 1], [(20892950, 0), [['ummm'], ['or ']], [[' return pair[0] if pair[0] != core else pair[1]\n']], ['pythonic solution for finding the other element in a list of length two'], 3, 1], [(20892950, 1), [['or '], ['or ']], [[' return set(pair) - [core]\n']], ['pythonic solution for finding the other element in a list of length two'], 3, 1], [(20892950, 2), [['or '], ['theres lots of other ways also']], [[' return  pair[not pair.index(core)]\n']], ['pythonic solution for finding the other element in a list of length two'], 3, 1], [(20959022, 0), [['I am not sure if this is what you are looking for:'], ['For instance:']], [[" >>> cp = '#U79c1'\n>>> chr(int(cp[2:],16))\n'私'\n"]], ['Python: Converting Unicode code point filenames to strings'], 3, 1], [(20959022, 1), [['For instance:'], ['prints']], [[" #! /usr/bin/python3\nimport re\n\ndef makeNice(s):\n    return re.subn('(#U[0-9a-f]{4})', lambda cp: chr(int(cp.groups()[0][2:],16)), s) [0]\n\na = '-#U2605-#U79c1-'\nprint(a, makeNice(a))\n"]], ['Python: Converting Unicode code point filenames to strings'], 3, 1], [(20959022, 2), [['prints'], ['-10000']], [[' -#U2605-#U79c1- -★-私-\n']], ['Python: Converting Unicode code point filenames to strings'], 3, 0], [(20974696, 0), [['I would just use HTTP methods and a single handler:'], ['But if you insist on using a separate handlers:']], [[" class QuestionHandler(RequestHandler):\n    def get(self, id):\n        # Display the question\n\n    def post(self, id):\n        # Validates the answer\n        answer = self.get_argument('answer')\n\napplication = Application([\n    (r'/(\\d+)', QuestionHandler),\n])\n"]], ['making regex capture group optional in url for a tornado app'], 2, 1], [(20974696, 1), [['But if you insist on using a separate handlers:'], ['-10000']], [[" class QuestionHandler(RequestHandler):\n    def get(self, id):\n        # Display the question\n\nclass AnswerHandler(RequestHandler):\n    def post(self, id):\n        # Validates the answer\n        answer = self.get_argument('answer')\n\napplication = Application([\n    (r'/(\\d+)', QuestionHandler),\n    (r'/(\\d+)/answer', AnswerHandler),\n])\n"]], ['making regex capture group optional in url for a tornado app'], 2, 1], [(20975430, 0), [['-10000'], ['-10000']], [["URLs # ... omitted\n    url(r'^profile/edit/$', profileviews.ProfileUpdateView.as_view(),\n# ... omitted\n"]], ['Django UpdateView without pk in the url'], 2, 0], [(20977408, 0), [['You can use a  %  in your string using this syntax, by escaping it with another  % :'], ['']], [[" >>> name = 'John'\n>>> string = 'hello %s! You owe 10%%.' % (name)\n>>> string\n'hello John! You owe 10%.'\n"]], ['Python Using (%s) in a string that slo contains a (%)?'], 2, 1], [(20977408, 1), [[''], ['-10000']], [[" >>> name = 'John'\n>>> string = 'hello {}! You owe 10%'.format(name)\n>>> string\n'Hello John! You owe 10%'\n# Another way, with naming for more readibility\n>>> string = 'hello {name}! You owe 10%.'.format(name=name)\n>>> str\n'hello John! You owe 10%.'\n"]], ['Python Using (%s) in a string that slo contains a (%)?'], 2, 1], [(20990336, 0), [['To emulate:'], ['your current approach with threads works:']], [[' echo foo |\nfirstCommand - | somePythonRoutine - |\nsecondCommand - | anotherPythonRoutine - |\nthirdCommand - > finalOutput\n']], ['How to thread multiple subprocess instances in Python 2.7?'], 3, 0], [(20990336, 1), [['your current approach with threads works:'], ['where each  bind()  starts a new thread:']], [[' from subprocess import Popen, PIPE\n\nfirst = Popen(["firstCommand", "-"], stdin=PIPE, stdout=PIPE, bufsize=1)\nsecond = Popen(["secondCommand", "-"], stdin=PIPE, stdout=PIPE, bufsize=1)\nbind(first.stdout, second.stdin, somePythonRoutine)\nwith open("finalOutput", "wb") as file:\n    third = Popen(["thirdCommand", "-"], stdin=PIPE, stdout=file, bufsize=1)\nbind(second.stdout, third.stdin, anotherPythonRoutine)\n\n# provide input for the pipeline\nfirst.stdin.write(b"foo")\nfirst.stdin.close()\n\n# wait for it to complete\npipestatus = [p.wait() for p in [first, second, third]]\n']], ['How to thread multiple subprocess instances in Python 2.7?'], 3, 0], [(20990336, 2), [['where each  bind()  starts a new thread:'], ['and  somePythonRoutine ,  anotherPythonRoutine  accept a single line and return it (possibly modified).']], [[" from threading import Thread\n\ndef bind(input_pipe, output_pipe, line_filter):\n    def f():\n        try:\n            for line in iter(input_pipe.readline, b''):\n                line = line_filter(line)\n                if line:\n                    output_pipe.write(line) # no flush unless newline present\n        finally:\n            try:\n                output_pipe.close()\n            finally:\n                input_pipe.close()\n    t = Thread(target=f)\n    t.daemon = True # die if the program exits\n    t.start()\n"]], ['How to thread multiple subprocess instances in Python 2.7?'], 3, 0], [(21015447, 0), [['It is giving the full ethernet packet which internally contains Ip, and TCP packet.'], ['you can access the source mac address from Ethernet packet as']], [[" In [87]: data\nOut[87]: Ethernet(src='\\x00\\x1a\\xa0kUf', dst='\\x00\\x13I\\xae\\x84,', data=IP(src='\\xc0\\xa8\\n\\n', off=16384, dst='C\\x17\\x030', sum=25129, len=52, p=6, id=51105, data=TCP(seq=9632694, off_x2=128, ack=3382015884L, win=54, sum=65372, flags=17, dport=80, sport=56145)))\n"]], ['How to parse the header files of the pcap file?'], 6, 0], [(21015447, 1), [['you can access the source mac address from Ethernet packet as'], ['Access the Ethernet packet data(which is IP pkt internally contains TCP pkt) as']], [[" In [88]: data.src\nOut[88]: '\\x00\\x1a\\xa0kUf'\n"]], ['How to parse the header files of the pcap file?'], 6, 0], [(21015447, 2), [['Access the Ethernet packet data(which is IP pkt internally contains TCP pkt) as'], ['Access the source Ip as']], [[" In [89]: data.data\nOut[89]: IP(src='\\xc0\\xa8\\n\\n', off=16384, dst='C\\x17\\x030', sum=25129, len=52, p=6, id=51105, data=TCP(seq=9632694, off_x2=128, ack=3382015884L, win=54, sum=65372, flags=17, dport=80, sport=56145))\n"]], ['How to parse the header files of the pcap file?'], 6, 0], [(21015447, 3), [['Access the source Ip as'], ['Access the TCP data as']], [[" In [90]: data.data.src\nOut[90]: '\\xc0\\xa8\\n\\n'\n"]], ['How to parse the header files of the pcap file?'], 6, 0], [(21015447, 4), [['Access the TCP data as'], ['The code used is']], [[' In [91]: data.data.data\nOut[91]: TCP(seq=9632694, off_x2=128, ack=3382015884L, win=54, sum=65372, flags=17, dport=80, sport=56145)\n']], ['How to parse the header files of the pcap file?'], 6, 0], [(21039772, 0), [['Random access via a constructed index is supported in 0.13'], ['To include an additional condition you would do like this:']], [[" In [26]: df = DataFrame(np.random.randn(100,2),columns=['A','B'])\n\nIn [27]: df.to_hdf('test.h5','df',mode='w',format='table')\n\nIn [28]: store = pd.HDFStore('test.h5')\n\nIn [29]: nrows = store.get_storer('df').nrows\n\nIn [30]: nrows\nOut[30]: 100\n\nIn [32]: r = np.random.randint(0,nrows,size=10)\n\nIn [33]: r\nOut[33]: array([69, 28,  8,  2, 14, 51, 92, 25, 82, 64])\n\nIn [34]: pd.read_hdf('test.h5','df',where=pd.Index(r))\nOut[34]: \n           A         B\n69 -0.370739 -0.325433\n28  0.155775  0.961421\n8   0.101041 -0.047499\n2   0.204417  0.470805\n14  0.599348  1.174012\n51  0.634044 -0.769770\n92  0.240077 -0.154110\n25  0.367211 -1.027087\n82 -0.698825 -0.084713\n64 -1.029897 -0.796999\n\n[10 rows x 2 columns]\n"]], ['PyTables read random subset'], 2, 1], [(21039772, 1), [['To include an additional condition you would do like this:'], ['-10000']], [[" # make sure that we have indexable columns\ndf.to_hdf('test.h5','df',mode='w',format='table',data_columns=True)\n\n# select where the index (an integer index) matches r and A > 0\nIn [14]: r\nOut[14]: array([33, 51, 33, 95, 69, 21, 43, 58, 58, 58])\n\nIn [13]: pd.read_hdf('test.h5','df',where='index=r & A>0')\nOut[13]: \n           A         B\n21  1.456244  0.173443\n43  0.174464 -0.444029\n\n[2 rows x 2 columns]\n"]], ['PyTables read random subset'], 2, 0], [(21053458, 0), [['You could actually implement an FSM:'], ['Or, the data-driven version:']], [[' s = \'\'\'that\'s my     string, "   keep these spaces     "    but reduce these \'\'\'\n\n\nnormal, quoted, eating = 0,1,2\nstate = eating\nresult = \'\'\nfor ch in s:\n  if (state, ch) == (eating, \' \'):\n    continue\n  elif (state,ch) == (eating, \'"\'):\n    result += ch\n    state = quoted\n  elif state == eating:\n    result += ch\n    state = normal\n  elif (state, ch) == (quoted, \'"\'):\n    result += ch\n    state = normal\n  elif state == quoted:\n    result += ch\n  elif (state,ch) == (normal, \'"\'):\n    result += ch\n    state = quoted\n  elif (state,ch) == (normal, \' \'):\n    result += ch\n    state = eating\n  else: # state == normal\n    result += ch\n\nprint result\n']], ['Python loop through string in nested for loops'], 2, 1], [(21053458, 1), [['Or, the data-driven version:'], ['-10000']], [[' actions = {\n    \'normal\' : {\n        \' \' : lambda x: (\'eating\', \' \'),\n        \'"\' : lambda x: (\'quoted\', \'"\'),\n        None: lambda x: (\'normal\', x)\n    },\n    \'eating\' : {\n        \' \' : lambda x: (\'eating\', \'\'),\n        \'"\' : lambda x: (\'quoted\', \'"\'),\n        None: lambda x: (\'normal\', x)\n    },\n    \'quoted\' : {\n        \'"\' : lambda x: (\'normal\', \'"\'),\n        \'\\\\\': lambda x: (\'escaped\', \'\\\\\'),\n        None: lambda x: (\'quoted\', x)\n    },\n    \'escaped\' : {\n        None: lambda x: (\'quoted\', x)\n    }\n}\n\ndef reduce(s):\n    result = \'\'\n    state = \'eating\'\n    for ch in s:\n        state, ch = actions[state].get(ch, actions[state][None])(ch)\n        result += ch\n    return result\n\ns = \'\'\'that\'s my     string, "   keep these spaces     "    but reduce these \'\'\'\nprint reduce(s)\n']], ['Python loop through string in nested for loops'], 2, 1], [(21073086, 1), [["I would also add the compliment to the DTR for the Arduino's with AVR's using built-in USB, such as the Leonoardo, Esplora and alike. The setup() should have the following while, to wait for the USB to be opened by the Host."], ["It will have no effect for FTDI's based UNO's and such."]], [[' void setup() {\n  //Initialize serial and wait for port to open:\n  Serial.begin(9600);\n  while (!Serial) {\n    ; // wait for serial port to connect. Needed for Leonardo only\n  }\n}\n']], ['Wait on Arduino auto-reset using pySerial'], 2, 0], [(21080357, 0), [['To get colocated groups of points, you should choose expected locations:'], ['Then generate points according to them:']], [[' coordstest = np.vstack([np.random.uniform(150, 220, 20), \n                        np.random.uniform(150, 220, 20)]).T\n']], ['Localized random points using numpy and pandas'], 4, 0], [(21080357, 1), [['Then generate points according to them:'], ['And plot']], [[' coords = np.vstack([np.random.multivariate_normal(coordstest[i,:], covs, 200) \n                         for i in range(10)])\n']], ['Localized random points using numpy and pandas'], 4, 0], [(21080357, 2), [['And plot'], ["Note that point are generated with linear dependency due to nontrivial covariance paramether for multivariate_normal. If you don't need it, you can for example do"]], [[" individuals = (np.arange(0,200).reshape(-1,1)*np.ones(10).reshape(1,-1)).flatten()\nindividuals = pd.Series(individuals)\n\nallCoords = pd.DataFrame(coords, columns = ['x','y'])\n\nplt.scatter(allCoords['x'], allCoords['y'], c = individuals, \n      s = 40, cmap = 'hot')\n"]], ['Localized random points using numpy and pandas'], 4, 0], [(21080357, 3), [["Note that point are generated with linear dependency due to nontrivial covariance paramether for multivariate_normal. If you don't need it, you can for example do"], ['resulting in ']], [[' coords = np.vstack([np.random.multivariate_normal(coordstest[i,:], \n               [[10,0],[0,10]], 200) for i in range(10)])\n']], ['Localized random points using numpy and pandas'], 4, 0], [(21091802, 1), [['This produces:'], ['-10000']], [[' Content-Type: multipart/form-data; boundary=6f9d948e26f140a289a9e8297c332a91\n\n--0ca5f18576514b069c33bc436ce6e2cd\nContent-Disposition: form-data; name="up"; filename="aa.png"\nContent-Type: image/png\n\n[ .. image data .. ]\n\n--0ca5f18576514b069c33bc436ce6e2cd\nContent-Disposition: form-data; name="exp"\n\npython\n--0ca5f18576514b069c33bc436ce6e2cd\nContent-Disposition: form-data; name="ptext"\n\ntext\n--0ca5f18576514b069c33bc436ce6e2cd\nContent-Disposition: form-data; name="board"\n\nPictures\n--0ca5f18576514b069c33bc436ce6e2cd--\n']], ['How to arrange the order of data and file using requests to post multipart/form-data?'], 2, 0], [(21097039, 0), [['One way to compute the average of a sliding window across a list in Python is to use a list comprehension. You can use'], ["to get the starting indices of each window, and then  numpy 's  mean  function to take the average of each window. See the demo below:"]], [[' >>> range(0, len(data), 2)\n[0, 2, 4, 6, 8]\n']], ['Average on overlapping windows in Python'], 4, 0], [(21106965, 0), [['Parameter in requests'], ['Few endpoints']], [[" class TodoSimple(Resource):\n    def get(self, todo_id):\n        return {todo_id: todos[todo_id]}\n\n    def put(self, todo_id):\n        todos[todo_id] = request.form['data']\n        return {todo_id: todos[todo_id]}\n\napi.add_resource(TodoSimple, '/<string:todo_id>')\n"]], ['How to add parameters to flask-restful in python?'], 2, 1], [(21111836, 0), [['First, groupby code and colour and then apply a customized function to format id and amount:'], ['And then modify the index:']], [[" df = df.groupby(['code', 'colour']).apply(lambda x:x.set_index('id').to_dict('dict')['amount'])\n"]], ['Pandas: transforming the DataFrameGroupBy object to desired format'], 5, 0], [(21111836, 1), [['And then modify the index:'], ['It will return a series, you can convert it back to DataFrame by:']], [[" df.index = ['/'.join(i) for i in df.index]\n"]], ['Pandas: transforming the DataFrameGroupBy object to desired format'], 5, 0], [(21111836, 2), [['It will return a series, you can convert it back to DataFrame by:'], ['Finally, add the column names by:']], [[' df = df.reset_index()\n']], ['Pandas: transforming the DataFrameGroupBy object to desired format'], 5, 0], [(21111836, 3), [['Finally, add the column names by:'], ['Result:']], [[" df.columns=['code/colour','id:amount']\n"]], ['Pandas: transforming the DataFrameGroupBy object to desired format'], 5, 0], [(21111836, 4), [['Result:'], ['-10000']], [[' In [105]: df\nOut[105]: \n   code/colour                               id:amount\n0    one/black                     {1: 0.392264412544}\n1    one/white  {2: 2.13950686015, 7: -0.393002947047}\n2  three/black                      {6: -2.0766612539}\n3  three/white                     {4: -1.18058561325}\n4    two/black                     {5: -1.51959565941}\n5    two/white  {8: -1.7659863039, 3: -0.595666853895}\n']], ['Pandas: transforming the DataFrameGroupBy object to desired format'], 5, 0], [(21125897, 0), [['I think this code might do what you want.'], ['my_data.csv']], [[" import csv\n\nwith open('my_data.csv') as data_file,\\\n     open('values.csv') as value_file, \\\n     open('my_new_data.csv', 'wb') as out_file:\n\n    data_reader = csv.reader(data_file, delimiter=' ', skipinitialspace=True)\n    value_reader = csv.reader(value_file, delimiter=',')\n    writer = csv.writer(out_file, delimiter=' ')\n    while True:\n        try:\n            row = next(data_reader)\n            row[1:4] = next(value_reader)\n            writer.writerows([row, next(data_reader), next(data_reader)])\n        except StopIteration:\n            break\n"]], ['change multiple lines in file python using regex'], 4, 1], [(21125897, 1), [['my_data.csv'], ['values.csv']], [['  1    253.31     78.20     490.0         0 0 1 0 0\n   101         0         0         0         0         0         0          \n     1         2         3         4         5         6\n     2    123.31   -122.20     -20.0         0 0 1 0 0\n   101         0         0         0         0         0         0          \n     7         8         9        10        11        12\n     3     53.21      10.2      90.0         0 0 1 0 0\n   101         0         0         0         0         0         0          \n    13        14        15        11        10        10\n']], ['change multiple lines in file python using regex'], 4, 0], [(21125897, 2), [['values.csv'], ['Output']], [[' 1.0,2.5,3.2\n4.1,5.2,6.2\n7.6,8.0,9.3\n']], ['change multiple lines in file python using regex'], 4, 0], [(21125897, 3), [['Output'], ['Note that the leading and trailing spaces are gone.']], [[' 1 1.0 2.5 3.2 0 0 1 0 0\n101 0 0 0 0 0 0 \n1 2 3 4 5 6\n2 4.1 5.2 6.2 0 0 1 0 0\n101 0 0 0 0 0 0 \n7 8 9 10 11 12\n3 7.6 8.0 9.3 0 0 1 0 0\n101 0 0 0 0 0 0 \n13 14 15 11 10 10\n']], ['change multiple lines in file python using regex'], 4, 0], [(21126108, 0), [['Inspired from a  solution described for concurrency checks , I came up with the following snippet of code. It works if one is able to appropriately predict the frequency at which the file in question is written. The solution is through the use of file-modification times.'], ['Upon further testing, I encountered a high-frequency write process that required the conditional logic to be modified from ']], [[' import os\nimport time\n\n\'\'\'Find if a file was modified in the last x seconds given by writeFrequency.\'\'\'\ndef isFileBeingWrittenInto(filename, \n                       writeFrequency = 180, overheadTimePercentage = 20):\n\n    overhead = 1+float(overheadTimePercentage)/100 # Add some buffer time\n    maxWriteFrequency = writeFrequency * overhead\n    modifiedTimeStart = os.stat(filename).st_mtime # Time file last modified\n    time.sleep(writeFrequency)                     # wait writeFrequency # of secs\n    modifiedTimeEnd = os.stat(filename).st_mtime   # File modification time again\n    if 0 < (modifiedTimeEnd - modifiedTimeStart) <= maxWriteFrequency:\n        return True\n    else:\n        return False\n\nif not isFileBeingWrittenInto(\'fileForSafeWrites.txt\'):\n    handle = open(\'fileForSafeWrites.txt\', \'a\')\n    handle.write("Text written safely when no one else is writing to the file")\n    handle.close()\n']], ['Ensuring that my program is not doing a concurrent file write'], 3, 1], [(21126108, 1), [['Upon further testing, I encountered a high-frequency write process that required the conditional logic to be modified from '], ['to ']], [[' if 0 < (modifiedTimeEnd - modifiedTimeStart) < maxWriteFrequency \n']], ['Ensuring that my program is not doing a concurrent file write'], 3, 0], [(21126108, 2), [['to '], ['That makes a better answer, in theory and in practice.']], [[' if 0 < (modifiedTimeEnd - modifiedTimeStart) <= maxWriteFrequency \n']], ['Ensuring that my program is not doing a concurrent file write'], 3, 0], [(21159782, 0), [['I would approach this as follows:'], ['Note, however, that the output is ']], [[' from collections import defaultdict # using defaultdict makes the sums easier\n\ncorrelations = defaultdict(int) # default to int (i.e. 0)\n\nfor i1, i2, correl in strScoresDict: # loop through data\n    correlations[i1] += correl # add score for first item\n    correlations[i2] += correl # and second item\n\noutput = sorted(correlations, \n                key=lambda x: correlations[x], \n                reverse=True) # sort keys by value\n']], ['Sorting a list based on associated scores'], 3, 1], [(21159782, 1), [['Note, however, that the output is '], ['As the total correlations are']], [[" output == ['item2', 'item1', 'item4', 'item3']\n"]], ['Sorting a list based on associated scores'], 3, 0], [(21159782, 2), [['As the total correlations are'], ['You can  read about  defaultdict  here .']], [[" {'item1': 220, 'item3': 100, 'item2': 240, 'item4': 200}\n"]], ['Sorting a list based on associated scores'], 3, 0], [(21162819, 0), [['This should be only fractionally slower than just copying the XML file.'], ['output']], [[' use strict;\nuse warnings;\n\nuse IO::Handle;\n\nSTDOUT->autoflush;\n\nopen my $in_xml,    \'<\', \'input.xml\'  or die "Failed to open XML file: $!";\nopen my $in_titles, \'<\', \'titles.txt\' or die "Failed to open titles file: $!";\nopen my $out_xml,   \'>\', \'output.xml\' or die "Failed to open output file: $!";\n\nwhile (my $xml_line = <$in_xml>) {\n\n  if ( $xml_line =~ /<text/ ) {\n\n    my ($id1) = $xml_line =~ /id="(\\d+)"/;\n    unless (defined $id1) {\n      chomp;\n      die sprintf qq{Error in input XML file at line %d: %s\\n-}, $in_xml->input_line_number, $_;\n    }\n    printf "Processing ID %d\\n", $id1 unless $id1 % 500;\n\n    my $title_line = <$in_titles>;\n    my ($id2, $title) = $title_line =~ /^(\\d+)\\s+(.+)/;\n    unless (defined $id2) {\n      chomp $title_line;\n      die sprintf qq{Error in input titles file at line %d: %s\\n-}, $in_titles->input_line_number, $title_line;\n    }\n\n    unless ($id1 == $id2) {\n      die sprintf "ID mismatch %d <=> %d\\nXML file line %d\\ntitles file line %d\\n-",\n          $id1, $id2, $in_xml->input_line_number, $in_titles->input_line_number\n    }\n\n    $xml_line =~ s/>/ title="$title">/;\n  }\n\n  print $out_xml $xml_line;\n}\n\nclose $out_xml or die "Failed to close output file: $!";\n']], ['huge text file (6Gb) search and replace'], 2, 1], [(21162819, 1), [['output'], ['-10000']], [[' <text id="1" title="title1">\nbla bla bla bla.........\n</text>\n<text id="2" title="title2">\nbla bla bla bla.........\n</text>\n<text id="3" title="title3">\nbla bla bla bla.........\n</text>\n']], ['huge text file (6Gb) search and replace'], 2, 0], [(21175455, 0), [['-10000'], ['-10000']], [[' ...\n@register.filter\ndef where_id(users,user_id):\n    return filter(lambda u:u.pk==user_id,users)\n...\n']], ['Django Templates: Is there a way to query a specific object based on its property (instead of iterating over all)?'], 2, 0], [(21175455, 1), [['-10000'], ['-10000']], [[' {%load my_tags %}\n...\n{% for user in users|where_id:10 %}\n....\n']], ['Django Templates: Is there a way to query a specific object based on its property (instead of iterating over all)?'], 2, 0], [(21195366, 0), [['At the start I set up a list of tuples so that I know what each of those strings mean, and then I can just iterate through all of the tuples in the list.'], ['Output:']], [[" values = [('tens', 10), ('fives', 5), ('ones', 1), ('tenths', 0.1)]\n\n\ndef get_digits(num):\n    num = int(num * 10)\n    num = float(num) / 10\n\n    output_dict = {}\n    for place, value in values:\n        output_dict[place] = num // value\n        num = num % value\n    return(output_dict)\n\nget_digits(123.456)\n"]], ['python breaking numbers in to 10s 5s 1s and .1s'], 2, 1], [(21195366, 1), [['Output:'], ["Here's a cool visualizer that might help you understand how the dict here is being generated if you paste in the above code:  http://pythontutor.com/visualize.html"]], [[" {'fives': 0.0, 'tens': 12.0, 'tenths': 4.0, 'ones': 3.0}\n"]], ['python breaking numbers in to 10s 5s 1s and .1s'], 2, 0], [(21208724, 0), [['You could try:'], ['A second way is return the link that contains "RNAfold/"']], [[' tell application "Safari"\n    set thelink to do JavaScript "document.links[4].href " in document 1\nend tell\n']], ['Extract text from webpage using either Python or Applescript'], 5, 0], [(21208724, 1), [['A second way is return the link that contains "RNAfold/"'], ['-10000']], [[' tell application "Safari" to set thelinkCount to do JavaScript "document.links.length " in document 1\nset theUrl to ""\nrepeat with i from 1 to thelinkCount\n    tell application "Safari" to set this_link to (do JavaScript "document.links[" & i & "].href" in document 1) as string\n    if this_link contains "RNAfold/" then\n        set theUrl to this_link\n        exit repeat\n    end if\nend repeat\n\nlog theUrl\n']], ['Extract text from webpage using either Python or Applescript'], 5, 0], [(21208724, 2), [['-10000'], ['-10000']], [[' tell application "Safari"\n    tell document 1 to set theUrl to (do JavaScript "document.getElementsByTagName(\'BODY\')[0].getElementsByTagName(\'b\')[0].getElementsByTagName(\'a\').item(0).innerHTML; ")\n end tell\n']], ['Extract text from webpage using either Python or Applescript'], 5, 0], [(21208724, 3), [['-10000'], ['-10000']], [[' do JavaScript "document.getElementsByClassName(\'proceed\')[0].click()" in document 1\n']], ['Extract text from webpage using either Python or Applescript'], 5, 0], [(21208724, 4), [['-10000'], ['-10000']], [[' set theUrl to ""\n\ntell application "Safari"\n\n    tell document 1\n\n        do JavaScript "document.getElementsByClassName(\'proceed\')[0].click()"\n        delay 1\n        set timeoutCounter to 0\n        repeat until (do JavaScript "document.readyState") is "complete"\n            set timeoutCounter to timeoutCounter + 1\n\n            delay 0.5\n            if timeoutCounter is greater than 50 then\n                exit repeat\n            end if\n        end repeat\n        set theUrl to (do JavaScript "document.getElementsByTagName(\'BODY\')[0].getElementsByTagName(\'b\')[0].getElementsByTagName(\'a\').item(0).innerHTML; ")\n\n    end tell\nend tell\nlog theUrl\n']], ['Extract text from webpage using either Python or Applescript'], 5, 1], [(21211756, 0), [['You want the  hasattr()  function  here:'], ['or, if the  gravity  method is defined by a specific parent class, you can test for that too:']], [[" for obj in all_objects:\n    if hasattr(obj, 'gravity'):\n        obj.gravity()\n"]], ['Call the same method in all objects in Python?'], 2, 1], [(21211756, 1), [['or, if the  gravity  method is defined by a specific parent class, you can test for that too:'], ['-10000']], [[' for obj in all_objects:\n    if isinstance(obj, Planet):\n        obj.gravity()\n']], ['Call the same method in all objects in Python?'], 2, 1], [(21212484, 0), [["Here's an example, assuming you read the data into a list from file:"], ['So get the labels back like this:']], [[" import sklearn.cluster\nimport numpy as np\n\ndata = [\n    ['bob', 1, 3, 7],\n    ['joe', 2, 4, 8],\n    ['bill', 1, 6, 4],\n]\n\nlabels = [x[0] for x in data]\na = np.array([x[1:] for x in data])\nclust_centers = 2\n\nmodel = sklearn.cluster.k_means(a, clust_centers)\n"]], ['Python Relating k-means cluster to instance'], 4, 0], [(21212484, 1), [['So get the labels back like this:'], ["And to print the cluster id for 'one':"]], [[' clusters = dict(zip(lables, model[1]))\n']], ['Python Relating k-means cluster to instance'], 4, 0], [(21212484, 2), [["And to print the cluster id for 'one':"], ['Or send it back out to a csv like this:']], [[" print clusters['bob']\n"]], ['Python Relating k-means cluster to instance'], 4, 0], [(21212484, 3), [['Or send it back out to a csv like this:'], ['-10000']], [[" for d in data:\n    print '%s,%d' % (','.join([str(x) for x in d]), clusters[d[0]])\n"]], ['Python Relating k-means cluster to instance'], 4, 0], [(21217108, 0), [['You can do it using  values.tolist() :'], ['output:']], [[" from pandas import DataFrame\n\ndf = DataFrame({'a': [2,4], 'b': [3,2], 'c': [2,6]})\nprint df\n\nlist1 = df.irow(0).values.tolist()\nlist2 = df.irow(1).values.tolist()\n"]], ['python datapanda: getting values from rows into list'], 2, 1], [(21217108, 1), [['output:'], ['If you want it as  int  you can map the list using  map(int, list1)']], [['    a  b  c\n0  2  3  2\n1  4  2  6\n\n[2L, 3L, 2L]\n[4L, 2L, 6L]\n']], ['python datapanda: getting values from rows into list'], 2, 0], [(21219262, 1), [['This is the argument to define a name for any related field, so:'], ['-10000']], [[" class SpecificUserProfile(UserProfile):\n    referrer = models.ForeignKey('self', related_name='referred')\n"]], ['Defining the name of a ManyToOne relationship in Django'], 2, 1], [(21223269, 0), [['So:'], ['What you need to do is capture it as separate  groups :']], [[" r = re.compile(r'#[a-z]+<')\n"]], ['python regular expressions in find and replace'], 3, 0], [(21223269, 1), [['What you need to do is capture it as separate  groups :'], ['And now, you can use references to those groups:']], [[" r = re.compile(r'(#[a-z]+)(<)')\n"]], ['python regular expressions in find and replace'], 3, 0], [(21223269, 2), [['And now, you can use references to those groups:'], ["(In this case, since your group 2 is a static string, you could simplify it slightly—don't put  <  in a group, and just use  r'\\1 <' . But I think it's more readable this way, and certainly more flexible/robust if you later extend what you're doing, and the performance cost is tiny.)"]], [[" r.sub(r'\\1 \\2', s)\n"]], ['python regular expressions in find and replace'], 3, 0], [(21298191, 0), [['Have a function in your module which will determine this. '], ['You do not need a conditional import here (since you are using only one external module), but it is possible to do it:']], [[' import matplotlib\n\ndef setEnv(env):\n    matplotlib.use(env)\n']], ['Conditional import in a module'], 2, 0], [(21298191, 1), [['You do not need a conditional import here (since you are using only one external module), but it is possible to do it:'], ['For more information about importing modules within function see these:']], [[' if condition:\n    import matplotlib as mlib\nelse:\n    import modifiedmatplotlib as mlib\n']], ['Conditional import in a module'], 2, 1], [(21298821, 0), [['contact/contact.html :'], ['core/core.html:']], [[" {% block 'title' %}\n{{ contact.title }}\n{% endblock %}\n\n{% block 'content' %}\n{% endblock %}\n"]], ["Call app template in a different app's template"], 2, 0], [(21310549, 0), [['start with an engine:'], ['quick path to all table /column names, use an inspector:']], [[' from sqlalchemy import create_engine\nengine = create_engine("postgresql://u:p@host/database")\n']], ['List database tables with SQLAlchemy'], 3, 0], [(21310549, 1), [['quick path to all table /column names, use an inspector:'], ['alternatively, use MetaData / Tables:']], [[' from sqlalchemy import inspect\ninspector = inspect(engine)\n\nfor table_name in inspector.get_table_names():\n   for column in inspector.get_columns(table_name):\n       print("Column: %s" % column[\'name\'])\n']], ['List database tables with SQLAlchemy'], 3, 0], [(21310549, 2), [['alternatively, use MetaData / Tables:'], ['docs:  http://docs.sqlalchemy.org/en/rel_0_9/core/reflection.html#reflecting-all-tables-at-once']], [[' from sqlalchemy import MetaData\nm = MetaData()\nm.reflect(engine)\nfor table in m.tables.values():\n    print(table.name)\n    for column in table.c:\n        print(column.name)\n']], ['List database tables with SQLAlchemy'], 3, 0], [(21314143, 0), [['-10000'], ['Output:']], [[' from string import ascii_lowercase\nalphabets = dict(zip(ascii_lowercase, range(1,27)))\n']], ['Iterating over a list while incrementing another variable at the same time'], 5, 1], [(21314143, 2), [['Other ways of doing this:'], ['OR ']], [[' {char:i for char,i in zip(ascii_lowercase, range(1,27))}\n']], ['Iterating over a list while incrementing another variable at the same time'], 5, 1], [(21314143, 3), [['OR '], ['OR']], [[' answer = {}\nfor i,char in enumerate(ascii_lowercase):\n    answer[char] = i+1\n']], ['Iterating over a list while incrementing another variable at the same time'], 5, 1], [(21314143, 4), [['OR'], ['-10000']], [[' dict((char,i) for i,char in enumerate(ascii_lowercase, 1))\n']], ['Iterating over a list while incrementing another variable at the same time'], 5, 1], [(21329988, 0), [["I'd read the text line-by-line and parse it myself.  This way you can handle large input as streams.  There are nicer solutions using multiline regexps but those will always suffer from being not able to handle the input as a stream."], ['In case you want to process not  sys.stdin  you can do it like this:']], [[' #!/usr/bin/env python\n\nimport sys, re\n\n# states for our state machine:\nOUTSIDE = 0\nINSIDE = 1\nINSIDE_AFTER_STATUTE = 2\n\ndef eachCite(stream):\n  state = OUTSIDE\n  for lineNumber, line in enumerate(stream):\n    if state in (INSIDE, INSIDE_AFTER_STATUTE):\n      capture += line\n    if re.match(\'^-CITE-\', line):\n      if state == OUTSIDE:\n        state = INSIDE\n        capture = line\n      elif state in (INSIDE, INSIDE_AFTER_STATUTE):\n        raise Exception("-CITE- in -CITE-??", lineNumber)\n      else:\n        raise NotImplementedError(state)\n    elif re.match(\'^-End-\', line):\n      if state == OUTSIDE:\n        raise Exception("-End- without -CITE-??", lineNumber)\n      elif state == INSIDE:\n        yield False, capture\n        state = OUTSIDE\n      elif state == INSIDE_AFTER_STATUTE:\n        yield True, capture\n        state = OUTSIDE\n      else:\n        raise NotImplementedError(state)\n    elif re.match(\'^-STATUTE-\', line):\n      if state == OUTSIDE:\n        raise Exception("-STATUTE- without -CITE-??", lineNumber)\n      elif state == INSIDE:\n        state = INSIDE_AFTER_STATUTE\n      elif state == INSIDE_AFTER_STATUTE:\n        raise Exception("-STATUTE- after -STATUTE-??", lineNumber)\n      else:\n        raise NotImplementedError(state)\n  if state != OUTSIDE:\n    raise Exception("EOF in -CITE-??")\n\nfor withStatute, cite in eachCite(sys.stdin):\n  if withStatute:\n    print "found cite with statute:"\n    print cite\n']], ['Extracting parts of text between specific delimiters from a large text file with custom delimiters and writing it to another file using Python'], 2, 1], [(21329988, 1), [['In case you want to process not  sys.stdin  you can do it like this:'], ['-10000']], [[' with open(\'myInputFileName\') as myInputFile, \\\n     open(\'myOutputFileName\', \'w\') as myOutputFile:\n  for withStatute, cite in eachCite(myInputFile):\n    if withStatute:\n      myOutputFile.write("found cite with statute:\\n")\n      myOutputFile.write(cite)\n']], ['Extracting parts of text between specific delimiters from a large text file with custom delimiters and writing it to another file using Python'], 2, 0], [(21332785, 0), [['To see this, you can modify your function f like so:'], ["Then Option 2 produces the output here:  (Notice how the integrator, being smart, is jumping the value it probes for 't' by a factor of 10.  This causes it to skip .345 all the way to 3.45.  So, the fact that f is going to return different isn't noticed by the integrator until it gets up to t 4.0)"]], [[' def f(t,ys,a):\n    print "f(%.17f) is returning %f" % (t, a)\n    return a\n']], ['How to use scipy.integrate.ode.set_f_params() to make time dependant parameter changes?'], 3, 0], [(21332785, 1), [["Then Option 2 produces the output here:  (Notice how the integrator, being smart, is jumping the value it probes for 't' by a factor of 10.  This causes it to skip .345 all the way to 3.45.  So, the fact that f is going to return different isn't noticed by the integrator until it gets up to t 4.0)"], ['In contrast, Option 1 produces this:']], [[' f(0.00000000000000000) is returning 1.000000\nf(0.00000000000014901) is returning 1.000000\nf(0.00000000000038602) is returning 1.000000\nf(0.00000000000031065) is returning 1.000000\nf(0.00000000310683694) is returning 1.000000\nf(0.00000003417209978) is returning 1.000000\nf(0.00000034482472820) is returning 1.000000\nf(0.00000345135101245) is returning 1.000000\nf(0.00003451661385491) is returning 1.000000\nf(0.00034516924227954) is returning 1.000000\nf(0.00345169552652583) is returning 1.000000\nf(0.03451695836898876) is returning 1.000000\nf(0.34516958679361798) is returning 1.000000\nf(3.45169587103990994) is returning 1.000000\n1.0 [ 1.] [1]\n2.0 [ 2.] [2]\n3.0 [ 3.] [3]\nf(34.51695871350283085) is returning 4.000000\nf(34.51695871350283085) is returning 4.000000\nf(6.55822215528620234) is returning 4.000000\nf(6.55822215528620234) is returning 4.000000\nf(3.76234849946453931) is returning 4.000000\nf(3.76234849946453931) is returning 4.000000\nf(3.45169587103990994) is returning 4.000000\nf(3.48276113388237274) is returning 4.000000\nf(3.51382639672483554) is returning 4.000000\nf(3.82447902514946492) is returning 4.000000\nf(6.93100530939575776) is returning 4.000000\n4.0 [ 5.64491239] [4]\n5.0 [ 9.64491239] [5]\n']], ['How to use scipy.integrate.ode.set_f_params() to make time dependant parameter changes?'], 3, 0], [(21332785, 2), [['In contrast, Option 1 produces this:'], ['-10000']], [[' f(0.00000000000000000) is returning 1.000000\nf(0.00000000000014901) is returning 1.000000\nf(0.00000000000038602) is returning 1.000000\nf(0.00000000000031065) is returning 1.000000\nf(0.00000000310683694) is returning 1.000000\nf(0.00000003417209978) is returning 1.000000\nf(0.00000034482472820) is returning 1.000000\nf(0.00000345135101245) is returning 1.000000\nf(0.00003451661385491) is returning 1.000000\nf(0.00034516924227954) is returning 1.000000\nf(0.00345169552652583) is returning 1.000000\nf(0.03451695836898876) is returning 1.000000\nf(0.34516958679361798) is returning 1.000000\nf(3.45169587103990994) is returning 1.000000\n1.0 [ 1.] [1]\nf(1.00000000000000000) is returning 2.000000\nf(1.00000004712160906) is returning 2.000000\nf(1.00004853947319172) is returning 2.000000\nf(1.00002426973659575) is returning 2.000000\nf(1.24272163569515759) is returning 2.000000\nf(3.66969529528077576) is returning 2.000000\n2.0 [ 3.] [2]\nf(2.00000000000000000) is returning 3.000000\nf(2.00000008161702114) is returning 3.000000\nf(2.00009034213922021) is returning 3.000000\nf(2.00004517106961011) is returning 3.000000\nf(2.45175586717085858) is returning 3.000000\nf(6.96886282818334202) is returning 3.000000\n3.0 [ 6.] [3]\nf(3.00000000000000000) is returning 4.000000\nf(3.00000009424321812) is returning 4.000000\nf(3.00009707894638256) is returning 4.000000\nf(3.00004853947319150) is returning 4.000000\nf(3.48544327138667454) is returning 4.000000\nf(8.33939059052150533) is returning 4.000000\n4.0 [10.] [4]\nf(4.00000000000000000) is returning 5.000000\nf(4.00000010536712125) is returning 5.000000\nf(4.00010264848819030) is returning 5.000000\nf(4.00005132424409471) is returning 5.000000\nf(4.51329376519484793) is returning 5.000000\nf(9.64571817470238457) is returning 5.000000\n5.0 [ 15.] [5]\n']], ['How to use scipy.integrate.ode.set_f_params() to make time dependant parameter changes?'], 3, 0], [(21333339, 0), [['Here is a complete example showing code being shared between two custom converters that convert Python objects contains an  int   x  and  y  attribute to a  Spam  object.  Additionally, the example shows how auxiliary functions can be used to pass converted objects by a non-const reference or pointer.'], ['Interactive usage:']], [[' #include <iostream>\n#include <boost/make_shared.hpp>\n#include <boost/python.hpp>\n#include <boost/shared_ptr.hpp>\n\n/// @brief Mockup Spam class.\nstruct Spam\n{\n  int x;\n  int y;\n  Spam()  { std::cout << "Spam()" << std::endl; }\n  ~Spam() { std::cout << "~Spam()" << std::endl; }\n\n  Spam(const Spam& rhs) : x(rhs.x), y(rhs.y)\n    { std::cout << "Spam(const Spam&)" << std::endl; }\n};\n\n/// @brief Helper function to ceck if an object has an attributed with a\n///        specific type.\ntemplate <typename T>\nbool hasattr(const boost::python::object& obj,\n             const char* name)\n{\n  return PyObject_HasAttrString(obj.ptr(), name) &&\n         boost::python::extract<T>(obj.attr(name)).check();\n}\n\n/// @brief Helper type that provides conversions from a Python object to Spam.\nstruct spam_from_python\n{\n  spam_from_python()\n  {\n    boost::python::converter::registry::push_back(\n      &spam_from_python::convertible,\n      &spam_from_python::construct,\n      boost::python::type_id<Spam>());\n  }\n\n  /// @brief Check if PyObject contains an x and y int attribute.\n  static void* convertible(PyObject* object)\n  {\n    namespace python = boost::python;\n    python::handle<> handle(python::borrowed(object));\n    python::object o(handle);\n\n    // If x and y are not int attributes, then return null.\n    if (!hasattr<int>(o, "x") && hasattr<int>(o, "y"))\n      return NULL;\n\n    return object;\n  }\n\n  /// @brief Convert PyObject to Spam.\n  static void construct(\n    PyObject* object,\n    boost::python::converter::rvalue_from_python_stage1_data* data)\n  {\n    // Obtain a handle to the memory block that the converter has allocated\n    // for the C++ type.\n    namespace python = boost::python;\n    typedef python::converter::rvalue_from_python_storage<Spam> storage_type;\n    void* storage = reinterpret_cast<storage_type*>(data)->storage.bytes;\n\n    // Allocate the C++ type into the converter\'s memory block, and assign\n    // its handle to the converter\'s convertible variable.\n    Spam* spam;\n    data->convertible = spam = new (storage) Spam();\n\n    // Initialize spam from an object.\n    initialize_spam(spam, object);\n  }\n\n  /// @brief Initialize a spam instance based on a python object.\n  static void initialize_spam(Spam* spam, PyObject* object)\n  {\n    namespace python = boost::python;\n    python::handle<> handle(python::borrowed(object));\n    python::object o(handle);\n\n    spam->x = python::extract<int>(o.attr("x"));\n    spam->y = python::extract<int>(o.attr("y"));\n  } \n};\n\n/// @brief Helper type that provides conversions from a Python object to\n///        boost::shared_ptr<Spam>.\nstruct shared_spam_from_python\n{\n  shared_spam_from_python()\n  {\n    boost::python::converter::registry::push_back(\n      &spam_from_python::convertible,\n      &shared_spam_from_python::construct,\n      boost::python::type_id<boost::shared_ptr<Spam> >());\n  }\n\n  /// @brief Convert PyObject to boost::shared<Spam>.\n  static void construct(\n    PyObject* object,\n    boost::python::converter::rvalue_from_python_stage1_data* data)\n  {\n    // Obtain a handle to the memory block that the converter has allocated\n    // for the C++ type.\n    namespace python = boost::python;\n    typedef python::converter::rvalue_from_python_storage<\n                                        boost::shared_ptr<Spam> > storage_type;\n    void* storage = reinterpret_cast<storage_type*>(data)->storage.bytes;\n\n    // Allocate the C++ type into the converter\'s memory block, and assign\n    // its handle to the converter\'s convertible variable.\n    boost::shared_ptr<Spam>* spam;\n    data->convertible = spam =\n        new (storage) boost::shared_ptr<Spam>(boost::make_shared<Spam>());\n\n    // Initialize spam from an object.\n    spam_from_python::initialize_spam(spam->get(), object);\n  }\n};\n\n/// @brief Mockup functions acceping Spam in different ways.\nvoid by_value(Spam spam)            { std::cout << "by_value()" << std::endl; }\nvoid by_const_ref(const Spam& spam) { std::cout << "by_cref()"  << std::endl; }\nvoid by_ref(Spam& spam)             { std::cout << "by_ref()"   << std::endl; }\nvoid by_ptr(Spam* spam)             { std::cout << "by_ptr()"   << std::endl; }\n\n/// @brief Use auxiliary functions that accept boost::shared_ptr<Spam> and \n///        delegate to functions that have formal parameters of Spam& and\n///        Spam*.\nvoid by_ref_wrap(boost::shared_ptr<Spam> spam) { return by_ref(*spam); }\nvoid by_ptr_wrap(boost::shared_ptr<Spam> spam) { return by_ptr(spam.get()); }\n\nBOOST_PYTHON_MODULE(example)\n{\n  namespace python = boost::python;\n\n  // Enable python to Spam conversion.\n  spam_from_python();\n\n  // Enable python to boost::shared_ptr<Spam> conversion.\n  shared_spam_from_python();\n\n  // Expose functions that have parameters that can accept a const Spam&\n  // argument.\n  python::def("by_value",     &by_value);\n  python::def("by_const_ref", &by_const_ref);\n\n  // Expose functions that have parameters that can accept a const\n  // boost::shared_ptr<Spam>& argument.  As copies of shared_ptr are cheap,\n  // a copy is used and the managed instance is passed to other functions,\n  // allowing Spam& and Spam* parameters.\n  python::def("by_ptr", &by_ptr_wrap);\n  python::def("by_ref", &by_ref_wrap);\n}\n']], ['Automatic conversion to boost shared_ptr in boost python'], 2, 1], [(21333339, 1), [['Interactive usage:'], ['-10000']], [[' >>> class Egg:\n...     x = 1\n...     y = 2\n... \n>>> import example\n>>> example.by_value(Egg())\nSpam()\nSpam(const Spam&)\nby_value()\n~Spam()\n~Spam()\n>>> example.by_const_ref(Egg())\nSpam()\nby_cref()\n~Spam()\n>>> example.by_ref(Egg())\nSpam()\nby_ref()\n~Spam()\n>>> example.by_ptr(Egg())\nSpam()\nby_ptr()\n~Spam()\n']], ['Automatic conversion to boost shared_ptr in boost python'], 2, 0], [(21343401, 0), [['The "un-Panda-ic" way of doing this would be using a Counter object on the series of datetimes converted to dates, converting this counter back to a series, and coercing the index on this series to datetimes.'], ['A more "Panda-ic" way would be to use a groupby operation on the series and then aggregate the output by length.']], [[" In[1]:  from collections import Counter\nIn[2]:  counted_dates = Counter(df['Time'].apply(lambda x: x.date()))\nIn[3]:  counted_series = pd.Series(counted_dates)\nIn[4]:  counted_series.index = pd.to_datetime(counted_series.index)\nIn[5]:  counted_series\nOut[5]:\n2013-01-01     60\n2013-01-02     60\n"]], ['Counting observations after grouping by dates in pandas'], 3, 1], [(21343401, 1), [['A more "Panda-ic" way would be to use a groupby operation on the series and then aggregate the output by length.'], ['EDIT: Another highly concise possibility, borrowed from  here  is to use the  nunique  class:']], [[" In[1]:  grouped_dates = df.groupby(df['Time'].apply(lambda x : x.date()))\nIn[2]:  grouped_dates['Time'].aggregate(len)\nOut[2]:  \n2013-01-01     60\n2013-01-02     60\n"]], ['Counting observations after grouping by dates in pandas'], 3, 1], [(21343401, 2), [['EDIT: Another highly concise possibility, borrowed from  here  is to use the  nunique  class:'], ["Besides stylistic differences, does one have significant performance advantages over the other? Are there other methods built-in that I've overlooked?"]], [[" In[1]:  df.groupby(df['Time'].apply(lambda x : x.date())).agg({'Time':pd.Series.nunique})\nOut[1]:  \n2013-01-01     60\n2013-01-02     60\n"]], ['Counting observations after grouping by dates in pandas'], 3, 1], [(21377990, 0), [['You can incorporate non-string data into strings with something like:'], ["Hence what you're after is something like:"]], [[' intval = 42\nstrVal = "The value of intVal is %d" % (intVal)\n']], ['Passing argument to python which is half "<direct string>" and half value of a variable'], 3, 1], [(21377990, 1), [["Hence what you're after is something like:"], ['Alternatively, since you can give arbitrary text to  strftime , just use:']], [[' makedir ("/myfolder/%s" % (datetime.date.today().strftime("%d %B, %Y")))\n']], ['Passing argument to python which is half "<direct string>" and half value of a variable'], 3, 1], [(21377990, 2), [['Alternatively, since you can give arbitrary text to  strftime , just use:'], ['-10000']], [[' makedir (datetime.date.today().strftime("/myfolder/%d %B, %Y"))\n']], ['Passing argument to python which is half "<direct string>" and half value of a variable'], 3, 1], [(21423213, 0), [['Hi here is another solution, please check :'], ['Output:']], [[" #!/usr/bin/python\n\nlol = list()\nmarker = '--->'\nwith open('txt', 'r') as fh:\n    mem = None\n    lo = []\n    for line in fh.readlines():\n        k,v = line.strip().split(marker)\n        k, v = [ x.strip() for x in [k,v]]\n        if not mem or mem == k:\n            lo.append((k,v))\n            mem = k\n        else:\n            lol.append(lo)\n            lo = [(k,v)]\n            mem = k\n    lol.append(lo)\n\nfor i in lol:\n    k,v = zip(*i)\n    print '%s%s %s' % (k[0],marker,' '.join(v))\n"]], ['grouping values for grammar generation in python'], 2, 1], [(21423213, 1), [['Output:'], ['-10000']], [[' NP---> N_NNP N_NN_S_NU N_NNP N_NNP\nVGF---> V_VM_VF\nNP---> N_NN\n']], ['grouping values for grammar generation in python'], 2, 0], [(21439948, 0), [['Often a neater way than writing for loops, especially if you are planning on using the result, is to use a list comprehension over a function:'], ['and concat:']], [[" def get_sumdf(area_tab):  # perhaps you can name better?\n    actdf,aname = get_data(area_tab)\n    lastq,fcast_yr,projections,yrahead,aname,actdf,merged2,mergederrs,montdist,ols_test,mergedfcst=do_projections(actdf)\n    sumdf=merged2[-2:]\n    sumdf['name']= aname #<<< I'll be doing a few more calculations here as well \n    return sumdf\n\n[get_sumdf(area_tab) for area_tab in areas_tabs]\n"]], ['Create a summary Pandas DataFrame using concat/append via a for loop'], 7, 0], [(21439948, 1), [['and concat:'], ['or you can also use a generator expression:']], [[' pd.concat([get_sumdf(area_tab) for area_tab in areas_tabs])\n']], ['Create a summary Pandas DataFrame using concat/append via a for loop'], 7, 0], [(21439948, 2), [['or you can also use a generator expression:'], ['To explain my comment re named tuples and dictionaries, I think this line is difficult to read and ripe for bugs:']], [[' pd.concat(get_sumdf(area_tab) for area_tab in areas_tabs)\n']], ['Create a summary Pandas DataFrame using concat/append via a for loop'], 7, 0], [(21439948, 3), [['To explain my comment re named tuples and dictionaries, I think this line is difficult to read and ripe for bugs:'], ['A trick is to have  do_projections  return a named tuple, rather than a tuple:']], [[' lastq,fcast_yr,projections,yrahead,aname,actdf,merged2,mergederrs,montdist,ols_test,mergedfcst=do_projections(actdf)\n']], ['Create a summary Pandas DataFrame using concat/append via a for loop'], 7, 0], [(21439948, 4), [['A trick is to have  do_projections  return a named tuple, rather than a tuple:'], ['then inside  do_projections :']], [[" from collections import namedtuple\nProjection = namedtuple('Projection', ['lastq', 'fcast_yr', 'projections', 'yrahead', 'aname', 'actdf', 'merged2', 'mergederrs', 'montdist', 'ols_test', 'mergedfcst'])\n"]], ['Create a summary Pandas DataFrame using concat/append via a for loop'], 7, 0], [(21439948, 5), [['then inside  do_projections :'], ['I think this avoids bugs and is a lot cleaner, especially to access the results later.']], [["  return (1, 2, 3, 4, ...)  # don't do this\n return Projection(1, 2, 3, 4, ...)  # do this\n return Projection(last_q=last_q, fcast_yr=f_cast_yr, ...)  # or this\n"]], ['Create a summary Pandas DataFrame using concat/append via a for loop'], 7, 0], [(21439948, 6), [['I think this avoids bugs and is a lot cleaner, especially to access the results later.'], ['-10000']], [[' projections = do_projections(actdf)\nprojections.aname\n']], ['Create a summary Pandas DataFrame using concat/append via a for loop'], 7, 0], [(21447599, 0), [['No need for iterative function, you can measure the length of the number by "turning" it into a string:'], ['But if you really want to do it iteratively:']], [[' num = 127\norder = len(str(num))\nprint(order) # prints 3\n']], ['Getting the number of digits of nonnegative integers (Python)'], 2, 1], [(21447599, 1), [['But if you really want to do it iteratively:'], ['-10000']], [[' def order(num):\n    res = 0\n    while num > 0:\n        num = int(num / 10)\n        res += 1\n    return res\n\nprint(order(127))  # prints 3\n']], ['Getting the number of digits of nonnegative integers (Python)'], 2, 1], [(21500596, 0), [["Here's a general solution. It's not pretty but it works:"], ['which gives:']], [[' def filtermax(g, filter_on, filter_items, max_over):\n    infilter = g.index.isin(filter_items).sum() > 0\n    if infilter:\n        return g[g[max_over] == g.ix[filter_items][max_over].max()]\n    else:\n        return g[g[max_over] == g[max_over].max()]\n    return g\n']], ['How to filter results of a groupby in pandas'], 2, 1], [(21500596, 1), [['which gives:'], ["If anyone can work out how to stop  B  being added as an index (at least on my system  x.groupby('B', as_index=False  doesn't help!) then this solution's pretty much perfect!"]], [[" >>> x.groupby('B').apply(filtermax, 'A', ['A0', 'A1', 'A4'], 'C')\n        B    C\nB  A          \nB0 A0  B0  0.5\nB1 A2  B1  0.6\nB2 A4  B2  1.0\n"]], ['How to filter results of a groupby in pandas'], 2, 0], [(21505354, 0), [["This doesn't work if any numbers are 0:"], ['Edit: Breaking the comprehension into a for loop for clarity:']], [[' >>> [[x or y or 0 for x, y in zip(a, b)] for a, b in zip(L1, L2)]\n[[1, 2, 3], [1, 2, 3]]\n']], ['merging two lists, removing empty strings'], 2, 1], [(21507319, 0), [['Use this:'], ['Or use this if you know map:']], [[' [[number+1 for number in group] for group in x]\n']], ['Python: List comprehension list of lists'], 2, 1], [(21507319, 1), [['Or use this if you know map:'], ['-10000']], [[' [map(lambda x:x+1 ,group) for group in x]\n']], ['Python: List comprehension list of lists'], 2, 1], [(21513187, 0), [['However, if you absolutely need to delete each page right after the user left it, use this:'], ['Then in yourscript.php, put something like the following:']], [[" $(window).bind('beforeunload', function() {\n    $.ajax('yourscript.php?currentUser=0814HIFA9032RHBFAP3RU');\n});\n"]], ['Is it possible to delete an entire Webpage when the user navigates away?'], 2, 0], [(21513187, 1), [['Then in yourscript.php, put something like the following:'], ['-10000']], [[" <?php\n\n// load your userId (for example, with $_SESSION, but do what you want here)\n$actualUser = $_SESSION['userId'];\n\n// checks if the requested id to delete fits your actual current user's id\nif (isset($_GET['currentUser'] && $_GET['currentUser'] == $actualUser)\n{\n    $user = $_GET['currentUser'];\n    $file = 'user'.$user.'.php';\n\n    unlink($file);\n}\n"]], ['Is it possible to delete an entire Webpage when the user navigates away?'], 2, 0], [(21515554, 1), [['View:'], ['-10000']], [[" hello = get_template_attribute('_cider.html', 'hello')\nreturn hello('World')\n"]], ['Render part of the template in Flask'], 2, 0], [(21532471, 0), [["Since Python3.4, you can use the  statistics  module  for calculating spread and average metrics. With that, Cohen's d can be calculated easily:"], ['Output:']], [[' from statistics import mean, stdev\nfrom math import sqrt\n\n# test conditions\nc0 = [2, 4, 7, 3, 7, 35, 8, 9]\nc1 = [i * 2 for i in c0]\n\ncohens_d = (mean(c0) - mean(c1)) / (sqrt((stdev(c0) ** 2 + stdev(c1) ** 2) / 2))\n\nprint(cohens_d)\n']], ["How to calculate cohen's d in Python?"], 2, 1], [(21532471, 1), [['Output:'], ['So we observe a medium effect.']], [[' -0.5567679522645598\n']], ["How to calculate cohen's d in Python?"], 2, 0], [(21538859, 1), [['Then the env file looks like this:'], ["And finally your virtualenv/bin/postactivate can source this file.  You could go further and export the variables as described  here  if you'd like, but since settings file directly calls the .env, there isn't really a need."]], [[" #!/bin/sh\n#\n# This should normally be placed in the ${SITE_ROOT}/.env\n#\n# DEPLOYMENT DO NOT MODIFY THESE..\nSECRET_KEY='XXXSECRETKEY'\n"]], ['Pycharm: set environment variable for run manage.py Task'], 2, 0], [(21588963, 0), [["You could override the cmd module's  completedefault()  method with:"], ['with the complete method looking like:']], [[' def completedefault(self, *ignored):\n        # Set the autocomplete preferences\n        readline.set_completer_delims(\' \\t\\n;\')\n        readline.parse_and_bind("tab: complete")\n        readline.set_completer(complete)\n']], ["Cmd module '~' completion"], 2, 0], [(21588963, 1), [['with the complete method looking like:'], ['This should now allow  ~  expansion.']], [[" def complete(text, state):\n    return (glob.glob(os.path.expanduser(text)+'*')+[None])[state]\n"]], ["Cmd module '~' completion"], 2, 0], [(21668606, 0), [["There's a few ways to plug an alternate operator in there, as well as creating a custom operator, but the most public/mainstream way to get at what happens when  __ne__()  is invoked is at the type level:"], ['so that will do the OR thing:']], [[' from sqlalchemy import TypeDecorator, type_coerce, String, or_\n\nclass NullComparisons(TypeDecorator):\n    impl = String\n\n    class comparator_factory(TypeDecorator.Comparator):\n        def __ne__(self, other):\n            expr = type_coerce(self.expr, String)\n            return or_(expr == None, expr != other)\n']], ['NULL safe inequality comparisons in SQL Alchemy?'], 6, 0], [(21668606, 1), [['so that will do the OR thing:'], ['gives us:']], [[" from sqlalchemy import Column, Integer\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\nclass Thing(Base):\n    __tablename__ = 'thing'\n\n    id = Column(Integer, primary_key=True)\n    data = Column(NullComparisons(50))\nprint(Thing.data != 'hi')\n"]], ['NULL safe inequality comparisons in SQL Alchemy?'], 6, 0], [(21668606, 2), [['gives us:'], ["then for the PG/MySQL operator, what we really should have is the ability to link @compiles to operators directly.   But that hook isn't present right now, so with more effort than it ideally should require, we can make a custom column element to handle it:"]], [[' thing.data IS NULL OR thing.data != :param_1\n']], ['NULL safe inequality comparisons in SQL Alchemy?'], 6, 0], [(21668606, 3), [["then for the PG/MySQL operator, what we really should have is the ability to link @compiles to operators directly.   But that hook isn't present right now, so with more effort than it ideally should require, we can make a custom column element to handle it:"], ['then we can try that out:']], [[' from sqlalchemy import TypeDecorator, type_coerce, String\nfrom sqlalchemy.ext.compiler import compiles\nfrom sqlalchemy.sql.expression import BinaryExpression\nimport operator\nclass IsDistinctFrom(BinaryExpression):\n    pass\n\n@compiles(IsDistinctFrom, "postgresql")\ndef pg_is_distinct_from(element, compiler, **kw):\n    return "%s IS DISTINCT FROM %s" % (\n                    compiler.process(element.left, **kw),\n                    compiler.process(element.right, **kw),\n                )\n\n@compiles(IsDistinctFrom, "mysql")\ndef mysql_is_distinct_from(element, compiler, **kw):\n    return "%s <=> %s" % (\n                    compiler.process(element.left, **kw),\n                    compiler.process(element.right, **kw),\n                )\n\nclass AdvancedNullComparisons(TypeDecorator):\n    impl = String\n\n    class comparator_factory(TypeDecorator.Comparator):\n        def __ne__(self, other):\n            expr = type_coerce(self.expr, String)\n            # this step coerces a literal into a SQL expression,\n            # this can be done without the private API here but the private\n            # function does the most thorough job, this could also be made\n            # public\n            other = self._check_literal(expr, operator.ne, other)\n            return IsDistinctFrom(self.expr, other, operator.ne)\n']], ['NULL safe inequality comparisons in SQL Alchemy?'], 6, 0], [(21668606, 4), [['then we can try that out:'], ['gives us:']], [[" from sqlalchemy import Column, Integer\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass Thing(Base):\n    __tablename__ = 'thing'\n\n    id = Column(Integer, primary_key=True)\n    data = Column(AdvancedNullComparisons(50))\n\nfrom sqlalchemy.dialects import postgresql, mysql\nprint(Thing.data != 'hi').compile(dialect=postgresql.dialect())\nprint(Thing.data != 'hi').compile(dialect=mysql.dialect())\n"]], ['NULL safe inequality comparisons in SQL Alchemy?'], 6, 0], [(21668606, 5), [['gives us:'], ['-10000']], [[' thing.data IS DISTINCT FROM %(param_1)s\nthing.data <=> %s\n']], ['NULL safe inequality comparisons in SQL Alchemy?'], 6, 0], [(21712375, 0), [['values is a list of of dictionaries rather than a dictionary or a simple list\nit would look something like this'], ['you can loop over it like a list']], [[" values = [{'k':'v'},{'k1':'v1'},...]\n"]], ['Key Value For Loop Template - Django Inquiry'], 4, 0], [(21712375, 3), [['is basically the same as'], ['in normal python']], [['   for k,v in values[1].items():\n']], ['Key Value For Loop Template - Django Inquiry'], 4, 0], [(21720721, 0), [['You can use  subprocess  and the  Popen.communicate  method:'], ['If you want the output from  grid.exe  to show up on the console, modify  create_grid  to look like the following:']], [[" import subprocess\n\ndef create_grid(*commands):\n    process = subprocess.Popen(\n        ['grid.exe'],\n        stdout=subprocess.PIPE,\n        stdin=subprocess.PIPE,\n        stderr=subprocess.PIPE)\n\n    process.communicate('\\n'.join(commands) + '\\n')\n\nif __name__ == '__main__':\n    create_grid('grid.grd', 'yes', 'not really')\n"]], ['How to run executable from python and pass it arguments asked for?'], 2, 1], [(21720721, 1), [['If you want the output from  grid.exe  to show up on the console, modify  create_grid  to look like the following:'], ["Caveat: I haven't fully tested my solutions, so can't confirm they work in every case."]], [[" def create_grid(*commands):\n    process = subprocess.Popen(\n        ['grid.exe'],\n        stdin=subprocess.PIPE)\n\n    process.communicate('\\n'.join(commands) + '\\n')\n"]], ['How to run executable from python and pass it arguments asked for?'], 2, 0], [(21736784, 0), [["Assuming your lists are consistent (i.e.  ['2', '2', '3', 'A'] ) and consist of elements of  RANKS , ordering by position in  RANKS  is sufficient :"], ['-10000']], [[' >>> sorted([\'2\', \'2\', \'3\', \'A\'], key=lambda x: RANKS.index(x))\n[\'A\', \'2\', \'2\', \'3\']\n>>> sorted([\'10\',"K","J","Q"], key=lambda x: RANKS.index(x))\n[\'10\', \'J\', \'Q\', \'K\']\n']], ['Sort Python list by dict key,value'], 5, 1], [(21736784, 1), [['-10000'], ['which create a dict that associates the RANK name with its value and its index. You can then simply sort using']], [[' val_dict = dict(zip(RANKS, zip(VALUES, range(len(VALUES)))))\n']], ['Sort Python list by dict key,value'], 5, 0], [(21736784, 2), [['which create a dict that associates the RANK name with its value and its index. You can then simply sort using'], ['as suggested several times.']], [[' sorted(myList, key=val_dict.get)\n']], ['Sort Python list by dict key,value'], 5, 0], [(21736784, 3), [['as suggested several times.'], ['for faster lookup. Identically, the value can be put in another dict for fast lookup :']], [[' {k: v for v, k in enumerate(RANKS)}\n']], ['Sort Python list by dict key,value'], 5, 0], [(21736784, 4), [['for faster lookup. Identically, the value can be put in another dict for fast lookup :'], ['-10000']], [[' {RANKS[v]: k for v, k in enumerate(VALUES)}\n']], ['Sort Python list by dict key,value'], 5, 0], [(21739450, 0), [['So in Ruby, you can do something like '], ["I believe in Python, it's something like (untested, only provides the logic, you are the Python developer, hopefully you will figure out)"]], [[' require \'selenium-webdriver\'\n\ncapabilities = Selenium::WebDriver::Remote::Capabilities.phantomjs("phantomjs.page.settings.resourceTimeout" => "5000")\ndriver = Selenium::WebDriver.for :phantomjs, :desired_capabilities => capabilities\n']], ['Setting timeout on selenium webdriver.PhantomJS'], 2, 0], [(21739450, 1), [["I believe in Python, it's something like (untested, only provides the logic, you are the Python developer, hopefully you will figure out)"], ['-10000']], [[" driver = webdriver.PhantomJS(desired_capabilities={'phantomjs.page.settings.resourceTimeout': '5000'})\n"]], ['Setting timeout on selenium webdriver.PhantomJS'], 2, 1], [(21756477, 0), [['This is clearly an application for metaclasses. That is if you want to change the behavior of a classe C then you should change the class of C itself which is a metaclass, usually  type . Here is a stub of solution:'], ["I'm inheriting from  type  to make a metaclass intercepting the creation of the class and storing the created class in the base  _subclass  attribute. Then with"]], [[' class Meta(type):\n    def __new__(cls, clsname, bases, dct):\n        res = type.__new__(cls, clsname, bases, dct)\n        for cls in bases:\n            if isinstance(cls, Meta):\n                try:\n                    cls.extending(res)\n                except AttributeError:\n                    pass\n        return res\n']], ['Execute code when extending a class in Python'], 4, 0], [(21756477, 1), [["I'm inheriting from  type  to make a metaclass intercepting the creation of the class and storing the created class in the base  _subclass  attribute. Then with"], ['Then']], [[' class Base(object):\n    __metaclass__ = Meta\n\n    subclasses = {}\n\n    @classmethod\n    def extending(cls, subclass):\n        cls.subclasses[subclass.__name__] = subclass\n\nclass Extend1(Base):\n    pass\n\nclass Extend2(Base):\n    pass\n']], ['Execute code when extending a class in Python'], 4, 0], [(21756477, 2), [['Then'], ['A very important point: metaclass are  inherited  (I think this is not the exactly the proper term here). Therefore  Extend1  and  Extend2  are also instances of  Meta :']], [[" >>> Base.subclasses\n{'Extend1': __main__.Extend1, 'Extend2': __main__.Extend2}\n"]], ['Execute code when extending a class in Python'], 4, 0], [(21756477, 3), [['A very important point: metaclass are  inherited  (I think this is not the exactly the proper term here). Therefore  Extend1  and  Extend2  are also instances of  Meta :'], ['-10000']], [[" >>> type(Extend1)\n<class '__main__.Meta'>\n"]], ['Execute code when extending a class in Python'], 4, 0], [(21808905, 0), [['Use  setattr :'], ['Example usage of  setattr :']], [[" keyMapping = { 'From': 'msg_from',\n               'To': 'msg_to',\n               'Body': 'msg_body' }\nfor k, v in keyMapping.items():\n    if form.getfirst(k):\n        setattr(msg, v, form.getfirst(k))\n"]], ["How to set a Python object's field/member by name"], 2, 1], [(21817657, 1), [["The  defaultdict  makes the code cleaner here; it's just a subclass of  dict  that will call the factory (here set to  list ) if a key doesn't yet exist. Without a  defaultdict  you'd have to use:"], ['and in the loop:']], [[' words = {}\n']], ['Merge some part of the list together using python'], 6, 0], [(21817657, 2), [['and in the loop:'], ['Demo:']], [[' words.setdefault(key, []).append(word)\n']], ['Merge some part of the list together using python'], 6, 0], [(21817657, 3), [['Demo:'], ['If your input list is sorted and order is important, you can also use  itertools.groupb() :']], [[" >>> from collections import defaultdict\n>>> raw = ['opst tops', 'opst opts', 'opst pots', 'eip pie', 'eip epi']\n>>> words = defaultdict(list)\n>>> for entry in raw:\n...     key, word = entry.split()\n...     words[key].append(word)\n... \n>>> [' '.join(v) for v in words.values()]\n['pie epi', 'tops opts pots']\n"]], ['Merge some part of the list together using python'], 6, 1], [(21817657, 5), [['Demo:'], ['-10000']], [[" >>> from itertools import groupby\n>>> [' '.join(w.split()[1] for w in words) \n...        for key, words in groupby(raw, key=lambda e: e.split()[0])]\n['tops opts pots', 'pie epi']\n"]], ['Merge some part of the list together using python'], 6, 1], [(21820700, 0), [['Yes, use  lambdify :'], ['If you want to use this with numpy, set  "numpy"  as the second argument of lambdify']], [[' >>> f = lambdify(x, integrate(x**2+2,x))\n>>> f(2)\n6.666666666666666\n']], ['Evaluate integral from sympy as lambda function'], 2, 1], [(21833068, 0), [['What the others said in the comments: use an existing parser. If none exists, roll your own, but use a parser library. Here e.g. with  Parcon :'], ['Result:']], [[' from pprint import pprint\nfrom parcon import (Forward, SignificantLiteral, Word, alphanum_chars, Exact,\n                    ZeroOrMore, CharNotIn, concat, OneOrMore)\n\nblock = Forward()\nhyphen = SignificantLiteral(\'"\')\nword = Word(alphanum_chars + \'/_.)\')\nvalue = word | Exact(hyphen + ZeroOrMore(CharNotIn(\'"\')) + hyphen)[concat]\npair = word + \'=\' + value\nflag = word\nattribute = pair | flag | block\nhead = word\nbody = ZeroOrMore(attribute)\nblock << \'{\' + head + body  + \'}\'\nblocks = OneOrMore(block)\n\nwith open(\'<your file name>.txt\') as infile:\n    pprint(blocks.parse_string(infile.read()))\n']], ['Parsing structured text file in python'], 2, 1], [(21833068, 1), [['Result:'], ['-10000']], [[' [(\'NETLIST\',\n  [\'topblock\',\n   (\'VERSION\', [\'2\', \'0\', \'0\']),\n   (\'CELL\',\n    [\'topblock\',\n     (\'PORT\',\n      [\'gearshift_h\',\n       \'vpsf\',\n       \'vphreg\',\n       \'pwron_h\',\n       \'vinp\',\n       \'vref_out\',\n       \'vcntrl_out\',\n       \'gd\',\n       \'meas_vref\',\n       \'vb\',\n       \'vout\',\n       \'meas_vcntrl\',\n       \'reset_h\',\n       \'vinm\']),\n     (\'INST\',\n      [(\'XI21/Mdummy1\', \'pch_18_mac\'),\n       (\'TYPE\', [\'MOS\']),\n       (\'PROP\',\n        [(\'n\', \'"sctg_inv1x/pch_18_mac"\'),\n         (\'Length\', \'0.152\'),\n         (\'NFIN\', \'8\')]),\n       (\'PIN\',\n        [(\'vpsf\', \'SRC\'),\n         (\'gs_h\', \'DRN\'),\n         (\'vpsf\', \'GATE\'),\n         (\'vpsf\', \'BULK\')])]),\n     (\'INST\',\n        ...\n']], ['Parsing structured text file in python'], 2, 0], [(21857875, 0), [['You should define an alias:'], ['or for the entire module']], [[' from System.Windows import WindowState as WindowState1\nfrom ESS.MS.Framework.UIG.Mask import WindowState as WindowState2\n']], ['IronPython import two enums with the same name'], 2, 1], [(21857875, 1), [['or for the entire module'], ['PS. choose of course better aliases']], [[' import System.Windows as Module1\nimport ESS.MS.Framework.UIG.Mask as Module2\n\n//...\nModule1.WindowState\nModule2.WindowState\n']], ['IronPython import two enums with the same name'], 2, 1], [(21871829, 0), [["If you're doing something like"], ["to convert your numbers to a two's complement string representation, you'll want to actually take the two's complement of a negative number before stringifying it:"]], [[" format(num, '016b')\n"]], ["two's complement of numbers in python"], 3, 0], [(21885814, 0), [['You can use  foo.__dict__  somehow like this:'], ['A more elegant (functional) way to get functions would be:']], [[" for name, val in foo.__dict__.iteritems(): # iterate through every module's attributes\n    if callable(val):                      # check if callable (normally functions)\n        val()                              # call it\n"]], ["How to iterate through a module's functions"], 3, 1], [(21885814, 1), [['A more elegant (functional) way to get functions would be:'], ['For example, this will list all functions in the  math  method:']], [[' [f for _, f in foo.__dict__.iteritems() if callable(f)]\n']], ["How to iterate through a module's functions"], 3, 1], [(21892080, 0), [['-10000'], ['-10000']], [["Main Monitoring of Cameras def monitorCam(camera, config, mainlog):\n    '''Uses the Watchdog package to monitor the data directory for new files.\n    See the MonitorFiles class in dosClasses for actual monitoring code.  Monitors each camera.'''\n\n    mainlog.info('Process Name, PID: {0},{1}'.format(mp.current_process().name,mp.current_process().pid))\n\n    #init cam log\n    camlog = initLogger(config, filename='manga_dos_{0}'.format(camera))\n    camlog.info('Camera {0}, PID {1} '.format(camera,mp.current_process().pid))\n    config.camera=camera\n\n    event_handler = dosclass.MonitorFiles(config, camlog, mainlog)\n\n    # add logging the the event handler\n    log_handler = LoggingEventHandler()\n\n    # set up observer\n    observer = Observer()\n    observer.schedule(event_handler, path=config.fitsDir, recursive=False)\n    observer.schedule(log_handler, config.fitsDir, recursive=False)\n    observer.daemon=True\n    observer.start()\n    camlog.info('Begin MaNGA DOS!')\n    camlog.info('Start watching directory {0} for new files ...'.format(config.fitsDir))\n    camlog.info('Watching directory {0} for new files from camera {1}'.format(config.fitsDir,camera))\n\n    # monitor\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.unschedule_all()\n        observer.stop()\n        camlog.info('Stop watching directory ...')\n        camlog.info('End MaNGA DOS!')\n        camlog.info('--------------------------')\n        camlog.info('')\n    #observer.join()\n\n    if observer.is_alive():\n        camlog.info('still alive')\n    else:\n        camlog.info('thread ending')    \n"]], ['combining python watchdog with multiprocessing or threading'], 2, 0], [(21892080, 1), [['-10000'], ['-10000']], [["Start of Multiple Camera Processes def startProcess(camera,config,log):\n    ''' Uses multiprocessing module to start 4 different camera monitoring processes'''\n\n    jobs=[]\n\n    #pdb.set_trace()\n\n    #log.info(mp.log_to_stderr(logging.DEBUG))\n    for i in range(len(camera)):\n        log.info('Starting to monitor camera {0}'.format(camera[i]))\n        print 'Starting to monitor camera {0}'.format(camera[i])\n        try:\n            p = mp.Process(target=monitorCam, args=(camera[i],config, log), name=camera[i])\n            p.daemon=True\n            jobs.append(p)\n            p.start()\n        except KeyboardInterrupt:\n            log.info('Ending process: {0} for camera {1}'.format(mp.current_process().pid, camera[i]))\n            p.terminate()\n            log.info('Terminated: {0}, {1}'.format(p,p.is_alive()))\n\n    for i in range(len(jobs)):\n        jobs[i].join()  \n\n    return      \n"]], ['combining python watchdog with multiprocessing or threading'], 2, 0], [(21896326, 0), [['Yes, it is  possible  to do this, though it is considered a  bad  thing to do:'], ['Instead you should do something like:']], [[" string = 'someString'\nglobals()[string] = dict()\n"]], ['Usng the value of a string as a variable name'], 2, 1], [(21896326, 1), [['Instead you should do something like:'], ['then  my_dynamic_vars[string]  is a  dict()']], [[" my_dynamic_vars = dict()\nstring = 'someString'\n\nmy_dynamic_vars.update({string: dict()})\n"]], ['Usng the value of a string as a variable name'], 2, 1], [(21905433, 0), [['To implement comparisons between custom classes, you need to implement the  comparison magic methods , e.g.:'], ['However, If your class has no attributes, you are effectively trying to compare on the name the class instance is assigned to, which makes no sense. Instead, refactor your class:']], [[' def __gt__(self, other): # is self greater than other?\n    return self.value > other.value # compare value attribute\n']], ['Python. How to make a class so that I can create a set of related objects(like"Rock, Paper, Scissors") with it?'], 3, 1], [(21905433, 1), [['However, If your class has no attributes, you are effectively trying to compare on the name the class instance is assigned to, which makes no sense. Instead, refactor your class:'], ['Now you can create the weapons, e.g.']], [[' class Weapon(object):\n\n    def __init__(self, name, beats):\n        self.name = name\n        self.beats = beats\n\n    def __gt__(self, other):\n        return other.name in self.beats\n']], ['Python. How to make a class so that I can create a set of related objects(like"Rock, Paper, Scissors") with it?'], 3, 1], [(21905433, 2), [['Now you can create the weapons, e.g.'], ['-10000']], [[' rock = Weapon("rock", ["scissors", "lizard"])\n']], ['Python. How to make a class so that I can create a set of related objects(like"Rock, Paper, Scissors") with it?'], 3, 0], [(21906759, 0), [["It's not that elegant but I can propose this:"], ['Here\'s an alternative solution using the "sets" EXSLT extensions:']], [[' for tr in subpage.cssselect(\'tr.nob-border\'):\n    previous = tr.xpath(\'count(./preceding-sibling::tr)+1\')\n    next = tr.xpath(\'count(./following-sibling::tr[contains(@class, "nob-border")][1]/preceding-sibling::tr)+1\')\n    tr_in_between = tr.xpath(\'./following-sibling::tr[position() < $next]\', next=next-previous)\n']], ['Selecting siblings from html with Python lxml(html) library'], 2, 1], [(21906759, 1), [['Here\'s an alternative solution using the "sets" EXSLT extensions:'], ['-10000']], [[' for tr in subpage.cssselect(\'tr.nob-border\'):\n    tr.xpath(""" set:difference(following-sibling::tr[not(contains(@class, "nob-border"))],\n                                following-sibling::tr[contains(@class, "nob-border")]\n                                                   /following-sibling::tr)""",\n             namespaces={"set": "http://exslt.org/sets"})\n']], ['Selecting siblings from html with Python lxml(html) library'], 2, 1], [(21919877, 0), [["str.replace takes a regular expression, for example ' macbook air 11'  followed  zero (or more) ( * ) of any characters ( . ) (you could also flag to be case insensitive):"], ['However, you might be better off, especially if you have already have a complete list of topics, to normalize the names (e.g. using fuzzywuzzy like in this  question / answer ):']], [[" Df['Description'].str.replace('macbook air 11.*' , 'macbook air 11')\n"]], ['How to replace all words in a series with a few specified words in Pandas,Python?'], 2, 1], [(21919877, 1), [['However, you might be better off, especially if you have already have a complete list of topics, to normalize the names (e.g. using fuzzywuzzy like in this  question / answer ):'], ['-10000']], [[" from fuzzywuzzy.fuzz import partial_ratio\nDf['Description'].apply(lambda x: max(topics, key=lambda t: partial_ratio(x, t)))\n"]], ['How to replace all words in a series with a few specified words in Pandas,Python?'], 2, 1], [(21928814, 0), [['http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-by-melt'], ['outputs this: ']], [[' import pandas as pd\nimport numpy as np\nfrom pandas import melt\n\ndf = pd.DataFrame(np.random.randint(10, 1000, size=(2,12)), index=[\'PrinterBlue\', \'PrinterBetter\'], columns=pd.date_range(\'1-1\', periods=12, freq=\'M\'))\n\ndft = df.T\ndft["date"] = dft.index\nresult = melt(dft, id_vars=["date"])\nresult.columns = ["date", "brand", "sales"]\nprint (result)\n']], ['Pandas dataframe : Multiple Time/Date columns to single Date index'], 2, 1], [(21928814, 1), [['outputs this: '], ['-10000']], [['          date          brand  sales\n0  2014-01-31    PrinterBlue    242\n1  2014-02-28    PrinterBlue    670\n2  2014-03-31    PrinterBlue    142\n3  2014-04-30    PrinterBlue    571\n4  2014-05-31    PrinterBlue    826\n5  2014-06-30    PrinterBlue    515\n6  2014-07-31    PrinterBlue    568\n7  2014-08-31    PrinterBlue     90\n8  2014-09-30    PrinterBlue    652\n9  2014-10-31    PrinterBlue    488\n10 2014-11-30    PrinterBlue    671\n11 2014-12-31    PrinterBlue    767\n12 2014-01-31  PrinterBetter    294\n13 2014-02-28  PrinterBetter     77\n14 2014-03-31  PrinterBetter     59\n15 2014-04-30  PrinterBetter    373\n16 2014-05-31  PrinterBetter    228\n17 2014-06-30  PrinterBetter    708\n18 2014-07-31  PrinterBetter     16\n19 2014-08-31  PrinterBetter    542\n20 2014-09-30  PrinterBetter    577\n21 2014-10-31  PrinterBetter    141\n22 2014-11-30  PrinterBetter    358\n23 2014-12-31  PrinterBetter    290\n']], ['Pandas dataframe : Multiple Time/Date columns to single Date index'], 2, 0], [(21941657, 0), [['Here is my rough attempt, test output below...'], ['Sample output:']], [[" def data_to_python(data_file_name):\n    with open(data_file_name,'r') as f:\n        data = []\n        first = True\n        for line in f:\n            if first:\n                first = False\n                datanames = line.split('\\t')\n            else:\n                temp = {}\n                for i,item in enumerate(line.split('\\t')):\n                     temp[datanames[i]] = item\n                data.append(temp)\n    return data\n\ndef searchByYear(data,year):\n    temp = []\n    for entry in data:\n        if entry['Dato'].endswith(str(year)):\n            temp.append(entry)\n    return temp\n"]], ['Write average weather data from a year given by user to a text file'], 2, 1], [(21941657, 1), [['Sample output:'], ['-10000']], [[" >>> data = dataToPython('test.txt')\n>>> searchByYear(data,1957)\n    [{'FFM': '6.2', 'DD18': '170', 'DD06': '150', 'Stnr': '50540', 'DD12': '170', 'FXM':'8.8', 'Dato': '07.01.1957', 'POM': '1010.6', 'UUM\\n': '94\\n', 'TAM': '6.3'}, {'FFM': '7.2', 'DD18': '200', 'DD06': '160', 'Stnr': '50540', 'DD12': '160', 'FXM': '9.8', 'Dato': '08.01.1957', 'POM': '1001.8', 'UUM\\n': '99\\n', 'TAM': '8.0'}, {'FFM': '8.1', 'DD18': '160', 'DD06': '290', 'Stnr': '50540', 'DD12': '200', 'FXM': '13.3', 'Dato': '09.01.1957', 'POM': '990.2', 'UUM\\n': '91', 'TAM': '5.7'}]\n>>> searchByYear(data,1956)\n[]\n"]], ['Write average weather data from a year given by user to a text file'], 2, 0], [(21959866, 1), [['then simply:'], ['Using the file at my link, here is an equivalent version for a line graph:']], [[' ax.bar(x, data, color=colors)\n']], ['multi colored plots in matplotlib plt based on certain properties of data'], 3, 0], [(21959866, 2), [['Using the file at my link, here is an equivalent version for a line graph:'], ['The last three arguments of colorline here tell it the color data and how to map it.']], [[" cmap = ListedColormap(['r', 'g']) # use the colors red and green\nnorm = BoundaryNorm([-1000,0,1000], cmap.N) # map red to negative and green to positive\n                                            # this may work with just 0 in the list\nfig, axes = plt.subplots()\ncolorline(x, data, data, cmap=cmap, norm=norm)\n\nplt.xlim(x.min(), x.max())\nplt.ylim(data.min(), data.max())\n\nplt.show()\n"]], ['multi colored plots in matplotlib plt based on certain properties of data'], 3, 1], [(22019213, 0), [['What you see in the output is the representation of the single  bytes  object inside the  price  list returned by  re.findall() . You could decode it into a string and print it:'], ['You could  use an html parser instead of a regex to parse html :']], [[' >>> for item in price:\n...     print(item.decode()) # assume utf-8\n... \n1,217.04\n']], ['How to display proper output when using re.findall() in python?'], 2, 1], [(22019213, 1), [['You could  use an html parser instead of a regex to parse html :'], ["Check whether yahoo provides API that doesn't require web scraping."]], [[' #!/usr/bin/env python3\nimport cgi\nfrom html.parser import HTMLParser\nfrom urllib.request import urlopen\n\nurl = \'http://finance.yahoo.com/q?s=GOOG\'\n\ndef is_price_tag(tag, attrs):\n    return tag == \'span\' and dict(attrs).get(\'id\') == \'yfs_l84_goog\'\n\nclass Parser(HTMLParser):\n    """Extract tag\'s text content from html."""\n    def __init__(self, html, starttag_callback):\n        HTMLParser.__init__(self)\n        self.contents = []\n        self.intag = None\n        self.starttag_callback = starttag_callback\n        self.feed(html)\n\n    def handle_starttag(self, tag, attrs):\n        self.intag = self.starttag_callback(tag, attrs)\n    def handle_endtag(self, tag):\n        self.intag = False\n    def handle_data(self, data):\n        if self.intag:\n            self.contents.append(data)\n\n# download and convert to Unicode\nresponse = urlopen(url)\n_, params = cgi.parse_header(response.headers.get(\'Content-Type\', \'\'))\nhtml = response.read().decode(params[\'charset\'])\n\n# parse html (extract text from the price tag)\ncontent = Parser(html, is_price_tag).contents[0]\nprint(content)\n']], ['How to display proper output when using re.findall() in python?'], 2, 1], [(22023193, 1), [['The webapp2 route for this handler looks like:'], ['To serve:']], [[" webapp2.Route(r'/dynserve/<resource:(.*)>', handler=DynServe)\n"]], ['Python App Engine serving files with Google Cloud Storage'], 3, 0], [(22023193, 2), [['To serve:'], ['-10000']], [[' <a href="/dynserve/<blob_key>.pdf">PDF download</a>\n']], ['Python App Engine serving files with Google Cloud Storage'], 3, 0], [(22024409, 0), [['You could do it something like this :'], ['And the output is :']], [[' from bs4 import BeautifulSoup\n\nhtml = """<html><body><div id="here"></div></body></html>"""\n\nsoup = BeautifulSoup(html)\ndiv = soup.find("div", id="here")\n\nhtml2 = """<html><body><script   src="//ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>\n           <script src="//cdn.sstatic.net/Js/stub.en.js?v=283ea58c715b"></script>\n           <link rel="stylesheet" type="text/css"  href="//cdn.ss  tatic.net/stackoverflow/all.css?   v=71d362e7c10c">\n           </body></html>"""\n\nsoup1 = BeautifulSoup(html2)\nvalue = soup1.body.extract()\n\ndiv.append(value)\nprint div\n']], ['How do I use BeautifulSoup to move tag contents from one soup to a template soup'], 4, 1], [(22024409, 1), [['And the output is :'], ['If you want the content inside the   body  you can do it something like this instead :']], [[' <div id="here"><body><script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>\n<script src="//cdn.sstatic.net/Js/stub.en.js?v=283ea58c715b"></script>\n<link href="//cdn.sstatic.net/stackoverflow/all.css?v=71d362e7c10c" rel="stylesheet"   type="text/css">\n</link></body></div>\n']], ['How do I use BeautifulSoup to move tag contents from one soup to a template soup'], 4, 0], [(22024409, 2), [['If you want the content inside the   body  you can do it something like this instead :'], ['And the output is :']], [[' #the above same lines\n\nsoup1 = BeautifulSoup(html2)\nvalue = soup1.body.extract()\n\ndiv.append(value)\n# replaces a tag with whatever’s inside that tag.\ndiv.body.unwrap()\nprint div\n']], ['How do I use BeautifulSoup to move tag contents from one soup to a template soup'], 4, 1], [(22024409, 3), [['And the output is :'], ['-10000']], [[' <div id="here"><script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>\n<script src="//cdn.sstatic.net/Js/stub.en.js?v=283ea58c715b"></script>\n<link href="//cdn.sstatic.net/stackoverflow/all.css?v=71d362e7c10c" rel="stylesheet"   type="text/css">\n</link></div>\n']], ['How do I use BeautifulSoup to move tag contents from one soup to a template soup'], 4, 0], [(22042490, 0), [['Python is highly modifiable. Just add your function to the  class :'], ['Having looked over the  mpl_toolkits.basemap.__init__  module, I do see that the  drawparallel  method relies on a  few  globals; you can import those from the module into your own namespace:']], [[' from mpl_toolkits.basemap import Basemap\n\n\ndef drawmlat(self, arg1, arg2, kw=something):\n    pass\n\nBasemap.drawmlat = drawmlat\n']], ['How do I add a method to a class from a third-party Python module without editing the original module'], 2, 1], [(22042490, 1), [['Having looked over the  mpl_toolkits.basemap.__init__  module, I do see that the  drawparallel  method relies on a  few  globals; you can import those from the module into your own namespace:'], ["This is no different from other imports you'd make; the original  drawparallel  method also relies on  import numpy as np  and  from matplotlib.lines import Line2D , which make both  np  and  Line2D  globals in the original module."]], [[' from mpl_toolkits.basemap import Basemap, _cylproj, _pseudocyl\n']], ['How do I add a method to a class from a third-party Python module without editing the original module'], 2, 0], [(22048792, 0), [['According to efiring , matplotlib does not support NumPy datetime64 objects (at least not yet).  Therefore, convert  x  to Python datetime.datetime objects:'], ['Next, you can specify the x-axis tick mark formatter like this:']], [[' x = x.astype(DT.datetime)\n']], ['How do I display dates when plotting in matplotlib.pyplot?'], 3, 0], [(22048792, 1), [['Next, you can specify the x-axis tick mark formatter like this:'], ['-10000']], [[" xfmt = mdates.DateFormatter('%b %d')\nax.xaxis.set_major_formatter(xfmt)\n"]], ['How do I display dates when plotting in matplotlib.pyplot?'], 3, 0], [(22083378, 0), [['One way is to  replace  the lower zeros with NaNs: '], ['Now you can use  where  to change these to 2:']], [[' In [11]: df.replace(0, np.nan).bfill()  #\xa0maybe neater way to do this?\nOut[11]:\n             a   b   c\n2000-03-02   1   1   1\n2000-03-03   1   1   1\n2000-03-04   1   1   1\n2000-03-05   1 NaN NaN\n2000-03-06 NaN NaN NaN\n2000-03-07 NaN NaN NaN\n']], ['how to forward fill non-null values in a pandas dataframe based on a set condition'], 3, 0], [(22083378, 1), [['Now you can use  where  to change these to 2:'], ['Edit: it may be faster to use a trick here with cumsum:']], [[' In [12]: df.where(df.replace(0, np.nan).bfill(), 2)\nOut[12]:\n            a  b  c\n2000-03-02  0  0  0\n2000-03-03  0  0  1\n2000-03-04  0  1  1\n2000-03-05  1  2  2\n2000-03-06  2  2  2\n2000-03-07  2  2  2\n']], ['how to forward fill non-null values in a pandas dataframe based on a set condition'], 3, 0], [(22118136, 0), [['The simplest, nltk-ish way to do this is with  nltk.ngrams() .'], ['If you want to ignore punctuation in the window size, you can strip it before scanning:']], [[' words = nltk.corpus.brown.words()\nk = 5\nfor ngram in nltk.ngrams(words, 2*k+1, pad_left=True, pad_right=True, pad_symbol=" "):\n    if ngram[k+1].lower() == "settle":\n        print(" ".join(ngram))\n']], ['NLTK: Find contexts of size 2k for a word'], 2, 1], [(22118136, 1), [['If you want to ignore punctuation in the window size, you can strip it before scanning:'], ['-10000']], [[' words = (w for w in nltk.corpus.brown.words() if re.search(r"\\w", w))\n']], ['NLTK: Find contexts of size 2k for a word'], 2, 0], [(22119987, 0), [['After getting the maximum, you can check each key of their values. This comprehension list returns a list of keys where the value associated if the same as  aiMove2 .'], ["Here's an example in Python shell:"]], [[' keys = [x for x,y in posValueD.items() if y == posValueD[aiMove2]]\n']], ['Returning all keys that have the same corresponding value in a dictionary with python'], 2, 1], [(22119987, 1), [["Here's an example in Python shell:"], ['-10000']], [[" >>> a = {'a':1, 'b':2, 'c':2}\n>>> [x for x,y in a.items() if y == 2]\n['c', 'b']\n"]], ['Returning all keys that have the same corresponding value in a dictionary with python'], 2, 1], [(22122385, 0), [['-10000'], ["This isn't actually using any special feature of regex, it's using  string formatting . Multiple strings can be passed in as:"]], [[" r1 = re.compile(r'SO ON')\nr2 = re.compile(r'WHATEVER AND (%s)*' % r1.pattern)\n"]], ['Nested Regular Expression in Python for'], 2, 1], [(22122385, 1), [["This isn't actually using any special feature of regex, it's using  string formatting . Multiple strings can be passed in as:"], ['-10000']], [[" r'WHATEVER AND (%s) (%s)' % (r1.pattern, 'hello')\n"]], ['Nested Regular Expression in Python for'], 2, 1], [(22134243, 0), [['You could loop directly over  str1  and add indices with the  enumerate()  function . You need to  add  the  len(str2)  result to  i  to find the endpoint, and make it print out the test; I used  ==  here as the resulting slice should be the  same string :'], ['Demo:']], [[' for i, char in enumerate(str1):\n    if str2[0] == char:\n        print("found first instance of letter at,", i)\n        print(str2 == str1[i:i + len(str2)])\n']], ["Recreating builtin s.find('substring') function"], 2, 1], [(22134243, 1), [['Demo:'], ['-10000']], [[' >>> str1 = \'my best test ever!\'\n>>> str2 = \'best\'\n>>> for i, char in enumerate(str1):\n...     if str2[0] == char:\n...         print("found first instance of letter at, ", i)\n...         print(str2 == str1[i:i + len(str2)])\n... \nfound first instance of letter at,  3\nTrue\n']], ["Recreating builtin s.find('substring') function"], 2, 1], [(22158110, 0), [['You can first install easy_install (which is part of set up tools) from the following location'], ['Once that is complete and you have added the scripts to your path variable (C...Python2.7..scripts), you can install pip using ']], [[' https://pypi.python.org/pypi/setuptools#windows\n']], ['How do I install pip in python 2.7?'], 2, 0], [(22158110, 1), [['Once that is complete and you have added the scripts to your path variable (C...Python2.7..scripts), you can install pip using '], ['Check out this video for more help.']], [[' easy_install pip\n']], ['How do I install pip in python 2.7?'], 2, 0], [(22161088, 0), [["Lastly, since it's not necessary to rename the .pages file to .zip — the filename you pass ZipFile()  can have any extension — I removed all that from the code. However, to overcome the limitation on extracting members to a different subdirectory, I had to add code to first extract the target member to a temporary directory, and then copy that to the final destination. Afterwards, of course, this temporary folder needs to deleted. So I'm not sure the net result is much simpler..."], ["Bonus:  If you'd like to actually view the final pdf file from the script, you can add the following function and use it on the final pdf created (assuming you have a PDF viewer application installed on your system):"]], [[' import os.path\nimport shutil\nimport sys\nimport tempfile\nfrom zipfile import ZipFile\n\nPREVIEW_PATH = \'QuickLooks/Preview.pdf\'  # archive member path\npages_file = input(\'Enter the path to the .pages file in question: \')\n#pages_file = r\'C:\\Stack Overflow\\extract_test.pages\'  # hardcode for testing\npages_file = os.path.abspath(pages_file)\nfilename, file_extension = os.path.splitext(pages_file)\nif file_extension == ".pages":\n    tempdir = tempfile.gettempdir()\n    temp_filename = os.path.join(tempdir, PREVIEW_PATH)\n    with ZipFile(pages_file, \'r\') as zipfile:\n        zipfile.extract(PREVIEW_PATH, tempdir)\n    if not os.path.isfile(temp_filename):  # extract failure?\n        sys.exit(\'unable to extract {} from {}\'.format(PREVIEW_PATH, pages_file))\n    final_PDF = filename + \'.pdf\'\n    shutil.copy2(temp_filename, final_PDF)  # copy and rename extracted file\n    # delete the temporary subdirectory created (along with pdf file in it)\n    shutil.rmtree(os.path.join(tempdir, os.path.split(PREVIEW_PATH)[0]))\n    print(\'Check out the PDF! It\\\'s located at "{}".\'.format(final_PDF))\n    #view_file(final_PDF)  # see Bonus below\nelse:\n    sys.exit(\'Sorry, that isn\\\'t a .pages file.\')\n']], ['How to extract a file within a folder within a zip?'], 2, 1], [(22161088, 1), [["Bonus:  If you'd like to actually view the final pdf file from the script, you can add the following function and use it on the final pdf created (assuming you have a PDF viewer application installed on your system):"], ['-10000']], [[' import subprocess\ndef view_file(filepath):\n    subprocess.Popen(filepath, shell=True).wait()\n']], ['How to extract a file within a folder within a zip?'], 2, 0], [(22214949, 0), [['-10000'], ['or']], [[' ["{0:03}".format(i) for i in range(121)]\n']], ['Generate numbers with 3 digits'], 3, 1], [(22214949, 1), [['or'], ['To print:']], [[' ["%03d" % i for i in range(121)]\n']], ['Generate numbers with 3 digits'], 3, 1], [(22214949, 2), [['To print:'], ['-10000']], [[' print "\\n".join(<either of the above expressions>)\n']], ['Generate numbers with 3 digits'], 3, 0], [(22221858, 0), [["You can use  datetimes 's  strptime()  function to convert the string to a valid  datetime :"], ["and later compare it to  now 's  time() :"]], [[" >>>d=datetime.datetime.strptime('15:30','%H:%M')\n"]], ['Compare string in format HH:MM to time now in python'], 2, 0], [(22221858, 1), [["and later compare it to  now 's  time() :"], ["You can read also doc's  strftime() and strptime() Behavior  which explained these methods and have a very good table resuming the  directives  to parse dates."]], [[' >>>dnow=datetime.datetime.now()  #11:42 am here ;)\n>>>dnow.time() < d.time()\nTrue\n']], ['Compare string in format HH:MM to time now in python'], 2, 0], [(22281406, 0), [['Batch File:'], ['dropScript.py:']], [[' python "dropScript.py" %*\npause\n']], ['Python drag and drop, get filenames'], 2, 0], [(22328160, 0), [['You may want to look at the  datetime  module. Using its date formatting functions, you can do something like this:'], ['In your function, you can use these as follows:']], [[' >>> import datetime as dt\n>>> ds = \'0104160F\'\n>>> parsed = dt.datetime.strptime(ds, "%y%m%d0F")\n>>> parsed\ndatetime.datetime(2001, 4, 16, 0, 0)    \n>>> reformatted = dt.datetime.strftime(parsed, "%Y-%m-%d")\n>>> reformatted\n\'20010416\'\n']], ['python string to date ISO 8601'], 2, 1], [(22328160, 1), [['In your function, you can use these as follows:'], ['-10000']], [[' def YYMMDD0FtoYYYYMMDD(date):\n    return dt.datetime.strftime(dt.datetime.strptime(date, "%y%m%d0F"), "%Y-%m-%d")\n']], ['python string to date ISO 8601'], 2, 1], [(22332069, 0), [['-10000'], ['Output:']], [[' from io import StringIO\nfrom collections import OrderedDict\n\ndatastring = StringIO(u"""\\\n# row = 0\n9501.7734375\n9279.390625\n8615.1640625\n# row = 1\n4396.1953125\n4197.1796875\n3994.4296875\n# row = 2\n9088.046875\n8680.6953125\n8253.0546875\n""")      \n\ncontent = datastring.readlines()\nout = OrderedDict()\nfinal = []\n\nfor line in content:\n    if line.startswith(\'# row\'):\n        header = line.strip(\'\\n#\')\n        out[header] = []\n    elif line not in out[header]:\n        out[header].append(line.strip(\'\\n\'))\n\n\nfor k, v in out.iteritems():\n    temp = (k + \',\' + \',\'.join([str(item) for item in v])).split(\',\')\n    final.append(temp)\n\nfinal = zip(*final)\nwith open("C:/temp/output.csv", \'w\') as fout:\n    for item in final:\n    fout.write(\'\\t\'.join([str(i) for i in item]))\n']], ['Python convert single column of data into multiple columns'], 2, 1], [(22332069, 1), [['Output:'], ['-10000']], [['  row = 0         row = 1        row = 2\n9501.7734375    4396.1953125    9088.046875\n9279.390625     4197.1796875    8680.6953125\n8615.1640625    3994.4296875    8253.0546875\n']], ['Python convert single column of data into multiple columns'], 2, 0], [(22346807, 0), [["I've been using the option"], ['where /tmp is the wheelhouse. This seems to actually check the wheelhouse and not re-download things. Using your example, try this:']], [['     --find-links=/tmp\n']], ['How to avoid rebuilding existing wheels when using pip?'], 2, 0], [(22346807, 1), [['where /tmp is the wheelhouse. This seems to actually check the wheelhouse and not re-download things. Using your example, try this:'], ['-10000']], [['     pip wheel --find-links=/tmp --wheel-dir=/tmp Cython==0.19.2\n']], ['How to avoid rebuilding existing wheels when using pip?'], 2, 1], [(22362010, 0), [["There's probably a more efficient way, (and you could write this much more readably) but you could always do something like:"], ['-10000']], [[' import pandas as pd\n\norg = [\'doclist[0]\', \'doclist[0]\', \'doclist[1]\', \'doclist[4]\', \'doclist[4]\']\nnp = [0, 1, 1, 1, 0]\npr = [0, 0, 0, 0, 1]\ndf = pd.DataFrame({\'Organization\':org, \'NP\':np, \'Pr\':pr})\n\n# Make a "lookup" dataframe of the sums for each category\n# (Both the "NP" and "Pr" colums of "sums" will contain the result)\nsums = df.groupby(\'Organization\').agg(lambda x: x[\'NP\'].sum() + x[\'Pr\'].sum())\n\n# Lookup the result based on the contents of the "Organization" row\ndf[\'Sum\'] = df.apply(lambda row: sums.ix[row[\'Organization\']][\'NP\'], axis=1)\n']], ['Using groupby to operate only on rows that have the same value for one of the columns pandas python'], 2, 1], [(22362010, 1), [['-10000'], ["Incidentally, @DSM's looks like a much better way to do this."]], [[' import pandas as pd\n\norg = [\'doclist[0]\', \'doclist[0]\', \'doclist[1]\', \'doclist[4]\', \'doclist[4]\']\nnp = [0, 1, 1, 1, 0]\npr = [0, 0, 0, 0, 1]\ndf = pd.DataFrame({\'Organization\':org, \'NP\':np, \'Pr\':pr})\n\n# Make a "lookup" dataframe of the sums for each category\nlookup = df.groupby(\'Organization\').agg(lambda x: x[\'NP\'].sum() + x[\'Pr\'].sum())\n\n# Lookup the result based on the contents of the "Organization" row\n# The "lookup" dataframe will have the relevant sum in _both_ "NP" and "Pr"\ndef func(row):\n    org = row[\'Organization\']\n    group_sum = lookup.ix[org][\'NP\']\n    return group_sum\ndf[\'Sum\'] = df.apply(func, axis=1)\n']], ['Using groupby to operate only on rows that have the same value for one of the columns pandas python'], 2, 1], [(22384398, 0), [['Rather than passing the parameter named as  field , you can use dictionary unpacking to use the  value of   field  as the name of the parameter:'], ['Using a mock of  update_by_email :']], [[' request = update_by_email(email, **{field: field_value})\n']], ['Using variable as keyword passed to **kwargs in Python'], 4, 1], [(22384398, 1), [['Using a mock of  update_by_email :'], ['When I call ']], [[' def update_by_email(email=None, **kwargs):\n    print(kwargs)\n']], ['Using variable as keyword passed to **kwargs in Python'], 4, 0], [(22384398, 2), [['When I call '], ['I see that  kwargs  inside  update_by_email  is ']], [[' update_field("joe@me.com", "name", "joe")\n']], ['Using variable as keyword passed to **kwargs in Python'], 4, 0], [(22384398, 3), [['I see that  kwargs  inside  update_by_email  is '], ['-10000']], [[" {'name': 'joe'}\n"]], ['Using variable as keyword passed to **kwargs in Python'], 4, 0], [(22394350, 0), [["This will parse all the inputs you wrote using regex, but remember that arithmetic operations are generated by a context-free grammar, so you won't found a regex (only valid for regular languages) that match all existing operations (like  (3*(3*2))*(3*1) ,  (3*(3*(3*2)))*(3*1)  and so on), you will need to build different ones."], ['The outputs here are:']], [[' import re\n\nparser1 = re.compile("[0-9]\\\\*?$")\nparser3 = re.compile("\\\\([0-9]\\\\*[0-9]\\\\)$")\nparser4 = re.compile("(\\\\([0-9]\\\\*[0-9]\\\\)|[0-9])\\\\*(\\\\([0-9]\\\\*[0-9]\\\\)|[0-9])$")\n\ndef validity(s):\n    valid = False\n\n    # Condition 1 and 2\n    if parser1.match(s):\n        return True\n    # Condition 3\n    if parser3.match(s):\n        return True\n    # Condition 4\n    if parser4.match(s):\n        return True\n\n    return False\n\nprint validity(\'1\') # Condition 1\nprint validity(\'9\') # Condition 1\nprint validity(\'10\') # Doesn\'t satisfy any of the conditions\nprint validity(\'1*\') # Condition 2\nprint validity(\'4*\') # Condition 2\nprint validity(\'9*\') # Condition 2\nprint validity(\'10*\') # Doesn\'t satisfy any of the conditions\nprint validity(\'(3*4)\') # Condition 3\nprint validity(\'(3*9)\') # Condition 3\nprint validity(\'(4*9)\') # Condition 3\nprint validity(\'(10*9)\') # Doesn\'t satisfy any of the conditions\nprint validity(\'(3*2)*(3*1)\') # Condition 4\nprint validity(\'(3*2)*8\') # Condition 4\nprint validity(\'(3*2)*z\') # Doesn\'t satisfy any of the conditions\n']], ['Validity of a string based on some conditions'], 2, 1], [(22394350, 1), [['The outputs here are:'], ['-10000']], [[' True\nTrue\nFalse\nTrue\nTrue\nTrue\nFalse\nTrue\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n']], ['Validity of a string based on some conditions'], 2, 0], [(22404273, 0), [['Just transform your geometries using ST_Transform ( http://postgis.org/docs/ST_Transform.html )'], ['If you want to transfrom a whole table do:']], [['  ST_Transform(geom,4326)\n']], ['EPSG:900913 to WGS 84 projection'], 2, 1], [(22425626, 0), [['Either use a non-greedy quantifier, like this:'], ['Or a character class, like this:']], [[" re.search('\\[(.*?)\\]', html_template)\n"]], ['Python - re - need help for regular expression'], 2, 1], [(22425626, 1), [['Or a character class, like this:'], ['And use  re.findall  to get all matching sub strings.']], [[" re.search('\\[([^\\]]*)\\]', html_template)\n"]], ['Python - re - need help for regular expression'], 2, 1], [(22462728, 0), [['-10000'], ['prints:']], [[' # -*- coding: utf-8 -*-\nfrom bs4 import BeautifulSoup\n\nbody = """\n<a href="http://good.com" target="_blank">good link</a>\n<ul>\n                    <li class="FOLLOW">\n                        <a href="http://bad.com" target="_blank">\n                            <em></em>\n                            <span>\n                                <strong class="FOLLOW-text">Follow On</strong>\n                                <strong class="FOLLOW-logo"></strong>\n                            </span>\n                        </a>\n                    </li>\n</ul>\n\n"""\n\nsoup = BeautifulSoup(body, \'html.parser\')\n\nlinks = soup.find_all(\'a\')\nfor link in links:\n    link = link.replace_with(\'<can_be_link>\')\n\nprint soup.prettify(formatter=None)\n']], ['Analyze and edit links in html code with BeautifulSoup'], 2, 1], [(22462728, 1), [['prints:'], ['Note the import statement - use the 4th  BeautifulSoup  version since  Beautiful Soup 3 is no longer being developed, and that Beautiful Soup 4 is recommended for all new projects.']], [[' <can_be_link>\n<ul>\n <li class="FOLLOW">\n  <can_be_link>\n </li>\n</ul>\n']], ['Analyze and edit links in html code with BeautifulSoup'], 2, 0], [(22484903, 0), [['I think what you want is:'], ['Your current pseudocode appears to be for  swapping  the items at  start  and  end , which is not what your example shows. If you did want to do this, you could do:']], [[' def reverse_sublist(lst, start, end):\n    lst[start:end] = reversed(lst[start:end])\n']], ['Replacing two elements of a list in place with a function [python 3]'], 5, 1], [(22484903, 2), [['-10000'], ['The result this gives is not the  [5, 2, 3, 4, 1]  you are expecting:']], [[' def test(lst, start, end):\n    lst.insert(start+1, lst[start])\n    lst.insert(end+1, lst[end])\n    print(lst)\n    lst[start] = lst[end+1]\n    lst[end] = lst[start+1]\n    print(lst)\n    del lst[start+1]\n    del lst[end+1]\n    print(lst)\n']], ['Replacing two elements of a list in place with a function [python 3]'], 5, 0], [(22484903, 3), [['The result this gives is not the  [5, 2, 3, 4, 1]  you are expecting:'], ['Instead, you would have to do the  insert  and swap on  end+2  and  end+1  to account for the extra item from the  insert  at  start+1 :']], [[' >>> test([1, 2, 3, 4, 5], 0, 4)\n[1, 1, 2, 3, 4, 4, 5] # after insert\n[4, 1, 2, 3, 1, 4, 5] # after swap\n[4, 2, 3, 1, 4] # after del\n']], ['Replacing two elements of a list in place with a function [python 3]'], 5, 0], [(22484903, 4), [['Instead, you would have to do the  insert  and swap on  end+2  and  end+1  to account for the extra item from the  insert  at  start+1 :'], ['-10000']], [[' def test(lst, start, end):\n    lst.insert(start+1, lst[start])\n    lst.insert(end+2, lst[end+1])\n    lst[start], lst[end+1] = lst[end+2], lst[start+1]\n    del lst[start+1]\n    del lst[end+1]\n']], ['Replacing two elements of a list in place with a function [python 3]'], 5, 1], [(22509908, 1), [['A more general approach would be to define a function decorator to attach the property:'], ['-10000']], [[' def remembercalltimes(f, *args, **kwargs):\n    """A decorator to help a function remember when it was last called."""\n    def inner(*args, **kwargs):\n        inner.last_called = datetime.now()\n        return f(*args, **kwargs)\n    return inner\n\n@remembercalltimes\ndef myfun():\n    # … do things\n\n>>> myfun()\n>>> myfun.last_called\n>>> datetime.datetime(2014, 3, 19, 11, 47, 5, 784833)\n']], ['Checking if function was not called for x amount of time'], 2, 1], [(22518000, 0), [['Python code:'], ['To speedup even more, you can use cython:']], [[' def dijkway2(dijkpredmat, i, j):\n    wayarr = []\n    while (i != j) & (j >= 0):\n        wayarr.append(j)\n        j = dijkpredmat.item(i,j)\n    return wayarr\n\ndef jumpvec2(pmat,node):\n    jumps = np.zeros(len(pmat))\n    jumps[node] = -999\n    todo = set()\n    for i in range(len(pmat)):\n        if i != node:\n            todo.add(i)\n\n    indexs = np.arange(len(pmat), 0, -1)\n    while todo:\n        r = todo.pop()\n        dway = dijkway2(pmat, node, r)\n        jumps[dway] = indexs[-len(dway):]\n        todo -= set(dway)\n    return jumps\n']], ["Calculate number of jumps in Dijkstra's algorithm?"], 4, 1], [(22518000, 1), [['To speedup even more, you can use cython:'], ['Here is my test, the cython version is 80x faster:']], [[' import numpy as np\ncimport numpy as np\nimport cython\n\n@cython.wraparound(False)\n@cython.boundscheck(False)\ncpdef dijkway3(int[:, ::1] m, int i, int j):\n    cdef list wayarr = []\n    while (i != j) & (j >= 0):\n        wayarr.append(j)\n        j = m[i,j]\n    return wayarr\n\n@cython.wraparound(False)\n@cython.boundscheck(False)\ndef jumpvec3(int[:, ::1] pmat, int node):\n    cdef np.ndarray jumps\n    cdef int[::1] jumps_buf\n    cdef int i, j, r, n\n    cdef list dway\n    jumps = np.zeros(len(pmat), int)\n    jumps_buf = jumps\n    jumps[node] = -999\n\n    for i in range(len(jumps)):\n        if jumps_buf[i] != 0:\n            continue\n        r = i\n        dway = dijkway3(pmat, node, r)\n        n = len(dway)\n        for j in range(n):\n            jumps_buf[<int>dway[j]] = n - j\n    return jumps\n']], ["Calculate number of jumps in Dijkstra's algorithm?"], 4, 1], [(22518000, 2), [['Here is my test, the cython version is 80x faster:'], ['output:']], [[' %timeit jumpvec3(pmat,1)\n%timeit jumpvec2(pmat, 1)\n%timeit jumpvec(pmat, 1)\n']], ["Calculate number of jumps in Dijkstra's algorithm?"], 4, 0], [(22518000, 3), [['output:'], ['-10000']], [[' 1000 loops, best of 3: 138 µs per loop\n100 loops, best of 3: 2.81 ms per loop\n100 loops, best of 3: 10.8 ms per loop\n']], ["Calculate number of jumps in Dijkstra's algorithm?"], 4, 0], [(22520948, 0), [['Change your script so it looks like this and your python script runs in the background saving its output to a temporary file  $$.tmp  where  $$  is your process id (pid):'], ['Now add the following lines at the end, so that you 1) create a script that tails your log file, 2) make it executable and 3) you execute it:']], [[' export PATH=${PATH}:/usr/local/bin:/usr/local/CrossPack-AVR/bin\ncd /Applications/MyApp\n/Applications/MyApp/doIt.py "$1" > $$.tmp &\n']], ['How to view stdout of script run within automator'], 2, 0], [(22520948, 1), [['Now add the following lines at the end, so that you 1) create a script that tails your log file, 2) make it executable and 3) you execute it:'], ['I would recommend renaming  x.command  as  $$.command  so that you can run it multiple times from multiple users without interactions between the various users. You should also clean up and delete the temporary files after use.']], [[' echo "tail -f $$.tmp" > x.command\nchmod +x x.command\nopen x.command\n']], ['How to view stdout of script run within automator'], 2, 0], [(22534983, 0), [["The idea is to find all  facultyMember  items and use python's list slicing:"], ['prints:']], [[' from xml.etree import ElementTree as ET\n\n\ndata = """<Faculty>\n    <facultyMember>\n        <FirstName>A</FirstName>\n    </facultyMember>\n    <facultyMember>\n        <FirstName>B</FirstName>\n    </facultyMember>\n    <facultyMember>\n        <FirstName>C</FirstName>\n    </facultyMember>\n    <facultyMember>\n        <FirstName>D</FirstName>\n    </facultyMember>\n    <facultyMember>\n        <FirstName>E</FirstName>\n    </facultyMember>\n    <facultyMember>\n        <FirstName>F</FirstName>\n    </facultyMember>\n    <facultyMember>\n        <FirstName>G</FirstName>\n    </facultyMember>\n    <facultyMember>\n        <FirstName>H</FirstName>\n    </facultyMember>\n\n</Faculty>"""\n\ntree = ET.fromstring(data)\nbegin, end = 3, 6\n\nfor element in tree.findall(\'.//facultyMember\')[begin - 1: end]:\n    print ET.tostring(element).strip()\n']], ['Get Nodes from xml by specifying limit'], 2, 1], [(22534983, 1), [['prints:'], ['-10000']], [[' <facultyMember>\n        <FirstName>C</FirstName>\n    </facultyMember>\n<facultyMember>\n        <FirstName>D</FirstName>\n    </facultyMember>\n<facultyMember>\n        <FirstName>E</FirstName>\n    </facultyMember>\n<facultyMember>\n        <FirstName>F</FirstName>\n    </facultyMember>\n']], ['Get Nodes from xml by specifying limit'], 2, 0], [(22535316, 0), [['I sniffed a session to log into that site using Fiddler and found that the POST is made to a different URL, but it has that JSESSIONID cookie set. So you need to make a get to the URL first, capture that cookie using the cookiehandler, then POST to this URL: '], ["You don't need to save the HTTP GET request at all, you can simply call opener.open(url), then in your code change the response line to this:"]], [[" post_url = 'http://www.broadinstitute.org/cmap/j_security_check'\n"]], ['How to log in to a website with urllib?'], 3, 0], [(22535316, 1), [["You don't need to save the HTTP GET request at all, you can simply call opener.open(url), then in your code change the response line to this:"], ["Also the payload was missing the submit method. Here's the whole thing with the changes I suggest:"]], [[' response = opener.open(post_url, binary_data)\n']], ['How to log in to a website with urllib?'], 3, 0], [(22535316, 2), [["Also the payload was missing the submit method. Here's the whole thing with the changes I suggest:"], ['Any other requests using the opener you created will re-use that cookie and you should be able to freely navigate the site.']], [[" import http.cookiejar\nimport urllib\n\nget_url = 'http://www.broadinstitute.org/cmap/index.jsp'\npost_url = 'http://www.broadinstitute.org/cmap/j_security_check'\n\nvalues = urllib.parse.urlencode({'j_username': <MYCOOLUSERNAME>,\n          'j_password': <MYCOOLPASSSWORD>,\n          'submit': 'sign in'})\npayload = bytes(values, 'ascii')\ncj = http.cookiejar.CookieJar()\nopener = urllib.request.build_opener(\n    urllib.request.HTTPRedirectHandler(),\n    urllib.request.HTTPHandler(debuglevel=0),\n    urllib.request.HTTPSHandler(debuglevel=0),\n    urllib.request.HTTPCookieProcessor(cj))\n\nopener.open(get_url) #First call to capture the JSESSIONID\nresp = opener.open(post_url, payload)\nresp_html = resp.read()\nresp_headers = resp.info()\n"]], ['How to log in to a website with urllib?'], 3, 1], [(22567247, 0), [["I haven't dug through your code yet, but from your description I assume your pseudo-code is like this:"], ["I'd suggest changing your strategy to be like this:"]], [[' if GO_TO_MAX_SPEED_CONDITION:\n    while NOT_AT_MAX_SPEED:\n        ACCELERATE\n']], ['Need help detecting a change in a variable outside of a while loop'], 3, 0], [(22567247, 1), [["I'd suggest changing your strategy to be like this:"], ["then at each iteration of your program, you'd have something like this:"]], [[' if GO_TO_MAX_SPEED_CONDITION:\n    GO_TO_MAX_SPEED = True\nif STOP_GOING_TO_MAX_SPEED_CONDITION:\n    GO_TO_MAX_SPEED = False\n']], ['Need help detecting a change in a variable outside of a while loop'], 3, 0], [(22567247, 2), [["then at each iteration of your program, you'd have something like this:"], ['-10000']], [[' if GO_TO_MAX_SPEED and NOT_AT_MAX_SPEED:\n    ACCELERATE\n']], ['Need help detecting a change in a variable outside of a while loop'], 3, 0], [(22576924, 0), [['What I would do is invert the logic a bit. In PACKAGE/__init__.py. Something like:'], ['Then just:']], [[" def get_apps():\n    apps = (\n        'apps.store',\n        'apps.other',\n        ...\n    )\n    return [__name__ + '.' + x for x in apps]\n"]], ['building reusable package in django'], 2, 0], [(22576924, 1), [['Then just:'], ['in settings.py. I do this quite a bit to keep our settings.py manageable and it seems to work quite well.']], [[' INSTALLED_APPS += get_apps()\n']], ['building reusable package in django'], 2, 0], [(22591297, 0), [['Use  params  as you mentioned:'], ['Use  fixture finalization  if you want to do fixture specific finalization:']], [[" @pytest.fixture(scope='module', params=[load_dataset1, load_dataset2])\ndef data(request):\n    loader = request.param\n    dataset = loader()\n    return dataset\n"]], ['Run same test on multiple datasets'], 2, 1], [(22591297, 1), [['Use  fixture finalization  if you want to do fixture specific finalization:'], ['-10000']], [[" @pytest.fixture(scope='module', params=[load_dataset1, load_dataset2])\ndef data(request):\n    loader = request.param\n    dataset = loader()\n    def fin():\n        # finalize dataset-related resource\n        pass\n    request.addfinalizer(fin)\n    return dataset\n"]], ['Run same test on multiple datasets'], 2, 1], [(22616944, 0), [['Iterate over  pycountry.countries  and initialize a mapping  name -> short name  ( alpha2 , or  alpha3 ):'], ['For the file containing:']], [[" mapping = {country.name: country.alpha2 for country in pycountry.countries}\nfor column in csv_file:\n    print column['name'], mapping.get(column['name'], 'No country found')\n"]], ['Convert Country Names to Country Code using Python DictReader/DictWriter'], 3, 1], [(22616944, 1), [['For the file containing:'], ['it prints:']], [[' name\nKazakhstan\nUkraine\n']], ['Convert Country Names to Country Code using Python DictReader/DictWriter'], 3, 0], [(22616944, 2), [['it prints:'], ['-10000']], [[' Kazakhstan KZ\nUkraine UA\n']], ['Convert Country Names to Country Code using Python DictReader/DictWriter'], 3, 0], [(22649851, 0), [['-10000'], ['The first two are by far the most common. If you want to limit the possibilities to just those three, you could do:']], [[" >>> re.sub('(?<![\\r\\n])(\\r?\\n|\\n?\\r)(?![\\r\\n])', ' ', s)\n'foo\\n\\nbar one two three\\n\\n\\nhello'\n"]], ['Best way of removing single newlines but keeping multiple newlines'], 2, 1], [(22657498, 0), [['Update:   Since Python 2.7.9  you could  pass SSLContext that specifies TLS protocol  to  urlopen()  function:'], ['-10000']], [[" import ssl\nimport urllib2\n\ncontext = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n# other settings (see ssl.create_default_context() implementation)\nurllib2.urlopen('https://example.com', context=context).close()\n"]], ['I want to choose the Transport Layer Security protocol in urllib2'], 2, 1], [(22668427, 0), [['Example: consider you have a  source.txt  with the following contents:'], ['Then, in your python script, you can load the JSON data structure into the python dictionary by using  json.load() :']], [[' {"hello": "world"}\n']], ['How do you read in a text (.txt) file as a .py file in Python 2.7?'], 6, 0], [(22668427, 2), [['prints:'], ['-10000']], [[" {u'hello': u'world'}\n"]], ['How do you read in a text (.txt) file as a .py file in Python 2.7?'], 6, 0], [(22668427, 3), [['-10000'], ['your script:']], [[' d = {"hello": "world"}\n']], ['How do you read in a text (.txt) file as a .py file in Python 2.7?'], 6, 0], [(22668427, 5), [['prints:'], ['Hope that helps.']], [[" {'hello': 'world'}\n"]], ['How do you read in a text (.txt) file as a .py file in Python 2.7?'], 6, 0], [(22672340, 0), [['How about using  bytearray :'], ['In your case, coming from a csv reader, something like']], [[" bytearray([222,7])\nOut[15]: bytearray(b'\\xde\\x07')\n\nstruct.unpack('H', bytearray([222,7]))\nOut[16]: (2014,)\n"]], ['(Python) Formatting strings for struct.unpack?'], 2, 1], [(22674166, 0), [['Wrappers is sexy'], ['Result']], [[' import sys\n\nclass Logger(file):\n    def __init__(self,*a,**kw):\n        # copy original stdout to instance\n        self.stdout = sys.stdout\n        return super(Logger,self).__init__(*a,**kw)\n\n    def write(self,data):\n        self.stdout.write(data) # to screen\n        return super(Logger,self).write(data) #to file\n\n    def writelines(self,lines):\n        for line in lines: self.write(line)\n\n    def close(self):\n        # return it back\n        sys.stdout = self.stdout\n\n\n\nsome_list = [\'elem1\', \'elem2\']\n\nfor elem in some_list:\n    with Logger("/tmp/1/{}.log".format(elem), "w") as sys.stdout:\n    # Do lots of stuff that print messages.\n        print \'lots of stuff for\', elem\n\n\n\nprint \'Code finished\'\n']], ['Store all stdout to file while still displaying it on screen'], 3, 1], [(22674166, 1), [['Result'], ['Cool side effect:']], [[' $ python2 out.py \nCode finished\n$ ls\nelem1.log  elem2.log  out.py\n']], ['Store all stdout to file while still displaying it on screen'], 3, 0], [(22674166, 2), [['Cool side effect:'], ['-10000']], [[' print \'this on screen\'\n\nwith Logger("/tmp/1/main.log", "w") as sys.stdout:\n     print \'this on screen an in main.log\'\n\n     with Logger("/tmp/1/sub.log", "w") as sys.stdout:\n          print \'this on screen, in man.log and in sub.log\'\n\nprint \'only on screen again\'\n']], ['Store all stdout to file while still displaying it on screen'], 3, 0], [(22693260, 0), [['Using  join  command:'], ["or if you don't want to pipe to  sed , you can do (a little more verbose) by setting the output format: "]], [[" $ join -t\\; -j 1 file1 file2 | sed 's/;;/;/g'\nDATE;BS-ICI,NSA,BAL,AT;BS-ICI,NSA,BAL,BE;BS-BYL,NSA,BAL,AT;BS-NAN,NSA,BAL,BE;\n2014M02;0.9;1.5;1.5;6.7;\n2014M01;-5.4;-4.4;-8.8;-4.4;\n2013M11;-7.9;-9.2;-2.5;-9.6;\n2013M10;-8.6;-14.0;-8.9;-11.4;\n"]], ['append csv files on column basis'], 2, 1], [(22693260, 1), [["or if you don't want to pipe to  sed , you can do (a little more verbose) by setting the output format: "], ['-10000']], [[' $ join -t\\; -j 1 -o 1.1 1.2 1.3 2.2 2.3 2.4 file1 file2 \nDATE;BS-ICI,NSA,BAL,AT;BS-ICI,NSA,BAL,BE;BS-BYL,NSA,BAL,AT;BS-NAN,NSA,BAL,BE;\n2014M02;0.9;1.5;1.5;6.7;\n2014M01;-5.4;-4.4;-8.8;-4.4;\n2013M11;-7.9;-9.2;-2.5;-9.6;\n2013M10;-8.6;-14.0;-8.9;-11.4;\n']], ['append csv files on column basis'], 2, 1], [(22694038, 0), [['Presuming a reasonable setup:'], ['use  sqlalchemy.func.coalesce() :']], [[' import sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass Product(Base):\n    __tablename__ = "product"\n    id = sa.Column(sa.Integer, primary_key=True)\n    actual = sa.Column(sa.String)\n    target = sa.Column(sa.String)\n']], ['SQLAlchemy (sql) conditional query'], 3, 0], [(22696168, 0), [['You could wrap your script in a'], ['block, or with a bash script:']], [[' while True:\n    ...\n']], ['How to restart a python script after it finishes'], 2, 1], [(22696168, 1), [['block, or with a bash script:'], ['-10000']], [[' while true ; do\n    yourpythonscript.py\ndone\n']], ['How to restart a python script after it finishes'], 2, 1], [(22700457, 0), [['Use a sorting key:'], ['Demo:']], [[' sorted(yourdict, key=lambda k: int(k.split()[0]))\n']], ['Sort Python Dictionary by first four characters in Key'], 5, 1], [(22700457, 1), [['Demo:'], ['Sorting both keys and values together:']], [[" >>> yourdict = {'666 -> 999': 4388, '4000 -> 4332': 4383, '1333 -> 1665': 7998, '5666 -> 5999': 4495, '3666 -> 3999': 6267, '3000 -> 3332': 9753, '6333 -> 6665': 7966, '0 -> 332': 877}\n>>> sorted(yourdict, key=lambda k: int(k.split()[0]))\n['0 -> 332', '666 -> 999', '1333 -> 1665', '3000 -> 3332', '3666 -> 3999', '4000 -> 4332', '5666 -> 5999', '6333 -> 6665']\n"]], ['Sort Python Dictionary by first four characters in Key'], 5, 1], [(22700457, 2), [['Sorting both keys and values together:'], ['This produces key-value pairs:']], [[' sorted(yourdict.items(), key=lambda item: int(item[0].split()[0]))\n']], ['Sort Python Dictionary by first four characters in Key'], 5, 1], [(22700457, 3), [['This produces key-value pairs:'], ['You could produce an  collections.OrderedDict()  object  with that:']], [[" >>> sorted(yourdict.items(), key=lambda item: int(item[0].split()[0]))\n[('0 -> 332', 877), ('666 -> 999', 4388), ('1333 -> 1665', 7998), ('3000 -> 3332', 9753), ('3666 -> 3999', 6267), ('4000 -> 4332', 4383), ('5666 -> 5999', 4495), ('6333 -> 6665', 7966)]\n"]], ['Sort Python Dictionary by first four characters in Key'], 5, 1], [(22700457, 4), [['You could produce an  collections.OrderedDict()  object  with that:'], ['-10000']], [[" >>> from collections import OrderedDict\n>>> OrderedDict(sorted(yourdict.items(), key=lambda item: int(item[0].split()[0])))\nOrderedDict([('0 -> 332', 877), ('666 -> 999', 4388), ('1333 -> 1665', 7998), ('3000 -> 3332', 9753), ('3666 -> 3999', 6267), ('4000 -> 4332', 4383), ('5666 -> 5999', 4495), ('6333 -> 6665', 7966)])\n"]], ['Sort Python Dictionary by first four characters in Key'], 5, 1], [(22727800, 0), [['You need to ensure that both json does not escape characters, and you write your json output as unicode:'], ['As for your second question: you can use  collections.OrderedDict , but you need to be careful to pass it directly to  json.dumps  without changing it to simple dict. See the difference:']], [[' import codecs\nimport json\n\nwith codecs.open(\'tmp.json\', \'w\', encoding=\'utf-8\') as f:\n    f.write(json.dumps({u\'hello\' : u\'привет!\'}, ensure_ascii=False) + \'\\n\')\n\n\n$ cat tmp.json\n{"hello": "привет!"}\n']], ['How do I sort objects inside of objects in JSON? (using Python 2.7)'], 2, 0], [(22727800, 1), [['As for your second question: you can use  collections.OrderedDict , but you need to be careful to pass it directly to  json.dumps  without changing it to simple dict. See the difference:'], ['-10000']], [[' from collections import OrderedDict\ndata = OrderedDict(zip((\'first\', \'second\', \'last\'), (1, 10, 3)))\nprint json.dumps(dict(data)) # {"second": 10, "last": 3, "first": 1}\nprint json.dumps(data) # {"first": 1, "second": 10, "last": 3}\n']], ['How do I sort objects inside of objects in JSON? (using Python 2.7)'], 2, 1], [(22739971, 0), [['Return a tuple, and negate the number instead of using  reverse :'], ['Demo:']], [[' list_name.sort(key=lambda x: (-x[2],) + x[:2])\n']], ['Organize Numerically Descending then Alphabetically Ascending by Different Elements in a List Python'], 2, 1], [(22741040, 0), [['You can use  itertools.product  like this'], ['Output']], [[" from itertools import product\nnames = [('Bob', 'Tom'), ('GreenWood', 'Pearson')]\nfor item in product(*names):\n    print(item)\n"]], ['How to make unique combinations of the following list of tuples'], 4, 1], [(22741040, 1), [['Output'], ['If you wanted to print the possible names as string, then you can join the result like this']], [[" ('Bob', 'GreenWood')\n('Bob', 'Pearson')\n('Tom', 'GreenWood')\n('Tom', 'Pearson')\n"]], ['How to make unique combinations of the following list of tuples'], 4, 0], [(22741040, 3), [['This will produce'], ['-10000']], [[' Bob GreenWood\nBob Pearson\nTom GreenWood\nTom Pearson\n']], ['How to make unique combinations of the following list of tuples'], 4, 0], [(22750555, 0), [['-10000'], ['As for mock_open patching:']], [[" import unittest.mock as mock\n\nmock_argparse = mock.Mock()\nwith mock.patch.dict('sys.modules', argparse=mock_argparse):\n    import argparse\n    print(argparse.ArgumentParser()) \n# <Mock name='mock.ArgumentParser()' id='140681471282448'>\n"]], ['python mock patch top level packages'], 2, 0], [(22750555, 1), [['As for mock_open patching:'], ['It seems like it creates  __main__.open  attribute with mock object which shadows the built-in version as if you defined  open()  function in your module. I suppose for the actual tests you should patch  module_x.open()  where "module_x" is the module that actually calls  open() .']], [[" m = mock_open()\nwith patch('__main__.open', m, create=True):\n"]], ['python mock patch top level packages'], 2, 0], [(22769503, 0), [['Use  //encryption[text()!="WPA-PSK"]/text()  xpath:'], ['prints:']], [[' from lxml import etree\n\ndata = """\n<detection-run>\n    <wireless-network>\n        <SSID>\n            <encryption>WEP</encryption>\n        </SSID>\n    </wireless-network>\n    <wireless-network>\n        <SSID>\n            <encryption>WPA-PSK</encryption>\n        </SSID>\n    </wireless-network>\n    <wireless-network>\n        <SSID>\n            <encryption>WPA2-PSK</encryption>\n        </SSID>\n    </wireless-network>\n</detection-run>\n"""\n\nroot = etree.fromstring(data)\nprint root.xpath(\'//encryption[text()!="WPA-PSK"]/text()\')\n']], ['Selecting text nodes with text not equal to a value'], 2, 1], [(22769503, 1), [['prints:'], ['-10000']], [[" ['WEP', 'WPA2-PSK']\n"]], ['Selecting text nodes with text not equal to a value'], 2, 0], [(22775168, 0), [["First turn the  date  column in  number  (I'll call it df) and  datelist  into  datetime64  columns. I'll assume the date column in  numbers  is already of type  datetime64 :"], ['And in  datelist , I will create a new column that is a  datetime64  type (note I changed that dates in datelist so not all of the  dates  in the  number  dataframe were less than all the dates in  datelist  and I made  datelist  have less observations to reduce the size of the output):']], [[' print df\n        date   group  number   \n0 2013-02-01  group1  -0.098765\n1 2013-02-02  group2   0.519878\n2 2013-02-03  group1  -0.098765\n3 2013-02-04  group3   1.960784\n4 2013-02-05  group3   2.859412\n5 2013-02-06  group2   1.960784\n6 2013-02-07  group1  -0.696594\n']], ['Pandas -- how to iterate through a list of dates which filter a DataFrame'], 3, 0], [(22775168, 1), [['And in  datelist , I will create a new column that is a  datetime64  type (note I changed that dates in datelist so not all of the  dates  in the  number  dataframe were less than all the dates in  datelist  and I made  datelist  have less observations to reduce the size of the output):'], ['Now, I will just loop the rows of datelist and create a new dataframe each time through out of the rows where  date <= end :']], [[" parse = lambda x: datetime(int(x[0]),int(x[1]),int(x[2]))\ndatelist['end'] = datelist['date'].str.split(',').apply(parse)\nprint datelist \n\n        date        end\n0  2013, 2,3 2013-02-03\n1  2013, 2,6 2013-02-06\n2  2013, 3,6 2013-03-06\n3  2013, 3,8 2013-03-08\n"]], ['Pandas -- how to iterate through a list of dates which filter a DataFrame'], 3, 0], [(22775168, 2), [['Now, I will just loop the rows of datelist and create a new dataframe each time through out of the rows where  date <= end :'], ["I concatenated the dataframes but you can process them by doing a groupby on 'end'."]], [[" pieces = []\nfor idx,rows in datelist[['end']].iterrows():\n  x = df[df['date'] <= rows['end']]\n  x['end'] = rows['end']\n  pieces.append(x)\n\nprint pd.concat(pieces,ignore_index=True)\n\n          date   group  number           end\n0  2013-02-01  group1  -0.098765 2013-02-03\n1  2013-02-02  group2   0.519878 2013-02-03\n2  2013-02-03  group1  -0.098765 2013-02-03\n3  2013-02-01  group1  -0.098765 2013-02-06\n4  2013-02-02  group2   0.519878 2013-02-06\n5  2013-02-03  group1  -0.098765 2013-02-06\n6  2013-02-04  group3   1.960784 2013-02-06\n7  2013-02-05  group3   2.859412 2013-02-06\n8  2013-02-06  group2   1.960784 2013-02-06\n9  2013-02-01  group1  -0.098765 2013-03-06\n10 2013-02-02  group2   0.519878 2013-03-06\n11 2013-02-03  group1  -0.098765 2013-03-06\n12 2013-02-04  group3   1.960784 2013-03-06\n13 2013-02-05  group3   2.859412 2013-03-06\n14 2013-02-06  group2   1.960784 2013-03-06\n15 2013-02-07  group1  -0.696594 2013-03-06\n16 2013-02-01  group1  -0.098765 2013-03-08\n17 2013-02-02  group2   0.519878 2013-03-08\n18 2013-02-03  group1  -0.098765 2013-03-08\n19 2013-02-04  group3   1.960784 2013-03-08\n20 2013-02-05  group3   2.859412 2013-03-08\n21 2013-02-06  group2   1.960784 2013-03-08\n22 2013-02-07  group1  -0.696594 2013-03-08\n"]], ['Pandas -- how to iterate through a list of dates which filter a DataFrame'], 3, 0], [(22827317, 0), [['Knowing this you can simply combine ButtonBehavior with any other widget you choose. Eg.'], ['This would be as simple as changing the source to animated gif or list of images inside a .zip.']], [[' from kivy.base import runTouchApp\nfrom kivy.lang import Builder\n\nkv = \'\'\'\n<ButImage@ButtonBehavior+AsyncImage>\n\nFloatLayout:\n    # we don\'t specify anything here so float layout takes the entire size of the window.\n    ButImage:\n        id: but\n        # take 50% size of the FloatLayout\n        size_hint: .5, .5\n        # Make Button change it\'s opacity when pressed for visual indication\n        opacity: 1 if self.state == \'normal\' else .5\n        source: \'http://www.victoriamorrow.com/sitebuildercontent/sitebuilderpictures/enter_button.gif\'\n        # Introduce Label incase you want text on top of the image\n        Label:\n            center: but.center\n            # change text acc to but state\n            text: "Normal" if but.state == \'normal\' else \'down\'\n\'\'\'\n\nif __name__ == \'__main__\':\n    runTouchApp(Builder.load_string(kv))\n']], ['Changing background of a Button to a different shape and Styles like shadow effect etc in kivy python'], 2, 0], [(22856566, 0), [['With scrapy  Selector  and  SelectorList  you can  use regular expressions via their  .re()  method :'], ['Alternative using the new CSS selectors:']], [[' >>> hxs.xpath(\'//td[contains(., "Phone")]/following-sibling::td[1]\').re(r\'(\\d[\\d ]+\\d)\')\n[u\'020 641512\']\n>>> \n']], ['XPATH: If there is element with certain value assume "phone" then get it\'s sibling value'], 2, 1], [(22856566, 1), [['Alternative using the new CSS selectors:'], ['-10000']], [[' >>> from scrapy.selector import Selector\n>>> selector = Selector(response)\n>>> selector.css(\'td:contains("Phone") + td\').re(r\'(\\d[\\d ]+\\d)\')\n[u\'020 641512\']\n>>> \n']], ['XPATH: If there is element with certain value assume "phone" then get it\'s sibling value'], 2, 1], [(22880882, 0), [['You can get all 2 spans with  metrics-authority  class, first one is a  Domain Authority , second one is a  Page Authority . Additionally, you can get  Root Domains  from the  div  with  id="metrics-page-link-metrics" :'], ['prints:']], [[' import urllib2\nfrom lxml import html\n\ntree = html.parse(urllib2.urlopen(\'http://www.opensiteexplorer.org/links?site=www.google.com\'))\n\nspans = tree.xpath(\'//span[@class="metrics-authority"]\')\ndata = [item.text.strip() for item in spans]\nprint "Domain Authority: {0}, Page Authority: {1}".format(*data)\n\ndiv = tree.xpath(\'//div[@id="metrics-page-link-metrics"]//div[@class="has-tooltip"]\')[1]\nprint "Root Domains: {0}".format(div.text.strip())\n']], ['How can I get certain text from a website with Python?'], 2, 1], [(22880882, 1), [['prints:'], ['Hope that helps. ']], [[' Domain Authority: 100, Page Authority: 97 \nRoot Domains: 680\n']], ['How can I get certain text from a website with Python?'], 2, 0], [(22893271, 0), [['Here is a recursive implementation'], ['Or']], [[' def recursive_sum(l1, l2, idx = 0):\n    if idx < min(len(l1), len(l2)):\n        return [l1[idx] + l2[idx]] + recursive_sum(l1, l2, idx + 1)\n    else:\n        return []\n\nprint recursive_sum([1, 2, 3], [4, 5, 6])\n# [5, 7, 9]\n']], ['sum two lists element-by-element in python recursively'], 2, 1], [(22893271, 1), [['Or'], ['-10000']], [[' def recursive_sum(l1, l2, result = None, idx = 0):\n    if result is None:\n        result = []\n    if idx < min(len(l1), len(l2)):\n        result.append(l1[idx] + l2[idx])\n        return recursive_sum(l1, l2, result, idx + 1)\n    else:\n        return result\n']], ['sum two lists element-by-element in python recursively'], 2, 1], [(22897195, 1), [['Note that in general this is better posed as a multi-index'], ['-10000']], [[" In [6]: df.index = MultiIndex.from_product([['a','b'],[1,2]])\n\nIn [7]: df\nOut[7]: \n     a  b\na 1  4  1\n  2  2  3\nb 1  4  5\n  2  6  7\n\n[4 rows x 2 columns]\n\nIn [8]: df.loc['a']\nOut[8]: \n   a  b\n1  4  1\n2  2  3\n\n[2 rows x 2 columns]\n\nIn [9]: df.loc[['a']]\nOut[9]: \n     a  b\na 1  4  1\n  2  2  3\n\n[2 rows x 2 columns]\n"]], ['Selecting rows with similar index names in Pandas'], 2, 1], [(22912351, 0), [['To get lines that are common to all files you can use:'], ['For the second part use  itertools.combinations :']], [[' for f in sys.argv[1:]:\n    data = []\n    with open(f) as inp:\n           lines = set(line.rstrip() for line in  inp)\n           data.append(lines)\n    common_lines = data[0].intersection(*data[1:])\n']], ['Intersection between multiple files'], 2, 0], [(22912351, 1), [['For the second part use  itertools.combinations :'], ['-10000']], [[' from itertools import combinations\n\nfor f1, f2 in combinations(sys.argv[1:], 2):\n    with open(f1) as inp1, open(f2) as inp2:\n        print set(line.rstrip() for line in inp1).intersection(map(str.rstrip,\n                                                                           inp2))\n']], ['Intersection between multiple files'], 2, 0], [(22912598, 1), [['I also had to change the figtext location:'], ['Result:']], [[" plt.figtext(0.0,0.85,'(a)',size=20)\nplt.figtext(0.0,0.45,'(b)',size=20)\n"]], ['How to resize subfigures when using ImageGrid from Matplotlib'], 2, 0], [(22920023, 1), [['To get the directory from that:'], ['-10000']], [[' os.path.dirname(__file__)\n']], ['Query current directory in Python (the one the script is running from)'], 3, 1], [(22920023, 2), [['-10000'], ['os.getcwd documentation']], [[' os.getcwd()\n']], ['Query current directory in Python (the one the script is running from)'], 3, 1], [(22953550, 0), [['You can group the elements with the list comprehension and then transpose it with  zip  function, like this'], ['Till this point we grouped the data like this']], [[' data = [15, 20, 25, 35, -20, -15, -10, -5, 10, 15, 20,\n        25, -25, -20, -15, -10, 5, 10, 15, 20, -35, -25, -20, -15]\nlength = len(data) / 3\ndata = [data[i:i + length] for i in xrange(0, len(data), length)]\n']], ['python list manipulation nesting vertically, making it look like a matrix'], 5, 0], [(22953550, 1), [['Till this point we grouped the data like this'], ['Now, we just have to transpose  data , with  zip']], [[' [[15, 20, 25, 35, -20, -15, -10, -5],\n [10, 15, 20, 25, -25, -20, -15, -10],\n [5, 10, 15, 20, -35, -25, -20, -15]]\n']], ['python list manipulation nesting vertically, making it look like a matrix'], 5, 0], [(22953550, 2), [['Now, we just have to transpose  data , with  zip'], ['Output']], [[' print zip(*data)\n']], ['python list manipulation nesting vertically, making it look like a matrix'], 5, 0], [(22953550, 3), [['Output'], ['zip(*data)  means we unpack all the elements of  data  and pass each of the elements as parameters to  zip . It is equivalent to']], [[' [(15, 10, 5),\n (20, 15, 10),\n (25, 20, 15),\n (35, 25, 20),\n (-20, -25, -35),\n (-15, -20, -25),\n (-10, -15, -20),\n (-5, -10, -15)]\n']], ['python list manipulation nesting vertically, making it look like a matrix'], 5, 0], [(22953550, 4), [['zip(*data)  means we unpack all the elements of  data  and pass each of the elements as parameters to  zip . It is equivalent to'], ['-10000']], [[' zip(data[0], data[1], data[2])\n']], ['python list manipulation nesting vertically, making it look like a matrix'], 5, 0], [(22959268, 0), [['Sort your  init_treats  keys:'], ['now you can use  itertools.groupby()  to group them on the first part of your key:']], [[' treats = sorted(init_treats)\n']], ['Loop through multiple different sized python dictionaries'], 3, 0], [(22959268, 1), [['now you can use  itertools.groupby()  to group them on the first part of your key:'], ['You could use a dictionary for a O(N + K) solution (K being the size of the  init_untreats  dictionary):']], [[' from itertools import groupby\nfrom operator import itemgetter\n\nfor untreat, group in groupby(sorted(init_treats), itemgetter(0)):\n    # group is now a sorted iterator of keys with the same first value\n    if init_untreat[untreat] + sum(map(init_treats.get, group)) == 0:\n        # sum of init_treat_n_m + init_untreat_n is 0\n']], ['Loop through multiple different sized python dictionaries'], 3, 0], [(22961541, 0), [['You can get a nice result using a  coo_matrix ,  plot()  and some adjustments:'], ['Note that the  y  axis is inverted to put the first row at the top of the figure. One example:']], [[" import matplotlib.pyplot as plt\nfrom scipy.sparse import coo_matrix\n\ndef plot_coo_matrix(m):\n    if not isinstance(m, coo_matrix):\n        m = coo_matrix(m)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, axisbg='black')\n    ax.plot(m.col, m.row, 's', color='white', ms=1)\n    ax.set_xlim(0, m.shape[1])\n    ax.set_ylim(0, m.shape[0])\n    ax.set_aspect('equal')\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    ax.invert_yaxis()\n    ax.set_aspect('equal')\n    ax.set_xticks([])\n    ax.set_yticks([])\n    return ax\n"]], ['python matplotlib plot sparse matrix pattern'], 2, 1], [(22961541, 1), [['Note that the  y  axis is inverted to put the first row at the top of the figure. One example:'], ['']], [[' import numpy as np\nfrom scipy.sparse import coo_matrix\n\nshape = (100000, 100000)\nrows = np.int_(np.round_(shape[0]*np.random.random(1000)))\ncols = np.int_(np.round_(shape[1]*np.random.random(1000)))\nvals = np.ones_like(rows)\n\nm = coo_matrix((vals, (rows, cols)), shape=shape)\nax = plot_coo_matrix(m)\nax.figure.show()\n']], ['python matplotlib plot sparse matrix pattern'], 2, 0], [(23008799, 0), [['I would use a dictionary to hold the values for each character:'], ['Then iterate through all ASCII uppercase characters, printing either the calculated values or e.g.  "N is empty..."']], [[" a = [('X', '63.658'), ('Y', '21.066'), ...]\n\nprocessed = {}\n\nfor char, value in data:\n    if char not in processed:\n        processed[char] = []\n    processed[char].append(value)\n"]], ['How to Search data from a list of Key-Value pair that it is in list or not'], 3, 0], [(23008799, 1), [['Then iterate through all ASCII uppercase characters, printing either the calculated values or e.g.  "N is empty..."'], ['You could simplify slightly with  collections.defaultdict :']], [[' import string\n\nfor char in string.ascii_uppercase:\n    if char not in processed:\n        print("{0} is empty...".format(char))\n    else:\n        print("{0}: min={1}, max={2}".format(char, \n                                             min(processed[char]),\n                                             max(processed[char])))\n']], ['How to Search data from a list of Key-Value pair that it is in list or not'], 3, 0], [(23008799, 2), [['You could simplify slightly with  collections.defaultdict :'], ['Generally, I would suggest breaking up your program a bit - separate the import of tuple data from a text file into one function, and processing the list into another. This makes it easier to develop and test each in isolation.']], [[' from collections import defaultdict\n\nprocessed = defaultdict(list)\n\nfor char, value in data:\n    processed[char].append(value)\n']], ['How to Search data from a list of Key-Value pair that it is in list or not'], 3, 0], [(23024861, 0), [['I would consider a folder structure like this:'], ["To import a specific model, view, form etc. you'll just do:"]], [[' myproject\n-> task\n----> models\n--------> __init__.py\n--------> base.py\n--------> math.py\n--------> etc.\n----> views\n--------> __init__.py\n--------> math.py\n--------> etc.\n----> urls\n--------> __init__.py\n--------> etc.\n-> check\n----> models\n--------> __init__.py\n--------> base.py\n--------> etc.\n\n-etc.- (you get the idea)\n']], ['Inherit/Extend Django Module or cram into same Module?'], 3, 0], [(23025497, 0), [['Using scipy, you could characterize such points as those which are both the maximum and the minimum of its neighborhood:'], ['Using only numpy, you could compare  data  with 8 shifted slices of itself to find the points which are equal:']], [[" import numpy as np\nimport scipy.ndimage.filters as filters\n\ndef using_filters(data):\n    return np.where(np.logical_and.reduce(\n        [data == f(data, footprint=np.ones((3,3)), mode='constant', cval=np.inf)\n         for f in (filters.maximum_filter, filters.minimum_filter)]))  \n\nusing_filters(data)\n# (array([2, 3]), array([5, 9]))\n"]], ['Retrieve position of elements with setting some criteria in numpy'], 5, 1], [(23025497, 1), [['Using only numpy, you could compare  data  with 8 shifted slices of itself to find the points which are equal:'], ['Using eight shifts (and comparisons) is much faster than looping over each cell in  data  and comparing it against its neighbors:']], [[' def using_eight_shifts(data):\n    h, w = data.shape\n    data2 = np.empty((h+2, w+2))\n    data2[(0,-1),:] = np.nan\n    data2[:,(0,-1)] = np.nan\n    data2[1:1+h,1:1+w] = data\n\n    result = np.where(np.logical_and.reduce([\n        (data2[i:i+h,j:j+w] == data)\n        for i in range(3)\n        for j in range(3)\n        if not (i==1 and j==1)]))\n    return result\n']], ['Retrieve position of elements with setting some criteria in numpy'], 5, 1], [(23025497, 2), [['Using eight shifts (and comparisons) is much faster than looping over each cell in  data  and comparing it against its neighbors:'], ['Here is a benchmark:']], [[' def using_quadratic_loop(data):\n    return np.array([[i,j]\n            for i in range(1,np.shape(data)[0]-1)\n            for j in range(1,np.shape(data)[1]-1)\n            if np.all(data[i-1:i+2,j-1:j+2]==data[i,j])]).T\n']], ['Retrieve position of elements with setting some criteria in numpy'], 5, 1], [(23025497, 3), [['Here is a benchmark:'], ['-10000']], [[' using_filters            : 0.130\nusing_eight_shifts       : 0.340\nusing_quadratic_loop     : 18.794\n']], ['Retrieve position of elements with setting some criteria in numpy'], 5, 0], [(23039188, 0), [['What you have written will work, but you are overwriting the value in the assignment, since you repeat  var . Instead, collect the results in a list:'], ['You can further simplify it by using a list comprehension:']], [[" def post(self):\n    var_list = ['var1', 'var2']\n    result_list = []\n    for var in var_list:\n        result_list.append(self.request.get(var))\n    return result_list # etc.\n"]], ['Using a string as a variable name'], 2, 1], [(23039188, 1), [['You can further simplify it by using a list comprehension:'], ['-10000']], [[" def post(self):\n    return [self.request.get(var) for var in ['var1', 'var2']]\n"]], ['Using a string as a variable name'], 2, 1], [(23039664, 1), [["However, there's lot of unnecessary code in your function. You should write it as"], ['-10000']], [[" def to_str(lst):\n    if not lst:\n        return ''\n    return str(lst[0]) + to_str(lst[1:])\n"]], ['Covert a list to string'], 2, 1], [(23046827, 0), [['For example:'], ["Here's some sample output:"]], [[" import random\nresults = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0}\nfor count in range(6000000):\n    die = random.randint(1, 6)\n    results[die] += 1\n\nprint('Here are the results:')\n# Loop over the *keys* of the dictionary, which are the die numbers\nfor die in results:\n    # The format(..., ',d') function formats a number with thousands separators\n    print(die, '=', format(results[die], ',d'))\n# Sum up all the die results and print them out\nprint('Total rolls equal:', sum(results.values()))\n"]], ['how to format numbers with commas in python'], 2, 1], [(23046827, 1), [["Here's some sample output:"], ['Note that for this simple example, we could also use a  list  to store the results. However, because of the index translation between zero-indexing and one-indexing, the code would be less clear.']], [[' Here are the results:\n1 = 1,000,344\n2 = 1,000,381\n3 = 999,903\n4 = 999,849\n5 = 1,000,494\n6 = 999,029\nTotal rolls equal: 6000000\n']], ['how to format numbers with commas in python'], 2, 0], [(23047215, 0), [['Demo:'], ['which gives you:']], [[' html = \'\'\'<li class="nv-talk"><a href="/wiki/Template_talk:Data_structures" title="Template talk:Data structures"><span title="Discuss this    template" style=";;background:none    transparent;border:none;;">t</span></a></li>    \'\'\'\nsoup = BeautifulSoup(html)\na_tag = soup.find(\'a\')\na_tag.find_parents(attrs={\'class\':\'nv-talk\'})\n']], ['Webcrawler - Check if <a> tag with href is within an li tag using Beautiful soup?'], 3, 1], [(23047215, 1), [['which gives you:'], ["Another way to go about this problem would be to see if the  href  attribute of the anchor tag begins with 'http' or 'https'. But I am not entirely sure if it fits the logic of your code. What I mean by this is, anchor tags with  href  attributes that begin with  #  are links to sections within the same page. If you need to ignore these you can look for anchor tags that do not begin with  #  but instead begin with  http  or  https . This is what I mean:"]], [[' [<li class="nv-talk"><a href="/wiki/Template_talk:Data_structures" title="Template talk:Data    structures"><span style=";;background:none transparent;border:none;;"    title="Discuss this template">t</span></a></li>]\n']], ['Webcrawler - Check if <a> tag with href is within an li tag using Beautiful soup?'], 3, 0], [(23047215, 2), [["Another way to go about this problem would be to see if the  href  attribute of the anchor tag begins with 'http' or 'https'. But I am not entirely sure if it fits the logic of your code. What I mean by this is, anchor tags with  href  attributes that begin with  #  are links to sections within the same page. If you need to ignore these you can look for anchor tags that do not begin with  #  but instead begin with  http  or  https . This is what I mean:"], ['This gives you only the link that begins with http.']], [[' html = \'\'\'\n<li class="toclevel-1 tocsection-1"><a href="#Overview"><span class="tocnumber">1</span> <span class="toctext">Overview</span></a></li>\n<li class="toclevel-1 tocsection-1"><a href="http://www.google.com"><span class="tocnumber">1</span> <span class="toctext">Overview</span></a></li>\n<li class="toclevel-1 tocsection-1"><a href="#Overview"><span class="tocnumber">1</span> <span class="toctext">Overview</span></a></li>\n\'\'\'\nsoup = BeautifulSoup(html)\na_tag = soup.find(\'a\', attrs={\'href\': re.compile(r\'^http.*\')})\n']], ['Webcrawler - Check if <a> tag with href is within an li tag using Beautiful soup?'], 3, 1], [(23059398, 0), [['Try this  ,'], ['OR']], [[' >>> a\n[[1, 2, 3], [4, 5, 6]]\n>>> result=[]\n>>> for i in a:\n    result+=i\n\n\n>>> result\n[1, 2, 3, 4, 5, 6]\n>>>\n']], ['How to merge item in list'], 5, 1], [(23059398, 1), [['OR'], ['Output:']], [[' >>> a\n[[1, 2, 3], [4, 5, 6]]\n>>> sum(a, [])\n']], ['How to merge item in list'], 5, 1], [(23059398, 2), [['Output:'], ['OR']], [[' [1, 2, 3, 4, 5, 6]\n']], ['How to merge item in list'], 5, 0], [(23059398, 3), [['OR'], ['Output:']], [[' >>> a1\n[1, 2, 3]\n>>> a2\n[4, 5, 6]\n>>> [item for item in itertools.chain(a1, a2)]\n']], ['How to merge item in list'], 5, 1], [(23059398, 4), [['Output:'], ['-10000']], [[' [1, 2, 3, 4, 5, 6]\n']], ['How to merge item in list'], 5, 0], [(23100704, 0), [['Sample example using threading:'], ['-10000']], [[" from threading import Thread\n\nclass myClassA(Thread):\n    def __init__(self):\n        Thread.__init__(self)\n        self.daemon = True\n        self.start()\n    def run(self):\n        while True:\n            print 'A'\n\nclass myClassB(Thread):\n    def __init__(self):\n        Thread.__init__(self)\n        self.daemon = True\n        self.start()\n    def run(self):\n        while True:\n            print 'B'\n\n\nmyClassA()\nmyClassB()\nwhile True:\n    pass\n"]], ['Running infinite loops using threads in python'], 2, 1], [(23100704, 1), [['-10000'], ['-10000']], [[' from threading import Thread\n\ndef runA():\n    while True:\n        print \'A\\n\'\n\ndef runB():\n    while True:\n        print \'B\\n\'\n\nif __name__ == "__main__":\n    t1 = Thread(target = runA)\n    t2 = Thread(target = runB)\n    t1.setDaemon(True)\n    t2.setDaemon(True)\n    t1.start()\n    t2.start()\n    while True:\n        pass\n']], ['Running infinite loops using threads in python'], 2, 1], [(23114734, 0), [['Code:  '], ['Testing:  I first created a file named as  frequencyList.txt  with the following contents:']], [[' from nltk.corpus import wordnet\n\nfList = open("frequencyList.txt","r")#Read the file\nlines = fList.readlines()\n\neWords = open("eng_words_only.txt", "a")#Open file for writing\n\nfor w in lines:\n    if not wordnet.synsets(w):#Comparing if word is non-English\n        print \'not \'+w\n    else:#If word is an English word\n        print \'yes \'+w\n        eWords.write(w)#Write to file \n\neWords.close()#Close the file\n']], ['how to remove all non english characters and words using NLTK >'], 4, 1], [(23114734, 1), [['Testing:  I first created a file named as  frequencyList.txt  with the following contents:'], ["then upon executing the code snippet you'll see the following output in the console:"]], [[' cat \nmeoooow \nmouse\n']], ['how to remove all non english characters and words using NLTK >'], 4, 0], [(23114734, 2), [["then upon executing the code snippet you'll see the following output in the console:"], ['wordlist-eng.txt ,  frequencyList.txt  and the python script in the same directory.']], [[' not cat\n\nnot meoooow\n\nyes mouse\n']], ['how to remove all non english characters and words using NLTK >'], 4, 0], [(23147735, 0), [['You could do it as:'], ['The problem is that you are modifying your list while iterating through it. If you want to use that kind of loop structure, do it as this instead:']], [[' my_new_list = [i for i in myList if i.count(None) < 4]\n\n[OUTPUT]\n[[3, 4, None, None, None]]\n']], ['Python: How to remove a list containing Nones from a list of lists?'], 2, 1], [(23147735, 1), [['The problem is that you are modifying your list while iterating through it. If you want to use that kind of loop structure, do it as this instead:'], ['-10000']], [[' i = 0\nwhile i < len(myList):\n    if(myList[i].count(None) >= 4):\n        del myList[i]\n    else:\n        i += 1\n']], ['Python: How to remove a list containing Nones from a list of lists?'], 2, 1], [(23177075, 0), [['Try this:'], ['And the output:']], [[' >>> for values in List:\n...     print (" ".join([chars for chars in values]), "\\n")\n']], ['Printing a list into grid'], 2, 1], [(23177075, 1), [['And the output:'], ['-10000']], [[' a a a a a a a a a\n\nb b b b b b b b b\n\nc c c c c c c c c\n']], ['Printing a list into grid'], 2, 0], [(23206062, 0), [["After you added the rest of the code, I'm slightly confused by your way of representing rows and columns so here is how I would write the code (if I was approaching the problem like you did); hope it helps:"], ['And as for the  print_board  function:']], [[' def _new_game_board() -> [[str]]:\n    """\n    Creates a new game board.  Initially, a game board has the size\n    BOARD_COLUMNS x BOARD_ROWS and is comprised only of strings with the\n    value NONE\n    """\n\n    return [[None] * BOARD_COLUMNS for _ in range(BOARD_ROWS)]\n\nConnectFourGameState = namedtuple(\'ConnectFourGameState\', [\'board\', \'turn\'])\n\ndef new_game_state() -> ConnectFourGameState:\n    """\n    Returns a ConnectFourGameState representing a brand new game\n    in which no moves have been made yet.\n    """\n\n    return ConnectFourGameState(board=_new_game_board(), turn=RED)\n']], ['Printing a two dimensional list'], 2, 0], [(23206062, 1), [['And as for the  print_board  function:'], ['-10000']], [[' def print_board(game_state):\n    """Prints the game board given the current game state"""\n\n    print("1 2 3 4 5 6 7")\n    for row in range(BOARD_ROWS):\n        for col in range(BOARD_COLUMNS):\n            if game_state.board[row][col] == connect_four.NONE:\n                print(\'.\', end=\' \')\n            elif game_state.board[row][col] == connect_four.RED:\n                print(\'R\', end=\' \')\n            elif game_state.board[row][col] == connect_four.YELLOW:\n               print(\'Y\', end=\' \')\n\n        print()\n']], ['Printing a two dimensional list'], 2, 1], [(23224696, 1), [['produces'], ['-10000']], [[" {'q': None, 'b': True, 't': True}\n"]], ['Python OptParse combine multiple options'], 2, 0], [(23231840, 0), [['So, for example, if you had a  data  column, and you wanted another column that was the same but with each value multiplied by 3, you could do this in two basic ways. The first is the "cell-by-cell" operation.'], ['The second is the vectorized way:']], [[" df['data_prime'] = df['data'].apply(lambda x: 3*x)\n"]], ["Spreadsheet Manipulation Tricks w/ Python's Pandas"], 7, 1], [(23231840, 1), [['The second is the vectorized way:'], ['-10000']], [[" df['data_prime'] = df['data'] * 3\n"]], ["Spreadsheet Manipulation Tricks w/ Python's Pandas"], 7, 1], [(23231840, 2), [['-10000'], ['Running total :']], [[" df['count'] = pandas.Series(range(len(df))\n"]], ["Spreadsheet Manipulation Tricks w/ Python's Pandas"], 7, 0], [(23231840, 3), [['Running total :'], ['Difference from a scalar  (set the scalar to a particular value in your df if you want):']], [[" df['running total'] = df['data'].cumsum()\n"]], ["Spreadsheet Manipulation Tricks w/ Python's Pandas"], 7, 0], [(23231840, 4), [['Difference from a scalar  (set the scalar to a particular value in your df if you want):'], ['Moving average :']], [[" df['diff'] = scalar - df['data']\n"]], ["Spreadsheet Manipulation Tricks w/ Python's Pandas"], 7, 0], [(23231840, 5), [['Moving average :'], ['If statement :']], [[" df['moving average'] = df['running total'] / df['count'].astype('float')\n"]], ["Spreadsheet Manipulation Tricks w/ Python's Pandas"], 7, 0], [(23231840, 6), [['If statement :'], ['-10000']], [[" df['new column'] = 0\nmask = df['data column'] >= 3\ndf.loc[mask, 'new column'] = 1\n"]], ["Spreadsheet Manipulation Tricks w/ Python's Pandas"], 7, 0], [(23246125, 0), [['The following alternative solution is compatible with  plt.hist()  (and this has the advantage for instance that you can call it after a  pandas.DataFrame.hist() .'], ['This can be used as in:']], [[' import numpy as np\n\ndef bins_labels(bins, **kwargs):\n    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n    plt.xlim(bins[0], bins[-1])\n']], ['How to center labels in histogram plot'], 2, 1], [(23248583, 0), [['The prediction generated by this model should be exactly'], ['Thus, if you want to sum several models, e.g.']], [[' np.dot(X_test, res_wls.params)\n']], ['How to add regression functions in python, or create a new regression function from given coefficients?'], 3, 0], [(23248583, 2), [['your prediction should be'], ['In this case there would be no need to use the built-in functions of the estimator.']], [[' np.dot(X_test, summed_params)\n']], ['How to add regression functions in python, or create a new regression function from given coefficients?'], 3, 0], [(23271192, 0), [['The metaclass documentation includes a nice  example  of how to get a class to remember what order its members were defined in:'], ['You can adapt this to your case like this:']], [[" class OrderedClass(type):\n\n     @classmethod\n     def __prepare__(metacls, name, bases, **kwds):\n        return collections.OrderedDict()\n\n     def __new__(cls, name, bases, namespace, **kwds):\n        result = type.__new__(cls, name, bases, dict(namespace))\n        result.members = tuple(namespace)\n        return result\n\nclass A(metaclass=OrderedClass):\n    def one(self): pass\n    def two(self): pass\n    def three(self): pass\n    def four(self): pass \n\n\n>>> A.members\n('__module__', 'one', 'two', 'three', 'four')\n"]], ["Find nested sub-classes in a class in the order they're defined"], 4, 1], [(23271192, 1), [['You can adapt this to your case like this:'], ['gives:']], [[' class A:\n    pass\n\nclass B(metaclass=OrderedClass):\n    x = 5\n    class D(A):\n        pass\n    class C(A):\n        pass\n\nprint(filter(lambda x: isinstance(getattr(B, x), type), b.members)))\n']], ["Find nested sub-classes in a class in the order they're defined"], 4, 1], [(23271192, 2), [['gives:'], ['Note that this gives you the names of the classes; if you want the classes themselves, you can do this instead:']], [[" ['D', 'C']\n"]], ["Find nested sub-classes in a class in the order they're defined"], 4, 0], [(23271192, 3), [['Note that this gives you the names of the classes; if you want the classes themselves, you can do this instead:'], ['-10000']], [[' print(list(filter(lambda x: isinstance(x, type), (getattr(B, x) for x in B.members))))\n']], ["Find nested sub-classes in a class in the order they're defined"], 4, 0], [(23297197, 0), [["That's not valid JSON; not all JavaScript is JSON. You could try to convert this to JSON it with:"], ['For your given value, this method works:']], [[' import re\n\ndef repair_json(val):\n    return re.sub(r\'(\\w+):\', r\'"\\1":\', \n                  val.replace(\'"\', \'\\u0022\').replace("\'", \'"\'))\n']], ['reading Unicode string as json object in python'], 3, 1], [(23297197, 1), [['For your given value, this method works:'], ['The  rows  list is a key under the  store  key:']], [[' >>> json.loads(repair_json(v[0]))\n{u\'maxColsVisible\': 100, u\'maxRowsVisible\': 20, u\'hasSearch\': True, u\'parent\': u\'rcJobsGrid_parent\', u\'url\': u\'/jobs/apply/ajax?action=careerCenterBean.jobsGrid.onAJAX&type=METHOD_ACTION\', u\'onPostRenderTable\': u\'if(WFN.getWidget("rcJobsGrid_toolbar_delete")!=null){WFN.getWidget("rcJobsGrid_toolbar_delete").set("useBusy",false);}WFN.handleButtonEnabling("rcJobsGrid", "rcJobsGrid_toolbar_delete");\', u\'widthType\': u\'px\', u\'store\': {u\'maxRowsVisible\': 20, u\'endPosition\': 6, u\'gridId\': u\'rcJobsGrid\', u\'gridExpressionString\': u\'#{careerCenterBean.jobsGrid}\', u\'noDataMessage\': u\'There are currently no jobs available.\', u\'customProperties\': [{u\'value\': u\'false\', u\'key\': u\'USE_DEFAULT_CONFIRM_DELETE_DLG\'}, {u\'value\': u\'0\', u\'key\': u\'OTHER_PAGES_SELECTION_COUNT\'}, {u\'value\': u\'Are you sure you want to delete the selected records?\', u\'key\': u\'TABLE_GRID_DELETE_CONFIRM_MSG\'}], u\'total\': 6, u\'hasPagination\': True, u\'tabIndex\': 0, u\'headerRows\': [{u\'columns\': [{u\'locked\': False, u\'align\': u\'left\', u\'label\': u\'Job Opening\', u\'width\': 300, u\'html\': False, u\'widthType\': u\'px\', u\'sortable\': True, u\'hidden\': False, u\'id\': u\'0\'}, {u\'locked\': False, u\'align\': u\'left\', u\'label\': u\'Worked In Country\', u\'width\': 200, u\'html\': False, u\'widthType\': u\'px\', u\'sortable\': True, u\'hidden\': False, u\'id\': u\'1\'}, {u\'locked\': False, u\'align\': u\'left\', u\'label\': u\'Location\', u\'width\': 225, u\'html\': False, u\'widthType\': u\'px\', u\'sortable\': True, u\'hidden\': False, u\'id\': u\'2\'}, {u\'locked\': False, u\'align\': u\'left\', u\'label\': u\'Date Posted\', u\'width\': 150, u\'html\': False, u\'widthType\': u\'px\', u\'sortable\': True, u\'hidden\': False, u\'id\': u\'3\'}, {u\'locked\': False, u\'align\': u\'left\', u\'label\': u\'Job ID\', u\'width\': 75, u\'html\': False, u\'widthType\': u\'px\', u\'sortable\': True, u\'hidden\': False, u\'id\': u\'4\'}]}], u\'rows\': [{u\'cells\': [{u\'action\': u\'#{careerCenterBean.viewJobPostingDetails}\', u\'align\': u\'left\', u\'type\': u\'LINK\', u\'id\': u\'0\', u\'value\': u\'Research Assistant\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'1\', u\'value\': u\'UNITED STATES\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'2\', u\'value\': u\'Arlington, VA\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'3\', u\'value\': u\'04/16/2014\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'4\', u\'value\': u\'1010\'}], u\'selected\': False, u\'id\': u\'0\', u\'customProperties\': [{u\'value\': u\'46702\', u\'key\': u\'oid\'}]}, {u\'cells\': [{u\'action\': u\'#{careerCenterBean.viewJobPostingDetails}\', u\'align\': u\'left\', u\'type\': u\'LINK\', u\'id\': u\'0\', u\'value\': u\'Research Analyst\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'1\', u\'value\': u\'UNITED STATES\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'2\', u\'value\': u\'Arlington, VA\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'3\', u\'value\': u\'04/16/2014\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'4\', u\'value\': u\'1011\'}], u\'selected\': False, u\'id\': u\'1\', u\'customProperties\': [{u\'value\': u\'46747\', u\'key\': u\'oid\'}]}, {u\'cells\': [{u\'action\': u\'#{careerCenterBean.viewJobPostingDetails}\', u\'align\': u\'left\', u\'type\': u\'LINK\', u\'id\': u\'0\', u\'value\': u\'User Experience Researcher\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'1\', u\'value\': u\'UNITED STATES\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'2\', u\'value\': u\'Arlington, VA\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'3\', u\'value\': u\'04/08/2014\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'4\', u\'value\': u\'1007\'}], u\'selected\': False, u\'id\': u\'2\', u\'customProperties\': [{u\'value\': u\'46467\', u\'key\': u\'oid\'}]}, {u\'cells\': [{u\'action\': u\'#{careerCenterBean.viewJobPostingDetails}\', u\'align\': u\'left\', u\'type\': u\'LINK\', u\'id\': u\'0\', u\'value\': u\'Research Manager\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'1\', u\'value\': u\'UNITED STATES\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'2\', u\'value\': u\'Arlington, VA\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'3\', u\'value\': u\'04/03/2014\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'4\', u\'value\': u\'1004\'}], u\'selected\': False, u\'id\': u\'3\', u\'customProperties\': [{u\'value\': u\'15082\', u\'key\': u\'oid\'}]}, {u\'cells\': [{u\'action\': u\'#{careerCenterBean.viewJobPostingDetails}\', u\'align\': u\'left\', u\'type\': u\'LINK\', u\'id\': u\'0\', u\'value\': u\'Summer Intern\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'1\', u\'value\': u\'UNITED STATES\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'2\', u\'value\': u\'Arlington, VA\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'3\', u\'value\': u\'04/03/2014\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'4\', u\'value\': u\'1008\'}], u\'selected\': False, u\'id\': u\'4\', u\'customProperties\': [{u\'value\': u\'46476\', u\'key\': u\'oid\'}]}, {u\'cells\': [{u\'action\': u\'#{careerCenterBean.viewJobPostingDetails}\', u\'align\': u\'left\', u\'type\': u\'LINK\', u\'id\': u\'0\', u\'value\': u\'All Other Jobs\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'1\', u\'value\': u\'UNITED STATES\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'2\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'3\', u\'value\': u\'04/03/2014\'}, {u\'align\': u\'left\', u\'type\': u\'OUTPUT_TEXT\', u\'id\': u\'4\', u\'value\': u\'1009\'}], u\'selected\': False, u\'id\': u\'5\', u\'customProperties\': [{u\'value\': u\'46530\', u\'key\': u\'oid\'}]}], u\'maxColsVisible\': 100, u\'label\': u\'name\', u\'width\': 950, u\'sortType\': 1, u\'hasSearch\': True, u\'lastSort\': 0, u\'widthType\': u\'px\', u\'transparent\': False, u\'url\': u\'/jobs/apply/ajax?action=careerCenterBean.jobsGrid.onAJAX&type=METHOD_ACTION\', u\'footerRows\': [], u\'startPosition\': 1, u\'identifier\': u\'id\', u\'possibleRowsPerPage\': u\'10, 20, 30\', u\'rowsPerPage\': 20}, u\'possibleRowsPerPage\': [10, 20, 30], u\'hasPagination\': True, u\'customRenderers\': [{u\'toggle\': False, u\'type\': u\'STATUS_PROGRESS_BAR_CUSTOM_TYPE\', u\'renderer\': u\'com.adp.wfn.customrenderers.renderStatusProgressBar\'}], u\'toolbar\': [{u\'iconClass\': u\'\', u\'title\': u\'\', u\'iconClassDisabled\': u\'\', u\'children\': None, u\'value\': u\'\', u\'label\': u\'\', u\'active\': False, u\'onClick\': u\'\', u\'action\': u\'\', u\'id\': u\'_toolbar_add\'}, {u\'iconClass\': u\'\', u\'title\': u\'\', u\'iconClassDisabled\': u\'\', u\'children\': None, u\'value\': u\'\', u\'label\': u\'\', u\'active\': False, u\'onClick\': u\'\', u\'action\': u\'\', u\'id\': u\'_toolbar_delete\'}], u\'timeout\': 30000, u\'hasResizeColumns\': True, u\'transparent\': False, u\'id\': u\'rcJobsGrid\', u\'rowsPerPage\': 20, u\'tabIndex\': 0}\n']], ['reading Unicode string as json object in python'], 3, 0], [(23297197, 2), [['The  rows  list is a key under the  store  key:'], ['To explore structures like these, I find the  pprint.pprint()  function  invaluable.']], [[" for row in data['store']['rows']:\n    print row\n"]], ['reading Unicode string as json object in python'], 3, 0], [(23298460, 0), [['I hope this is not too clever.  TIL boolean indexing does not broadcast, so I had to manually do the broadcasting.  Let me know if anything is unclear.'], ['Then,']], [[' import numpy as np\nA = [1,2,3,4,5]\nB = [50,40,30,20,10]\nC = np.vstack((A,B)) # float so that I can use np.nan\n\ni = np.arange(0, 6, 2)[:, None]\nselections = np.logical_and(A >= i, A < i+2)[None]\n\nD, selections = np.broadcast_arrays(C[:, None], selections)\nD = D.astype(float)     # allows use of nan, and makes a copy to prevent repeated behavior\nD[~selections] = np.nan # exclude these elements from mean\n\nD = np.nanmean(D, axis=-1)\n']], ['Averaging out sections of a multiple row array in Python'], 3, 0], [(23298460, 1), [['Then,'], ['Another way, using  np.histogram  to bin your data.  This may be faster for large arrays, but is only useful for few rows, since a hist must be done with different weights for each row:']], [[' >>> D\narray([[  1. ,   2.5,   4.5],\n       [ 50. ,  35. ,  15. ]])\n']], ['Averaging out sections of a multiple row array in Python'], 3, 0], [(23298460, 2), [['Another way, using  np.histogram  to bin your data.  This may be faster for large arrays, but is only useful for few rows, since a hist must be done with different weights for each row:'], ['-10000']], [[' bins = np.arange(0, 7, 2)     # include the end\nn = np.histogram(A, bins)[0]  # number of columns in each bin\na_mean = np.histogram(A, bins, weights=A)[0]/n\nb_mean = np.histogram(A, bins, weights=B)[0]/n\nD = np.vstack([a_mean, b_mean])\n']], ['Averaging out sections of a multiple row array in Python'], 3, 0], [(23310630, 0), [['The fastest so far:'], ['-10000']], [[' def count_zeros(matrix):\n    total = 0\n    for row in matrix:\n        total += row.count(0)\n    return total\n']], ['Counting elements matching a pattern in a tuple of tuples'], 4, 1], [(23310630, 1), [['-10000'], ['Time comparison:']], [[' def count_zeros_gen(matrix):\n    return sum(row.count(0) for row in matrix)\n']], ['Counting elements matching a pattern in a tuple of tuples'], 4, 1], [(23310630, 2), [['Time comparison:'], ['For the baseline:']], [[' %timeit [item for row in m for item in row].count(0) # OP\n1000000 loops, best of 3: 1.15 µs per loop\n\n%timeit len([item for row in m for item in row if item == 0]) # @thefourtheye\n1000000 loops, best of 3: 913 ns per loop\n\n%timeit sum(row.count(0) for row in m) \n1000000 loops, best of 3: 1 µs per loop\n\n%timeit count_zeros(m)\n1000000 loops, best of 3: 775 ns per loop\n']], ['Counting elements matching a pattern in a tuple of tuples'], 4, 0], [(23310630, 3), [['For the baseline:'], ['-10000']], [[' def f(m): pass\n%timeit f(m)\n10000000 loops, best of 3: 110 ns per loop\n']], ['Counting elements matching a pattern in a tuple of tuples'], 4, 0], [(23312803, 0), [['From numpy you can get the  e  constant with  numpy.e  (or  np.e  if you  import numpy as np )'], ['-10000']], [[' import numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some data.\nx = np.linspace(0, 2, 1000)\ny = x**np.e\n\nplt.loglog(x,y, basex=np.e, basey=np.e)\nplt.show()\n']], ['pyplot: loglog() with base e'], 2, 1], [(23312803, 1), [['-10000'], ['']], [[" import numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\n\nx = np.linspace(1, 4, 1000)\n\ny = x**3\n\nfig, ax = plt.subplots()\n\nax.loglog(x,y, basex=np.e, basey=np.e)\n\ndef ticks(y, pos):\n    return r'$e^{:.0f}$'.format(np.log(y))\n\nax.xaxis.set_major_formatter(mtick.FuncFormatter(ticks))\nax.yaxis.set_major_formatter(mtick.FuncFormatter(ticks))\n\nplt.show()\n"]], ['pyplot: loglog() with base e'], 2, 1], [(23317342, 0), [["I'd do something like the following:"], ['I think that gets you what you want but if you also want to pretty things up and get a City, State, Country column order, you could add the following:']], [[" foo = lambda x: pd.Series([i for i in reversed(x.split(','))])\nrev = df['City, State, Country'].apply(foo)\nprint rev\n\n      0    1        2\n0   HUN  NaN      NaN\n1   ESP  NaN      NaN\n2   GBR  NaN      NaN\n3   ESP  NaN      NaN\n4   FRA  NaN      NaN\n5   USA   ID      NaN\n6   USA   GA      NaN\n7   USA   NJ  Hoboken\n8   USA   NJ      NaN\n9   AUS  NaN      NaN\n"]], ['Pandas Dataframe: split column into multiple columns, right-align inconsistent cell entries'], 2, 1], [(23317342, 1), [['I think that gets you what you want but if you also want to pretty things up and get a City, State, Country column order, you could add the following:'], ['-10000']], [[" rev.rename(columns={0:'Country',1:'State',2:'City'},inplace=True)\nrev = rev[['City','State','Country']]\nprint rev\n\n     City State Country\n0      NaN   NaN     HUN\n1      NaN   NaN     ESP\n2      NaN   NaN     GBR\n3      NaN   NaN     ESP\n4      NaN   NaN     FRA\n5      NaN    ID     USA\n6      NaN    GA     USA\n7  Hoboken    NJ     USA\n8      NaN    NJ     USA\n9      NaN   NaN     AUS\n"]], ['Pandas Dataframe: split column into multiple columns, right-align inconsistent cell entries'], 2, 0], [(23323675, 0), [['Nope, you either have to flatten like this'], ['Or']], [[' print([item for lang in languages_list for item in [lang.code] + list(lang.alt)])\n']], ['Returning a list in each iteration using list comprehension'], 2, 1], [(23323675, 1), [['Or'], ["I would prefer the  itertools.chain  method, since it doesn't have to create a long list, incase your  lang.alt  is long."]], [[' from itertools import chain\nprint([item for lang in languages_list for item in chain([lang.code], lang.alt)])\n']], ['Returning a list in each iteration using list comprehension'], 2, 1], [(23368164, 0), [['You can try something like this:'], ['This implementaiton works with lists of arbitrary elements and will return the result as a list. If you want just your  x,y  string, the code can be simplified and optimized some, e.g. using  len  this often would be wasteful is you have very long lists of  x s and  y s. Or you can just write a wrapper for that:']], [[' from __future__ import division\ndef spreadout(X, Y):\n    ratio = len(X) / len(Y)\n    result = []\n    while X or Y:\n        if not Y or len(X)/len(Y) >= ratio:\n            result.append(X.pop())\n        else:\n            result.append(Y.pop())\n    return result\n']], ['Python - "properly" organise (spread out) x and y data'], 3, 1], [(23368164, 1), [['This implementaiton works with lists of arbitrary elements and will return the result as a list. If you want just your  x,y  string, the code can be simplified and optimized some, e.g. using  len  this often would be wasteful is you have very long lists of  x s and  y s. Or you can just write a wrapper for that:'], ['Example Output:']], [[' def xy_wrapper(x, y):\n    return ",".join(spreadout([\'x\'] * x, [\'y\'] * y))\n']], ['Python - "properly" organise (spread out) x and y data'], 3, 1], [(23368164, 2), [['Example Output:'], ['-10000']], [[' >>> spreadout(range(6), list("ABC"))\n[5, \'C\', 4, 3, \'B\', 2, 1, \'A\', 0]\n>>> xy_wrapper(5, 17)\n\'x,y,y,y,y,x,y,y,y,x,y,y,y,y,x,y,y,y,x,y,y,y\'\n']], ['Python - "properly" organise (spread out) x and y data'], 3, 0], [(23388668, 0), [['You could do e.g.'], ['or have a list of functions:']], [[' if start >= 1:\n    function1()\nif start >= 2:\n    function2()\nif start >= 3:\n    function3()\n']], ['How to start at a specific step in a script?'], 2, 1], [(23388668, 1), [['or have a list of functions:'], ['-10000']], [[' f = [None, function1, function2, function3, ...]\nfor f in f_list[start:]:\n    f()\n']], ['How to start at a specific step in a script?'], 2, 1], [(23402150, 0), [["I  think you want to group on both 'Type' and 'Name':"], ["Or if it is important to have the column named 'Frequency', you could do something like the following:"]], [[" print df.groupby(['Type','Name']).size()\n\nType     Name       \nBird     Flappy Bird    1\n         Pigeon         2\nPokemon  Jerry          3\n         Mudkip         2\n"]], ['Grouping and Computing Frequency ,Pandas'], 2, 1], [(23402150, 1), [["Or if it is important to have the column named 'Frequency', you could do something like the following:"], ['-10000']], [[" print df.groupby(['Type','Name'])['Type'].agg({'Frequency':'count'})\n\n                     Frequency\nType    Name                  \nBird    Flappy Bird          1\n        Pigeon               2\nPokemon Jerry                3\n        Mudkip               2\n"]], ['Grouping and Computing Frequency ,Pandas'], 2, 1], [(23429426, 0), [['-10000'], ['Or even better (efficient) implementation']], [[' from collections import Counter\nprint [item for items, c in Counter(a).most_common() for item in [items] * c]\n# [5, 5, 5, 5, 3, 3, 3, 4, 4, 4, 1, 1, 2]\n']], ['Sorting a List by frequency of occurrence in a list'], 4, 1], [(23429426, 1), [['Or even better (efficient) implementation'], ['Or']], [[' from collections import Counter\nfrom itertools import repeat, chain\nprint list(chain.from_iterable(repeat(i, c) for i,c in Counter(a).most_common()))\n# [5, 5, 5, 5, 3, 3, 3, 4, 4, 4, 1, 1, 2]\n']], ['Sorting a List by frequency of occurrence in a list'], 4, 1], [(23429426, 2), [['Or'], ['If you prefer in-place sort']], [[' from collections import Counter\nprint sorted(a, key=Counter(a).get, reverse=True)\n# [5, 5, 5, 5, 3, 3, 3, 4, 4, 4, 1, 1, 2]\n']], ['Sorting a List by frequency of occurrence in a list'], 4, 1], [(23429968, 0), [["So I've been fiddling around with this, and I believe I have come up with a solution that produces the results I'm after.  Given the model above, I'm using the following:"], ['In our actual model, we have different types of leads as well and an additional field  type .  So if I wanted to take that into consideration as well, I would simply add a  type  field to the model and use the following:']], [[" Lead.objects.values('site', 'companies').annotate(Count('id'))\n"]], ['In Django, how could I in a single query get total row count based on distinct field values?'], 2, 1], [(23429968, 1), [['In our actual model, we have different types of leads as well and an additional field  type .  So if I wanted to take that into consideration as well, I would simply add a  type  field to the model and use the following:'], ['Using this, I would get one dictionary per site, per type, per company, each with its own count.  Django is pretty smart!']], [[" Lead.objects.values('site', 'companies', 'type').annotate(Count('id'))\n"]], ['In Django, how could I in a single query get total row count based on distinct field values?'], 2, 1], [(23441228, 0), [["Some of your code is a bit unusual, like the  str(files) ; I'd expect the filenames to be strings already?"], ['On my system this gives:']], [[' import numpy\nimport timeit\n\n\ndef makebigfile(outname):\n    data = numpy.random.standard_normal((100000, 7))\n    numpy.savetxt(outname, data, delimiter=",")\n\n\ndef csvdump(files, original=True):\n\n        date, time, opens, high, low, close, vol = numpy.genfromtxt(str(files)+\'.csv\', unpack=True, delimiter=\',\')\n        if original:\n            for line in high:\n                x=str(1/line)\n                outr=open(str(files)+"inverse-original.txt", "a")\n                outr.write(x)\n                outr.write(\'\\n\')\n        else:\n            numpy.savetxt(str(files)+"inverse-savetxt.txt",1/high)\n\n\n\nmakebigfile(\'foo.txt\')\n\n\nprint timeit.timeit(stmt=\'__main__.csvdump("foo",True)\',setup=\'import __main__\',number=1000)\nprint timeit.timeit(stmt=\'__main__.csvdump("foo",False)\',setup=\'import __main__\',number=1000)\n']], ['Fasted Python way to bulk csv convert outside of using pandas'], 2, 1], [(23441228, 1), [['On my system this gives:'], ['-10000']], [[' 1.41840219498\n0.56161403656\n']], ['Fasted Python way to bulk csv convert outside of using pandas'], 2, 0], [(23460155, 1), [['To validate your input you can do:'], ["Tuples are indexed just like lists are. However, they are immutable which means you can't change them or append new items to them. And I believe that's desired in your case."]], [[' input = raw_input()\ntry:\n    key = float(input)\nexcept ValueError:\n    key = input\n\ntry:\n    value = data[key]\nexcept KeyError:\n    print "Invalid input. Valid keys are: " + \', \'.join(data.keys())\nelse:\n    #input was valid, so value == data[key]\n']], ['python how to create list of interchangeable values?'], 2, 0], [(23555829, 0), [['A simpler solution will be to use json'], ['To save the list you would do the following']], [[' import json\nli = []\ndef getinput(li):\n    li.append(raw_input("Type in a string: "))\n']], ['Saving an Element in an Array Permanently'], 3, 0], [(23555829, 1), [['To save the list you would do the following'], ['And to load the file you simply do']], [[' savefile = file("backup.json", "w")\nsavefile.write(json.dumps(li))\n']], ['Saving an Element in an Array Permanently'], 3, 0], [(23555829, 2), [['And to load the file you simply do'], ['You may want to handle the case where the file does not exist. One thing to note would be that complex structures like classes cannot be stored as json. ']], [[' savefile = open("backup.json")\nli = json.loads(savefile.read())\n']], ['Saving an Element in an Array Permanently'], 3, 0], [(23555995, 0), [["I guess my suggestion would be to create your own class, which accepts a string as an argument instead of tokens. Here is a class loosely based upon the nltk's  ConcordanceIndex  class that might function as a starting point:"], ['Now you can test the class like this:']], [[' import re\n\n\nclass RegExConcordanceIndex(object):\n    "Class to mimic nltk\'s ConcordanceIndex.print_concordance."\n\n    def __init__(self, text):\n        self._text = text\n\n    def print_concordance(self, regex, width=80, lines=25, demarcation=\'\'):\n        """\n        Prints n <= @lines contexts for @regex with a context <= @width".\n        Make @lines 0 to display all matches.\n        Designate @demarcation to enclose matches in demarcating characters.\n        """ \n        concordance = []\n        matches = re.finditer(regex, self._text, flags=re.M)\n        if matches:\n            for match in matches:\n                start, end = match.start(), match.end()\n                match_width = end - start\n                remaining = (width - match_width) // 2\n                if start - remaining > 0:\n                    context_start = self._text[start - remaining:start]\n                    #  cut the string short if it contains a newline character\n                    context_start = context_start.split(\'\\n\')[-1]\n                else:\n                    context_start = self._text[0:start + 1].split(\'\\n\')[-1]\n                context_end = self._text[end:end + remaining].split(\'\\n\')[0]\n                concordance.append(context_start + demarcation + self._text\n                                   [start:end] + demarcation + context_end)\n                if lines and len(concordance) >= lines:\n                    break\n            print("Displaying %s matches:" % (len(concordance)))\n            print \'\\n\'.join(concordance)\n        else:\n            print "No matches"\n']], ['Can you do regex with concordance?'], 2, 1], [(23555995, 1), [['Now you can test the class like this:'], ['-10000']], [[' >>> from nltk.corpus import gutenberg\n>>> emma = gutenberg.raw(fileids=\'austen-emma.txt\')\n>>> comma_separated = RegExConcordanceIndex(emma)\n>>> comma_separated.print_concordance(r"(?<=, )[A-Za-z]+(?=,)", demarcation=\'**\')  # matches are enclosed in double asterisks\n\nDisplaying 25 matches:\nEmma Woodhouse, **handsome**, clever, and rich, with a comfortab\nEmma Woodhouse, handsome, **clever**, and rich, with a comfortable home\nThe real evils, **indeed**, of Emma\'s situation were the power \no her many enjoyments.  The danger, **however**, was at present\nwell-informed, **useful**, gentle, knowing all the ways of the\nwell-informed, useful, **gentle**, knowing all the ways of the family,\na good-humoured, **pleasant**, excellent man, that he thoroughly \n"No, **papa**, nobody thought of your walking.  We \n"I believe it is very true, my dear, **indeed**," said Mr. Woodhouse,\nshould not like her so well as we do, **sir**,\ne none for myself, papa; but I must, **indeed**,\nmet with him in Broadway Lane, **when**, because it began to drizzle,\nlike Mr. Elton, **papa**,--I must look about for a wife for hi\n"With a great deal of pleasure, **sir**, at any time," said Mr. Knightley,\nbetter thing.  Invite him to dinner, **Emma**, and help him to the best\ny.  He had received a good education, **but**,\nMiss Churchill, **however**, being of age, and with the full co\nFrom the expense of the child, **however**, he was soon relieved.\nIt was most unlikely, **therefore**, that he should ever want his\n strong enough to affect one so dear, **and**, as he believed,\nIt was, **indeed**, a highly prized letter.  Mrs. Westo\nand he had, **therefore**, earnestly tried to dissuade them \nFortunately for him, **Highbury**, including Randalls in the same par\nhandsome, **rich**, nor married.  Miss Bates stood in th\na real, **honest**, old-fashioned Boarding-school, wher\n']], ['Can you do regex with concordance?'], 2, 0], [(23575195, 0), [['Instead, try:'], ["I think that works.\nEDIT: No, it actually doesn't. Here, I'll post a different prime checker:"]], [[' def isprime(n):\n    if n % 1 != 0:\n        return True\n    else:\n        for j in range(2, math.ceil(math.sqrt(n))):\n            if n % j != 0:\n                return False\n        return True\n']], ['Python and the modulus operator with very large numbers'], 2, 0], [(23575195, 1), [["I think that works.\nEDIT: No, it actually doesn't. Here, I'll post a different prime checker:"], ['-10000']], [[" def isprime(n):\n    '''check if integer n is a prime'''\n    n = abs(int(n))\n    if n < 2:\n        return False\n    if n == 2: \n        return True    \n    if not n & 1: \n        return False\n    for x in range(3, int(n**0.5)+1, 2):\n        if n % x == 0:\n            return False\n    return True\n"]], ['Python and the modulus operator with very large numbers'], 2, 1], [(23576318, 0), [['Use  sum() :'], ['Demo:']], [[' with open("numberGood.txt") as f:\n    print(sum(float(line) for line in f))\n']], ['Python - sum variables from a text file'], 2, 1], [(23576318, 1), [['Demo:'], ['-10000']], [[' $ cat numberGood.txt \n10.01\n19.99\n30.0\n40\n$ python3\n>>> with open("numberGood.txt") as f:\n...     print(sum(float(line) for line in f))\n... \n100.0\n']], ['Python - sum variables from a text file'], 2, 1], [(23587296, 0), [['i would go for contours/shapeMatching instead:'], ['-10000']], [[' void findNeedles( const std::vector<cv::Point> & needle_contour, const cv::Mat & haystack_binarized)\n{\n    int nfound = 0;\n    std::vector<std::vector<cv::Point>> contours;\n    cv::findContours(haystack_binarized, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_NONE);\n    for (size_t i = 0; i < contours.size(); i++)\n    {\n        // pre-filter for size:\n        if ( ( contours[i].size() < needle_contour.size()/2 )\n          || ( contours[i].size() > needle_contour.size()*2 ) )\n          continue;\n\n        double d = cv::matchShapes(contours[i],needle_contour,CV_CONTOURS_MATCH_I2,0);\n        if ( d < 8.4 ) // heuristic value, experiments needed !!\n        {\n            cv::drawContours(haystack_binarized, contours, i, 128, 3);\n            nfound ++;\n        }\n    }\n    cerr << nfound << " objects found" << endl;\n    cv::imshow("haystack",haystack_binarized);\n    //imwrite("hay.png",haystack_binarized);\n    cv::waitKey();\n}\n\n\nint main()\n{\n    // 1. get the contour of our needle:\n    Mat needle = imread("needle.png",0);\n    Mat needle_b; \n    threshold(needle,needle_b,120,255,1); \n    imshow("needle",needle_b);\n\n    std::vector<std::vector<cv::Point>> needle_conts;\n    cv::findContours(needle_b, needle_conts, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_NONE);\n    if ( needle_conts.size() == 0 )\n    {\n        std::cout << " no contour Found" << std::endl;\n        return -1;\n    }\n    std::vector<cv::Point> needle_contour = needle_conts[0];\n\n    // 2. check a positive sample:\n    Mat haypos = imread("hay_pos.png",0);\n    Mat haypos_b; \n    threshold(haypos,haypos_b,120,255,1);\n    findNeedles(needle_contour, haypos_b);\n\n    // 3. check a negative sample:\n    Mat hayneg = imread("hay_neg.png",0);\n    Mat hayneg_b; \n    threshold(hayneg,hayneg_b,120,255,1);\n    findNeedles(needle_contour, hayneg_b);\n\n    return 0;\n}\n']], ['Recognising objects in images using HAAR cascade and OpenCV'], 2, 1], [(23587296, 1), [['-10000'], ['']], [['-------------- > haystack.exe\n5 objects found\n0 objects found\n']], ['Recognising objects in images using HAAR cascade and OpenCV'], 2, 0], [(23613138, 0), [["I'm not quite sure what you're asking, but if you want to print each row that contains any of the numbers in  affiliate_phone_dict , this will do:"], ['data.csv']], [[" lookup = {'name1': 'xxx-xxx-xxxx',\n          'name2': 'yyy-yyy-yyyy'}\n\nwith open('data.csv') as data_file, open('out.csv', 'w') as out_file:\n    for row in data_file:\n        if any(num in row for num in lookup.values()):\n            out_file.write(row)\n"]], ['How do I get python to search a csv file for items in a dictionary then print out the entire excel row...Thanks'], 3, 1], [(23613138, 1), [['data.csv'], ['out.csv']], [[' Date Time Length Cost Bill Category Destination Number Destination City Origin Number OriginCity\n01/01/0001  10:37   3   $0.00   LOCAL AIRTIME, LONG DISTANCE and INTERNATIONAL CHARGES  xxx-xxx-xxxx    City Name   aaa-aaa-aaaa    City Name   Mobile\n01/01/0001  10:37   10  $0.00   LOCAL AIRTIME, LONG DISTANCE and INTERNATIONAL CHARGES  yyy-yyy-yyyy    City Name   zzz-zzz-zzzz    City Name   Mobile\n01/01/0001  10:37   10  $0.00   LOCAL AIRTIME, LONG DISTANCE and INTERNATIONAL CHARGES  123-456-7890    City Name   zzz-zzz-zzzz    City Name   Mobile\n']], ['How do I get python to search a csv file for items in a dictionary then print out the entire excel row...Thanks'], 3, 0], [(23613138, 2), [['out.csv'], ['-10000']], [[' 01/01/0001  10:37   3   $0.00   LOCAL AIRTIME, LONG DISTANCE and INTERNATIONAL CHARGES  xxx-xxx-xxxx    City Name   aaa-aaa-aaaa    City Name   Mobile\n01/01/0001  10:37   10  $0.00   LOCAL AIRTIME, LONG DISTANCE and INTERNATIONAL CHARGES  yyy-yyy-yyyy    City Name   zzz-zzz-zzzz    City Name   Mobile\n']], ['How do I get python to search a csv file for items in a dictionary then print out the entire excel row...Thanks'], 3, 0], [(23614259, 0), [["This code does the trick - I've put your data in the tmpData.txt file for convenience, and get the desired result. Please check"], ['Output:']], [[" def get_pivots():\n    data = pd.DataFrame.from_csv('tmpData.txt')\n    data['swings'] = np.nan\n\n    pivot = data.irow(0).open\n    last_pivot_id = 0\n    up_down = 0\n\n    diff = .3\n\n    for i in range(0, len(data)):\n        row = data.irow(i)\n\n        # We don't have a trend yet\n        if up_down == 0:\n            if row.low < pivot - diff:\n                data.ix[i, 'swings'] = row.low - pivot\n                pivot, last_pivot_id = row.low, i\n                up_down = -1\n            elif row.high > pivot + diff:\n                data.ix[i, 'swings'] = row.high - pivot\n                pivot, last_pivot_id = row.high, i\n                up_down = 1\n\n        # Current trend is up\n        elif up_down == 1:\n            # If got higher than last pivot, update the swing\n            if row.high > pivot:\n                # Remove the last pivot, as it wasn't a real one\n                data.ix[i, 'swings'] = data.ix[last_pivot_id, 'swings'] + (row.high - data.ix[last_pivot_id, 'high'])\n                data.ix[last_pivot_id, 'swings'] = np.nan\n                pivot, last_pivot_id = row.high, i\n            elif row.low < pivot - diff:\n                data.ix[i, 'swings'] = row.low - pivot\n                pivot, last_pivot_id = row.low, i\n                # Change the trend indicator\n                up_down = -1\n\n        # Current trend is down\n        elif up_down == -1:\n             # If got lower than last pivot, update the swing\n            if row.low < pivot:\n                # Remove the last pivot, as it wasn't a real one\n                data.ix[i, 'swings'] = data.ix[last_pivot_id, 'swings'] + (row.low - data.ix[last_pivot_id, 'low'])\n                data.ix[last_pivot_id, 'swings'] = np.nan\n                pivot, last_pivot_id = row.low, i\n            elif row.high > pivot - diff:\n                data.ix[i, 'swings'] = row.high - pivot\n                pivot, last_pivot_id = row.high, i\n                # Change the trend indicator\n                up_down = 1\n\n    print data\n"]], ['Identifying price swings/trends in pandas dataframe with stock quotes'], 2, 1], [(23614259, 1), [['Output:'], ['-10000']], [[' date                  close  high    low     open    volume    swings                                            \n2014-05-09 13:30:00  187.56  187.73  187.54  187.70  1922600     NaN\n2014-05-09 13:31:00  187.49  187.56  187.42  187.55   534400     NaN\n2014-05-09 13:32:00  187.42  187.51  187.35  187.49   224800   -0.35\n2014-05-09 13:33:00  187.55  187.58  187.39  187.40   303700     NaN\n2014-05-09 13:34:00  187.67  187.67  187.53  187.56   438200     NaN\n2014-05-09 13:35:00  187.60  187.71  187.56  187.68   296400    0.36\n2014-05-09 13:36:00  187.41  187.67  187.38  187.60   329900     NaN\n2014-05-09 13:37:00  187.31  187.44  187.28  187.40   404000     NaN\n2014-05-09 13:38:00  187.26  187.37  187.26  187.30   912800     NaN\n2014-05-09 13:39:00  187.22  187.28  187.12  187.25   607700   -0.59\n']], ['Identifying price swings/trends in pandas dataframe with stock quotes'], 2, 0], [(23626026, 0), [['Calling  supervisorctl  in this way:'], ['Following the sample code from "Welcome to Fabric!" it would look like:']], [[' $ supervisorctl status logproxy\nlogproxy                         STOPPED    Not started\n']], ['How to exit a supervisor process with fabric file?'], 4, 0], [(23626026, 1), [['Following the sample code from "Welcome to Fabric!" it would look like:'], ['And would be used.']], [[' from fabric.api import run\n\ndef super_status():\n    uname = "zen"\n    pswd = "then"\n    cmd = "supervisorctl -u {uname} -p {pswd} status logproxy".format(uname=uname, pswd=pswd)\n    # to see the command you are going to call, just for show\n    print cmd\n    # and run it\n    run(cmd)\n']], ['How to exit a supervisor process with fabric file?'], 4, 0], [(23626026, 2), [['And would be used.'], ['and calling the task  super_status :']], [[' $ fab -l\n']], ['How to exit a supervisor process with fabric file?'], 4, 0], [(23626026, 3), [['and calling the task  super_status :'], ['-10000']], [[' $ fab super_status -H localhost\n']], ['How to exit a supervisor process with fabric file?'], 4, 0], [(23635576, 0), [['fifo.c'], ['fifo.py']], [[' #include <sys/stat.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <stdio.h>\n\nint main (void)\n{\n    // Array to send\n    int arr[] = {2,4,6,8};\n    int len = 4;\n\n    // Create FIFO\n    char filename[] = "fifo.tmp";\n\n    int s_fifo = mkfifo(filename, S_IRWXU);\n    if (s_fifo != 0)\n    {\n        printf("mkfifo() error: %d\\n", s_fifo);\n        return -1;\n    }\n\n    FILE * wfd = fopen(filename, "w");\n    if (wfd < 0)\n    {\n        printf("open() error: %d\\n", wfd);\n        return -1;\n    }\n\n    // Write to FIFO\n    for (int i=0; i<len; i++)\n    {\n        int s_write = fprintf(wfd, "%d ", arr[i]);\n\n        if (s_write < 0)\n        {\n            printf("fprintf() error: %d\\n", s_write);\n            break;\n        }\n    }\n\n    // Close and delete FIFO\n    fclose(wfd);\n    unlink(filename);\n}\n']], ['Send data from c program to python program using pipe?'], 2, 0], [(23635576, 1), [['fifo.py'], ["You'd first run the writer (c), which would block until the reader (python) opened and read the data.  Then run the reader and both processes will terminate."]], [[' filename = "fifo.tmp"\n\n# Block until writer finishes...\nwith open(filename, \'r\') as f:\n    data = f.read()\n\n# Split data into an array\narray = [int(x) for x in data.split()]\n\nprint array\n']], ['Send data from c program to python program using pipe?'], 2, 0], [(23642406, 0), [['Well, you can include  SampleMeta  as part of the groupby:'], ["If you don't want  SampleMeta  as part of the index when done you could modify it as follows:"]], [[" print test.groupby(['GroupID','Sample','SampleMeta']).sum()\n\n                           Value\nGroupID Sample SampleMeta       \n1       S1     S1_meta         2\n2       S2     S2_meta         1\n"]], ['Sum grouped Pandas dataframe by single column'], 3, 1], [(23642406, 1), [["If you don't want  SampleMeta  as part of the index when done you could modify it as follows:"], ["This will only work right if there is no variation within  SampleMeta  for  ['GroupID','Sample'] . Of course, If there was variation within  ['GroupID','Sample']  then  you probably to exclude  SampleMeta  from the groupby/sum entirely:"]], [[" print test.groupby(['GroupID','Sample','SampleMeta']).sum().reset_index(level=2)\n\n               SampleMeta  Value\nGroupID Sample                  \n1       S1        S1_meta      2\n2       S2        S2_meta      1\n"]], ['Sum grouped Pandas dataframe by single column'], 3, 1], [(23642406, 2), [["This will only work right if there is no variation within  SampleMeta  for  ['GroupID','Sample'] . Of course, If there was variation within  ['GroupID','Sample']  then  you probably to exclude  SampleMeta  from the groupby/sum entirely:"], ['-10000']], [[" print test.groupby(['GroupID','Sample'])['Value'].sum()\n\nGroupID  Sample\n1        S1        2\n2        S2        1\n"]], ['Sum grouped Pandas dataframe by single column'], 3, 1], [(23648826, 0), [["There is nothing provided by robot to give you this information. However, it's pretty easy to write a python script that uses the robot parser to get all of the tag information. Here's a quick hack that I think is correct (though I only tested it very briefly):"], ['Save the code to a file, eg get_tags.py, and run it like this:']], [[' from robot.parsing import TestData\nimport sys\n\ndef main(path):\n    suite = TestData(parent=None, source=path)\n    tags = get_tags(suite)\n    print ", ".join(sorted(set(tags)))\n\ndef get_tags(suite):\n    tags = []\n\n    if suite.setting_table.force_tags:\n        tags.extend(suite.setting_table.force_tags.value)\n\n    if suite.setting_table.default_tags:\n        tags.extend(suite.setting_table.default_tags.value)\n\n    for testcase in suite.testcase_table.tests:\n        if testcase.tags:\n            tags.extend(testcase.tags.value)\n\n    for child_suite in suite.children:\n        tags.extend(get_tags(child_suite))\n\n    return tags\n\nif __name__ == "__main__":\n    main(sys.argv[1])\n']], ['How to print available tags while using Robot Framework'], 2, 1], [(23648826, 1), [['Save the code to a file, eg get_tags.py, and run it like this:'], ['-10000']], [[' $ python /tmp/get_tags.py /tmp/tests/\na tag, another force tag, another tag, default tag, force tag, tag-1, tag-2\n']], ['How to print available tags while using Robot Framework'], 2, 0], [(23669024, 0), [['Use  str.replace .'], ['Alternatively use  re  and use regular expressions.  This will allow the removal of leading/trailing spaces.']], [[" >>> papa.replace('papa', '')\n' is a good man'\n>>> app.replace('papa', '')\n'app is important'\n"]], ['How to strip a specific word from a string?'], 2, 1], [(23669024, 1), [['Alternatively use  re  and use regular expressions.  This will allow the removal of leading/trailing spaces.'], ['-10000']], [[" >>> import re\n>>> papa = 'papa is a good man'\n>>> app = 'app is important'\n>>> papa3 = 'papa is a papa, and papa'\n>>>\n>>> patt = re.compile('(\\s*)papa(\\s*)')\n>>> patt.sub('\\\\1mama\\\\2', papa)\n'mama is a good man'\n>>> patt.sub('\\\\1mama\\\\2', papa3)\n'mama is a mama, and mama'\n>>> patt.sub('', papa3)\n'is a, and'\n"]], ['How to strip a specific word from a string?'], 2, 1], [(23677258, 0), [['Please try this (copy and pasteable):'], ['Comparison on lower triangles \nIn order to compare back, we set all the upper triangles to  0']], [[' import numpy as np\nshape = (3, 10, 10, 19, 75, 10, 10)\np = np.arange(np.prod(shape)).reshape(shape)  # this is not symmetric, but not important\n\nix, iy = np.tril_indices(10)\n# In order to index properly, we need to add axes. This can be done by hand or with this\nix1, ix2 = np.ix_(ix, ix)\niy1, iy2 = np.ix_(iy, iy)\n\np_ltriag = p[:, ix1, iy1, :, :, ix2, iy2]\nprint p_ltriag.shape  # yields (55, 55, 3, 19, 75), axis order can be changed if needed\n\nq = np.zeros_like(p)\nq[:, ix1, iy1, :, :, ix2, iy2] = p_ltriag  # fills the lower triangles on both sides\nq[:, ix1, iy1, :, :, iy2, ix2] = p_ltriag  # fills the lower on left, upper on right\nq[:, iy1, ix1, :, :, ix2, iy2] = p_ltriag  # fills the upper on left, lower on right\nq[:, iy1, ix1, :, :, iy2, ix2] = p_ltriag  # fills the upper triangles on both sides\n']], ['numpy multidimensional indexing and diagonal symmetries'], 2, 0], [(23677258, 1), [['Comparison on lower triangles \nIn order to compare back, we set all the upper triangles to  0'], ['-10000']], [[' ux, uy = np.triu_indices(10)\np[:, ux, uy] = 0\nq[:, ux, uy] = 0\np[:, :, :, :, :, ux, uy] = 0\nq[:, :, :, :, :, ux, uy] = 0\n\nprint ((p - q) ** 2).sum()  # euclidean distance is 0, so p and q are equal\n\nprint ((p ** 2).sum(), (q ** 2).sum())  # prove that not all entries are 0 ;) - This has a negative result due to an overflow\n']], ['numpy multidimensional indexing and diagonal symmetries'], 2, 0], [(23699378, 0), [['We can visualize an n-element permutation p as an n-vertex, n-arc directed graph where, for each vertex v, there is an arc from v to p(v). This digraph consists of a collection of vertex-disjoint cycles. For example, the permutation 31024 looks like'], ['Given a prefix of a permutation, we can visualize the subgraph corresponding to that prefix, which will be a collection of vertex-disjoint paths and cycles. For example, the prefix 310 looks like']], [['  _______\n/       \\\n\\->2->0->3\n __     __\n/  |   /  |\n1<-/   4<-/ .\n']], ['Get permutation with specified degree by index number'], 5, 0], [(23699378, 1), [['Given a prefix of a permutation, we can visualize the subgraph corresponding to that prefix, which will be a collection of vertex-disjoint paths and cycles. For example, the prefix 310 looks like'], ['The definition, more or less, of the (n,k)-th Stirling number of the first kind, written']], [[' 2->0->3\n __\n/  |\n1<-/ .\n']], ['Get permutation with specified degree by index number'], 5, 0], [(23699378, 2), [['The definition, more or less, of the (n,k)-th Stirling number of the first kind, written'], ['(ASCII art square brackets), is the number of n-element permutations of degree n - k. To compute the number of extensions of an r-element prefix of an n-element permutation, count c, the number of complete cycles in the prefix. Sum, for each degree d in the specified set, the Stirling number']], [[' [n]\n[ ]\n[k]\n']], ['Get permutation with specified degree by index number'], 5, 0], [(23699378, 3), [['(ASCII art square brackets), is the number of n-element permutations of degree n - k. To compute the number of extensions of an r-element prefix of an n-element permutation, count c, the number of complete cycles in the prefix. Sum, for each degree d in the specified set, the Stirling number'], ["Here's some Python code for both (including a test function)."]], [[' [  n - r  ]\n[         ]\n[n - d - c]\n']], ['Get permutation with specified degree by index number'], 5, 0], [(23699378, 4), [["Here's some Python code for both (including a test function)."], ['-10000']], [[' import itertools\n\nmemostirling1 = {(0, 0): 1}\ndef stirling1(n, k):\n    ans = memostirling1.get((n, k))\n    if ans is None:\n        if not 1 <= k <= n: return 0\n        ans = (n - 1) * stirling1(n - 1, k) + stirling1(n - 1, k - 1)\n        memostirling1[(n, k)] = ans\n    return ans\n\ndef cyclecount(prefix):\n    c = 0\n    visited = [False] * len(prefix)\n    for (i, j) in enumerate(prefix):\n        while j < len(prefix) and not visited[j]:\n            visited[j] = True\n            if j == i:\n                c += 1\n                break\n            j = prefix[j]\n    return c\n\ndef extcount(n, dset, prefix):\n    c = cyclecount(prefix)\n    return sum(stirling1(n - len(prefix), n - d - c) for d in dset)\n\ndef unrank(n, dset, rnk):\n    assert rnk >= 0\n    choices = set(range(n))\n    prefix = []\n    while choices:\n        for i in sorted(choices):\n            prefix.append(i)\n            count = extcount(n, dset, prefix)\n            if rnk < count:\n                choices.remove(i)\n                break\n            del prefix[-1]\n            rnk -= count\n        else:\n            assert False\n    return tuple(prefix)\n\ndef rank(n, dset, perm):\n    assert n == len(perm)\n    rnk = 0\n    prefix = []\n    choices = set(range(n))\n    for j in perm:\n        choices.remove(j)\n        for i in sorted(choices):\n            if i < j:\n                prefix.append(i)\n                rnk += extcount(n, dset, prefix)\n                del prefix[-1]\n        prefix.append(j)\n    return rnk\n\ndef degree(perm):\n    return len(perm) - cyclecount(perm)\n\ndef test(n, dset):\n    for (rnk, perm) in enumerate(perm for perm in itertools.permutations(range(n)) if degree(perm) in dset):\n        assert unrank(n, dset, rnk) == perm\n        assert rank(n, dset, perm) == rnk\n\ntest(7, {2, 3, 5})\n']], ['Get permutation with specified degree by index number'], 5, 1], [(23718340, 0), [["Well, I'd probably do it as follows (an example dataframe the hopefully captures your situation well enough):"], ['Get the columns of interest:']], [[' >>> df\n\n   A  B abc1 abc2 abc3 abc4\n0  1  4    x    r    a    d\n1  1  3    y    d    b    e\n2  2  4    z    e    c    r\n3  3  5    r    g    d    f\n4  4  8    z    z    z    z\n']], ['pandas dataframe: return column that is a compression of other columns'], 4, 0], [(23718340, 3), [["Now, if  you need to check if the strings contain 'r' instead of equalling 'r', you could do as follows:"], ["This should still be pretty fast because it uses  pandas ' vectorized string methods for each of the columns (the apply is across the columns, not an iteration over the rows)."]], [[" >>> df\n\n  A  B abc1  abc2 abc3 abc4\n0  1  4    x  root    a    d\n1  1  3    y     d    b    e\n2  2  4    z     e    c  bar\n3  3  5    r     g    d    f\n4  4  8    z     z    z    z\n\n>>> cols = [x for x in df.columns if 'abc' in x]\n>>> df['newcol'] = df[cols].apply(lambda x: x.str.contains('r'),axis=0).any(axis=1)\n>>> df['newcol'] = df['newcol'].map({True:'r',False:'np.nan'}) \n>>> df\n\n   A  B abc1  abc2 abc3 abc4  newcol\n0  1  4    x  root    a    d       r\n1  1  3    y     d    b    e  np.nan\n2  2  4    z     e    c  bar       r\n3  3  5    r     g    d    f       r\n4  4  8    z     z    z    z  np.nan\n"]], ['pandas dataframe: return column that is a compression of other columns'], 4, 1], [(23732057, 0), [["Instead  stemmer  you can use  lemmatizer . Here's an example with python NLTK:"], ['In some cases, it may not do what you expect:']], [[' from nltk.stem import WordNetLemmatizer\n\ns = """\n You all are so beautiful soooo beautiful\n Thought that was a really awesome quote\n Beautiful things don\'t ask for attention\n """\n\nwnl = WordNetLemmatizer()\nprint " ".join([wnl.lemmatize(i) for i in s.split()]) #You all are so beautiful soooo beautiful Thought that wa a really awesome quote Beautiful thing don\'t ask for attention\n']], ['Remove word extension in python'], 2, 1], [(23732057, 1), [['In some cases, it may not do what you expect:'], ['Then you can combine both approaches:  stemming  and  lemmatization .']], [[" print wnl.lemmatize('going') #going\n"]], ['Remove word extension in python'], 2, 0], [(23733922, 0), [['It is still a dictionary, just use the key:'], ['Demo:']], [[" your_ordered_dict['clicks__c']\n"]], ['How to Parse an orderedDict?'], 2, 1], [(23733922, 1), [['Demo:'], ["If you parsed this from a JSON object, in the vast majority of cases  order won't matter . It certainly doesn't with your values here. You could just have parsed it to regular dictionaries and not lost functionality."]], [[" >>> from collections import OrderedDict\n>>> od = OrderedDict([(u'attributes', OrderedDict([(u'type', u'Campaign__c'), (u'url', u'/services/data/v29.0/sobjects/Campaign__c/a0B9000000I6CDUEA3')])), (u'clicks__c', 0.0)])\n>>> od.keys()\n[u'attributes', u'clicks__c']\n>>> od['clicks__c']\n0.0\n"]], ['How to Parse an orderedDict?'], 2, 1], [(23795777, 0), [["Could you post a code snippet? I'm not sure I get the question, but my first thought would be to generate a grid with  tk.Labels  assigned to each spot, and keep references to them in a list (or 2-D list). Then, when you need to update, just call "], ["Edit: \nNo, I wouldn't hard-code it, it should be straightforward to do with a loop, e.g.:"]], [[" self.labels[i][j].config(text='foo')\n"]], ['python tkinter calender, placing the numbers'], 3, 0], [(23795777, 1), [["Edit: \nNo, I wouldn't hard-code it, it should be straightforward to do with a loop, e.g.:"], ['which spits out']], [[" import math\n\n# Initialize the calendar matrix\ncal = []\nfor i in range(5): # 5 weeks\n    cal.append([])\n    for j in range(7): # 7 days per week\n        cal[i].append('')\n\n# Set the calendar for some month\nstart = 3 # Wed\nfor day in range(31):\n    row = math.floor( (day+start) / 7)\n    col = (day+start) - 7*row\n    cal[row][col] = str(day+1)\n\nprint(cal)\n"]], ['python tkinter calender, placing the numbers'], 3, 1], [(23795777, 2), [['which spits out'], ["though in the GUI of course, you'd want to have a matrix of  tk.Label  or whatever."]], [[" [['', '', '', '1', '2', '3', '4'], ['5', '6', '7', '8', '9', '10', '11'], ['12', '13', '14', '15', '16', '17', '18'], ['19', '20', '21', '22', '23', '24', '25'], ['26', '27', '28', '29', '30', '31', '']]\n"]], ['python tkinter calender, placing the numbers'], 3, 0], [(23832259, 1), [['If you want output that matches what you have in your original question, you can do this:'], ['-10000']], [[' >>> print("\\n".join(["{}, {} {}OK".format(i, j, "" if i == j else "N") for i, j in izip_longest(a, b, fillvalue="null")]))\ne, e OK\nf, f OK\ng, h NOK\nh, i NOK\ni, j NOK\nnull, g NOK\n']], ['Python - diff-like order comparision of 2 lists with unequal sizes,'], 2, 1], [(23833763, 0), [['-10000'], ['So in your case:']], [[" In [96]:\n\ndf = pd.DataFrame({'a':randn(10), 'b':randn(10), 'c':randn(10)})\ndf\nOut[96]:\n          a         b         c\n0 -0.849903  0.944912  1.285790\n1 -1.038706  1.445381  0.251002\n2  0.683135 -0.539052 -0.622439\n3 -1.224699 -0.358541  1.361618\n4 -0.087021  0.041524  0.151286\n5 -0.114031 -0.201018 -0.030050\n6  0.001891  1.601687 -0.040442\n7  0.024954 -1.839793  0.917328\n8 -1.480281  0.079342 -0.405370\n9  0.167295 -1.723555 -0.033937\n\n[10 rows x 3 columns]\nIn [97]:\n\ndf[df > 1.0].count()\n\nOut[97]:\na    0\nb    2\nc    2\ndtype: int64\n"]], ['Pandas count number of elements in each column less than x'], 3, 1], [(23833763, 1), [['So in your case:'], ['some timings']], [[' df[df < 2.0 ].count() \n']], ['Pandas count number of elements in each column less than x'], 3, 0], [(23833763, 2), [['some timings'], ["So @DSM's suggestions are correct and much faster than my suggestion"]], [[' In [3]:\n\n%timeit df[df < 1.0 ].count() \n%timeit (df < 1.0).sum()\n%timeit (df < 1.0).apply(np.count_nonzero)\n1000 loops, best of 3: 1.47 ms per loop\n1000 loops, best of 3: 560 us per loop\n1000 loops, best of 3: 529 us per loop\n']], ['Pandas count number of elements in each column less than x'], 3, 0], [(23837696, 0), [['Simple enough:'], ['You  may  want to limit the permissible characters between  /team/  and  /Euro_2012  to reduce the chances of false positives in larger text:']], [[" re.findall(r'/team/.*?/Euro_2012', inputtext)\n"]], ['Using regex to find a string starting with /team/ and ending with /Euro_2012'], 3, 1], [(23837696, 1), [['You  may  want to limit the permissible characters between  /team/  and  /Euro_2012  to reduce the chances of false positives in larger text:'], ['Demo:']], [[" re.findall(r'/team/[\\w\\d%.~+-/]*?/Euro_2012', inputtext)\n"]], ['Using regex to find a string starting with /team/ and ending with /Euro_2012'], 3, 1], [(23837696, 2), [['Demo:'], ['-10000']], [[" >>> import re\n>>> sample = '''\\\n... /team/Croatia/Euro_2012\n... /team/Netherlands/Euro_2012\n... /team/Netherlands/WC2014\n... '''\n>>> re.findall(r'/team/.*?/Euro_2012', sample)\n['/team/Croatia/Euro_2012', '/team/Netherlands/Euro_2012']\n>>> re.findall(r'/team/[\\w\\d%.~+-/]*?/Euro_2012', sample)\n['/team/Croatia/Euro_2012', '/team/Netherlands/Euro_2012']\n"]], ['Using regex to find a string starting with /team/ and ending with /Euro_2012'], 3, 1], [(23866378, 0), [['If you are looking for the elements which exist in both lists, the following list comprehension should work:'], ['Like so:']], [[' c = [item for item in b if item in a]\n']], ['Compare unequal lists'], 4, 0], [(23866378, 1), [['Like so:'], ['If you want to, say print something every time the values match, use the following  for  loop:']], [[' >>> a = [6]\n>>> b = [6,7,8]\n>>> c = [item for item in b if item in a]\n>>> c\n[6]\n>>> \n']], ['Compare unequal lists'], 4, 0], [(23866378, 2), [['If you want to, say print something every time the values match, use the following  for  loop:'], ['This runs as:']], [[" for i in b:\n    if i in a:\n        print '%d in both sets!' %(i)\n    else:\n        print '%d does not match!' %(i)\n"]], ['Compare unequal lists'], 4, 1], [(23866378, 3), [['This runs as:'], ['-10000']], [[" >>> a = [6, 7]\n>>> b = [6, 7, 8]\n>>> for i in b:\n...     if i in a:\n...             print '%d in both sets!' %(i)\n...     else:\n...             print '%d does not match!' %(i)\n... \n6 in both sets!\n7 in both sets!\n8 does not match!\n>>> \n"]], ['Compare unequal lists'], 4, 0], [(23918947, 0), [['Its quite simple: go through the string and whenever you find a possible mutation point, mutate if the random number says to:'], ['If you wanted to be fancier, you could use a list comprehension:']], [[" import random\ndef mutate(string, mutation, threshold):\n    dna = list(string)\n    for index, char in enumerate(dna):\n        if char in mutation:\n            if random.random() < threshold:\n                dna[index] = mutation[char]\n\n    return ''.join(dna)\n"]], ['Using Random Module to Administer DNA Mutations'], 2, 1], [(23918947, 1), [['If you wanted to be fancier, you could use a list comprehension:'], ['-10000']], [[" import random\ndef mutate(string, mutation, threshold):\n    return ''.join([mutation[char] if random.random() < threshold \n                                       and char in mutation else char\n                                       for char in string])\n"]], ['Using Random Module to Administer DNA Mutations'], 2, 1], [(23923658, 0), [['server.py'], ['And then you would have a client.py for your command line tool, like']], [[' import gevent\nimport gevent.monkey\ngevent.monkey.patch_all()\nimport zmq.green as zmq\nimport json\n\ncontext = zmq.Context()\nsocket = context.socket(zmq.ROUTER)\nsocket.bind("ipc:///tmp/myapp.ipc")\n\ndef do_something(parsed):\n    return sum(parsed.get("values"))\n\ndef handle(msg):\n    data = msg[1]\n    parsed = json.loads(data)\n    total = do_something(parsed)\n    msg[1] = json.dumps({"response": total})\n    socket.send_multipart(msg)\n\ndef handle_zmq():\n    while True:\n        msg = socket.recv_multipart()\n        gevent.spawn(handle, msg)\n\nif __name__ == "__main__":\n    handle_zmq()\n']], ['Exposing python daemon as a service'], 2, 0], [(23923658, 1), [['And then you would have a client.py for your command line tool, like'], ['Obviously this is a contrived example, but you should get the idea.  Alternatively you could use something like xmlrpc or jsonrpc for this as well.  ']], [[' import json\nimport zmq\n\nrequest_data = {\n        "values": [10, 20, 30 , 40],\n        }\n\ncontext = zmq.Context()\nsocket = context.socket(zmq.DEALER)\nsocket.connect("ipc:///tmp/myapp.ipc")\nsocket.send(json.dumps(request_data))\nprint socket.recv()\n']], ['Exposing python daemon as a service'], 2, 0], [(23961648, 0), [['Numpy offers very powerful  indexing capabilities . One of these is indexing using Boolean arrays. You can assign elements matching a condition to a certain value, which appears to be what you want. For example,'], ['will assign each element in  flow  whose absolute value is too close to zero. Supposing that  flow  looked like this:']], [[' threshold = 2\nflow[np.abs(flow) < threshold] = 0\n']], ['openCV Thresholding negative values'], 3, 1], [(23961648, 1), [['will assign each element in  flow  whose absolute value is too close to zero. Supposing that  flow  looked like this:'], ['The result of applying this operation would be:']], [[' [ 1  2  3]\n[-1 -2 -3]\n']], ['openCV Thresholding negative values'], 3, 0], [(23961648, 2), [['The result of applying this operation would be:'], ['Which has correctly removed positive and negative elements with a small magnitude, but retaining the sign of the negative elements.']], [[' [0  2  3]\n[0 -2 -3]\n']], ['openCV Thresholding negative values'], 3, 0], [(24002551, 0), [["Here's one solution with good old  Popen :"], ['-10000']], [[' import random, time\nfrom subprocess import Popen\n\n\ndef work_diligently():\n    cmd = ["/bin/sleep", str(random.randrange(2,4))]\n    proc = Popen(cmd)\n    print \'\\t{}\\t{}\'.format(proc.pid, cmd) # pylint: disable=E1101\n    return proc\n\n\ndef spawn(num):\n    return [ work_diligently() for _ in xrange(num) ]\n\n\nNUM_PROCS = 3\nprocs = spawn(NUM_PROCS)\nwhile True:\n    print time.ctime(), \'scan\'\n    procs = [ \n        proc for proc in procs\n        if proc.poll() is None\n    ]\n    num_exited = NUM_PROCS - len(procs)\n    if num_exited:\n        print \'Uhoh! Restarting {} procs\'.format(num_exited)\n        procs.extend( spawn(num_exited) )\n    time.sleep(1)\n']], ['wait() on a group of Popen objects'], 2, 1], [(24002551, 1), [['-10000'], ['-10000']], [["Output:     2340    ['/bin/sleep', '2']\n    2341    ['/bin/sleep', '2']\n    2342    ['/bin/sleep', '3']\nMon Jun  2 18:01:42 2014 scan\nMon Jun  2 18:01:43 2014 scan\nMon Jun  2 18:01:44 2014 scan\nUhoh! Restarting 2 procs\n    2343    ['/bin/sleep', '3']\n    2344    ['/bin/sleep', '2']\nMon Jun  2 18:01:45 2014 scan\nUhoh! Restarting 1 procs\n    2345    ['/bin/sleep', '2']\nMon Jun  2 18:01:46 2014 scan\nUhoh! Restarting 1 procs\n    2346    ['/bin/sleep', '2']\nMon Jun  2 18:01:47 2014 scan\nUhoh! Restarting 2 procs\n    2347    ['/bin/sleep', '3']\n    2349    ['/bin/sleep', '2']\n"]], ['wait() on a group of Popen objects'], 2, 0], [(24004106, 0), [["If you don't need the exact format that you provide you could use  defaultdict"], ['Result:']], [[" dictlist = [{'day': 0, 'start': '8:00am', 'end': '5:00pm'},\n            {'day': 1, 'start': '10:00am', 'end': '7:00pm'},\n            {'day': 2, 'start': '8:00am', 'end': '5:00pm'},\n            {'day': 3, 'start': '10:00am', 'end': '7:00pm'},\n            {'day': 4, 'start': '8:00am', 'end': '5:00pm'},\n            {'day': 5, 'start': '11:00am', 'end': '1:00pm'}]\n\nfrom collections import defaultdict\n\ndd = defaultdict(list)\n\nfor d in dictlist:\n    dd[(d['start'],d['end'])].append(d['day'])\n"]], ['Summarize a list of dictionaries based on common key values'], 3, 1], [(24004106, 1), [['Result:'], ['And if format is important to you could do:']], [[" >>> dd\ndefaultdict(<type 'list'>, {('11:00am', '1:00pm'): [5], ('10:00am', '7:00pm'): [1, 3], ('8:00am', '5:00pm'): [0, 2, 4]})\n"]], ['Summarize a list of dictionaries based on common key values'], 3, 0], [(24004106, 2), [['And if format is important to you could do:'], ['-10000']], [[" >>> my_list = [(v, k[0], k[1]) for k,v in dd.iteritems()]\n>>> my_list\n[([5], '11:00am', '1:00pm'), ([1, 3], '10:00am', '7:00pm'), ([0, 2, 4], '8:00am', '5:00pm')]\n>>> # If you need the output sorted:  \n>>> sorted_my_list = sorted(my_list, key = lambda k : len(k[0]), reverse=True)\n>>> sorted_my_list\n[([0, 2, 4], '8:00am', '5:00pm'), ([1, 3], '10:00am', '7:00pm'), ([5], '11:00am', '1:00pm')]\n"]], ['Summarize a list of dictionaries based on common key values'], 3, 0], [(24018965, 0), [["append  isn't working because the dictionary's values are not lists.  If you make them lists here by placing them in  [...] :"], ['append  will now work:']], [[" phonebook = {}\nphonebook ['ana'] = ['12345']\nphonebook ['maria'] = ['23456' , 'maria@gmail.com']\n"]], ['How to add a another value to a key in python'], 2, 0], [(24018965, 1), [['append  will now work:'], ['-10000']], [[' def add_contact():\n   name = raw_input("Please enter a name:")\n   number = raw_input("Please enter a number:")\n   phonebook[name].append(number)\n']], ['How to add a another value to a key in python'], 2, 0], [(24024966, 0), [['(Note using recursion for retries is probably not a great idea ...)'], ['-10000']], [[' def Http500Resistant(func):\n    num_retries = 5\n    @functools.wraps(func)\n    def wrapper(*a, **kw):\n        sleep_interval = 2\n        for i in range(num_retries):\n            try:\n                return func(*a, **kw)\n            except apiclient.errors.HttpError, e:\n                if e.resp.status == 500 and i < num_retries-1:\n                    sleep(sleep_interval)\n                    sleep_interval = min(2*sleep_interval, 60)\n                else:\n                    raise e    \n    return wrapper\n\nclass A(object):\n\n    @Http500Resistant\n    def f1(self): ...\n\n    @Http500Resistant\n    def f2(self): ...\n']], ['Try/Except Every Method in Class?'], 4, 1], [(24024966, 1), [['-10000'], ['and apply like this:']], [[' import inspect\ndef decorate_all_methods(decorator):\n    def apply_decorator(cls):\n        for k, f in cls.__dict__.items():\n            if inspect.isfunction(f):\n                setattr(cls, k, decorator(f))\n        return cls\n    return apply_decorator\n']], ['Try/Except Every Method in Class?'], 4, 0], [(24024966, 2), [['and apply like this:'], ['Or like:']], [[' @decorate_all_methods(Http500Resistant)\nclass A(object):\n    ...\n']], ['Try/Except Every Method in Class?'], 4, 0], [(24024966, 3), [['Or like:'], ['-10000']], [[' class A(object): ...\nA = decorate_all_methods(Http500Resistant)(A)\n']], ['Try/Except Every Method in Class?'], 4, 0], [(24042596, 0), [['A more-useful transformation is likely to turn it into  bytes :'], ['Or alternately a  bytearray :']], [[" rem_spaces = str.maketrans({' ':None})\n\nfrom binascii import unhexlify\n\nunhexlify(u.translate(rem_spaces))\nOut[13]: b'\\x01\\xa02\\x00\\x00\\x00\\x00\\xfe\\x12o\\x04'\n"]], ['Transform string in a list with elements separated on Python'], 3, 1], [(24042596, 1), [['Or alternately a  bytearray :'], ['If you really want a  list  of  int s:']], [[" bytearray(int(x,16) for x in u.split())\nOut[14]: bytearray(b'\\x01\\xa02\\x00\\x00\\x00\\x00\\xfe\\x12o\\x04')\n"]], ['Transform string in a list with elements separated on Python'], 3, 1], [(24055067, 0), [['You could use a simple generator expression and  collidepoint() , like'], ['or, if you really want the index instead of the  Rect  itself:']], [[' >>> rects = [pygame.Rect(0,0,100,100), pygame.Rect(30,30,30,30)]\n>>> next((r for r in rects if r.collidepoint(10, 10)), None)\n<rect(0, 0, 100, 100)>\n>>> next((r for r in rects if r.collidepoint(200, 200)), None)\n>>>\n']], ['Looking for a concise way to check for point collision in a list of Rects'], 2, 1], [(24055067, 1), [['or, if you really want the index instead of the  Rect  itself:'], ['-10000']], [[' >>> rects = [pygame.Rect(0,0,100,100), pygame.Rect(30,30,30,30)]\n>>> next((i for (i, r) in enumerate(rects) if r.collidepoint(10, 10)), -1)\n0\n>>> next((i for (i, r) in enumerate(rects) if r.collidepoint(100, 200)), -1)\n-1\n>>>\n']], ['Looking for a concise way to check for point collision in a list of Rects'], 2, 1], [(24065575, 2), [['-10000'], ['-10000']], [[" msg = 'ü' # len(msg) is 1 character\nencoded_msg = msg.encode('utf-8') # len(encoded_msg) is 2 bytes\nencoded_prefix = '{:0>5d}'.format(len(encoded_msg)).encode('utf-8')\nfull_message = encoded_prefix + encoded_msg # both are bytes, so we can concat\n\nprint(full_message) # prints: b'00002\\xc3\\xbc'\n"]], ['Byte formatting in python 3'], 3, 1], [(24072567, 0), [['-10000'], ['Here is another solution, accomplished by creating a subclass of  Frame  that is able to take keyboard focus:']], [[' from tkinter import *\n\ntop = Tk()\n\nEntry(top, width="20").pack()\nb = Frame(top, width=200, height=200, bg=\'blue\')\ng = Frame(top, width=200, height=200, bg=\'green\')\ny = Frame(top, width=200, height=200, bg=\'yellow\')\n\nb.pack()\ng.pack()\ny.pack()\n\nb.bind("<1>", lambda event: b.focus_set())\ng.bind("<1>", lambda event: g.focus_set())\ny.bind("<1>", lambda event: y.focus_set())\n\ntop.mainloop()\n']], ['Remove focus from Entry widget'], 3, 1], [(24072567, 1), [['Here is another solution, accomplished by creating a subclass of  Frame  that is able to take keyboard focus:'], ['-10000']], [[' from tkinter import *\n\nclass FocusFrame(Frame):\n    def __init__(self, *args, **kwargs):\n        Frame.__init__(self, *args, **kwargs)\n        self.bind("<1>", lambda event: self.focus_set())\n\ntop = Tk()\n\nEntry(top, width="20").pack()\nFocusFrame(top, width=200, height=200, bg=\'blue\').pack()\nFocusFrame(top, width=200, height=200, bg=\'green\').pack()\nFocusFrame(top, width=200, height=200, bg=\'yellow\').pack()    \n\ntop.mainloop()\n']], ['Remove focus from Entry widget'], 3, 1], [(24084817, 0), [['The non-zero entries of a CSR matrix  X  are obtained by'], ['and (a permutation of) the values of the actual row would be obtained by appending  X.shape[1] - len(X[i].data)  zeros to that.']], [[' X[i].data\n']], ['Log-sum-exp trick on a sparse matrix in scipy'], 7, 0], [(24084817, 1), [['and (a permutation of) the values of the actual row would be obtained by appending  X.shape[1] - len(X[i].data)  zeros to that.'], ["for a vector  a . Let's set  b = X[i].data  and  k = X.shape[1] - len(X[i].data)  and denote our earlier permuted row of  X  as"]], [[' logsumexp(a) = max(a) + log(∑ exp[a - max(a)])\n']], ['Log-sum-exp trick on a sparse matrix in scipy'], 7, 0], [(24084817, 2), [["for a vector  a . Let's set  b = X[i].data  and  k = X.shape[1] - len(X[i].data)  and denote our earlier permuted row of  X  as"], ['using 0ₖ to denote a zero vector of length  k  and (⋅, ⋅) for concatenation. Then']], [[' (b, 0ₖ)\n']], ['Log-sum-exp trick on a sparse matrix in scipy'], 7, 0], [(24084817, 3), [['using 0ₖ to denote a zero vector of length  k  and (⋅, ⋅) for concatenation. Then'], ['So we get the algorithm']], [[' logsumexp((b, 0ₖ))\n = max((b, 0ₖ)) + log(∑ exp[(b, 0ₖ) - max((b, 0ₖ))])\n = max(max(b), 0) + log(∑ exp[(b, 0ₖ) - max(max(b), 0)])\n = max(max(b), 0) + log(∑ exp[b - max(max(b), 0)] + ∑ exp[0ₖ - max(max(b), 0)])\n = max(max(b), 0) + log(∑ exp[b - max(max(b), 0)] + k × exp[-max(max(b), 0)])\n']], ['Log-sum-exp trick on a sparse matrix in scipy'], 7, 0], [(24084817, 4), [['So we get the algorithm'], ['for a CSR row vector. Extending this algorithm to the full matrix is easily done by a list comprehension, although a more efficient form would loop over the rows using the  indptr :']], [[' def logsumexp_csr_row(x):\n    data = x.data\n    mx = max(np.max(data), 0)\n    tmp = data - mx\n    r = np.exp(tmp, out=tmp).sum()\n    k = X.shape[1] - len(data)\n    return mx + np.log(r + k * np.exp(-mx))\n']], ['Log-sum-exp trick on a sparse matrix in scipy'], 7, 0], [(24084817, 5), [['for a CSR row vector. Extending this algorithm to the full matrix is easily done by a list comprehension, although a more efficient form would loop over the rows using the  indptr :'], ['UPDATE  Ok, I misunderstood the question: the OP is not interested in handling the zeros at all, so the above derivation is useless and the algorithm should be']], [[' def logsumexp_csr_rows(X):\n    result = np.empty(X.shape[0])\n    for i in range(X.shape[0]):\n        data = X.data[X.indptr[i]:X.indptr[i+1]]\n        # fill in from logsumexp_csr_row\n        result[i] = mx + np.log(r + k * np.exp(-mx))\n    return result\n']], ['Log-sum-exp trick on a sparse matrix in scipy'], 7, 0], [(24084817, 6), [['UPDATE  Ok, I misunderstood the question: the OP is not interested in handling the zeros at all, so the above derivation is useless and the algorithm should be'], ['This is just filling in the general scheme of row-wise operations on a CSR matrix. For column-wise, transpose, convert back to CSR and apply the above.']], [[' def logsumexp_row_nonzeros(X):\n    result = np.empty(X.shape[0])\n    for i in range(X.shape[0]):\n        result[i] = logsumexp(X.data[X.indptr[i]:X.indptr[i+1]])\n    return result\n']], ['Log-sum-exp trick on a sparse matrix in scipy'], 7, 1], [(24097930, 1), [['-10000'], ['-10000']], [[' @app.route(\'/<slug>\')\ndef feature(slug):\n    if slug_in_database(slug):\n        return "feature: " + slug\n    with app.test_request_context(url_for(\'catch\', url=slug))\n        return catch(slug)\n\n@app.route(\'/<path:url>\')\ndef catch(url):\n    return "catch: " + url\n']], ['Skip/pass over view function so the next can execute in Flask'], 3, 1], [(24097930, 2), [['-10000'], ['-10000']], [[' @app.route(\'/<path:url>\')\ndef feature_or_catch(url):\n    slug  = url\n    if \'/\' not in slug and slug_in_database(slug):\n        return "feature: " + slug\n    return "catch: " + url\n']], ['Skip/pass over view function so the next can execute in Flask'], 3, 1], [(24103624, 0), [['You could also look at  meshgrid ,  mgrid , and/or  indices :'], ['This works because  x  and  y  are arrays with the appropriate  x  and  y  coordinates:']], [[' >>> H, W = 4,5\n>>> x, y = np.indices([H, W])\n>>> m\narray([[  0. ,   0.5,   2. ,   4.5,   8. ],\n       [  0.5,   1. ,   2.5,   5. ,   8.5],\n       [  2. ,   2.5,   4. ,   6.5,  10. ],\n       [  4.5,   5. ,   6.5,   9. ,  12.5]])\n']], ['NumPy map calculation depending on the indices'], 3, 1], [(24103624, 1), [['This works because  x  and  y  are arrays with the appropriate  x  and  y  coordinates:'], ['meshgrid  and  mgrid  allow for finer control, e.g. ']], [[' >>> x\narray([[0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1],\n       [2, 2, 2, 2, 2],\n       [3, 3, 3, 3, 3]])\n>>> y\narray([[0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4]])\n']], ['NumPy map calculation depending on the indices'], 3, 0], [(24103624, 2), [['meshgrid  and  mgrid  allow for finer control, e.g. '], ['-10000']], [[' >>> x, y = np.meshgrid(np.linspace(0, 1, 5), np.linspace(0, 10, 3))\n>>> x\narray([[ 0.  ,  0.25,  0.5 ,  0.75,  1.  ],\n       [ 0.  ,  0.25,  0.5 ,  0.75,  1.  ],\n       [ 0.  ,  0.25,  0.5 ,  0.75,  1.  ]])\n>>> y\narray([[  0.,   0.,   0.,   0.,   0.],\n       [  5.,   5.,   5.,   5.,   5.],\n       [ 10.,  10.,  10.,  10.,  10.]])\n']], ['NumPy map calculation depending on the indices'], 3, 1], [(24108842, 0), [['One option is to convert it to a list of sublists (a sublist for each row) with a list comprehension:'], ['Another option is reshaping the list as a numpy array (but this has the disadvantage to leading to a column with object dtype as noted by @DSM, so to end up with the same result as above, the column should be set as float manually):']], [[' In [10]: x_sublists = [x[i:i+3] for i in range(0, len(x), 3)]\n\nIn [11]: pd.DataFrame(x_sublists [1:], columns=x_sublists [0])\nOut[11]: \n   Phase            Formula                Sat Indx\n0  Calcite          CaCO3            0.840931478691\n1  Aragonite        CaCO3            0.697161631298\n2  H2O(g)           H2O              -1.51011433303\n3  CO2(g)           CO2              -1.55228705787\n4  Gypsum           CaSO4:2H2O        -2.9936491424\n5  Anhydrite        CaSO4            -3.21352846684\n6  Portlandite      Ca(OH)2          -10.7380672515\n7  H2(g)            H2                        -22.6\n8  O2(g)            O2                -37.987869775\n9  CH4(g)           CH4              -66.1697168119\n']], ['Converting and reshaping a list into a DataFrame in Pandas'], 2, 1], [(24108842, 1), [['Another option is reshaping the list as a numpy array (but this has the disadvantage to leading to a column with object dtype as noted by @DSM, so to end up with the same result as above, the column should be set as float manually):'], ['-10000']], [[" In [67]: x_reshaped = np.array(x[3:], dtype=object).reshape((-1, 3))\n\nIn [68]: df = pd.DataFrame(x_reshaped, columns=x[:3])\n\nIn [69]: df['Sat Indx'] = df['Sat Indx'].astype(float)\n"]], ['Converting and reshaping a list into a DataFrame in Pandas'], 2, 1], [(24127569, 0), [['If you have a 2d numpy array, you can use the  sort  method on arrays, and specify  axis=0 :'], ['And then you can transpose this if you want to work with the rows and not the columns:']], [[' >>> d\narray([[ 0.17 ,  0.045,  0.01 ],\n       [ 0.28 ,  0.1  ,  0.19 ],\n       [ 0.31 ,  0.19 ,  0.09 ],\n       [ 0.36 ,  0.42 ,  0.38 ],\n       [ 0.62 ,  0.02 ,  0.03 ],\n       [ 0.32 ,  0.12 ,  0.26 ]])\n>>> d2 = d.copy()\n>>> d2.sort(axis=0)\n>>> d2\narray([[ 0.17 ,  0.02 ,  0.01 ],\n       [ 0.28 ,  0.045,  0.03 ],\n       [ 0.31 ,  0.1  ,  0.09 ],\n       [ 0.32 ,  0.12 ,  0.19 ],\n       [ 0.36 ,  0.19 ,  0.26 ],\n       [ 0.62 ,  0.42 ,  0.38 ]])\n']], ['Sort individual components of a list in python'], 2, 0], [(24127569, 1), [['And then you can transpose this if you want to work with the rows and not the columns:'], ['Et cetera.']], [[' >>> d2.T\narray([[ 0.17 ,  0.28 ,  0.31 ,  0.32 ,  0.36 ,  0.62 ],\n       [ 0.02 ,  0.045,  0.1  ,  0.12 ,  0.19 ,  0.42 ],\n       [ 0.01 ,  0.03 ,  0.09 ,  0.19 ,  0.26 ,  0.38 ]])\n>>> for row in d2.T:\n...     print(row)\n...     \n[ 0.17  0.28  0.31  0.32  0.36  0.62]\n[ 0.02   0.045  0.1    0.12   0.19   0.42 ]\n[ 0.01  0.03  0.09  0.19  0.26  0.38]\n']], ['Sort individual components of a list in python'], 2, 0], [(24129445, 0), [['Content of sample file:'], ['Code:']], [[' {"somestring":"myfunction"}\n']], ['Clean way to manage parse-dictionaries that contain function names'], 4, 0], [(24129445, 1), [['Code:'], ['First you load the dictionary from a file as illustrated in the code above. After that, you build a new dictionary where the strings of the function names are replaced by the actual functions. Demo:']], [[" import json\nd = json.load(open('very_small_dic.txt', 'r'))\nprint(d) # {'somestring': 'myfunction'}\n"]], ['Clean way to manage parse-dictionaries that contain function names'], 4, 0], [(24144766, 0), [['Overload the  __iter__  special method : '], ['-10000']], [[' >>> class C(object):\n...     def __init__(self, lst):\n...         self.lst = lst\n...     def __iter__(self):\n...         return iter(self.lst)\n...\n>>> def f(a, b, c):\n...     print "Arguments: ", a, b, c\n...\n>>> c = C([1, 2, 3])\n>>> f(*c)\nArguments:  1 2 3\n>>>\n']], ['What does a class need to implement in order to be used as an argument tuple?'], 2, 1], [(24144766, 1), [['-10000'], ['-10000']], [[' >>> class C(object):\n...     def __init__(self, lst):\n...         self.lst = lst\n...     def __getitem__(self, key):\n...         return self.lst[key]\n...\n>>> def f(a, b, c):\n...     print "Arguments: ", a, b, c\n...\n>>> c = C([1, 2, 3])\n>>> f(*c)\nArguments:  1 2 3\n>>>\n']], ['What does a class need to implement in order to be used as an argument tuple?'], 2, 1], [(24145957, 0), [['You can include a capture group (using parentheses) to select the part you want:'], ["but your regex seems odd - it gets a digit ( '\\d' ) followed by  any character  ( '.'  -  not  a full stop) followed by a digit followed by any character. You may be better with:"]], [['  StartTime = re.findall(r"StartTime (\\d.\\d.)", text)\n                                  # ^ capture this part\n']], ['Python regular expression: get result without the search string used'], 3, 1], [(24145957, 1), [["but your regex seems odd - it gets a digit ( '\\d' ) followed by  any character  ( '.'  -  not  a full stop) followed by a digit followed by any character. You may be better with:"], ["which is a digit followed by a full stop ( '\\.'  - note backslash to escape) followed by two digits."]], [[' StartTime = re.findall(r"StartTime (\\d\\.\\d{2})", text)\n']], ['Python regular expression: get result without the search string used'], 3, 1], [(24145957, 2), [["which is a digit followed by a full stop ( '\\.'  - note backslash to escape) followed by two digits."], ['-10000']], [[' >>> import re\n>>> s = """[AC 2 StartTime 3.29 s   32912KB -> 27720KB   24.54 ms]\n[AC 3 StartTime 3.35 s   39404KB -> 36252KB   11.05 ms]\n[AC 4 StartTime 3.55 s   44592KB -> 39316KB   1.91 ms]"""\n>>> re.findall(r"StartTime (\\d\\.\\d{2})", s)\n[\'3.29\', \'3.35\', \'3.55\']\n']], ['Python regular expression: get result without the search string used'], 3, 1], [(24162868, 0), [['In Python you can use  functools.partial  to pass the method like a function pre-defining  self  argument:'], ['But you  cannot  define such a partial function in C. For this reason I would externalize the integrand and define it as one parameter of your class, instead of an extra method. Note that this is like using a static method, but  Cython does not support it yet . Another important tip is to use  log  form  math.h . See the prototype below:']], [[' from functools import partial\n\nfoo = Foo()\nintegrand_func = partial(Foo._integrand, foo)\n']], ['Use a class method as an integrand to GSL QAGS'], 2, 1], [(24172896, 0), [['First off just to demonstrate that reading this  in  is fine:'], ['You have to use  quoting=csv.QUOTING_NONNUMERIC * when outputing the csv:']], [[" In [11]: df = pd.read_clipboard(sep=',', index_col=0)\n\nIn [12]: df\nOut[12]:\n   pgtime  pgstat  age  eet     g2  grade  gleason      ploidy\n1     6.1       0   64    2  10.26      2        4     diploid\n2     9.4       0   62    1    NaN      3        8   aneuploid\n3     5.2       1   59    2   9.99      3        7     diploid\n4     3.2       1   62    2   3.57      2        4     diploid\n5     1.9       1   64    2  22.56      4        8  tetraploid\n6     4.8       0   69    1   6.14      3        7     diploid\n7     5.8       0   75    2  13.69      2      NaN  tetraploid\n8     7.3       0   71    2    NaN      3        7   aneuploid\n9     3.7       1   73    2  11.77      3        6     diploid\n"]], ['Pandas, to_csv () to a specific format'], 3, 0], [(24172896, 1), [['You have to use  quoting=csv.QUOTING_NONNUMERIC * when outputing the csv:'], ["Now, this isn't  quite  what you want, since the index column is not quoted, I would just modify the index:"]], [[' In [21]: s = StringIO()\n\nIn [22]: df.to_csv(s, quoting=2)  # or output to file instead\n\nIn [23]: s.getvalue()\nOut[23]: \'"","pgtime","pgstat","age","eet","g2","grade","gleason","ploidy"\\n1,6.1,0,64,2,10.26,2,4.0,"diploid"\\n2,9.4,0,62,1,"",3,8.0,"aneuploid"\\n3,5.2,1,59,2,9.99,3,7.0,"diploid"\\n4,3.2,1,62,2,3.57,2,4.0,"diploid"\\n5,1.9,1,64,2,22.56,4,8.0,"tetraploid"\\n6,4.8,0,69,1,6.14,3,7.0,"diploid"\\n7,5.8,0,75,2,13.69,2,"","tetraploid"\\n8,7.3,0,71,2,"",3,7.0,"aneuploid"\\n9,3.7,1,73,2,11.77,3,6.0,"diploid"\\n\'\n']], ['Pandas, to_csv () to a specific format'], 3, 0], [(24172896, 2), [["Now, this isn't  quite  what you want, since the index column is not quoted, I would just modify the index:"], ['As required.']], [[' In [24]: df.index = df.index.astype(str)  # unicode in python 3?\n\nIn [25]: s = StringIO()\n\nIn [26]: df.to_csv(s, quoting=2)\n\nIn [27]: s.getvalue()\nOut[27]: \'"","pgtime","pgstat","age","eet","g2","grade","gleason","ploidy"\\n"1",6.1,0,64,2,10.26,2,4.0,"diploid"\\n"2",9.4,0,62,1,"",3,8.0,"aneuploid"\\n"3",5.2,1,59,2,9.99,3,7.0,"diploid"\\n"4",3.2,1,62,2,3.57,2,4.0,"diploid"\\n"5",1.9,1,64,2,22.56,4,8.0,"tetraploid"\\n"6",4.8,0,69,1,6.14,3,7.0,"diploid"\\n"7",5.8,0,75,2,13.69,2,"","tetraploid"\\n"8",7.3,0,71,2,"",3,7.0,"aneuploid"\\n"9",3.7,1,73,2,11.77,3,6.0,"diploid"\\n\'\n']], ['Pandas, to_csv () to a specific format'], 3, 0], [(24191793, 0), [['Here is a quick and dirty fix for your code (can be improved further!):'], ['Update : Modified version to check for a harcoded name only:']], [[' import os\n#hard code the path to the external file\nexternal_file = \'names.txt\'\n#Ask the user\'s name\nname = raw_input("What\'s your name?")\n#if file exists, use it to load name, else create a new file\nif not os.path.exists(external_file):\n    with open(external_file, "a") as f: # using "a" will append to the file\n        f.write(name)\n        f.write("\\n")\n        f.close()\nelse:\n    #if file exists, use it to load name, else ask user\n    with open(external_file, "r+") as f:# r+ open a file for reading & writing\n        lines = f.read().split(\'\\n\') # split the names \n        #print lines\n        if name in lines:\n            print "Hi {}".format(name)\n        else:\n            f.seek(0,2) # Resolves an issue in Windows\n            f.write(name)\n            f.write("\\n")\n            f.close()\n']], ['Store input based on computer and change stored input on command'], 2, 1], [(24191793, 1), [['Update : Modified version to check for a harcoded name only:'], ['Reason for using  file.seek()  is  here .']], [[' import os\n#hard code the path to the external file\nexternal_file = \'names.txt\'\nusername = \'testuser\'# Our hardcoded name\n\n#if file doesn\' exists, create a new file\nif not os.path.exists(external_file):\n    #Ask the user\'s name\n    name = raw_input("What\'s your name?")\n    with open(external_file, "a") as f: # using "a" will append to the file\n        f.write(name)# Write the name to names.txt\n        f.write("\\n")\n        f.close()\nelse:\n    #if file exists, use it to load name, else ask user\n    with open(external_file, "r+") as f:# r+ open a file for reading & writing\n        lines = f.read().split(\'\\n\') # split the names \n        print lines\n        if username in lines: #Check if the file has any username as \'testuser\'\n            print "Hi {}".format(username)\n        else: # If there is no username as \'testuser\' then ask for a name\n            name = raw_input("What\'s your name?")\n            f.seek(0,2) # Resolves an issue in Windows\n            f.write(name)# Write the name to names.txt\n            f.write("\\n")\n            f.close()\n']], ['Store input based on computer and change stored input on command'], 2, 1], [(24195234, 0), [['Example:'], ['and usage:']], [[' def pause_wrapper(x, n):\n    def decorator(f):\n        config = [x, time.time()+n]\n        def wrapped(*args, **kwargs):\n            if config[0] == 0:\n                time.sleep(config[1] - time.time())\n                config = [x, time.time() + n]\n\n            return f(*args, **kwargs)\n        return wrapped\n    return decorator\n']], ['Dynamically pass parameters to function'], 2, 1], [(24195234, 1), [['and usage:'], ['-10000']], [[' @pause_wrapper(x, n)\ndef function(a, b, c):\n    ...\n']], ['Dynamically pass parameters to function'], 2, 0], [(24195898, 0), [['Since you are already using numpy:'], ['outputs:']], [[' np.swapaxes(np.swapaxes(myArray,0,2),0,1)\n']], ['generate lists from 3 dimensional array'], 2, 1], [(24195898, 1), [['outputs:'], ['-10000']], [[' array([[[ 1,  0,  2],\n        [ 2,  1,  3],\n        [ 3,  2,  4]],\n\n       [[ 0,  1,  5],\n        [ 0,  1,  6],\n        [ 0,  1,  7]],\n\n       [[ 2,  3,  8],\n        [ 2,  3,  9],\n        [ 2,  3, 10]]])\n']], ['generate lists from 3 dimensional array'], 2, 0], [(24216198, 0), [['Try the following code:'], ['This runs as:']], [[" def unique_words(input_file):\n    file = open(input_file)\n    wordlist = {}\n    dups = []\n    copy = []\n    for index, value in enumerate(file):\n        words = value.split()\n        for word in words:\n            wordlist[word] = index\n            dups.append(word)\n    for word in dups:\n        if dups.count(word) != 1 and word not in copy:\n            del(wordlist[word])\n            copy.append(word)\n    for item in wordlist:\n        print 'The unique word '+item+' occurs on line '+str(wordlist[item])\n"]], ['Storing a string and a set in a dictionary'], 2, 1], [(24216198, 1), [['This runs as:'], ['-10000']], [[" >>> unique_words('test.txt')\nThe unique word them occurs on line 2\nThe unique word I occurs on line 1\nThe unique word there occurs on line 0\nThe unique word some occurs on line 2\nThe unique word times occurs on line 3\nThe unique word say occurs on line 2\nThe unique word too occurs on line 3\nThe unique word have occurs on line 1\nThe unique word of occurs on line 2\n>>> \n"]], ['Storing a string and a set in a dictionary'], 2, 0], [(24243929, 1), [['If you want the first solution (mouse clicks), then add:'], ['Otherwise (key pressing), use:']], [[' WM_KEYDOWN = 0x0100\nWM_KEYUP = 0x0101\n\ndef point_to_long(x, y):\n    return (y * 0x10000) + x\n\ndef show_menu(handle):\n    target_pos = point_to_long(30, 40)\n    send_message(window_handle, WM_LBUTTONDOWN, 0, target_pos)\n    send_message(window_handle, WM_LBUTTONUP, 0, target_pos)\n']], ['Display menu bar items of IE using Python'], 3, 0], [(24243929, 2), [['Otherwise (key pressing), use:'], ['Hope this helps.']], [[' VK_MENU = 0x12\nVK_F = 0x46\n\ndef show_menu(handle):\n    for key in (VK_MENU, VK_F):\n        send_message(window_handle, WM_KEYDOWN, key, 0)\n        send_message(window_handle, WM_KEYUP, key, 0)\n']], ['Display menu bar items of IE using Python'], 3, 0], [(24269756, 0), [['You could use  img.putdata :'], ['If you have NumPy, you could instead use  Image.fromarray :']], [[' import Image\n\nvalue = "0110100001100101011011000110110001101111"\n\ncmap = {\'0\': (255,255,255),\n        \'1\': (0,0,0)}\n\ndata = [cmap[letter] for letter in value]\nimg = Image.new(\'RGB\', (8, len(value)//8), "white")\nimg.putdata(data)\nimg.show()        \n']], ['Turning binary string into an image with PIL'], 4, 1], [(24269756, 1), [['If you have NumPy, you could instead use  Image.fromarray :'], ['but this timeit test suggests using  putdata  is faster:']], [[' import Image\nimport numpy as np\n\nvalue = "0110100001100101011011000110110001101111"\n\ncarr = np.array([(255,255,255), (0,0,0)], dtype=\'uint8\')\ndata = carr[np.array(map(int, list(value)))].reshape(-1, 8, 3)\nimg = Image.fromarray(data, \'RGB\')\nimg.save(\'/tmp/out.png\', \'PNG\')\n']], ['Turning binary string into an image with PIL'], 4, 1], [(24269756, 2), [['but this timeit test suggests using  putdata  is faster:'], ['-10000']], [[' value = "0110100001100101011011000110110001101111"*10**5\n\ndef using_fromarray():\n    carr = np.array([(255,255,255), (0,0,0)], dtype=\'uint8\')\n    data = carr[np.array(map(int, list(value)))].reshape(-1, 8, 3)\n    img = Image.fromarray(data, \'RGB\')\n    return img\n\ndef using_putdata():\n    cmap = {\'0\': (255,255,255),\n            \'1\': (0,0,0)}\n\n    data = [cmap[letter] for letter in value]\n    img = Image.new(\'RGB\', (8, len(value)//8), "white")\n    img.putdata(data)\n    return img\n']], ['Turning binary string into an image with PIL'], 4, 1], [(24269756, 3), [['-10000'], ['-10000']], [[' In [79]: %timeit using_fromarray()\n1 loops, best of 3: 1.67 s per loop\n\nIn [80]: %timeit using_putdata()\n1 loops, best of 3: 632 ms per loop\n']], ['Turning binary string into an image with PIL'], 4, 0], [(24285311, 0), [["AFAIK  optparse  doesn't provide that value in the public API via the result of  parse_args , but you don't need it.\nYou can simply name the constant before using it:"], ['In fact the  add_option  method returns the  Option  object which does have the  nargs  field, so you could do:']], [[" NUM_CATEGORIES = 4\n\n# ...\n\nparser.add_option('-c', '--categories', dest='categories', nargs=NUM_CATEGORIES)\n\n# later\n\nif not options.categories:\n    options.categories = [raw_input('Enter input: ') for _ in range(NUM_CATEGORIES)]\n"]], ['how to access nargs of optparse-add_action?'], 2, 0], [(24285311, 1), [['In fact the  add_option  method returns the  Option  object which does have the  nargs  field, so you could do:'], ["However I really don't see how this is better than using a costant in the first place."]], [[" categories_opt = parser.add_option(..., nargs=4)\n\n# ...\n\nif not options.categories:\n    options.categories = [raw_input('Enter input: ') for _ in range(categories_opt.nargs)]\n"]], ['how to access nargs of optparse-add_action?'], 2, 0], [(24314839, 0), [["I'm not sure if this is supported in OptionParser, but I would suggest using a triple quote \ni.e:  "], ['argparse example:  ']], [[" parser = OptionParser()\nparser.add_option('--s',\n                  dest='s'\n                  type='string'\n                  help='''\nWith triple quotes I can directly put in anything including line spaces.\n\\n will appear as a string rather than a newline.''')\n"]], ['How to string format OptionParser() help message?'], 2, 1], [(24314839, 1), [['argparse example:  '], ['-10000']], [[" import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument('--s',\n                  help='''first line\nsecond line''')\nargs = parser.parse_args()\nprint args.s\n"]], ['How to string format OptionParser() help message?'], 2, 1], [(24319973, 0), [['The better approach for achieving your requirement is to use the inbuilt  Group  and  Permissions  model in Django. But since  Permissions  can be a little tricky, an alternative approach is to create a  UserProfile  model like below:'], ['Then use decorators for controlling access to the views like this:']], [[' from django.contrib.auth.models import User\nclass UserProfile(models.Model):\n    user = models.ForeignKey(User)\n    type = models.CharField(max_length=15)\n']], ['How to handle multiple user type in Django'], 3, 0], [(24319973, 1), [['Then use decorators for controlling access to the views like this:'], ['The  UserProfile  model will also be useful to save all of the preferences of your user. Also you would need to set the following setting:']], [[" from django.contrib.auth.decorators import user_passes_test\n@user_pass_test(lambda u: u.get_profile().type == 'client')\ndef view_for_client(request):\n    ...\n"]], ['How to handle multiple user type in Django'], 3, 0], [(24319973, 2), [['The  UserProfile  model will also be useful to save all of the preferences of your user. Also you would need to set the following setting:'], ['-10000']], [[" AUTH_PROFILE_MODULE = 'accounts.UserProfile'\n"]], ['How to handle multiple user type in Django'], 3, 0], [(24325232, 0), [['So I finally managed to do this by creating a new scale in matplotlib. It can be improved but here is my class definition, based on  http://matplotlib.org/examples/api/custom_scale_example.html  :'], ['And here is a working example :']], [[" import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom matplotlib import scale as mscale\nfrom matplotlib import transforms as mtransforms\n\nclass MagScale(mscale.ScaleBase):\n    name = 'mag'\n\n    def __init__(self, axis, **kwargs):\n        mscale.ScaleBase.__init__(self)\n        self.thresh = None #thresh\n\n    def get_transform(self):\n        return self.MagTransform(self.thresh)\n\n    def set_default_locators_and_formatters(self, axis):\n        pass\n\n    class MagTransform(mtransforms.Transform):\n        input_dims = 1\n        output_dims = 1\n        is_separable = True\n\n        def __init__(self, thresh):\n            mtransforms.Transform.__init__(self)\n            self.thresh = thresh\n\n        def transform_non_affine(self, mag):\n            return 10**((np.array(mag) -1)/(-2.5))\n\n        def inverted(self):\n            return MagScale.InvertedMagTransform(self.thresh)\n\n    class InvertedMagTransform(mtransforms.Transform):\n        input_dims = 1\n        output_dims = 1\n        is_separable = True\n\n        def __init__(self, thresh):\n            mtransforms.Transform.__init__(self)\n            self.thresh = thresh\n\n        def transform_non_affine(self, flux):\n            return -2.5 * np.log10(np.array(flux)) + 1.\n\n        def inverted(self):\n            return MagScale.MagTransform(self.thresh)\n\n\n\ndef flux_to_mag(flux):\n    return  -2.5 * np.log10(flux) + 1\n\n\nmscale.register_scale(MagScale)\n"]], ['Two corresponding y-axis'], 2, 1], [(24325232, 1), [['And here is a working example :'], ['-10000']], [[" x    = np.arange(20.)\nflux = x * 2 + 1\nmag  = flux_to_mag(flux)\n\nMagTransform = MagScale.InvertedMagTransform(0)\n\n\nfig = plt.figure()\nax_flux = fig.add_subplot(111)\n\nax_flux.plot(x, flux,'-')\nax_flux.set_ylim([1,40])\nax_flux.set_ylabel('flux')\n\nax_mag  = ax_flux.twinx()\nax_mag.set_ylim(MagTransform.transform_non_affine(ax_flux.get_ylim())) #There may be an easier to do this.\nax_mag.set_yscale('mag')\n\nax_mag.plot(x,mag,'+')\nplt.show()\n"]], ['Two corresponding y-axis'], 2, 0], [(24327683, 0), [['You can directly use column indexing ( http://pandas.pydata.org/pandas-docs/stable/indexing.html ) to compare and filter ratios.'], ['Here is the solution using apply - First define a function operating in  rows  of the DataFrame.']], [[' buy_ratio = (abs(df["Buy"])  > abs(df["Sell"])) * df["Price"] / df["Buy"]\nsell_ratio = (abs(df["Buy"])  <= abs(df["Sell"])) * df["Price"] / df["Sell"]\ndf["Ratio"] = buy_ratio + sell_ratio\n']], ['Pandas Dataframe row by row fill new column'], 2, 1], [(24327683, 1), [['Here is the solution using apply - First define a function operating in  rows  of the DataFrame.'], ['Finally, set the  Ratio  column appropriately using apply.']], [[' def f(row):\n  if abs(row["Buy"]) > abs(row["Sell"]):\n    return row["Price"] / row["Buy"]\n  else:\n    return row["Price"] / row["Sell"]\n']], ['Pandas Dataframe row by row fill new column'], 2, 1], [(24406677, 0), [['-10000'], ['Which can be read as follows:']], [['<code>data.yaml</code> MyHome:\n- "10.0.0.3"\n- "10.0.0.9"\n- "10.0.0.234"\n']], ['Python array from CSV file'], 3, 0], [(24406677, 1), [['Which can be read as follows:'], ['Before you run it, you have to install PyYaml']], [[' >>> import yaml\n>>> fname = "data.yaml"\n>>> with open(fname) as f:\n...     cfg = yaml.load(f)\n...\n>>> cfg\n{\'MyHome\': [\'10.0.0.3\', \'10.0.0.9\', \'10.0.0.234\']}\n']], ['Python array from CSV file'], 3, 0], [(24406677, 2), [['Before you run it, you have to install PyYaml'], ['-10000']], [[' $ pip install pyyaml\n']], ['Python array from CSV file'], 3, 0], [(24418864, 0), [['You can create a circular buffer with the names.'], ['and then change a counter']], [[" images = ['data/down1.png','data/down2.png','data/down3.png']\n"]], ['Pygame How to use walking animations'], 2, 0], [(24418864, 1), [['and then change a counter'], ['It will change the image while the button is pressed.']], [[' ...\n\nif event.type == pygame.KEYDOWN and event.key == pygame.K_DOWN:\n    player = pygame.image.load(images[counter])\n    counter = (counter + 1) % len(images)\n    playerY = playerY + 5\n...\n']], ['Pygame How to use walking animations'], 2, 0], [(24427828, 0), [['Okay, there is an out-of-the-box solution with geopy, it is just not well-documented:'], ['A simple solution would be:']], [[' import geopy\nimport geopy.distance\n\n# Define starting point.\nstart = geopy.Point(48.853, 2.349)\n\n# Define a general distance object, initialized with a distance of 1 km.\nd = geopy.distance.VincentyDistance(kilometers = 1)\n\n# Use the `destination` method with a bearing of 0 degrees (which is north)\n# in order to go from point `start` 1 km to north.\nprint d.destination(point=start, bearing=0)\n']], ['Calculate point based on distance and direction'], 5, 1], [(24427828, 3), [['Edit:  an example implementation of my proposal:'], ['Output:']], [[' import geopy\nimport geopy.distance\nimport scipy.optimize\n\n\ndef north(startpoint, distance_km):\n    """Return target function whose argument is a positive latitude\n    change (in degrees) relative to `startpoint`, and that has a root\n    for a latitude offset that corresponds to a point that is \n    `distance_km` kilometers away from the start point.\n    """\n    def target(latitude_positive_offset):\n        return geopy.distance.distance(\n            startpoint, geopy.Point(\n                latitude=startpoint.latitude + latitude_positive_offset,\n                longitude=startpoint.longitude)\n            ).km - distance_km\n    return target\n\n\nstart = geopy.Point(48.853, 2.349)\nprint "Start: %s" % start\n\n# Find the root of the target function, vary the positve latitude offset between\n# 0 and 2 degrees (which is for sure enough for finding a 1 km distance, but must\n# be adjusted for larger distances).\nlatitude_positive_offset = scipy.optimize.bisect(north(start, 1),  0, 2)\n\n\n# Build Point object for identified point in space.\nend = geopy.Point(\n    latitude=start.latitude + latitude_positive_offset,\n    longitude=start.longitude\n    )\n\nprint "1 km north: %s" % end\n\n# Make the control.\nprint "Control distance between both points: %.4f km." % (\n     geopy.distance.distance(start, end).km)\n']], ['Calculate point based on distance and direction'], 5, 1], [(24427828, 4), [['Output:'], ['-10000']], [[' $ python test.py \nStart: 48 51m 0.0s N, 2 21m 0.0s E\n1 km north: 48 52m 0.0s N, 2 21m 0.0s E\nControl distance between both points: 1.0000 km.\n']], ['Calculate point based on distance and direction'], 5, 0], [(24438325, 1), [['or possibly using xpath with a parameter:'], ['This assumes, you have  lxml  installed:']], [[' xp = "//PropertySetProperty[Key/text()=$key]/Value/text()"\nwanted = doc.xpath(xp, key="ConnectionFile")[0]\n']], ['parsing single text items from xml with Python'], 4, 0], [(24438325, 2), [['This assumes, you have  lxml  installed:'], ['On windows better use:']], [[' $ pip install lxml\n']], ['parsing single text items from xml with Python'], 4, 0], [(24438325, 3), [['On windows better use:'], ['as it will install from downloaded exe installer and will not try to compile from sources.']], [[' $ easy_install lxml\n']], ['parsing single text items from xml with Python'], 4, 0], [(24445991, 0), [['You can also run a python script with command line input from AppleScript:'], ["Ned's example has python calling AppleScript, then returning control to python, this is the other way around. Then in Python access list of parameters:"]], [[' --make sure to escape properly if needed\nset pythonvar to "whatever"\nset outputvar to (do shell script "python \'/path/to/script\' \'" & pythonvar & "\'")\n']], ['Getting Variable from Applescript and using in Python'], 2, 1], [(24445991, 1), [["Ned's example has python calling AppleScript, then returning control to python, this is the other way around. Then in Python access list of parameters:"], ['-10000']], [[" import sys\nvar_from_as = sys.argv[1] # for 1rst parameter cause argv[0] is file name\nprint 'this gets returned to AppleScript' # this gets set to outputvar\n"]], ['Getting Variable from Applescript and using in Python'], 2, 1], [(24458430, 0), [['At the beginning of my stored procedure, I execute the line'], ['And at the end of the stored procedure,']], [[' update RunningStatus set status = 1;\n']], ['make python wait for stored procedure to finish executing'], 3, 0], [(24458430, 1), [['And at the end of the stored procedure,'], ['In my Python script, I open a new connection and cursor to the same database. After my  execute  line, I simply add']], [[' update RunningStatus set status = 0;\n']], ['make python wait for stored procedure to finish executing'], 3, 0], [(24458430, 2), [['In my Python script, I open a new connection and cursor to the same database. After my  execute  line, I simply add'], ['You need to make a new connection and cursor, because any calls from the old connection will interrupt the stored procedure and potentially cause  status  to never go back to 0.']], [[" while 1:\n    q = status_check_cursor.execute('select status from RunningStatus').fetchone()\n    if q[0] == 0:\n        break\n"]], ['make python wait for stored procedure to finish executing'], 3, 0], [(24465953, 0), [["You're looking for the break statement."], ["and then use that to break out of every other two for loops you've initiated."]], [[' ...\n    if "color=brown" in part:\n        print part\n        # set some variable to check at the last thing before your other for loops\n        # turnover.\n        br = True\n        break\n']], ['python read files and stop when a condition satisfies'], 2, 0], [(24465953, 1), [["and then use that to break out of every other two for loops you've initiated."], ['-10000']], [['     if br == True:\n        break\n    else:\n        pass\nif br == True:\n    break\nelse:\n    pass\n']], ['python read files and stop when a condition satisfies'], 2, 0], [(24481614, 0), [['Rather than accessing the  table.c  by attribute, use the  get  method.'], ['Remember to sanitize your inputs; you can probably check for whether  field in table.c']], [[' >>> from sqlalchemy import MetaData, Table, Integer, Column, create_engine\n>>> engine = create_engine(\'sqlite://\')\n>>> metadata = MetaData(bind=engine)\n>>> table = Table("Bookings", metadata,\n...     Column(\'id\', Integer(), primary_key=True,),\n...     Column(\'value\', Integer(),),\n... )\n>>> field = \'value\'\n>>> table.c.get(field)\nColumn(\'value\', Integer(), table=<Bookings>)\n>>> table.c[field]\nColumn(\'value\', Integer(), table=<Bookings>)\n']], ['SqlAlchemy Dynamic Where'], 2, 1], [(24481614, 1), [['Remember to sanitize your inputs; you can probably check for whether  field in table.c'], ["Looks like this isn't officially documented , but it works."]], [[" >>> field in table.c\nTrue\n>>> 'id' in table.c\nTrue\n>>> 'nothere' in table.c\nFalse\n"]], ['SqlAlchemy Dynamic Where'], 2, 0], [(24495059, 0), [['Using the following input:'], ['and this script:']], [[' IGHV3-23-IGHJ4-CAKDRGYTGYGVYFDYW\nIGHV4-39-IGHJ4-CARHDILTGYSYYFDYW\nIGHV3-23-IGHJ3-CAKSGGWYLSDAFDIW\nIGHV4-39-IGHJ4-CARTGFGELGFDYW\nIGHV1-2-IGHJ2-CARDSDYDWYFDLW\nIGHV1-8-IGHJ3-CARGQTYYDILTGPSDAFDIW\nIGHV4-39-IGHJ5-CARSTGDWFDPW\nIGHV3-9-IGHJ3-CANVPIYSSSYDAFDIW\nIGHV3-23-IGHJ4-CAKDWELYYFDYW\nIGHV3-23-IGHJ4-CAKDRGYTGFGVYFDYW\nIGHV4-39-IGHJ4-CARHLGYNNSWYPFDYW\nIGHV1-2-IGHJ4-CAREGYNWNDEGRFDYW\nIGHV3-23-IGHJ3-CAKSSGWYLSDAFDIW\nIGHV4-39-IGHJ4-CARYLGYNSNWYPFDYW\nIGHV3-23-IGHJ6-CAKEGCSSGCPYYYYGMDVW\nIGHV3-23-IGHJ3-CAKWGPDAFDIW\nIGHV3-11-IGHJ-CATSGGSP\nIGHV3-11-IGHJ4-CARDGDGYNDYW\nIGHV1-2-IGHJ4-CARRIGYSSGSEDYW\nIGHV1-2-IGHJ4-CARDIAVPGHGDYW\nIGHV6-1-IGHJ4-CASGGAVPGYYFDYW\nIGHV1-2-CAREGYNWNDEGRFDYW\nIGHV4-39-CARSTGDWFDPW\nIGHV1-2-CARDSDYDWYFDLW\n']], ['Comparing items in large list - finding items differing in 1 letter by length - Python'], 3, 0], [(24495059, 1), [['and this script:'], ['Output:']], [[' from collections import defaultdict\nfrom itertools import izip, tee\nimport os\nimport sys\n\n# http://en.wikipedia.org/wiki/Hamming_distance#Algorithm_example\ndef hamming_distance(s1, s2):\n    """ Count number of mismatched characters in equal length strings. """\n    if not isinstance(s1, basestring): raise ValueError(\'s1 is not a string\')\n    if not isinstance(s2, basestring): raise ValueError(\'s2 is not a string\')\n    if len(s1) != len(s2): raise ValueError(\'string lengths do not match\')\n    return sum(a != b for a, b in izip(s1, s2))\n\ndef pairwise(iterable):  # itertools recipe\n    "s -> (s0,s1), (s1,s2), (s2, s3), ..."\n    a, b = tee(iterable)\n    next(b, None)\n    return izip(a, b)\n\ninp = sys.argv[1]  # Input file\n\nunique = defaultdict(list)\nwith open(inp, \'rb\') as file:\n    for fields in (line.strip().split(\'-\') for line in file):\n        id = \'-\'.join(fields[:-1])  # recombine all but last field into an id\n        unique[id].append(fields[-1])  # accumulate ending fields with same id\n\nfor id in sorted(unique):\n    final_fields = unique[id]\n    final_fields.sort(key=lambda field: len(field))  # sort by length\n    print id + \':\' + \'-\'.join(final_fields)\n    if len(final_fields) > 1:  # at least one pair to compare for mismatches?\n        for a, b in pairwise(final_fields):\n            if len(a) == len(b) and hamming_distance(a, b) < 2:\n                print \'  {!r} and {!r} differ by < 2 characters\'.format(a, b)\n']], ['Comparing items in large list - finding items differing in 1 letter by length - Python'], 3, 1], [(24495059, 2), [['Output:'], ['Hope this update is also helpful...']], [[" IGHV1-2:CARDSDYDWYFDLW-CAREGYNWNDEGRFDYW\nIGHV1-2-IGHJ2:CARDSDYDWYFDLW\nIGHV1-2-IGHJ4:CARDIAVPGHGDYW-CARRIGYSSGSEDYW-CAREGYNWNDEGRFDYW\nIGHV1-8-IGHJ3:CARGQTYYDILTGPSDAFDIW\nIGHV3-11-IGHJ:CATSGGSP\nIGHV3-11-IGHJ4:CARDGDGYNDYW\nIGHV3-23-IGHJ3:CAKWGPDAFDIW-CAKSGGWYLSDAFDIW-CAKSSGWYLSDAFDIW\n  'CAKSGGWYLSDAFDIW' and 'CAKSSGWYLSDAFDIW' differ by < 2 characters\nIGHV3-23-IGHJ4:CAKDWELYYFDYW-CAKDRGYTGYGVYFDYW-CAKDRGYTGFGVYFDYW\n  'CAKDRGYTGYGVYFDYW' and 'CAKDRGYTGFGVYFDYW' differ by < 2 characters\nIGHV3-23-IGHJ6:CAKEGCSSGCPYYYYGMDVW\nIGHV3-9-IGHJ3:CANVPIYSSSYDAFDIW\nIGHV4-39:CARSTGDWFDPW\nIGHV4-39-IGHJ4:CARTGFGELGFDYW-CARHDILTGYSYYFDYW-CARHLGYNNSWYPFDYW-CARYLGYNSNWYPFDYW\nIGHV4-39-IGHJ5:CARSTGDWFDPW\nIGHV6-1-IGHJ4:CASGGAVPGYYFDYW\n"]], ['Comparing items in large list - finding items differing in 1 letter by length - Python'], 3, 0], [(24495452, 0), [["For doing a curve fit, I suggest to use not the density but the cumulative distribution: Each sample has a height of  1/N , which successively sum up to 1. This has the advantage that you don't need to group samples in bins. "], ['prints']], [[' import numpy as np\nfrom scipy.stats import norm\nfrom scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\n\n# Beginning in one dimension:\nmean = 0; Var = 1; N = 100\nscatter = np.random.normal(mean,np.sqrt(Var),N)\nscatter = np.sort(scatter)\nmu1,sigma1 = norm.fit(scatter) # classical fit\n\nscat_sum = np.cumsum(np.ones(scatter.shape))/N # cumulative samples\n[mu2,sigma2],Cx = curve_fit(norm.cdf, scatter, scat_sum, p0=[0,1]) # curve fit\nprint(u"norm.fit():  µ1= {:+.4f}, σ1={:.4f}".format(mu1, sigma1))\nprint(u"curve_fit(): µ2= {:+.4f}, σ2={:.4f}".format(mu2, sigma2))\n\nfg = plt.figure(1); fg.clf()\nax = fg.add_subplot(1, 1, 1)\nt = np.linspace(-4,4, 1000)\nax.plot(t, norm.cdf(t, mu1, sigma1), alpha=.5, label="norm.fit()")\nax.plot(t, norm.cdf(t, mu2, sigma2), alpha=.5, label="curve_fit()")\nax.step(scatter, scat_sum, \'x-\', where=\'post\', alpha=.5, label="Samples")\nax.legend(loc="best")\nax.grid(True)\nax.set_xlabel("$x$")\nax.set_ylabel("Cumulative Probability Density")\nax.set_title("Fit to Normal Distribution")\n\nfg.canvas.draw()\nplt.show()\n']], ['How can I find the right gaussian curve given some data?'], 2, 1], [(24495452, 1), [['prints'], ['and plots']], [[' norm.fit():  µ1= +0.1534, σ1=1.0203\ncurve_fit(): µ2= +0.1135, σ2=1.0444\n']], ['How can I find the right gaussian curve given some data?'], 2, 0], [(24496320, 0), [['You could write a merge function like this, but you really should consider rewriting your SQL query. Here is a simple solution:'], ['A better way would be to use two select statements and merge their results together:']], [[" def merge_books(books):\n    merged = {}\n\n    for book in books:\n        authorId = book['authorId']\n\n        # Create article attribute\n        book['articles'] = [{\n            'articles.id': book['articles.id'],\n            'authorId':    book['authorId'],\n            'Title':       book['Title'],\n        }]\n\n        # Remove redundant information\n        del book['articles.id']\n        del book['authorId']\n        del book['Title']\n\n        if authorId in merged:\n            merged[authorId]['articles'].append(book['articles'][0])\n        else:\n            merged[authorId] = book\n\n    # Convert dict into a tuple, but why not a list?\n    return tuple(merged.values())\n"]], ['Combine dict with same keys into one dict with list'], 2, 1], [(24496320, 1), [['A better way would be to use two select statements and merge their results together:'], ['-10000']], [[" import MySQLdb\n\ndef get_authors_with_articles(connection):\n    cursor = connection.cursor()\n\n    authors = {}\n    for author in cursor.execute('SELECT * FROM Authors'):\n        # Initialize empty article list that will be popluated with the next select\n        author['articles'] = []\n        authors[author['id']] = author\n\n    for article in cursor.execute('SELECT * FROM Articles').fetchall():\n        # Fetch and delete redundant information\n        author_id = article['authorId']\n        del article['authorId']\n\n        authors[author_id]['articles'].append(article)\n\n    return list(authors.values())\n\n\nif __name__ == '__main__':\n    connection = MySQLdb.connect(\n        mysql_host,\n        mysql_user,\n        mysql_pass,\n        mysql_base,\n        cursorclass=MySQLdb.cursors.DictCursor\n    )\n    print(get_authors_with_articles(connection))\n"]], ['Combine dict with same keys into one dict with list'], 2, 1], [(24518769, 0), [['First I a create your dataframe:'], ['Then split data by date , and compute the mean of time lag for each date.']], [[' import pandas as pd\nfrom StringIO import StringIO\ntext = """site date time\n1   Google.com 2012-05-01 19:16:08.070000\n2   Google.com 2012-05-01 19:20:07.880000\n3   Google.com 2012-05-01 19:33:02.200000\n4   Google.com 2012-05-01 19:35:09.173000\n5   Google.com 2012-05-01 20:18:55.610000\n6   Google.com 2012-05-01 20:26:27.577000\n8   Google.com 2012-05-02 12:51:12.013000\n9   Google.com 2012-05-02 12:56:52.013000\n10  Google.com 2012-05-02 12:59:55.167000\n11  Google.com 2012-05-02 13:04:25.687000\n12  Google.com 2012-05-02 13:16:36.263000\n"""\ntab = pd.read_table(StringIO(text),index_col=0,sep=\'\\s+\')\n']], ['Average inter signout time in pandas dataframe'], 2, 0], [(24518769, 1), [['Then split data by date , and compute the mean of time lag for each date.'], ['-10000']], [[" for group,value in tab.groupby('date'):\n    print group\n    print pd.to_datetime(value.time).diff().mean()\n\n## 2012-05-01\n## 0   00:14:03.901400\n## dtype: timedelta64[ns]\n## 2012-05-02\n## 0   00:06:21.062500\n## dtype: timedelta64[ns]\n"]], ['Average inter signout time in pandas dataframe'], 2, 0], [(24584784, 0), [['You need to do your argparse in two passes:'], ['This should do the trick:']], [[' parser = ArgumentParser()\nparser.add_argument("function", \n                    nargs="?",\n                    choices=[\'function1\', \'function2\', \'function2\'],\n                    default=\'function1\',\n                    )\nargs, sub_args = parser.parse_known_args()\n\nif args.function == "function1":\n    parser = ArgumentParser()\n    parser.add_argument(\'-a\',\'--a\')\n    parser.add_argument(\'-b\',\'--b\')\n    parser.add_argument(\'-c\',\'--c\')\n    args = parser.parse_args(sub_args)\n    function1(args.a, args.b, args.c)\nelif args.function == "function2":\n    ...\nelif args.function == "function3":\n    ...\n']], ['Use argparse to call different functions'], 2, 1], [(24584784, 1), [['This should do the trick:'], ['-10000']], [[' # Parse the subcommand argument first\nparser = ArgumentParser(add_help=False)\nparser.add_argument("function", \n                    nargs="?",\n                    choices=[\'function1\', \'function2\', \'function2\'],\n                    )\nparser.add_argument(\'--help\', action=\'store_true\')\nargs, sub_args = parser.parse_known_args([\'--help\'])\n\n# Manually handle help\nif args.help:\n    # If no subcommand was specified, give general help\n    if args.function is None: \n        print parser.format_help()\n        sys.exit(1)\n    # Otherwise pass the help option on to the subcommand\n    sub_args.append(\'--help\')\n\n# Manually handle the default for "function"\nfunction = "function1" if args.function is None else args.function\n\n# Parse the remaining args as per the selected subcommand\nparser = ArgumentParser(prog="%s %s" % (os.path.basename(sys.argv[0]), function))\nif function == "function1":\n    parser.add_argument(\'-a\',\'--a\')\n    parser.add_argument(\'-b\',\'--b\')\n    parser.add_argument(\'-c\',\'--c\')\n    args = parser.parse_args(sub_args)\n    function1(args.a, args.b, args.c)\nelif function == "function2":\n    ...\nelif function == "function3":\n    ...\n']], ['Use argparse to call different functions'], 2, 1], [(24593478, 0), [['The correct way is as follows:'], ['This will give you:']], [[" Yvalues = [1, 2, 3, 4, 5]\nfile_out = open('file.csv','wb')\nmywriter=csv.writer(file_out, delimiter = '\\n')\nmywriter.writerow(Yvalues)\nfile_out.close()\n"]], ['Python and appending items to text and excel file'], 2, 1], [(24593478, 1), [['This will give you:'], ['-10000']], [[' 1\n\n2\n\n3\n\n4\n\n5\n']], ['Python and appending items to text and excel file'], 2, 0], [(24638781, 0), [['(1) and (3) are pretty simple, so I\'ll focus on (2). The main thing you need to do is iterate through your "disorder string" where you can access the character at each position, as well as the position itself. One way to do this is to use  enumerate :'], ['which gives you a  generator  for each position (stored in  i ) and character (stored in  x ) in string  S . Once you have that, all you need to do is record the position and the character in  seq  whenever the disorder string has an  "X" . In Python, this could look like:']], [[' for i, x in enumerate(S)\n']], ['How to align and compare two elements (sequence) in a list using python'], 4, 0], [(24638781, 1), [['which gives you a  generator  for each position (stored in  i ) and character (stored in  x ) in string  S . Once you have that, all you need to do is record the position and the character in  seq  whenever the disorder string has an  "X" . In Python, this could look like:'], ["Here's a complete example: "]], [[' if (x == \'X\'):\n    new_disorder.append( "{} {}".format(i, seq[i]) )\n']], ['How to align and compare two elements (sequence) in a list using python'], 4, 0], [(24638781, 2), [["Here's a complete example: "], ['Note that I get slightly different output than the example you gave:']], [[' # Parse the file which was already split into split_list\nsplit_list = [\'>103L\', \'Sequence:\', \'MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNSLDAAKSELDKAIGRNTNGVITKDEAEKLFNQDVDAAVRGILRNAKLKPVYDSLDAVRRAALINMVFQMGETGVAGFTNSLRMLQQKRWDEAAVNLAKSRWYNQTPNRAKRVITTFRTGTWDAYKNL\', \'Disorder:\', \'----------------------------------XXXXXX-----------------------------------------------------------------------------------------------------------------------------XX\']\nheader   = split_list[0] + " " + split_list[1]\nseq      = split_list[2]\ndisorder = split_list[4]\n\n# Create the new disorder string\nnew_disorder = ["Disorder: Posi R"]\nfor i, x in enumerate(disorder):\n    if x == "X":\n        # Appends of the form: "AminoAcid Position"\n        new_disorder.append( "{} {}".format(i, seq[i]) )\n\nnew_disorder = " ".join(new_disorder)\n\n# Output the modified file\nopen("seq2.txt", "w").write( "\\n".join([header, seq, new_disorder]))\n']], ['How to align and compare two elements (sequence) in a list using python'], 4, 1], [(24638781, 3), [['Note that I get slightly different output than the example you gave:'], ['-10000']], [[' 103L Sequence:\nMNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNSLDAAKSELDKAIGRNTNGVITKDEAEKLFNQDVDAAVRGILRNAKLKPVYDSLDAVRRAALINMVFQMGETGVAGFTNSLRMLQQKRWDEAAVNLAKSRWYNQTPNRAKRVITTFRTGTWDAYKNL\nDisorder: Posi R 34 K 35 S 36 P 37 S 38 L 39 N 165 N 166 L\n']], ['How to align and compare two elements (sequence) in a list using python'], 4, 0], [(24642669, 0), [['I don\'t know about "quickest" (quickest to write? read? runtime?), but this is how I\'d write it recursively:'], ['demo:']], [[' def re_round(li, _prec=5):\n     try:\n         return round(li, _prec)\n     except TypeError:\n         return type(li)(re_round(x, _prec) for x in li)\n']], ['Python Quickest way to round every float in nested list of tuples'], 3, 1], [(24642669, 2), [['(old generator version of the function, for posterity:)'], ['-10000']], [[' def re_round(li, _prec=5):\n    for x in li:\n        try:\n            yield round(x, _prec)\n        except TypeError:\n            yield type(x)(re_round(x, _prec))\n']], ['Python Quickest way to round every float in nested list of tuples'], 3, 1], [(24660923, 0), [['-10000'], ['Using your  l ,  nat  and  a  variables:']], [[' import operator\n\nvector1 = (1, 2, 3)\n\n# get a list of vectors\nvectors = [\n    (4, 5, 6),\n    (7, 8, 9)\n]\n\n# for loop through the vectors,\n# assignig the current vector to vector2 in every iteration\nfor vector2 in vectors:\n    dotProduct = reduce(operator.add, map(operator.mul, vector1, vector2))\n    print dotProduct\n']], ['How to apply parameters/for loop'], 2, 1], [(24674723, 0), [['You can use  getattr  (note that you are referring to  attributes , or possibly  methods , not  functions ):'], ["getattr  takes an optional third argument, the default value in case  attr  isn't found, so you could do e.g.:"]], [[' for alarm in alarms:\n    for attr in whitelist:\n        print getattr(alarm, attr)\n']], ['get function names from a list python'], 2, 1], [(24674723, 1), [["getattr  takes an optional third argument, the default value in case  attr  isn't found, so you could do e.g.:"], ['-10000']], [[' for attr in whitelist:\n    print "{0}: {1}".format(attr, getattr(alarm, attr, "<Not defined>"))\n']], ['get function names from a list python'], 2, 1], [(24697061, 0), [['You can index a  tuple  using the same indexing you would for a list  [] . So if you want the  list , which is the second element, you can just index the element  [1]  from the return of the function call.'], ['Output']], [[" def get_stuff():\n    return 'a string', [1,2,3,5]\n\nall_stuff = [6,7]\nall_stuff.extend(get_stuff()[1])\n"]], ['How to append the second return value, directly to a list, in Python'], 2, 1], [(24697061, 1), [['Output'], ['-10000']], [[' [6, 7, 1, 2, 3, 5]\n']], ['How to append the second return value, directly to a list, in Python'], 2, 0], [(24717673, 1), [['Your code: '], ['Though I need to quote from the  docs : ']], [[' class userData(ndb.Model):\n    id = ndb.StringProperty()\n    name = ndb.StringProperty()\n    emailAddress = ndb.StringProperty()\n\nuser = userData.query().filter(ndb.GenericProperty(\'id\') ==  "requiredId")\\\n                       .fetch(projection=[userData.id, userData.name])\n']], ['google app engine - ndb query to only get a few columns in python'], 2, 1], [(24728933, 1), [['for each key name retreive the values from the dict'], ['-10000']], [[' for i in sortednames:\n   values=dictUsers[i]\n   print("Name= " + i)\n   print ("   Age= " + values.age)\n   print ("   Address= " + values.address)\n   print ("   Phone Number= " + values.phone)\n']], ['Sort dictionary alphabetically when the key is a string (name)'], 2, 0], [(24746231, 0), [['If you have a specific set of colors that you want to use for you colormap, you can build it based on those.  For example:'], ['However, if you did just want the top half of some particularly complex colormap, you can copy a portion of it by evaluating the colormap over the range you\'re interested in.  For example, if you wanted the "top" half, you\'d evaluate it from 0.5 to 1:']], [[" import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n\ncmap = LinearSegmentedColormap.from_list('name', ['green', 'yellow', 'red'])\n\n# Generate some data similar to yours\ny, x = np.mgrid[-200:1900, -300:2000]\nz = np.cos(np.hypot(x, y) / 100) + 1\n\nfig, ax = plt.subplots()\n\ncax = ax.contourf(x, y, z, cmap=cmap)\ncbar = fig.colorbar(cax)\ncbar.set_label('Z-Values')\n\nplt.show()\n"]], ['Matplotlib Half color axis'], 2, 1], [(24746231, 1), [['However, if you did just want the top half of some particularly complex colormap, you can copy a portion of it by evaluating the colormap over the range you\'re interested in.  For example, if you wanted the "top" half, you\'d evaluate it from 0.5 to 1:'], ['']], [[" import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Evaluate an existing colormap from 0.5 (midpoint) to 1 (upper end)\ncmap = plt.get_cmap('gist_earth')\ncolors = cmap(np.linspace(0.5, 1, cmap.N // 2))\n\n# Create a new colormap from those colors\ncmap2 = LinearSegmentedColormap.from_list('Upper Half', colors)\n\ny, x = np.mgrid[-200:1900, -300:2000]\nz = np.cos(np.hypot(x, y) / 100) + 1\n\nfig, axes = plt.subplots(ncols=2)\nfor ax, cmap in zip(axes.flat, [cmap, cmap2]):\n    cax = ax.imshow(z, cmap=cmap, origin='lower',\n                    extent=[x.min(), x.max(), y.min(), y.max()])\n    cbar = fig.colorbar(cax, ax=ax, orientation='horizontal')\n    cbar.set_label(cmap.name)\n\nplt.show()\n"]], ['Matplotlib Half color axis'], 2, 1], [(24747191, 0), [['If you want to use regexes, try this:'], ['If you are confident that all of your data conforms to the pattern, you can also do this without regexes:']], [[" s = 'module hi(a, b, c)'\nregex = re.compile(r'\\s(\\w+)\\(([^\\)]+)\\)')\ntry:\n    module_name, parameters = regex.search(s).groups()\nexcept AttributeError as e:\n    print 'No match for: {}'.format(s)\n    raise\nparameters = parameters.split(',')\nprint module_name, parameters\nd = {'module_name':module_name,\n     'module_params':parameters[:-1],\n     'module_last_param':parameters[-1]}\nprint d\n# {'module_last_param': ' c', 'module_name': 'hi', 'module_params': ['a', ' b']}\n"]], ['Save matches on array'], 2, 1], [(24747191, 1), [['If you are confident that all of your data conforms to the pattern, you can also do this without regexes:'], ['-10000']], [[" name, params = s.split('(')\nname = name.split()[1]\nparams = params[:-1].split(',')\nd = {'module_name':name,\n     'module_params':params[:-1],\n     'module_last_param':params[-1]}\n"]], ['Save matches on array'], 2, 1], [(24747996, 0), [['First you need to find the path to your python installation, you can do this by typing this:'], ['You can then add the full path of this directory to  PATH  by typing']], [[' which python\n']], ['How do I make pip available from command line mac?'], 3, 0], [(24747996, 1), [['You can then add the full path of this directory to  PATH  by typing'], ['So for example mine was:']], [[' export PATH=$PATH:"<insert_path_here>"\n']], ['How do I make pip available from command line mac?'], 3, 0], [(24747996, 2), [['So for example mine was:'], ['You are only appending the new path to  PATH , not replacing the old one. Be very careful to add the  $PATH:  after the equals. This is what keeps the old  PATH  intact. The : is the path separator.']], [[' export PATH=$PATH:"/cygdrive/c/Python27/Scripts"\n']], ['How do I make pip available from command line mac?'], 3, 0], [(24748179, 1), [['Then I make  myscript.py  sensitive to the possible difference:'], ['-10000']], [[' try: from BigPackage.SmallSubset import TheOnlyFunctionIReallyNeed\nexcept ImportError: from BigPackageSmallSubset import TheOnlyFunctionIReallyNeed\n']], ['py2exe: excluding parts of a package that wants to import all its parts'], 2, 0], [(24752712, 0), [['You need to use a  defaultdict  for this:'], ['If you want to store other objects, for example a dictionary, just pass that as the callable:']], [[" >>> from collections import defaultdict\n>>> d = defaultdict(list)\n>>> d['a'].append(1)\n>>> d['a'].append(2)\n>>> d['b'].append(3)\n>>> d['c'].append(4)\n>>> d['b'].append(5)\n>>> print(d['a'])\n[1, 2]\n>>> print(d)\ndefaultdict(<type 'list'>, {'a': [1, 2], 'c': [4], 'b': [3, 5]})\n"]], ['How to address a dictionary in a list of ordered dicts by unique key value?'], 2, 1], [(24752712, 1), [['If you want to store other objects, for example a dictionary, just pass that as the callable:'], ['-10000']], [[" >>> d = defaultdict(dict)\n>>> d['a']['values'] = []\n>>> d['b']['values'] = []\n>>> d['a']['values'].append('a')\n>>> d['a']['values'].append('b')\n>>> print(d)\ndefaultdict(<type 'dict'>, {'a': {'values': ['a', 'b']}, 'b': {'values': []}})\n"]], ['How to address a dictionary in a list of ordered dicts by unique key value?'], 2, 1], [(24772845, 0), [["Finding all  href 's inside class  tab-pane fade in active :"], ['output']], [[' soup = BeautifulSoup(st)                                             \nfor a in soup.findAll(\'div\', {"class":"tab-pane fade in active"}):   \n    for b in a.findAll(\'a\'):                                         \n        print b.get(\'href\')\n']], ['Python: Extract hrefs inside a div'], 2, 1], [(24772845, 1), [['output'], ['-10000']], [[' /accounting?id=265\n/downloadpdf?id=265&type=pdf\n/downloadpdf?id=265&type=file\n']], ['Python: Extract hrefs inside a div'], 2, 0], [(24780464, 0), [["You define the function elsewhere, then call it within the loop. You don't define the function over and over again within the loop."], ['As a working example, lets just say I call the  sum  function on each  array']], [[' def do_something(np_array):\n    # work on the array here\n\nfor i in list_of_array:\n    do_something(i)\n']], ['Iterate through a list of numpy arrays'], 4, 0], [(24780464, 1), [['As a working example, lets just say I call the  sum  function on each  array'], ['Now I can call it in the  for  loop']], [[' def total(np_array):\n    return sum(np_array)\n']], ['Iterate through a list of numpy arrays'], 4, 0], [(24780464, 2), [['Now I can call it in the  for  loop'], ['Output']], [[' for i in list_of_arrays:\n    print total(i)\n']], ['Iterate through a list of numpy arrays'], 4, 0], [(24780464, 3), [['Output'], ['-10000']], [[' [ 0.  0.]\n[ 1.13075762  0.87658186]\n[ 2.34610724  0.77485066]\n[ 1.08704527  2.59122417]\n']], ['Iterate through a list of numpy arrays'], 4, 0], [(24787224, 0), [['In Python 2, use the str-to-str  string_escape  codec :'], ['Demo:']], [[" string.decode('string_escape')\n"]], ['How to convert a python string'], 7, 1], [(24787224, 1), [['Demo:'], ["In Python 3, you'd have to use the  codecs.decode()  and the  unicode_escape  codec:"]], [[" >>> string = '\\\\n    this is a docstring for\\\\n    the main function.\\\\n    a,\\\\n    b,\\\\n    c\\\\n    '\n>>> string.decode('string_escape')\n'\\n    this is a docstring for\\n    the main function.\\n    a,\\n    b,\\n    c\\n    '\n>>> print string.decode('string_escape')\n\n    this is a docstring for\n    the main function.\n    a,\n    b,\n    c\n\n>>> '\\\\t\\\\n\\\\r\\\\xa0\\\\040'.decode('string_escape')\n'\\t\\n\\r\\xa0 '\n"]], ['How to convert a python string'], 7, 0], [(24787224, 2), [["In Python 3, you'd have to use the  codecs.decode()  and the  unicode_escape  codec:"], ['Demo:']], [[" codecs.decode(string, 'unicode_escape')\n"]], ['How to convert a python string'], 7, 1], [(24787224, 4), [['-10000'], ['The  \\\\  pair should be replaced by just one  \\  characters, leaving the  n  uninterpreted. But the replace option either will end up replacing the trailing  \\  together with the  n  with a newline character,  or  you end up with  \\\\  replaced by  \\ , and then the  \\  and the  n  are replaced by a newline. Either way, you end up with the wrong output.']], [[" >>> '\\\\\\\\n'.decode('string_escape')\n'\\\\n'\n>>> '\\\\\\\\n'.replace('\\\\n', '\\n').replace('\\\\\\\\', '\\\\')\n'\\\\\\n'\n>>> '\\\\\\\\n'.replace('\\\\\\\\', '\\\\').replace('\\\\n', '\\n')\n'\\n'\n"]], ['How to convert a python string'], 7, 0], [(24787224, 6), [['But it  does  handle the escaped escape properly:'], ['Do know this is  far slower  than using the built-in codec.']], [[" >>> unescape_string(string)\n'\\n    this is a docstring for\\n    the main function.\\n    a,\\n    b,\\n    c\\n    '\n>>> unescape_string('\\\\\\\\n')\n'\\\\n'\n"]], ['How to convert a python string'], 7, 0], [(24833045, 0), [['You need to ceate a list outside the loop and append the values.'], ['If you want to keep final a list and append a dict each time use:']], [[" final = [] # add values you want saved to final\nuniq_ident = 1\nfor name in glob.glob('/Users/jorjis/Desktop/test/*'):\n     jfile = open(name, 'r')\n     values = json.load(jfile)\n     jfile.close()\n     body1 = values['article']['description']\n     tokens = nltk.wordpunct_tokenize(body1)\n     tokens = [w.lower() for w in tokens]\n     vocab = [word for word in tokens if word not in stop]\n     final.append([uniq_ident,vocab]) # append vocab or whatever values you want to keep\n     uniq_ident += 1\n     print body1\n"]], ['Get specific data from a .json file and save them to a 2D matrix/dictionary in python'], 2, 1], [(24833045, 1), [['If you want to keep final a list and append a dict each time use:'], ['-10000']], [['  final.append({uniq_ident:vocab})\n']], ['Get specific data from a .json file and save them to a 2D matrix/dictionary in python'], 2, 0], [(24833817, 1), [['An example with 20x20 data:'], ['']], [[' import matplotlib.pyplot as plt\nimport numpy\n\n# create the data to be shown with "scatter"\nyvec, xvec = np.meshgrid(np.linspace(-4.75, 4.75, 20), np.linspace(-4.75, 4.75, 20))\nsc_data = random.random((20,20))\n\n# create the data to be shown with "imshow" (20 pixels)\nim_data = random.random((20,20))\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.imshow(im_data, extent=[-5,5,-5,5], interpolation=\'nearest\', cmap=plt.cm.gray)\nax.scatter(xvec, yvec, 100*sc_data)\n']], ['Aligning two combined plots - Matplotlib'], 2, 1], [(24834560, 0), [['At least one rather robust way is to do the image scaling by using the  extent  keyword.'], ['Just as a small example:']], [[' ax.imshow(image, extent=[0, 10.4, 0, 4.2], aspect=1)\n']], ['Matplotlib: force aspect ratio in series of plots'], 2, 1], [(24834560, 1), [['Just as a small example:'], ['This gives:']], [[" import matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.imshow(np.random.random((20, 20)), extent=(0, 10.5, 2, 4.7), aspect=1, interpolation='nearest')\n"]], ['Matplotlib: force aspect ratio in series of plots'], 2, 1], [(24886310, 0), [["You'll have to encode special characters properly, as e.g.  urlencode  does:"], ["If you're open to get a third party package,  requests  would be a popular choice.\nIt would simplify things to:"]], [[" In[16]: urllib.urlencode([('postnr',4320),('vejnavn', 'Bispegårdsvej'), ('husnr',2)])\nOut[16]: 'postnr=4320&vejnavn=Bispeg%C3%A5rdsvej&husnr=2'\n"]], ['Encoding in Python - non-English characters into a URL'], 2, 1], [(24896943, 0), [['-10000'], ['Output:']], [[" #!/bin/bash\n\npython - 1 2 3 << 'EOF'\nimport sys\n\nprint 'Argument List:', str(sys.argv)\nEOF\n"]], ['How to insert a python program into a bash script?'], 2, 1], [(24896943, 1), [['Output:'], ['-10000']], [[" Argument List: ['-', '1', '2', '3']\n"]], ['How to insert a python program into a bash script?'], 2, 0], [(24900064, 0), [['You can check its length with '], ['or']], [[' if ranking_list:\n    print ranking_list \n']], ['Scrapy:newbie attempts to pass the null value'], 2, 1], [(24900064, 1), [['or'], ['-10000']], [[' if len(ranking_list) > 0:\n    print ranking_list \n']], ['Scrapy:newbie attempts to pass the null value'], 2, 1], [(24915181, 0), [['RQ offers methods to make any queue empty:'], ['Install rq-dashboard:']], [[' >>> from redis import Redis\n>>> from rq import Queue\n>>> qfail = Queue("failed", connection=Redis())\n>>> qfail.count\n8\n>>> qfail.empty()\n8L\n>>> qfail.count\n0\n']], ['RQ - Empty & Delete Queues'], 4, 1], [(24915181, 1), [['Install rq-dashboard:'], ['Start it:']], [[' $ pip install rq-dashboard\n']], ['RQ - Empty & Delete Queues'], 4, 0], [(24915181, 2), [['Start it:'], ['Using DEL on each key we purge our database job by job.']], [[' $ rq-dashboard\nRQ Dashboard, version 0.3.4\n * Running on http://0.0.0.0:9181/\n']], ['RQ - Empty & Delete Queues'], 4, 0], [(24915181, 3), [['Using DEL on each key we purge our database job by job.'], ['-10000']], [[' >>> import redis\n>>> r = redis.StrictRedis()\n>>> qname = "rq:queue:failed"\n>>> def purgeq(r, qname):\n... while True:\n...     jid = r.lpop(qname)\n...     if jid is None:\n...         break\n...     r.delete("rq:job:" + jid)\n...     print jid\n...\n>>> purge(r, qname)\na0be3624-86c1-4dc4-bb2e-2043d2734b7b\n3796c312-9b02-4a77-be89-249aa7325c25\nca65f2b8-044c-41b5-b5ac-cefd56699758\n896f70a7-9a35-4f6b-b122-a08513022bc5\n']], ['RQ - Empty & Delete Queues'], 4, 1], [(24918515, 0), [['So:'], ['-10000']], [[' bin_counts = [0 for bin in bins]\nfor data_point in data_points:\n    bin_number = data_point // bin_width\n    bin_counts[bin_number] += 1\n']], ['How to count how many data points fall in a bin'], 2, 1], [(24918515, 1), [['-10000'], ['Here, each bin is a list of  [start, stop, count] , instead of having a list of  (start, stop)  bins and a separate list of  count  values.']], [[' bins = [[i*bin_width, (i+1)*bin_width, 0] for i in range(num_bins)]\nfor data_point in data_points:\n    bin_number = data_point // bin_width\n    bins[bin_number][2] += 1\n']], ['How to count how many data points fall in a bin'], 2, 1], [(24928086, 0), [['If you really only need a single logger, then you might as well use the root one. Rather than passing around your logger, just get it from the logging module in each of your modules:'], ['However, the common, recommended pattern, is to instead use named loggers, replacing the second line with:']], [[" import logging\nlogger = logging.getLogger()\nlogger.debug('Heya')\n"]], ['Better logging system for entire package'], 2, 1], [(24928086, 1), [['However, the common, recommended pattern, is to instead use named loggers, replacing the second line with:'], ['This keeps the door open to easily change your logging configuration later to direct certain logs elsewhere or change their logging level, etc.']], [[' logger = logging.getLogger(__name__)\n']], ['Better logging system for entire package'], 2, 0], [(24941665, 0), [['Each module object has a  __file__  attribute:'], ['Demo:']], [[' import module\n\nprint module.__file__\n']], ['How can you find where python imported a particular module from?'], 2, 1], [(24994284, 0), [['You can use  str.format()  out of the box for this:'], ['This will look up  clad-den  and  clad-temp  as keys in the  data  dictionary:']], [[" 'MATERIAL 4 {clad-den} {clad-temp} 2'.format(**data)\n"]], ['python - replace string entry with a dictionary entry'], 3, 1], [(24994284, 2), [['You can do it with  re.sub()  too, using a function for the replacement parameter:'], ["but this doesn't offer the same flexibility and power that string formatting can offer."]], [[" re.sub(r'{([^{}]+)}', lambda m: str(data[m.group(1)]), template_text)\n"]], ['python - replace string entry with a dictionary entry'], 3, 1], [(25000584, 0), [['In a new voting.html, I had this code to capture the arrow buttons the joystick was mapped to:'], ['Then in views.py, I used GET instead of POST to capture the up or down votes:']], [[' <div id="Vote" class = "high">\n  <div style="text-align: center">\n  {% for entry in voting_entry_list %} \n    <li><a href="/entries/{{ entry.id }}/">{{ entry.text }}&nbsp{{ entry.score }}</a></li>\n    <p>\n    <input type="submit" id="voteid" name=\'voteid\' value="{{ entry.id }}" autofocus value="" onfocus="this.value = this.value;" class = "transparent"/>\n          <script>\n            $(document).ready(function() {\n              $("#voteid").bind("keydown", function(e) { //input type=id above\n                if (e.keyCode == 38) {\n                  var text = $("#voteid").val();        \n                  var args = {\'voteid\':text};       \n                  $.get("/voteup/", args).done(function(data) {\n                    console.log("message: " + data);\n                    location.reload();  \n                  });\n                return false;\n                }\n                if (e.keyCode == 40) {\n                  var text = $("#voteid").val();        \n                  var args = {\'voteid\':text};       \n                  $.get("/votedown/", args).done(function(data) {\n                    console.log("message: " + data);\n                    location.reload();  \n                  });\n                return false;\n                }       \n              });\n            });     \n          </script>\n  {% endfor %}\n  </div>\n</div>\n']], ['using key presses instead of buttons in django forms'], 2, 0], [(25000584, 1), [['Then in views.py, I used GET instead of POST to capture the up or down votes:'], ['This seems to avoid any issues with forms and keypresses. Since it is on a separate voting page, the transparent dummy submit button makes that selection active on refresh, as opposed to the text entry box when they were on the same page. I can access the sorted entries from the voting_entry_list, and vote up or down with separate js scripts and views.py requests for each button.']], [[" def voting(request):   \ncontext = {\n  'latest_entry_list': Entry.objects.order_by('-pub_date')[:10], # simple sorting by datetime, latest first, 10 items\n  'high_entry_list': Entry.objects.order_by('-score','-pub_date')[:10], # simple sorting by score high to low, 10 items\n  'high_entry': Entry.objects.order_by('-score','-pub_date')[:1], # simple sorting by score high to low, 10 items\n  'low_entry_list': Entry.objects.order_by('score','-pub_date')[:10], # simple sorting by score low to high, 10 items\n  'voting_entry_list': Entry.objects.unvoted_or_random(), # actually one item, command from extended object manager\n}\nreturn render(request, 'entries/voting.html', context); # returns when vote is accessed\n\ndef voteup(request):\nvoting_id = request.GET.get('voteid') # voting id number is brought in as var\nif request.method=='GET': #always polling, when get votes, save and redirect to /index to refresh\n    v = Entry.objects.get(pk=voting_id) # get by voting id var\n    v.score +=1 # add one to score for voteup button\n    v.voted=True # set voted boolean to true\n    v.save() # explicit save, as is not saved with change above\nelse:\n    pass\nreturn HttpResponse('done') # Only on console \n\ndef votedown(request):\nvoting_id = request.GET.get('voteid') # voting id number is brought in as var\nif request.method=='GET': #always polling, when get votes, save and redirect to /index to refresh\n    v = Entry.objects.get(pk=voting_id) # get by voting id var\n    v.score -=1 # add one to score for voteup button\n    v.voted=True # set voted boolean to true\n    v.save() # explicit save, as is not saved with change above\nelse:\n    pass\nreturn HttpResponse('done') # Only on console\n"]], ['using key presses instead of buttons in django forms'], 2, 0], [(25002150, 0), [['First, how do you create each of the sub-dicts? At the point where you have the  bet_pav  and  kk  values you want, just do this:'], ["Now, how do you add them each to the main dict? Well, it looks like you wanted each  pav  to map to a tuple of sub-dicts, or maybe a list of them, but forgot the parentheses or square brackets. Either way, what you want to do is append to the existing tuple/list for each new sub-dict, starting with an empty tuple/list if this is the first sub-dict you've gotten. This is easier to do with a list than a tuple, so let's do that:"]], [[' subdict = {bet_pav: [kk]}\n']], ['dictionary of dictionaries(nested dicts)'], 4, 0], [(25002150, 1), [["Now, how do you add them each to the main dict? Well, it looks like you wanted each  pav  to map to a tuple of sub-dicts, or maybe a list of them, but forgot the parentheses or square brackets. Either way, what you want to do is append to the existing tuple/list for each new sub-dict, starting with an empty tuple/list if this is the first sub-dict you've gotten. This is easier to do with a list than a tuple, so let's do that:"], ['Or, if you prefer, you can just create  pavdict  as a  defaultdict(list) , and then this line is just:']], [[' pavdict.setdefault(pav, []).append(subdict)\n']], ['dictionary of dictionaries(nested dicts)'], 4, 0], [(25002150, 2), [['Or, if you prefer, you can just create  pavdict  as a  defaultdict(list) , and then this line is just:'], ['-10000']], [[' pavdict[pav].append(subdict)\n']], ['dictionary of dictionaries(nested dicts)'], 4, 0], [(25002459, 0), [['You can format your data into a string; with  string formatting , for example:'], ["You can also make use of  print() 's ability to convert all arguments to a string and automatic newlines, and have  it  write to the file:"]], [[' firstline = "Log Created: {}/nLog deleted and recreated.".format(grab_date)\n']], ['Writing variables with .write() Python 3'], 3, 1], [(25002459, 1), [["You can also make use of  print() 's ability to convert all arguments to a string and automatic newlines, and have  it  write to the file:"], ["If you can avoid it, don't reinvent the logging wheel and use the  logging  module . It can be  configured to take a different date format :"]], [[' print("Log Created:", grab_date, file=f)\nprint("Log deleted and recreated.", file=f)\n']], ['Writing variables with .write() Python 3'], 3, 1], [(25002459, 2), [["If you can avoid it, don't reinvent the logging wheel and use the  logging  module . It can be  configured to take a different date format :"], ['-10000']], [[' >>> import logging\n>>> logging.basicConfig(datefmt="%A %d, %B %Y %I:%M:%S %p %Z", format=\'Log Created: %(asctime)-15s %(message)s\')\n>>> logging.warn(\'Foo bar baz!\')\nLog Created: Monday 28, July 2014 08:13:44 PM BST Foo bar baz!\n']], ['Writing variables with .write() Python 3'], 3, 1], [(25024087, 0), [['One option would be to use  requests :'], ['prints:']], [[' import requests\n\nurl = "http://geocoding.geo.census.gov/geocoder/locations/addressbatch"\ndata = {\'benchmark\': \'Public_AR_Census2010\'}\nfiles = {\'addressFile\': open(\'t.csv\')}\n\nresponse = requests.post(url, data=data, files=files)\nprint response.content\n']], ['Mimic curl in python'], 3, 1], [(25024087, 1), [['prints:'], ['-10000']], [[' "1"," 800 Wilshire Blvd,  Los Angeles,  CA,  90017","Match","Exact","800 Wilshire Blvd, LOS ANGELES, CA, 90017","-118.25818,34.049366","141617176","L"\n']], ['Mimic curl in python'], 3, 0], [(25024087, 2), [['-10000'], ['This prints the same result as is with using a real file.']], [[' from StringIO import StringIO\nimport requests\n\ncsv_data = "1, 800 Wilshire Blvd, Los Angeles, CA, 90017"\nbuffer = StringIO()\nbuffer.write(csv_data)\nbuffer.seek(0)\n\nurl = "http://geocoding.geo.census.gov/geocoder/locations/addressbatch"\ndata = {\'benchmark\': \'Public_AR_Census2010\'}\nfiles = {\'addressFile\': buffer}\n\nresponse = requests.post(url, data=data, files=files)\nprint response.content\n']], ['Mimic curl in python'], 3, 1], [(25025291, 0), [["I don't think you need cython for this, I think you're looking for  numpy.bincount . Here is an example:"], ['-10000']], [[' import numpy as np\nd = np.random.random(10**5)\nnumbins = 10\n\nbins = np.linspace(d.min(), d.max(), numbins+1)\n# This line is not necessary, but without it the smallest bin only has 1 value.\nbins = bins[1:]\ndigitized = bins.searchsorted(d)\n\nbin_means = (np.bincount(digitized, weights=d, minlength=numbins) /\n             np.bincount(digitized, minlength=numbins))\n']], ['Binning data based on one column in 2D array and estimate mean in each bin using cython'], 2, 1], [(25025291, 1), [['-10000'], ["It has 1 pass (well 2 passes if you count the max) over  digitized  so it has complexity O(n). Also bincount is already written in C and compiled so it already has very little overhead and is very fast. Cython is most helpful when you have code which has a lot of interpreter and type-check overhead so that declaring types and compiling the code removes that overhead. Hope that's helpful."]], [[' def bincount(digitized, Weights):\n   out = zeros(digitized.max() + 1)\n   for i, w = zip(digitized, Weights):\n       out[i] += w\n   return out\n']], ['Binning data based on one column in 2D array and estimate mean in each bin using cython'], 2, 0], [(25030548, 0), [["I think what you're looking for is  partial function application , which you can do using  functools ."], ['Example:']], [[' def apply_something(something, config, some_var):\n    pass  # ...\n\nimport functools\n\nreduce(functools.partial(apply_something, some_var=True), \n       [1, 2, 3], something_initializer)\n']], ['Passing more than two arguments in reduce function'], 2, 1], [(25047254, 0), [['Could be done in a one-liner...'], ['or more readable']], [[" open(files[0]).read().split('1:', 1)[1].split('\\n')[:19]\n"]], ['parse blocks of text from text file using Python'], 6, 0], [(25047254, 1), [['or more readable'], ['then join the lines with a newline (and add a newline to the end) before writing it to a new file:']], [[' txt = open(files[0]).read()           # read the file into a big string\nbefore, after = txt.split(\'1:\', 1)    # split the file on the first "1:"\nafter_lines = after.split(\'\\n\')       # create lines from the after text\nlines_to_save = after_lines[:19]      # grab the first 19 lines after "1:"\n']], ['parse blocks of text from text file using Python'], 6, 0], [(25047254, 2), [['then join the lines with a newline (and add a newline to the end) before writing it to a new file:'], ['to comply with best practice for reading and writing files you should also be using the with statement to ensure that the file handles are closed as soon as possible.  You can create convenience functions for it:']], [[' out_text = "1:"                       # add back "1:"\nout_text += "\\n".join(lines_to_save)  # add all 19 lines with newlines between them\nout_text += "\\n"                      # add a newline at the end\n\nopen("outputfile.txt", "w").write(out_text)\n']], ['parse blocks of text from text file using Python'], 6, 0], [(25047254, 3), [['to comply with best practice for reading and writing files you should also be using the with statement to ensure that the file handles are closed as soon as possible.  You can create convenience functions for it:'], ['then you can replace the first line above with:']], [[' def read_file(fname):\n    "Returns contents of file with name `fname`."\n    with open(fname) as fp:\n         return fp.read()\n\ndef write_file(fname, txt):\n    "Writes `txt` to a file named `fname`."\n    with open(fname, \'w\') as fp:\n         fp.write(txt)\n']], ['parse blocks of text from text file using Python'], 6, 0], [(25047254, 4), [['then you can replace the first line above with:'], ['and the last line with:']], [[' txt = read_file(files[0])\n']], ['parse blocks of text from text file using Python'], 6, 0], [(25047254, 5), [['and the last line with:'], ['-10000']], [[' write_file("outputfile.txt", out_text)\n']], ['parse blocks of text from text file using Python'], 6, 0], [(25057912, 0), [["OK, I've found an answer to the first part of my question. Actually it's a nobrainer:"], ['And then:']], [[' .. _table:\n\n.. table Supertable\n\n    +--------+----+\n    |Foo     |Bar |\n    +--------+----+\n']], ['Automatically numbering and referencing Sphinx tables'], 2, 0], [(25057912, 1), [['And then:'], ["As for enumerated tables I have actually seen enumerated figures, not tables and it gets done in LaTeX output. I looked around and haven't found any trace of automatically enumerated tables in Sphinx. It would probably make a good feature request, but for now there seems to be no such feature."]], [[' :ref:`table`\n']], ['Automatically numbering and referencing Sphinx tables'], 2, 0], [(25068002, 0), [['You need to call something equivalent to :'], ['to reproduce']], [[' obj = __import__("mymod", ...).mymod\n']], ['Import object from module of same name using __import__'], 4, 0], [(25068002, 1), [['to reproduce'], ['Getting the attribute of an object by its name can be done using']], [[' from mymod import mymod\n']], ['Import object from module of same name using __import__'], 4, 0], [(25068002, 2), [['Getting the attribute of an object by its name can be done using'], ['Pick one. (I would go for  getattr  if I really had to).']], [[" getattr(obj, 'mymod')\n# or\nobj.__dict__['mymod']\n# or\nvars(obj)['mymod']\n"]], ['Import object from module of same name using __import__'], 4, 0], [(25068218, 0), [['You can iterate over the result of  .find_next_siblings()  that are  <ul>  elements:'], ['Demo:']], [[" from itertools import takewhile, ifilter\n\ndiv = soup.find('div', class_='layout4-background')\nfor header in div.find_all('h6'):\n    print header.get_text()\n    listings = takewhile(lambda t: t.name == 'ul',\n                         header.find_next_siblings(text=False))\n    for listing in listings:\n        # do something with listing\n"]], ['python BeautifulSoup how get values between tags?'], 2, 1], [(25068218, 1), [['Demo:'], ['-10000']], [[' >>> from bs4 import BeautifulSoup\n>>> from itertools import takewhile\n>>> soup = BeautifulSoup(\'\'\'\\\n... <div class="layout4-background">\n...     <h6 class="game">Game1. How to get all listings below and assign to class"game"?</h6>\n...     <ul>\n...         <li class="listing">\n...     </ul>\n...     <ul>\n...         <li class="listing">\n...     </ul>\n...     <ul>\n...         <li class="listing">\n...     </ul>\n...     <h6 class="game">Game2. How to get all listings below and assign to class"game?</h6>\n...     <ul>\n...         <li class="listing">\n...     </ul>\n...     <h6 class="game">Game3. How to get all listings below and assign to class"game?</h6>\n...     <ul>\n...         <li class="listing">\n...     </ul>\n... </div>\n... \'\'\')\n>>> div = soup.find(\'div\', class_=\'layout4-background\')\n>>> for header in div.find_all(\'h6\'):\n...     print header.get_text()\n...     listings = takewhile(lambda t: t.name == \'ul\',\n...                          header.find_next_siblings(text=False))\n...     print \'Listings found:\', len(list(listings))\n... \nGame1. How to get all listings below and assign to class"game"?\nListings found: 3\nGame2. How to get all listings below and assign to class"game?\nListings found: 1\nGame3. How to get all listings below and assign to class"game?\nListings found: 1\n']], ['python BeautifulSoup how get values between tags?'], 2, 1], [(25088066, 0), [['Using this as my test case,'], ['I use the following to loop through the nodes and updating which  div  the current node is currently "under" in.']], [[' <div class="asdf">\n  <div class="button-left" style="margin-bottom: 4px">04.09.2013</div>\n  <table width="100%" class="record generic schedule margin-4">1</table>\n  <table width="100%" class="record generic schedule margin-4">2</table>\n  <div class="button-left" style="margin-bottom: 4px">05.10.2013</div>\n  <table width="100%" class="record generic schedule margin-4">3</table>\n  <table width="100%" class="record generic schedule margin-4">4</table>\n  <table width="100%" class="record generic schedule margin-4">5</table>\n  <table width="100%" class="record generic schedule margin-4">6</table>\n</div>\n']], ['How to scrape table with different xpath on the same level with Scrapy?'], 3, 0], [(25088066, 2), [['This results into:'], ['-10000']], [[" {u'04.09.2013': [u'1', u'2'], u'05.10.2013': [u'3', u'4', u'5', u'6']}\n"]], ['How to scrape table with different xpath on the same level with Scrapy?'], 3, 0], [(25100105, 0), [['You could create a class:'], ['And then create an instance of it:']], [[' class Disk(object):\n    def __init__(self, test1=None, test2=None, test3=None):\n        self.test1 = test1\n        self.test2 = test2\n        self.test3 = test3\n']], ['How to create a object of variables, and return it, in Python?'], 3, 0], [(25100105, 1), [['And then create an instance of it:'], ['You can, however, add properties to instances of your own classes. For example:']], [[' mydist = Disk()\nmydist.test1 = "value"\n# And so on\n']], ['How to create a object of variables, and return it, in Python?'], 3, 0], [(25100105, 2), [['You can, however, add properties to instances of your own classes. For example:'], ['-10000']], [[' class Example(object):\n    pass\n\nmyobject = Example()\nmyobject.a = "value"\n']], ['How to create a object of variables, and return it, in Python?'], 3, 0], [(25104929, 0), [["Fortunately, you can get Twisted to  manage tk's event loop for you!   At the begining of your program, you should add:"], ["then, Once you've created your gui as normal, you should  not  call  Tkinter.mainloop() , use:"]], [[' from Tkinter import Tk\nfrom twisted.internet import tksupport\nroot_window = Tk()\ntksupport.install(root_window)\n']], ['Initiating TCP Client after running reactor.run()'], 4, 0], [(25104929, 1), [["then, Once you've created your gui as normal, you should  not  call  Tkinter.mainloop() , use:"], ["In case that's not quite enough, here's some real, working code!  First a really simple server"]], [[' from twisted.internet import reactor\nroot_window.protocol("WM_DELETE_WINDOW", reactor.stop)\nreactor.run()\n']], ['Initiating TCP Client after running reactor.run()'], 4, 0], [(25104929, 2), [["In case that's not quite enough, here's some real, working code!  First a really simple server"], ['and a client, with a gui and network activity:']], [[" from twisted.internet.protocol import Protocol, Factory\nfrom twisted.internet import reactor\n\nclass Echo(Protocol):\n    def dataReceived(self, data):\n        print 'recieved:', data\n    def connectionLost(self, reason):\n        print 'connection closed', reason\n\nf = Factory()\nf.protocol = Echo\nreactor.listenTCP(8080, f)\nreactor.run()\n"]], ['Initiating TCP Client after running reactor.run()'], 4, 0], [(25137972, 0), [['In this case, line 1 of a file is to be selected with greater probability than the last line, and with reducing probability for intervening lines, so our weights would be  range(n, 0, -1)  where n is the number of lines in the file, e.g. if there were 5 lines in the file, then the weights would be  [5, 4, 3, 2, 1]  and this would correspond to probabilities of:'], ['Next we need to construct a cumulative distribution based on the weights, select a random value within that distribution, locate the random value within the distribution, and use that to retrieve a line from the file. Here is some code that does that.']], [[' weights = range(5, 0, -1)\ntotal_weights = float(sum(weights))\nprobabilities = [w/total_weights for w in weights]\n>>> [round(p, 5) for p in probabilities]    # rounded for readability\n[0.33333, 0.26667, 0.2, 0.13333, 0.06667]\n']], ['Weighted random choice from a variable length text file'], 2, 0], [(25137972, 1), [['Next we need to construct a cumulative distribution based on the weights, select a random value within that distribution, locate the random value within the distribution, and use that to retrieve a line from the file. Here is some code that does that.'], ["This uses weights according to my interpretation of the question. It's easy enough to adapt this to other weights, e.g. if you wanted a weighted select with city population as the weights, you'd just change  weights = range(n, 0, -1)  to a list of populations corresponding to each line in the file."]], [[' import bisect\nimport random\ntry:\n    from itertools import accumulate     # Python >= 3.2\nexcept ImportError:\n    def accumulate(weights):\n        accumulator = 0\n        for w in weights:\n            accumulator += w\n            yield accumulator\n\ndef count(iterable):\n    return sum(1 for elem in iterable)\n\ndef get_nth(iterable, n):\n    assert isinstance(n, int), "n must be an integer, got %r" % type(n)\n    assert n > 0, "n must be greater than 0, got %r" % n\n    for i, elem in enumerate(iterable, 1):\n        if i == n:\n            return elem\n\ndef weighted_select(filename):\n    with open(filename) as f:\n        n = count(f)\n        if n == 0:\n            return None\n\n        # set up cumulative distribution\n        weights = range(n, 0, -1)\n        cumulative_dist = list(accumulate(weights))\n\n        # select line number\n        x = random.random() * cumulative_dist[-1]\n        selected_line = bisect.bisect(cumulative_dist, x)\n\n        # retrieve line from file\n        f.seek(0)\n        return get_nth(f, selected_line + 1)    # N.B. +1 for nth line\n']], ['Weighted random choice from a variable length text file'], 2, 0], [(25141467, 0), [['Benchmark it!'], ['These three methods give the following benchmarks:']], [[' import numpy as np\n\n# some data\nA = np.random.random((250000, 30))\n\n# some random indices\nx = np.random.randint(0, 250000, 150000)\ny = np.random.randint(0, 30, 10)\n\ndef method1(A, x, y):\n    return A[x[:, np.newaxis], y]\n\ndef method2(A, x, y):\n    return A[np.ix_(x,y)]\n\ndef method3(A, x, y):\n    return A[x][:,y]\n\ndef method4(A, x, y):\n    return A[:,y][x]\n']], ['Numpy: Efficient Way To Extract Subarray'], 2, 1], [(25141467, 1), [['These three methods give the following benchmarks:'], ['So, the answer is that there is not real difference between the two methods in the question.']], [[' method1: 87.7 ms\nmethod2: 89.2 ms\nmethod3: 115 ms\nmethod4: 141 ms\n']], ['Numpy: Efficient Way To Extract Subarray'], 2, 0], [(25217124, 0), [['Here are solutions using apply.'], ['A non-apply solution for getting count of not x:']], [[" df['count of not x'] = df.apply(lambda x: (x[['y','z']] != x['x']).sum(), axis=1)\ndf['unique'] = df.apply(lambda x: x[['x','y','z']].nunique(), axis=1)\n"]], ['Getting stats about each row and putting them into a new column. Pandas'], 3, 1], [(25217124, 1), [['A non-apply solution for getting count of not x:'], ["Can't think of anything great for unique.  This uses apply, but may be faster, depending on the shape of the data."]], [[" df['count of not x'] = (~df[['y','z']].isin(df['x'])).sum(1)\n"]], ['Getting stats about each row and putting them into a new column. Pandas'], 3, 1], [(25217124, 2), [["Can't think of anything great for unique.  This uses apply, but may be faster, depending on the shape of the data."], ['-10000']], [[" df['unique'] = df[['x','y','z']].T.apply(lambda x: x.nunique())\n"]], ['Getting stats about each row and putting them into a new column. Pandas'], 3, 1], [(25233885, 0), [['This line has no effect:'], ['you must reassign the result:']], [[' user_profiles.filter(gender=gender)\n']], ['How to chain django query filters to conditionally filter by certain criteria'], 2, 0], [(25233885, 1), [['you must reassign the result:'], ['-10000']], [[' user_profiles = user_profiles.filter(gender=gender)\n']], ['How to chain django query filters to conditionally filter by certain criteria'], 2, 0], [(25244751, 0), [['Assuming they are always adjacent, and using your example data:'], ['Printing that in your format:']], [[" import csv\n\nwith open(fn, 'r') as fin:\n    reader=csv.reader(fin, skipinitialspace=True)\n    header=next(reader)\n    data={k:[] for k in header}\n    for row in reader:\n        row_di={k:v for k,v in zip(header, row)}\n        if (all(len(data[e]) for e in header) \n               and row_di['Third col']==data['Third col'][-1] \n               and row_di['Fourth col']==data['Fourth col'][-1]):\n            for e in header:\n                data[e].pop()\n        else:\n            for e in header:\n                data[e].append(row_di[e])\n\n>>> data\n{'Second col': ['Bryant', 'Bryant', 'Williams', 'Williams', 'Williams'], 'First col': ['Pat', 'Pat', 'Jim', 'Jim', 'Jim'], 'Fourth col': ['29th April', '9th May', '10th March', '17th March', '21st March'], 'Third col': ['ID2', 'ID2', 'ID3', 'ID3', 'ID3'], '...': ['...   ', '... ', '...  ', '...   ', '...']}\n"]], ['Python - compare columns in a text file, loop and pop lists'], 3, 1], [(25244751, 1), [['Printing that in your format:'], ['Prints:']], [[" unique_ids=set(data['Third col'])    \n\nwhile True:                        \n    try:    \n        print ', '.join([data[e].pop(0) for e in header])\n    except IndexError:\n        break     \nprint 'Unique IDs:', len(unique_ids)         \n"]], ['Python - compare columns in a text file, loop and pop lists'], 3, 0], [(25244751, 2), [['Prints:'], ['Notes:']], [[' Pat, Bryant, ID2, 29th April, ...   \nPat, Bryant, ID2, 9th May, ... \nJim, Williams, ID3, 10th March, ...  \nJim, Williams, ID3, 17th March, ...   \nJim, Williams, ID3, 21st March, ...\nUnique IDs: 2\n']], ['Python - compare columns in a text file, loop and pop lists'], 3, 0], [(25249663, 1), [['Output:'], ['It steps from one layer to another an checks, which nodes still can be reached given the predefined  threshold . Unreachable nodes are removed from the array. When the loop continues, those nodes are not considered anymore.']], [[' Finding edges from layer 0 to 1 ...\nReachable nodes of next layer: [10]\nFinding edges from layer 1 to 2 ...\nReachable nodes of next layer: [13]\nTrue\n\nFinding edges from layer 0 to 1 ...\nReachable nodes of next layer: [10, 13]\nFinding edges from layer 1 to 2 ...\nReachable nodes of next layer: [13]\nTrue\n']], ['Python: Determine whether each step in path across n arrays falls below threshold value'], 2, 0], [(25255535, 1), [['Then, your want you call you can use this;'], ['-10000']], [[" foundQTreeWidgetItem  = self.findItemWidget(findQWidget) # Don't part argument currentQTreeWidgetItem use in recursive loop\n"]], ['How to get QTreeWidgetItem if its ItemWidget is known'], 2, 0], [(25269476, 0), [["I don't know if there's a module, but I'd go with this code, which is easily generalizeable:"], ['With no numpy installed:']], [[' import numpy as np\nfrom collections import Counter\na = [2, 1, 3, 1, 2, 3, 1, 2, 2, 2]\nb = np.zeros((3,3))\nfor (x,y), c in Counter(zip(a, a[1:])).iteritems():\n    b[x-1,y-1] = c\nprint b\narray([[ 0.,  2.,  1.],\n       [ 1.,  2.,  1.],\n       [ 2.,  0.,  0.]])\n']], ['Python transition matrix'], 2, 1], [(25269476, 1), [['With no numpy installed:'], ["A few details of what's going on, if needed:"]], [[' b = [[0 for _ in xrange(3)] for _ in xrange(3)]\nfor (x,y), c in Counter(zip(a, a[1:])).iteritems():\n    b[x-1][y-1] = c\n\nprint b\n[[0, 2, 1], [1, 2, 1], [2, 0, 0]]\n']], ['Python transition matrix'], 2, 1], [(25277092, 0), [['This can be easily done if we index into the raveled  data  array:'], ['-10000']], [[' out = data.ravel()[ind.ravel() + np.repeat(range(0, 8*ind.shape[0], 8), ind.shape[1])].reshape(ind.shape)\n']], ['Extract elements of a 2d array with indices from another 2d array'], 2, 1], [(25277092, 1), [['-10000'], ['ind  has the information on the elements from  data  that we want.  Unfortunately, it is expressed in 2-D indices.  The first line above converts these into  indices  of the 1-D raveled  data .  The second line above selects those elements out of the raveled array  data .  The third line restores the 2-D shape to  out .\nThe 2-D indices represented by  ind  is converted to ind indices  has the indices']], [[' indices = ind.ravel() + np.repeat(range(0, 8*ind.shape[0], 8), ind.shape[1])\nout = data.ravel()[indices]\nout = out.reshape(ind.shape)\n']], ['Extract elements of a 2d array with indices from another 2d array'], 2, 1], [(25286811, 0), [['I recreated the density scatter plot in mayavi as follows:'], ["Setting the scale_mode to 'none' prevents glyphs from being scaled in proportion to the density vector. In addition for large datasets, I disabled scene rendering and used a mask to reduce the number of points. "]], [[" import numpy as np\nfrom scipy import stats\nfrom mayavi import mlab\n\nmu, sigma = 0, 0.1 \nx = 10*np.random.normal(mu, sigma, 5000)\ny = 10*np.random.normal(mu, sigma, 5000)\nz = 10*np.random.normal(mu, sigma, 5000)\n\nxyz = np.vstack([x,y,z])\nkde = stats.gaussian_kde(xyz)\ndensity = kde(xyz)\n\n# Plot scatter with mayavi\nfigure = mlab.figure('DensityPlot')\npts = mlab.points3d(x, y, z, density, scale_mode='none', scale_factor=0.07)\nmlab.axes()\nmlab.show()\n"]], ['How to plot a 3D density map in python with matplotlib'], 4, 1], [(25286811, 1), [["Setting the scale_mode to 'none' prevents glyphs from being scaled in proportion to the density vector. In addition for large datasets, I disabled scene rendering and used a mask to reduce the number of points. "], ['Next, to evaluate the gaussian kde on a grid:']], [[" # Plot scatter with mayavi\nfigure = mlab.figure('DensityPlot')\nfigure.scene.disable_render = True\n\npts = mlab.points3d(x, y, z, density, scale_mode='none', scale_factor=0.07) \nmask = pts.glyph.mask_points\nmask.maximum_number_of_points = x.size\nmask.on_ratio = 1\npts.glyph.mask_input_points = True\n\nfigure.scene.disable_render = False \nmlab.axes()\nmlab.show()\n"]], ['How to plot a 3D density map in python with matplotlib'], 4, 0], [(25296219, 0), [["If you don't have any more dots in the filename then you can do something with importlib (example with a filename  4-1.py )"], ['Now, if you have dots in the filename, the situation is more tricky because dots mean subpackage structure to python.  Never the less it is still kinda possible with  imp , \nso here is that gnarly trick:']], [[" import importlib\nmy_module = importlib.import_module('4-1')\n"]], ['Import .py files with punctuation before extension'], 2, 1], [(25296219, 1), [['Now, if you have dots in the filename, the situation is more tricky because dots mean subpackage structure to python.  Never the less it is still kinda possible with  imp , \nso here is that gnarly trick:'], ['-10000']], [[" import imp\nmy_module = imp.load_source('my_module', 'strange.name-1.py')\n"]], ['Import .py files with punctuation before extension'], 2, 1], [(25344576, 0), [['The  Standard Scaler  from scikit learn handles this, and corner cases, pretty well.'], ['If necessary, you can access the means and standard deviations of the feature columns using']], [[' from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X1)\noutput = scaler.transform(X2)\n']], ['scale two matrices with scipy or sklearn'], 2, 1], [(25344576, 1), [['If necessary, you can access the means and standard deviations of the feature columns using'], ['You can also use the StandardScaler in a pipeline as preprocessing preceding an estimator.']], [[' scaler.std_\nscaler.mean_\n']], ['scale two matrices with scipy or sklearn'], 2, 0], [(25345513, 0), [['Yes, it is possible to send  any  sequence of bytes with the library:'], ['In fact, the  first multipart-encoded file example  in the  requests  documentation posts a binary file:']], [[" with open(audiofile, 'rb') as fobj:\n    requests.post(url, files={'fieldname', fobj})\n"]], ['Is it possible to post audio files with the python requests library'], 2, 1], [(25345843, 0), [['Any comparison (other than  != ) of a NaN to a non-NaN value will always return False:'], ['So you can simply ignore the fact that there are NaNs already in your array and do:']], [[' >>> x < -1000\narray([False, False, False,  True, False, False], dtype=bool)\n']], ['inequality comparison of numpy array with nan to a scalar'], 3, 0], [(25345843, 1), [['So you can simply ignore the fact that there are NaNs already in your array and do:'], ["EDIT  I don't see any warning when I ran the above, but if you really need to stay away from the NaNs, you can do something like:"]], [[' >>> x[x < -1000] = np.nan\n>>> x\narray([ nan,   1.,   2.,  nan,  nan,   5.])\n']], ['inequality comparison of numpy array with nan to a scalar'], 3, 1], [(25345843, 2), [["EDIT  I don't see any warning when I ran the above, but if you really need to stay away from the NaNs, you can do something like:"], ['-10000']], [[' mask = ~np.isnan(x)\nmask[mask] &= x[mask] < -1000\nx[mask] = np.nan\n']], ['inequality comparison of numpy array with nan to a scalar'], 3, 1], [(25411441, 1), [['Compiling the regular expression is optional. Without compiling, you would issue'], ['and ']], [[" exre = r'decadal[0-9]{4}'\n"]], ['Create list using regex inputs'], 3, 0], [(25411441, 2), [['and '], ["Compiling can be useful when you need to apply a regex a lot of times in order to do the compiling part only once. However, most of the time you won't notice a difference, as even if you don't compile the regex manually Python will cache the last used regexes. To be precise, the last one hundred regexes, though the only reference I got for this is the Regular Expression Cookbook by Jan Goyvaerts and Steven Levithan."]], [[' dirs = [d for d in dirs if d not in dirExclude and not re.search(exre, d)]\n']], ['Create list using regex inputs'], 3, 0], [(25435908, 1), [["Here's an example of it in action:"], ['Output:']], [[' from _threading_local import local\nimport threading\nimport time\n\nl = local()\n\ndef f():\n   global l\n   l.ok = "HMM"\n   time.sleep(50)\n\nif __name__ == "__main__":\n    l.ok = \'hi\'\n    t = threading.Thread(target=f)\n    t.start()\n    for t in threading.enumerate():\n        for item in t.__dict__:\n           if isinstance(item, tuple):\n               print("Thread\'s local is %s" % t.__dict__[item])\n']], ['Python: Getting all the items out of a `threading.local`'], 4, 1], [(25435908, 2), [['Output:'], ["This is exploiting the fact that the pure-python implementation of  local  stores each thread's  local  state in the  Thread  object's  __dict__ , using a tuple object as the key:"]], [[" Thread's local is {'ok': 'hi'}\nThread's local is {'ok': 'HMM'}\n"]], ['Python: Getting all the items out of a `threading.local`'], 4, 0], [(25435908, 3), [["This is exploiting the fact that the pure-python implementation of  local  stores each thread's  local  state in the  Thread  object's  __dict__ , using a tuple object as the key:"], ["If you're using the implementation of  local  written in  C  (which is usually the case if you just use  from threading import local ), I'm not sure how/if you can do it."]], [[" >>> threading.current_thread().__dict__\n{ ..., ('_local__key', 'thread.local.140466266257288'): {'ok': 'hi'}, ...}\n"]], ['Python: Getting all the items out of a `threading.local`'], 4, 0], [(25457718, 3), [['Update:  upon rereading your question it sounds like you might prefer the positional version of the above, which looks like this:'], ['The  *  is a lot like the  ** : instead of using a dict to set keyword arguments, it is using a list (or tuple) to set positional arguments.']], [[" >>> '{0} {1}'.format('hello', 'world')\n'hello world'\n>>> inputs = ['hello', 'world']  # or 'hello world'.split()\n>>> '{0} {1}'.format(*inputs)\n'hello world'\n"]], ['How to map word combinations in python'], 4, 1], [(25467360, 0), [['You can use  get_dummies  to do the hard work.  Something like'], ['produces']], [[" target = pd.DataFrame(0, index=df.index, columns=range(1,13))\ndm = pd.get_dummies(df.index.month).set_index(df.index)\ntarget = (target + dm).fillna(0)\ntarget.columns = ['is'+x.capitalize() for x in pd.datetools.MONTHS]\npd.concat([df, target], axis=1)\n"]], ['Pandas Dataframe - How To Convert Date to Boolean Columns?'], 8, 1], [(25467360, 1), [['produces'], ['-10000']], [['                 temp  isJan  isFeb  isMar  isApr  isMay  isJun  isJul  isAug  \\\n2011-01-01  0.419860      1      0      0      0      0      0      0      0   \n2011-03-22  0.479502      0      0      1      0      0      0      0      0   \n2011-06-10  0.687352      0      0      0      0      0      1      0      0   \n2011-08-29  0.377993      0      0      0      0      0      0      0      1   \n2011-11-17  0.877410      0      0      0      0      0      0      0      0   \n\n            isSep  isOct  isNov  isDec  \n2011-01-01      0      0      0      0  \n2011-03-22      0      0      0      0  \n2011-06-10      0      0      0      0  \n2011-08-29      0      0      0      0  \n2011-11-17      0      0      1      0  \n']], ['Pandas Dataframe - How To Convert Date to Boolean Columns?'], 8, 0], [(25467360, 2), [['-10000'], ["Now let's make something that has the right shape as what we want (we shouldn't assume that we'll necessarily see every month, after all; our test example only has 5 months with nonzero values):"]], [[' >>> index = pd.date_range("2011-01-01", periods=5, freq="80d")\n>>> df = pd.DataFrame({"temp": np.random.random(5)}, index=index)\n>>> df\n                temp\n2011-01-01  0.566277\n2011-03-22  0.965421\n2011-06-10  0.854030\n2011-08-29  0.780752\n2011-11-17  0.148783\n']], ['Pandas Dataframe - How To Convert Date to Boolean Columns?'], 8, 0], [(25467360, 3), [["Now let's make something that has the right shape as what we want (we shouldn't assume that we'll necessarily see every month, after all; our test example only has 5 months with nonzero values):"], ['get_dummies  will generate an indicator matrix:']], [[' >>> target = pd.DataFrame(0, index=df.index, columns=range(1,13))\n>>> target\n            1   2   3   4   5   6   7   8   9   10  11  12\n2011-01-01   0   0   0   0   0   0   0   0   0   0   0   0\n2011-03-22   0   0   0   0   0   0   0   0   0   0   0   0\n2011-06-10   0   0   0   0   0   0   0   0   0   0   0   0\n2011-08-29   0   0   0   0   0   0   0   0   0   0   0   0\n2011-11-17   0   0   0   0   0   0   0   0   0   0   0   0\n']], ['Pandas Dataframe - How To Convert Date to Boolean Columns?'], 8, 0], [(25467360, 4), [['get_dummies  will generate an indicator matrix:'], ['(And now you can see why we wanted to have the missing columns somewhere.)  We can add these two together:']], [[' >>> dm = pd.get_dummies(df.index.month).set_index(df.index)\n>>> dm\n            1   3   6   8   11\n2011-01-01   1   0   0   0   0\n2011-03-22   0   1   0   0   0\n2011-06-10   0   0   1   0   0\n2011-08-29   0   0   0   1   0\n2011-11-17   0   0   0   0   1\n']], ['Pandas Dataframe - How To Convert Date to Boolean Columns?'], 8, 0], [(25467360, 5), [['(And now you can see why we wanted to have the missing columns somewhere.)  We can add these two together:'], ["And we're all done except for making it look pretty.  There are lots of ways to get month names; let's choose one at random:"]], [[' >>> target = (target + dm).fillna(0)\n>>> target\n            1   2   3   4   5   6   7   8   9   10  11  12\n2011-01-01   1   0   0   0   0   0   0   0   0   0   0   0\n2011-03-22   0   0   1   0   0   0   0   0   0   0   0   0\n2011-06-10   0   0   0   0   0   1   0   0   0   0   0   0\n2011-08-29   0   0   0   0   0   0   0   1   0   0   0   0\n2011-11-17   0   0   0   0   0   0   0   0   0   0   1   0\n']], ['Pandas Dataframe - How To Convert Date to Boolean Columns?'], 8, 0], [(25467360, 6), [["And we're all done except for making it look pretty.  There are lots of ways to get month names; let's choose one at random:"], ['And now the columns are named as you wanted.  All that remains is to combine everything:']], [[" >>> pd.datetools.MONTHS\n['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n>>> target.columns = ['is'+x.capitalize() for x in pd.datetools.MONTHS]\n"]], ['Pandas Dataframe - How To Convert Date to Boolean Columns?'], 8, 0], [(25467360, 7), [['And now the columns are named as you wanted.  All that remains is to combine everything:'], ['-10000']], [[' >>> pd.concat([df, target], axis=1)\n                temp  isJan  isFeb  isMar  isApr  isMay  isJun  isJul  isAug  \\\n2011-01-01  0.566277      1      0      0      0      0      0      0      0   \n2011-03-22  0.965421      0      0      1      0      0      0      0      0   \n2011-06-10  0.854030      0      0      0      0      0      1      0      0   \n2011-08-29  0.780752      0      0      0      0      0      0      0      1   \n2011-11-17  0.148783      0      0      0      0      0      0      0      0   \n\n            isSep  isOct  isNov  isDec  \n2011-01-01      0      0      0      0  \n2011-03-22      0      0      0      0  \n2011-06-10      0      0      0      0  \n2011-08-29      0      0      0      0  \n2011-11-17      0      0      1      0  \n']], ['Pandas Dataframe - How To Convert Date to Boolean Columns?'], 8, 0], [(25469326, 0), [['Second, you can find out what packages contain things in that directory using:'], ['(Yes, the list is very long.) Knowing that list, we can request those packages to be reinstalled:']], [[' $ dpkg -S /usr/lib/python2.7\npython-qgis, python-gdal, python-psycopg2, python-pyspatialite, youtube-dl, virtualbox, duplicity, bzr-git, bzr-builddeb, debconf, ipython, libpython2.7-minimal:i386, libpython2.7-dev:i386, tahoe-lafs, seascope, samba, qbzr, python2.7, python-zope.interface, python-zfec, python-yaml, python-xdg, python-xapian, python-wxversion, python-wxgtk2.8, python-ws4py, python-webob, python-wadllib, python-vipscc, python-utidylib, python-usb, python-urllib3, python-tz, python-twisted, python-twisted-words, python-twisted-web, python-twisted-runner, python-twisted-news, python-twisted-names, python-twisted-mail, python-twisted-lore, python-twisted-core, python-twisted-conch, python-twisted-bin, python-tk, python-tdb, python-talloc, python-support, python-subversion, python-sphinx, python-software-properties, python-six, python-sip, python-simplejson, python-simplegeneric, python-setuptools, python-setools, python-serial, python-sepolicy, python-sepolgen, python-semanage, python-selinux, python-secretstorage, python-scipy, python-samba, python-routes, python-roman, python-requests, python-repoze.lru, python-reportlab, python-reportlab-accel, python-renderpm, python-radare2, python-qt4, python-qt4-gl, python-qscintilla2, python-pyvorbis, python-pytools, python-pysqlite2, python-pyside.qtxml, python-pyside.qtwebkit, python-pyside.qtuitools, python-pyside.qttest, python-pyside.qtsvg, python-pyside.qtsql, python-pyside.qtscript, python-pyside.qtopengl, python-pyside.qtnetwork, python-pyside.qthelp, python-pyside.qtgui, python-pyside.qtdeclarative, python-pyside.qtcore, python-pyside.phonon, python-pyparsing, python-pyopencl, python-pygments, python-pygame, python-pycurl, python-pycryptopp, python-pyaudio, python-pyasn1, python-poppler-qt4, python-ply, python-pkg-resources, python-pivy, python-pip, python-pil, python-pexpect, python-paramiko, python-pam, python-openssl, python-opengl, python-opencv, python-ogg, python-oauthlib, python-oauth, python-numpy, python-ntdb, python-newt, python-nevow, python-networkx, python-netifaces, python-mysqldb, python-musicbrainz, python-mock, python-mechanize, python-markupsafe, python-markdown, python-mako, python-magic, python-lxml, python-libxml2, python-ldb, python-lazr.uri, python-lazr.restfulclient, python-launchpadlib, python-keyring, python-jinja2, python-ipy, python-imaging, python-httplib2, python-html5lib, python-gtk2, python-gst0.10, python-gst0.10-rtsp, python-gpgme, python-gobject-2, python-glade2, python-gi, python-freenect, python-foolscap, python-feedparser, python-fastimport, python-eyed3, python-enchant, python-egenix-mxtools, python-egenix-mxdatetime, python-ecdsa, python-dulwich, python-docutils, python-docopt, python-dnspython, python-distro-info, python-distlib, python-decorator, python-debian, python-dbus, python-dateutil, python-cssutils, python-cssselect, python-crypto, python-configobj, python-colorama, python-collada, python-cherrypy3, python-chardet, python-bzrlib, python-bluez, python-beautifulsoup, python-audit, python-apt, python-apsw, policycoreutils, mercurial, mercurial-common, lsb-release, iotop, hugin-tools, hplip, frescobaldi, libpython2.7:i386, libpython2.7-stdlib:i386, dblatex, cython, cfv, bzr-upload, bzr-search, bzr-pipeline, bzr-loom, bzr-explorer: /usr/lib/python2.7\n']], ['Delete "usr/lib/python2.7" byMistake, how to fix it?'], 2, 0], [(25480433, 0), [["Usually you'd use a filtered version of the object, for example:"], ['Similar you can also simply construct a filtered bytes object for further processing:']], [[" In [63]: test\nOut[63]: 'hello\\x00world'\nIn [68]: for my_bytes in filter(lambda x: x != b'\\x00', test):\n   ....:     print(my_bytes)\n   ....:\nh\ne\nl\nl\no\nw\no\nr\nl\nd\n"]], ['How to consistently ignore one byte from a string'], 2, 1], [(25480433, 1), [['Similar you can also simply construct a filtered bytes object for further processing:'], ['I usually use  bytes  objects as it does not share the interface with strings in python 3. Certainly not byte  arrays .']], [[" In [62]: test = b'hello\\x00world'\nIn [63]: test\nOut[63]: 'hello\\x00world'\nIn [64]: test_without_nulls = bytes(filter(lambda x: x != b'\\x00', test))\nIn [65]: test_without_nulls\nOut[65]: 'helloworld'\n"]], ['How to consistently ignore one byte from a string'], 2, 1], [(25493559, 1), [['EX:'], ['Adding them to a dictionary is as simple as:']], [['  Mark = Employees()\n Mark.surname = \'Johnson\'\n Mark.salary = 5\n Mark.car_man = \'Volvo\'\n\n John = Employees()\n John.surname = "Doe"\n John.salary = 10\n John.car_man = Daewoo\n']], ['How do I sort a complex dictionary by a key, which resides deep the dictionary?'], 3, 0], [(25493559, 2), [['Adding them to a dictionary is as simple as:'], ['-10000']], [[' my_dict = {}\nmy_dict[#key] = # your instance\n']], ['How do I sort a complex dictionary by a key, which resides deep the dictionary?'], 3, 0], [(25513929, 0), [['An efficient way of doing this is to use  yield :'], ['And then in the code that calls this function, you can do:']], [[" def grabber3(datafile):\n    with open(datafile, 'rb') as f:\n        r =csv.DictReader(f)\n        for line in r:\n            del line['thisthing']\n            yield line\n"]], ['Returning elements from a loop, one at a time'], 3, 0], [(25513929, 1), [['And then in the code that calls this function, you can do:'], ['And then iterate through this  dict_generator  as:']], [[' dict_generator = grabber3(a_file)\n']], ['Returning elements from a loop, one at a time'], 3, 0], [(25513929, 2), [['And then iterate through this  dict_generator  as:'], ['More on  yield  and generators here:   ']], [[' for a_dict in dict_generator:\n    print a_dict\n']], ['Returning elements from a loop, one at a time'], 3, 0], [(25537262, 0), [['Eventually, I took the way of Middleware. I wrote a custom middleware and set a variable in the middleware, something like,'], ['It is global.\nAnd a local thread:']], [[' CONSTANT_NAME = None\n']], ['Set global constant cross all the view'], 4, 0], [(25537262, 1), [['It is global.\nAnd a local thread:'], ['Then I have two methods in the middleware,']], [[' _thread_local = threading.local()\n']], ['Set global constant cross all the view'], 4, 0], [(25537262, 2), [['Then I have two methods in the middleware,'], ['Then inside my middleware, I have']], [[" def get_constant_value()\n    return getattr(_thread_local, 'CONSTANT_NAME', None)\n\ndef set_constant_value(value):\n    CONSTANT_NAME = value\n"]], ['Set global constant cross all the view'], 4, 0], [(25537262, 3), [['Then inside my middleware, I have'], ['At this point, I call set and get this server-crossed variable from any view I want.']], [[' def process_request(self, request):\n    _thread_local.CONSTANT_NAME = CONSTANT_NAME\n']], ['Set global constant cross all the view'], 4, 0], [(25538578, 0), [["How a class gets printed is determined by it's  __str__  and  __repr__  methods, so you can add these to  Object1 . Note that you should only do this if you're sure that you want the value of  Object1  to be represented by it's  d  attribute:"], ['Output:']], [[' class Object1:\n    d = 1\n\n    def __str__(self):\n        return str(self.d)\n\n    def __repr__(self):\n        return str(self.d)\n']], ['Python: How can I print out an object as a regular dictionary without reference?'], 2, 1], [(25538578, 1), [['Output:'], ['-10000']], [[" print b.__dict__\n{'a': 2, 'o': 2}\n"]], ['Python: How can I print out an object as a regular dictionary without reference?'], 2, 0], [(25541651, 0), [['Newline characters ( \\n ) are not translated to new lines when rendered as HTML.  You can use a  <pre>  tag (preformatted) to allow them to have meaning when being rendered.  '], ['Or you could replace newline characters with a  <br> , like so:']], [[' ...\nprint """\n<html><head></head>\n<body>\n<br>\n<pre>\n"""\nprint nova.servers.get_console_output(VMID)\n\nprint """\n</pre>\n</body></html>\n"""\n']], ['How to print formatted python output for javascript?'], 2, 1], [(25641980, 0), [['First, your selection of  transform  nodes. I assume you already have something along these lines:'], ["Iterate over all the children of a given node, returning  False  if any of them aren't  transform . Otherwise return  True ."]], [[' selection = pymel.core.ls(selection=True, transforms=True)\n']], ['How to isolate group nodes in maya with python'], 4, 0], [(25641980, 1), [["Iterate over all the children of a given node, returning  False  if any of them aren't  transform . Otherwise return  True ."], ['Now you just need to filter the selection, in  one  of the following two ways, depending on which style you find most clear:']], [[' def is_group(node):\n    children = node.getChildren()\n    for child in children:\n        if type(child) is not pymel.core.nodetypes.Transform:\n            return False\n    return True\n']], ['How to isolate group nodes in maya with python'], 4, 0], [(25641980, 2), [['Now you just need to filter the selection, in  one  of the following two ways, depending on which style you find most clear:'], ['or']], [[' selection = filter(is_group, selection)\n']], ['How to isolate group nodes in maya with python'], 4, 0], [(25641980, 3), [['or'], ['-10000']], [[' selection = [node for node in selection if is_group(node)]\n']], ['How to isolate group nodes in maya with python'], 4, 0], [(25649412, 0), [['eg:'], ['This can then be vectorized using numpy:']], [[' N(2) = N(2) + N(1) * exp(-0.05)\nN(3) = N(3) + (N(2) + N(1) * exp(-0.05))*exp(-0.05)\nN(3) = N(3) + N(2)*exp(-0.05) + N(1)*exp(-0.1)\nN(4) = ...and so on\n']], ['Exponential Decay on Python Pandas DataFrame'], 5, 0], [(25649412, 2), [['Because it is vectorized, it should be fast:'], ["This compares with (note I'm using python 3 and had to make a change to the behaviour on the first row...):"]], [[' %timeit a = pd.expanding_apply(dataset, rollingsum)\n10 loops, best of 3: 25.5 ms per loop\n']], ['Exponential Decay on Python Pandas DataFrame'], 5, 0], [(25649412, 4), [['This comes out as:'], ['-10000']], [[' In[68]: %timeit multipleApply(dataset)\n1 loops, best of 3: 414 ms per loop\n']], ['Exponential Decay on Python Pandas DataFrame'], 5, 0], [(25664682, 0), [['http://dragly.org/2013/03/25/working-with-percolation-clusters-in-python/'], ['This will identify the clusters:']], [[' from pylab import *\nfrom scipy.ndimage import measurements\n\nz2 = array([[0,0,0,0,0,0,0,0,0,0],\n    [0,0,1,0,0,0,0,0,0,0],\n    [0,0,1,0,1,0,0,0,1,0],\n    [0,0,0,0,0,0,1,0,1,0],\n    [0,0,0,0,0,0,1,0,0,0],\n    [0,0,0,0,1,0,1,0,0,0],\n    [0,0,0,0,0,1,1,0,0,0],\n    [0,0,0,1,0,1,0,0,0,0],\n    [0,0,0,0,1,0,0,0,0,0],\n    [0,0,0,0,0,0,0,0,0,0]])\n']], ['How to find cluster sizes in 2D numpy array?'], 3, 0], [(25664682, 1), [['This will identify the clusters:'], ['The following will calculate their area.']], [[' lw, num = measurements.label(z2)\nprint lw\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n   [0, 0, 1, 0, 2, 0, 0, 0, 3, 0],\n   [0, 0, 0, 0, 0, 0, 4, 0, 3, 0],\n   [0, 0, 0, 0, 0, 0, 4, 0, 0, 0],\n   [0, 0, 0, 0, 5, 0, 4, 0, 0, 0],\n   [0, 0, 0, 0, 0, 4, 4, 0, 0, 0],\n   [0, 0, 0, 6, 0, 4, 0, 0, 0, 0],\n   [0, 0, 0, 0, 7, 0, 0, 0, 0, 0],\n   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n']], ['How to find cluster sizes in 2D numpy array?'], 3, 0], [(25664682, 2), [['The following will calculate their area.'], ['This gives what you expect, although I would think that you would have a cluster with 8 members by eye-percolation.']], [[' area = measurements.sum(z2, lw, index=arange(lw.max() + 1))\nprint area\n[ 0.  2.  1.  2.  6.  1.  1.  1.]\n']], ['How to find cluster sizes in 2D numpy array?'], 3, 0], [(25690354, 0), [['You can write your function as:'], ['then']], [[' def print_multiples(n, m = 10):\n    for i in range(0, m + 1):\n        print n * i,\n    print ""\n']], ['How to generalize a multiplication table for (n * m)'], 9, 0], [(25690354, 1), [['then'], ['will print']], [['  print_multiples(2)\n']], ['How to generalize a multiplication table for (n * m)'], 9, 0], [(25690354, 2), [['will print'], ['print_multiples(2, 5)']], [[' 0 2 4 6 8 10 12 14 16 18 20\n']], ['How to generalize a multiplication table for (n * m)'], 9, 0], [(25690354, 3), [['print_multiples(2, 5)'], ['Then with the function:']], [[' 0 2 4 6 8 10\n']], ['How to generalize a multiplication table for (n * m)'], 9, 0], [(25690354, 4), [['Then with the function:'], ['you can:']], [[' def print_table(n = 10):\n    for i in range(1, n + 1):\n        print_multiples(i)\n']], ['How to generalize a multiplication table for (n * m)'], 9, 0], [(25690354, 5), [['you can:'], ['and this produces the output:']], [['  print_table()\n']], ['How to generalize a multiplication table for (n * m)'], 9, 0], [(25690354, 6), [['and this produces the output:'], ['while ']], [[' 0 1 2 3 4 5 6 7 8 9 10  \n0 2 4 6 8 10 12 14 16 18 20 \n0 3 6 9 12 15 18 21 24 27 30 \n...\n0 10 20 30 40 50 60 70 80 90 100 \n']], ['How to generalize a multiplication table for (n * m)'], 9, 0], [(25690354, 7), [['while '], ['produces:']], [['  print_table(2)\n']], ['How to generalize a multiplication table for (n * m)'], 9, 0], [(25690354, 8), [['produces:'], ['-10000']], [[' 0 1 2 3 4 5 6 7 8 9 10 \n0 2 4 6 8 10 12 14 16 18 20 \n']], ['How to generalize a multiplication table for (n * m)'], 9, 0], [(25690778, 0), [['Prepare a dictionary containing value - display text pairs for all options in the select, e.g '], ['In  yourtemplate.html :']], [[" mydict = {'5min': '5-Min', '1hour': 'Hour', '1day': 'Day'}\n"]], ['Jinja2 to put a whole element in <option>'], 3, 0], [(25690778, 1), [['In  yourtemplate.html :'], ['How to pass the  target  - in your view you need to do this (I assume you know the basics of views in Flask)']], [[' <select name="my_name">\n    {% for key, value in mydict.items() %}\n        <option value="{{key}}" \n        {% if (key == target) %} selected="selected" { %endif %}\n        >\n        {{value}}\n        </option>\n    {% endfor %}\n</select>\n']], ['Jinja2 to put a whole element in <option>'], 3, 0], [(25705612, 0), [['You can use  find_all()  and get the  .name  for every tag found:'], ['Prints:']], [[' from bs4 import BeautifulSoup\n\ndata = """<?xml version="1.0" encoding="UTF-8"?>\n<note>\n    <to> Tove</to>\n    <from>Jani</from>\n    <heading>Reminder</heading>\n    <body>Don\'t forget me this weekend!</body>\n</note>\n"""\n\nsoup = BeautifulSoup(data, \'xml\')\nprint [tag.name for tag in soup.find_all()]\n']], ['List of distinct XML element names using BeautifulSoup'], 6, 1], [(25705612, 1), [['Prints:'], ['Example, using  lxml :']], [[" ['note', 'to', 'from', 'heading', 'body']\n"]], ['List of distinct XML element names using BeautifulSoup'], 6, 0], [(25705612, 2), [['Example, using  lxml :'], ['Prints:']], [[' from lxml import etree\n\ndata = """<?xml version="1.0" encoding="UTF-8"?>\n<note>\n    <to> Tove</to>\n    <from>Jani</from>\n    <heading>Reminder</heading>\n    <body>Don\'t forget me this weekend!</body>\n</note>\n"""\n\ntree = etree.fromstring(data)\nprint [item.tag for item in tree.xpath(\'//*\')]\n']], ['List of distinct XML element names using BeautifulSoup'], 6, 1], [(25705612, 3), [['Prints:'], ['-10000']], [[" ['note', 'to', 'from', 'heading', 'body']\n"]], ['List of distinct XML element names using BeautifulSoup'], 6, 0], [(25705612, 4), [['-10000'], ['Prints:']], [[' from xml.etree.ElementTree import fromstring, ElementTree\n\ndata = """<?xml version="1.0" encoding="UTF-8"?>\n<note>\n    <to> Tove</to>\n    <from>Jani</from>\n    <heading>Reminder</heading>\n    <body>Don\'t forget me this weekend!</body>\n</note>\n"""\n\ntree = ElementTree(fromstring(data))\nprint [item.tag for item in tree.getiterator()]\n']], ['List of distinct XML element names using BeautifulSoup'], 6, 1], [(25705612, 5), [['Prints:'], ['-10000']], [[" ['note', 'to', 'from', 'heading', 'body']\n"]], ['List of distinct XML element names using BeautifulSoup'], 6, 0], [(25713738, 0), [['(Chunking function is from  this answer )'], ['It\'s not clear to me whether the arrays will always be generated by  numpy.linspace  or not.  If so, there are simpler ways of doing this, like simply picking each nth member of the original array, where n is determined by the "compression" ratio:']], [[' #  Chunking function \ndef chunks(l, n):\n    for i in xrange(0, len(l), n):\n        yield l[i:i+n]\n\n# Resampling function\ndef resample(arr, newLength):\n    chunkSize = len(arr)/newLength\n    return [np.mean(chunk) for chunk in chunks(arr, chunkSize)]\n\n# Example:\nimport numpy as np\nx = np.linspace(-1,1,15)\ny = resample(x, 5)\nprint y\n# Result:\n# [-0.85714285714285721, -0.4285714285714286, -3.7007434154171883e-17, 0.42857142857142844, 0.8571428571428571]\n']], ['Compress an array in python?'], 2, 1], [(25726345, 0), [['You can define a data type that will be the concatenation of your columns, allowing you to use the 1d set operations:'], ['If you wanted only  D , for example, you could have done:']], [[' a = np.ascontiguousarray(A).view(np.dtype((np.void, A.shape[1]*min(A.strides))))\nb = np.ascontiguousarray(B).view(np.dtype((np.void, B.shape[1]*min(B.strides))))\n\ncheck = np.in1d(a, b)\nC = np.where(check)[0]\nD = A[check]\n\ncheck = np.in1d(b, a)\nE = np.where(check)[0]\n']], ["'Remove' command for ND arrays in Python"], 2, 1], [(25728442, 0), [['Basically, I make a button group:'], ['Then in the javascript from the mpld3-flask example I use:']], [['   <div class="btn-group" data-toggle="buttons">\n  <label class="btn btn-primary">\n      <input type="radio" name="options" id="home"> Option 1\n  </label>\n  <label class="btn btn-primary">\n      <input type="radio" name="options" id="option2"> Option 2\n  </label>\n  <label class="btn btn-primary">\n      <input type="radio" name="options" id="option3"> Option 3\n  </label>\n']], ['How to place a matplotlib plot into an html container using mpld3 and flask'], 2, 0], [(25728442, 1), [['Then in the javascript from the mpld3-flask example I use:'], ["Now I have a radio-button bar, with the currently active plot button set to 'active', which only requires one click on one of the buttons to draw a new plot. "]], [[' $(\'.btn-primary\').on(\'click\', function(){\n  var qu = {"plot_type":$(this).find(\'input\').attr(\'id\')}\n  $(this).addClass(\'active\').siblings().removeClass(\'active\');\n  $.ajax({\n    type: "POST",\n    async:true,\n    contentType: "application/json; charset=utf-8",\n    url: "/query",\n    data: JSON.stringify(qu),\n    success: function (data) {\n     var graph = $("#container");\n     graph.html(data);\n     $("#container").show();\n     },\n   dataType: "html"\n  });  \n}); \n']], ['How to place a matplotlib plot into an html container using mpld3 and flask'], 2, 0], [(25744399, 0), [['It\'s possible to conditionally assign on only one line, but I don\'t consider it "elegant".'], ['Result:']], [[' test = True\na = 23\nb = 42\na,b = (1,b) if test else (a,1)\nprint (a,b)\n']], ['Switch between assignments to different variables in python? With ternary operator?'], 4, 1], [(25744399, 1), [['Result:'], ['-10000']], [[' (1, 42)\n']], ['Switch between assignments to different variables in python? With ternary operator?'], 4, 0], [(25744399, 2), [['-10000'], ['Or, if the names have no semantic value, store your numbers in a list.']], [[' test = True\nd = {"a": 23, "b": 42}\nd["a" if test else "b"] = 1\nprint d\n#result: {\'a\': 1, \'b\': 42}\n']], ['Switch between assignments to different variables in python? With ternary operator?'], 4, 1], [(25746147, 0), [['Group the df by the column B and get the first and last element of each identical value in this group.'], ['-10000']], [[" df.groupby('B').head(1)\ndf.groupby('B').last()\n"]], ['Pandas: Get value of mutliple sorting/grouping query'], 2, 0], [(25746147, 1), [['-10000'], ['-10000']], [[' df[df.A % 0.1 == 0]\n']], ['Pandas: Get value of mutliple sorting/grouping query'], 2, 0], [(25757650, 0), [['Using regular expressions, its a trivial task:'], ["If you want to search and replace, then you can use  re.sub  for substituting matches; so if I want to replace all matches with the word 'hello':"]], [[" >>> s = '''C  DesignerTEE edBore 1 1/42006\n... Cylinder SingleVerticalB DesignerHHJ e 1 1/8Cooling 1\n... EngineBore 11/16 DesignerTDT 8Length 3Width 3\n... EngineCy DesignerHEE Inline2008Bore 1\n... Height 4TheChallen DesignerTET e 1Stroke 1P 305\n... Height 8C 606Wall15ccG DesignerQBG ccGasEngineJ 142\n... Height DesignerEQE C 60150ccGas2007'''\n>>> import re\n>>> exp = 'Designer[A-Z]{3}'\n>>> re.findall(exp, s)\n['DesignerTEE', 'DesignerHHJ', 'DesignerTDT', 'DesignerHEE', 'DesignerTET', 'DesignerQBG', 'DesignerEQE']\n"]], ['replacing appointed characters in a string in txt file'], 2, 1], [(25765631, 0), [["I'm not sure what the values enclosed by the inequality signs are, so I have replaced them with  foo  and  bar . Something like this ought to do the trick:"], ['Output (as CSV):']], [[" import re\nimport csv\n\nfiltered_messages = ['UpdatePlaybackStatusInfo', 'Assert']\nfieldnames = ['ticks', 'foo', 'type', 'bar', 'message']\n\nwith open('log.txt') as log:\n    with open('output.csv', 'w') as csv_file:\n        writer = csv.DictWriter(csv_file, delimiter=',', fieldnames=fieldnames)\n        writer.writerow(dict((fn,fn) for fn in fieldnames))\n        for line in log:\n            match = re.search(r'^Ticks = (?P<ticks>\\d+)\\s+<(?P<foo>\\d+)> <(?P<type>\\w+)> <(?P<bar>\\d+)>\\s+(?P<message>.+)$', line)\n            if match is not None and match.group('type') in filtered_messages:\n                writer.writerow(match.groupdict())\n"]], ['Need to parse a tool log file in python and then save the results in excel or csv'], 2, 1], [(25765631, 1), [['Output (as CSV):'], ['-10000']], [[' ticks   foo type    bar message\n\n2408967 3360    UpdatePlaybackStatusInfo    0   Avg Prefetch(ms): 157.739, Avg Render(ms): 25.7375, Avg Display FPS: 27.3688\n\n3371181 3360    UpdatePlaybackStatusInfo    0   Frames dropped during playback: 0 / 219, Preroll(ms): 812.849\n\n3371181 3360    UpdatePlaybackStatusInfo    0   Avg Prefetch(ms): 17.1389, Avg Render(ms): 33.8339, Avg Display FPS: 29.5562\n\n3465531 10548   Assert  0   Debug Assert failed!\n\n3465531 10548   Assert  0   wglMakeCurrent failed: Error 0: The operation completed successfully.\n']], ['Need to parse a tool log file in python and then save the results in excel or csv'], 2, 0], [(25838448, 0), [['You can also look at the python.el file and look for  define-key :'], ['Or  indent']], [[' ;; Indent specific                                                                                                                         \n(define-key map "\\177" \'python-indent-dedent-line-backspace)                                                                               \n(define-key map (kbd "<backtab>") \'python-indent-dedent-line)                                                                              \n(define-key map "\\C-c<" \'python-indent-shift-left)                                                                                         \n(define-key map "\\C-c>" \'python-indent-shift-right)                                                                                        \n(define-key map ":" \'python-indent-electric-colon)      \n']], ['Cycling through possible indentations in python.el in Emacs'], 2, 1], [(25838448, 1), [['Or  indent'], ['-10000']], [[" ;; Indentation: Automatic indentation with indentation cycling is                                                                              \n;; provided, it allows you to navigate different available levels of                                                                           \n;; indentation by hitting <tab> several times.  Also when inserting a                                                                          \n;; colon the `python-indent-electric-colon' command is invoked and                                                                             \n;; causes the current line to be dedented automatically if needed. \n"]], ['Cycling through possible indentations in python.el in Emacs'], 2, 1], [(25859572, 0), [['You can use  isin  to filter for valid rows, and then use  replace  to replace the values:'], ['Input (the dummy  df  above):']], [[' import pandas as pd\nHashTable = {"chr1" : 1, "chr2" : 2, "chr3" : 3, "chr4" : 4, "chr5" : 5, "chr6" : 6, "chr7" : 7, "chr8" : 8, "chr9" : 9, "chr10" : 10, "chr11" : 11, "chr12" : 12, "chr13" : 13, "chr14" : 14, "chr15" : 15, "chr16" : 16, "chr17" : 17, "chr18" : 18, "chr19" : 19, "chrX" : 20, "chrY" : 21, "chrM" : 22, \'chrMT\': 23}\n# A dummy DataFrame with all the valid chromosomes and one unknown chromosome\ndf = pd.DataFrame({"Chrom": HashTable.keys() + ["unknown_chr"]})\n# Filter for valid rows\ndf = df[df["Chrom"].isin(HashTable.keys())]\n# Replace the values according to dict\ndf["Chrom"].replace(HashTable, inplace=True)\nprint df\n']], ['Pandas: Change dataframe values based on dictionary and remove rows with no match'], 4, 1], [(25859572, 1), [['Input (the dummy  df  above):'], ['Output DataFrame:']], [['           Chrom\n0         chrMT\n1          chrY\n2          chrX\n3         chr13\n4         chr12\n5         chr11\n6         chr10\n7         chr17\n8         chr16\n9         chr15\n10        chr14\n11        chr19\n12        chr18\n13         chrM\n14         chr7\n15         chr6\n16         chr5\n17         chr4\n18         chr3\n19         chr2\n20         chr1\n21         chr9\n22         chr8\n23  unknown_chr\n']], ['Pandas: Change dataframe values based on dictionary and remove rows with no match'], 4, 0], [(25859572, 2), [['Output DataFrame:'], ['If the resulting values are all integers, you change the above  replace  line to enforce the correct  dtype :']], [['    Chrom\n0     23\n1     21\n2     20\n3     13\n4     12\n5     11\n6     10\n7     17\n8     16\n9     15\n10    14\n11    19\n12    18\n13    22\n14     7\n15     6\n16     5\n17     4\n18     3\n19     2\n20     1\n21     9\n22     8\n']], ['Pandas: Change dataframe values based on dictionary and remove rows with no match'], 4, 0], [(25859572, 3), [['If the resulting values are all integers, you change the above  replace  line to enforce the correct  dtype :'], ['-10000']], [[' df["Chrom"] = df["Chrom"].replace(HashTable).astype(int)\n']], ['Pandas: Change dataframe values based on dictionary and remove rows with no match'], 4, 0], [(25882275, 0), [['Supposing you are just asking to do the dynamic way use the following:'], ['Output is:']], [[" set_mean = -10\n#calculated_mean = None\n\nenergy = []\ncalculated_mean = float('inf')\nx = 1\nwhile calculated_mean > set_mean:\n    for i in range(x, x+4):  # you can change step size here by passing it as last argument\n        energy.append(i-i*i)  \n        print(energy)\n        calculated_mean =  sum(energy[-2:])/2\n        print(calculated_mean)\n    x = x + 1\n"]], ['iterate the range in for loop to satisfy the condition'], 2, 1], [(25882275, 1), [['Output is:'], ['I think this is exactly what you want. Because the loop stops when you get  -16']], [[' [0]\n0\n[0, -2]\n-1\n[0, -2, -6]\n-4\n[0, -2, -6, -12]\n-9\n[0, -2, -6, -12, -2]\n-7\n[0, -2, -6, -12, -2, -6]\n-4\n[0, -2, -6, -12, -2, -6, -12]\n-9\n[0, -2, -6, -12, -2, -6, -12, -20]\n-16\n']], ['iterate the range in for loop to satisfy the condition'], 2, 0], [(25883410, 0), [["As long as the number of items isn't too large, you can brute-force this:"], ['You can use it to iterate over all matches:']], [[' import itertools\ndef matches(d, target):\n    # First try single items, then couples, then triplets etc.\n    for num in range(1,len(d)+1):\n        # Iterate over all possible combinations of length num\n        for com in itertools.combinations(d.items(), num):\n            # Does the sum of all second items per key/value pair match the target?\n            if sum(item[1] for item in com) == target:\n                # Yield one item at a time, so the caller can decide when to stop\n                yield com\n']], ['How to sort through keys in a dictionary, adding the values and returning a list of keys if combined values equal a certain number'], 2, 1], [(25883410, 1), [['You can use it to iterate over all matches:'], ['or add a  break  after the  print()  line to make your program stop at the first match.']], [[" >>> mydict = {'a':1, 'b':12, 'c':33, 'd':40, 'e':15, 'f':6, 'g':27}\n>>> for match in matches(mydict,55):\n...     print(match)\n...\n(('d', 40), ('e', 15))\n(('c', 33), ('e', 15), ('f', 6), ('a', 1))\n(('b', 12), ('e', 15), ('g', 27), ('a', 1))\n"]], ['How to sort through keys in a dictionary, adding the values and returning a list of keys if combined values equal a certain number'], 2, 0], [(25923521, 0), [['You could turn  lista  into a set for fast membership testing, then just loop over  listb  to select any that are found in  lista :'], ['The next step is turning  listb  into a dictionary:']], [[' lista_set = set(lista)\nfor item in listb:\n    if item[0] in lista_set:\n        print item\n']], ['Compare list w/ sublist'], 3, 0], [(25923521, 1), [['The next step is turning  listb  into a dictionary:'], ['Now you can use sets to pick out  just  the ones that are both in  lista_set  and  listb_dict :']], [[' listb_dict = {item[0]: item[1:] for item in listb}\n']], ['Compare list w/ sublist'], 3, 0], [(25923521, 2), [['Now you can use sets to pick out  just  the ones that are both in  lista_set  and  listb_dict :'], ['-10000']], [[' for match in listb_dict.viewkeys() & lista_set:\n    print match, listb_dict[match]\n']], ['Compare list w/ sublist'], 3, 0], [(25932166, 0), [['Passing an instance of a mapped object to inspect, returns an  InstanceState , describing that object.\nThis state also contains the identity:'], ['Will give:']], [[" Base = declarative_base()\n\nclass MyClass(Base):\n    __tablename__ = 'mytable'\n    key = Column(Integer, primary_key=True)\na = MyClass(key=1)\n\nfrom sqlalchemy.inspection import inspect    \npk = inspect(a).identity\nprint pk\n"]], ['Generic way to get primary key from declaratively defined instance in SQLAlchemy'], 2, 1], [(25932166, 1), [['Will give:'], ["Since primary keys can consist of multiple columns, the identity in general is a tuple containing all the column values that are part of the primary key.\nIn your case, that's simply the  key ."]], [[' (1,)\n']], ['Generic way to get primary key from declaratively defined instance in SQLAlchemy'], 2, 0], [(25946008, 0), [["Why don't you just use regexs to remove the parts you don't want and then parse it using beautifulsoup?"], ['Output']], [[' import re\n\ndata = """document.write(\'<table>\');\ndocument.write(\'\n <tr>\n  <td>\n   <span class="prod">\n   some text\n   </span>\n  </td>\n  \');\ndocument.write(\'\n  <td>\n   <span class="prod">\n    7.70.022\n   </span>\n  </td>\n </tr>\n \');\ndocument.write(\'</table>\');"""\n\npattern = re.compile(r"document\\.write\\(\'\\n?([^\']*?)(?:\\n\\s*)?\'\\);")\ndata = pattern.sub(\'\\g<1>\', data)\nprint data\n']], ['How to remove all "document.write(\' \');" with beautifulsoup'], 2, 1], [(25946008, 1), [['Output'], ['-10000']], [[' <table>\n <tr>\n  <td>\n   <span class="prod">\n   some text\n   </span>\n  </td>\n  <td>\n   <span class="prod">\n    7.70.022\n   </span>\n  </td>\n </tr>\n</table>\n']], ['How to remove all "document.write(\' \');" with beautifulsoup'], 2, 0], [(25959543, 0), [["You give raw text and don't specify the kind of formatting you want to do. Leaving the formatting details out, yes you can replace text in FileA that is also in FileB with formatted content."], ['output']], [[' import re\nwith open(\'fileA.txt\') as A:\n    A_content=[x.strip() for x in A]\nwith open(\'fileB.txt\') as B:\n    B_content=[x.strip() for x in B]\noutput=[]\nfor line_A in A_content:\n    for line_B in B_content:\n        #do whatever formatting you need on the text, \n        # I am just surrounding it with *\'s here\n\n        replace = "**" + line_B + "**"\n\n        #use re.sub, \n        # details here: https://docs.python.org/2/library/re.html#re.sub\n\n        line_A = re.sub(line_B, replace , line_A)\n    #I am adding everything to the output array but you can check if it is \n    # different from the initial content. I leave that for you to do\n    output.append(line_A)\n']], ['Match rows between two files and mark the matched strings'], 2, 1], [(25959543, 1), [['output'], ['-10000']], [[' **NM_134083**  mmu-miR-96-5p   **NM_134083**       0.96213 -0.054\n**NM_177305**  mmu-miR-96-5p   **NM_177305**       0.95707 -0.099\nNM_026184  mmu-miR-93-3p   NM_026184       0.9552  -0.01\n']], ['Match rows between two files and mark the matched strings'], 2, 0], [(25996817, 1), [['To append  ,nodev :'], ['-10000']], [[" >>> re.sub(r'(?<=\\s)(?!.*nodev)(?=\\S*,\\S*)\\S+', r'\\g<0>,nodev', s)\n'/dev/mapper/ex_s-l_home /home  ext4    rw,exec,auto,nouser,async,nodev    1  2'\n>>> re.sub(r'(?<=\\s)(?!.*nodev)(?=\\S*,\\S*)\\S+', r'\\g<0>,nodev', s2)\n'/dev/mapper/ex_s-l_home /home  ext4    rw,exec,auto,nodev,nouser,async    1  2'\n"]], ['python regex comma separated group'], 2, 0], [(26059710, 0), [['-10000'], ['optimized one']], [[" f1 = open('a', 'r').readlines()\nf2 = open('b', 'r').readlines()\nout = []\ncount = 1 \nfor i in f1:\n    flag = False\n    for j in f2:\n        if i == j:\n            flag = True\n    if not flag:\n        out.append(count)\n    count+=1\nfor o in out:\n    print o\n"]], ['Compare two files in python and save line differences in a new file'], 2, 1], [(26059710, 1), [['optimized one'], ['-10000']], [[" f1 = open('a', 'r').readlines()\nf2 = open('b', 'r').readlines()\nout = []\nindexa = 0\nindexb = 0\nout = []\nwhile(1):\n    try:\n        if f1[indexa][:-1] ==  f2[indexb][:-1]:\n            indexa +=1\n            indexb +=1\n        elif f1[indexa][:-1] > f2[indexb][:-1]:\n            indexb += 1\n        elif f1[indexa][:-1] < f2[indexb][:-1]:\n            out.append(indexa+1)\n            indexa += 1\n    except IndexError:\n        break\nfor i in out:\n    print i\n"]], ['Compare two files in python and save line differences in a new file'], 2, 1], [(26063269, 0), [['As Warren Weckesser suggested, I can simply follow the Scipy cookbook for the coupled mass-spring system. First, I need to write my "right side" equations as:'], ['And here is the code:']], [[" x'  = vx\ny'  = vy\nz'  = vz\nvx' = Ac*x/r\nvy' = Ac*y/r + q*E/m\nvz' = Ac*z/r \n"]], ['Simulating electron motion - differential equation with adaptive step size in python'], 2, 0], [(26126880, 0), [['The following should give you what you want.'], ['Getting rows/columns/values out from this format is possible by using  .loc :']], [[" df_wanted = pd.pivot_table(\n    df_orig, \n    index=['AN', 'Bincode', 'BC_all'], \n    columns=['Treatment', 'Timepoint'], \n    values=['RIA_avg', 'sum14N_avg']\n)\n"]], ['Python Pandas DataFrame how to Pivot'], 2, 1], [(26126880, 1), [['Getting rows/columns/values out from this format is possible by using  .loc :'], ['-10000']], [[" df_wanted.loc['XYK987', :]\ndf_wanted.loc[:, ('sum14N_avg')]\ndf_wanted.loc['ALF234', ('RIA_avg', 'C', 24)]\n"]], ['Python Pandas DataFrame how to Pivot'], 2, 0], [(26163563, 0), [["Perform a 'left'  merge  in your case on column 'B':"], ["Another method would be to set 'B' on your second df as the index and then call  map :"]], [[" In [206]:\n\ndf.merge(df1, how='left', on='B')\nOut[206]:\n   A  B  C  D\n0  1  1  3  5\n1  1  1  2  5\n2  1  2  5  6\n3  2  2  7  6\n4  2  3  7  4\n"]], ['combination of two DF, pandas'], 2, 1], [(26163563, 1), [["Another method would be to set 'B' on your second df as the index and then call  map :"], ['-10000']], [[" In [215]:\n\ndf1 = df1.set_index('B')\ndf['D'] = df['B'].map(df1['D'])\ndf\nOut[215]:\n   A  B  C  D\n0  1  1  3  5\n1  1  1  2  5\n2  1  2  5  6\n3  2  2  7  6\n4  2  3  7  4\n"]], ['combination of two DF, pandas'], 2, 1], [(26179639, 0), [['You could use numpy.all and index broadcasting for this'], ['Here is the full code without a  for  loop:']], [[' filter_matrix = np.array(filterColumns)\ncombination_array = np.array(combination)\nbool_matrix = filter_matrix == combination_array[newaxis, :]   #not sure of the newaxis position\nsubset = raw_data[bool_matrix]\n']], ['Python & Numpy - create dynamic, arbitrary subsets of ndarray'], 2, 0], [(26179639, 1), [['Here is the full code without a  for  loop:'], ['An alternative implementation would be to transform the indexing matrix into a string matrix, sum row-wise, get an argsort over the now unique indexing column and split as above.']], [[' import numpy as np\n\n# select filtering indexes\nfilter_indexes = [1, 3]\n# generate the test data\nraw_data = np.random.randint(0, 4, size=(50,5))\n\n\n# create a column that we would use for indexing\nindex_columns = raw_data[:, filter_indexes]\n\n# sort the index columns by lexigraphic order over all the indexing columns\nargsorts = np.lexsort(index_columns.T)\n\n# sort both the index and the data column\nsorted_index = index_columns[argsorts, :]\nsorted_data = raw_data[argsorts, :]\n\n# in each indexing column, find if number in row and row-1 are identical\n# then group to check if all numbers in corresponding positions in row and row-1 are identical\nautocorrelation = np.all(sorted_index[1:, :] == sorted_index[:-1, :], axis=1)\n\n# find out the breakpoints: these are the positions where row and row-1 are not identical\nbreakpoints = np.nonzero(np.logical_not(autocorrelation))[0]+1\n\n# finally find the desired subsets \nsubsets = np.split(sorted_data, breakpoints)\n']], ['Python & Numpy - create dynamic, arbitrary subsets of ndarray'], 2, 1], [(26187054, 0), [['Code:'], ['Result:']], [[' src = """<tr align="center" class="tableRow1Font" >\n<td>OPEN</td>\n<td>80002</td>\n<td>\n<span style="font-weight:bold;">\nACCY\n</span> \n<A HREF="http://bulletin.gwu.edu/search/?P=ACCY+2001" target="_blank">\n<span style="font-weight:bold;">\n2001\n</span>\n</A>\n</td>\n<td>10</td>\n<td>Intro Financial Accounting</td>\n<td>3.00</td>\n<td> Ray, K</td>\n<td><a href="http://virtualtour.gwu.edu/#MON" target="_blank" >MON</a> 113</td>\n<td>MW<br>12:45PM - 02:00PM</td>\n<td>08/25/14 - 12/06/14</td>\n<td>\n</td>\n</tr>"""\n\nfrom lxml import html\n\ntree = html.fromstring(src)\ntds = tree.xpath("//td/descendant-or-self::*/text()[normalize-space()]")\n\nprint ", ".join([td.strip() for td in tds])\n']], ['Extract html cell data XPath'], 2, 1], [(26187054, 1), [['Result:'], ['Note that this gets all the text from inside all  td  tags, including the ones from inside the  <a>  child node, ie.  MON .']], [[' OPEN, 80002, ACCY, 2001, 10, Intro Financial Accounting, 3.00, Ray, K, MON, 113, MW, 12:45PM - 02:00PM, 08/25/14 - 12/06/14\n[Finished in 0.5s]\n']], ['Extract html cell data XPath'], 2, 0], [(26205922, 0), [['First to calculate the "weighted average":'], ['If you set this as a column, you can groupby over it:']], [[' In [11]: g = df.groupby(\'Date\')\n\nIn [12]: df.value / g.value.transform("sum") * df.wt\nOut[12]:\n0    0.125000\n1    0.250000\n2    0.416667\n3    0.277778\n4    0.444444\ndtype: float64\n']], ['Calculate weighted average using a pandas/dataframe'], 4, 0], [(26205922, 1), [['If you set this as a column, you can groupby over it:'], ['Now the sum of this column is the desired:']], [[' In [13]: df[\'wa\'] = df.value / g.value.transform("sum") * df.wt\n']], ['Calculate weighted average using a pandas/dataframe'], 4, 0], [(26205922, 2), [['Now the sum of this column is the desired:'], ['or potentially:']], [[' In [14]: g.wa.sum()\nOut[14]:\nDate\n01/01/2012    0.791667\n01/02/2012    0.722222\nName: wa, dtype: float64\n']], ['Calculate weighted average using a pandas/dataframe'], 4, 0], [(26205922, 3), [['or potentially:'], ['-10000']], [[' In [15]: g.wa.transform("sum")\nOut[15]:\n0    0.791667\n1    0.791667\n2    0.791667\n3    0.722222\n4    0.722222\nName: wa, dtype: float64\n']], ['Calculate weighted average using a pandas/dataframe'], 4, 0], [(26222720, 0), [['Note that when you start dynamically inspecting  globals  like this, people start to wonder ...  with that said, here\'s a working version of your code that works so long as you only "read" from the global variable.'], ['A  better  way is to just use keyword arguments:']], [[' def calledfunction():\n  default_local = \'some default\'\n  var = globalvar if \'globalvar\' in globals() else default_local\n  print var\n\n# -----------------\n\nprint "calling function before the variable is defined"\nprint\ncalledfunction()\n\nglobalvar = "created outside the function"\n\nprint "calling function after the variable is defined"\nprint\ncalledfunction()\n']], ['Python: checking for the existence of a variable in globals() makes it invisible in the local context'], 2, 1], [(26238723, 0), [['The NetworkX component functions return Python generators. You can create a list of items in the generator using the Python  list  function.  Here is an example showing that and also finding the largest weakly connected component.'], ['You can use e.g. list to turn the generator into a list of subgraphs:']], [[' In [1]: import networkx as nx\n\nIn [2]: G = nx.DiGraph()\n\nIn [3]: G.add_path([1,2,3,4])\n\nIn [4]: G.add_path([10,11,12])\n']], ['Largest weakly connected component in networkX'], 3, 0], [(26238723, 1), [['You can use e.g. list to turn the generator into a list of subgraphs:'], ['The max operator takes a key argument which you can set to the Python function  len  which calls len(g) on each subgraph to compute the number of nodes.  So to get the component with the largest number of nodes you can write']], [[' In [5]: list(nx.weakly_connected_component_subgraphs(G))\nOut[5]: \n[<networkx.classes.digraph.DiGraph at 0x278bc10>,\n <networkx.classes.digraph.DiGraph at 0x278ba90>]\n']], ['Largest weakly connected component in networkX'], 3, 0], [(26240228, 0), [['You can use  heapq.merge :'], ['In Python 3.x (3.3+):']], [[" import heapq\nimport contextlib\n\nfiles = [open(fn) for fn in inFiles]\nwith contextlib.nested(*files):\n    with open('output', 'w') as f:\n        f.writelines(heapq.merge(*files))\n"]], ['how to join multiple sorted files in Python alphabetically?'], 2, 1], [(26240228, 1), [['In Python 3.x (3.3+):'], ['-10000']], [[" import heapq\nimport contextlib\n\nwith contextlib.ExitStack() as stack:\n    files = [stack.enter_context(open(fn)) for fn in inFiles]\n    with open('output', 'w') as f:\n        f.writelines(heapq.merge(*files))\n"]], ['how to join multiple sorted files in Python alphabetically?'], 2, 1], [(26265015, 0), [['The python code first:'], ['And then the kivy file named shellapp.kv']], [['     from kivy.app import App\n    from kivy.uix.boxlayout import BoxLayout\n    from kivy.uix.popup import Popup\n    from kivy.properties import ObjectProperty\n    from kivy.uix.label import Label \n    import subprocess\n\n    class shellcommand(BoxLayout):\n        first=ObjectProperty()\n        second=ObjectProperty()\n        third=ObjectProperty()\n\n        def uname(self):\n            v=subprocess.check_output("uname -a",shell=True)\n            result=Popup(title="RESULT",content=Label(text="kernel is\\n" + v))\n            result.open()\n        def date(self):\n            d=subprocess.check_output("date",shell=True)\n            res=Popup(title="DATE",content=Label(text="the date today is\\n" + d))\n            res.open()\n        def last(self):\n            last=subprocess.check_output("w",shell=True)\n            ls=Popup(title="LOGIN",content=Label(text="logged in \\n" + last))\n            ls.open()\n\n\n    class shellApp(App):\n        def build(self):\n            return shellcommand()\n\n    shellApp().run()\n']], ['How to get console output printed using kivy'], 2, 0], [(26265015, 1), [['And then the kivy file named shellapp.kv'], ['If there is a way to improve this code please let Me know how to.Thanks']], [[' <shellcommand>:\norientation: "vertical"\nfirst:one\nsecond:two\nthird:three\ncanvas:\n    Rectangle:\n        source: "snaps.png" #location of any picture\n        pos: self.pos\n        size: self.size\n\n\n\nBoxLayout:\n    orientation: "horizontal"\n    Button:\n        id:one\n        text: "UNAME"\n        background_color: 0,0,0,1\n        font_size:32\n        size_hint:1,None\n        on_press: root.uname()\n\n\n    Button:\n        id:two      \n        text: "DATE"\n        background_color: 1,1.5,0,1\n        font_size:32\n        size_hint:1,None\n        on_press: root.date()\n\n\n    Button:\n        id: three\n        text: "LOGGED IN"\n        background_color: 1,0,0,1\n        font_size:32\n        size_hint: 1,None\n        on_press: root.last()\n']], ['How to get console output printed using kivy'], 2, 0], [(26277322, 0), [['-10000'], ['-10000']], [['x.c (compiled with <code>cl /LD x.c</code>: #include <stdlib.h>\n#include <stdint.h>\n__declspec(dllexport) void read(int16_t** input, size_t size)\n{\n  int i;\n  int16_t* p = (int16_t*) malloc (size*sizeof(int16_t));\n  for(i=0;i<size;i++)\n    p[i] = i;\n  *input = p;\n}\n__declspec(dllexport) void release(int16_t* input)\n{\n    free(input);\n}\n']], ['passing arrays with ctypes'], 6, 0], [(26277322, 2), [['-10000'], ["Note this leaves you with potential memory leak if you don't remember to  free  the  malloc .  A better way would be to allocate the buffer in Python and tell the C function the size:"]], [['Output: 0\n1\n2\n3\n4\n']], ['passing arrays with ctypes'], 6, 0], [(26277322, 3), [["Note this leaves you with potential memory leak if you don't remember to  free  the  malloc .  A better way would be to allocate the buffer in Python and tell the C function the size:"], ['-10000']], [['x.c #include <stdlib.h>\n#include <stdint.h>\n__declspec(dllexport) void read(int16_t* input, size_t size)\n{\n  int i;\n  for(i=0;i<size;i++)\n    input[i] = i;\n}\n']], ['passing arrays with ctypes'], 6, 0], [(26277322, 5), [['-10000'], ['-10000']], [['Output [0, 1, 2, 3, 4]\n']], ['passing arrays with ctypes'], 6, 0], [(26279903, 0), [['Stick with Numpy array and use its  sum()  method:'], ['Of course you can do it with Python lists as well but it is going to be slow:']], [[' >>> arr = np.array([[1,2,3,5,4,3], \n          [5,7,2,4,6,7],\n          [3,6,2,4,5,9]])\n>>> arr.sum(axis=0)\narray([ 9, 15,  7, 13, 15, 19])\n']], ['Addition of multiple arrays in python'], 2, 1], [(26279903, 1), [['Of course you can do it with Python lists as well but it is going to be slow:'], ['-10000']], [[' >>> lst = [[1,2,3,5,4,3], \n          [5,7,2,4,6,7],\n          [3,6,2,4,5,9]]\n>>> map(sum, zip(*lst))\n[9, 15, 7, 13, 15, 19]\n']], ['Addition of multiple arrays in python'], 2, 1], [(26286980, 0), [["You can define your sublisting action as a function and apply it twice. This is probably inefficient since it will construct intermediate lists before constructing ones with the finest level of sublisting. But, is is easier to read since you're already familiar with the first step given that you used it when asking this question."], ['A more efficient way to do it would be to create a generator that yields a list of up to two items from the front of the list. Then chain them.']], [[' def nest_in_pairs(original):\n    return [original[i:i+2] for i in range(0,len(original),2)]\n\nprint nest_in_pairs(nest_in_pairs(original))\n']], ['create sublists within sublists in python'], 3, 1], [(26286980, 1), [['A more efficient way to do it would be to create a generator that yields a list of up to two items from the front of the list. Then chain them.'], ["Here's an example of playing with this after pasting the above code into an IPython session:"]], [[' from types import GeneratorType\n\ndef yield_next_two(seq):\n    if not isinstance(seq, GeneratorType):\n        for i in range(0, len(seq), 2):\n            yield seq[i:i+2]\n    else:\n        while True:\n            item1 = next(seq)\n            try:\n                item2 = next(seq)\n                yield [item1, item2]\n            except StopIteration:\n                yield [item1]\n\npair_generator = yield_next_two(original)\n\nquad_generator = yield_next_two(yield_next_two(original))\n\nnext(pair_generator)\n\nnext(quad_generator)\n']], ['create sublists within sublists in python'], 3, 1], [(26317418, 1), [["[('2014', [('Mary', 2)]), ('1970', [('John', 2)])]"], ['In 2014 the name Mary occured the most (2 times)']], [[" for year,r in results:\n  if int(year) in valid:\n   print('In {0} the name {1} occured the most ({2} times)'.format(year, r[0][0], r[0][1]))\n"]], ['Reading text file and returning most popular name for that year'], 2, 0], [(26321557, 0), [['Following will find every  tr  tag with viewLicense'], ['So, it will work for the text provided in quesiton:']], [[' soup.find_all("tr", class_="viewLicense")\n']], ["Beautiful Soup - Class contains 'a' and not contains 'b'"], 3, 1], [(26321557, 1), [['So, it will work for the text provided in quesiton:'], ['However if you have a  tr  tag which has both  viewLicense  and  viewLicenseDetails  classes, then following will find all  tr  tags with  viewLicense  and then remove tags with  viewLicenseDetails :']], [[' >>> soup.find_all("tr", class_="viewLicense")\n[<tr class="viewLicense inactive"></tr>, <tr class="viewLicense"></tr>]\n']], ["Beautiful Soup - Class contains 'a' and not contains 'b'"], 3, 1], [(26321557, 2), [['However if you have a  tr  tag which has both  viewLicense  and  viewLicenseDetails  classes, then following will find all  tr  tags with  viewLicense  and then remove tags with  viewLicenseDetails :'], ['-10000']], [[' >>> both_tags = soup.find_all("tr", class_="viewLicense")\n>>> for tag in both_tags:\n...     if \'viewLicenseDetails\' not in tag.attrs[\'class\']:\n...             print tag\n']], ["Beautiful Soup - Class contains 'a' and not contains 'b'"], 3, 1], [(26427128, 0), [['Using a server with these specs from  inxi -C :'], ["Let's try to profile some of the steps before you get the POS tags (using just 1 core):"]], [[' CPU(s): 2 Hexa core Intel Xeon CPU E5-2430 v2s (-HT-MCP-SMP-) cache: 30720 KB flags: (lm nx sse sse2 sse3 sse4_1 sse4_2 ssse3 vmx) \nClock Speeds: 1: 2500.036 MHz\n']], ['How to make POS n-grams more effective?'], 3, 0], [(26427128, 1), [["Let's try to profile some of the steps before you get the POS tags (using just 1 core):"], ['[out]:']], [[' import time\n\nfrom nltk.corpus import brown\nfrom nltk import sent_tokenize, word_tokenize, pos_tag\nfrom nltk import pos_tag_sents\n\n# Load brown corpus\nstart = time.time()\nbrown_corpus = brown.raw()\nloading_time = time.time() - start\nprint "Loading brown corpus took",  loading_time\n\n# Sentence tokenizing corpus\nstart = time.time()\nbrown_sents = sent_tokenize(brown_corpus)\nsent_time = time.time() - start\nprint "Sentence tokenizing corpus took", sent_time\n\n\n# Word tokenizing corpus\nstart = time.time()\nbrown_words = [word_tokenize(i) for i in brown_sents]\nword_time = time.time() - start\nprint "Word tokenizing corpus took", word_time\n\n# Loading, sent_tokenize, word_tokenize all together.\nstart = time.time()\nbrown_words = [word_tokenize(s) for s in sent_tokenize(brown.raw())]\ntokenize_time = time.time() - start\nprint "Loading and tokenizing corpus took", tokenize_time\n\n# POS tagging one sentence at a time took.\nstart = time.time()\nbrown_tagged = [pos_tag(word_tokenize(s)) for s in sent_tokenize(brown.raw())]\ntagging_time = time.time() - start\nprint "Tagging sentence by sentence took", tagging_time\n\n\n# Using batch_pos_tag.\nstart = time.time()\nbrown_tagged = pos_tag_sents([word_tokenize(s) for s in sent_tokenize(brown.raw())])\ntagging_time = time.time() - start\nprint "Tagging sentences by batch took", tagging_time\n']], ['How to make POS n-grams more effective?'], 3, 1], [(26427128, 2), [['[out]:'], ['Note: that the  pos_tag_sents  was previously called  batch_pos_tag  in version before NLTK3.0']], [[' Loading brown corpus took 0.154870033264\nSentence tokenizing corpus took 3.77206301689\nWord tokenizing corpus took 13.982845068\nLoading and tokenizing corpus took 17.8847839832\nTagging sentence by sentence took 1114.65085101\nTagging sentences by batch took 1104.63432097\n']], ['How to make POS n-grams more effective?'], 3, 0], [(26430002, 0), [["You can use  itertools.groupby . You can construct a  lambda  expression that looks for the value corresponding to the  'command'  key, then finds the  [1]  and  [2]  elements of splitting on the  ';'  character."], ['Output']], [[" d =[{'name': 'fire', 'command': '1;2;3;4'},\n    {'name': 'brain', 'command': '2;2;3;4'},\n    {'name': 'word', 'command': '1;3;4;5'},\n    {'name': 'cellphone', 'command': '6;1;3;4'},\n    {'name': 'ocean', 'command': '9;3;7;4'}]\n\nimport itertools\ngroups = itertools.groupby(d, lambda i: i['command'].split(';')[1:3])\n\nfor key, group in groups:\n    print(list(group))\n"]], ['how to goup items in a list of dictionaries by matching values \u200b\u200bin python'], 3, 1], [(26430002, 1), [['Output'], ['To find groups that had more than one member, you need one more step:']], [[" [{'name': 'fire', 'command': '1;2;3;4'}, {'name': 'brain', 'command': '2;2;3;4'}]\n[{'name': 'word', 'command': '1;3;4;5'}]\n[{'name': 'cellphone', 'command': '6;1;3;4'}]\n[{'name': 'ocean', 'command': '9;3;7;4'}]\n"]], ['how to goup items in a list of dictionaries by matching values \u200b\u200bin python'], 3, 0], [(26430002, 2), [['To find groups that had more than one member, you need one more step:'], ['-10000']], [[" for key, group in groups:\n    groupList = list(group)\n    if len(groupList) > 1:\n        print(groupList)\n\n[{'command': '1;2;3;4', 'name': 'fire'}, {'command': '2;2;3;4', 'name': 'brain'}]\n"]], ['how to goup items in a list of dictionaries by matching values \u200b\u200bin python'], 3, 0], [(26450673, 0), [["Let's set some things up and train some models:"], ['Now multiply the LSA components and the k-means centroids:']], [[" >>> from sklearn.datasets import fetch_20newsgroups\n>>> from sklearn.feature_extraction.text import TfidfVectorizer\n>>> from sklearn.cluster import KMeans\n>>> from sklearn.decomposition import TruncatedSVD\n>>> data = fetch_20newsgroups()\n>>> vectorizer = TfidfVectorizer(min_df=3, max_df=.95, stop_words='english')\n>>> lsa = TruncatedSVD(n_components=10)\n>>> km = KMeans(n_clusters=3)\n>>> X = vectorizer.fit_transform(data.data)\n>>> X_lsa = lsa.fit_transform(X)\n>>> km.fit(X_lsa)\n"]], ['sklearn decomposition top terms'], 3, 0], [(26450673, 1), [['Now multiply the LSA components and the k-means centroids:'], ['Then print; we need absolute values for the weights because of the sign indeterminacy in LSA:']], [[' >>> X.shape\n(11314, 38865)\n>>> lsa.components_.shape\n(10, 38865)\n>>> km.cluster_centers_.shape\n(3, 10)\n>>> weights = np.dot(km.cluster_centers_, lsa.components_)\n>>> weights.shape\n(3, 38865)\n']], ['sklearn decomposition top terms'], 3, 0], [(26450673, 2), [['Then print; we need absolute values for the weights because of the sign indeterminacy in LSA:'], ['Mind you, you really need a stop word filter for this to work. The stop words tend to end up in every single component, and get a high weight in every cluster centroid.']], [[" >>> features = vectorizer.get_feature_names()\n>>> weights = np.abs(weights)\n>>> for i in range(km.n_clusters):\n...     top5 = np.argsort(weights[i])[-5:]\n...     print(zip([features[j] for j in top5], weights[i, top5]))\n...     \n[(u'escrow', 0.042965734662740895), (u'chip', 0.07227072329320372), (u'encryption', 0.074855609122467345), (u'clipper', 0.075661844826553887), (u'key', 0.095064798549230306)]\n[(u'posting', 0.012893125486957332), (u'article', 0.013105911161236845), (u'university', 0.0131617377000081), (u'com', 0.023016036009601809), (u'edu', 0.034532489348082958)]\n[(u'don', 0.02087448155525683), (u'com', 0.024327099321009758), (u'people', 0.033365757270264217), (u'edu', 0.036318114826463417), (u'god', 0.042203130080860719)]\n"]], ['sklearn decomposition top terms'], 3, 0], [(26453595, 0), [['If you  must  use subscript notation, then your current solution is the most compact besides maybe a dynamic class created with  type :'], ['Instead, I would recommend that you use  slice , which allows you to create slice objects directly:']], [[" >>> Slice = type('', (), {'__getitem__': lambda _, x: x})()\n>>> Slice[1:2]\nslice(1, 2, None)\n>>> Slice[1:2:3]\nslice(1, 2, 3)\n>>>\n"]], ['Build slice objetcs from subscript notation'], 2, 1], [(26453595, 1), [['Instead, I would recommend that you use  slice , which allows you to create slice objects directly:'], ['The built-in was made specifically for this purpose (well, that and a few others such as type-checking with  isinstance ) and is therefore very portable as well as pythonic.']], [[' >>> slice(1, 2)\nslice(1, 2, None)\n>>> slice(1, 2, 3)\nslice(1, 2, 3)\n>>>\n']], ['Build slice objetcs from subscript notation'], 2, 1], [(26487617, 0), [["You're misunderstanding the way  apply_async  works. It doesn't call the function you pass to it in every process in the  Pool . It just calls the function one time, in one of the worker processes. So the results you're seeing are to be expected. You have a couple of options to get the behavior you want:"], ['Or']], [[' from multiprocessing import Pool                                                                                   \nimport time\nimport random\n\nSOME_LIST = []\n\ndef myfunc():\n    a = random.randint(0,3)\n    time.sleep(a)\n    return a\n\ndef cb(retval):\n    SOME_LIST.append(retval)\n\nprint("Starting...")\n\np = Pool(processes=8)\nfor _ in range(p._processes):\n    p.apply_async(myfunc, callback=cb)\np.close()\np.join()\n\nprint("Stopping...")\nprint(SOME_LIST)\n']], ['Managing Processes from Python multiprocessing module'], 2, 1], [(26487617, 1), [['Or'], ['Note that you could also call  apply_async  or  map  for  more  than the number of processes in the pool. The idea of the  Pool  is that it guarantees exactly  num_processes  processes will be running for the entire lifetime of the  Pool , no matter how many tasks you submit. So if you create a  Pool(8)  and call  apply_async  once, one of your eight workers will get a task, and the other seven will be idle. If you create a  Pool(8)  and call  apply_async  80 times, the 80 tasks will get distributed to your eight workers, with no more than eight of the tasks actually being processed at once.']], [[' from multiprocessing import Pool                                                                                      \nimport time\nimport random\n\n\ndef myfunc():\n    a = random.randint(0,3)\n    time.sleep(a)\n    return a\n\nprint("Starting...")\n\np = Pool(processes=8)\nSOME_LIST = p.map(myfunc, range(p._processes))\np.close()\np.join()\n\nprint("Stopping...")\nprint(SOME_LIST)\n']], ['Managing Processes from Python multiprocessing module'], 2, 1], [(26497396, 0), [['-10000'], ['yields']], [[" import pandas as pd\ndf = pd.read_table('data', sep='\\s{2,}').set_index('observation_date')\ndf.index = pd.DatetimeIndex(df.index)\ndf.index = df.index + pd.DateOffset(year=2013)\nprint(df)\n"]], ['How to change a DateTimeIndex in a pandas dataframe to all the same year?'], 2, 1], [(26497396, 1), [['yields'], ['-10000']], [['              Charge 1  Charge 2\n2013-01-31  35.535318  0.073390\n2013-02-28  27.685739  0.050302\n2013-01-31  27.671290  0.296882\n2013-02-28  26.647262  0.225714\n2013-03-31  21.495699  0.362151\n']], ['How to change a DateTimeIndex in a pandas dataframe to all the same year?'], 2, 0], [(26498100, 1), [['And this is the response (save it in the client with the proper format)'], ['in the client you can do this (in python for continuity)']], [[' {\n  "message": "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"\n}\n']], ['How to Define Google Endpoints API File Download Message Endpoint'], 3, 0], [(26498100, 2), [['in the client you can do this (in python for continuity)'], ['-10000']], [[' import base64\n\nmyFile = open("mock.jpg", "wb")\nimg = base64.b64decode(value)  #value is the returned string\nmyFile.write(img)\nmyFile.close()\n']], ['How to Define Google Endpoints API File Download Message Endpoint'], 3, 0], [(26498794, 0), [["If you don't know the bounds of the range in advance, one solution is to just use  while True: , and use a  break  when you've reached the target:"], ['-10000']], [[' while True:\n    x = x + 1\n    y = x ** 2\n    total = total + y\n    if total >= n:\n        break\nprint(total)\n']], ['How to calculate the value of the sum of squares defined as 1^2 + 2^2 + 3^2 + ... +n2 until a user specified sum has been reached'], 2, 1], [(26498794, 1), [['-10000'], ['-10000']], [[' numbers = itertools.count(1) # all positive integers\nsquares = (x**2 for x in numbers) # all squares of positive integers\ntotals = itertools.accumulate(squares) # all running totals of squares of ...\nbigtotals = itertools.dropwhile(lambda total: total < n, totals) # all ... starting >= n\ntotal = next(bigtotals) # first ... starting >= n\n']], ['How to calculate the value of the sum of squares defined as 1^2 + 2^2 + 3^2 + ... +n2 until a user specified sum has been reached'], 2, 1], [(26499216, 0), [["Here's an example using  requests :"], ['Prints the JSON structure containing the player game logs:']], [[" import requests\n\nurl = 'http://stats.nba.com/stats/playergamelog'\n\nparams = {\n    'Season': '2013-14',\n    'SeasonType': 'Regular Season',\n    'LeagueID': '00',\n    'PlayerID': '2544',\n    'pageNo': '1',\n    'rowsPerPage': '100'\n}\nresponse = requests.post(url, data=params)\n\nprint response.json()\n"]], ['Scraping website that uses javascript'], 2, 1], [(26499216, 1), [['Prints the JSON structure containing the player game logs:'], ['-10000']], [[" {u'parameters': {u'LeagueID': u'00',\n                 u'PlayerID': 2544,\n                 u'Season': u'2013-14',\n                 u'SeasonType': u'Regular Season'},\n u'resource': u'playergamelog',\n u'resultSets': [{u'headers': [u'SEASON_ID',\n                               u'Player_ID',\n                               u'Game_ID',\n                               u'GAME_DATE',\n                               u'MATCHUP',\n                               u'WL',\n                               u'MIN',\n                               u'FGM',\n                               u'FGA',\n                               u'FG_PCT',\n                               u'FG3M',\n                               u'FG3A',\n                               u'FG3_PCT',\n                               u'FTM',\n                               u'FTA',\n                               u'FT_PCT',\n                               u'OREB',\n                               u'DREB',\n                               u'REB',\n                               u'AST',\n                               u'STL',\n                               u'BLK',\n                               u'TOV',\n                               u'PF',\n                               u'PTS',\n                               u'PLUS_MINUS',\n                               u'VIDEO_AVAILABLE'],\n                  u'name': u'PlayerGameLog',\n                  u'rowSet': [[u'22013',\n                               2544,\n                               u'0021301192',\n                               u'APR 12, 2014',\n                               u'MIA @ ATL',\n                               u'L',\n                               37,\n                               10,\n                               22,\n                               0.455,\n                               3,\n                               7,\n                               0.429,\n                               4,\n                               8,\n                               0.5,\n                               3,\n                               5,\n                               8,\n                               5,\n                               0,\n                               1,\n                               3,\n                               2,\n                               27,\n                               -13,\n                               1],\n                              [u'22013',\n                               2544,\n                               u'0021301180',\n                               u'APR 11, 2014',\n                               u'MIA vs. IND',\n                               u'W',\n                               35,\n                               11,\n                               20,\n                               0.55,\n                               2,\n                               4,\n                               0.5,\n                               12,\n                               13,\n                               0.923,\n                               1,\n                               5,\n                               6,\n                               1,\n                               1,\n                               1,\n                               2,\n                               1,\n                               36,\n                               13,\n                               1],\n                              [u'22013',\n                               2544,\n                               u'0021301167',\n                               u'APR 09, 2014',\n                               u'MIA @ MEM',\n                               u'L',\n                               41,\n                               14,\n                               23,\n                               0.609,\n                               3,\n                               5,\n                               0.6,\n                               6,\n                               7,\n                               0.857,\n                               1,\n                               5,\n                               6,\n                               5,\n                               2,\n                               0,\n                               5,\n                               1,\n                               37,\n                               -8,\n                               1],\n    ...\n}\n"]], ['Scraping website that uses javascript'], 2, 0], [(26511109, 0), [['-10000'], ['also, you could use a dict comprehension instead:']], [[' res = {}\nt = df - df.shift(1)\nfor col in df.columns:\n    res[col] = t[col][t[col] != 0]\n']], ['Filtering for row-wise patterns in columns with a sequence of 0 and 1'], 2, 1], [(26511109, 1), [['also, you could use a dict comprehension instead:'], ['-10000']], [[' res = {col: t[col][t[col] != 0] for col in df.columns}\n']], ['Filtering for row-wise patterns in columns with a sequence of 0 and 1'], 2, 1], [(26552266, 0), [["Use numpy's  random.permutation  function, which, if given a single scalar argument  x , will return a random permutation of the numbers from 0 to  x . For instance:"], ['Gives:']], [[' np.random.permutation(10)\n']], ['I need to generate x random numbers in an interval from 1 to x but each number have to occur only once'], 2, 1], [(26552266, 1), [['Gives:'], ["So, in particular,  np.random.permutation(70128) + 1  does precisely what you'd like."]], [[' array([3, 2, 8, 7, 0, 9, 6, 4, 5, 1])\n']], ['I need to generate x random numbers in an interval from 1 to x but each number have to occur only once'], 2, 0], [(26562487, 0), [['I modified your code:'], ['Tests:']], [[' def try_parse(string):\n    string2 = ""\n    for c in string:\n        if not c.isdigit() and c != \'.\':\n            break\n        string2 += c\n    return string2\n']], ['saving the number into the variable in every run of cycle python'], 2, 1], [(26562487, 1), [['Tests:'], ['Note']], [[" >>> try_parse('123')\n'123'\n>>> try_parse('12n3')\n'12'\n>>> try_parse('')\n''\n>>> try_parse('4.13n3')\n'4.13'\n"]], ['saving the number into the variable in every run of cycle python'], 2, 0], [(26563683, 0), [['You can create a new function that wraps the closure function.'], ['Then call it like this:']], [[' def make_subtract(fn, val):\n    def wrapper(x):\n        return fn(x) - val\n    return wrapper\n']], ['Adding a constant to a closure expression'], 2, 1], [(26563683, 1), [['Then call it like this:'], ['-10000']], [[' new_a = make_subtract(a, a(100))\n']], ['Adding a constant to a closure expression'], 2, 0], [(26613341, 0), [['If you want to use the variable once you can do this.'], ['If you want to be able to change the variable later.  You can create a  property \nOr simply do this:']], [[' # part2.py\n\ndef scream():\n print(sound)  \n\n# part1.py\nimport part2\n\nif __name__=="__main__":\n    part2.sound = "Yoooo"\n    part2.scream()\n\n#Output:\nYoooo\n']], ['Python 3.x.x one variable spread across multiple .py files'], 2, 1], [(26613341, 1), [['If you want to be able to change the variable later.  You can create a  property \nOr simply do this:'], ['-10000']], [[' # part2.py\n# gvars is defined later\ndef scream():\n print(gvars.sound)\n\n\n# part1.py\nimport part2\n\nclass GameVariables:\n    pass\n\nif __name__=="__main__":\n    gvars = GameVariables()\n    part2.gvars = gvars\n    gvars.sound = "Yooo"\n    part2.scream()\n    gvars.sound = "Whaa"\n    part2.scream()\n\n#output\nYooo\nWhaa\n']], ['Python 3.x.x one variable spread across multiple .py files'], 2, 1], [(26629789, 0), [['Using a list comprehension with a nested loop:'], ['If you like  itertools , you can use  itertools.chain.from_iterable()  to make this into a lazy iterable:']], [[' unrolled = [c for c, count in weighted for _ in range(count)]\n']], ['Creating multiple copies of list elements'], 3, 1], [(26629789, 2), [['Demo:'], ['I used  list()  to turn the  chain  iterator back into a sequence.']], [[' >>> weighted = [ ("a", 3), ("b", 1), ("c", 4) ]\n>>> [c for c, count in weighted for _ in range(count)]\n[\'a\', \'a\', \'a\', \'b\', \'c\', \'c\', \'c\', \'c\']\n>>> from itertools import chain\n>>> list(chain.from_iterable([c] * count for c, count in weighted))\n[\'a\', \'a\', \'a\', \'b\', \'c\', \'c\', \'c\', \'c\']\n']], ['Creating multiple copies of list elements'], 3, 1], [(26644002, 2), [['if you have multiple colums, and you want to have a list out of the following colums to that keyvalue:'], ['-10000']], [["  edges = open('romEdges.txt')\n dict = {line[:1]:line[1:].split() for line in edges}\n print dict\n edges.close()\n"]], ['How to create a dictionary with columns given as keys and values'], 3, 1], [(26666329, 0), [['So for your number this would look like this:'], ['Edit: If you need too remove the  0b  part, you can use this code:']], [[" bin(260768607) # Result: '0b1111100010110000001101011111'\n"]], ['Convert a hashcode to its binary representation'], 2, 1], [(26683175, 1), [['You can use it like this:'], ['The output:']], [[' code = \'\'\'line 1\n    __LINE TO CHANGE__\nline 3\'\'\'\n\nprint(\'\\n\'.join(replace_line(\n    code.split(\'\\n\'),                           # one string per line\n    \'__LINE TO CHANGE__\',                       # the string to replace\n    ["added code line a", "added code line b"]  # the strings to replace with\n)))\n']], ['How can I keep the indentation between lines?'], 4, 0], [(26683175, 2), [['The output:'], ['You can also use this with a file, by doing something like:']], [[' line 1\n    added code line a\n    added code line b\nline 3\n']], ['How can I keep the indentation between lines?'], 4, 0], [(26683175, 3), [['You can also use this with a file, by doing something like:'], ["Note that here I've added a  '\\n'  to the ends of the pattern and replacements. If you intend on using this with the output of  readlines  (which includes a  \\n  at the end of each line) then you may want to adjust the function to expect them and do this for you."]], [[' with open("input") as f:\n    print(\'\'.join(replace_line(f, \'some pattern\\n\', [\'foo\\n\', \'bar\\n\'])))\n']], ['How can I keep the indentation between lines?'], 4, 0], [(26694500, 1), [['Or if you were to use XML, you could save your document something like this:'], ['And you could use xml.etree.ElementTree to walk through the nodes and pick out each piece of information you needed.']], [[' <users>\n    <user name="yrName" highscore="yrScore" averagescore="yrAverage" \n          attempt1="1" attempt2="2" attempt3="3">       \n    </user>\n    <user>\n        ...\n</users>\n']], ['How to convert text from a file into a list in Python?'], 2, 0], [(26700006, 0), [["You'd use a queue to track nodes still to process, adding to it as you process them:"], ['or you could use a stack, processing children first:']], [[' def print_nonrec_breathfirst(node):\n    queue = [node]\n    while queue:\n        node, queue = queue[0], queue[1:]\n        print node\n        for c in node.children:\n            queue.append(c)\n']], ['Print tree without recursion'], 3, 1], [(26700006, 1), [['or you could use a stack, processing children first:'], ['Demo:']], [[' def print_nonrec_depthfirst(node):\n    stack = [node]\n    while stack:\n        node = stack.pop()\n        print node\n        for c in node.children:\n            stack.append(c)\n']], ['Print tree without recursion'], 3, 1], [(26700006, 2), [['Demo:'], ['-10000']], [[' >>> print_nonrec_breathfirst(n1)\n1\n2\n3\n4\n5\n6\n7\n>>> print_nonrec_depthfirst(n1)\n1\n4\n3\n6\n7\n5\n2\n']], ['Print tree without recursion'], 3, 0], [(26705235, 1), [['Output: '], ['-10000']], [[' 4->1->12->10\n1->4->10->12\n']], ['How do I implement SelectionSort and InsertionSort on a linked list in Python?'], 2, 0], [(26716576, 1), [['When you need this in your templates, just enclose it in double brackets:'], ['-10000']], [[' {{ photo.category_image }}\n']], ['Auto Incrementing natural keys with django / postgres'], 2, 0], [(26725669, 1), [['When you do  raw_list = c._meta.get_fields_with_model()  raw_list contains something like:'], ['To get a "parsed" list that only contains the name of the datatype we can do:']], [[' ((<django.db.models.fields.AutoField: id>, None), (<django.db.models.fields.TextField: signature>, None) etc...\n']], ['How to get a list of datatypes on Django model?'], 6, 0], [(26725669, 4), [["In both ways you'll get a list like :"], ['Just the code:']], [[" ['AutoField', 'TextField', 'TextField', 'FloatField', 'CharField', 'BooleanField', 'IntegerField', 'ImageField', 'BooleanField'...\n"]], ['How to get a list of datatypes on Django model?'], 6, 0], [(26742987, 0), [['Python has dictionary literals, which are both faster and much nicer to read than constructing it by setting keys individually.'], ['The only reason you would want to recreate the dictionary each time would be if you intend to mutate the dictionary each time you use it, without that affecting future uses. It sounds like your use case, however, just requires you access the dictionary in other functions.']], [[" def dict_function(self):\n    return {\n        'sky': 'blue'\n        'clouds': 'white'\n        'grass': 'green'\n    }\n"]], ['Calling/Passing dictionary objects in python'], 2, 0], [(26787410, 0), [['-10000'], ['For example removing a line from a txt file that starts with 55:']], [[' with open(your_f) as f:\n    lines = f.readlines()\n    for ind, line in enumerate(lines): \n        if your condition: # if line contains a match \n            lines[ind] ="" # set line to empty string\n    with open(your_f,"w") as f: # reopen with w to overwrite\n        f.writelines(lines) # write updated lines\n']], ['to delete records from a file in python'], 4, 1], [(26787410, 1), [['For example removing a line from a txt file that starts with 55:'], ['input:']], [[' with open("in.txt") as f:\n    lines = f.readlines()\n    for ind, line in enumerate(lines):\n        if line.startswith("55"):\n            lines[ind] = ""\n    with open("in.txt","w") as f:\n        f.writelines(lines)\n']], ['to delete records from a file in python'], 4, 1], [(26787410, 2), [['input:'], ['output:']], [[' foo\nbar\n55 foobar\n44 foo\n']], ['to delete records from a file in python'], 4, 0], [(26787410, 3), [['output:'], ['-10000']], [[' foo\nbar\n44 foo\n']], ['to delete records from a file in python'], 4, 0], [(26812595, 0), [['if you want to use join:'], ['but much easier would be:']], [[" print '\\n'.join( ''.join('#' for column in range(10)) for row in range(10))\n"]], ['How can I properly join these strings together (by column then row)?'], 2, 1], [(26812595, 1), [['but much easier would be:'], ['-10000']], [[" print ('#'*10 + '\\n')*10\n"]], ['How can I properly join these strings together (by column then row)?'], 2, 1], [(26826838, 0), [['-10000'], ['Solution for your updated problem:']], [[" >>> data = [['Country', 'Destination', 'Country Code', 'Destination Code', 'Remarks'],\n... ['AAA', 'Some Mobile', '111', '12, 23, 34, 46','Some remarks'],\n... ['AAA', 'Some city A', '111', '55, 56, 57, 51', 'Some more remarks'],\n... ['BBB', 'Some city B', '222', '234, 345, 456', 'Other remarks']]\n>>> \n>>> op=[data[0]]\n>>> for i in data[1:]:\n...    for j in i.pop(3).split(','):\n...       op.append([k+j.strip() if i.index(k)==2 else k for k in i])\n... \n\n>>> for i in op:\n...    print i\n... \n['Country', 'Destination', 'Country Code', 'Destination Code', 'Remarks']\n['AAA', 'Some Mobile', '11112', 'Some remarks']\n['AAA', 'Some Mobile', '11123', 'Some remarks']\n['AAA', 'Some Mobile', '11134', 'Some remarks']\n['AAA', 'Some Mobile', '11146', 'Some remarks']\n['AAA', 'Some city A', '11155', 'Some more remarks']\n['AAA', 'Some city A', '11156', 'Some more remarks']\n['AAA', 'Some city A', '11157', 'Some more remarks']\n['AAA', 'Some city A', '11151', 'Some more remarks']\n['BBB', 'Some city B', '222234', 'Other remarks']\n['BBB', 'Some city B', '222345', 'Other remarks']\n['BBB', 'Some city B', '222456', 'Other remarks']\n"]], ['How to match phone number prefixes?'], 2, 1], [(26826838, 1), [['Solution for your updated problem:'], ['-10000']], [[" >>> data = [['Country', 'Destination', 'Country Code', 'Destination Code', 'Remarks'],\n...  ['AAA', 'Some Mobile', '111', '12, 23, 34, 46','Some remarks'],\n...  ['AAA', 'Some city A', '111', '55, 56, 57, 51', 'Some more remarks'],\n...  ['BBB', 'Some city B', '222', '234, 345, 456', 'Other remarks']]\n>>>  \n>>> op=[data[0]]\n>>> for i in data[1:]:\n...    for id,j in enumerate(i.pop(3).split(',')):\n...       k=i[:]\n...       k.insert(3,i[2]+j.strip())\n...       op.append(k)\n... \n>>> for i in op:\n...    print i\n... \n['Country', 'Destination', 'Country Code', 'Destination Code', 'Remarks']\n['AAA', 'Some Mobile', '111', '11112', 'Some remarks']\n['AAA', 'Some Mobile', '111', '11123', 'Some remarks']\n['AAA', 'Some Mobile', '111', '11134', 'Some remarks']\n['AAA', 'Some Mobile', '111', '11146', 'Some remarks']\n['AAA', 'Some city A', '111', '11155', 'Some more remarks']\n['AAA', 'Some city A', '111', '11156', 'Some more remarks']\n['AAA', 'Some city A', '111', '11157', 'Some more remarks']\n['AAA', 'Some city A', '111', '11151', 'Some more remarks']\n['BBB', 'Some city B', '222', '222234', 'Other remarks']\n['BBB', 'Some city B', '222', '222345', 'Other remarks']\n['BBB', 'Some city B', '222', '222456', 'Other remarks']\n"]], ['How to match phone number prefixes?'], 2, 1], [(26830752, 0), [['One way would be to create a column of boolean values like this:'], ["You can then change the boolean values to 'pass' or 'fail' using  replace :"]], [[" >>> df['filter'] = (df['a'] >= 20) & (df['b'] >= 20)\n    a   b   c filter\n0   1  50   1  False\n1  10  60  30  False\n2  20  55   1   True\n3   3   0   0  False\n4  10   0   0  False\n"]], ['Making new column in pandas DataFrame based on filter'], 4, 0], [(26830752, 1), [["You can then change the boolean values to 'pass' or 'fail' using  replace :"], ['-10000']], [[" >>> df['filter'].astype(object).replace({False: 'fail', True: 'pass'})\n0    fail\n1    fail\n2    pass\n3    fail\n4    fail\n"]], ['Making new column in pandas DataFrame based on filter'], 4, 0], [(26830752, 2), [['-10000'], ['Using  all  across axis 1 of this DataFrame creates the new column:']], [[" >>> cols = ['a', 'b', 'c'] # a list of columns to test\n>>> df[cols] > 0 \n      a      b      c\n0  True   True   True\n1  True   True   True\n2  True   True   True\n3  True  False  False\n4  True  False  False\n"]], ['Making new column in pandas DataFrame based on filter'], 4, 0], [(26830752, 3), [['Using  all  across axis 1 of this DataFrame creates the new column:'], ['-10000']], [[' >>> (df[cols] > 0).all(axis=1)\n0     True\n1     True\n2     True\n3    False\n4    False\ndtype: bool\n']], ['Making new column in pandas DataFrame based on filter'], 4, 0], [(26856378, 1), [['Writing a value is as follows:'], ['Using the value:']], [[' def process():\n    # Do the measurement\n    # Do the calculation\n    Buffer.onNewReading(data1, data2, etc)\n']], ['Python thread-safe access without blocking or uncontrolled queue growth?'], 3, 0], [(26856378, 2), [['Using the value:'], ['-10000']], [[" def handleRequest():\n    results = Buffer.onUserRequest()\n    # Format a response, using the results\n    if not results:\n        return 'No data available'  # or any other useful error message\n    return response(results[0][0], results[0][1])\n"]], ['Python thread-safe access without blocking or uncontrolled queue growth?'], 3, 0], [(26871083, 0), [['If we form the reshaped matrix  y = x.reshape(2,2,3,2) , then the (i,j) 2x2 submatrix is given by  y[i,:,j,:] .  E.g.:'], ['To get the mean of the 2x2 submatrices, use the  mean  method, with  axis=(1,3) :']], [[' In [340]: x\nOut[340]: \narray([[  0.,   1.,   2.,   3.,   4.,   5.],\n       [  6.,   7.,   8.,   9.,  10.,  11.],\n       [ 12.,  13.,  14.,  15.,  16.,  17.],\n       [ 18.,  19.,  20.,  21.,  22.,  23.]])\n\nIn [341]: y = x.reshape(2,2,3,2)\n\nIn [342]: y[0,:,0,:]\nOut[342]: \narray([[ 0.,  1.],\n       [ 6.,  7.]])\n\nIn [343]: y[1,:,2,:]\nOut[343]: \narray([[ 16.,  17.],\n       [ 22.,  23.]])\n']], ['How can I vectorize the averaging of 2x2 sub-arrays of numpy array?'], 8, 0], [(26871083, 1), [['To get the mean of the 2x2 submatrices, use the  mean  method, with  axis=(1,3) :'], ["If you are using an older version of numpy that doesn't support using a tuple for the axis, you could do:"]], [[' In [344]: y.mean(axis=(1,3))\nOut[344]: \narray([[  3.5,   5.5,   7.5],\n       [ 15.5,  17.5,  19.5]])\n']], ['How can I vectorize the averaging of 2x2 sub-arrays of numpy array?'], 8, 0], [(26871083, 2), [["If you are using an older version of numpy that doesn't support using a tuple for the axis, you could do:"], ['To generalize this to a 2-d array with shape (m, n), where m and n are even, use']], [[' In [345]: y.mean(axis=1).mean(axis=-1)\nOut[345]: \narray([[  3.5,   5.5,   7.5],\n       [ 15.5,  17.5,  19.5]])\n']], ['How can I vectorize the averaging of 2x2 sub-arrays of numpy array?'], 8, 0], [(26871083, 3), [['To generalize this to a 2-d array with shape (m, n), where m and n are even, use'], ['To compute the reduced array of averages of these blocks, use the  mean  method, with  axis=(1, 3)  (i.e. average over axes 1 and 3):']], [[' y = x.reshape(x.shape[0]/2, 2, x.shape[1], 2)\n']], ['How can I vectorize the averaging of 2x2 sub-arrays of numpy array?'], 8, 0], [(26871083, 4), [['To compute the reduced array of averages of these blocks, use the  mean  method, with  axis=(1, 3)  (i.e. average over axes 1 and 3):'], ["Here's an example where  x  has shape (8, 10), so the array of averages of the 2x2 blocks has shape (4, 5):"]], [[' avg = y.mean(axis=(1, 3))\n']], ['How can I vectorize the averaging of 2x2 sub-arrays of numpy array?'], 8, 0], [(26871083, 5), [["Here's an example where  x  has shape (8, 10), so the array of averages of the 2x2 blocks has shape (4, 5):"], ['Take a look at a couple of the 2x2 blocks:    ']], [[' In [10]: np.random.seed(123)\n\nIn [11]: x = np.random.randint(0, 4, size=(8, 10))\n\nIn [12]: x\nOut[12]: \narray([[2, 1, 2, 2, 0, 2, 2, 1, 3, 2],\n       [3, 1, 2, 1, 0, 1, 2, 3, 1, 0],\n       [2, 0, 3, 1, 3, 2, 1, 0, 0, 0],\n       [0, 1, 3, 3, 2, 0, 3, 2, 0, 3],\n       [0, 1, 0, 3, 1, 3, 0, 0, 0, 2],\n       [1, 1, 2, 2, 3, 2, 1, 0, 0, 3],\n       [2, 1, 0, 3, 2, 2, 2, 2, 1, 2],\n       [0, 3, 3, 3, 1, 0, 2, 0, 2, 1]])\n\nIn [13]: y = x.reshape(x.shape[0]/2, 2, x.shape[1]/2, 2)\n']], ['How can I vectorize the averaging of 2x2 sub-arrays of numpy array?'], 8, 0], [(26871083, 6), [['Take a look at a couple of the 2x2 blocks:    '], ['Compute the averages of the blocks:']], [[' In [14]: y[0, :, 0, :]\nOut[14]: \narray([[2, 1],\n       [3, 1]])\n\nIn [15]: y[1, :, 2, :]\nOut[15]: \narray([[3, 2],\n       [2, 0]])\n']], ['How can I vectorize the averaging of 2x2 sub-arrays of numpy array?'], 8, 0], [(26871083, 7), [['Compute the averages of the blocks:'], ['-10000']], [[' In [16]: avg = y.mean(axis=(1, 3))\n\nIn [17]: avg\nOut[17]: \narray([[ 1.75,  1.75,  0.75,  2.  ,  1.5 ],\n       [ 0.75,  2.5 ,  1.75,  1.5 ,  0.75],\n       [ 0.75,  1.75,  2.25,  0.25,  1.25],\n       [ 1.5 ,  2.25,  1.25,  1.5 ,  1.5 ]])\n']], ['How can I vectorize the averaging of 2x2 sub-arrays of numpy array?'], 8, 0], [(26889734, 0), [['Getting:'], ['Setting:']], [[' >>> a = np.arange(25).reshape((5,5))\n>>> a\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24]])\n>>> rows = b = np.array([0,4,2,3,3])\n>>> cols = np.arange(len(b))\n>>> [a[b[i], i] for i in range(5)]\n[0, 21, 12, 18, 19]\n>>> a[rows, cols]\narray([ 0, 21, 12, 18, 19])\n']], ['Using fancy indexing to get one value from each column of a numpy matrix'], 2, 0], [(26889734, 1), [['Setting:'], ['-10000']], [[' >>> a[rows, cols] = 69\n>>> a\narray([[69,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 69, 13, 14],\n       [15, 16, 17, 69, 69],\n       [20, 69, 22, 23, 24]])\n>>> a[rows, cols] = np.array([-111, -111, -222, -333, -666])\n>>> a\narray([[-111,    1,    2,    3,    4],\n       [   5,    6,    7,    8,    9],\n       [  10,   11, -222,   13,   14],\n       [  15,   16,   17, -333, -666],\n       [  20, -111,   22,   23,   24]])\n']], ['Using fancy indexing to get one value from each column of a numpy matrix'], 2, 0], [(26897708, 0), [['If you have a list  lst , then you can simply do:'], ['to get a random entry of the list. So here, you will want something like:']], [[' random_word = random.choice(lst)\n']], ['Selecting a random value from a dictionary in python'], 2, 1], [(26911426, 0), [['This should work'], ['Another method, that might be more readable (i.e. generate a set of consecutive weeks and check against the observed week)']], [[" df.groupby(['Country', 'Product']).apply(lambda sdf: sdf[(sdf.Week.diff(1).fillna(1) != 1).astype('int').cumsum() == 0]).reset_index(drop=True)\n"]], ['Python Pandas: Eliminate a row from a dataframe if a value in a any preceding row in a groupby meets a certain criteria'], 2, 1], [(26911426, 1), [['Another method, that might be more readable (i.e. generate a set of consecutive weeks and check against the observed week)'], ['-10000']], [[" df['expected_week'] = df.groupby(['Country', 'Product']).Week.transform(lambda s: range(s.min(), s.min() + s.size))\ndf[df.Week == df.expected_week]\n"]], ['Python Pandas: Eliminate a row from a dataframe if a value in a any preceding row in a groupby meets a certain criteria'], 2, 1], [(26922284, 0), [['I think you want to use  pivot_table :'], ['To get the filled in months, you can reindex (this feels a little hacky, there may be a neater way):']], [[' In [11]: df.pivot_table(values="incoming", index="month", columns="goods", aggfunc="sum")\nOut[11]:\ngoods   a   b   c\nmonth\n1       0  30 NaN\n2      30 NaN  10\n3     NaN  70 NaN\n5     NaN  40  50\n6      20 NaN NaN\n']], ['Filling gaps for cumulative sum with Pandas'], 5, 0], [(26922284, 1), [['To get the filled in months, you can reindex (this feels a little hacky, there may be a neater way):'], ['-10000']], [[' In [12]: res.reindex(np.arange(res.index[0], res.index[-1] + 1))\nOut[12]:\ngoods   a   b   c\n1       0  30 NaN\n2      30 NaN  10\n3     NaN  70 NaN\n4     NaN NaN NaN\n5     NaN  40  50\n6      20 NaN NaN\n']], ['Filling gaps for cumulative sum with Pandas'], 5, 0], [(26922284, 2), [['-10000'], ['and then you can reindex by the period range:']], [[' In [21]: df.pivot_table(values="incoming", index=pd.DatetimeIndex(df.date).to_period("M"), columns="goods", aggfunc="sum")\nOut[21]:\ngoods     a   b   c\n2014-01   0  30 NaN\n2014-02  30 NaN  10\n2014-03 NaN  70 NaN\n2014-05 NaN  40  50\n2014-06  20 NaN NaN\n']], ['Filling gaps for cumulative sum with Pandas'], 5, 0], [(26922284, 3), [['and then you can reindex by the period range:'], ['-10000']], [[' In [22]: res2.reindex(pd.period_range(res2.index[0], res2.index[-1], freq="M"))\nOut[22]:\ngoods     a   b   c\n2014-01   0  30 NaN\n2014-02  30 NaN  10\n2014-03 NaN  70 NaN\n2014-04 NaN NaN NaN\n2014-05 NaN  40  50\n2014-06  20 NaN NaN\n']], ['Filling gaps for cumulative sum with Pandas'], 5, 0], [(26922284, 4), [['-10000'], ['and reindex.']], [[' In [31]: dfg.pivot_table(["incoming", "level"], "month", "goods")\nOut[31]:\n      incoming         level\ngoods        a   b   c     a    b   c\nmonth\n1            0  30 NaN     0   30 NaN\n2           30 NaN  10    30  NaN  10\n3          NaN  70 NaN   NaN  100 NaN\n5          NaN  40  50   NaN  140  60\n6           20 NaN NaN    50  NaN NaN\n']], ['Filling gaps for cumulative sum with Pandas'], 5, 0], [(26934349, 0), [['As mentioned in a comment to my question, the sequence interface won\'t work for sparse  matrices , because they don\'t lose a dimension when indexed with a single number.\nTo try it anyway, I created a very limited quick-and-dirty sparse  array  class in pure Python, which, when indexed with a single number, returns a "row" class (which holds a view to the original data), which again can be indexed with a single number to yield the actual value at this index. Using an instance  s  of my class, assigning to a NumPy array  a  works exactly as requested:'], ['To make the assignment more efficient and still use no temporary copy of the dense array data, NumPy would have to internally do something similar to']], [[' a[:] = s\n']], ['How to assign scipy.sparse matrix to NumPy array via indexing?'], 3, 1], [(26934349, 2), [['However, there is a way to do something very similar, by providing an  __array__()  method that returns a NumPy array. Incidentally, SciPy sparse matrices already have such a method, just with a different name:  toarray() . So I just renamed it:'], ['This works like a charm (also with the other sparse matrix classes) and is totally fast!']], [[' scipy.sparse.dok_matrix.__array__ = scipy.sparse.dok_matrix.toarray\na[:] = s\n']], ['How to assign scipy.sparse matrix to NumPy array via indexing?'], 3, 1], [(26969526, 0), [['To centralise the ticks you need to add 0.5 to each value:'], ['Also, you might want to add the following so that the overall figure size is adjusted to take account of the rotated x labels:']], [[' plt.yticks([0.5,1.5,2.5], ["first", "second", "third"])\nplt.xticks([0.5,1.5,2.5], ["first", "second", "third"], rotation=\'vertical\')\n']], ['Creating a correlation plot with matplotlib'], 2, 0], [(26969526, 1), [['Also, you might want to add the following so that the overall figure size is adjusted to take account of the rotated x labels:'], ['-10000']], [[' plt.tight_layout()\n']], ['Creating a correlation plot with matplotlib'], 2, 0], [(26983187, 0), [['A dict is a map from keys to values. A NumPy array can also act as a map from\nkeys to values. For example, '], ["The dict is more flexible -- it's keys can be any hashable object. The array\nmust be indexed by integers. But the array may be more appropriate in a NumPy\nsetting since the array can itself be indexed by an integer array:"]], [[' In [11]: dct = {3:40, 2:30, 1:20, 0:10}\n\nIn [9]: arr = np.array([10,20,30,40])\n\nIn [12]: arr[3]\nOut[12]: 40\n\nIn [13]: dct[3]\nOut[13]: 40\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 1), [["The dict is more flexible -- it's keys can be any hashable object. The array\nmust be indexed by integers. But the array may be more appropriate in a NumPy\nsetting since the array can itself be indexed by an integer array:"], ['whereas the equivalent using a dict requires a loop:']], [[' In [8]: index = np.array([3,2,1,0])\n\nIn [10]: arr[index]\nOut[10]: array([40, 30, 20, 10])\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 2), [['whereas the equivalent using a dict requires a loop:'], ['Integer indexing is much faster than dict lookups in a loop:']], [[' In [17]: [dct[i] for i in index]\nOut[17]: [40, 30, 20, 10]\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 3), [['Integer indexing is much faster than dict lookups in a loop:'], ['Suppose you have this setup:']], [[' In [19]: %timeit arr[index]\n1000000 loops, best of 3: 201 ns per loop\n\nIn [20]: %timeit [dct[i] for i in index]\n1000000 loops, best of 3: 1.63 µs per loop\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 4), [['Suppose you have this setup:'], ['Then:']], [[" import numpy as np\n\ncolor = np.array([\n    [  0,   0,   0],\n    [128,   0, 128],\n    [  0, 128, 128],\n    [  0,   0, 128],\n    [  0, 128,   0],\n    [128, 128,   0],\n    [128, 128, 128],\n    [128,   0,   0],], dtype='uint8').reshape(-1,2,3)\n\ncolor2ind = {(128, 128, 128): 6, \n             (0, 128, 128): 2, \n             (128, 0, 128): 1, \n             (128, 0, 0): 7, \n             (128, 128, 0): 5, \n             (0, 0, 128): 3, \n             (0, 128, 0): 4, \n             (0, 0, 0): 0}\n"]], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 6), [['yields'], ['Here is a benchmark showing rgb2vals, which uses NumPy indexing, is much faster\nthan using a double for-loop:']], [[' [[0 1]\n [2 3]\n [4 5]\n [6 7]]\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 7), [['Here is a benchmark showing rgb2vals, which uses NumPy indexing, is much faster\nthan using a double for-loop:'], ['-10000']], [[' def using_loops(color, color2ind):\n    M, N = color.shape[:2]\n    out = np.zeros((M, N))\n    for i in range(M):\n        for j in range(N):\n            out[i][j] = color2ind[tuple(color[i,j,:])]\n    return out\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 8), [['-10000'], ['-10000']], [[' In [295]: color = np.tile(color, (100,100,1))\n\nIn [296]: (rgb2vals(color, color2ind) == using_loops(color, color2ind)).all()\nOut[296]: True\n\nIn [297]: %timeit rgb2vals(color, color2ind)\n100 loops, best of 3: 6.74 ms per loop\n\nIn [298]: %timeit using_loops(color, color2ind)\n1 loops, best of 3: 751 ms per loop\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 9), [['-10000'], ['Now we do the same for the (r,g,b) triplet keys in the  color2ind  dict:']], [[' In [270]: int_colors = rgb2int(color)\nIn [270]: int_colors\nOut[270]: \narray([[      0, 8388736],\n       [  32896,     128],\n       [  32768, 8421376],\n       [8421504, 8388608]], dtype=uint32)\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 10), [['Now we do the same for the (r,g,b) triplet keys in the  color2ind  dict:'], ['Concatenate these two arrays and then use  np.unique  to find the inverse index:']], [[" In [271]: int_keys = rgb2int(np.array(color2ind.keys(), dtype='uint8'))\nIn [271]: int_keys\nOut[271]: \narray([8388608, 8421504, 8388736, 8421376,     128,       0,   32768,\n         32896], dtype=uint32)\n"]], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 11), [['Concatenate these two arrays and then use  np.unique  to find the inverse index:'], ['uniq  holds the unique values in  int_colors  and  int_keys .\n index  holds the index values such that  uniq[index] = int_array :']], [[' In [283]: int_array = np.r_[int_colors.ravel(), int_keys]\n\nIn [284]: uniq, index = np.unique(int_array, return_inverse=True)\n\nIn [285]: index\nOut[285]: array([0, 5, 3, 1, 2, 6, 7, 4, 4, 7, 5, 6, 1, 0, 2, 3])\n\nIn [286]: uniq\nOut[286]: \narray([      0,     128,   32768,   32896, 8388608, 8388736, 8421376,\n       8421504], dtype=uint32)\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 12), [['uniq  holds the unique values in  int_colors  and  int_keys .\n index  holds the index values such that  uniq[index] = int_array :'], ['Once we have  index  we are golden. The values in  index  are like labels, each label is associated to a particular color. The first  color.size  items in  index  are labels for the colors in  color , the last  len(color2ind)  items in  index  are the labels for the keys in  color2ind .']], [[' In [265]: (uniq[index] == int_array).all()\nOut[265]: True\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 13), [['Once we have  index  we are golden. The values in  index  are like labels, each label is associated to a particular color. The first  color.size  items in  index  are labels for the colors in  color , the last  len(color2ind)  items in  index  are the labels for the keys in  color2ind .'], ['Now all we need is to make an array,  colormap  with the values in  color2ind.values() , such that  the key labels map to the values:']], [[' color_labels = index[:int_colors.size]\nkey_labels = index[-len(color2ind):]\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 14), [['Now all we need is to make an array,  colormap  with the values in  color2ind.values() , such that  the key labels map to the values:'], ['By placing the values in  color2ind  at the index positions equal to the\nassociated key labels, we create a colormap array which is can in effect act\nlike a dict.  colormap[color_labels]  maps the color labels to  color2ind  values, which is exactly what we want:']], [[' colormap[key_labels] = color2ind.values()\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(26983187, 15), [['By placing the values in  color2ind  at the index positions equal to the\nassociated key labels, we create a colormap array which is can in effect act\nlike a dict.  colormap[color_labels]  maps the color labels to  color2ind  values, which is exactly what we want:'], ['-10000']], [[' out = colormap[color_labels].reshape(color.shape[:2])\n\nIn [267]: out\nOut[267]: \narray([[7, 6],\n       [1, 5],\n       [3, 0],\n       [4, 2]], dtype=uint32)\n']], ['Convert a 3D array to 2D array based on dictionary'], 16, 0], [(27007260, 0), [['Definitely not my prettiest piece of code. But here it is. Basically, just store all the information in a list of lists, then iterate over it from there.'], ["In an expanded form (or one that doesn't have  reduce  - before someone complains):"]], [[" def sumColumns1(columnfile):\n    import csv\n    with open(columnfile) as csvfile:\n        r = csv.reader(csvfile)\n        names = next(r)\n        Int = lambda x: 0 if x=='' else int(x)\n        sums  = reduce(lambda x,y: [ Int(a)+Int(b) for a,b in zip(x,y) ], r)\n        return dict(zip(names,sums))\n"]], ['python 3: Adding .csv column sums in to dictionaries with header keys'], 2, 1], [(27007260, 1), [["In an expanded form (or one that doesn't have  reduce  - before someone complains):"], ['Gives me the correct output. Hopefully someone comes up with something more pythonic.']], [[" def sumColumns1(columnfile):\n    import csv\n    with open(columnfile) as csvfile:\n        r = csv.reader(csvfile)\n        names = next(r)\n        sums = [ 0 for _ in names ]\n        for line in r:\n            for i in range(len(sums)):\n                sums[i] += int(0 if line[i]=='' else line[i])\n        return dict(zip(names,sums))\n"]], ['python 3: Adding .csv column sums in to dictionaries with header keys'], 2, 1], [(27024392, 0), [['Try escaping your outermost parentheses pair.'], ['This appears to make it match properly, at least for my little sample input:']], [[" navigated_pages = re.findall(r'EVENT\\(X(.*?)\\) ',data,re.DOTALL|re.MULTILINE)\n"]], ['Getting strings in between two keywords from a file in python'], 3, 1], [(27024392, 1), [['This appears to make it match properly, at least for my little sample input:'], ["If you want the starting X too, you should nudge the inner parentheses to the left by one. Don't worry, I'm pretty sure the  *?  will still have the proper precedence."]], [[' >>> s = "EVENT(X_HELLO) ... EVENT(X_HOW_ARE_YOU_DOING_TODAY)... EVENT(this one shouldn\'t appear because it doesn\'t start with X)"\n>>> re.findall(r"EVENT\\(X(.*?)\\)", s)\n[\'_HELLO\', \'_HOW_ARE_YOU_DOING_TODAY\']\n']], ['Getting strings in between two keywords from a file in python'], 3, 1], [(27027500, 1), [['For a nice looking plot, you have to take into account that  X  is associated with frequencies  0*dw, 1*dw, ..., (N-1)*dw  and that, in a nice looking plot, you usually want to use a range  -N*dw/2 ,  +N*dw/2  for your abscissas.'], ['as you can see, this type of plot kind of stresses the periodicity of the DFT, but it is customary to plot the DFT centered around the zero frequency, and this can be done like this']], [["Complete answer import matplotlib.pyplot as plt\nimport numpy as np\nnp.random.seed(57)\n\nN = 64 ; dw = 0.2\nw = np.linspace(0,N*dw-dw,N)\nX = 200 + (np.arange(N)-N/2)**2*np.random.random(N)\n\nplt.bar(w, abs(X), align='center', width=dw)\nplt.xticks([i*8*dw for i in range(N/8)]+[N*dw-dw/2])\nplt.xlim(-dw/2,N*dw-dw/2)\nplt.show()\n"]], ['How do I plot a histogram using Python so that x-values are frequencies of a spectra?'], 3, 1], [(27027500, 2), [['as you can see, this type of plot kind of stresses the periodicity of the DFT, but it is customary to plot the DFT centered around the zero frequency, and this can be done like this'], ['and this is the result\n']], [[" w2=np.concatenate((w-N*dw,w))\nX2=np.concatenate((X,X)\n\nplt.bar(w2, abs(X2), align='center', width=dw)\nplt.xticks([i*8*dw for i in range(-N/16,1+N/16)])\nplt.xlim(-dw*N/2,dw*N/2)\nplt.show()\n"]], ['How do I plot a histogram using Python so that x-values are frequencies of a spectra?'], 3, 1], [(27031053, 0), [['demo:'], ['demo with  IT :']], [[" >>> [ str(x).zfill(5) for x in range(10) ]\n['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009']\n"]], ['How do you create a list of values in Python within a certain range?'], 3, 1], [(27031053, 1), [['demo with  IT :'], ['you can also use  format :']], [[" >>>[ 'IT'+str(x).zfill(5) for x in range(10) ]\n['IT00000', 'IT00001', 'IT00002', 'IT00003', 'IT00004', 'IT00005', 'IT00006', 'IT00007', 'IT00008', 'IT00009']\n"]], ['How do you create a list of values in Python within a certain range?'], 3, 1], [(27031053, 2), [['you can also use  format :'], ['-10000']], [[" >>> [ '{}{:05d}'.format('IT',x) for x in range(10) ]\n['IT00000', 'IT00001', 'IT00002', 'IT00003', 'IT00004', 'IT00005', 'IT00006', 'IT00007', 'IT00008', 'IT00009']\n"]], ['How do you create a list of values in Python within a certain range?'], 3, 1], [(27032670, 0), [['-10000'], ["if you didn't understand about map how it working:"]], [[' value = [ ",".join(map(str,i)) for i in value ]\n']], ['Best way to convert value in nested list to string'], 2, 1], [(27032670, 1), [["if you didn't understand about map how it working:"], ['-10000']], [[' value = [ ",".join(str(x) for x in i) for i in value ]\n']], ['Best way to convert value in nested list to string'], 2, 1], [(27054358, 0), [['-10000'], ['i have used split to split it  then strip to remove extra spaces. I have use set to remove duplication, but set dosent care about order. so i need to sort in the order as they are ']], [[' >>> a = "15-105;ZH0311;TZZGJJ; ZH0311; ZH0311;DOC"\n>>> a = map(str.strip,a.split(\';\'))\n>>> a\n[\'15-105\', \'ZH0311\', \'TZZGJJ\', \'ZH0311\', \'ZH0311\', \'DOC\']\n>>> a = sorted(set(a),key=lambda x:a.index(x))\n>>> a\n[\'15-105\', \'ZH0311\', \'TZZGJJ\', \'DOC\']\n>>> ";".join(a)\n\'15-105;ZH0311;TZZGJJ;DOC\'\n']], ['Remove duplicated string(s) in strings in a list'], 3, 1], [(27054358, 1), [['i have used split to split it  then strip to remove extra spaces. I have use set to remove duplication, but set dosent care about order. so i need to sort in the order as they are '], ['if your string is delimited by space:']], [[' >>> def remove_duplication(my_list):\n...     my_newlist = []\n...     for x in my_list:\n...         x = map(str.strip,x.split(\';\'))\n...         my_newlist.append(";".join(sorted(set(x),key=lambda y:x.index(y))))\n...     return my_newlist\n... \n>>> remove_duplication(a_list)\n[\'15~105;~ PO185-400CT;NGG;DOC\', \'15~105;-1;NGG;DOC\', \'15~105;NGG;-10;DOC\', \'15~55;J205~J208;POI;DOC\', \'15-105;ZH0305~;WER /;TZZGJJ;DOC\', \'15-105;ZH0311;TZZGJJ;DOC\', \'15-115;PL026~ PL028;Dry;PTT\']\n']], ['Remove duplicated string(s) in strings in a list'], 3, 1], [(27054358, 2), [['if your string is delimited by space:'], ['split  split the string on some delimiter, it may be space punchuatation or character or can be anything.']], [[' >>> a="# -- coding: utf-8 --" \n>>> a= map(str.strip,a.split())\n>>> a\n[\'#\', \'--\', \'coding:\', \'utf-8\', \'--\']\n>>> a = " ".join(sorted(set(a),key=lambda x:a.index(x)))\n>>> a\n\'# -- coding: utf-8\'\n']], ['Remove duplicated string(s) in strings in a list'], 3, 1], [(27064243, 0), [['Perhaps you need to extract the data from all cells and only skip rows without  <td>  cells here:'], ['This produces']], [[" for row in soup('table')[5].findAll('tr'):\n    tds = row('td')\n    if not tds:\n        continue\n    print u' '.join([cell.string for cell in tds if cell.string])\n"]], ['Python: Read Content of Hidden HTML Table'], 2, 1], [(27064243, 1), [['This produces'], ['-10000']], [[' United States, California\nVa Long Beach Healthcare System\nLong Beach, California, United States, 90822  \nUnited States, Georgia\nGastrointestinal Specialists Of Georgia Pc\nMarietta, Georgia, United States, 30060  \n# .... \nLocal Institution\nTaipei, Taiwan, 100  \nLocal Institution\nTaoyuan, Taiwan, 333  \nUnited Kingdom\nLocal Institution\nLondon, Greater London, United Kingdom, SE5 9RS  \n']], ['Python: Read Content of Hidden HTML Table'], 2, 0], [(27103165, 1), [['To replace inbetween one or more space characters.'], ['Example:']], [[" re.sub(r'(?<=\\d)\\s+(?=\\d)', r'', string)\n"]], ['Python: How to remove whitespace from number in a string'], 4, 1], [(27103165, 2), [['Example:'], ['Regular Expression:']], [[' >>> import re\n>>> s = "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris 850 152 nisi ut aliquip ex ea commodo consequat. Duis aute irure 360 458 000 dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."\n>>> re.sub(r\'(?<=\\d)\\s(?=\\d)\', r\'\', s)\n\'Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris 850152 nisi ut aliquip ex ea commodo consequat. Duis aute irure 360458000 dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\'\n']], ['Python: How to remove whitespace from number in a string'], 4, 1], [(27103165, 3), [['Regular Expression:'], ['-10000']], [[' (?<=                     look behind to see if there is:\n  \\d                       digits (0-9)\n)                        end of look-behind\n\\s+                      whitespace (\\n, \\r, \\t, \\f, and " ") (1 or\n                         more times)\n(?=                      look ahead to see if there is:\n  \\d                       digits (0-9)\n)                        end of look-ahead\n']], ['Python: How to remove whitespace from number in a string'], 4, 0], [(27112449, 0), [['You can use  chr()  function as:'], ['To convert back use  ord()  funtion as:']], [[" >>> chr(60)\n'<'\n>>> chr(97)\n'a'\n>>> chr(67)\n'C'\n"]], ['how to represent a number value as a string in python?'], 2, 1], [(27112449, 1), [['To convert back use  ord()  funtion as:'], ['-10000']], [[" >>> ord('C')\n67\n"]], ['how to represent a number value as a string in python?'], 2, 0], [(27122584, 0), [['mail/html-message.html'], ['views.py']], [[' Hi {{ first_name }}.\n\n    This is your {{ email }}\n\nThank you\n']], ['Sending email with html in Django 1.7'], 2, 0], [(27127176, 0), [['if your file is like this:'], ['code here:']], [[' 00:47:12: start interaction\n00:47:18: End interaction\n00:47:20: Start interaction\n00:47:23: End interaction\n00:47:25: Start interaction\n00:47:28: End interaction\n00:47:29: Start interaction\n00:47:31: End interaction\n']], ['Subtracting an integer value from a text file and displaying the result in Python2.7'], 3, 0], [(27139744, 0), [['Use the top row to figure out what the column headings are. Initialize a dictionary of totals based on the headings.'], ['Also, let me mention that the data you posted appears to have four columns:']], [[' import csv\n\nwith open("file.csv") as f:\n  reader = csv.reader(f)\n\n  titles = next(reader)\n  while titles[-1] == \'\':\n    titles.pop()\n  num_titles = len(titles)      \n  totals = { title: 0 for title in titles }\n\n  for row in reader:\n    for i in range(num_titles):\n      totals[titles[i]] += int(row[i])\n\nprint(totals)\n']], ['Python: Effective reading from a file using csv module'], 3, 1], [(27139744, 1), [['Also, let me mention that the data you posted appears to have four columns:'], ["That's why I did this:"]], [[' John,Jeff,Judy,\n21,19,32,\n178,182,169,\n85,74,57,\n']], ['Python: Effective reading from a file using csv module'], 3, 0], [(27139744, 2), [["That's why I did this:"], ['-10000']], [["   while titles[-1] == '':\n    titles.pop()\n"]], ['Python: Effective reading from a file using csv module'], 3, 0], [(27150664, 0), [['You can use  ast.literal_eval  with some  str.replace  calls:'], ['As @Martijn Pieters suggested you can replace the two  str.replace  calls with a single  str.translate  call:']], [[" >>> from ast import literal_eval\n>>> s = '1,2,{3,4,5},6'\n>>> [x if isinstance(x, tuple) else (x,) for x \n                         in literal_eval(s.replace('{', '(').replace('}', ')'))]\n[(1,), (2,), (3, 4, 5), (6,)]\n"]], ['Pythonic way to parse preflib Orders with Ties files'], 3, 1], [(27150664, 1), [['As @Martijn Pieters suggested you can replace the two  str.replace  calls with a single  str.translate  call:'], ["In Python 3 you won't need any  str.replace  or  str.translate  calls calls, it fails in Python 2.7 and here is the  related bug :"]], [[" >>> from string import maketrans\n>>> table = maketrans('{}', '()')\n>>> [x if isinstance(x, tuple) else (x,) for x in literal_eval(s.translate(table))]\n[(1,), (2,), (3, 4, 5), (6,)]\n"]], ['Pythonic way to parse preflib Orders with Ties files'], 3, 1], [(27159189, 0), [['np.where(pd.isnull(df))  returns the row and column indices where the value is NaN:'], ['Finding values which are empty strings could be done with applymap:']], [[' In [152]: import numpy as np\nIn [153]: import pandas as pd\nIn [154]: np.where(pd.isnull(df))\nOut[154]: (array([2, 5, 6, 6, 7, 7]), array([7, 7, 6, 7, 6, 7]))\n\nIn [155]: df.iloc[2,7]\nOut[155]: nan\n\nIn [160]: [df.iloc[i,j] for i,j in zip(*np.where(pd.isnull(df)))]\nOut[160]: [nan, nan, nan, nan, nan, nan]\n']], ['Find empty or NaN entry in Pandas Dataframe'], 2, 1], [(27178829, 0), [["Will  scipy's 1d interpolation  functions work?"], ['Which gives:']], [[' import numpy as np\nfrom scipy.interpolate import interp1d\n\nx = y = np.arange(5)\nf = interp1d(x,y, kind="linear", fill_value=0., bounds_error=False)\n\nprint f(0)\nprint f(2)\nprint f(3)\nprint f(3.4)\n']], ['Convert a python list into function'], 2, 1], [(27178829, 1), [['Which gives:'], ['-10000']], [[' 1.0\n2.0\n3.0\n3.4\n']], ['Convert a python list into function'], 2, 0], [(27193884, 1), [['Demo:'], ['-10000']], [[" >>> from bs4 import BeautifulSoup\n>>> soup = BeautifulSoup('''\\\n... <div>\n...     <h3>First header</h3>\n...     <div>First div to go with a header</div>\n...     <h3>Second header</h3>\n...     <div>Second div to go with a header</div>\n... </div>\n... ''')\n>>> for header in soup.select('div h3'):\n...     next_div = header.find_next_sibling('div')\n...     print(header.text, next_div.text)\n... \nFirst header First div to go with a header\nSecond header Second div to go with a header\n"]], ['how to grab alternating child tags in python beautifulsoup'], 2, 1], [(27216944, 1), [['http://regex101.com/r/hQ9xT1/32'], ['Your regex  \\{(.|\\s)\\}  didnt work coz you had not quantified it.Use  \\{(?:.|\\s)+\\} .']], [[' import re\np = re.compile(ur\'{([^}]+)}\')\ntest_str = u"{\'AuthorSite\': None,\\n \'FirstText\': None,\\n \'Image\': None,\\n \'SrcDate\': None,\\n \'Title\': None,\\n \'Url\': None}"\n\nre.findall(p, test_str)\n']], ['Regular expressions matching across multiple line in Sublime Text'], 2, 1], [(27216950, 0), [['Then you can do:'], ['Which outputs:']], [[' results = {}\nfor key in data.keys():\n    # key is \'20101021\', \'20101004\'...\n    # data[key].keys() is \'4x4, \'4x2\'... so let\'s make sure\n    # that the result dictionary contains all those \'4x4\', \'4x2\'\n    # being zero if nothing better can be calculated.\n    results[key] = dict.fromkeys(data[key].keys(), 0)\n\n    for sub_key in data[key].keys():\n        # sub_key is \'4x4\', \'4x2\'...\n        # Also, don\'t consider a \'valid value\' someting that is not a\n        # "Central Spectrum" or a "Full Frame"\n        valid_values = [\n            int(v) for k, v in data[key][sub_key].items()\n            if k in ["Central Spectrum", "Full Frame"]\n        ]\n        # Now add the \'valid_values\'\n        results[key][sub_key] = sum(valid_values)\nprint results\n']], ['summing nested dictionary entries'], 4, 1], [(27216950, 1), [['Which outputs:'], ['In many cases, I only used  dict.keys()  because maybe that clarifies the process? (well, and once  dict.items() ) You also have  dict.values()  (and all the tree functions have their iterator equivalents) which might shorten your code. Also, see what  dict.fromkeys  does.']], [[" {\n  u'20101021': {u'1x1': 9, u'4x4': 10, u'4x2': 10},\n  u'20101004': {u'1x1': 10, u'4x4': 10, u'4x2': 10}\n}\n"]], ['summing nested dictionary entries'], 4, 0], [(27216950, 2), [['In many cases, I only used  dict.keys()  because maybe that clarifies the process? (well, and once  dict.items() ) You also have  dict.values()  (and all the tree functions have their iterator equivalents) which might shorten your code. Also, see what  dict.fromkeys  does.'], ['Which outputs:']], [[' VALID_KEYS = ["Central Spectrum", "Full Frame"]\nresults = {}\nfor key_1 in data.keys():\n    # key_1 is \'20101021\', \'20101004\'...\n\n    for key_2 in data[key_1].keys():\n        # key_2 is \'4x4\', \'4x2\'...\n        if key_2 not in results:\n            results[key_2] = dict.fromkeys(VALID_KEYS, 0)\n        for key_3 in data[key_1][key_2].keys():\n            # key_3 is \'Central Spectrum\', \'Full Frame\', \'Custom\'...\n            if key_3 in VALID_KEYS:\n                results[key_2][key_3] += data[key_1][key_2][key_3]\nprint results\n']], ['summing nested dictionary entries'], 4, 1], [(27216950, 3), [['Which outputs:'], ['-10000']], [[" {\n    u'1x1': {'Central Spectrum': 10, 'Full Frame': 9},\n    u'4x4': {'Central Spectrum': 10, 'Full Frame': 10},\n    u'4x2': {'Central Spectrum': 10, 'Full Frame': 10}\n}\n"]], ['summing nested dictionary entries'], 4, 0], [(27255080, 0), [['You can use the squared Euclidian distance between two points on the unit circle and the law of cosines to get the absolute difference between two angles:'], ['This works with radians. If the angle is in degrees, you must do a conversion:']], [[' from math import sin, cos, acos\nfrom unittest import assertAlmostEqual        \n\ndef assertAlmostEqualAngles(x, y, **kwargs):\n    c2 = (sin(x)-sin(y))**2 + (cos(x)-cos(y))**2\n    angle_diff = acos((2.0 - c2)/2.0) # a = b = 1\n    assertAlmostEqual(angle_diff, 0.0, **kwargs)\n']], ['Python unittesting: Test whether two angles are almost equal'], 2, 1], [(27255080, 1), [['This works with radians. If the angle is in degrees, you must do a conversion:'], ['-10000']], [[' from math import sin, cos, acos, radians, degrees\nfrom unittest import assertAlmostEqual        \n\ndef assertAlmostEqualAngles(x, y, **kwargs):\n    x,y = radians(x),radians(y)\n    c2 = (sin(x)-sin(y))**2 + (cos(x)-cos(y))**2\n    angle_diff = degrees(acos((2.0 - c2)/2.0))\n    assertAlmostEqual(angle_diff, 0.0, **kwargs)\n']], ['Python unittesting: Test whether two angles are almost equal'], 2, 1], [(27257991, 0), [["You can do something that IMHO is very bad (downgraded  very bad  to  meeeeh... so, so  after reading @ ivan-pozdeev 's comments in this answer)"], ['That... well, that works:']], [[" class Time:\n    def __init__(self, hours=0, minutes=0, seconds=0, time_now=''):\n        if hours == 'now':\n            tmp_t = now()\n            self.hour = tmp_t.hour\n            self.min = tmp_t.min\n            self.sec = tmp_t.sec\n        else:\n            t = abs(3600*hours + 60*minutes + seconds)\n            self.hour = t//3600\n            self.min = t//60%60\n            self.sec = t%60\n"]], ['Accept a single string instead of normal parameters'], 2, 1], [(27257991, 1), [['That... well, that works:'], ['But that leaves the code in a very weird state. Is very difficult to read. I certainly would try to come with a different approach altogether...']], [[" >>> a = Time('now')\n>>> print vars(a)\n{'sec': 20, 'hour': 15, 'min': 18}\n>>>\n>>> a = Time(hours=19, minutes=4, seconds=5)\n>>> print vars(a)\n{'sec': 5, 'hour': 19, 'min': 4}\n"]], ['Accept a single string instead of normal parameters'], 2, 0], [(27265939, 0), [['comparing 2 dictionaries using recursion:'], ['Output:']], [[' d1= {\'a\':{\'b\':{\'cs\':10},\'d\':{\'cs\':20}}}\nd2= {\'a\':{\'b\':{\'cs\':30} ,\'d\':{\'cs\':20}},\'newa\':{\'q\':{\'cs\':50}}}\n\ndef findDiff(d1, d2, path=""):\n    for k in d1.keys():\n        if not d2.has_key(k):\n            print path, ":"\n            print k + " as key not in d2", "\\n"\n        else:\n            if type(d1[k]) is dict:\n                if path == "":\n                    path = k\n                else:\n                    path = path + "->" + k\n                findDiff(d1[k],d2[k], path)\n            else:\n                if d1[k] != d2[k]:\n                    print path, ":"\n                    print " - ", k," : ", d1[k]\n                    print " + ", k," : ", d2[k] \n\nprint "comparing d1 to d2:"\nprint findDiff(d1,d2)\nprint "comparing d2 to d1:"\nprint findDiff(d2,d1)\n']], ['Comparing Python dictionaries and nested dictionaries'], 2, 1], [(27265939, 1), [['Output:'], ['-10000']], [[' comparing d1 to d2:\na->b :\n -  cs  :  10\n +  cs  :  30\nNone\ncomparing d2 to d1:\na->b :\n -  cs  :  30\n +  cs  :  10\na :\nnewa as key not in d2 \n\nNone\n']], ['Comparing Python dictionaries and nested dictionaries'], 2, 0], [(27270532, 0), [["If you just want to match the first four dot-separated numbers in your string, then it's trivial:"], ['If you want to do some additional checking (only allowing numbers between 0 and 255), you can:']], [[' >>> re.search(r"\\d+\\.\\d+\\.\\d+\\.\\d+", a).group()\n\'100.80.54.162\'\n']], ['better way to find pattern in string?'], 2, 1], [(27270532, 1), [['If you want to do some additional checking (only allowing numbers between 0 and 255), you can:'], ['-10000']], [[' >>> re.search(r"""(?x)\\b(25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\\.\n...                     (25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\\.\n...                     (25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\\.\n...                     (25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\\b""", b).group()\n\'100.80.54.93\'\n']], ['better way to find pattern in string?'], 2, 1], [(27277381, 0), [['In your case:'], ['glob.glob  will operate in the current working directory, so ýou might want to use the absolute path instead:']], [[" import glob\nimport numpy as np\n\narray_files = glob.glob('*.corr.npy')\nfor fname in array_files:\n    x = np.load(fname)\n    plt.plot(x)\n"]], ['Plot arrays same extension Matlotlib'], 2, 1], [(27302220, 0), [['Dummy data:'], ['np.percentile  seems to work just fine?']], [[" In [135]: df = pd.DataFrame([['a',2,3],\n                             ['a',5,6],\n                             ['a',7,8], \n                             ['b',9,10], \n                             ['b',11,12], \n                             ['b',13,14]], columns=list('abc'))\n"]], ['pandas pivot_table percentile / quantile'], 2, 0], [(27308840, 0), [['-10000'], ['Keep in mind  range  is exclusive of the  stop  parameter.']], [[' for i in range(m, low - 1, -1):\n']], ['Converting C style for loop to python'], 2, 1], [(27308840, 1), [['Keep in mind  range  is exclusive of the  stop  parameter.'], ['The difference between this code and the C code is that in Python  2 , a  list  is being constructed in memory by  range  so for very huge ranges this could be a problem. Replacing  range  with  xrange  would not build a list in memory and make the code practically the same. In Python  3  this issue no longer exists. ']], [[' range(...)\n    range(stop) -> list of integers\n    range(start, stop[, step]) -> list of integers\n']], ['Converting C style for loop to python'], 2, 0], [(27327513, 0), [['Install  FPDF for Python :'], ['Now you can use the same logic:']], [[' pip install fpdf\n']], ['Create PDF from a list of images'], 2, 0], [(27331006, 0), [['Test for  http://example.com/category/  at the start of the string and the  page  parameter with one or more digits in the value:'], ['Demo (using your example urls):']], [[" Rule(LinkExtractor(allow=('^http://example.com/category/\\?.*?(?=page=\\d+)', )), callback='parse_item'),\n"]], ['How to create LinkExtractor rule which based on href in Scrapy'], 2, 1], [(27331006, 1), [['Demo (using your example urls):'], ['-10000']], [[' >>> import re\n>>> pattern = re.compile(r\'^http://example.com/category/\\?.*?(?=page=\\d+)\')\n>>> should_match = [\n...     \'http://example.com/category/?sort=a-z&page=1\',\n...     \'http://example.com/category/?page=1&sort=a-z&cache=1\',\n...     \'http://example.com/category/?page=1&sort=a-z#\'\n... ]\n>>> for url in should_match:\n...     print "Matches" if pattern.search(url) else "Doesn\'t match"\n... \nMatches\nMatches\nMatches\n']], ['How to create LinkExtractor rule which based on href in Scrapy'], 2, 1], [(27356890, 0), [['There might be a nicer way, but I usually do it like this:'], ["UPDATE:  If you want to enclose that code in a function that returns the selected folder, you'll need to save the path to a non-local variable:"]], [[' from gi.repository import Gtk, Gdk, GLib\n\ndef run_dialog(_None):\n    dialog = Gtk.FileChooserDialog("Please choose a folder", None,\n    Gtk.FileChooserAction.SELECT_FOLDER,\n        (Gtk.STOCK_CANCEL, Gtk.ResponseType.CANCEL,\n        "Select", Gtk.ResponseType.OK))\n\n    response = dialog.run()\n    if response == Gtk.ResponseType.OK:\n        print("Select clicked")\n        print("Folder selected: " + dialog.get_filename())\n    elif response == Gtk.ResponseType.CANCEL:\n        print("Cancel clicked")\n\n    dialog.destroy()\n    Gtk.main_quit()\n\n\nGdk.threads_add_idle(GLib.PRIORITY_DEFAULT, run_dialog, None)\nGtk.main()\n']], ['Proper way to destroy a file chooser dialog in pygtk for python'], 2, 1], [(27356890, 1), [["UPDATE:  If you want to enclose that code in a function that returns the selected folder, you'll need to save the path to a non-local variable:"], ['In python 3, you can use  nonlocal result  and  result= dialog.get_filename()  instead of the ugly list reference.']], [[' def run_folder_chooser_dialog():\n    result= []\n\n    def run_dialog(_None):\n        dialog = Gtk.FileChooserDialog("Please choose a folder", None,\n        Gtk.FileChooserAction.SELECT_FOLDER,\n            (Gtk.STOCK_CANCEL, Gtk.ResponseType.CANCEL,\n            "Select", Gtk.ResponseType.OK))\n\n        response = dialog.run()\n        if response == Gtk.ResponseType.OK:\n            result.append(dialog.get_filename())\n        else:\n            result.append(None)\n\n        dialog.destroy()\n        Gtk.main_quit()\n\n\n    Gdk.threads_add_idle(GLib.PRIORITY_DEFAULT, run_dialog, None)\n    Gtk.main()\n    return result[0]\n']], ['Proper way to destroy a file chooser dialog in pygtk for python'], 2, 1], [(27407485, 0), [['A simpler version of your code that does pretty much what you want :)'], ['Alternative solutions with regular expressions:']], [[" import string\nimport collections\n\ndef cleanedup(fh):\n    for line in fh:\n        word = ''\n        for character in line:\n            if character in string.ascii_letters:\n                word += character\n            elif word:\n                yield word\n                word = ''\n\nwith open ('DQ.txt') as doc:\n    wordlist = collections.Counter(cleanedup(doc))\n    print wordlist.most_commond(5)\n"]], ['Python program: foreign language word-frequency dictionary'], 3, 1], [(27407485, 1), [['Alternative solutions with regular expressions:'], ['Or:']], [[" import re\nimport collections\n\ndef cleandup(fh):\n    for line in fh:\n        for word in re.findall('[a-z]+', line.lower()):\n            yield word\n\nwith open ('DQ.txt') as doc:\n    wordlist = collections.Counter(cleanedup(doc))\n    print wordlist.most_commond(5)\n"]], ['Python program: foreign language word-frequency dictionary'], 3, 1], [(27407485, 2), [['Or:'], ['-10000']], [[" import re\nimport collections\n\ndef cleandup(fh):\n    for line in fh:\n        for word in re.split('[^a-z]+', line.lower()):\n            yield word\n\nwith open ('DQ.txt') as doc:\n    wordlist = collections.Counter(cleanedup(doc))\n    print wordlist.most_commond(5)\n"]], ['Python program: foreign language word-frequency dictionary'], 3, 1], [(27419345, 0), [["Your problem is that you're using  str :"], ['You want to do:']], [[" >>> str(0x61cc1000)\n'1640763392'  # int value of the hex number as a string\n"]], ['How to treat a hex as string?'], 4, 0], [(27419345, 1), [['You want to do:'], ['Or']], [[' "{0:x}".format(0x61cc1000)\n']], ['How to treat a hex as string?'], 4, 1], [(27419345, 2), [['Or'], ['As already stated in other answer, you can simply:']], [[" '{:#x}'.format(0x61cc1000)\n"]], ['How to treat a hex as string?'], 4, 1], [(27419345, 3), [['As already stated in other answer, you can simply:'], ['See  6.1.3.1. Format Specification Mini-Language  for details.']], [[" >>> hex(0x61cc1000)\n'0x61cc1000'\n"]], ['How to treat a hex as string?'], 4, 1], [(27444949, 0), [['to_offset  returns a  pd.DateOffset . So you can directly build this object:'], ['For a slightly nicer string representation:']], [[" >>> td = datetime.timedelta(hours=1)\n>>> pd.DateOffset(seconds=td.total_seconds())\n<DateOffset: kwds={'seconds': 3600.0}>\n\n>>> to_offset(pd.DateOffset(seconds=td.total_seconds()))\n<DateOffset: kwds={'seconds': 3600.0}>\n"]], ['Build a Pandas pd.tseries.offsets from timedelta'], 2, 1], [(27458073, 0), [['After its installed, do:'], ['Now go to other machine, and install  virtualenv  and  virtualenvwrapper']], [[' $ mkdir my-project; cd my-project\n$ mkvirtualenv my-env-name\n$ pip install django <more-good-stuff>\n$ pip freeze > requirements.txt\n$ git init; git add --all; git commit -m "Initial Commit"\n... push to github ...\n']], ['Uploading Django projects set up within virtual environment on Github'], 2, 0], [(27458073, 1), [['Now go to other machine, and install  virtualenv  and  virtualenvwrapper'], ['-10000']], [[' $ git clone <url> my-project; cd my-project \n$ mkvirtualenv my-env-name\n$ pip install -r requirements.txt\n... continue your work, commit and push push and win at life :D\n']], ['Uploading Django projects set up within virtual environment on Github'], 2, 0], [(27491734, 0), [['pandas adds a dashed horizontal line on the axis of bar plots.  There is a line in  pandas/tools/plotting.py , in  BarPlot._post_plot_logic  (line 1842 in my version):'], ['This doesn\'t seem to be explicitly documented, and there\'s apparently no way to stop it from doing this.  Worse, the plot doesn\'t keep any reference to the line, so there\'s no clear way to safely remove it.  If the barplot is "plain", then this will work:']], [[" ax.axhline(0, color='k', linestyle='--')\n"]], ['How do I get rid of dotted line on x axis of Pandas/Matplotlib bar plot?'], 2, 0], [(27491734, 1), [['This doesn\'t seem to be explicitly documented, and there\'s apparently no way to stop it from doing this.  Worse, the plot doesn\'t keep any reference to the line, so there\'s no clear way to safely remove it.  If the barplot is "plain", then this will work:'], ['This only works because in the plain barplot, this is the only Line artist in the plot.  If you do anything else that adds other lines to the plot, it could get tricky to determine which one is the axis line you want to remove.']], [[' ax.get_lines()[0].set_visible(False)\n']], ['How do I get rid of dotted line on x axis of Pandas/Matplotlib bar plot?'], 2, 1], [(27491988, 0), [['We could try the current date first. If it is not DST, then we are in luck. If it is, then we could step through the list of utc transition dates (which are stored in  tzone._utc_transition_times ) until we find one that is not DST:'], ['yields ']], [[" import pytz\nimport datetime as DT\nutcnow = DT.datetime.utcnow()\n\ncanonical = dict()\nfor name in pytz.all_timezones:\n    tzone = pytz.timezone(name)\n    try:\n        dstoffset = tzone.dst(utcnow, is_dst=False)\n    except TypeError:\n        # pytz.utc.dst does not have a is_dst keyword argument\n        dstoffset = tzone.dst(utcnow)\n    if dstoffset == DT.timedelta(0):\n        # utcnow happens to be in a non-DST period\n        canonical[name] = tzone.localize(utcnow, is_dst=False).strftime('%z') \n    else:\n        # step through the transition times until we find a non-DST datetime\n        for transition in tzone._utc_transition_times[::-1]:\n            dstoffset = tzone.dst(transition, is_dst=False) \n            if dstoffset == DT.timedelta(0):\n                canonical[name] = (tzone.localize(transition, is_dst=False)\n                                   .strftime('%z'))\n                break\n\nfor name, utcoffset in canonical.iteritems():\n    print('{} --> {}'.format(name, utcoffset)) \n\n# All timezones have been accounted for\nassert len(canonical) == len(pytz.all_timezones)\n"]], ['"Canonical" offset from UTC using pytz?'], 3, 1], [(27491988, 1), [['yields '], ['Here is what the code would look like without using  _utc_transition_times :']], [[' ...\nMexico/BajaNorte --> -0800\nAfrica/Kigali --> +0200\nBrazil/West --> -0400\nAmerica/Grand_Turk --> -0400\nMexico/BajaSur --> -0700\nCanada/Central --> -0600\nAfrica/Lagos --> +0100\nGMT-0 --> +0000\nEurope/Sofia --> +0200\nSingapore --> +0800\nAfrica/Tripoli --> +0200\nAmerica/Anchorage --> -0900\nPacific/Nauru --> +1200\n']], ['"Canonical" offset from UTC using pytz?'], 3, 0], [(27491988, 2), [['Here is what the code would look like without using  _utc_transition_times :'], ['-10000']], [[" import pytz\nimport datetime as DT\nutcnow = DT.datetime.utcnow()\n\ncanonical = dict()\nfor name in pytz.all_timezones:\n    tzone = pytz.timezone(name)\n    try:\n        dstoffset = tzone.dst(utcnow, is_dst=False)\n    except TypeError:\n        # pytz.utc.dst does not have a is_dst keyword argument\n        dstoffset = tzone.dst(utcnow)\n    if dstoffset == DT.timedelta(0):\n        # utcnow happens to be in a non-DST period\n        canonical[name] = tzone.localize(utcnow, is_dst=False).strftime('%z') \n    else:\n        # step through the transition times until we find a non-DST datetime\n        date = utcnow\n        while True:\n            date = date - DT.timedelta(days=1)\n            dstoffset = tzone.dst(date, is_dst=False) \n            if dstoffset == DT.timedelta(0):\n                canonical[name] = (tzone.localize(date, is_dst=False)\n                                   .strftime('%z'))\n                break\n\nfor name, utcoffset in canonical.iteritems():\n    print('{} --> {}'.format(name, utcoffset)) \n\n# All timezones have been accounted for\nassert len(canonical) == len(pytz.all_timezones)\n"]], ['"Canonical" offset from UTC using pytz?'], 3, 1], [(27551521, 0), [['You can use a  url processor .'], ['You can also just decorate the specific functions you want to validate.  This would be more general than the Flask solution.']], [[" @app.url_value_preprocessor\ndef _is_valid_token(endpoint, values):\n    if 'token' not in values:\n        return\n\n    if values['token'] != TOKEN:\n        abort(400)\n"]], ['Auto validate a function parameter using a method'], 2, 1], [(27551521, 1), [['You can also just decorate the specific functions you want to validate.  This would be more general than the Flask solution.'], ['-10000']], [[' def _is_valid_token(f):\n    @wraps(f)\n    def decorated(token, *args, **kwargs):\n        if token != TOKEN:\n            abort(400)\n\n        return f(token, *args, **kwargs):\n\n    return decorated\n\n@app.route(...)\n@_is_valid_token\ndef create_new_game(token, ...):\n    ...\n']], ['Auto validate a function parameter using a method'], 2, 1], [(27551921, 0), [['Perhaps a little shorter and faster way, since by all odds this function is going to be used on very large data:'], ['Using  map  allows your loops to be executed in C rather than in Python. This should prove much faster than using plain loops or even list comprehensions.']], [[' from Bio import Seq\nfrom itertools import product\n\ndef extend_ambiguous_dna(seq):\n   """return list of all possible sequences given an ambiguous DNA input"""\n   d = Seq.IUPAC.IUPACData.ambiguous_dna_values\n   return [ list(map("".join, product(*map(d.get, seq)))) ]\n']], ['how to extend ambiguous dna sequence'], 3, 1], [(27551921, 2), [['Outputs:'], ["Clearly  map  is better, but just by a factor of 2 or 3. It's certain it could be further optimised."]], [[' # len(seq) = 2:\nList delay: 0.02 ms\nMap delay: 0.01 ms\n\n# len(seq) = 3:\nList delay: 0.04 ms\nMap delay: 0.02 ms\n\n# len(seq) = 4\nList delay: 0.08 ms\nMap delay: 0.06 ms\n\n# len(seq) = 5\nList delay: 0.43 ms\nMap delay: 0.17 ms\n\n# len(seq) = 10\nList delay: 126.68 ms\nMap delay: 77.15 ms\n\n# len(seq) = 12\nList delay: 1887.53 ms\nMap delay: 1320.49 ms\n']], ['how to extend ambiguous dna sequence'], 3, 0], [(27573800, 0), [['-10000'], ['Output:']], [[" orig_data = [{'Range': '192.168.1.1-192.168.1.254', 'Org_ID': 'TX', 'name': 'TX-Dallas'}, {'Range': '192.168.2.1-192.168.2.254', 'Org_ID': 'TX', 'name': 'TX-Dallas'}, {'Range': '192.168.3.1-192.168.3.254', 'Org_ID': 'TX', 'name': 'TX-Dallas'}, {'Range': '10.0.0.1-10.0.0.254', 'Org_ID': 'TX', 'name': 'TX-Dallas'}, {'Range': '192.168.9.1-192.168.1.254', 'Org_ID': 'CA', 'name': 'CA-San Diego'}, {'Range': '10.0.5.1-10.0.5.254', 'Org_ID': 'CA', 'name': 'CA-San Diego'}, {'Range': '172.16.0.1-172.16.0.254', 'Org_ID': 'TX', 'name': 'TX-Houston'}, {'Range': '172.16.3.1-172.16.3.254', 'Org_ID': 'TX', 'name': 'TX-Houston'}]\n\ncont = collections.defaultdict(lambda : collections.defaultdict(list))\nfor d in orig_data:\n    cont[d['Org_ID']][d['name']].append(d['Range'])\n\nanswer = []\nfor orgid in cont:\n    for name,rangelist in cont[orgid].items():\n        answer.append({'Org_ID':orgid, 'name':name, 'Range':rangelist})\n"]], ['combine list of dictionaries with same key'], 2, 1], [(27573800, 1), [['Output:'], ['-10000']], [[" In [226]: answer\nOut[226]: \n[{'name': 'TX-Houston',\n  'Org_ID': 'TX',\n  'Range': ['172.16.0.1-172.16.0.254', '172.16.3.1-172.16.3.254']},\n {'name': 'TX-Dallas',\n  'Org_ID': 'TX',\n  'Range': ['192.168.1.1-192.168.1.254',\n   '192.168.2.1-192.168.2.254',\n   '192.168.3.1-192.168.3.254',\n   '10.0.0.1-10.0.0.254']},\n {'name': 'CA-San Diego',\n  'Org_ID': 'CA',\n  'Range': ['192.168.9.1-192.168.1.254', '10.0.5.1-10.0.5.254']}]\n"]], ['combine list of dictionaries with same key'], 2, 0], [(27576462, 1), [["Note: Since there's a label at the end of each file (and your training_data ), you might want to use the following instead which would leave it out of what is passed to the  feature_hasher_vect.transform()  method:"], ['-10000']], [[" print [[' '.join(x) for x in sample[:-1]]\n                        for sample in my_load_files(text_folder, 'File_*')]\n"]], ['How to load_files and process a .txt file with scikit-learn?'], 2, 0], [(27585173, 0), [['str.translate  might be appropriate; something along the lines of'], ['and']], [[" replacements = [\n    ('abc', 'x'),\n    ('def', 'y'),\n    ('ghi', 'z'),\n]\n\ntrans = str.maketrans({ k: v for l, v in replacements for k in l })\n"]], ['Using multiple (similar) generator expressions'], 2, 0], [(27585173, 1), [['and'], ['-10000']], [[' new_row = [item.translate(trans) for item in row]\n']], ['Using multiple (similar) generator expressions'], 2, 0], [(27591621, 1), [["After tagging a sentence you can tie a word inside the sentence with a SYNSET using this function. Here's an example:"], ["Result:  [Synset('be.v.01'), Synset('travel.v.01'), Synset('buy.v.01'), Synset('gift.n.01')]"]], [[' from nltk.stem import WordNetLemmatizer\nfrom nltk import pos_tag, word_tokenize\n\nsentence = "I am going to buy some gifts"\ntagged = pos_tag(word_tokenize(sentence))\n\nsynsets = []\nlemmatzr = WordNetLemmatizer()\n\nfor token in tagged:\n    wn_tag = penn_to_wn(token[1])\n    if not wn_tag:\n        continue\n\n    lemma = lemmatzr.lemmatize(token[0], pos=wn_tag)\n    synsets.append(wn.synsets(lemma, pos=wn_tag)[0])\n\nprint synsets\n']], ['NLTK convert tokenized sentence to synset format'], 2, 0], [(27605834, 0), [['-10000'], ['Result:']], [[" l1 = [['a',1], ['b',2], ['c',3]]\nl2 = [['b',2], ['c',3], ['a',1]]\nprint sorted(l1) == sorted(l2)\n"]], ['Test if two lists of lists are equal'], 2, 1], [(27605834, 1), [['Result:'], ['-10000']], [[' True\n']], ['Test if two lists of lists are equal'], 2, 0], [(27615872, 0), [['The way you are doing it is good because it is very readable... but if a one-liner is what you are after the I will oblige:'], ['The best way to construct (mentally) nested list comprehensions is to think of it how you would write it in a normal loop.']], [[' >>> A = [2,3,1,4,5,2,4]\n>>> B = [4,2,3,6,2,5,1]\n>>> [i for sublist in [[a, b] if a < b else [b, a] for a, b in zip(A, B)] for i in sublist]\n[2, 4, 2, 3, 1, 3, 4, 6, 2, 5, 2, 5, 1, 4]\n']], ['Make one list from two list applying constraint'], 3, 1], [(27615872, 2), [['Then you just flatten the nested loops and move the  yield i  to the front, dropping the  yield .'], ['Now you can just replace C with the list comp above and get the one-liner I posted.']], [[' for sublist in C for i in sublist yield i\n|-> yield i for sublist in C for i in sublist\n    |-> i for sublist in C for i in sublist\n']], ['Make one list from two list applying constraint'], 3, 0], [(27665039, 0), [['Here is a fixed version with a modified part that gets the amounts:'], ['Prints:']], [[' from lxml import html\nimport requests\n\ndef historic_quotes(symbol, stMonth, stDate, stYear, enMonth, enDate, enYear):\n    url = \'https://finance.yahoo.com/q/hp?s=%s+Historical+Prices\' % symbol\n\n    params = {\n        \'a\': stMonth,\n        \'b\': stDate,\n        \'c\': stYear,\n        \'d\': enMonth,\n        \'e\': enDate,\n        \'f\': enYear,\n        \'submit\': \'submit\',\n    }\n    response = requests.get(url, params=params)\n\n    tree = html.document_fromstring(response.content)\n    for amount in tree.xpath(\'//table[@class="yfnc_datamodoutline1"]//tr[td[@class="yfnc_tabledata1"]]//td[5]/text()\'):\n        print amount\n\nhistoric_quotes(\'baba\', \'00\', \'11\', \'2010\', \'00\', \'11\', \'2015\')\n']], ['Python: Scrape Data from Web after Inputing Info'], 2, 1], [(27665039, 1), [['Prints:'], ['-10000']], [[' 105.95\n105.95\n105.52\n108.77\n110.65\n109.25\n109.02\n105.77\n104.70\n105.11\n104.97\n103.88\n107.48\n105.07\n107.90\n...\n90.57\n']], ['Python: Scrape Data from Web after Inputing Info'], 2, 0], [(27670683, 0), [['Parallelization is the ideal use case for a  FeatureHasher . It can also accept dictionaries over (feature_name, value). For example:'], ['At the end combine the results:']], [[" from sklearn.feature_extraction FeatureHasher\nimport scipy\n\nvect = FeatureHasher(n_features=4, non_negative=True)\n\n# thread 1 \nl1 = [{'foo': 1, 'bar': 2}]\nX1 = vect.fit_transform(l1) \n# thread 2\nl2 = [{'foo': 3, 'baz': 1}]\nX2 = vect.fit_transform(l2)\n"]], ['Parallelize DictVectorizer Creation'], 2, 0], [(27670683, 1), [['At the end combine the results:'], ['Just make sure that you use a large enough number of features (like 2**18) so that there are no collisions.']], [[' >>> scipy.sparse.vstack([X1, X2]).toarray()\narray([[ 1.,  2.,  0.,  0.],\n       [ 3.,  0.,  1.,  0.]])\n']], ['Parallelize DictVectorizer Creation'], 2, 0], [(27674145, 0), [['You can use  dictionary expression'], ['Yields:']], [[" data = [['cups', 'cusp', 'cpus', 'cpsu', 'csup', 'cspu',],\n        ['pups', 'pusp','upsp', 'upps', 'upsp', 'uspp']]\n\nresult = {each[0]:each[1:] for each in data}           \nprint result\n"]], ['Python: Create Dictionary From List with [0] = Key and [1:]= Values'], 2, 1], [(27674145, 1), [['Yields:'], ['-10000']], [[" {'pups': ['pusp', 'upsp', 'upps', 'upsp', 'uspp'], \n'cups': ['cusp', 'cpus', 'cpsu', 'csup', 'cspu']}\n"]], ['Python: Create Dictionary From List with [0] = Key and [1:]= Values'], 2, 0], [(27676866, 0), [["This works, and couldn't be any more compact:"], ['To answer your side question –  "is there any difference between them?"  – no, they\'re all the same:']], [[" >>> tup4 = My_tuple(**dict(zip(vars, vals)))\n>>> tup4\nMy_tuple(var1='val1', var2='val2')\n"]], ['creating namedtuple instances with kwargs'], 2, 1], [(27724543, 1), [['you need to layout the new window ... since you clearly want it to fill the 500,500 area you will need to use sizers'], ['or just force the size of the contained scrollwindow (which is what you normally do for scrolled windows)']], [[" def newFrame(self, event):\n    self.new_window = wx.Frame(self, title='frame2', size=(500, 500), pos=(800,0))\n    sz = wx.BoxSizer()\n    sz.SetMinSize((500,500)) #force minimum size\n    self.scroll = wx.ScrolledWindow(self.new_window, -1)\n    sz.Add(self.scroll,1,wx.EXPAND)\n    self.scroll.SetScrollbars(1, 1, 1600, 1400)\n    self.new_window.SetSizer(sz)\n    self.new_window.Layout()\n    self.new_window.Fit()\n    self.new_window.Show()\n"]], ['creating a wxpython scrolled window (frame) by an event'], 3, 1], [(27724543, 2), [['or just force the size of the contained scrollwindow (which is what you normally do for scrolled windows)'], ['-10000']], [[" def newFrame(self, event):\n    self.new_window = wx.Frame(self, title='frame2', pos=(800,0))\n\n    self.scroll = wx.ScrolledWindow(self.new_window, -1,size=(500,500))\n    self.scroll.SetScrollbars(1, 1, 1600, 1400)\n    self.new_window.Layout()\n    self.new_window.Fit()\n    self.new_window.Show()\n"]], ['creating a wxpython scrolled window (frame) by an event'], 3, 1], [(27733482, 1), [['This confirms that the values values generated by  orig  and  using_numpy  are \nthe same:'], ['-10000']], [[" assert np.allclose(expected['corr'].dropna(), result['corr'].dropna())\n"]], ['pandas: Rolling correlation with fixed patch for pattern-matching'], 3, 0], [(27733482, 2), [['-10000'], ['-- a 2600x speedup.']], [[' In [77]: %timeit orig(df.copy(), patch.copy())\n1 loops, best of 3: 3.56 s per loop\n\nIn [78]: %timeit using_numpy(df.copy(), patch.copy())\n1000 loops, best of 3: 1.35 ms per loop\n']], ['pandas: Rolling correlation with fixed patch for pattern-matching'], 3, 0], [(27739381, 0), [["You can use  \\s+  (match all whitspaces) or  ' +'  but as look-behind requires fixed-width pattern you need to put it outside the look-behind and use grouping  also you can just use  re.search :\n:"], ['or']], [[" >>> string = 'I love my           world of dreams'\n>>> print re.search (r'(?<=my)\\s+([^ -.]*)', string).group(1)\nworld\n"]], ['Regular expression to find a word after multiple spaces'], 2, 1], [(27739381, 1), [['or'], ['-10000']], [[" >>> string = 'I love my           world of dreams'\n>>> print re.search (r'(?<=my) +([^ -.]*)', string).group(1)\nworld\n"]], ['Regular expression to find a word after multiple spaces'], 2, 1], [(27743031, 0), [['You can prevent injections just by parameterising arguments, for example:'], ['Will read ']], [[' "SELECT * FROM Users WHERE name=\\"".name."\\";"\n']], ['Secure MySQL login data in a Python client program'], 5, 0], [(27743031, 1), [['Will read '], ['But an be "injected" with:']], [[' SELECT * FROM Users WHERE name="AlecTeal";\n']], ['Secure MySQL login data in a Python client program'], 5, 0], [(27743031, 2), [['But an be "injected" with:'], ['Then it will read']], [[' name="\\" or UserType=\\"Admin"\n']], ['Secure MySQL login data in a Python client program'], 5, 0], [(27743031, 3), [['Then it will read'], ["That's bad, you can prevent that with stuff like:"]], [[' SELECT * FROM Users WHERE name="" or UserType="Admin";\n']], ['Secure MySQL login data in a Python client program'], 5, 0], [(27743031, 4), [["That's bad, you can prevent that with stuff like:"], ["and binding your variables, then the SQL server doesn't actually parse any data from the user, it sees the  ?  and just reads from the parameters."]], [[' SELECT * FROM Users WHERE name=?\n']], ['Secure MySQL login data in a Python client program'], 5, 0], [(27746297, 0), [["As a stand-alone example, let's say we have something similar to the following:"], ["Now let's try detrending it with a 2nd order polynomial function (note the 2 in the line  model = np.polyfit(x, y, 2) ):"]], [[" import numpy as np\nimport matplotlib.pyplot as plt\n\nnum = 1000\nx = np.linspace(0, 10, num)\ny = np.exp(x)\n\n# Add some non-stationary noise that's hard to see without de-trending\nnoise = 100 * np.exp(0.2 * x) * np.random.normal(0, 1, num)\ny += noise\n\nfig, ax = plt.subplots()\nax.plot(x, y, 'ro')\nplt.show()\n"]], ['Detrend Flux Time Series with Non-Linear Trend'], 2, 0], [(27746297, 1), [["Now let's try detrending it with a 2nd order polynomial function (note the 2 in the line  model = np.polyfit(x, y, 2) ):"], ['']], [[" import numpy as np\nimport matplotlib.pyplot as plt\n\nnum = 1000\nx = np.linspace(0, 10, num)\ny = np.exp(x)\n\n# Add some non-stationary noise that's hard to see without de-trending\nnoise = 100 * np.exp(0.2 * x) * np.random.normal(0, 1, num)\ny += noise\n\n# Detrend with a 2d order polynomial\nmodel = np.polyfit(x, y, 2)\npredicted = np.polyval(model, x)\n\nfig, axes = plt.subplots(nrows=2, sharex=True)\naxes[0].plot(x, y, 'ro')\naxes[0].plot(x, predicted, 'k-')\naxes[0].set(title='Original Data and 2nd Order Polynomial Trend')\n\naxes[1].plot(x, y - predicted, 'ro')\naxes[1].set(title='Detrended Residual')\n\nplt.show()\n"]], ['Detrend Flux Time Series with Non-Linear Trend'], 2, 1], [(27747712, 1), [['Then:'], ['-10000']], [[" >>> c = MagicCounter()\n>>> c['a'] = 1\n>>> c['b'] = 1\n>>> c['c'] = 1\n>>> c\nMagicCounter({'a': 1, 'c': 1, 'b': 1})\n>>> c['abc'] += 1\n>>> c\nMagicCounter({'a': 2, 'c': 2, 'b': 2, 'abc': 1})\n"]], ['Attach callback to Counter() value'], 2, 0], [(27773141, 0), [['You can check the "key" == \'Type A\' / \'Type B\' by using  get  method, like this:'], ['In fact, you can improve your code by using a better xpath accessing  directly:']], [[' for node in tree.iterfind(\'.//logging/Adapter[@type="abcdef"]\'):\n    for child in node:\n        # check if the key is \'Type A\'\n        if child.get(\'key\') == \'Type A\':\n            child.set(\'value\', \'false\')\n        # ... if \'Type B\' ...\n']], ['XML <arg> value Replacement in Python'], 2, 1], [(27773141, 1), [['In fact, you can improve your code by using a better xpath accessing  directly:'], ['-10000']], [[' for node in tree.iterfind(\'.//logging/Adapter[@type="abcdef"]/arg\'):\n    # so you don\'t need another inner loop to access <arg> elements\n    if node.get(\'key\') == \'Type A\':\n        node.set(\'value\', \'false\')\n    # ... if \'Type B\' ...\n']], ['XML <arg> value Replacement in Python'], 2, 1], [(27779615, 0), [['You could return a list as the result at the current nesting level and join together the nested results using extend.'], ['outputs:']], [[" l = [['A', ['A', 'B', ['A', 'B', 'C'], ['A', 'B', 'D']], ['A', 'D', ['A', 'D', 'A']], ['A', 'C', ['A', 'C', 'B'], ['A', 'C', 'A']], ['A', 'A', ['A', 'A', 'D']]]]\n\ndef un_nest(l):\n    r = []\n    k = []\n    for item in l:\n        if type(item) is list:\n            r.extend(un_nest(item))\n        else:\n            k.append(item)\n    if k:\n        r.insert(0, k)\n    return r\n\nprint(un_nest(l))\n"]], ['python - how to convert a nested list to a list of all individual sub-lists'], 2, 1], [(27779615, 1), [['outputs:'], ['-10000']], [[" [['A'], ['A', 'B'], ['A', 'B', 'C'], ['A', 'B', 'D'], ['A', 'D'], ['A', 'D', 'A'], ['A', 'C'], ['A', 'C', 'B'], ['A', 'C', 'A'], ['A', 'A'], ['A', 'A', 'D']]\n"]], ['python - how to convert a nested list to a list of all individual sub-lists'], 2, 0], [(27781555, 1), [['in your template:'], ['-10000']], [[' {% some_simple_tag something myobject.body %}\n']], ['Is it possible to pass the evaluated result of one template tag as a parameter to another tag?'], 2, 0], [(27793543, 0), [['Rely on the chart element, get the  next  table  sibling  and find all rows inside:'], ['Prints:']], [[" from bs4 import BeautifulSoup\nimport requests\n\nurl = 'http://www.boxofficemojo.com/movies/?page=daily&view=chart&id=hungergames3.htm'\n\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.content)\n\nfor tr in soup.find('div', id='chart_container').find_next_sibling('table').find_all('tr')[1:]:\n    print [td.text for td in tr('td')]\n"]], ['Python BeautifulSoup Mix Matching items in Table'], 2, 1], [(27793543, 1), [['Prints:'], ['-10000']], [[" [u'Fri', u'Nov. 21, 2014', u'1', u'$55,139,942', u'-', u'-', u'4,151', u'$13,284', u'$55,139,942', u'1']\n[u'Sat', u'Nov. 22, 2014', u'1', u'$40,905,873', u'-25.8%', u'-', u'4,151', u'$9,854', u'$96,045,815', u'2']\n[u'Sun', u'Nov. 23, 2014', u'1', u'$25,851,819', u'-36.8%', u'-', u'4,151', u'$6,228', u'$121,897,634', u'3']\n[u'Mon', u'Nov. 24, 2014', u'1', u'$8,978,318', u'-65.3%', u'-', u'4,151', u'$2,163', u'$130,875,952', u'4']\n[u'Tue', u'Nov. 25, 2014', u'1', u'$12,131,853', u'+35.1%', u'-', u'4,151', u'$2,923', u'$143,007,805', u'5']\n[u'Wed', u'Nov. 26, 2014', u'1', u'$14,620,517', u'+20.5%', u'-', u'4,151', u'$3,522', u'$157,628,322', u'6']\n[u'Thu', u'Nov. 27, 2014', u'1', u'$11,079,983', u'-24.2%', u'-', u'4,151', u'$2,669', u'$168,708,305', u'7']\n[u'']\n[u'Fri', u'Nov. 28, 2014', u'1', u'$24,199,442', u'+118.4%', u'-56.1%', u'4,151', u'$5,830', u'$192,907,747', u'8']\n[u'Sat', u'Nov. 29, 2014', u'1', u'$21,992,225', u'-9.1%', u'-46.2%', u'4,151', u'$5,298', u'$214,899,972', u'9']\n[u'Sun', u'Nov. 30, 2014', u'1', u'$10,780,932', u'-51.0%', u'-58.3%', u'4,151', u'$2,597', u'$225,680,904', u'10']\n[u'Mon', u'Dec. 1, 2014', u'1', u'$2,635,435', u'-75.6%', u'-70.6%', u'4,151', u'$635', u'$228,316,339', u'11']\n[u'Tue', u'Dec. 2, 2014', u'1', u'$3,160,145', u'+19.9%', u'-74.0%', u'4,151', u'$761', u'$231,476,484', u'12']\n[u'Wed', u'Dec. 3, 2014', u'1', u'$2,332,453', u'-26.2%', u'-84.0%', u'4,151', u'$562', u'$233,808,937', u'13']\n[u'Thu', u'Dec. 4, 2014', u'1', u'$2,317,894', u'-0.6%', u'-79.1%', u'4,151', u'$558', u'$236,126,831', u'14']\n...\n"]], ['Python BeautifulSoup Mix Matching items in Table'], 2, 0], [(27805919, 0), [['just start another loop when you reach the line you want to start from :'], ['A simple example:']], [[" for files in filepath:\n    with open(files, 'r') as f:\n        for line in f:\n            if 'Abstract' in line:                \n                for line in f: # now you are at the lines you want\n                    # do work\n"]], ['How to only read lines in a text file after a certain string using python?'], 3, 1], [(27805919, 2), [['You can also use  itertools.dropwhile  to consume the lines up to the point you want.'], ['-10000']], [[' from itertools import dropwhile\n\nfor files in filepath:\n    with open(files, \'r\') as f:\n        dropped = dropwhile(lambda _line: "Abstract" not in _line, f)\n        next(dropped,"")\n        for line in dropped:\n                print(line)\n']], ['How to only read lines in a text file after a certain string using python?'], 3, 1], [(27810523, 0), [["Code perfectly equivalent to the one you've shown is:"], ["Should the names  not  actually be  filter1 ,  filter2 , etc, that's OK as long as the required names are known:"]], [[" def get_query_results(*filters):\n    res = models.Item.query\n    for i, filt in enumerate(filters, 1):\n        if filt is not None:\n            d = {'filter{}'.format(i): filt}\n            res = res.filter(**d)\n    return res.all()\n"]], ['sqlalchemy - elegant way to deal with several optional filters?'], 2, 1], [(27810523, 1), [["Should the names  not  actually be  filter1 ,  filter2 , etc, that's OK as long as the required names are known:"], ['This variant would work in this case.']], [[" NAMES = 'foo bar baz bat'.split()\n\ndef get_query_results(*filters):\n    res = models.Item.query\n    for name, filt in zip(NAMES, filters):\n        if filt is not None:\n            d = {name: filt}\n            res = res.filter(**d)\n    return res.all()\n"]], ['sqlalchemy - elegant way to deal with several optional filters?'], 2, 1], [(27823447, 0), [['You need to define the key for comparing 2 elements:'], ['Then sort it:']], [[' import time\ndef key(item):\n    return time.strptime(item[0][-16:], "%d/%m/%y à %H:%M")\n']], ["python - sorting a list of lists by a key that's substring of each element"], 2, 0], [(27823447, 1), [['Then sort it:'], ['-10000']], [[' print sorted(my_list,key=key)\n']], ["python - sorting a list of lists by a key that's substring of each element"], 2, 0], [(27827982, 0), [['-10000'], ['Here it is with xpath, and I think it better matches what you are trying to do, i.e. given a column, look down the rows for the value 0:']], [[' from selenium import webdriver\nimport re\n\ndriver = webdriver.PhantomJS()\ndriver.set_window_size(1120, 550) #For bug\ndriver.get("http://localhost:8000")\n\npattern = r"""\n    \\s*         #Match whitespace, 0 or more times, followed by...\n    (\\d+)       #a digit, one or more times, captured, followed by\n    \\s*         #whitespace, 0 or more times, followed by...\n    [|]         #vertical bar, followed by...\n    \\s*         #whitespace, 0 or more times, followed by...\n    \\d+         #a digit, one or more times\n"""\nregex = re.compile(pattern, re.X)\n\ntable = driver.find_element_by_id(\'ambassadors-for-assignment\')\ntrs = table.find_elements_by_tag_name(\'tr\')\n\nfor tr in trs:\n    tds = tr.find_elements_by_tag_name(\'td\')\n\n    for td in tds:\n        match_obj = re.search(regex, text)\n\n        if match_obj and match_obj.group(1) == \'0\':\n            success_button = tr.find_element_by_css_selector(\'button.btn-success\')\n            print success_button.get_attribute(\'type\')\n            success_button.click()\n']], ['how to dynamically read a specific cell value in a table using selenium and python'], 5, 1], [(27827982, 1), [['Here it is with xpath, and I think it better matches what you are trying to do, i.e. given a column, look down the rows for the value 0:'], ['The output will look like the following, depending on what text you are trying to match with the regex:']], [[' from selenium import webdriver\nimport re\n\ndriver = webdriver.PhantomJS()\ndriver.set_window_size(1120, 550) #For bug\ndriver.get("http://localhost:8000")\n\npattern = r""" \n    \\s*         #Match whitespace, 0 or more times, followed by...\n    (\\d+)       #a digit, one or more times, captured, followed by\n    \\s*         #whitespace, 0 or more times, followed by...\n    [|]         #vertical bar, followed by...\n    \\s*         #whitespace, 0 or more times, followed by...\n    \\d+         #a digit, one or more times\n"""\nregex = re.compile(pattern, re.X)\n\ntrs = driver.find_elements_by_xpath(\'//table[@id="ambassadors-for-assignment"]/tbody/tr\')\ntarget_columns = [3, 4]\n\nfor target_column in target_columns:\n    for tr in trs:\n        target_column_xpath = \'./td[{}]\'.format(target_column)  #VARY COLUMN HERE ***\n        td = tr.find_element_by_xpath(target_column_xpath)\n        match_obj = re.match(regex, td.text)\n\n        if match_obj and match_obj.group(1) == \'0\':\n            button_xpath = \'.//button[contains(concat(" ", normalize-space(@class), " "), " btn-success ")]\' \n            success_button = tr.find_element_by_xpath(button_xpath)\n            #success_button.click()\n\n            print "column {}:".format(target_column)\n            print match_obj.group(0)\n            print success_button.get_attribute(\'class\')\n            print\n']], ['how to dynamically read a specific cell value in a table using selenium and python'], 5, 1], [(27827982, 2), [['The output will look like the following, depending on what text you are trying to match with the regex:'], ['But in my opinion, having to use the following in an xpath:']], [[' column 3:\n0 | 5\nbtn btn-success\n\ncolumn 4:\n0 | 61\nbtn btn-success\n']], ['how to dynamically read a specific cell value in a table using selenium and python'], 5, 0], [(27827982, 3), [['But in my opinion, having to use the following in an xpath:'], ['to match a class, means that using xpath is NOT the way to do it.  The python method:']], [[' \'[contains(concat(" ", normalize-space(@class), " "), " btn-success ")]\'\n']], ['how to dynamically read a specific cell value in a table using selenium and python'], 5, 0], [(27827982, 4), [['to match a class, means that using xpath is NOT the way to do it.  The python method:'], ['...will do the same thing more succinctly and clearly.']], [[" find_element_by_csss_selector('button.btn-success')\n"]], ['how to dynamically read a specific cell value in a table using selenium and python'], 5, 0], [(27855146, 0), [['You just need to search for the data inside the relevant part of the page ( div  with  id="siteTable" ):'], ['Tested, here is what I get for, for example,  votes_likes :']], [[' def parse(self, response):\n    # make a selector and search the fields inside it\n    sel = response.xpath(\'//div[@id="siteTable"]\')\n\n    item = ExItem()\n    item["title"] = sel.xpath(\'.//p[contains(@class,"title")]/a/text()\').extract()\n    item["rank"] = sel.xpath(\'.//span[contains(@class,"rank")]/text()\').extract()\n    item["votes_dislike"] = sel.xpath(\'.//div[contains(@class,"score dislikes")]/text()\').extract()\n    item["votes_unvoted"] = sel.xpath(\'.//div[contains(@class,"score unvoted")]/text()\').extract()\n    item["votes_likes"] = sel.xpath(\'.//div[contains(@class,"score likes")]/text()\').extract()\n    item["video_reference"] = sel.xpath(\'.//a[contains(@class,"thumbnail may-blank")]/@href\').extract()\n    item["image"] = sel.xpath(\'.//a[contains(@class,"thumbnail may-blank")]/img/@src\').extract()\n    return item\n']], ['remove the unicode from the output of JSON using scrapy'], 2, 1], [(27855146, 1), [['Tested, here is what I get for, for example,  votes_likes :'], ['-10000']], [["  'votes_likes': [u'5340',\n                 u'4041',\n                 u'4080',\n                 u'5055',\n                 u'4385',\n                 u'4784',\n                 u'3842',\n                 u'3734',\n                 u'4081',\n                 u'3731',\n                 u'4580',\n                 u'5279',\n                 u'2540',\n                 u'4345',\n                 u'2068',\n                 u'3715',\n                 u'3249',\n                 u'4232',\n                 u'4025',\n                 u'522',\n                 u'2993',\n                 u'2789',\n                 u'3529',\n                 u'3450',\n                 u'3533'],\n"]], ['remove the unicode from the output of JSON using scrapy'], 2, 0], [(27857842, 0), [["Let's create the dataframe :"], ['result :']], [[" import pandas as pd\n\ndata = {'product_id': [23, 65, 66, 98, 998, 798],\n        'category': ['cat1', 'cat2', 'cat1', 'cat1', 'cat1', 'cat2'],\n        'number_of_purchase': [18,19,4,9,1,8]}\n\ndf = pd.DataFrame(data)\nprint df\n"]], ['Python, use "order by" inside a "group concat" with pandas DataFrame'], 8, 0], [(27857842, 1), [['result :'], ['First step : we sort the dataframe by sales :']], [['   category  number_of_purchase  product_id\n0     cat1                  18          23\n1     cat2                  19          65\n2     cat1                   4          66\n3     cat1                   9          98\n4     cat1                   1         998\n5     cat2                   8         798\n']], ['Python, use "order by" inside a "group concat" with pandas DataFrame'], 8, 0], [(27857842, 2), [['First step : we sort the dataframe by sales :'], ['result :']], [[" df = df.sort(columns='number_of_purchase', ascending=False)\ndf\n"]], ['Python, use "order by" inside a "group concat" with pandas DataFrame'], 8, 0], [(27857842, 3), [['result :'], ['Seconde step : We use a groupby operation.For each category, it will create a list of the top two categories. Data is still integer.']], [['   category  number_of_purchase  product_id\n1     cat2                  19          65\n0     cat1                  18          23\n3     cat1                   9          98\n5     cat2                   8         798\n2     cat1                   4          66\n4     cat1                   1         998\n']], ['Python, use "order by" inside a "group concat" with pandas DataFrame'], 8, 0], [(27857842, 4), [['Seconde step : We use a groupby operation.For each category, it will create a list of the top two categories. Data is still integer.'], ['result :']], [[" df = df.groupby('category').apply(lambda x: list(x.product_id)[:2])\nprint df\n"]], ['Python, use "order by" inside a "group concat" with pandas DataFrame'], 8, 0], [(27857842, 5), [['result :'], ['If you need to have the result as a string, we use a simple lambda operation :']], [[' category\ncat1         [23, 98]\ncat2        [65, 798]\ndtype: object\n']], ['Python, use "order by" inside a "group concat" with pandas DataFrame'], 8, 0], [(27857842, 6), [['If you need to have the result as a string, we use a simple lambda operation :'], ['result :']], [[" df.apply(lambda x: '&'.join([str(elem) for elem in x]))\n"]], ['Python, use "order by" inside a "group concat" with pandas DataFrame'], 8, 0], [(27857842, 7), [['result :'], ['-10000']], [[' category\ncat1         23&98\ncat2        65&798\ndtype: object\n']], ['Python, use "order by" inside a "group concat" with pandas DataFrame'], 8, 0], [(27884051, 0), [['Create a python_run.bat file similar to this:'], ['Then you simply have to type the following to execute any script located in your SCRIPT_DIR.']], [[' @ECHO OFF\n\nREM *** MODIFY THE NEXT LINE TO SPECIFY THE LOCATION OF YOUR SCRIPTS ***\nSET SCRIPT_DIR=C:\\Path\\To\\Scripts\n\nREM *** MODIFY THE NEXT LINE TO SPECIFY THE LOCATION OF YOUR PYTHON.EXE ***\nSET PYTHON_BIN=C:\\Python27\\python.exe\n\nPUSHD %SCRIPT_DIR%\n%PYTHON_BIN% %*\nPOPD\n']], ['How do I run python file without path?'], 3, 0], [(27884051, 1), [['Then you simply have to type the following to execute any script located in your SCRIPT_DIR.'], ['And it will result in running the following command as if you were already inside your scripts folder:']], [[' python_run my_cool_script.py --foo=bar\n']], ['How do I run python file without path?'], 3, 0], [(27884051, 2), [['And it will result in running the following command as if you were already inside your scripts folder:'], ['-10000']], [[' C:\\Python27\\python.exe my_cool_script.py --foo=bar\n']], ['How do I run python file without path?'], 3, 0], [(27885989, 0), [['-10000'], ['Also you can do it directly on your main code :']], [[" >>> l=('hostzi.com', [datetime.datetime(2009, 5, 12, 13, 4, 12)])\n>>> l[1][0].strftime('%Y/%m/%d')\n'2009/05/12'\n"]], ['How to convert a list of datetime.datetime objects to date in Python?'], 2, 1], [(27885989, 1), [['Also you can do it directly on your main code :'], ['-10000']], [[" f = open (file,'r')\nwith open (output,'wt') as m:\n    for line in f:\n        line = line.strip('\\n')\n        domain = line.split(';')\n        try:\n            w = pythonwhois.get_whois(domain)\n            c_date = (w['creation_date'])\n            print (domain,c_date[0].strftime('%Y/%m/%d'))\n\n        except:\n            pass\n"]], ['How to convert a list of datetime.datetime objects to date in Python?'], 2, 1], [(27887545, 1), [['Example:'], ['OR']], [[' >>> s1 = r\'STR("<some_string>")\'\n>>> s2 = r\'STR("test \\") string")\'\n>>> re.findall(r\'STR\\("(.+?)(?<!\\\\)"\\)\', s1)\n[\'<some_string>\']\n>>> re.findall(r\'STR\\("(.+?)(?<!\\\\)"\\)\', s2)\n[\'test \\\\") string\']\n']], ['Python - how to ignore escape chars in regexp'], 3, 1], [(27914360, 1), [['output'], ['The trick is to use the reset_index() method (so you easily get the integer index of the group)']], [['             DeliveryCount  DeliveryNb\nDate                                 \n2007-04-26             23         706\n2007-04-27             10         705\n2007-04-27           1089         708\n2007-04-27             82         450\n2007-04-27             34         283\n2007-04-28            100          45\n2007-04-28             11          89\n']], ['Python pandas idxmax for multiple indexes in a dataframe'], 5, 0], [(27914360, 2), [['The trick is to use the reset_index() method (so you easily get the integer index of the group)'], ['applying it :']], [[" def func(df):\n    idx = df.reset_index()['DeliveryCount'].idxmax()\n    return df['DeliveryNb'].iloc[idx]\n"]], ['Python pandas idxmax for multiple indexes in a dataframe'], 5, 0], [(27914360, 3), [['applying it :'], ['result :']], [[' g = df.groupby(df.index)\ng.apply(func)\n']], ['Python pandas idxmax for multiple indexes in a dataframe'], 5, 0], [(27914360, 4), [['result :'], ['-10000']], [[' Date\n2007-04-26    706\n2007-04-27    708\n2007-04-28     45\ndtype: int64\n']], ['Python pandas idxmax for multiple indexes in a dataframe'], 5, 0], [(27925861, 0), [['The tricky part is merging the two series/dataframes that have indexes with different datetime resolutions. Once you combine them intelligently, you can just filter normally.'], ['Now you can do something like']], [[" # Make sure your series has a name\n# Make sure the index is pure dates, not date 00:00:00\nmost_liquid_contracts.name = 'most'\nmost_liquid_conttracts.index = most_liquid_contracts.index.date\n\ndata = df\ndata['day'] = data.index.date\ncombined = data.join(most_liquid_contracts, on='day', how='left')\n"]], ['python pandas filter dataframe by another series, multiple columns'], 2, 0], [(27925861, 1), [['Now you can do something like'], ['This will yield the rows in  data  ( df ) where  data.delivery  is equal to the value in  most_liquid_contracts  for that day.']], [[' combined[combined.delivery == combined.most]\n']], ['python pandas filter dataframe by another series, multiple columns'], 2, 0], [(27947419, 0), [["As soon as you talk of means and standard deviations for lots of data, you should start using any of the numerical libraries. Consider using numpy, or even pandas (for readability) here. I'll be using them in this example, together with the  Counter object from the collections module . Read up on both to see how they work, but I'll explain a bit throughout the code as well."], ["At this point, the layout of the  results  is two columns filled with the  chrom  ( results[:,0] ) and  pos  ( results[:,1] ) labels from the text file,\nthen 5 columns of population A, where the first of those 5 contains the relative frequency of the 'C' base, next\n column of the 'A' base and so on (see  nucleotid_bases  for the order). Then, the last 5 columns are similar, but they are for population B:"]], [[' import numpy as np\nfrom collections import Counter    \n\nnucleotid_bases = (\'C\', \'A\', \'T\', \'G\', \'.\')\nresults = []\nchecksum = []\nwith open(\'datafile.txt\') as f:\n    for line in f:\n        fields = line.split()  # splits by consecutive whitespace, empty records will be purged\n        chrom, pos = [int(fields[x]) for x in (0,1)]\n        results.append([chrom,pos])  # start by building the current record\n        allele1, allele2 = [fields[i] for i in (3,4)]\n        checksum.append([allele1, allele2])  # you wanted to keep these, most likely for debugging purposes?\n        popA = fields[3:26]  # population size: 2*23\n        popB = fields[26:36]  # population size: 2*10\n        for population in (popA, popB):\n            summary = Counter(population) # traverses the line only once - much more efficient!\n            base_counts = [ sum(summary[k] for k in summary.keys() if base in k) for base in nucleotid_bases]\n            for index, base_name in enumerate(nucleotid_bases):\n                # Double the count when there is an exact match, e.g. "A/A" -> "A"\n                # An \'in\' match can match an item anywhere in the string: \'A\' in \'A/C\' evaluates to True\n                base_counts[index] += summary[base_name]    \n            results[-1].extend(base_counts)  # append to the current record\nresults = np.array(results, dtype=np.float)  # shape is now (x, 12) with x the amount of lines read\nresults[:, 2:7] /= 46\nresults[:, 7:] /= 20\n']], ['How can I assign scores to a list of datapoints and then output values > 2 standard deviations from the mean in python?'], 5, 0], [(27947419, 1), [["At this point, the layout of the  results  is two columns filled with the  chrom  ( results[:,0] ) and  pos  ( results[:,1] ) labels from the text file,\nthen 5 columns of population A, where the first of those 5 contains the relative frequency of the 'C' base, next\n column of the 'A' base and so on (see  nucleotid_bases  for the order). Then, the last 5 columns are similar, but they are for population B:"], ['If you want to ignore records (rows) in this table where either of the unknowns-frequencies (columns 6 and 11) are above a threshold, you would do:']], [[' chrom, pos, freqC_in_A,..., freqG_in_A, freq_dot_in_A freqC_in_B, ..., freqG_in_B, freq_dot_in_B\n']], ['How can I assign scores to a list of datapoints and then output values > 2 standard deviations from the mean in python?'], 5, 0], [(27947419, 2), [['If you want to ignore records (rows) in this table where either of the unknowns-frequencies (columns 6 and 11) are above a threshold, you would do:'], ['Now you can compute the table of frequency differences with:']], [[' threshold = .1 # arbitrary: 10%\nto_consider = np.logical_and(results[:,6] < threshold, results[:,11] < threshold)\ntable = results[to_consider][:, [0,1,2,3,4,5,7,8,9,10]]\n']], ['How can I assign scores to a list of datapoints and then output values > 2 standard deviations from the mean in python?'], 5, 0], [(27947419, 3), [['Now you can compute the table of frequency differences with:'], ["Now you'll want to check if the  condition  was valid for any elements of the row, so e.g. if\nthe frequency difference for 'C' between popA and popB was .8 and the\n(mean+2*std) was .7, then it will return True. But it will also return True\nfor the same row if this condition was fulfilled for any of the other\nnucleotids. To check if the condition was True for any of the nucleotid frequency differences, do this:"]], [[' freq_diffs  = np.abs(table[:,2:6] - table[:,-4:])  # 4 columns, n rows\n\nmean_freq_diff = freq_diffs.mean(axis=0) # holds 4 numbers, these are the means over all the rows\nstd_freq_diff = freq_diffs.std(axis=0) # similar: std over all the rows\n\ncondition = freq_diffs > (mean_freq_diff + 2*std_freq_diff)\n']], ['How can I assign scores to a list of datapoints and then output values > 2 standard deviations from the mean in python?'], 5, 0], [(27947419, 4), [["Now you'll want to check if the  condition  was valid for any elements of the row, so e.g. if\nthe frequency difference for 'C' between popA and popB was .8 and the\n(mean+2*std) was .7, then it will return True. But it will also return True\nfor the same row if this condition was fulfilled for any of the other\nnucleotids. To check if the condition was True for any of the nucleotid frequency differences, do this:"], ['-10000']], [[' specials = np.any(condition, axis=1)  \nprint(table[specials, :2])\n']], ['How can I assign scores to a list of datapoints and then output values > 2 standard deviations from the mean in python?'], 5, 0], [(27960965, 0), [['a little bit more than the functionality for the example given is done'], ['usage:']], [[' from __future__ import print_function\nimport ast\n\ndef transform(eq,functions):\n    class EqVisitor(ast.NodeVisitor):\n        def visit_BinOp(self,node):\n            #generate("=>BinOp")\n            generate("(")\n            self.visit(node.left)\n            self.visit(node.op)\n            #generate("ici",str(node.op),node._fields,node._attributes)\n            #generate(dir(node.op))\n            self.visit(node.right)\n            generate(")")\n            #ast.NodeVisitor.generic_visit(self,node)\n        def visit_USub(self,node):\n            generate("-")\n        def visit_UAdd(self,node):\n            generate("+")\n\n        def visit_Sub(self,node):\n            generate("-")\n        def visit_Add(self,node):\n            generate("+")\n        def visit_Pow(self,node):\n            generate("**")\n        def visit_Mult(self,node):\n            generate("*")\n        def visit_Div(self,node):\n            generate("/")\n        def visit_Name(self,node):\n            generate(node.id)\n        def visit_Call(self,node):\n            debug("function",node.func.id)\n            if node.func.id in functions:\n                debug("defined function")\n                func_visit(functions[node.func.id],node.args)\n                return\n            debug("not defined function",node.func.id)    \n            #generate(node._fields)\n            #generate("args")\n            generate(node.func.id)\n            generate("(")\n            sep = ""\n            for arg in node.args:\n                generate (sep)\n                self.visit(arg)\n                sep=","\n            generate(")")\n        def visit_Num(self,node):\n            generate(node.n)\n        def generic_visit(self, node):\n\n\n            debug ("\\n",type(node).__name__)\n            debug (node._fields)\n            ast.NodeVisitor.generic_visit(self, node)  \n\n    def func_visit(definition,concrete_args):\n        class FuncVisitor(EqVisitor):\n            def visit_arguments(self,node):\n                #generate("visit arguments")\n                #generate(node._fields)\n                self.arguments={}\n                for concrete_arg,formal_arg in zip(concrete_args,node.args):\n                    #generate(formal_arg._fields)\n                    self.arguments[formal_arg.id]=concrete_arg\n                debug(self.arguments)\n            def visit_Name(self,node):\n                debug("visit Name",node.id)\n                if node.id in self.arguments:\n                    eqV.visit(self.arguments[node.id])\n                else:\n                    generate(node.id)\n\n\n        funcV=FuncVisitor()\n        funcV.visit(ast.parse(definition))\n\n    eqV=EqVisitor()\n    result = []\n    def generate(s):\n        #following line maybe usefull for debug\n        debug(str(s))\n        result.append(str(s))\n    eqV.visit(ast.parse(eq,mode="eval"))\n    return "".join(result)\ndef debug(*args,**kwargs):\n    #print(*args,**kwargs)\n    pass\n']], ['Parsing an equation with custom functions in python'], 3, 1], [(27960965, 1), [['usage:'], ['result']], [[' functions= {\n    "f1":"def f1(x,y):return x+y**2",\n    "f2":"def f2(x,y):return sin(x+y)",\n}\neq="-(a+b)+f1(f2(+x,y),z)*4/365.12-h"\nprint(transform(eq,functions))\n']], ['Parsing an equation with custom functions in python'], 3, 0], [(27996151, 1), [['so, for example:'], ['-10000']], [[" # paying $63.51\nx = 6351 // 1000      # == 6    maximum number of $10.00 bills\ny = 6351 % 1000       # == 351  $3.51 not payable in 10s.\n\n# you could instead do\ny = 6351 - (6351 // 1000) * 1000\n\n# this would give the same result,\n# but you've got to admit it's a lot\n# less readable.\n"]], ['Can someone please explain to me the way to calculate the number of bills and coins of change in python?'], 2, 1], [(28002993, 0), [['You can do it the slow way:'], ["You could add an index to your class that tracks maps ids and / or values to specific indices, but you'd need to keep that index up-to-date as you manipulate the contained list of orders. It'd look something like this:"]], [[' def remove(self, id=None, value=None):\n    for elem in self:\n        if (id is not None and elem.id == id or\n                value is not None and elem.value == value):\n            super(Orders, self).remove(elem)\n            break\n']], ['Remove namedtuple from list based on value'], 3, 1], [(28002993, 1), [["You could add an index to your class that tracks maps ids and / or values to specific indices, but you'd need to keep that index up-to-date as you manipulate the contained list of orders. It'd look something like this:"], ['and, provided you also adjust all other methods that can alter the list and change ordering, etc., you can then find orders quickly by their id:']], [[" def __init__(self, *args):\n    # ...\n    self._ids = {}\n\ndef append(self, id, value):\n    if id in ids:\n        raise ValueError('This order already exists!')\n    super(Orders, self).append(Order(id, value))\n    self._ids[id] = len(self) - 1\n"]], ['Remove namedtuple from list based on value'], 3, 0], [(28015044, 0), [['Starting from your  csv_dict , you can do something like '], ['Resulting  out.csv :']], [[" import csv\nimport itertools\n\ncsv_dict = {'label1': ['val1', 'val2', 'val3'],\n            'label2': ['otherval1', 'otherval2'],\n            'label3': ['yetanotherval1']}\nkeys = csv_dict.keys()\ncsvrows = itertools.izip_longest(*[csv_dict[k] for k in keys], fillvalue='dummy')\n\nwith open('out.csv', 'w') as csvfile:\n    csvwriter = csv.writer(csvfile, delimiter=';',\n                            quotechar='\\\\', quoting=csv.QUOTE_MINIMAL)\n    csvwriter.writerow(keys)\n    for row in csvrows:\n        csvwriter.writerow(row)\n"]], ['python - Nested list in dict to csv files'], 2, 1], [(28015044, 1), [['Resulting  out.csv :'], ['With the following remarks:']], [[' label1;label2;label3\nval1;otherval1;yetanotherval1\nval2;otherval2;dummy\nval3;dummy;dummy\n']], ['python - Nested list in dict to csv files'], 2, 0], [(28016212, 0), [['To advance more than one line, call  next  in a loop:'], ['-10000']], [[' for _ in range(times_to_advance):\n    next(file_object)\n']], ['Advance a file object more than one line as a way of skipping blank lines and lines containing strings'], 2, 1], [(28016212, 1), [['-10000'], ['-10000']], [[' from itertools import islice\nnext(islice(file_object, times_to_advance, times_to_advance), None)\n']], ['Advance a file object more than one line as a way of skipping blank lines and lines containing strings'], 2, 1], [(28020874, 0), [['You could do this by creating an  (n, m, m, ..., m)  array of indices for  column 1, column 2, ..., column n  using  np.indices() , then reshaping the output into an  (n ** m, n)  array:'], ['For example:']], [[' import numpy as np\n\ndef permgrid(m, n):\n    inds = np.indices((m,) * n)\n    return inds.reshape(n, -1).T\n']], ['Permutation of values on numpy array/matrix'], 2, 1], [(28020874, 1), [['For example:'], ['-10000']], [[' print(permgrid(2, 3))\n\n# [[0 0 0]\n#  [0 0 1]\n#  [0 1 0]\n#  [0 1 1]\n#  [1 0 0]\n#  [1 0 1]\n#  [1 1 0]\n#  [1 1 1]]\n']], ['Permutation of values on numpy array/matrix'], 2, 0], [(28036818, 0), [['Depending on exactly what you mean by "a hex string", it should be easy.  E.g:'], ['Now you have to decide how you want to represent this list of small integers.   array.array  would be best, or, as a bytestring:']], [[" >>> text=b'Hello World'\n>>> hexi=b'\\12\\34\\45\\EF\\CD\\AB'\n>>> xors=[ord(t)^ord(x) for t,x in zip(text,hexi)]\n>>> xors\n[66, 121, 73, 48, 42, 102, 11, 44, 54, 48, 37]\n"]], ['How to xor in python using hex'], 2, 1], [(28036818, 1), [['Now you have to decide how you want to represent this list of small integers.   array.array  would be best, or, as a bytestring:'], ['(this would show with a leading  b  in Python 3, where the distinction between strings of bytes and actual text is clearer and sharper, but all the code I show here works otherwise the same in Python 2 and 3).']], [[" >>> b''.join(chr(x) for x in xors)\n'ByI0*f\\x0b,60%'\n"]], ['How to xor in python using hex'], 2, 0], [(28059257, 0), [['To achieve #1, you could define a simple setter method in your proxy model class:'], ["You would also need to of course invoke that setter within your  MyWindow  class's constructor:"]], [[' def setView(self, view):\n    self._view = view\n']], ['How to select QTableView index or row from inside of Model'], 7, 0], [(28059257, 1), [["You would also need to of course invoke that setter within your  MyWindow  class's constructor:"], ["Achieving #2 is a simple matter of creating this attribute in the proxy model class's constructor"]], [[' proxyModel.setView(self.tableview)\n']], ['How to select QTableView index or row from inside of Model'], 7, 0], [(28059257, 2), [["Achieving #2 is a simple matter of creating this attribute in the proxy model class's constructor"], ["Now that your classes are prepared, you can implement your desired behavior. In your  filterAcceptsRow()  re-implementation, you only want to select the rows if they contain  '_B_'  and is the filter is active (that is, the button was clicked):"]], [[' self.filterActive = False\n']], ['How to select QTableView index or row from inside of Model'], 7, 0], [(28059257, 3), [["Now that your classes are prepared, you can implement your desired behavior. In your  filterAcceptsRow()  re-implementation, you only want to select the rows if they contain  '_B_'  and is the filter is active (that is, the button was clicked):"], ["Finally, you want to make sure that these conditions are met once the button is clicked, so in your clicked() method you need to set the  proxyModel 's  filterActive  attribute to True and you need to call the  QSortFilterProxyModel  class's  invalidateFilter()  method to indicate that the existing filter is invalid and therefore  filterAcceptsRow()  should be called again:"]], [[" def filterAcceptsRow(self, row, parent):\n    if self.filterActive and '_B_' in self.sourceModel().data(self.sourceModel().index(row, 0), Qt.DisplayRole).toPyObject():\n        self._view.selectRow(row)\n    return True\n"]], ['How to select QTableView index or row from inside of Model'], 7, 0], [(28059257, 4), [["Finally, you want to make sure that these conditions are met once the button is clicked, so in your clicked() method you need to set the  proxyModel 's  filterActive  attribute to True and you need to call the  QSortFilterProxyModel  class's  invalidateFilter()  method to indicate that the existing filter is invalid and therefore  filterAcceptsRow()  should be called again:"], ['So the new code, in full, is:']], [[' def clicked(self, arg):\n    proxyModel=self.tableview.model()\n    self.tableview.clearSelection()\n    proxyModel.filterActive = True\n    proxyModel.invalidateFilter()\n']], ['How to select QTableView index or row from inside of Model'], 7, 0], [(28059257, 5), [['So the new code, in full, is:'], ['Having said all of that, the purpose of  filterAcceptsRow()  is so that you can implement your own custom  filtering  in a subclass of  QSortFilterProxyModel . So, a more typical implementation (following your desired rule) would be:']], [[' from PyQt4.QtCore import *\nfrom PyQt4.QtGui import *\nimport sys\n\nclass Model(QAbstractTableModel):\n    def __init__(self, parent=None, *args):\n        QAbstractTableModel.__init__(self, parent, *args)\n        self.items = [\'Item_A_001\',\'Item_A_002\',\'Item_B_001\',\'Item_B_002\']\n\n    def rowCount(self, parent=QModelIndex()):\n        return len(self.items)       \n    def columnCount(self, parent=QModelIndex()):\n        return 1\n\n    def data(self, index, role):\n        if not index.isValid(): return QVariant()\n        elif role != Qt.DisplayRole:\n            return QVariant()\n\n        row=index.row()\n        if row<len(self.items):\n            return QVariant(self.items[row])\n        else:\n            return QVariant()\n\nclass Proxy(QSortFilterProxyModel):\n    def __init__(self):\n        super(Proxy, self).__init__()\n        self.filterActive = False\n\n    def setView(self, view):\n        self._view = view\n\n    def filterAcceptsRow(self, row, parent):\n        if self.filterActive and \'_B_\' in self.sourceModel().data(self.sourceModel().index(row, 0), Qt.DisplayRole).toPyObject():\n            self._view.selectRow(row)\n        return True\n\nclass MyWindow(QWidget):\n    def __init__(self, *args):\n        QWidget.__init__(self, *args)\n\n        tableModel=Model(self)               \n\n        proxyModel=Proxy()\n        proxyModel.setSourceModel(tableModel)\n\n        self.tableview=QTableView(self) \n        self.tableview.setModel(proxyModel)\n        self.tableview.horizontalHeader().setStretchLastSection(True)\n        self.tableview.setSelectionMode(QAbstractItemView.MultiSelection)\n\n        proxyModel.setView(self.tableview)\n\n        button=QPushButton(self)\n        button.setText(\'Select Items with B\')\n        button.clicked.connect(self.clicked)\n\n        layout = QVBoxLayout(self)\n        layout.addWidget(self.tableview)\n        layout.addWidget(button)\n        self.setLayout(layout)\n\n    def clicked(self, arg):\n        proxyModel=self.tableview.model()\n        self.tableview.clearSelection()\n        proxyModel.filterActive = True\n        proxyModel.invalidateFilter()\n\nif __name__ == "__main__":\n    app = QApplication(sys.argv)\n    w = MyWindow()\n    w.show()\n    sys.exit(app.exec_())\n']], ['How to select QTableView index or row from inside of Model'], 7, 1], [(28067258, 1), [['Then to access all days between  two_bdays_before  and  two_bdays_later :'], ['-10000']], [[' >>> df[two_bdays_before:two_bdays_later]]\n                   A         B         C         D\n2015-01-01  0.741045 -0.051576  0.228247 -0.429165\n2015-01-02 -0.312247 -0.391012 -0.256515 -0.849694\n2015-01-03 -0.581522 -1.472528  0.431249  0.673033\n2015-01-04 -1.408855  0.564948  1.019376  2.986657\n2015-01-05 -0.566606 -0.316533  1.201412 -1.390179\n2015-01-06 -0.052672  0.293277 -0.566395 -1.591686\n2015-01-07 -1.669806  1.699540  0.082697 -1.229178\n']], ['python pandas Slicing datetime dates by number of rows'], 2, 0], [(28072914, 0), [['1) You can implement a UDP server which processes incoming messages in\nan infinite loop much more simply with these lines of code:'], ['And kicking this off into its own thread is very easily acccomplished\nwith:']], [['  import socket\n\n def udp_server(udp_ip, udp_port, ...):\n   sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n   sock.bind((upd_ip, upd_port))\n   while True:\n     data, addr = sock.recvfrom(1024) # buffer size is 1024 bytes\n     ...process data...\n']], ['Data structure for UDP Server parsing JSON objects in python'], 5, 0], [(28072914, 1), [['And kicking this off into its own thread is very easily acccomplished\nwith:'], ['To summarize, where is how I would write the code:']], [['  import threading\n\n t = threading.Thread(target = udp_server, args = (...))\n t.start()\n']], ['Data structure for UDP Server parsing JSON objects in python'], 5, 0], [(28072914, 2), [['To summarize, where is how I would write the code:'], ['Does the main thread need to be informed when new nodes have been added to\nthe node table? Then perhaps a Queue is what you want. You would 1) create it\nin  main()  and 2) pass it to  udp_server :']], [['  def main():\n   nodes = {}     # use a simple dict for storing the nodes\n   lock = RLock() # if you need this\n   # pass nodes and lock to server thread and start it\n   t = threading.Thread(target = udp_server, args = (udp_ip, udp_port, nodes, lock))\n   t.start() \n   ...\n']], ['Data structure for UDP Server parsing JSON objects in python'], 5, 0], [(28072914, 3), [['Does the main thread need to be informed when new nodes have been added to\nthe node table? Then perhaps a Queue is what you want. You would 1) create it\nin  main()  and 2) pass it to  udp_server :'], ['and in the udp server function  ...process data...  will put something onto the queue:']], [['  def main()\n   nodes = {}     # use a simple dict for storing the nodes\n   lock = RLock() # if you need this\n   q = Queue()    # create a Queue and pass it to the udp server\n   # pass nodes and lock to server thread and start it\n   t = threading.Thread(target = udp_server, args = (udp_ip, udp_port, nodes, lock, q))\n   t.start() \n   # process entries from the Queue\n   while True:\n     item = q.get()\n     ... process item...\n']], ['Data structure for UDP Server parsing JSON objects in python'], 5, 0], [(28072914, 4), [['and in the udp server function  ...process data...  will put something onto the queue:'], ['-10000']], [['    while True:\n     data, addr = sock.recvfrom(1024) # buffer size is 1024 bytes\n     ...json decode, etc. ...\n     q.put(...) \n']], ['Data structure for UDP Server parsing JSON objects in python'], 5, 0], [(28076006, 0), [['This will add them to the list:'], ['But I would change your first line as well to:']], [[" scores.append({'name': name, 'score': score})\n"]], ['How to store a name and score into a list?'], 3, 1], [(28076006, 1), [['But I would change your first line as well to:'], ['Alternatively, if you want to keep them as a string, just do this:']], [[" scores = [{'Name':'Sam': 'Score':10}]\n"]], ['How to store a name and score into a list?'], 3, 0], [(28083576, 0), [['Just judge if a node is a leaf and add the sum to the weight, here is an example:'], ['OutPut:']], [[' class Node:\n    def __init__(self, name, weight, children):\n        self.children = children\n        self.weight = weight\n        self.weight_plus_children = weight\n\n    def get_all_weight(self):\n        if self.children is None:\n          return self.weight_plus_children\n        else:\n          for child in self.children:\n            print "child.get_all_weight()", child.get_weigth_with_children()\n            self.weight_plus_children += child.get_weigth_with_children()\n\n        return self.weight_plus_children\n\n    def get_weigth_with_children(self):\n        return self.weight_plus_children\n\nleaf1 = Node(\'C1\', 58, None)\nleaf2 = Node(\'C2\', 7, None)\nleaf3 = Node(\'C3\', 10, None)\nleaf4 = Node(\'C4\', 20, None)\n\nsubroot = Node(\'B1\', 50, [leaf1, leaf2])\nsubroot1 = Node(\'B2\', 50, [leaf3, leaf4])\n\nroot = Node(\'A\', 100, [subroot, subroot1])\n\nprint subroot.get_all_weight()\nprint\nprint subroot1.get_all_weight()\nprint\nprint root.get_all_weight()\n']], ['How to recursively sum and store all child values in a tree'], 2, 1], [(28083576, 1), [['OutPut:'], ['-10000']], [[' F:\\so>python test-tree.py\nchild.get_all_weight() 58\nchild.get_all_weight() 7\n115\n\nchild.get_all_weight() 10\nchild.get_all_weight() 20\n80\n\nchild.get_all_weight() 115\nchild.get_all_weight() 80\n295\n']], ['How to recursively sum and store all child values in a tree'], 2, 0], [(28104377, 0), [["Your code is broken:  u.read()  returns  bytes  object.  str(bytes_object)  returns a string  representation  of the object (how the bytes literal would look like) -- you don't want it here:"], ['Either save the bytes on disk as is:']], [[' >>> str(b\'\\xe2\\x86\\x90\')\n"b\'\\\\xe2\\\\x86\\\\x90\'"\n']], ['how to convert UTF-8 code to symbol characters in python'], 4, 0], [(28104377, 1), [['Either save the bytes on disk as is:'], ["or open the file in binary mode:  'wb'  and save it manually:"]], [[" import urllib.request\n\nurllib.request.urlretrieve('http://stackoverflow.com', 'so.html')\n"]], ['how to convert UTF-8 code to symbol characters in python'], 4, 1], [(28104377, 2), [["or open the file in binary mode:  'wb'  and save it manually:"], ['or convert bytes to Unicode and save them to disk using any encoding you like.']], [[" import shutil\nfrom urllib.request import urlopen\n\nwith urlopen('http://stackoverflow.com') as u, open('so.html', 'wb') as file:\n    shutil.copyfileobj(u, file)\n"]], ['how to convert UTF-8 code to symbol characters in python'], 4, 1], [(28104377, 3), [['or convert bytes to Unicode and save them to disk using any encoding you like.'], ['-10000']], [[" import io\nimport shutil\nfrom urllib.request import urlopen\n\nwith urlopen('http://stackoverflow.com') as u, \\\n     open('so.html', 'w', encoding='utf-8', newline='') as file, \\\n     io.TextIOWrapper(u, encoding=u.headers.get_content_charset('utf-8'), newline='') as t:\n    shutil.copyfileobj(t, file)\n"]], ['how to convert UTF-8 code to symbol characters in python'], 4, 1], [(28176483, 0), [['You can do a simple list comprehension'], ['If your list is always like that, then you can use strides']], [[' >>> n = 3\n>>> l = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n>>> [i for i in l if i%n==0]\n[0, 3, 6, 9]\n']], ['Extract a value out of n'], 3, 1], [(28176483, 2), [['Use  range  to generate lists like that'], ['-10000']], [[' >>> range(10)\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n']], ['Extract a value out of n'], 3, 0], [(28187921, 0), [['I suspect that your sparse matrices are becoming non sparse when you perform the operation have you tried just:'], ['If A is not already the correct type of sparse matrix you might need:']], [[' A.multiply(B)\n']], ['Scipy sparse matrices element wise multiplication'], 2, 1], [(28198883, 0), [['Define a function to generate invoice number.'], ['Now use this function as default value in your model filed.']], [[" def increment_invoice_number():\n    last_invoice = Invoice.objects.all().order_by('id').last()\n    if not last_invoice:\n         return 'MAG0001'\n    invoice_no = last_invoice.invoice_no\n    invoice_int = int(invoice_no.split('MAG')[-1])\n    new_invoice_int = invoice_int + 1\n    new_invoice_no = 'MAG' + str(new_invoice_int)\n    return new_invoice_no\n"]], ['Auto increament the invoice number in django backend for new invoice'], 2, 0], [(28198883, 1), [['Now use this function as default value in your model filed.'], ['This is just an idea. Modify the function to match your preferred invoice number format.']], [[' invoice_no = models.CharField(max_length=500, default=increment_invoice_number, null=True, blank=True)\n']], ['Auto increament the invoice number in django backend for new invoice'], 2, 0], [(28199359, 0), [['-10000'], ['Consider this single-threaded code:']], [[' l = [0]\n']], ['Python: sharing a list between threads'], 2, 0], [(28199359, 1), [['Consider this single-threaded code:'], ['Notice how  b[0] = 2  and  b = [0]  differ. In the first one, the object to which  b  is bound is modified. In the second,  b  is bound to a whole new object.']], [[' a = b = [1]  # a and b are both bound to the same list\nprint a,b    # [1] [1]\nb[0] = 2     # modifies the object to which a and b are bound\nprint a,b    # [2] [2]\nb = [0]      # now b is bound to a new list\nprint a,b    # [2] [0]\n']], ['Python: sharing a list between threads'], 2, 0], [(28208430, 0), [['If you are working with NumPy arrays, it is quite simple:'], ['If you have lists, you could do:']], [[' a = np.array([[1,2,3],[4,5,6],[7,8,9]])\nnp.random.random(a.shape)\n']], ['numpy random numpers in specified shape of any complexity'], 2, 1], [(28208430, 1), [['If you have lists, you could do:'], ['-10000']], [[' import random\n\ndef shaperand(s):\n    return [shaperand(e) if isinstance(e, list) else random.random() for e in s]\n']], ['numpy random numpers in specified shape of any complexity'], 2, 1], [(28244029, 0), [["Answering my own question.\nShort answer is Threading will do it. It is also unnecessary. The subprocess module has enough for me to make it work. I just wasn't doing it right"], ["For those who care threading route did get me to a certain point and I'll add that but I didn't go to the last condition since well... I found the easier route"]], [[" RunSer2Command(lines2[21])\ntime.sleep(1)   \nls_output = subprocess.Popen(['tcpclient.exe','192.168.4.110','8000','10000','1400'],stdin=subprocess.PIPE,stdout=subprocess.PIPE,bufsize=3)\ntime.sleep(2)\nRunSer2Command(lines2[22])\nRunSer2Command(lines2[23])\ntime.sleep(1)\nls_output.communicate(input = '3')\nls_output.wait()\nRunSer2Command(lines2[24])\n"]], ['Using multiple programs simultaneously in Python'], 2, 1], [(28244029, 1), [["For those who care threading route did get me to a certain point and I'll add that but I didn't go to the last condition since well... I found the easier route"], ["I still havent managed to work out all the kinks. There appear to be some timing issues. I'll update it once I get it working perfectly."]], [[" def start_tcp_client(cond): \n    ls_output = subprocess.Popen(['tcpclient.exe','192.168.4.110','8000','1000','1400'],stdin=subprocess.PIPE,stdout=subprocess.PIPE,bufsize=3)\n    with cond:\n        cond.wait()\n        ls_output.communicate(input = '3')\n        ls_output.communicate()\n\ndef TCPSettings(cond):\n    with cond:\n        RunSer2Command(lines2[22])\n        RunSer2Command(lines2[23])\n        cond.notify()\n\n    condition = threading.Condition()\n    condition1 = threading.Condition()\n    Client_thread=threading.Thread(name='Client_thread', target=start_tcp_client, args=(condition,))\n    TCP_thread=threading.Thread(name='TCP_thread', target=TCPSettings, args=(condition,))\n    RunSer2Command(lines2[21])\n    time.sleep(2)   \n    Client_thread.start()\n    time.sleep(2)\n    TCP_thread.start()\n    time.sleep(1)\n    Client_thread.join()\n    time.sleep(10)\n    RunSer2Command(lines2[24])\n"]], ['Using multiple programs simultaneously in Python'], 2, 1], [(28246655, 0), [['The following assumes that the columns to compare have the same names.'], ['Eg.']], [[' def temp(row):\n    index = df2[((row-df2).abs() < .3).all(axis=1)].index\n    return df2.loc[index[0], :] if len(index) else [None]*df2.shape[1]\n']], ['Pandas Datframe1 search for match in range of Dataframe2'], 3, 1], [(28246655, 1), [['Eg.'], ['produces']], [[' df1 = pd.DataFrame([[1,2],[3,4], [5,6]], columns=["d1", "d2"])\ndf2 = pd.DataFrame([[1.1,1.9],[3.2,4.3]], columns=["d1", "d2"])\ndf1.apply(temp, axis=1)\n']], ['Pandas Datframe1 search for match in range of Dataframe2'], 3, 0], [(28246655, 2), [['produces'], ['-10000']], [['     d1   d2\n0  1.1  1.9\n1  3.2  4.3\n2  NaN  NaN\n']], ['Pandas Datframe1 search for match in range of Dataframe2'], 3, 0], [(28255693, 0), [['If you are producing combinations of 3 elements from a large list, then just pick samples of 3:'], ['Instead of:']], [[' def random_combinations_sample(lst, element_count, sample_size):\n    result = set()\n    while len(result) < sample_size:\n        indices = random.sample(xrange(len(lst)), element_count)\n        sample = tuple(lst[i] for i in sorted(indices))\n        result.add(sample)\n    return list(result)\n']], ['Randomize a generator'], 3, 1], [(28255693, 1), [['Instead of:'], ["you'd use"]], [[' random.sample(itertools.combinations(a_large_set, 3), 10)\n']], ['Randomize a generator'], 3, 0], [(28255693, 2), [["you'd use"], ['-10000']], [[' random_combinations_sample(a_large_set, 3, 10)\n']], ['Randomize a generator'], 3, 0], [(28257632, 0), [['You could try:'], ["However,  int.from_bytes(bytes_input, 'big')  is the most time consuming part of that code snippet by a factor 2 to 1. If you can convert your data from  bytes  to  int  once, at the beginning of the program, then you will see quicker bit masking operations."]], [[" (int.from_bytes(bytes_input, 'big') >> bit_position) & 0b11\n"]], ['In Python how do I parse the 11th and 12th bit of 3 bytes?'], 2, 1], [(28257632, 1), [["However,  int.from_bytes(bytes_input, 'big')  is the most time consuming part of that code snippet by a factor 2 to 1. If you can convert your data from  bytes  to  int  once, at the beginning of the program, then you will see quicker bit masking operations."], ['-10000']], [[" In [52]: %timeit n = int.from_bytes(bytes_input, 'big')\n1000000 loops, best of 3: 237 ns per loop\n\nIn [53]: %timeit n >> bit_position & 0b11\n10000000 loops, best of 3: 107 ns per loop\n"]], ['In Python how do I parse the 11th and 12th bit of 3 bytes?'], 2, 1], [(28267563, 0), [['First level:'], ['Second level:']], [[" SELECT t1.alt_bilesen\n  FROM urunler_seviyeler t1 \n WHERE t1.parcano = 'E40'\n"]], ['MySQL select all components of a product'], 5, 0], [(28267563, 1), [['Second level:'], ['Third level:']], [[" SELECT t2.alt_bilesen\n  FROM urunler_seviyeler t1\n  JOIN urunler_seviyeler t2\n    ON t2.parcano = t1.alt_bilesen\n WHERE t1.parcano = 'E40'\n"]], ['MySQL select all components of a product'], 5, 0], [(28267563, 2), [['Third level:'], ['Fourth level:']], [[" SELECT t3.alt_bilesen\n  FROM urunler_seviyeler t1\n  JOIN urunler_seviyeler t2 ON t2.parcano = t1.alt_bilesen\n  JOIN urunler_seviyeler t3 ON t3.parcano = t2.alt_bilesen\n WHERE t1.parcano = 'E40'\n"]], ['MySQL select all components of a product'], 5, 0], [(28267563, 3), [['Fourth level:'], ['It is possible to combine the queries with  UNION ALL  set operators']], [[" SELECT t4.alt_bilesen\n  FROM urunler_seviyeler t1\n  JOIN urunler_seviyeler t2 ON t2.parcano = t1.alt_bilesen\n  JOIN urunler_seviyeler t3 ON t3.parcano = t2.alt_bilesen\n  JOIN urunler_seviyeler t4 ON t4.parcano = t3.alt_bilesen\n WHERE t1.parcano = 'E40'\n"]], ['MySQL select all components of a product'], 5, 0], [(28267563, 4), [['It is possible to combine the queries with  UNION ALL  set operators'], ['-10000']], [[" ( SELECT t1.alt_bilesen\n    FROM urunler_seviyeler t1 \n   WHERE t1.parcano = 'E40'\n)\nUNION ALL\n( SELECT t2.alt_bilesen\n    FROM urunler_seviyeler t1\n    JOIN urunler_seviyeler t2\n      ON t2.parcano = t1.alt_bilesen\n   WHERE t1.parcano = 'E40'\n)\nUNION ALL\n( SELECT t3.alt_bilesen\n   FROM urunler_seviyeler t1\n   JOIN urunler_seviyeler t2 ON t2.parcano = t1.alt_bilesen\n   JOIN urunler_seviyeler t3 ON t3.parcano = t2.alt_bilesen\n  WHERE t1.parcano = 'E40'\n) \nUNION ALL\n( SELECT t4.alt_bilesen\n    FROM urunler_seviyeler t1\n    JOIN urunler_seviyeler t2 ON t2.parcano = t1.alt_bilesen\n    JOIN urunler_seviyeler t3 ON t3.parcano = t2.alt_bilesen\n    JOIN urunler_seviyeler t4 ON t4.parcano = t3.alt_bilesen\n   WHERE t1.parcano = 'E40'\n)\nORDER BY 1\n"]], ['MySQL select all components of a product'], 5, 1], [(28280507, 0), [['Here I basically use your model, but:\n1) changed the name of the FK column\n1) added a  relationship  (please read  Relationship Configuration  part of the documentation)'], ['With this you are able to get the name of the region as below:']], [[" class Person(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String(100))\n    # @note: renamed the column, so that can use the name 'region' for\n    # relationship\n    region_id = db.Column(db.Integer, db.ForeignKey('region.id'))\n\n    # define relationship\n    region = db.relationship('Region', backref='people')\n\n\nclass Region(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String(50))\n"]], ['setup relationship one-to-one in Flask + SQLAlchemy'], 3, 1], [(28280507, 1), [['With this you are able to get the name of the region as below:'], ['In order to make sure that the region is loaded from the database at the same time as the person is, you can use  joinedload  option:']], [[" region_name = my_person.region.name  # navigate a 'relationship' and get its 'name' attribute\n"]], ['setup relationship one-to-one in Flask + SQLAlchemy'], 3, 0], [(28280507, 2), [['In order to make sure that the region is loaded from the database at the same time as the person is, you can use  joinedload  option:'], ['-10000']], [[' p = (db.session.query(Person)\n     .options(db.eagerload(Person.region))\n     .get(1)\n     )\n\nprint(p)\n# below will not trigger any more SQL, because `p.region` is already loaded\nprint(p.region.name)\n']], ['setup relationship one-to-one in Flask + SQLAlchemy'], 3, 0], [(28306700, 0), [['The updated code below now features a function designed to do exactly what you want.'], ['Output:']], [[' from collections import Counter\nfrom operator import attrgetter\n\nclass Record(object):\n    def __init__(self, **kwargs):\n        for key, value in kwargs.iteritems():\n             setattr(self, key, value)\n\nrecords = [Record(uid=\'001\', url=\'www.google.com\', status=200),\n           Record(uid=\'002\', url=\'www.google.com\', status=404),\n           Record(uid=\'339\', url=\'www.ciq.com\',    status=200)]\n\ndef count_attr(attr, records):\n    """ Returns Counter keyed by unique values of attr in records sequence. """\n    get_attr_from = attrgetter(attr)\n    return Counter(get_attr_from(r) for r in records)\n\nfor attr in (\'status\', \'url\'):\n    print(\'{!r:>8}: {}\'.format(attr, count_attr(attr, records)))\n']], ['Python how to use Counter on objects according to attributes'], 2, 1], [(28306700, 1), [['Output:'], ['-10000']], [[" 'status': Counter({200: 2, 404: 1})\n   'url': Counter({'www.google.com': 2, 'www.ciq.com': 1})\n"]], ['Python how to use Counter on objects according to attributes'], 2, 0], [(28330317, 1), [["Here's a boilerplate procedure I use:"], ['-10000']], [[" import logging\n\ndef setup_custom_logger(name):\n    formatter = logging.Formatter(fmt='%(asctime)s %(levelname)-8s %(message)s',\n                                  datefmt='%Y-%m-%d %H:%M:%S')\n    handler = logging.FileHandler('log.txt', mode='w')\n    handler.setFormatter(formatter)\n    screen_handler = logging.StreamHandler(stream=sys.stdout)\n    screen_handler.setFormatter(formatter)\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n    logger.addHandler(handler)\n    logger.addHandler(screen_handler)\n    return logger\n\n>>> logger = setup_custom_logger('myapp')\n>>> logger.info('This is a message!')\n2015-02-04 15:07:12 INFO     This is a message!\n>>> logger.error('Here is another')\n2015-02-04 15:07:30 ERROR    Here is another\n"]], ['Print timestamp for logging in Python'], 2, 1], [(28332217, 0), [['First, the setup:'], ['Then you can plot it at all, using different initial conditions for N1 and N2:']], [[' import numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\n\ntime=np.linspace(0,15,5*1024)\n\ndef derivN(N, t):\n    """Return the derivative of the vector N, which represents\n    the tuple (N1, N2). """\n\n    N1, N2  = N\n    return np.array([N1*(1 - N1 - .7*N2), N2*(1 - N2 - .3*N1)])\n\ndef coupled(time, init, ax):\n    """Visualize the system of coupled equations, by passing a timerange and\n    initial conditions for the coupled equations.\n\n    The initical condition is the value that (N1, N2) will assume at the first\n    timestep. """\n\n    N = integrate.odeint(derivN, init, time)\n    ax[0].plot(N[:,0], N[:,1], label=\'[{:.1f}, {:.1f}]\'.format(*init))  # plots N2 vs N1, with time as an implicit parameter\n    l1, = ax[1].plot(time, N[:,0], label=\'[{:.1f}, {:.1f}]\'.format(*init))\n    ax[1].plot(time, N[:,1], color=l1.get_color())\n']], ['Solve Lotka-Volterra model using SciPy'], 2, 0], [(28332217, 1), [['Then you can plot it at all, using different initial conditions for N1 and N2:'], ['']], [[" fh, ax = plt.subplots(1,2)\ncoupled(time, [.3, 1/.7], ax)\ncoupled(time, [.4, 1/.7], ax)\ncoupled(time, [1/.7, .3], ax)\ncoupled(time, [.5, .5], ax)\ncoupled(time, [.1, .1], ax)\nax[0].legend()\nax[1].legend()\nax[0].set_xlabel('N1')\nax[0].set_ylabel('N2')\nax[1].set_xlabel('time')\nax[1].set_ylabel(r'$N_i$')\nax[0].set_title('implicit')\nax[1].set_title('explicit (i.e. vs independant variable time)')\nplt.show()\n"]], ['Solve Lotka-Volterra model using SciPy'], 2, 0], [(28348300, 1), [['You will also be able to test these more easily. \n \nIf you are determined to do the plotting inside, you could pass in a plot function:'], ['This would allow you to control which function shows where.']], [[' def random(x, show):\n    variable_x = x\n    result = f(x)\n    show(result)\n\ndef show(result):\n    plt.plot(result, x)\n    plt.show()\n\nresult = random(x, show)\n']], ['Is there a way to create a subplot that contains plots created inside functions?'], 2, 1], [(28348485, 0), [['Create a number phrase as such:'], ['[out]:']], [[' import nltk\n\ngroucho_grammar = nltk.CFG.fromstring("""\nS -> NP VP\nPP -> P NP\nNP -> Det N | Det N PP | \'I\' | NUM N\nVP -> V NP | VP PP\nDet -> \'an\' | \'my\'\nN -> \'elephant\' | \'pajamas\' | \'elephants\'\nV -> \'shot\'\nP -> \'in\'\nNUM -> \'0\' | \'1\' | \'2\' | \'3\' | \'4\' | \'5\' | \'6\' | \'7\' | \'8\' | \'9\' | \'10\'\n""")\n\nsent = \'I shot 3 elephants\'.split()\nparser = nltk.ChartParser(groucho_grammar)\nfor tree in parser.parse(sent):\n    print(tree)\n']], ['How to match integers in NLTK CFG?'], 6, 1], [(28348485, 1), [['[out]:'], ["But note that that can only handle single digit number. So let's try compressing integers into a single token-type, e.g. '#NUM#':"]], [[' (S (NP I) (VP (V shot) (NP (NUM 3) (N elephants))))\n']], ['How to match integers in NLTK CFG?'], 6, 0], [(28348485, 2), [["But note that that can only handle single digit number. So let's try compressing integers into a single token-type, e.g. '#NUM#':"], ['[out]:']], [[' import nltk\n\ngroucho_grammar = nltk.CFG.fromstring("""\nS -> NP VP\nPP -> P NP\nNP -> Det N | Det N PP | \'I\' | NUM N\nVP -> V NP | VP PP\nDet -> \'an\' | \'my\'\nN -> \'elephant\' | \'pajamas\' | \'elephants\'\nV -> \'shot\'\nP -> \'in\'\nNUM -> \'#NUM#\'\n""")\n\nsent = \'I shot 333 elephants\'.split()\nsent = [\'#NUM#\' if i.isdigit() else i for i in sent]\n\nparser = nltk.ChartParser(groucho_grammar)\nfor tree in parser.parse(sent):\n    print(tree)\n']], ['How to match integers in NLTK CFG?'], 6, 1], [(28348485, 3), [['[out]:'], ['To put the numbers back, try:']], [[' (S (NP I) (VP (V shot) (NP (NUM #NUM#) (N elephants))))\n']], ['How to match integers in NLTK CFG?'], 6, 0], [(28348485, 4), [['To put the numbers back, try:'], ['[out]:']], [[' import nltk\n\ngroucho_grammar = nltk.CFG.fromstring("""\nS -> NP VP\nPP -> P NP\nNP -> Det N | Det N PP | \'I\' | NUM N\nVP -> V NP | VP PP\nDet -> \'an\' | \'my\'\nN -> \'elephant\' | \'pajamas\' | \'elephants\'\nV -> \'shot\'\nP -> \'in\'\nNUM -> \'#NUM#\'\n""")\n\noriginal_sent = \'I shot 333 elephants\'.split()\nsent = [\'#NUM#\' if i.isdigit() else i for i in original_sent]\nnumbers = [i for i in original_sent if i.isdigit()]\n\nparser = nltk.ChartParser(groucho_grammar)\nfor tree in parser.parse(sent):\n    treestr = str(tree)\n    for n in numbers:\n        treestr = treestr.replace(\'#NUM#\', n, 1)\n    print(treestr)\n']], ['How to match integers in NLTK CFG?'], 6, 1], [(28348485, 5), [['[out]:'], ['-10000']], [[' (S (NP I) (VP (V shot) (NP (NUM 333) (N elephants))))\n']], ['How to match integers in NLTK CFG?'], 6, 0], [(28348838, 0), [['Make the string a raw string'], ['Or as  Avinash  suggests, Use word boundaries  \\b . They are better as they would help you ignore digits that are not two digits, like  3456']], [[' >>> re.sub(r"\'(\\d\\d)", r"19\\1", "Today \'45")\n\'Today 1945\'\n']], ["Python replace year mentions like '85 with 1985"], 2, 1], [(28348838, 1), [['Or as  Avinash  suggests, Use word boundaries  \\b . They are better as they would help you ignore digits that are not two digits, like  3456'], ['-10000']], [[' >>> re.sub(r"\'(\\d{2})\\b", r"19\\1", "Today \'45, \'3456")\n"Today 1945, \'3456"\n']], ["Python replace year mentions like '85 with 1985"], 2, 1], [(28356451, 0), [['From the docs:'], ['Then use the service:']], [[" from apiclient.discovery import build\n\ndef build_service(credentials):\n  http = httplib2.Http()\n  http = credentials.authorize(http)\n  return build('drive', 'v2', http=http)\n"]], ['How to request a File in Google Drive'], 2, 0], [(28356451, 1), [['Then use the service:'], ['-10000']], [[" from apiclient import errors\ntry:\n  service = build_service(### Credentials here ###)\n  file = service.files().get(fileId=file_id).execute()\n\n  print 'Title: %s' % file['title']\n  print 'Description: %s' % file['description']\n  print 'MIME type: %s' % file['mimeType']\nexcept errors.HttpError, error:\n  if error.resp.status == 401:\n    # Credentials have been revoked.\n    # TODO: Redirect the user to the authorization URL.\n    raise NotImplementedError()\n"]], ['How to request a File in Google Drive'], 2, 0], [(28364676, 0), [['You can send  some  signals on Windows e.g.:'], ['You could use  threading.Timer  to call a function at a later time:']], [[' os.kill(os.getpid(), signal.CTRL_C_EVENT) # send Ctrl+C to itself\n']], ['Timeout function in Python'], 3, 0], [(28364676, 1), [['You could use  threading.Timer  to call a function at a later time:'], ['where  kill_yourself_now() :']], [[" from threading import Timer\n\ndef kill_yourself(delay):\n    t = Timer(delay, kill_yourself_now)\n    t.daemon = True # no need to kill yourself if we're already dead\n    t.start()\n"]], ['Timeout function in Python'], 3, 0], [(28364676, 2), [['where  kill_yourself_now() :'], ['If your scripts starts other processes then see:  how to kill child process(es) when parent dies?  See also,  How to terminate a python subprocess launched with shell=True  -- it demonstrates how to kill a process tree.']], [[" import os\nimport signal\nimport sys\n\ndef kill_yourself_now():\n    sig = signal.CTRL_C_EVENT if sys.platform == 'win32' else signal.SIGINT\n    os.kill(os.getpid(), sig) # raise KeyboardInterrupt in the main thread\n"]], ['Timeout function in Python'], 3, 0], [(28387109, 0), [['Assuming the csv files  orig.csv :'], ['and  remove_list.csv :']], [[' ID,Name,Nickname,Income,Car\n1,A,test,12k,Benz\n2,B,test1,23k,Audi\n3,C,test2,20k,BMW\n']], ['How could I delete certain columns then write wanted columns into csv python'], 4, 0], [(28387109, 1), [['and  remove_list.csv :'], ['we can do something like this to filter:']], [[' Nickname\nCar\n']], ['How could I delete certain columns then write wanted columns into csv python'], 4, 0], [(28387109, 2), [['we can do something like this to filter:'], ['which gives the output  filtered.csv :']], [[" def remove_cols():\n    remove_list = []\n\n    with open('remove_list.csv') as f:\n        for line in f:\n            remove_list.append(line.strip())\n\n    colIndexesToKeep = []\n\n    with open('orig.csv') as origFile:\n        with open('filtered.csv', 'w') as filteredFile:\n            for line in origFile:\n                if not colIndexesToKeep:\n                    for ix, name in enumerate(line.split(',')):\n                        if name.strip() not in remove_list:\n                            colIndexesToKeep.append(ix)\n\n                filteredLine = [val.strip() for ix, val in \n                  enumerate(line.split(',')) if ix in colIndexesToKeep]\n                filteredFile.write(','.join(filteredLine))     \n                filteredFile.write('\\n')           \n"]], ['How could I delete certain columns then write wanted columns into csv python'], 4, 1], [(28387109, 3), [['which gives the output  filtered.csv :'], ['-10000']], [[' ID,Name,Income\n1,A,12k\n2,B,23k\n3,C,20k\n']], ['How could I delete certain columns then write wanted columns into csv python'], 4, 0], [(28404183, 0), [['The following code does what you need:'], ['Examples:']], [[' def main():\n    """To print a names numeric value"""\n    name = input("Enter your full name here: ")\n    return sum(ord(character) - 96 for character in name.lower() if character != " ")\n']], ['Numerical value of a name'], 4, 1], [(28404183, 1), [['Examples:'], ['-10000']], [[' >>> main()\nEnter your full name here: a\n1\n>>> main()\nEnter your full name here: abc\n6\n>>> main()\nEnter your full name here: a b          c\n6\n']], ['Numerical value of a name'], 4, 0], [(28404183, 2), [['-10000'], ['This restricts the loop to those characters which are not blanks.']], [[' sum(ord(character) - 96 for character in name.lower() if character != " ")\n']], ['Numerical value of a name'], 4, 0], [(28404183, 3), [['This restricts the loop to those characters which are not blanks.'], ['This eliminates the blanks with  replace(\' \', \'\') instead of with if character != " "`.  Otherwise, it works the same way.']], [[' def main():\n    """To print a names numeric value"""\n    name = input("Enter your full name here: ")\n    return sum( ord(c) - 96 for c in name.replace(\' \', \'\').lower())\n']], ['Numerical value of a name'], 4, 1], [(28416559, 0), [['This assumes that  voxel_communities  is a simple array containing a community label for each voxel at index  i . It sounds like you can generate that pretty quickly. It also assumes that voxels are present in only one node.'], ["Here's a quick explanation. This uses an inverse indexing trick to reorder the columns and rows of an array of diagonal blocks into the desired matrix. "]], [[' def voxel_adjacency(voxel_communities):\n    n_voxels = voxel_communities.size\n    comm_labels = sorted(set(voxel_communities))\n    comm_counts = [(voxel_communities == l).sum() for l in comm_labels]\n\n    blocks = numpy.zeros((n_voxels, n_voxels), dtype=bool)\n    start = 0\n    for c in comm_counts:\n        blocks[start:start + c, start:start + c] = 1\n        start += c\n\n    ix = numpy.empty_like(voxel_communities)\n    ix[voxel_communities.argsort()] = numpy.arange(n_voxels)\n    blocks[:] = blocks[ix,:]\n    blocks[:] = blocks[:,ix]\n    return blocks\n']], ['Fill scipy / numpy matrix based on indices and values'], 6, 1], [(28416559, 1), [["Here's a quick explanation. This uses an inverse indexing trick to reorder the columns and rows of an array of diagonal blocks into the desired matrix. "], ['These lines are used to construct the initial block matrix. So for example, say you have six voxels and three communities, and each community contains two voxels. Then the initial block matrix will look like this: ']], [['     n_voxels = voxel_communities.size\n    comm_labels = sorted(set(voxel_communities))\n    comm_counts = [(voxel_communities == l).sum() for l in comm_labels]\n\n    blocks = numpy.zeros((n_voxels, n_voxels), dtype=bool)\n    start = 0\n    for c in comm_counts:\n        blocks[start:start + c, start:start + c] = 1\n        start += c\n']], ['Fill scipy / numpy matrix based on indices and values'], 6, 0], [(28416559, 2), [['These lines are used to construct the initial block matrix. So for example, say you have six voxels and three communities, and each community contains two voxels. Then the initial block matrix will look like this: '], ['This is essentially the same as the desired adjacency matrix  after  the voxels have been sorted by community membership. So we need to reverse that sorting. We do so by constructing an inverse argsort array. ']], [[' array([[ True,  True, False, False, False, False],\n       [ True,  True, False, False, False, False],\n       [False, False,  True,  True, False, False],\n       [False, False,  True,  True, False, False],\n       [False, False, False, False,  True,  True],\n       [False, False, False, False,  True,  True]], dtype=bool)\n']], ['Fill scipy / numpy matrix based on indices and values'], 6, 0], [(28416559, 3), [['This is essentially the same as the desired adjacency matrix  after  the voxels have been sorted by community membership. So we need to reverse that sorting. We do so by constructing an inverse argsort array. '], ['Now  ix  will reverse the sorting process when used as an index. And since this is a symmetric matrix, we can perform the reverse sorting operation separately on columns and then on rows:']], [['     ix = numpy.empty_like(voxel_communities)\n    ix[voxel_communities.argsort()] = numpy.arange(n_voxels)\n']], ['Fill scipy / numpy matrix based on indices and values'], 6, 0], [(28416559, 4), [['Now  ix  will reverse the sorting process when used as an index. And since this is a symmetric matrix, we can perform the reverse sorting operation separately on columns and then on rows:'], ["Here's an example of the result it generates for a small input:"]], [['     blocks[:] = blocks[ix,:]\n    blocks[:] = blocks[:,ix]\n    return blocks\n']], ['Fill scipy / numpy matrix based on indices and values'], 6, 0], [(28416559, 5), [["Here's an example of the result it generates for a small input:"], ['It seems to me that this does something quite similar to  voxel_matrix[np.ix_(voxels1, voxels2)] = 1  as suggested by  pv. , except it does it all at once, instead of tracking each possible combination of nodes.']], [[' >>> voxel_adjacency(numpy.array([0, 3, 1, 1, 0, 2]))\narray([[ True, False, False, False,  True, False],\n       [False,  True, False, False, False, False],\n       [False, False,  True,  True, False, False],\n       [False, False,  True,  True, False, False],\n       [ True, False, False, False,  True, False],\n       [False, False, False, False, False,  True]], dtype=bool)\n']], ['Fill scipy / numpy matrix based on indices and values'], 6, 0], [(28416678, 0), [["Here's something to get you going in the right direction."], ['For small files, you could do something like:']], [[" with open('path/to/filename') as filehandler_name:\n    # this is how you open a file for reading\n\nwith open('path/to/filename', 'w') as filehandler_name:\n    # this is how you open a file for (over)writing\n    # note the 'w' argument to the open built-in\n\nimport csv\n# this is the module that handles csv files\n\nreader = csv.reader(filehandler_name)\n# this is how you create a csv.reader object\nwriter = csv.writer(filehandler_name)\n# this is how you create a csv.writer object\n\nfor line in reader:\n    # this is how you read a csv.reader object line by line\n    # each line is effectively a list of the fields in that line\n    # of the file.\n    # # XXXX-XXXX, 0 --> ['XXXX-XXXX', '0']\n"]], ['Python - Replacing value of a row in a CSV file'], 3, 1], [(28416678, 1), [['For small files, you could do something like:'], ["For large files that  inf.readlines  will kill your memory allocation since it's pulling the whole file into memory at once, and you should do something like:"]], [[" import csv\n\nwith open('path/to/filename') as inf:\n    reader = csv.reader(inf.readlines())\n\nwith open('path/to/filename', 'w') as outf:\n    writer = csv.writer(outf)\n    for line in reader:\n        if line[1] == '0':\n            writer.writerow([line[0], '1')\n            break\n        else:\n            writer.writerow(line)\n    writer.writerows(reader)\n"]], ['Python - Replacing value of a row in a CSV file'], 3, 1], [(28416678, 2), [["For large files that  inf.readlines  will kill your memory allocation since it's pulling the whole file into memory at once, and you should do something like:"], ['-10000']], [[" import csv, os\n\nwith open('path/to/filename') as inf, open('path/to/filename_temp', 'w') as outf:\n    reader = csv.reader(inf)\n    writer = csv.writer(outf)\n    for line in reader:\n        if line[1] == '0':\n           ...\n        ... # as above\n\nos.remove('path/to/filename')\nos.rename('path/to/filename_temp', 'path/to/filename')\n"]], ['Python - Replacing value of a row in a CSV file'], 3, 1], [(28417585, 0), [["If you're using  regex package , this  recursive pattern  could work:"], ['Added by @noshelter:  Based on this information, the function could be adjusted as follows...']], [[' <(?:[^><]|(?R))*>\n']], ['Detagging with regex does not catch nested tags'], 2, 0], [(28417585, 1), [['Added by @noshelter:  Based on this information, the function could be adjusted as follows...'], ['-10000']], [[" def detag(text,opentag='<',closetag='>'):\n    t1 = regex.escape(opentag)\n    t2 = regex.escape(closetag)\n    re = regex.compile(t1 + '(?:[^' + t2 + t1 + ']|(?R))*' + t2)\n    result = re.sub('',text)\n    return result\n"]], ['Detagging with regex does not catch nested tags'], 2, 1], [(28418901, 0), [['Updated for Weekly Cumulative:'], ['Output:']], [[" df = pd.DataFrame(data)\ndf.columns = ['Date','Profit']\ndf['Date'] = pd.to_datetime(df['Date'])\ndf['weekofyear'] = df['Date'].dt.weekofyear\ndf.reset_index('Date')\ndf.sort_index(inplace=True)\ndf['Weekly_Cum'] = df.groupby('weekofyear').cumsum()\n"]], ['How to do a rolling aggregation of data week wise in python?'], 2, 1], [(28418901, 1), [['Output:'], ['-10000']], [['          Date  Profit  weekofyear  Weekly_Cum\n0  2013-06-21      14          25          14\n1  2013-06-22      19          25          33\n2  2013-06-23      11          25          44\n3  2013-06-24      13          26          13\n4  2013-06-25       6          26          19\n5  2013-06-26      22          26          41\n6  2013-06-27      22          26          63\n7  2013-06-28       3          26          66\n8  2013-06-29       5          26          71\n9  2013-06-30      10          26          81\n10 2013-07-01      17          27          17\n11 2013-07-02      14          27          31\n12 2013-07-03       9          27          40\n13 2013-07-04       7          27          47\n']], ['How to do a rolling aggregation of data week wise in python?'], 2, 0], [(28419477, 0), [['Just test the existence of the generated code in the loop.'], ['If you want to limit the number of attempts then change the loop from  while  to  for :']], [[' from django.contrib.auth.models import User\n\ndef unique_rand():\n    while True:\n        code = password = User.objects.make_random_password(length=8)\n        if not Person.objects.filter(code=code).exists():\n            return code\n\nclass Person(models.Model):\n    code = models.CharField(max_length=8, unique=True, default=unique_rand)\n']], ['Django unique random as a default value'], 2, 1], [(28419477, 1), [['If you want to limit the number of attempts then change the loop from  while  to  for :'], ['-10000']], [[" def unique_rand():\n    for _ in range(5):\n        ...\n    raise ValueError('Too many attempts to generate the code')\n"]], ['Django unique random as a default value'], 2, 0], [(28431519, 0), [['When you use '], ['So the alignment fails because  df_  has a single index, not the MultiIndex that\nis needed. To see that the index of  df_  is indeed the problem, note that']], [[" df.loc['A', :] = df_\n"]], ['pandas multiindex assignment from another dataframe'], 6, 0], [(28431519, 2), [['succeeds, yielding something like'], ['Of course, you probably do not want to have to create a new MultiIndex every\ntime you want to assign a block of values. So instead, to work around this\nalignment problem, you can use a NumPy array as the assignment value:']], [[' A a  0.229970  0.730824  0.784356\n  b  0.584390  0.628337  0.318222\n  c  0.257192  0.624273  0.221279\n  d  0.787023  0.056342  0.240735\nB a       NaN       NaN       NaN\n  b       NaN       NaN       NaN\n  c       NaN       NaN       NaN\n  d       NaN       NaN       NaN\n']], ['pandas multiindex assignment from another dataframe'], 6, 0], [(28431519, 3), [['Of course, you probably do not want to have to create a new MultiIndex every\ntime you want to assign a block of values. So instead, to work around this\nalignment problem, you can use a NumPy array as the assignment value:'], ['Note also that assignment-by-NumPy-array can also help you perform more complicated assignments such as to rows which are not contiguous:']], [[" df.loc['A', :] = df_.values\n"]], ['pandas multiindex assignment from another dataframe'], 6, 0], [(28431519, 4), [['Note also that assignment-by-NumPy-array can also help you perform more complicated assignments such as to rows which are not contiguous:'], ['yields']], [[" idx = pd.IndexSlice\ndf.loc[idx[:,('a','b')], :] = df_.values\n"]], ['pandas multiindex assignment from another dataframe'], 6, 0], [(28431519, 5), [['yields'], ['for example.']], [[' In [85]: df\nOut[85]: \n          1st       2nd       3rd\nA a  0.229970  0.730824  0.784356\n  b  0.584390  0.628337  0.318222\n  c       NaN       NaN       NaN\n  d       NaN       NaN       NaN\nB a  0.257192  0.624273  0.221279\n  b  0.787023  0.056342  0.240735\n  c       NaN       NaN       NaN\n  d       NaN       NaN       NaN\n']], ['pandas multiindex assignment from another dataframe'], 6, 0], [(28438247, 0), [['OS X is a Unix at its base, so you can use Unix commands. you can use either:'], ['or ']], [[' #!/usr/bin/python\nimport os\nos.system("shutdown -h now")\n']], ['Computer Shut Off Python 3.4'], 2, 1], [(28438247, 1), [['or '], ['-10000']], [[' import subprocess\nsubprocess.call([\'osascript\', \'-e\',\n\'tell app "System Events" to shut down\'])\n']], ['Computer Shut Off Python 3.4'], 2, 1], [(28443428, 1), [['Outputs:'], ['Whoops... here it is with  3 col x 4 rows:']], [['    0  1  2  3\n0  A  B  C  D\n1  E  F  G  H\n2  I  J  K  L\n']], ['Convert a string with whitespaces to a dataframe with desired dimensions in Python'], 3, 0], [(28461458, 1), [['So using your input all you need is something like the  following depending on how you want to write the data to the output file:'], ['Your output will be:']], [[' with open("test.txt") as f, open(\'test_output.txt\',"w") as out:\n    wr = csv.writer(out, delimiter=",")\n    for line in f:\n        wr.writerow(filter(None, line.rstrip().translate(None, "|").split(",")))\n']], ['(Python) Breaking an output text file into tokens'], 5, 1], [(28461458, 2), [['Your output will be:'], ['For python3 we need to do a bit more work as str.translate is slightly different. We need to use str.maketrans to create a table:']], [[' Operation_ID,Operation_Name,business_group_name,business_unit_name,Program_ID,Program_Name,Project_ID,Project_Name,Program_Type_Name,Program_Cost_Type_Name,Start_date,Estimated_End_Date,End_Date,SQA_Name,CMA_Name,SSE_Name,PMs,TLs,PortfolioManager,Finished,Research,SQA_ID,CMA_ID,SSE_ID\n20,XXX,YYY,ZZZ,1,WWW,2163,QQQ,15/12/2008,22/01/2009,EEE EEE ,True\n22,XXX,YYY,ZZZ,3,WWW,2165,QQQ,01/01/2009,09/04/2010,EEE EEE EEE,True,False\n20,XXX,YYY,ZZZ,10,WWW,2164,QQQ,Development,Direct,15/12/2008,26/02/2010,EEE ,EEE EEE ; EEE EEE ; EEE EEE ,True,False\n22,XXX,YYY,ZZZ,3,WWW,2166,QQQ,15/12/2008,31/05/2010,True,False\n20,XXX,YYY,ZZZ,10,WWW,2168,QQQ,Development,Direct,05/01/2009,20/05/2009,EEE EEE EEE,EEE EEE ,True\n20,XXX,YYY,ZZZ,1,WWW,2169,QQQ,13/01/2009,22/05/2009,EEE EEE EEE,EEE EEE EEE EEE,True\n etc.................\n']], ['(Python) Breaking an output text file into tokens'], 5, 0], [(28467688, 0), [['With the standard Python  httplib  and  urllib  libraries you can do'], ['or if you want to use the nice HTTP library called  "Requests" .']], [[' import httplib, urllib\n\nheaders = {\'X-API-TOKEN\': \'your_token_here\'}\npayload = "\'title\'=\'value1\'&\'name\'=\'value2\'"\n\nconn = httplib.HTTPConnection("heise.de")\nconn.request("POST", "", payload, headers)\nresponse = conn.getresponse()\n\nprint response\n']], ['how to make post request in python'], 2, 1], [(28467688, 1), [['or if you want to use the nice HTTP library called  "Requests" .'], ['-10000']], [[' import requests\n\nheaders = {\'X-API-TOKEN\': \'your_token_here\'}\npayload = {\'title\': \'value1\', \'name\': \'value2\'}\n\nr = requests.post("http://foo.com/foo/bar", data=payload, headers=headers)\n']], ['how to make post request in python'], 2, 1], [(28486144, 0), [['You could use the following  lambda  as the sort key:'], ['This returns a sorted copy of the list  sav  - you can rebind the name to the sorted list:']], [[" >>> sorted(sav, key=lambda x: int(x[3]))\n[['Name: ', 'James', 'Score: ', '1'],\n ['Name: ', 'Alex', 'Score: ', '2'],\n ['Name: ', 'Josh', 'Score: ', '3']]\n"]], ['Sorting an array by a number string (Python 3.4.2)'], 2, 1], [(28486144, 1), [['This returns a sorted copy of the list  sav  - you can rebind the name to the sorted list:'], ['-10000']], [[' sav = sorted(sav, key=lambda x: int(x[3]))\n']], ['Sorting an array by a number string (Python 3.4.2)'], 2, 1], [(28486550, 0), [['You can use the metod  .read()'], ['If you do  data.info()  you will get something like this  :']], [[' data = web.urlopen(message)\nstr_data = data.read()\n']], ['How to convert an urlopen into a string in python'], 2, 1], [(28486550, 1), [['If you do  data.info()  you will get something like this  :'], ['You can read more about this  here  .']], [[' <httplib.HTTPMessage instance at 0x7fceeb2ca638>\n']], ['How to convert an urlopen into a string in python'], 2, 0], [(28500524, 1), [['Demo:'], ['-10000']], [[" >>> from collections import namedtuple\n>>> ReadElement = namedtuple('ReadElement', 'address value')\n>>> LookupElement = namedtuple('LookupElement', ReadElement._fields + ('lookups',))\n>>> LookupElement._fields\n('address', 'value', 'lookups')\n>>> LookupElement('addr', 'val', 'lookup') \nLookupElement(address='addr', value='val', lookups='lookup')\n"]], ['Python: Extending a predefined named tuple'], 2, 1], [(28500718, 0), [['-10000'], ['So either']], [[' $ cat BP.mk\nVAR := $(shell python -c \'print("include_path_with\\\\[weird\\\\]characters")\')\n\nall:\n        echo \'DIRECT := `python -c \'\\\'\'print("include_path_with\\\\[weird\\\\]characters")\'\\\'\'`\'\n        echo "DIRECT := `python -c \'print("include_path_with\\\\[weird\\\\]characters")\'`"\n        echo DIRECT := `python -c \'print("include_path_with\\\\[weird\\\\]characters")\'`\n        echo \'VAR := $(VAR)\'\n        echo "VAR := $(VAR)"\n        echo VAR := $(VAR)\n$ make -f BP.mk\necho \'DIRECT := `python -c \'\\\'\'print("include_path_with\\\\[weird\\\\]characters")\'\\\'\'`\'\nDIRECT := `python -c \'print("include_path_with\\\\[weird\\\\]characters")\'`\necho "DIRECT := `python -c \'print("include_path_with\\\\[weird\\\\]characters")\'`"\nDIRECT := include_path_with\\[weird\\]characters\necho DIRECT := `python -c \'print("include_path_with\\\\[weird\\\\]characters")\'`\nDIRECT := include_path_with\\[weird\\]characters\necho \'VAR := include_path_with\\[weird\\]characters\'\nVAR := include_path_with\\[weird\\]characters\necho "VAR := include_path_with\\[weird\\]characters"\nVAR := include_path_with\\[weird\\]characters\necho VAR := include_path_with\\[weird\\]characters\nVAR := include_path_with[weird]characters\n']], ['How to deal with special characters in make command expansion?'], 3, 0], [(28500718, 1), [['So either'], ['or']], [[' VAR2 := $(shell python -c \'print("include_path_with[weird]characters")\')\ng++ main.cpp -I\'$(OUT)\'\n']], ['How to deal with special characters in make command expansion?'], 3, 1], [(28500718, 2), [['or'], ['-10000']], [[' g++ main.cpp -I"$$(python -c \'print("include_path_with[weird]characters")\')"\n']], ['How to deal with special characters in make command expansion?'], 3, 1], [(28510518, 0), [['With  BeautifulSoup  it is fairly straight-forward:'], ['If you have multiple  td  elements and you need to extract the  data-tooltip  from each one:']], [[' from bs4 import BeautifulSoup\n\ndata = """\n<td class="tl-cell tl-popularity" data-tooltip="7,944,796" data-tooltip-instant="">\n<div class="pop-meter">\n<div class="pop-meter-background"></div>\n<div class="pop-meter-overlay" style="width: 55%"></div>\n</div>\n</td>\n"""\n\nsoup = BeautifulSoup(data)\nprint(soup.td[\'data-tooltip\'])\n']], ['Extract Text from HTML Python (BeautifulSoup, RE, Other Option?)'], 2, 1], [(28566041, 0), [["Use a dictionary! It's easy to build a  for  loop that goes through your tuples and appends the second element to a dictionary, keyed on the first element."], ["Once it's in a dictionary, you can do:"]], [[" d = {}\ntuples = [('Jem', 10), ('Sam', 10), ('Sam', 2), ('Jem', 9), ('Jem', 10)]\nfor tuple in tuples:\n    key,val = tuple\n    d.setdefault(key, []).append(val)\n"]], ['How can I find the average of each similar entry in a list of tuples?'], 5, 0], [(28566041, 1), [["Once it's in a dictionary, you can do:"], ['-10000']], [[' for name, values in d.items():\n    print("{name} {avg}".format(name=name, avg=sum(values)/len(values)))\n']], ['How can I find the average of each similar entry in a list of tuples?'], 5, 0], [(28566041, 2), [['-10000'], ['This builds a structure that looks kind of like:']], [[" from itertools import groupby\n\ntuples = [('Jem', 10), ('Sam', 10), ('Sam', 2), ('Jem', 9), ('Jem', 10)]\ntuples.sort(key=lambda tup: tup[0])\n# tuples is now [('Jem', 10), ('Jem', 9), ('Jem', 10), ('Sam', 10), ('Sam', 2)]\n\ngroups = groupby(tuples, lambda tup: tup[0])\n"]], ['How can I find the average of each similar entry in a list of tuples?'], 5, 0], [(28566041, 3), [['This builds a structure that looks kind of like:'], ['We can use that to build our names and averages:']], [[" [('Jem', [('Jem', 10), ('Jem', 9), ('Jem', 10)]),\n ('Sam', [('Sam', 10), ('Sam', 2)])]\n"]], ['How can I find the average of each similar entry in a list of tuples?'], 5, 0], [(28566041, 4), [['We can use that to build our names and averages:'], ['-10000']], [[' for groupname, grouptuples in groups:\n    values = [t[1] for t in groupvalues]\n    print("{name} {avg}".format(name=groupname, avg=sum(values)/len(values)))\n']], ['How can I find the average of each similar entry in a list of tuples?'], 5, 0], [(28596212, 1), [['you can probably even just use the builtin  subprocess.Process.kill()  (see the docs  https://docs.python.org/2/library/subprocess.html#subprocess.Popen.send_signal )'], ['there is no way to exit your thread ( t ) from outside of  some_long_running_external_process']], [['  t = Thread(target=some_long_running_external_process)\n t.start()\n']], ['Killing Thread and releasing memory in Python'], 2, 0], [(28606124, 0), [['If the list sorted as in your case then you could use  itertools.groupby()  to group the timestamps into days:'], ['-10000']], [[' #!/usr/bin/env python\nfrom datetime import date, timedelta\nfrom itertools import groupby\n\nepoch = date(1970, 1, 1)\n\nresult = {}\nassert timestamps == sorted(timestamps)\nfor day, group in groupby(timestamps, key=lambda ts: ts // 86400):\n    # store the interval + day/month in a dictionary.\n    same_day = list(group)\n    assert max(same_day) == same_day[-1] and min(same_day) == same_day[0]\n    result[epoch + timedelta(day)] = same_day[0], same_day[-1] \nprint(result)\n']], ['Finding time intervals per day from a list of timestamps in Python'], 3, 1], [(28606124, 1), [['-10000'], ['how would you afterwards do to test if the last (for example) 5 entries in the result have a larger interval than the previous 14? ']], [['Output {datetime.date(2007, 4, 10): (1176239419.0, 1176239419.0),\n datetime.date(2007, 4, 11): (1176334733.0, 1176334733.0),\n datetime.date(2007, 4, 13): (1176445137.0, 1176445137.0),\n datetime.date(2007, 4, 26): (1177619954.0, 1177621082.0),\n datetime.date(2007, 4, 29): (1177838576.0, 1177838576.0),\n datetime.date(2007, 5, 5): (1178349385.0, 1178401697.0),\n datetime.date(2007, 5, 6): (1178437886.0, 1178437886.0),\n datetime.date(2007, 5, 11): (1178926650.0, 1178926650.0),\n datetime.date(2007, 5, 12): (1178982127.0, 1178982127.0),\n datetime.date(2007, 5, 14): (1179130340.0, 1179130340.0),\n datetime.date(2007, 5, 15): (1179263733.0, 1179264930.0),\n datetime.date(2007, 5, 19): (1179574273.0, 1179574273.0),\n datetime.date(2007, 5, 20): (1179671730.0, 1179671730.0),\n datetime.date(2007, 5, 30): (1180549056.0, 1180549056.0),\n datetime.date(2007, 6, 2): (1180763342.0, 1180763342.0),\n datetime.date(2007, 6, 9): (1181386289.0, 1181386289.0),\n datetime.date(2007, 6, 16): (1181990860.0, 1181990860.0),\n datetime.date(2007, 6, 27): (1182979573.0, 1182979573.0),\n datetime.date(2007, 7, 1): (1183326862.0, 1183326862.0)}\n']], ['Finding time intervals per day from a list of timestamps in Python'], 3, 0], [(28606124, 2), [['how would you afterwards do to test if the last (for example) 5 entries in the result have a larger interval than the previous 14? '], ['-10000']], [[' entries = sorted(result.items())\nintervals = [(end - start) for _, (start, end) in entries]\nprint(max(intervals[-5:]) > max(intervals[-5-14:-5]))\n# -> False\n']], ['Finding time intervals per day from a list of timestamps in Python'], 3, 0], [(28616651, 1), [['-10000'], ['-10000']], [[' awk -F \'[ ,]\' \'{sub(/:.+$/, "", $3); a[$3]+=$11} END{for (i in a) print i, a[i]}\' file\n10.20.10.144 2896\n']], ['manipulate column fields for clean representation'], 2, 1], [(28617958, 2), [['Which then lets you write:'], ['-10000']], [[" import proto\nproto.struct_token_type_delta.from_buffer(bytearray(b'\\xff\\x11\\x22'))\n"]], ['Casting string/buffer data using swig wrapped typedef structs and enums in python'], 3, 0], [(28643401, 0), [['You could either simply use'], ['A better way would be to set a variable when the execution finished and continue only then:']], [[' casp.run(function(){});\n']], ['How to call python script from CasperJS'], 2, 1], [(28643401, 1), [['A better way would be to set a variable when the execution finished and continue only then:'], ['If you want to pass multiple arguments to the external program, you should use an array as the second argument to  execFile']], [[" casp.start().then(function() {\n  var finished = false;\n  var cp = require('child_process');\n  cp.execFile('/usr/bin/python','test.py', {},function(_,stdout,stderr){\n    console.log(stdout);\n    console.log(stderr);\n    finished = true;\n  });\n  this.waitFor(function check(){\n    return finished;\n  }, function then(){\n    // can stay empty\n  });\n}).run();\n"]], ['How to call python script from CasperJS'], 2, 1], [(28647371, 0), [['You are replacing your  (value, index)  tuples with  just  the value:'], ['You need to replace that with a new tuple:']], [[' self.values[index] = self.generators[index].next()\n']], ['Sort generated numbers using another python generator'], 5, 0], [(28647371, 1), [['You need to replace that with a new tuple:'], ['Your generator is missing a loop and handling of empty generators:']], [[' self.values[index] = (self.generators[index].next(), index)\n']], ['Sort generated numbers using another python generator'], 5, 0], [(28647371, 2), [['Your generator is missing a loop and handling of empty generators:'], ['Demo:']], [[' def generate(self):\n    while any(self.values):\n        r, index = min(v for v in self.values if v)\n        try:\n            self.values[index] = (self.generators[index].next(), index)\n        except StopIteration:\n            self.values[index] = None\n        yield r\n']], ['Sort generated numbers using another python generator'], 5, 0], [(28647371, 3), [['Demo:'], ['The standard library does it more efficiently still with the  heapq.merge()  function ; it uses a heap to keep the iterables sorted by lowest value in a very efficient manner;  min()  needs to loop through all K iterables, while using a heap only takes log-K steps to keep the heap invariant intact.']], [[' >>> class GeneratorSort():\n...     def __init__(self, *args):\n...         self.values = [(arg.next(), i) for i, arg in enumerate(args)]\n...         self.generators = args\n...     def generate(self):\n...         while any(self.values):\n...             r, index = min(v for v in self.values if v)\n...             try:\n...                 self.values[index] = (self.generators[index].next(), index)\n...             except StopIteration:\n...                 self.values[index] = None\n...             yield r\n... \n>>> l1 = [2, 5, 6, 8]\n>>> l2 = [1, 4, 5, 7]\n>>> l3 = [0, 3, 9, 10]\n>>> a = GeneratorSort(iter(l1), iter(l2), iter(l3))\n>>> list(a.generate())\n[0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10]\n']], ['Sort generated numbers using another python generator'], 5, 1], [(28647371, 4), [['The standard library does it more efficiently still with the  heapq.merge()  function ; it uses a heap to keep the iterables sorted by lowest value in a very efficient manner;  min()  needs to loop through all K iterables, while using a heap only takes log-K steps to keep the heap invariant intact.'], ['You can study the  source code , which has been highly tuned for maximum performance.']], [[' >>> import heapq\n>>> list(heapq.merge(l1, l2, l3))\n[0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10]\n']], ['Sort generated numbers using another python generator'], 5, 0], [(28654483, 0), [['-10000'], ['-10000']], [[' import random\n\ndef read_file():\n    res = {}\n    start = True\n    with open(\'pairs.txt\', \'r\') as f:\n        for line in f.readlines():\n            if start:\n                start = False\n                continue\n            woman, matches = line.strip().split(\': \')\n            woman = int(woman)\n            matches = map(int, matches.split(\' \'))\n            res[woman] = matches\n    return res\n\n\ndef build_random_match(graph):\n    edges = {}\n    for woman in graph:\n        for man in graph[woman]:\n            if already_in_edges(man, edges):\n                continue\n            else:\n                edges[woman] = man\n                break\n    return edges\n\n\ndef already_in_edges(man, edges):\n    for woman in edges:\n        if edges[woman] == man:\n            return True\n    else:\n        return False\n\n\ndef get_unmatched_women(match, graph):\n    return  [woman for woman in graph.keys() if woman not in match.keys()]\n\n\ndef not_in_match(man, match):\n    for woman in match:\n        if match[woman] == man:\n            return False\n    else:\n        return True\n\n\ndef find_unmatched_man(graph, match, woman):    \n    potentials = graph[woman]\n    for man in potentials:\n        if not_in_match(man, match):\n            return man\n    else:\n        return False\n\n\ndef remove_man_from_match(man, unmatched_woman, match, graph):  \n    # find the woman that this man is currently matched with\n    # and cancel this matching\n    for woman in match:\n        if match[woman] == man:\n            match_to_del = woman\n            break   \n    del match[match_to_del]\n    # also remove the man from the orig woman (graph) \n    # to prevent infinite loop\n    men = graph[unmatched_woman]\n    men.remove(man)\n    graph[unmatched_woman] = men\n\n    return match_to_del\n\n\ndef relax(unmatched_woman, match, graph):   \n    unmatched_man = find_unmatched_man(graph, match, unmatched_woman)\n    if unmatched_man:\n        match[unmatched_woman] = unmatched_man      \n    elif len(graph[unmatched_woman]) == 0:\n        return match\n    else:\n        # grab one of the possible matchings randomly\n        rand_index = random.randint(0, len(graph[unmatched_woman])-1)\n        man = graph[unmatched_woman][rand_index]\n        new_unmatched_woman = remove_man_from_match(man, unmatched_woman, match, graph)\n        match[unmatched_woman] = man\n        match = relax(new_unmatched_woman, match, graph)\n\n    return match\n\n\ndef improve_match(match, graph):\n    if len(match) == len(graph):\n        return match\n\n    unmatched_women = get_unmatched_women(match, graph) \n    for woman in unmatched_women:\n        copy_graph = graph.copy()\n        suggested = relax(woman, match, copy_graph)\n        if len(suggested) > len(match):\n            return suggested\n        else:\n            suggested = match\n    else:\n        return suggested\n\n\ndef main():\n    graph = read_file()\n    match = build_random_match(graph)   \n    if len(match) == len(graph):\n        print \'Got a perfect match:\', match\n    else:\n        match_size = 0\n        while match_size < len(match):\n            match_size = len(match)\n            match = improve_match(match, graph)\n\n    return match\n\nif __name__ == \'__main__\':\n    res = main()    \n    print "Size of match:", len(res)\n    print "Match:", res\n']], ['How do I find the maximum amount of possible correct matches in these arrays?'], 2, 1], [(28654483, 1), [['-10000'], ['-10000']], [[' Size of match: 17\nMatch: {2: 28, 3: 32, 4: 22, 5: 38, 6: 34, 7: 37, 8: 30, 9: 23, 10: 24, 11: 29, 12: 26, 13: 21, 15: 20, 16: 31, 17: 27, 18: 35, 19: 25}\n']], ['How do I find the maximum amount of possible correct matches in these arrays?'], 2, 0], [(28658817, 0), [['We can do linear:'], ['Result:']], [[' values = [7, 3, 2, 7, 1, 9, 8]\n\nrange_by_min, range_by_max = {}, {}\n\nfor v in values:\n    range_by_min[v] = range_by_max[v] = [v, v]\n\nfor v in values:\n    if v - 1 in range_by_max and v in range_by_min:\n        p, q = range_by_max[v - 1], range_by_min[v]\n        del range_by_min[q[0]]\n        del range_by_max[p[1]]\n        p[1] = q[1]\n        range_by_max[p[1]] = p\n\nprint(range_by_min, range_by_max)\n\nresult = {k: v[1] - v[0] + 1 for k, v in range_by_min.iteritems()}\nprint(result)\n']], ['Partitioning a set of values in Python'], 3, 1], [(28658817, 1), [['Result:'], ['I saw the  link  suggested by David Eisenstat. Based on this link, the implementation can be updated to use only one dictionary:']], [[' ({1: [1, 3], 7: [7, 9]}, {3: [1, 3], 9: [7, 9]})\n{1: 3, 7: 3}\n']], ['Partitioning a set of values in Python'], 3, 0], [(28658817, 2), [['I saw the  link  suggested by David Eisenstat. Based on this link, the implementation can be updated to use only one dictionary:'], ['-10000']], [[' ranges = {v: [v, v] for v in values}\n\nfor v in values:\n    if v - 1 in ranges and v in ranges:\n        p, q = ranges[v - 1], ranges[v]\n        if p[1] == v - 1 and q[0] == v:\n            if q[0] != q[1]:\n                del ranges[q[0]]\n            if p[0] != p[1]:\n                del ranges[p[1]]\n            p[1] = q[1]\n            ranges[p[1]] = p\n\nresult = {k: v[1] - v[0] + 1 for k, v in ranges.iteritems() if k == v[0]}\n']], ['Partitioning a set of values in Python'], 3, 1], [(28665356, 0), [['Use  enumerate  with a start index of 1 and  str.format :'], ['You can also use a list comprehension and  iter  without needing a while loop, it will keep looping until the user enters the  sentinel  value  "nothing" :']], [[' while True:\n    myInput = input()\n    if myInput == "nothing":\n        print(\'There are {} items in the basket: \'.format(len(basket)))\n        for ind, item in enumerate(basket,1):\n            print("Item{}: {} ".format(ind,item))\n        break\n    else:\n        basket.append(myInput)\n        print(\'Okay, what else?\')\n']], ['Line breaks with lists'], 2, 1], [(28665356, 1), [['You can also use a list comprehension and  iter  without needing a while loop, it will keep looping until the user enters the  sentinel  value  "nothing" :'], ['-10000']], [[' print(\'Add as many items to the basket as you want. When you are done, enter "nothing".\')\nprint(\'What do you want to put into the basket now?\')\nbasket = [ line for line in iter(lambda:input("Please enter an item to add"), "nothing")]\n\nprint(\'There are {} items in the basket: \'.format(len(basket)))\nfor ind,item in enumerate(basket,1):\n    print("Item{}: {} ".format(ind,item))\n']], ['Line breaks with lists'], 2, 1], [(28677840, 0), [['You can do it the easy way by using the  TerminalServerSession  bool-property from .NET Framework:'], ['Output:']], [[' Add-Type -AssemblyName System.Windows.Forms\n[System.Windows.Forms.SystemInformation]::TerminalServerSession\n']], ['Get system metrics using PowerShell'], 4, 1], [(28677840, 1), [['Output:'], ['Or you could do it the manual way (like  TerminalServerSession  does internally) and use C# and P/Invoke to add load and use  GetSystemMetrics()  in PowerShell.']], [[' False\n']], ['Get system metrics using PowerShell'], 4, 0], [(28677840, 2), [['Or you could do it the manual way (like  TerminalServerSession  does internally) and use C# and P/Invoke to add load and use  GetSystemMetrics()  in PowerShell.'], ['Output: ']], [[' $def = @"\n//I removed every other enum-value to shorten the sample\npublic enum SystemMetric\n   {\n     SM_REMOTESESSION           = 0x1000, // 0x1000\n   }\n\n[DllImport("user32.dll")]\npublic static extern int GetSystemMetrics(SystemMetric smIndex);\n"@\n\nAdd-Type -Namespace NativeMethods -Name User32Dll -MemberDefinition $def\n\n[NativeMethods.User32Dll]::GetSystemMetrics([NativeMethods.User32Dll+SystemMetric]::SM_REMOTESESSION)\n']], ['Get system metrics using PowerShell'], 4, 1], [(28677840, 3), [['Output: '], ['-10000']], [[' 0\n']], ['Get system metrics using PowerShell'], 4, 0], [(28687087, 0), [['There are also two installations of pip. For example:'], ['If you need to leave the system numpy untouched, you can run the  /usr/local  Python as your default Python instead of the system Python. Here we create a symbolic link from the default python to the local python, so that the local python becomes the default.']], [[' $ which pip\n/usr/local/bin/pip\n$ ls -l /usr/local/bin/pip\nlrwxr-xr-x  1 dmao  admin  30 Feb 14 19:09 /usr/local/bin/pip -> ../Cellar/python/2.7.9/bin/pip\n']], ["How to override OSX's version of numpy when I import in Python 2.7?"], 3, 0], [(28687087, 1), [['If you need to leave the system numpy untouched, you can run the  /usr/local  Python as your default Python instead of the system Python. Here we create a symbolic link from the default python to the local python, so that the local python becomes the default.'], ['You can restore your default Python version anytime by replacing the symlink. /usr/bin has the links you need.']], [[' sudo ln -s /usr/bin/python /usr/local/bin/python\n']], ["How to override OSX's version of numpy when I import in Python 2.7?"], 3, 0], [(28687087, 2), [['You can restore your default Python version anytime by replacing the symlink. /usr/bin has the links you need.'], ['-10000']], [[' $ ls -l /usr/bin/ | grep python\nlrwxr-xr-x   1 root   wheel        76 Feb 21  2014 pythonw2.5 -> ../../System/Library/Frameworks/Python.framework/Versions/2.5/bin/pythonw2.5\nlrwxr-xr-x   1 root   wheel        76 Feb 21  2014 pythonw2.6 -> ../../System/Library/Frameworks/Python.framework/Versions/2.6/bin/pythonw2.6\nlrwxr-xr-x   1 root   wheel        76 Feb 21  2014 pythonw2.7 -> ../../System/Library/Frameworks/Python.framework/Versions/2.7/bin/pythonw2.7\n']], ["How to override OSX's version of numpy when I import in Python 2.7?"], 3, 0], [(28716265, 0), [['There is a  groupby/cumcount/unstack  trick which converts long-format DataFrames to wide-format DataFrames:'], ['yields']], [[" import pandas as pd\ndf = pd.read_table('data', sep='\\s+')\n\ncommon = ['weather', 'location', 'time', 'date', 'Condition']\ngrouped = df.groupby(common)\ndf['idx'] = grouped.cumcount()\ndf2 = df.set_index(common+['idx'])\ndf2 = df2.unstack('idx')\ndf2 = df2.swaplevel(0, 1, axis=1)\ndf2 = df2.sortlevel(axis=1)\ndf2.columns = df2.columns.droplevel(0)\ndf2 = df2.reset_index()\nprint(df2)\n"]], ['How can I use python pandas to parse CSV into the format I want?'], 2, 1], [(28716265, 1), [['yields'], ["While wide-format may be useful for presentation, note that long-format\nis usually the right format for data processing. See Hadley Wickham's  article on the virtues of tidy data (PDF) ."]], [['   weather  location       time        date  Condition insectName  count  \\\n0   sunny  balabala  0900:1200  1990-02-10         25        aaa     15   \n1   sunny  balabala  1300:1500  1990-02-15         38        XXX     40   \n\n  insectName  count insectName  count insectName  count  \n0        bbb     10        ccc     20        ddd     50  \n1        yyy     10        yyy     25        NaN    NaN  \n']], ['How can I use python pandas to parse CSV into the format I want?'], 2, 0], [(28720893, 0), [['I can generate a string in a window as if it was typed there. Although it does fail with Unicode in Linux:'], ["Not sure what the solution there is. How do you type any Unicode character into a text window anyway? There's a Gnomey-Linux standard where you can type Ctrl-Shift-u and then hex digits, then Ctrl-Shift to end. Do that with:"]], [[' >>> time.sleep(5) ; k.type_string(\'ΣΣ\')\nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\n  File "/usr/local/lib/python2.7/dist-packages/pykeyboard/base.py", line 48, in type_string\n    self.tap_key(i)\n  File "/usr/local/lib/python2.7/dist-packages/pykeyboard/base.py", line 40, in tap_key\n    self.press_key(character)\n  File "/usr/local/lib/python2.7/dist-packages/pykeyboard/x11.py", line 91, in press_key\n    keycode = self.lookup_character_keycode(character)\n  File "/usr/local/lib/python2.7/dist-packages/pykeyboard/x11.py", line 222, in lookup_character_keycode\n    keysym = Xlib.XK.string_to_keysym(special_X_keysyms[character])\nKeyError: \'\\xce\'\n']], ['Save text cursor position in the currently focused application/control, then restore it and paste text'], 2, 0], [(28720893, 1), [["Not sure what the solution there is. How do you type any Unicode character into a text window anyway? There's a Gnomey-Linux standard where you can type Ctrl-Shift-u and then hex digits, then Ctrl-Shift to end. Do that with:"], ['and get a Σ']], [[' k.press_key(k.shift_key)\nk.press_key(k.control_key)\nk.type_string("u03a3")\nk.release_key(k.shift_key)\nk.release_key(k.control_key)\n']], ['Save text cursor position in the currently focused application/control, then restore it and paste text'], 2, 0], [(28754280, 0), [['You can use a loop for the different parts to be reversed, and then replace that slice of the list with the same slice in reverse order.'], ['Or this way, as pointed out in comments, which also gets rid of those nasty off-by-one indices:']], [[' lst = list(range(20))\nfor start in range(5, len(lst), 10):\n    lst[start:start+5] = lst[start+4:start-1:-1]\n']], ['Python3 Make a list that increments for a certain amount, decrements for a certain amount'], 3, 1], [(28754280, 1), [['Or this way, as pointed out in comments, which also gets rid of those nasty off-by-one indices:'], ['Or, in case the intervals to be reversed are irregular (as it seems to be in your question):']], [[' for start in range(5, len(lst), 10):\n    lst[start:start+5] = reversed(lst[start:start+5])\n']], ['Python3 Make a list that increments for a certain amount, decrements for a certain amount'], 3, 1], [(28754280, 2), [['Or, in case the intervals to be reversed are irregular (as it seems to be in your question):'], ['-10000']], [[' reverse = [(3, 7), (12,17)]\nfor start, end in reverse:\n    lst[start:end] = reversed(lst[start:end])\n']], ['Python3 Make a list that increments for a certain amount, decrements for a certain amount'], 3, 1], [(28755798, 0), [['Try this:'], ['This gives me the desired result:']], [[' import pandas as pd\nimport json\nimport urllib\n\njs = json.loads(urllib.urlopen("test.json").read())\ndata = js["data"]\nrows = [row["row"] for row in data] # Transform the \'row\' keys to list of lists.\ndf = pd.DataFrame(rows, columns=js["columns"])\nprint df\n']], ['JSON to Pandas: is there a more elegant solution?'], 2, 1], [(28755798, 1), [['This gives me the desired result:'], ['-10000']], [['    rank          name    deaths\n0     1    Mao Zedong  63000000\n1     2  Jozef Stalin  23000000\n']], ['JSON to Pandas: is there a more elegant solution?'], 2, 0], [(28766133, 0), [['As others have suggested, csv reading is faster.  So if you are on windows and have Excel, you could call a vbscript to convert the Excel to csv and then read the csv.  I tried the script below and it took about 30 seconds.'], ["Here's a little snippet of python to create the ExcelToCsv.vbs script:"]], [[" # create a list with sheet numbers you want to process\nsheets = map(str,range(1,6))\n\n# convert each sheet to csv and then read it using read_csv\ndf={}\nfrom subprocess import call\nexcel='C:\\\\Users\\\\rsignell\\\\OTT_Data_All_stations.xlsx'\nfor sheet in sheets:\n    csv = 'C:\\\\Users\\\\rsignell\\\\test' + sheet + '.csv' \n    call(['cscript.exe', 'C:\\\\Users\\\\rsignell\\\\ExcelToCsv.vbs', excel, csv, sheet])\n    df[sheet]=pd.read_csv(csv)\n"]], ['Faster way to read Excel files to pandas dataframe'], 2, 0], [(28766133, 1), [["Here's a little snippet of python to create the ExcelToCsv.vbs script:"], ['This answer benefited from  Convert XLS to CSV on command line  and   csv & xlsx files import to pandas data frame: speed issue']], [[' #write vbscript to file\nvbscript="""if WScript.Arguments.Count < 3 Then\n    WScript.Echo "Please specify the source and the destination files. Usage: ExcelToCsv <xls/xlsx source file> <csv destination file> <worksheet number (starts at 1)>"\n    Wscript.Quit\nEnd If\n\ncsv_format = 6\n\nSet objFSO = CreateObject("Scripting.FileSystemObject")\n\nsrc_file = objFSO.GetAbsolutePathName(Wscript.Arguments.Item(0))\ndest_file = objFSO.GetAbsolutePathName(WScript.Arguments.Item(1))\nworksheet_number = CInt(WScript.Arguments.Item(2))\n\nDim oExcel\nSet oExcel = CreateObject("Excel.Application")\n\nDim oBook\nSet oBook = oExcel.Workbooks.Open(src_file)\noBook.Worksheets(worksheet_number).Activate\n\noBook.SaveAs dest_file, csv_format\n\noBook.Close False\noExcel.Quit\n""";\n\nf = open(\'ExcelToCsv.vbs\',\'w\')\nf.write(vbscript.encode(\'utf-8\'))\nf.close()\n']], ['Faster way to read Excel files to pandas dataframe'], 2, 0], [(28767484, 0), [['If I split your test input string in blocks of 4 characters and decode each one apart, I get the following:'], ['However, the correct base64 encoding of your test string  sdadasdasdasdasdtest  is:']], [[" >>> import base64\n>>> s = 'cw==ZA==YQ==ZA==YQ==cw==ZA==YQ==cw==ZA==YQ==cw==ZA==YQ==cw==ZA==dA==ZQ==cw==dA=='\n>>> ''.join(base64.b64decode(s[i:i+4]) for i in range(0, len(s), 4))\n\n'sdadasdasdasdasdtest'\n"]], ['Python: Decode base64 multiple strings in a file'], 3, 0], [(28767484, 1), [['However, the correct base64 encoding of your test string  sdadasdasdasdasdtest  is:'], ['If you place this string in  my_file.txt  (and rewriting your code to be a bit more concise) then it all works.']], [[" >>> base64.b64encode('sdadasdasdasdasdtest')\n'c2RhZGFzZGFzZGFzZGFzZHRlc3Q='\n"]], ['Python: Decode base64 multiple strings in a file'], 3, 0], [(28767484, 2), [['If you place this string in  my_file.txt  (and rewriting your code to be a bit more concise) then it all works.'], ['-10000']], [[' import base64\n\nwith open("my_file.txt") as f, open("original_b64.txt", \'w\') as g:\n    encoded = f.read()\n    decoded = base64.b64decode(encoded)\n    g.write(decoded)\n']], ['Python: Decode base64 multiple strings in a file'], 3, 1], [(28774852, 0), [['I came up with this function to get latest stable version of a package:'], ['When executed, this produces following results:']], [[' import requests\nimport json\ntry:\n    from packaging.version import parse\nexcept ImportError:\n    from pip._vendor.packaging.version import parse\n\n\nURL_PATTERN = \'https://pypi.python.org/pypi/{package}/json\'\n\n\ndef get_version(package, url_pattern=URL_PATTERN):\n    """Return version of package on pypi.python.org using json."""\n    req = requests.get(url_pattern.format(package=package))\n    version = parse(\'0\')\n    if req.status_code == requests.codes.ok:\n        j = json.loads(req.text.encode(req.encoding))\n        if \'releases\' in j:\n            releases = j[\'releases\']\n            for release in releases:\n                ver = parse(release)\n                if not ver.is_prerelease:\n                    version = max(version, ver)\n    return version\n\n\nif __name__ == \'__main__\':\n    print("Django==%s" % get_version(\'Django\'))\n']], ['PyPI API - How to get stable package version'], 2, 1], [(28774852, 1), [['When executed, this produces following results:'], ['-10000']], [[' $ python v.py\nDjango==1.9\n']], ['PyPI API - How to get stable package version'], 2, 0], [(28795561, 0), [['The nginx idea I proposed there is better, but has the drawback that you have to host two separate applications. Back then I missed to mention a third alternative, which is to use a blueprint for each API version. For example, consider the following app structure (greatly simplified for clarity):'], ['The  routes.py  for each API version define the routes, and when necessary call into  common.py  functions to avoid duplicating logic. For example, your v1 and v1.1  routes.py  can have:']], [[' my_project\n+-- api/\n    +-- v1/\n        +-- __init__.py\n        +-- routes.py\n    +-- v1_1/\n        +-- __init__.py\n        +-- routes.py\n    +-- v2/\n        +-- __init__.py\n        +-- routes.py\n    +-- __init__.py\n    +-- common.py\n']], ['Support multiple API versions in flask'], 3, 0], [(28795561, 1), [['The  routes.py  for each API version define the routes, and when necessary call into  common.py  functions to avoid duplicating logic. For example, your v1 and v1.1  routes.py  can have:'], ['Note the  api.route . Here  api  is a blueprint. Having each API version implemented as a blueprint helps to combine everything with the proper versioned URLs. Here is an example app setup code that imports the API blueprints into the application instance:']], [[" from api import common\n\n@api.route('/users')\ndef get_users():\n    return common.get_users()\n"]], ['Support multiple API versions in flask'], 3, 0], [(28795561, 2), [['Note the  api.route . Here  api  is a blueprint. Having each API version implemented as a blueprint helps to combine everything with the proper versioned URLs. Here is an example app setup code that imports the API blueprints into the application instance:'], ['This structure is very nice because it keeps all API versions separate, yet they are served by the same application. As an added benefit, when the time comes to stop supporting v1, you just remove the  register_blueprint  call for that version, delete the  v1  package from your sources and you are done.']], [[" from api.v1 import api as api_v1\nfrom api.v1_1 import api as api_v1_1\nfrom api.v2 import api as api_v2\n\napp.register_blueprint(api_v1, url_prefix='/v1')\napp.register_blueprint(api_v1_1, url_prefix='/v1.1')\napp.register_blueprint(api_v2, url_prefix='/v2')\n"]], ['Support multiple API versions in flask'], 3, 0], [(28800634, 0), [['You can use  filter :'], ['Using for loop:']], [[" small_names = filter(lambda n: len(n)<=4, names)\n#equivalent to: small_names = [n for n in names if len(n) <=4]\n\nprint(small_names) # ['jake', 'Brad', 'Tony']\n"]], ["Python: how to create a list from elements that don't meet a certain condition"], 2, 1], [(28800634, 1), [['Using for loop:'], ['-10000']], [[' small_names = []\n\nfor n in names:\n    if len(n) <= 4:\n        small_names.append(n)\n']], ["Python: how to create a list from elements that don't meet a certain condition"], 2, 1], [(28812868, 0), [['Use the mebmers of   sys.version_info  if you want to base your code on the Python version:'], ['Use these members like this:']], [[' sys.version_info.major\nsys.version_info.minor\nsys.version_info.micro\n']], ['Python Version Specific Code'], 3, 0], [(28812868, 1), [['Use these members like this:'], ['pygame has  a similar structure :']], [[' if sys.version_info.major == 3 and sys.version_info.minor == 4:\n    print("I like Python 3.4")\n']], ['Python Version Specific Code'], 3, 1], [(28812868, 2), [['pygame has  a similar structure :'], ['-10000']], [[' pygame.version.vernum\n']], ['Python Version Specific Code'], 3, 0], [(28823052, 0), [['python: '], ['java:']], [[' p.stdin.write("haha")\n']], ['stdout from python to stdin java'], 5, 0], [(28823052, 1), [['java:'], ['-10000']], [[' Scanner in = new Scanner(System.in)\ndata = in.next()\n']], ['stdout from python to stdin java'], 5, 0], [(28823052, 2), [['-10000'], ['...with this java code:']], [[' import subprocess\n\np = subprocess.Popen(\n    [\n        \'java\',  \n        \'-cp\',\n        \'/Users/7stud/java_programs/myjar.jar\',\n        \'MyProg\'\n    ],\n    stdout = subprocess.PIPE, \n    stdin = subprocess.PIPE,\n)\n\n\np.stdin.write("haha\\n")\nprint "i am done" \nprint p.stdout.readline().rstrip()\n']], ['stdout from python to stdin java'], 5, 0], [(28823052, 3), [['...with this java code:'], ['...produces this output:']], [[' public class MyProg {\n    public static void main(String[] args) {\n        Scanner in = new Scanner(System.in);\n        String data = in.next();\n\n        System.out.println("Java program received: " + data);\n    }\n}\n']], ['stdout from python to stdin java'], 5, 0], [(28823052, 4), [['...produces this output:'], ['-10000']], [[' i am done\nJava program received: haha\n']], ['stdout from python to stdin java'], 5, 0], [(28823170, 0), [['OK, now Python has a ternary, which looks like'], ['But even that is kinda sloppy. If you really want a one liner, make a function.']], [[' val_if_true if condition else val_if_false\n']], ['single line if statement - Python'], 3, 1], [(28823170, 1), [['But even that is kinda sloppy. If you really want a one liner, make a function.'], ['Your  specific  case is a little more specialized, since you want the  else  to be the original value. You could do']], [[' def val():\n    if condition:\n        return val_if_true\n    else:\n        return val_if_false\n']], ['single line if statement - Python'], 3, 1], [(28823170, 2), [['Your  specific  case is a little more specialized, since you want the  else  to be the original value. You could do'], ['But again, the  if  statement is just more readable and clear as to the intent.']], [[' box[a][b] = box[a][b] or chr(current_char)\n']], ['single line if statement - Python'], 3, 1], [(28832166, 0), [['Simple one-liner:'], ['For better understanding the above code can be expanded to:']], [[" a = ['item1', 'item2', 'item3','item4']\nprint reduce(lambda x, y: {y: x}, reversed(a))\n"]], ['List to nested dictionary in python'], 2, 1], [(28832166, 1), [['For better understanding the above code can be expanded to:'], ['-10000']], [[' def nest_me(x, y):\n    """\n    Take two arguments and return a one element dict with first\n    argument as a value and second as a key\n    """\n    return {y: x}\n\na = [\'item1\', \'item2\', \'item3\',\'item4\']\nrev_a = reversed(a) # [\'item4\', \'item3\', \'item2\',\'item1\']\nprint reduce(\n    nest_me, # Function applied until the list is reduced to one element list\n    rev_a # Iterable to be reduced\n)\n# {\'item1\': {\'item2\': {\'item3\': \'item4\'}}}\n']], ['List to nested dictionary in python'], 2, 1], [(28855043, 0), [['To append at the start of each line.'], ['To append at the end of each line.']], [[' with open("test.txt", "r") as myfile:\n    fil = myfile.read().rstrip(\'\\n\')\nwith open("test.txt", "w") as f:\n    f.write(re.sub(r\'(?m)^\', r\'append text\', fil))\n']], ['Append in each line of a .txt file a specific string using Python'], 2, 1], [(28857930, 0), [['For integers only, you can get there in a slightly devious way with the following:'], ['However, converting  n  to a float in the numerator (to get a float return) slows it to the same speed as your original.']], [[' def justify(n):\n    return n / 1<<(n.bit_length()-1)\n']], ['Bitwise operations to produce power of two in Python'], 4, 1], [(28857930, 3), [['It is possible to do it completely with bitwise operators:'], ['But  timeit  clocks this at 2.16 microseconds. An order of magnitude slower than using  bit_length']], [[' def justify_bitwise(n):\n   int_n = int(abs(n))\n   p = 0\n   while int_n != 1:\n       p += 1\n       int_n >>= 1\n\n   return float(n) / (1<<p)\n']], ['Bitwise operations to produce power of two in Python'], 4, 1], [(28868384, 0), [['-10000'], ['yields']], [[" import numpy as np\nimport pandas as pd\nnp.random.seed(0)\ndf = pd.DataFrame(np.random.randint(5, size=(5,4)), columns=list('ABCD'))\nprint(df)\n#    A  B  C  D\n# 0  4  0  3  3\n# 1  3  1  3  2\n# 2  4  0  0  4\n# 3  2  1  0  1\n# 4  1  0  1  4\ndct = {func.__name__:df.apply(func) for func in (pd.Series.nunique, pd.Series.count)}\nprint(pd.concat(dct, axis=1))\n"]], ['Pandas Compute Unique Values per Column as Series'], 2, 1], [(28868384, 1), [['yields'], ['-10000']], [['    count  nunique\nA      5        4\nB      5        2\nC      5        3\nD      5        4\n']], ['Pandas Compute Unique Values per Column as Series'], 2, 0], [(28870344, 0), [['I like the idea of breaking out a function to do the parsing.  You can then use that function with map, or within a list comprehension.'], ['OUTPUT']], [[" inval = ['48998.tyrone-cluster;gic1_nwgs;mbupi;18:45:44;R;qp32\\n', '48999.tyrone-cluster;gic2_nwgs;mbupi;0;Q;batch\\n', '49005.tyrone-cluster;...01R-1849-01_2;mcbkss;00:44:23;R;qp32\\n', '49032.tyrone-cluster;gaussian_top.sh;chemraja;0;Q;qp32\\n', '49047.tyrone-cluster;jet_egrid;asevelt;312:33:0;R;qp128\\n', '49052.tyrone-cluster;case3sqTS1e-4;mecvamsi;0;Q;qp32\\n', '49053.tyrone-cluster;...01R-1850-01_1;mcbkss;0;Q;batch\\n', '49054.tyrone-cluster;...01R-1850-01_2;mcbkss;0;Q;batch\\n']\n\ndef parse(raw):\n    parts = raw.strip().split(';')\n    _id, _ = parts[0].split('.')\n    return _id, parts[3], parts[4], parts[5]\n\nprint map(parse, inval)\n\n# or \n# print [parse(val) for val in inval]\n"]], ['separate list elements based on semicolon'], 2, 1], [(28870344, 1), [['OUTPUT'], ['Personally I favor readability in this type of parsing.  Nested list comprehensions or more advanced techniques are completely acceptable, but simple, easy-to-follow code has extreme value in my book.']], [[" [('48998', '18:45:44', 'R', 'qp32'),\n ('48999', '0', 'Q', 'batch'),\n ('49005', '00:44:23', 'R', 'qp32'),\n ('49032', '0', 'Q', 'qp32'),\n ('49047', '312:33:0', 'R', 'qp128'),\n ('49052', '0', 'Q', 'qp32'),\n ('49053', '0', 'Q', 'batch'),\n ('49054', '0', 'Q', 'batch')]\n"]], ['separate list elements based on semicolon'], 2, 0], [(28898735, 0), [['-10000'], ['Output:']], [[' M = [[0, 0, 1, 0], [1, 0, 0, 0], [0, 0, 5, 1], [0, 1, 0, 0]]\nx=1\n\nwhile (x<=2):\n    if (x==1):\n        y=2\n    else:\n        y=0\n    while (y<=3):\n        M[x][y]="x"\n        y+=1\n    x+=1\n']], ['Python: replace multiple values of a Matrix'], 2, 1], [(28898735, 1), [['Output:'], ['-10000']], [[' [[0, 0, 1, 0], [1, 0, "x", "x"], ["x", "x", "x", "x"], [0, 1, 0, 0]]\n']], ['Python: replace multiple values of a Matrix'], 2, 0], [(28907503, 0), [["You don't need to use  $in"], ['Output']], [[' for item in col.find({"$and": [{"item1": \'a\', "item1": \'b\', "item1": \'c\'}]}):\n    print(item)\n']], ['mongo - find items who at least match an array of values'], 4, 1], [(28907503, 1), [['Output'], ['You could also use aggregation pipelines and the  $setIsSubset  operator. ']], [[" {'_id': ObjectId('54fa181014d995a397252a1a'), 'item1': ['a', 'b', 'c']}\n"]], ['mongo - find items who at least match an array of values'], 4, 0], [(28907503, 2), [['You could also use aggregation pipelines and the  $setIsSubset  operator. '], ['Output']], [[' col.aggregate([{"$project": { "item1": 1, "is_subset": { "$setIsSubset": [ [\'a\', \'b\', \'c\'], "$item1" ] }}},{"$match": {"is_subset": True}}])\n']], ['mongo - find items who at least match an array of values'], 4, 1], [(28907503, 3), [['Output'], ['-10000']], [[" {\n    'ok': 1.0,\n    'result': [\n                  {\n                      '_id': ObjectId('54fa181014d995a397252a1a'), \n                      'item1': ['a', 'b', 'c'], \n                      'is_subset': True\n                   }\n               ]\n }\n"]], ['mongo - find items who at least match an array of values'], 4, 0], [(28928049, 0), [['You need to loop over your dictionary items then write them:'], ['Result:']], [[" dictionary = {'Alice': ['10', '10'], 'Tom': ['9', '8'], 'Ben': ['10', '9']}\n\nimport csv\nwith open('eggs.csv', 'wb') as csvfile:\n    spamwriter = csv.writer(csvfile, delimiter=',')\n    for item in dictionary.items():\n         spamwriter.writerow(item)\n"]], ['Arranging keys and values from a dictionary in a csv file - Python'], 2, 1], [(28928049, 1), [['Result:'], ['-10000']], [[" Ben     ['10', '9']\nAlice   ['10', '10']\nTom     ['9', '8']\n"]], ['Arranging keys and values from a dictionary in a csv file - Python'], 2, 0], [(29033262, 1), [['json file:'], ['-10000']], [[' {\n "email" : "([^@|\\\\s]+@[^@]+\\\\.[^@|\\\\s]+)",\n "phone" : "(\\\\d{3}[-\\\\.\\\\s]??\\\\d{3}[-\\\\.\\\\s]??\\\\d{4}|\\\\(\\\\d{3}\\\\)\\\\s*\\\\d{3}[-\\\\.\\\\s]??\\\\d{4}|\\\\d{3}[-\\\\.\\\\s]??\\\\d{4})"\n}\n']], ['Execute regex located in an external file in python'], 2, 0], [(29036344, 0), [['-10000'], ['-10000']], [["models.py from django.db import models\n\nclass CheckList(models.Model):\n    name = models.CharField(max_length=255)\n    checklist_type = models.ForeignKey('CheckListType')\n    options = models.ManyToManyField('CheckListOption', blank=True)\n\n    def __unicode__(self):\n        return self.name\n\nclass CheckListType(models.Model):\n    name = models.CharField(max_length=255)\n    options = models.ManyToManyField('CheckListOption')\n\n    def __unicode__(self):\n        return self.name\n\nclass CheckListOption(models.Model):\n    name = models.CharField(max_length=255)\n\n    def __unicode__(self):\n        return self.name\n"]], ['Django Model Design - Many-To-Many Fields'], 3, 0], [(29036344, 1), [['-10000'], ['-10000']], [["forms.py from django import forms\n\nfrom .models import CheckList, CheckListOption\n\nclass CheckListForm(forms.ModelForm):\n    class Meta:\n        model = CheckList\n        fields = '__all__'\n\n    def __init__(self, *args, **kwargs):\n        super(CheckListForm, self).__init__(*args, **kwargs)\n        if self.instance.pk:\n            self.fields['options'].queryset = CheckListOption.objects.filter(\n                checklisttype=self.instance.checklist_type_id\n            )\n        else:\n            self.fields['options'].queryset = CheckListOption.objects.none()\n"]], ['Django Model Design - Many-To-Many Fields'], 3, 0], [(29036344, 2), [['-10000'], ['There is only one drawback - when you already have a saved  CheckList  instance and you want to change the  checklist_type , you wont get the new  options  on the moment. The user doing the change should unselect the selected options ( this is kind of an optional, but if not done, the selected options will remain until the next save ), save the model and edit it again to chose the new options.']], [['admin.py from django.contrib import admin\n\nfrom .forms import CheckListForm\nfrom .models import CheckList, CheckListType, CheckListOption\n\nclass CheckListAdmin(admin.ModelAdmin):\n    form = CheckListForm\n\nadmin.site.register(CheckList, CheckListAdmin)\nadmin.site.register(CheckListType)\nadmin.site.register(CheckListOption)\n']], ['Django Model Design - Many-To-Many Fields'], 3, 0], [(29041324, 0), [['This should work. First it splits by the  | . The last element of that contains your answers. Then we remove the answers from the keys. Now we split the answers into their parts. Finally we get the correct answer by searching for the  !  and save that in the string  answer .'], ['Output']], [[' with open("questions.txt", "r") as questions:\n    keys = questions.read().split(\'|\')\n    answers = keys[3]\n    keys[3] = keys[3].split(\'/\', 1)[0]\n\n    answers = answers.split(\'/\')[1:]\n\n    answer = [x for x in answers if \'!\' in x][0].strip(\'!\')\n\n    answers = [x.strip(\'!\') for x in answers]\n\n    print(keys)\n    print(answers)\n    print(answer)\n']], ['Split a string by three delimiters, and adding them to different lists'], 2, 1], [(29041324, 1), [['Output'], ['-10000']], [[" ['Poles', 'Magnet', '?', 'Battery']\n['Charge', 'Ends', 'Magic', 'Metal']\nCharge\n"]], ['Split a string by three delimiters, and adding them to different lists'], 2, 0], [(29058135, 0), [['You can do this in O(n) using a  defaultdict() :'], ['Another way is using two separate list comprehensions (not recommended fro long lists):']], [[" In [3]: from collections import defaultdict\n\nIn [4]: d = defaultdict(list)\n\nIn [5]: for num in A:\n   ...:     if num < 0:\n   ...:         d['neg'].append(num)\n   ...:     else: # This will also append zero to the positive list, you can change the behavior by modifying the conditions \n   ...:         d['pos'].append(num)\n   ...:         \n\nIn [6]: d\nOut[6]: defaultdict(<class 'list'>, {'neg': [-3, -2, -5, -7], 'pos': [1, 8, 4, 6]})\n"]], ['Python - Split a list of integers into positive and negative'], 3, 1], [(29058135, 1), [['Another way is using two separate list comprehensions (not recommended fro long lists):'], ['Or using  filter  function :']], [[' >>> B,C=[i for i in A if i<0 ],[j for j in A if j>0]\n>>> B\n[-3, -2, -5, -7]\n>>> C\n[1, 8, 4, 6]\n']], ['Python - Split a list of integers into positive and negative'], 3, 1], [(29058643, 0), [['Just concatenate these lists with  +  operator:'], ['Or, if you need an iterator and the  list  is huge, use  itertools.chain :']], [[' range(15, 30, 3) + [0]\n']], ['Extend Python list "inline"'], 2, 1], [(29058643, 1), [['Or, if you need an iterator and the  list  is huge, use  itertools.chain :'], ["A quick note:  range  creates a  range  object in Python 3+, which doesn't allow concatenation:"]], [[' import itertools\nit = itertools.chain(range(15, 30, 3), [0])\n']], ['Extend Python list "inline"'], 2, 1], [(29083478, 0), [["I'm not quite sure what you want, but this code gives you all the complete diagonals in each direction:"], ['That is:']], [[' L = [[1,2,3],[4,5,6], [7,8,9]]\n# number of rows, number of columns: ie L is m x n\nm, n = len(L), len(L[0])\n\n# Retreive the NE-SW (diag1) and NW-SE (diag2) diagonals\ndiag1 = []\ndiag2 = []\nfor p in range(m+n-1):\n    diag1.append([])\n    diag2.append([])\n    q1 = 0\n    if p >= n:\n        q1 = p - n + 1\n    q2 = m\n    if p < m-1:\n        q2 = p+1\n    for q in range(q1, q2):\n        x, y = p - q, q\n        diag1[-1].append(L[y][x])\n        # To get the other diagonal, read each row "backwards"\n        x = n - x - 1\n        diag2[-1].append(L[y][x])\nprint \'diag1:\', diag1\nprint \'diag2:\', diag2\n']], ['Diagonals at different points of a 2D list in Python'], 2, 1], [(29083478, 1), [['That is:'], ['-10000']], [[' diag1: [[1], [2, 4], [3, 5, 7], [6, 8], [9]]\ndiag2: [[3], [2, 6], [1, 5, 9], [4, 8], [7]]\n']], ['Diagonals at different points of a 2D list in Python'], 2, 0], [(29087010, 0), [['Also that just returns a readable string representing the object. It does not print it. You would want to do.'], ['or just']], [[' print(self.__str__())\n']], ['call __str__ inside a class? python 3.X'], 2, 1], [(29087010, 1), [['or just'], ['-10000']], [[' print(self)\n']], ['call __str__ inside a class? python 3.X'], 2, 1], [(29112610, 0), [["To expand on @Justin 's answer:  what is happening:"], ['You should look at the DStream transformations: e.g. map(): here is code that is not 100% debugged yet - but it provides a structure:']], [[' median()\n']], ['Finding median in Spark Streaming'], 2, 0], [(29112610, 1), [['You should look at the DStream transformations: e.g. map(): here is code that is not 100% debugged yet - but it provides a structure:'], ['-10000']], [[' from pyspark.streaming import *\nssc = StreamingContext(sc, 30)\ndataRdd = [sc.parallelize(d, 1) for d in [[1,2,3],[4,5],[6,7,8,9,9]]]\nqs = ssc.queueStream(dataRdd)\n\ndef list_median((med,mylist),newval):\n    mylist = [newval] if not mylist else mylist.append(newval)\n    mylist = sorted(mylist)\n    return (mylist[int(len(mylist)/2)], mylist)\n\nmedians = qs.reduce(list_median).map(lambda (med,list): med)\ndef printRec(rdd):\n    import sys\n    rdd.foreach(lambda rec: sys.stderr.write(repr(rec)))\n\nmedians.foreachRDD(printRec)\nssc.start(); ssc.awaitTermination()\n']], ['Finding median in Spark Streaming'], 2, 1], [(29114133, 0), [['Working with  itertools  early in the morning is a recipe for disaster, but something like'], ['should work:']], [[' from itertools import product, takewhile\ndef new(max_len_string, alphabet=range(2)):\n    alphabet = list(alphabet)\n    zero = alphabet[0]\n    for p in product(alphabet, repeat=max_len_string):\n        right_zeros = sum(1 for _ in takewhile(lambda x: x==zero, reversed(p)))\n        base = p[:-right_zeros]\n        yield from filter(None, (base+(zero,)*i for i in range(right_zeros)))\n        yield p\n']], ['Iterator for all lexicographically ordered variable strings up to length n'], 2, 1], [(29114133, 1), [['should work:'], ["This assumes the alphabet is passed in the canonical order;  list  can be replaced with  sorted  if that's not the case."]], [[' >>> list(new(3)) == list(variable_strings_complete(3))\nTrue\n>>> list(new(20)) == list(variable_strings_complete(20))\nTrue\n>>> list(new(10, alphabet=range(4))) == list(variable_strings_complete(10, range(4)))\nTrue\n']], ['Iterator for all lexicographically ordered variable strings up to length n'], 2, 0], [(29114975, 0), [['-10000'], ['This produces the output:']], [[" array = [ [int(s) for s in line.split()] for line in open('file') ]\nfor line in array:\n    print('%08i %3.1f %3i %3i' % (line[0], sum(line[1:])/len(line[1:]), min(line[1:]), max(line[1:])))\n"]], ['Need to read from a file and add the elements and get avg in python 3.4'], 3, 1], [(29114975, 1), [['This produces the output:'], ['-10000']], [[' 75647485 14.4  10  20\n63338495 17.2  11  20\n00453621 11.2   3  20\n90812341 15.2   7  20\n']], ['Need to read from a file and add the elements and get avg in python 3.4'], 3, 0], [(29114975, 2), [['-10000'], ['-10000']], [[" with open('file') as f:\n    array = [ [int(s) for s in line.split()] for line in f ]\nfor line in array:\n    print('{:08.0f} {:3.1f} {:3.0f} {:3.0f}'.format(line[0], sum(line[1:])/len(line[1:]), min(line[1:]), max(line[1:])))\n"]], ['Need to read from a file and add the elements and get avg in python 3.4'], 3, 1], [(29153805, 0), [['You could convert the boolean series  df.col2 > 0  to an integer series ( True  becomes  1  and  False  becomes  0 ):'], ['This produces  col3  as:']], [[" df['col3'] = (df.col2 > 0).astype('int')\n"]], ['pandas: Use if-else to populate new column'], 3, 1], [(29153805, 1), [['This produces  col3  as:'], ['Another way to create the column could be to use  np.where , which lets you specify a value for either of the true or false values and is perhaps closer to the syntax of the R function  ifelse . For example:']], [['    col2  col3\n0     0     0\n1     1     1\n2     0     0\n3     0     0\n4     3     1\n5     0     0\n6     4     1\n']], ['pandas: Use if-else to populate new column'], 3, 0], [(29153805, 2), [['Another way to create the column could be to use  np.where , which lets you specify a value for either of the true or false values and is perhaps closer to the syntax of the R function  ifelse . For example:'], ['-10000']], [[" >>> np.where(df['col2'] > 0, 4, -1)\narray([-1,  4, -1, -1,  4, -1,  4])\n"]], ['pandas: Use if-else to populate new column'], 3, 1], [(29153930, 0), [['Version 2.1 introduced the  metadata  argument to the extension.  If all you want to customize about the base model is the metadata, you can pass a custom  MetaData  instance to it.'], ['-10000']], [[" db = SQLAlchemy(metadata=MetaData(naming_convention={\n    'pk': 'pk_%(table_name)s',\n    'fk': 'fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s',\n    'ix': 'ix_%(table_name)s_%(column_0_name)s',\n    'uq': 'uq_%(table_name)s_%(column_0_name)s',\n    'ck': 'ck_%(table_name)s_%(constraint_name)s',\n}))\n"]], ['Changing constraint naming conventions in Flask-SQLAlchemy'], 2, 1], [(29153930, 1), [['-10000'], ['-10000']], [[" from flask_sqlalchemy import SQLAlchemy as BaseSQLAlchemy, Model, _BoundDeclarativeMeta, _QueryProperty\nfrom sqlalchemy import MetaData\n\nclass SQLAlchemy(BaseSQLAlchemy):\n    def make_declarative_base(self):\n        metadata = MetaData(naming_convention={\n            'pk': 'pk_%(table_name)s',\n            'fk': 'fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s',\n            'ix': 'ix_%(table_name)s_%(column_0_name)s',\n            'uq': 'uq_%(table_name)s_%(column_0_name)s',\n            'ck': 'ck_%(table_name)s_%(constraint_name)s',\n        })\n        base = declarative_base(metadata=metadata, cls=Model, name='Model', metaclass=_BoundDeclarativeMeta)\n        base.query = _QueryProperty(self)\n        return base\n"]], ['Changing constraint naming conventions in Flask-SQLAlchemy'], 2, 1], [(29155628, 0), [['Use  csv  module.'], ['Output file:']], [[' # Test Parser\n\nfrom xml.dom.minidom import parse\nimport csv \n\n\ndef writeToCSV(myLibrary):\n    csvfile = open(\'output.csv\', \'w\')\n    fieldnames = [\'title\', \'author\']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n\n    books = myLibrary.getElementsByTagName("book")\n    for book in books:\n        titleValue = book.getElementsByTagName("title")[0].childNodes[0].data\n        for author in book.getElementsByTagName("author"):\n            authorValue = author.childNodes[0].data\n            writer.writerow({\'title\': titleValue, \'author\': authorValue})\n\ndoc = parse(\'library.xml\')\nmyLibrary = doc.getElementsByTagName("library")[0]\n\n# Get book elements in library\nbooks = myLibrary.getElementsByTagName("book")\n\n# Print each book\'s title\nwriteToCSV(myLibrary)\n']], ['Python minidom - Parse XML file and write to CSV'], 2, 1], [(29155628, 1), [['Output file:'], ['-10000']], [[' title,author\nSandman Volume 1: Preludes and Nocturnes,Neil Gaiman\nGood Omens,Neil Gamain\nGood Omens,Terry Pratchett\n"""Repent, Harlequin!"" Said the Tick-Tock Man",Harlan Ellison\n']], ['Python minidom - Parse XML file and write to CSV'], 2, 0], [(29192826, 0), [['You could use  pd.get_dummies :'], ['yields']], [[" import pandas as pd\nd = {'a': [1,2,3,4,3,3,3], 'b': [5,6,7,8,4,4,4], 'c': [9,10,11,12,3,3,3], \n     'd': pd.Series(['red', 'blue', 'green', 'red', 'orange', 'blue', 'red'], \n                    dtype='category')}\ndf = pd.DataFrame(d)\ndummies = pd.get_dummies(df['d'])\ndf = pd.concat([df, dummies], axis=1)\ndf = df.drop(['d', 'green'], axis=1)\nprint(df)\n"]], ["R's relevel() and factor variables in linear regression in pandas"], 5, 0], [(29192826, 1), [['yields'], ['-10000']], [['    a  b   c  blue  orange  red\n0  1  5   9     0       0    1\n1  2  6  10     1       0    0\n2  3  7  11     0       0    0\n3  4  8  12     0       0    1\n4  3  4   3     0       1    0\n5  3  4   3     1       0    0\n6  3  4   3     0       0    1\n']], ["R's relevel() and factor variables in linear regression in pandas"], 5, 0], [(29192826, 2), [['-10000'], ['yields']], [[" import statsmodels.formula.api as smf\nmodel = smf.ols('a ~ b + c + blue + orange + red', df).fit()\nprint(model.summary())\n"]], ["R's relevel() and factor variables in linear regression in pandas"], 5, 0], [(29192826, 3), [['yields'], ['-10000']], [['                             OLS Regression Results                            \n==============================================================================\nDep. Variable:                      a   R-squared:                       1.000\nModel:                            OLS   Adj. R-squared:                  1.000\nMethod:                 Least Squares   F-statistic:                 2.149e+25\nDate:                Sun, 22 Mar 2015   Prob (F-statistic):           1.64e-13\nTime:                        05:57:33   Log-Likelihood:                 200.74\nNo. Observations:                   7   AIC:                            -389.5\nDf Residuals:                       1   BIC:                            -389.8\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nIntercept     -1.6000   6.11e-13  -2.62e+12      0.000        -1.600    -1.600\nb              1.6000   1.59e-13   1.01e+13      0.000         1.600     1.600\nc             -0.6000   6.36e-14  -9.44e+12      0.000        -0.600    -0.600\nblue         1.11e-16   3.08e-13      0.000      1.000     -3.91e-12  3.91e-12\norange      7.994e-15   3.87e-13      0.021      0.987     -4.91e-12  4.93e-12\nred         4.829e-15   2.75e-13      0.018      0.989     -3.49e-12   3.5e-12\n==============================================================================\nOmnibus:                          nan   Durbin-Watson:                   0.203\nProb(Omnibus):                    nan   Jarque-Bera (JB):                0.752\nSkew:                           0.200   Prob(JB):                        0.687\nKurtosis:                       1.445   Cond. No.                         85.2\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n']], ["R's relevel() and factor variables in linear regression in pandas"], 5, 0], [(29195983, 0), [['One approach is to use  format  and  zfill'], ["You can also accomplish this with just a single  format  (although it's a little harder to read)"]], [[' n = 27\nprint "{0:b}".format(n).zfill(10) # prints "0000011010"\n']], ['Python - workaround with sets'], 2, 1], [(29195983, 1), [["You can also accomplish this with just a single  format  (although it's a little harder to read)"], ['-10000']], [[' n = 27\nprint "{0:010b}".format(n) # prints "0000011010"\n']], ['Python - workaround with sets'], 2, 1], [(29224567, 0), [['Suppose we have the same shape of a array of arrays you mention:'], ['We can test each elements with a where clause:']], [[' >>> A=np.array([np.random.random((4,3)), np.random.random((3,2))])\n>>> A\narray([ array([[ 0.20621572,  0.83799579,  0.11064094],\n       [ 0.43473089,  0.68767982,  0.36339786],\n       [ 0.91399729,  0.1408565 ,  0.76830952],\n       [ 0.17096626,  0.49473758,  0.158627  ]]),\n       array([[ 0.95823229,  0.75178047],\n       [ 0.25873872,  0.67465796],\n       [ 0.83685788,  0.21377079]])], dtype=object)\n']], ['Python: compare an array element-wise with a float'], 4, 0], [(29224567, 2), [['But not the whole thing:'], ['So just rebuild the array B thus:']], [[' >>> A>.2\nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n']], ['Python: compare an array element-wise with a float'], 4, 0], [(29238534, 0), [['See example for  eval :'], ['See example for  exec .']], [[' def fun():\n    print "in fun"\n\neval("fun()")\n\nx="fun()"\neval(x)\n']], ['Execute a string as a command'], 2, 1], [(29238534, 1), [['See example for  exec .'], ['-10000']], [[' exec("print \'hi\'")\n']], ['Execute a string as a command'], 2, 1], [(29246483, 0), [['It would be easier to pick an index at random from  myList .'], ['But if you are stuck with picking an item, just get the index of the item with the...  index  function!']], [[" from random import randint\n\nmyList = ['a', 'b', 'c']\nmyOtherList = [1, 2, 3]\n\nindex = randint(0, len(myList)-1)\n\ndel myList[index]\ndel myOtherList[index]\n"]], ['Removing an element from a list and a corresponding value'], 2, 1], [(29258758, 0), [["I really don't understand the Assignment sheet, Specifically boxes needed to buy, which will always return 10, but I think this is what it is asking for:"], ['Returns:']], [[" #!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport random   \ndef box():\n    startbox = 0\n    allcards = 0\n    cards = [1,2,3,4,5,6,7,8,9,10]\n    curcards = []\n    while True:\n        randomn = random.randrange(0,10)\n        allcards = allcards+1\n        if str(cards[randomn]) not in curcards:\n            cards[randomn]\n            startbox = startbox + 1\n            curcards.append(str(cards[randomn]))\n        if len(curcards) == 10:\n            break\n    return 'Boxes to buy: ' + str(startbox) + ' Cards Found: ' + '; '.join(curcards) + ' Total amount of cards: ' + str(allcards)\n\n#print box()\nbox()\n"]], ['How to use an array to keep track of different numbers?'], 2, 1], [(29258758, 1), [['Returns:'], ['-10000']], [[' Boxes to buy: 10 Cards Found: 9; 1; 2; 8; 5; 7; 10; 6; 4; 3 Total Amount Of Cards: 31\n']], ['How to use an array to keep track of different numbers?'], 2, 0], [(29263680, 0), [['You can do:'], ['Prints:']], [[" txt='''\\\nCall me on my mobile anytime: 555-666-1212 \nThe office is best at 555-222-3333 \nDont ever call me at 555-666-2345 '''\n\nimport re\n\nprint re.findall(r'(?:(mobile|office).{0,15}(\\+?[2-9]\\d{2}\\)?[ -]?\\d{3}[ -]?\\d{4}))', txt)\n"]], ['Regex match following substring in string python'], 2, 1], [(29263680, 1), [['Prints:'], ['-10000']], [[" [('mobile', '555-666-1212'), ('office', '555-222-3333')]\n"]], ['Regex match following substring in string python'], 2, 0], [(29308274, 1), [['The last timestamps in  a  that are smaller than or equal to each item in  b  would be  [0, 4, 6] , which correspond to indices  [0, 2, 3] , which is exactly what we get if we do:'], ["If you don't use  side='right'  then you would get wrong values for the second term, where there is an exactly matching timestamp in both arrays:"]], [[" >>> np.searchsorted(a, b, side='right') - 1\narray([0, 2, 3])\n>>> a[np.searchsorted(a, b, side='right') - 1]\narray([0, 4, 6])\n"]], ['Using np.searchsorted to find the most recent timestamp'], 3, 0], [(29308274, 2), [["If you don't use  side='right'  then you would get wrong values for the second term, where there is an exactly matching timestamp in both arrays:"], ['-10000']], [[' >>> np.searchsorted(a, b) - 1\narray([0, 1, 3])\n']], ['Using np.searchsorted to find the most recent timestamp'], 3, 0], [(29309643, 0), [['You can use a  dict comprehension  and slicing :'], ['In python 3 you can use a more elegant way with unpacking operation :']], [[" >>> list1 = [['James','24','Canada','Blue','Tall'],['Ryan','21','U.S.','Green','Short']]\n>>> {i[0]:i[1:] for i in list1}\n{'James': ['24', 'Canada', 'Blue', 'Tall'], 'Ryan': ['21', 'U.S.', 'Green', 'Short']}\n"]], ['Converting List to Dict'], 2, 1], [(29318963, 0), [['You can use  DataFrame.interpolate  with the  "time"  method after a  resample .  (It won\'t give quite the numbers you gave, because there are only 30 days between 2 Nov and 2 Dec, not 31):'], ["The downside here is that it'll extrapolate using the last value at the end:"]], [[' >>> dnew = df.resample("1d").interpolate("time")\n>>> dnew.head(100)\n                 295340      299616\n2014-11-02   304.904110  157.123288\n2014-11-03   314.650753  162.068795\n[...]\n2014-11-28   558.316839  285.706466\n2014-11-29   568.063483  290.651972\n2014-11-30   577.810126  295.597479\n2014-12-01   587.556770  300.542986\n2014-12-02   597.303413  305.488493\n2014-12-03   606.948799  310.299014\n[...]\n2014-12-30   867.374215  440.183068\n2014-12-31   877.019600  444.993589\n2015-01-01   886.664986  449.804109\n2015-01-02   896.310372  454.614630\n[...]\n2015-02-01  1182.828960  594.911891\n2015-02-02  1192.379580  599.588466\n[...]\n']], ['Pandas, Filling between dates with average change between previous rows'], 2, 1], [(29318963, 1), [["The downside here is that it'll extrapolate using the last value at the end:"], ["So you'd have to decide how you want to handle that."]], [[' [...]\n2015-01-31  1173.278341  590.235315\n2015-02-01  1182.828960  594.911891\n2015-02-02  1192.379580  599.588466\n2015-02-03  1201.832532  604.125411\n2015-02-04  1211.285484  608.662356\n2015-02-05  1211.285484  613.199302\n2015-02-06  1211.285484  617.736247\n[...]\n']], ['Pandas, Filling between dates with average change between previous rows'], 2, 0], [(29327493, 0), [['You are basically looking for  Thresholding , basically the concept is selecting a threshold value and any pixel value (grayscale) greater than threshold is set to be white and black otherwise.  OpenCV  has some beautiful inbuilt methods to do the same but it is really simple code:'], ['Now we simply iterate over the image and substitute the values accordingly.']], [[' skin = #Initialize this variable with the image produced after separating the skin pixels from the image.\n\nbw_image = cv2.cvtColor(skin, cv2.HSV2GRAY)\n\nnew_image = bw_image[:]\n\nthreshold = 1 \n #This value is set to 1 because We want to separate out the pixel values which are purely BLACK whose grayscale value is constant (0) \n']], ['Trying to convert HSV image to Black and white [opencv]'], 2, 0], [(29327493, 1), [['Now we simply iterate over the image and substitute the values accordingly.'], ['-10000']], [[' h,b = skin.shape[:2]    \n\nfor i in xrange(h):\n    for j in xrange(b):\n        if bw_image[i][j] > threshold:\n            new_image[i][j] = 255 #Setting the skin tone to be White\n        else:\n            new_image[i][j] = 0 #else setting it to zero.\n']], ['Trying to convert HSV image to Black and white [opencv]'], 2, 0], [(29351492, 0), [['Use  itertools.product .'], ['Result:']], [[' from string import ascii_lowercase\nimport itertools\n\ndef iter_all_strings():\n    size = 1\n    while True:\n        for s in itertools.product(ascii_lowercase, repeat=size):\n            yield "".join(s)\n        size +=1\n\nfor s in iter_all_strings():\n    print s\n    if s == \'bb\':\n        break\n']], ['How to make a continuous alphabetic list python (from a-z then from aa, ab, ac etc)'], 3, 1], [(29351492, 1), [['Result:'], ["Bonus style tip: if you don't like having an explicit  break  inside the bottom loop, you can use  islice  to make the loop terminate on its own:"]], [[' a\nb\nc\nd\ne\n...\ny\nz\naa\nab\nac\n...\nay\naz\nba\nbb\n']], ['How to make a continuous alphabetic list python (from a-z then from aa, ab, ac etc)'], 3, 0], [(29351492, 2), [["Bonus style tip: if you don't like having an explicit  break  inside the bottom loop, you can use  islice  to make the loop terminate on its own:"], ['-10000']], [[' for s in itertools.islice(iter_all_strings(), 54):\n    print s\n']], ['How to make a continuous alphabetic list python (from a-z then from aa, ab, ac etc)'], 3, 0], [(29356022, 0), [['Create your Pipe when you create the Process, and return a tuple of the Process an Pipe.'], ['After calling  mkproc  to create processes, store the result in a list;']], [[' import multiprocessing as mp\n\ndef mkproc(func):\n    parent_conn, child_conn = mp.Pipe()\n    p = mp.Process(func, args=(child_conn,))\n    p.start()\n    return (p, parent_conn)\n']], ['python multiprocessing dynamically created processes and pipes'], 3, 0], [(29356022, 1), [['After calling  mkproc  to create processes, store the result in a list;'], ['The contents of  allproc  is now a list of ( Process ,  Pipe ) tuples. If you iterate over the list you have the process and the pipe that belongs with it;']], [[' allprocs = [mkproc(f) for f in (foo, bar, baz)]\n']], ['python multiprocessing dynamically created processes and pipes'], 3, 0], [(29356022, 2), [['The contents of  allproc  is now a list of ( Process ,  Pipe ) tuples. If you iterate over the list you have the process and the pipe that belongs with it;'], ['-10000']], [[' for proc, conn in allprocs:\n    # do something with the process or pipe.\n']], ['python multiprocessing dynamically created processes and pipes'], 3, 0], [(29365357, 0), [['If you need arbitrary criteria, then filtering is OK, but it is slightly shorter to use a list comprehension. For example, instead of'], ['use:']], [[' self.skills = filter(lambda skill: skill.id != skill_to_remove.id, self.skills)\n']], ['Python. How to efficiently remove custom object from array'], 3, 0], [(29384588, 0), [['So, instead of calling:'], ['Do:']], [[' transactional.reset_index(inplace = True)\n']], ['How to reset an unordered index to an ordered one in python?'], 2, 0], [(29384588, 1), [['Do:'], ['-10000']], [[' transactional.reset_index(inplace = True, drop=True)\n']], ['How to reset an unordered index to an ordered one in python?'], 2, 1], [(29392606, 0), [['This approach is the fastest I have tried:'], ['This approach is a tiny bit little slower:']], [[" foo = foobar2.clip_lower(0)\nfoo = foo['var1']+foo['var2']-foo['var3']-foo['var4']\n"]], ['Pandas: Adding conditionally'], 3, 1], [(29392606, 1), [['This approach is a tiny bit little slower:'], ['You can also use the  apply  method for a one-liner, which is simpler and clearer but also slower even than your approach:']], [[" foo = foobar2.clip_lower(0)\nfoo['var3']*=-1\nfoo['var4']*=-1\nfoo = foo.sum(axis=1)\n"]], ['Pandas: Adding conditionally'], 3, 1], [(29392606, 2), [['You can also use the  apply  method for a one-liner, which is simpler and clearer but also slower even than your approach:'], ['-10000']], [[" foo = foobar2.clip_lower(0).apply(lambda x: x['var1']+x['var2']-x['var3']-x['var4'], axis=1)\n"]], ['Pandas: Adding conditionally'], 3, 1], [(29395674, 0), [['Try picking a random string of letters, then a random string of digits, then joining them with a hyphen:'], ['As such:']], [[' import string, random\ndef pick(num):\n    for j in range(num):\n        print("".join([random.choice(string.ascii_uppercase) for i in range(3)])+"-"+"".join([random.choice(string.digits) for i in range(3)]))\n']], ['Generate two random strings with dash in between'], 2, 1], [(29395674, 1), [['As such:'], ['-10000']], [[' >>> pick(5)\nOSD-711\nKRH-340\nMDE-271\nZJF-921\nLUX-920\n>>> pick(0)\n>>> pick(3)\nSFT-252\nXSL-209\nMAF-579\n']], ['Generate two random strings with dash in between'], 2, 0], [(29415538, 0), [['In case you want  G  to have the same dimensionality as  A  and then change the appropriate elements of  G , the following code should work:'], ['After fiddling a long time and finding bugs ... I ended up with this code. I checked it against several random matrices  A  and specific choices of  B  ']], [[" # create G as a copy of A, otherwise you might change A by changing G\nG = A.copy()\n\n# getting the mask for all columns except the last one\nm = (B[:,0][:,None] != np.arange(d2-1)[None,:]) & (B[:,1]==0)[:,None]\n\n# getting a matrix with those elements of A which fulfills the conditions\nC = np.where(m,A[:,:d2-1],0).astype(np.float)\n\n# get the 'modified' average you use\navg = np.sum(C,axis=0)/np.sum(m.astype(np.int),axis=0)\n\n# change the appropriate elements in all the columns except the last one\nG[:,:-1] = np.where(m,avg,A[:,:d2-1])\n"]], ['numpy array slicing to avoid for loop'], 2, 1], [(29415538, 1), [['After fiddling a long time and finding bugs ... I ended up with this code. I checked it against several random matrices  A  and specific choices of  B  '], ['and so far your and my result were in agreement.']], [[' A = numpy.random.randint(100,size=(5,10))\nB = np.column_stack(([4,2,1,3,4],np.zeros(5)))\n']], ['numpy array slicing to avoid for loop'], 2, 0], [(29451598, 0), [['After you extract the script contents, use regular expressions to extract the desired javascript object, then, load it via  json.loads()  to get the Python dictionary:'], ['Prints:']], [[' import json\nimport re\nfrom bs4 import BeautifulSoup\nimport requests\n\npattern = re.compile(r"window\\.BC\\.product = (.*);", re.MULTILINE)\n\nresponse = requests.get("http://www.steepandcheap.com/gear-cache/shop-smartwool-on-sale/SWL00II-GRA")\nsoup = BeautifulSoup(response.content)   \n\nscript = soup.find("script", text=lambda x: x and "window.BC.product" in x).text\ndata = json.loads(re.search(pattern, script).group(1))\nprint data\n']], ["Scrape 'dictionary' type object from top of HTML file (bunch of text, not in a class)"], 2, 1], [(29451598, 1), [['Prints:'], ['-10000']], [[" {u'features': [{u'name': u'Material', u'description': u'[shell] 86% polyester, ... u'Zippered back pocket\\r', u'Reflective details']}\n"]], ["Scrape 'dictionary' type object from top of HTML file (bunch of text, not in a class)"], 2, 0], [(29481485, 0), [['Create data:'], ['Output:']], [[" import pandas as pd\nfrom scipy.spatial import distance_matrix\n\ndata = [[5, 7], [7, 3], [8, 1]]\nctys = ['Boston', 'Phoenix', 'New York']\ndf = pd.DataFrame(data, columns=['xcord', 'ycord'], index=ctys)\n"]], ['Creating a Distance Matrix?'], 4, 0], [(29481485, 1), [['Output:'], ['Using the distance matrix function:']], [['           xcord ycord\nBoston      5   7\nPhoenix     7   3\nNew York    8   1\n']], ['Creating a Distance Matrix?'], 4, 0], [(29481485, 2), [['Using the distance matrix function:'], ['Results:']], [['  pd.DataFrame(distance_matrix(df.values, df.values), index=df.index, columns=df.index)\n']], ['Creating a Distance Matrix?'], 4, 0], [(29481485, 3), [['Results:'], ['-10000']], [['           Boston    Phoenix     New York\nBoston    0.000000  4.472136    6.708204\nPhoenix   4.472136  0.000000    2.236068\nNew York  6.708204  2.236068    0.000000\n']], ['Creating a Distance Matrix?'], 4, 0], [(29484529, 0), [['You could define these two functions'], ['and use them as in this example']], [[' def word2vec(word):\n    from collections import Counter\n    from math import sqrt\n\n    # count the characters in word\n    cw = Counter(word)\n    # precomputes a set of the different characters\n    sw = set(cw)\n    # precomputes the "length" of the word vector\n    lw = sqrt(sum(c*c for c in cw.values()))\n\n    # return a tuple\n    return cw, sw, lw\n\ndef cosdis(v1, v2):\n    # which characters are common to the two words?\n    common = v1[1].intersection(v2[1])\n    # by definition of cosine distance we have\n    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]\n']], ['cosine similarity between two words in a list'], 2, 1], [(29484529, 1), [['and use them as in this example'], ["BTW, the  word2vec  that you mention in a tag is quite a different business, that requires that one of us take a great deal of time and commitment for studying it and guess what, I'm not that one..."]], [[" >>> a = 'safasfeqefscwaeeafweeaeawaw'\n>>> b = 'tsafdstrdfadsdfdswdfafdwaed'\n>>> c = 'optykop;lvhopijresokpghwji7'\n>>> \n>>> va = word2vec(a)\n>>> vb = word2vec(b)\n>>> vc = word2vec(c)\n>>> \n>>> print cosdis(va,vb)\n0.551843662321\n>>> print cosdis(vb,vc)\n0.113746579656\n>>> print cosdis(vc,va)\n0.153494378078\n"]], ['cosine similarity between two words in a list'], 2, 0], [(29497029, 0), [['I think you want the  BlockDeviceMapping  for the instance.  Based on your example above the following should find the  block_device_mapping  for the instance which is a dictionary.  Each key in the dictionary is a device name and the value is a  BlockDeviceType  object which contain information about the block device associated with that device name.'], ['This should print something like:']], [[" for reservation in reservations:\n    for instance in reservation.instances:\n        bdm = instance.block_device_mapping\n        for device in bdm:\n            print('Device: {}'.format(device)\n            bdt = bdm[device]\n            print('\\tVolumeID: {}'.format(bdt.volume_id))\n            print('\\tVolume Status: {}'.format(bd.volume_status))\n"]], ['Python Boto List Storage Devices Attached to Instance'], 2, 1], [(29497029, 1), [['This should print something like:'], ['There are other fields in the  BlockDeviceType  object.  You should be able to find more info about that in the Boto docs.']], [[' Device: /dev/sda1\n    VolumeID: vol-1d011806\n    Volume Size: attached\n']], ['Python Boto List Storage Devices Attached to Instance'], 2, 0], [(29509781, 0), [['Assignments are wide and varied and can include assignments that are explicitly discarded again. For example, if your function was used in a comparison expression:'], ['Using different functions:']], [[" if f() == 'Return something':\n"]], ['In python, return value only when the function is used in an assignment'], 3, 0], [(29509781, 1), [['Using different functions:'], ['or parameters:']], [[' def f_with_return():\n    return \'something\'\n\ndef f_without_return():\n    f_with_return()  # ignores the return value!\n    print "I won\'t return something"\n']], ['In python, return value only when the function is used in an assignment'], 3, 0], [(29509781, 2), [['or parameters:'], ['lets you control what is returned.']], [[' def f(return_something=True):\n    if return_something:\n        return \'something\'\n    print "I won\'t return something"\n']], ['In python, return value only when the function is used in an assignment'], 3, 0], [(29514238, 0), [["Here's one solution:"], ['You could use the following, too:']], [[' headers = {key for count in counts_to_display.values() for key in count}\n']], ['How to write defaultdict in more pythonic way?'], 2, 1], [(29514238, 1), [['You could use the following, too:'], ['-10000']], [[' import itertools\nheaders = set(itertools.chain.from_iterable(counts_to_display.values()))\n']], ['How to write defaultdict in more pythonic way?'], 2, 1], [(29527654, 0), [['To clean iOS simulator:'], ['To clean android simulator:']], [[' xcrun simctl erase <udid here>\n']], ['Appium - Clean app state at the first test and last test, but not between tests'], 2, 0], [(29527654, 1), [['To clean android simulator:'], ['Note that for android simulator, this must be run while the simulator is open and the app closed.']], [[' adb shell pm clear <app package here>\n']], ['Appium - Clean app state at the first test and last test, but not between tests'], 2, 0], [(29538559, 1), [['For example,'], ['Do not call  df.plot  or  plt.scatter  once for each dot. That would become terribly slow as the number of dots increases. Instead, collect requisite the data (the longitudes and latitudes) in the DataFrame so that the dots can be drawn with  one call  to  df.plot :']], [[" import pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({'Total': [20,15,13,1],\n                   'lat': [40,0,-30,50],\n                   'lon': [40,50,60,70], }, \n                  index=['Location {}'.format(i) for i in range(1,5)])\n\ncmap = plt.get_cmap('gist_rainbow_r')\ndf.plot(kind='scatter', x='lon', y='lat', s=df['Total']*50, c=df['Total'], cmap=cmap)\n\nfor idx, row in df.iterrows():\n    x, y = row[['lon','lat']]\n    plt.annotate(\n        str(idx), \n        xy = (x, y), xytext = (-20, 20),\n        textcoords = 'offset points', ha = 'right', va = 'bottom',\n        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n\nplt.show()\n"]], ['Draw different sized circles on a map'], 3, 1], [(29547906, 0), [['In Python with  Pandas  you can do:'], ['-10000']], [[' import pandas as pd\n\ndf = pd.read_clipboard() # from your sample\n\ndf\n   ID Code\n0   1    A\n1   1    B\n2   1    C\n3   2    A\n4   2    C\n5   3    B\n6   3    C\n']], ['How do I collapse categorical data into a single record in R or Python?'], 2, 0], [(29571644, 0), [["At first I have written Java class which adds configuration of additional layers to default resources for  org.apache.hadoop.conf.Configuration . It's static initialization appends Configuration default resoutces:"], ['Now I need to extend Python Spark scripts with access to configurator during Spark context startup:']], [[' public class Configurator {\n\n    static {\n\n        // We initialize needed Hadoop configuration layers default configuration\n        // by loading appropriate classes.\n\n        try {\n            Class.forName("org.apache.hadoop.hdfs.DistributedFileSystem");\n        } catch (ClassNotFoundException e) {\n            LOG.error("Failed to initialize HDFS configuartion layer.");\n        }\n\n        try {\n            Class.forName("org.apache.hadoop.mapreduce.Cluster");\n        } catch (ClassNotFoundException e) {\n            LOG.error("Failed to initialize YARN/MapReduce configuartion layer.");\n        }\n\n        // We do what actually HBase should: default HBase configuration\n        // is added to default Hadoop resources.\n        Configuration.addDefaultResource("hbase-default.xml");\n        Configuration.addDefaultResource("hbase-site.xml");\n    }\n\n    // Just \'callable\' handle.\n    public void init() {\n    }\n\n}\n']], ['Custom Hadoop Configuration for Spark from Python (PySpark)?'], 2, 0], [(29571644, 1), [['Now I need to extend Python Spark scripts with access to configurator during Spark context startup:'], ['So now normal Hadoop  new Configuration()  construction (which is common inside  PythonRDD  infrastructure for Hadoop-based datasets) leads to all layers configuration loaded from class path where I can place configuration for needed cluster.']], [[' # Create minimal Spark context.\nsc = SparkContext(appName="ScriptWithIntegratedConfig")\n\n# It\'s critical to initialize configurator so any\n# new org.apach.hadoop.Configuration object loads our resources.\nsc._jvm.com.wellcentive.nosql.Configurator.init()\n']], ['Custom Hadoop Configuration for Spark from Python (PySpark)?'], 2, 0], [(29573963, 0), [['Use list_comprehension.'], ['Update:']], [[" >>> x = ['temp1_a','temp2_b', None, 'temp3_c']\n>>> y, z  = [i if i is None else i.split('_')[0] for i in x ], [i if i is None else i.split('_')[1] for i in x ]\n>>> y\n['temp1', 'temp2', None, 'temp3']\n>>> z\n['a', 'b', None, 'c']\n"]], ['How do I split items in a list (with delimiter) within a list?'], 2, 1], [(29573963, 1), [['Update:'], ['-10000']], [[" >>> x = [['temp1_a','temp2_b', None, 'temp3_c'],['list1_a','list2_b','list3_c']]\n>>> y, z = [i if i is None else i.split('_')[0] for i in itertools.chain(*x)], [i if i is None else i.split('_')[1] for i in itertools.chain(*x) ]\n>>> y\n['temp1', 'temp2', None, 'temp3', 'list1', 'list2', 'list3']\n>>> z\n['a', 'b', None, 'c', 'a', 'b', 'c']\n"]], ['How do I split items in a list (with delimiter) within a list?'], 2, 1], [(29600513, 0), [['While there are compatibility libraries;  six  and  future  being the 2 most widely known, sometimes one needs to live without compatibility libs. You can always write your own class decorator, and put it into say  mypackage/compat.py . The following works nicely for writing the class in Python 3 format and converting the 3-ready class to Python 2 if needed (the same can be used for  next  vs  __next__ , etc:'], ['To supply a  __str__  method that encodes the  __unicode__  to UTF-8 in Python 2, you can replace the  del cls.__str__  with']], [[" import sys\n\nif sys.version_info[0] < 3:\n    def py2_compat(cls):\n        if hasattr(cls, '__str__'):\n            cls.__unicode__ = cls.__str__\n            del cls.__str__\n            # or optionally supply an str that \n            # encodes the output of cls.__unicode__\n        return cls\nelse:\n    def py2_compat(cls):\n        return cls\n\n@py2_compat\nclass MyPython3Class(object):\n    def __str__(self):\n        return u'Here I am!'\n"]], ['define different function for different versions of python'], 2, 1], [(29600513, 1), [['To supply a  __str__  method that encodes the  __unicode__  to UTF-8 in Python 2, you can replace the  del cls.__str__  with'], ['-10000']], [[" def __str__(self):\n    return unicode(self).encode('UTF-8')\ncls.__str__ = __str__\n"]], ['define different function for different versions of python'], 2, 0], [(29643161, 0), [['make the  tab2  addressable, and add code to listen to tab change event:'], ['Then add the action   ']], [['     #...\n    self.tab2 = support\n\n    self.tabs.addTab(tab1,"tab1")\n    self.tabs.addTab(self.tab2,"SUPPORT")\n    #\n    self.tabs.currentChanged.connect(self.load_on_show)\n']], ['Python PyQt QWebView load site in clicked tab'], 3, 0], [(29643161, 1), [['Then add the action   '], ['Make  view  addressable, again ( self.view ) and add code ']], [[' def load_on_show(self):\n    idx = self.tabs.currentIndex()\n    if idx == 1:\n        url = "http://www.google.com"\n        print url\n        self.tab2.load_url(url)\n']], ['Python PyQt QWebView load site in clicked tab'], 3, 0], [(29643161, 2), [['Make  view  addressable, again ( self.view ) and add code '], ['Does this help?']], [[' def load_url(self, url):\n    self.view. load(QtCore.QUrl(url))\n']], ['Python PyQt QWebView load site in clicked tab'], 3, 0], [(29703388, 0), [['seaborn  does a lot of this for you, very flexibly:'], ['If you want to subset the data, pass the subset as the  data  argument: ']], [[" import seaborn as sns\nsns.factorplot('ids', 'data', hue='var', kind='bar', data=df)\n"]], ['How to iterate over a pandas dataframe and compare certain columns based on a third column?'], 2, 1], [(29703388, 1), [['If you want to subset the data, pass the subset as the  data  argument: '], ['']], [[" sns.factorplot('ids', 'data', hue='var', kind='bar', \n               data=df[df.isin({'ids':['Bob','Mary']}).any(1)])\n"]], ['How to iterate over a pandas dataframe and compare certain columns based on a third column?'], 2, 0], [(29721519, 1), [['Other database adapters use  ?  and  :name  as the positional and named arguments; you can query the style used with the  paramstyle  attribute  on the module:'], ["but because most drivers support both positional and named styles, they usually just name one ( 'format'  or  'qmark' ) while also supporting the named variants. Always consult the documentation to verify this."]], [[" >>> import MySQLdb\n>>> MySQLdb.paramstyle\n'format'\n"]], ['String formatting on SQL insert using dict'], 2, 0], [(29744665, 0), [['Access by the key, you may also need to import Decimal:'], ['So just assign to the value returned:']], [[' from decimal import Decimal\n\nprint(access.getinfo()["balance"])\n']], ['Python json-rpc help, how to extract data'], 2, 0], [(29744665, 1), [['So just assign to the value returned:'], ['-10000']], [['  bal, pay_tax = access.getinfo()["balance"], access.getinfo()["paytxfee"]\n .....\n']], ['Python json-rpc help, how to extract data'], 2, 0], [(29761118, 0), [['How about this:'], ['This would output:']], [[" foods = ['I_want_ten_orange_cookies', 'I_want_four_orange_juices', 'I_want_ten_lemon_cookies', 'I_want_four_lemon_juices']\n\norange=[]\nlemon=[]\n\nfor food in foods:\n    if 'orange' in food.split('_'):\n        orange.append(food)\n    elif 'lemon' in food.split('_'):\n        lemon.append(food) \n"]], ['How to separate a single list into multiple list in python'], 3, 1], [(29761118, 1), [['This would output:'], ["You could, in theory, just do  if 'orange' in food  but that would fail if the substring is found in another word. For example:"]], [[" >>> orange\n['I_want_ten_orange_cookies', 'I_want_four_orange_juices']\n\n>>> lemon\n['I_want_ten_lemon_cookies', 'I_want_four_lemon_juices']\n"]], ['How to separate a single list into multiple list in python'], 3, 0], [(29761118, 2), [["You could, in theory, just do  if 'orange' in food  but that would fail if the substring is found in another word. For example:"], ['-10000']], [[' >>> s=\'I_appeared_there\'\n\n>>> if \'pear\' in s:\n    print "yes"\n\nyes\n\n>>> if \'pear\' in s.split(\'_\'):\n    print "yes"\n\n>>>\n']], ['How to separate a single list into multiple list in python'], 3, 0], [(29785451, 0), [['if it sounds simple ... it probably is'], ['you can also use itertools.islice to skip parts of an iterator']], [[' from itertools import count\na = count(1)\n\nnext(a)\nnext(a)\nprint next(a)\n']], ['How to print from itertools count object?'], 2, 1], [(29785451, 1), [['you can also use itertools.islice to skip parts of an iterator'], ['-10000']], [[' from itertools import count,islice\na = count(1)\nfor item in islice(a,2,4):\n    print item\n']], ['How to print from itertools count object?'], 2, 1], [(29799542, 0), [['You can use a  custom formatter function  to add these specific entities to the entity substitution.'], ['-10000']], [[' from bs4 import BeautifulSoup\nfrom bs4.dammit import EntitySubstitution\n\ndef custom_formatter(string):\n    """add &quot; and &apos; to entity substitution"""\n    return EntitySubstitution.substitute_html(string).replace(\'"\',\'&quot;\').replace("\'",\'&apos;\')\n\ninput_file = \'\'\'<tag1>\n  <tag2 attr1="a1">&quot; example text &quot;</tag2>\n  <tag3>\n    <tag4 attr2="a2">&quot; example text &quot;</tag4>\n    <tag5>\n      <tag6 attr3="a3">&apos; example text &apos;</tag6>\n    </tag5>\n  </tag3>\n</tag1>\n\'\'\'\n\nsoup = BeautifulSoup(input_file, "xml")\n\nprint soup.encode(formatter=custom_formatter)\n']], ['How to retain &quot; and &apos; while parsing xml using bs4 python'], 2, 1], [(29799542, 1), [['-10000'], ["The trick is to do it after the  EntitySubstitution.substitute_html()  so your  & s don't get substituted to  &amp; s. "]], [[' <?xml version="1.0" encoding="utf-8"?>\n<tag1>\n<tag2 attr1="a1">&quot; example text &quot;</tag2>\n<tag3>\n<tag4 attr2="a2">&quot; example text &quot;</tag4>\n<tag5>\n<tag6 attr3="a3">&apos; example text &apos;</tag6>\n</tag5>\n</tag3>\n</tag1>\n']], ['How to retain &quot; and &apos; while parsing xml using bs4 python'], 2, 0], [(29831030, 0), [["To get yesterday's  struct_time , use any of many  existing  datetime  solutions  and call  .timetuple()  to get  struct_time  e.g.:"], ['You could also get yesterday using only  time  module (but less directly):']], [[' #!/usr/bin/env python\nfrom datetime import date, timedelta\n\ntoday = date.today()\nyesterday = today - timedelta(1)\nprint(yesterday.timetuple())\n# -> time.struct_time(tm_year=2015, tm_mon=4, tm_mday=22, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=2, tm_yday=112, tm_isdst=-1)\n']], ['Time - get yesterdays date'], 2, 1], [(29831030, 1), [['You could also get yesterday using only  time  module (but less directly):'], ["It assumes that  time.gmtime()  accepts POSIX timestamp  on the given platform ( Python's stdlib breaks otherwise  e.g., if non-POSIX  TZ=right/UTC  is used).  calendar.timegm()  could be used instead of  posix_time()  but the former may use  datetime  internally."]], [[' #!/usr/bin/env python\nimport time\n\ndef posix_time(utc_time_tuple):\n    """seconds since Epoch as defined by POSIX."""\n    # from https://gist.github.com/zed/ff4e35df3887c1f82002\n    tm_year = utc_time_tuple.tm_year - 1900\n    tm_yday = utc_time_tuple.tm_yday - 1\n    tm_hour = utc_time_tuple.tm_hour\n    tm_min = utc_time_tuple.tm_min\n    tm_sec = utc_time_tuple.tm_sec\n    # http://pubs.opengroup.org/stage7tc1/basedefs/V1_chap04.html#tag_04_15\n    return (tm_sec + tm_min*60 + tm_hour*3600 + tm_yday*86400 +\n            (tm_year-70)*31536000 + ((tm_year-69)//4)*86400 -\n            ((tm_year-1)//100)*86400 + ((tm_year+299)//400)*86400)\n\nnow = time.localtime()\nyesterday = time.gmtime(posix_time(now) - 86400)\nprint(yesterday)\n# -> time.struct_time(tm_year=2015, tm_mon=4, tm_mday=22, tm_hour=22, tm_min=6, tm_sec=16, tm_wday=2, tm_yday=112, tm_isdst=0)\n']], ['Time - get yesterdays date'], 2, 1], [(29857558, 1), [['and then:'], ['Which is 9 characters shorter!']], [[' for i in r(l):\n    ...\n']], ["Short for 'for i in range(1,len(a)):' in python"], 2, 0], [(29867175, 0), [['You should use subparsers:'], ['Usage:']], [[" import argparse\n\nparser = argparse.ArgumentParser()\nsubparsers = parser.add_subparsers(title='subcommands')\n\nparser_foo = subparsers.add_parser('foo')\nparser_foo.set_defaults(target='foo')\n\nparser_bar = subparsers.add_parser('bar')\nparser_bar.add_argument('more')\nparser_bar.set_defaults(target='bar')\n"]], ['Nested options with argparse'], 3, 1], [(29867175, 2), [['-10000'], ['-10000']], [[" parser = argparse.ArgumentParser()\n\nsubparsers = parser.add_subparsers(title = 'subcommands')\n\nparser_create = subparsers.add_parser('create')\nparser_create.add_argument('path')\nparser_create.add_argument('-s', '--skeleton')\nparser_create.set_defaults(target=create)\n\nparser_build = subparsers.add_parser('build')\nparser_build.set_defaults(target = build)\n\nargs = parser.parse_args()\nargs.target(**{k: v for k, v in vars(args).items() if k != 'target'})\n"]], ['Nested options with argparse'], 3, 1], [(29870041, 0), [['To convert a string to an array of bytes: '], ['To convert array of bytes to int:']], [[" b = bytes('abcd', 'ascii')\n"]], ['How to XOR literal with a string'], 2, 0], [(29870041, 1), [['To convert array of bytes to int:'], ['-10000']], [[" i = int.from_bytes(b, byteorder='big', signed=False)\n"]], ['How to XOR literal with a string'], 2, 0], [(29908931, 0), [['But since YAML uses indentation, even for scalars spanning multiple lines, you can use a simple line based parser that recognises where each sequence element starts and feed those into the normal  load()  function one at a time:'], ['resulting in:']], [[' #/usr/bin/env python\n\nimport ruamel.yaml\n\ndef list_elements(fp, depth=0):\n    buffer = None\n    in_header = True\n    list_element_match = \' \' * depth + \'- \'\n    for line in fp:\n        if line.startswith(\'---\'):\n            in_header = False\n            continue\n        if in_header:\n            continue\n        if line.startswith(list_element_match):\n            if buffer is None:\n                buffer = line\n                continue\n            yield ruamel.yaml.load(buffer)[0]\n            buffer = line\n            continue\n        buffer += line\n    if buffer:\n       yield ruamel.yaml.load(buffer)[0]\n\n\nwith open("foobar.yaml") as fp:\n   for element in list_elements(fp):\n       print(str(element))\n']], ['YAML list -> Python generator?'], 2, 1], [(29908931, 1), [['resulting in:'], ['I used the enhanced version of PyYAML,  ruamel.yaml  here (of which I am the author), but  PyYAML should work in the same way.']], [[" {'something_else': 'blah', 'foo': ['bar', 'baz', 'bah']}\n{'bar': 'yet_another_thing'}\n"]], ['YAML list -> Python generator?'], 2, 0], [(29910229, 0), [["You can get a Model's fields and their metadata like this:"], ['Usage:']], [[' def get_model_metadata(model_class, meta_whitelist=[]):\n  field_list = model_class._meta.fields\n  return_data = {}\n  for field in field_list:\n    field_name = field.name\n    field_meta = field.__dict__\n    return_meta = {}\n    for meta_name in field_meta:\n      if meta_name in meta_whitelist:\n        return_meta[meta_name] = field_meta[meta_name]\n    if len(return_meta) > 0:\n      return_data[field_name] = return_meta\n  return return_data\n']], ['How can i extract metdata from django models'], 3, 1], [(29910229, 1), [['Usage:'], ['Returns:']], [[" from django.contrib.auth.models import User\nget_model_metadata(User, meta_whitelist=['max_length'])\n"]], ['How can i extract metdata from django models'], 3, 0], [(29910229, 2), [['Returns:'], ['Improvements to this method would include blacklist of field metadata, whitelist/blacklist for fields, and maybe a boolean for not showing metadata that has None value.']], [[" {\n  'username': {'max_length': 30},\n  'first_name': {'max_length': 30},\n  'last_name': {'max_length': 30},\n  'is_active': {'max_length': None},\n  'email': {'max_length': 75},\n  'is_superuser': {'max_length': None},\n  'is_staff': {'max_length': None},\n  'last_login': {'max_length': None},\n  'password': {'max_length': 128},\n  u'id': {'max_length': None},\n  'date_joined': {'max_length': None}\n}\n"]], ['How can i extract metdata from django models'], 3, 0], [(29932225, 0), [['Using the  heap queue  algorithm:'], ['Also note that this gives you all three largest values in order as a list, simply remove the  [-1] :']], [[" import heapq\ny = {'a':55, 'b':33, 'c':67, 'd':12}\nprint heapq.nlargest(n=3, iterable=y, key=y.get)[-1]\n# b\n"]], ["Obtain x'th largest item in a dictionary"], 2, 1], [(29935056, 0), [['You could do'], ['Or use  query  method like']], [[" In [276]: df[(df['fold'] >= 2) | (df['fold'] <= -0.6)]\nOut[276]:\n   label         Y88_N          diff       div      fold\n0      0  25273.626713  17348.581851  2.016404  2.016404\n1      1  29139.510491  -4208.868050  0.604304 -0.604304\n5      5  28996.634708  10934.944533  2.031293  2.031293\n"]], ['Pandas: How to extract rows of a dataframe matching Filter1 OR filter2'], 3, 1], [(29935056, 1), [['Or use  query  method like'], ['And,  pd.eval()  works well with expressions containing large arrays    ']], [[" In [277]: df.query('fold >=2 | fold <=-0.6')\nOut[277]:\n   label         Y88_N          diff       div      fold\n0      0  25273.626713  17348.581851  2.016404  2.016404\n1      1  29139.510491  -4208.868050  0.604304 -0.604304\n5      5  28996.634708  10934.944533  2.031293  2.031293\n"]], ['Pandas: How to extract rows of a dataframe matching Filter1 OR filter2'], 3, 1], [(29935056, 2), [['And,  pd.eval()  works well with expressions containing large arrays    '], ['-10000']], [[" In [278]: df[pd.eval('df.fold >=2 | df.fold <=-0.6')]\nOut[278]:\n   label         Y88_N          diff       div      fold\n0      0  25273.626713  17348.581851  2.016404  2.016404\n1      1  29139.510491  -4208.868050  0.604304 -0.604304\n5      5  28996.634708  10934.944533  2.031293  2.031293\n"]], ['Pandas: How to extract rows of a dataframe matching Filter1 OR filter2'], 3, 1], [(29947844, 0), [['You are looking for the  symmetric difference ; all elements that appear only in set a or in set b, but not both:'], ['You can use the  ^  operator too, if both  a  and  b  are sets:']], [[' a.symmetric_difference(b)\n']], ['Opposite of set.intersection in python?'], 2, 1], [(29947844, 1), [['You can use the  ^  operator too, if both  a  and  b  are sets:'], ['while  set.symmetric_difference()  takes any iterable for the  other  argument.']], [[' a ^ b\n']], ['Opposite of set.intersection in python?'], 2, 1], [(29950856, 0), [["Step 1 :  Convert the string 'list' column to actual lists:"], ["Step 2 :  Loop through each dictionary to get the 'values' (e.g. cars, pets, shoes, etc.).  Add a column to the DataFrame for each unique value."]], [[" from ast import literal_eval \n\ndf['misc'] = [literal_eval(r) for r in df.misc] \n"]], ['remove dictionary from list in pandas colum'], 3, 0], [(29950856, 1), [["Step 2 :  Loop through each dictionary to get the 'values' (e.g. cars, pets, shoes, etc.).  Add a column to the DataFrame for each unique value."], ['Step 3 :  Create a dictionary which gets the value for each type (this assumes that there is not more than one type for a given list of dictionaries in the row).  Then enumerate through these value counts and assign the result back to the DataFrame:']], [[" sublists = [[d.get('type') for d in cell] for cell in df.misc]\ncols = list(set([item for sublist in sublists for item in sublist]))\nfor c in cols:\n    df[c] = 0\n"]], ['remove dictionary from list in pandas colum'], 3, 0], [(29950856, 2), [['Step 3 :  Create a dictionary which gets the value for each type (this assumes that there is not more than one type for a given list of dictionaries in the row).  Then enumerate through these value counts and assign the result back to the DataFrame:'], ['-10000']], [[" value_counts = [{d.get('type'): d.get('value') for d in cell} for cell in df.misc]\nfor n, row in enumerate(value_counts):\nif row:\n    items, values = zip(*row.items())\n    df.loc[df.index[n], items] = values\n\ndel df['misc']\n\n>>> df\n  name  age  cars  shoes  pets  siblings\n0  Jim   44     3     13     1         0\n1  Bob   25     0      0     1         3\n2  Sue   55     0      0     0         0\n"]], ['remove dictionary from list in pandas colum'], 3, 0], [(29952373, 0), [['You could go through the list items and split the items after the first one, and get the last two items from the list and append it to a new List'], ['-10000']], [[" l = ['GIS_FPC_PP,PERIMETER,MAT,LIGHTS,PARK,SPACES,LAT,LNG\\n',\n     '8266.99157657,453.7255798,Paved,1,American Legion,20,40.0188044212,-75.0547647126\\n',\n     '20054.5870679,928.20201772,Paved,1,Barnes Foundation Museum, ,39.9610355788,-75.1725011285\\n']\n\nnewList = []\nfor i in range(0, len(l)):\n    item = l[i]\n    tempList = []\n    if i != 0:\n        itemSplit = item.split(',')\n        tempList.append(itemSplit[-2].strip())\n        tempList.append(itemSplit[-1].strip())\n        newList.append(tuple(tempList))\nprint newList\n"]], ['Parse list to other list'], 2, 1], [(29952373, 1), [['-10000'], ['-10000']], [["Output [('40.0188044212', '-75.0547647126'), ('39.9610355788', '-75.1725011285')]\n"]], ['Parse list to other list'], 2, 0], [(29968046, 0), [['You need to index into the list object too:'], ['or shorter (since you already have  v  referencing the same value):']], [[' for k, v in PointsOfInterest.iteritems():\n    if k in mypkt.Text:\n        PointsOfInterest[k][1] = PointsOfInterest[k][1] + 1\n']], ['Python incrementing a Dictionary value entry held within a list'], 3, 1], [(29968046, 1), [['or shorter (since you already have  v  referencing the same value):'], ['The same would apply to appending items to a nested list in the value:']], [[' for k, v in PointsOfInterest.iteritems():\n    if k in mypkt.Text:\n        v[1] += 1\n']], ['Python incrementing a Dictionary value entry held within a list'], 3, 1], [(29968046, 2), [['The same would apply to appending items to a nested list in the value:'], ['-10000']], [[' for k, v in PointsOfInterest.iteritems():\n    if k in mypkt.Text:\n        v[1].append(mykt.Text)\n']], ['Python incrementing a Dictionary value entry held within a list'], 3, 1], [(29969430, 1), [['Okay, so in your post when you say "If I don\'t use groupby, pandas would apply this function to every row of the dataframe", that\'s not necessarily true. You should try to read up on the way operations on  numpy  arrays are "vectorized". So, like people have pointed out in the comments, your function works fine without having to do the groupby:'], ['That said, you could have avoided writing the function in the first place because  numpy  can do weighted means for you:']], [[' mdft(df)\nOut[9]: 1.9429828309434094\n']], ['Apply a weighted average function to a dataframe without grouping it, as if it was a single group'], 3, 0], [(29974139, 0), [['For example, you can create file  /etc/supervisor/conf.d/myprog.conf :'], ["Then reload supervisor's config:"]], [[' [program:myprog]\ncommand=/opt/myprog/bin/myprog --opt1 --opt2\ndirectory=/opt/myprog\nuser=myuser\n']], ['How to automatically rerun a python program after it finishes? Supervisord?'], 2, 0], [(29974139, 1), [["Then reload supervisor's config:"], ["and it's on. Isn't it simple enough?"]], [[' $ sudo supervisorctl reload\n']], ['How to automatically rerun a python program after it finishes? Supervisord?'], 2, 0], [(29998052, 0), [['The final program will be like'], ['And the output will be']], [[' def eliminate_consonants(x):\n        vowels= [\'a\',\'e\',\'i\',\'o\',\'u\']\n        for char in x:\n            if char in vowels:\n                print(char,end = "")\n\neliminate_consonants(\'mississippi\')\n']], ['Deleting consonants from a string in Python'], 19, 1], [(29998052, 1), [['And the output will be'], ['-10000']], [[' iiii\n']], ['Deleting consonants from a string in Python'], 19, 0], [(29998052, 2), [['-10000'], ['A list comprehension']], [[' def eliminate_consonants(x):\n    for char in x:\n        if char in \'aeiou\':\n            print(char,end = "")\n']], ['Deleting consonants from a string in Python'], 19, 1], [(29998052, 3), [['A list comprehension'], ['A generator expression']], [["  ''.join([c for c in x if c in 'aeiou'])\n"]], ['Deleting consonants from a string in Python'], 19, 1], [(29998052, 4), [['A generator expression'], ['You can use  re.findall  to discover only the vowels in your string. The code']], [[" ''.join(c for c in x if c in 'aeiou')\n"]], ['Deleting consonants from a string in Python'], 19, 1], [(29998052, 5), [['You can use  re.findall  to discover only the vowels in your string. The code'], ["will return a list of vowels found in the string i.e.  ['i', 'i', 'i', 'i'] . So now we can use  str.join  and then use "]], [[' re.findall(r\'[aeiou]\',"mississippi")\n']], ['Deleting consonants from a string in Python'], 19, 0], [(29998052, 6), [["will return a list of vowels found in the string i.e.  ['i', 'i', 'i', 'i'] . So now we can use  str.join  and then use "], ['-10000']], [[' \'\'.join(re.findall(r\'[aeiou]\',"mississippi"))\n']], ['Deleting consonants from a string in Python'], 19, 1], [(29998052, 8), [['this will return the mapping. Do store it in a variable (here  m  for map)'], ['You can use  dict.fromkeys  along with  sys.maxunicode . But remember to  import sys  first! ']], [[' "mississippi".translate(m)\n']], ['Deleting consonants from a string in Python'], 19, 0], [(29998052, 10), [['and now use  str.translate . '], ['-10000']], [[" 'mississippi'.translate(m)\n"]], ['Deleting consonants from a string in Python'], 19, 0], [(29998052, 12), [['Using this we can translate the word ,'], ['bytes  returns an bytes object and is the immutable version of  bytearray . ( It is Python 3 specific )']], [[" 'mississippi'.encode('ascii', 'ignore').translate(None, non_vowels)\n"]], ['Deleting consonants from a string in Python'], 19, 0], [(29998052, 14), [['Using this we can translate the word ,'], ['which will return  b\'iiii\' . This can easily be converted to  str  by using  decode  i.e.  b\'iiii\'.decode("ascii") . ']], [[" 'mississippi'.encode('ascii', 'ignore').translate(None, non_vowels)\n"]], ['Deleting consonants from a string in Python'], 19, 0], [(29998052, 16), [['The timings in sorted order'], ['As you can see the final method using  bytes  is the fastest. ']], [[' translate (bytes)    |  2.88\ntranslate (bytearray)|  3.06\nList Comprehension   | 53.2\nRegular expressions  | 57.0\nGenerator exp        | 60.1\ndict.fromkeys        | 71.3\ntranslate (unicode)  | 71.6\n']], ['Deleting consonants from a string in Python'], 19, 0], [(29998052, 18), [['The timings in sorted order'], ['-10000']], [[' translate (unicode)  |  2.33\ndict.fromkeys        |  2.39\ntranslate (bytes)    |  4.17\ntranslate (bytearray)|  4.21\nList Comprehension   | 86.6\nRegular expressions  | 74.3\nGenerator exp        | 97.1\n']], ['Deleting consonants from a string in Python'], 19, 0], [(30002261, 0), [['What about something like this'], ['Filter for fork == True via boolean indexing']], [[" import matplotlib.pyplot as plt\nsubset = pd.DataFrame({'fork': {0: True, 1: False, 2: False, 3: False, 4: False, 5: True, 6: False},\n 'percentage_remains': {0: 20.0,\n  1: 9.0909089999999999,\n  2: 2.0,\n  3: 0.0,\n  4: 0.0,\n  5: 33.333333000000003,\n  6: 20.0}})\n"]], ['How to draw stacked histogram in pandas'], 3, 0], [(30002261, 1), [['Filter for fork == True via boolean indexing'], ["Then use matplotlib directly.  Notice I'm passing a list, one element are the true values and the other is for the false values    "]], [[' filter = subset["fork"] == True`\n']], ['How to draw stacked histogram in pandas'], 3, 0], [(30002261, 2), [["Then use matplotlib directly.  Notice I'm passing a list, one element are the true values and the other is for the false values    "], ['']], [['     plt.hist([subset["percentage_remains"][filter],subset["percentage_remains"][~filter]],\n                                                   stacked=True)\n        plt.show()\n']], ['How to draw stacked histogram in pandas'], 3, 0], [(30053381, 0), [['The function  cumtrapz  accepts an  axis  argument.  For example, suppose you put your first column in  x  and the remaining columns in  y , and they have these values:'], ['You can integrate each column of  y  with respect to  x  as follows:']], [[' In [61]: x\nOut[61]: array([100, 110, 120, 130])\n\nIn [62]: y\nOut[62]: \narray([[ 1.1,  2.1,  2. ,  1.1,  1.1],\n       [ 2. ,  2.1,  1. ,  1.2,  2.1],\n       [ 1.2,  1. ,  1.1,  1. ,  1.2],\n       [ 2. ,  1.1,  1.2,  2. ,  1.2]])\n']], ['Working with multiple columns from a data file'], 2, 0], [(30053381, 1), [['You can integrate each column of  y  with respect to  x  as follows:'], ['-10000']], [[' In [63]: cumtrapz(y, x=x, axis=0, initial=0)\nOut[63]: \narray([[  0. ,   0. ,   0. ,   0. ,   0. ],\n       [ 15.5,  21. ,  15. ,  11.5,  16. ],\n       [ 31.5,  36.5,  25.5,  22.5,  32.5],\n       [ 47.5,  47. ,  37. ,  37.5,  44.5]])\n']], ['Working with multiple columns from a data file'], 2, 0], [(30068271, 0), [["For such a case,  signal.convolve2d  with an appropriate kernel could be used. At the end, you need to divide those summations by the number of ones in kernel, i.e.  kernel.sum()  as only those contributed to the summations. Here's the implementation -"], ['-10000']], [[" import numpy as np\nfrom scipy import signal\n\n# Inputs\na = [[1,2,3],[3,4,5],[5,6,7],[4,8,9]]\n\n# Convert to numpy array\narr = np.asarray(a,float)    \n\n# Define kernel for convolution                                         \nkernel = np.array([[0,1,0],\n                   [1,0,1],\n                   [0,1,0]]) \n\n# Perform 2D convolution with input data and kernel \nout = signal.convolve2d(arr, kernel, boundary='wrap', mode='same')/kernel.sum()\n"]], ['Python get get average of neighbours in matrix with na value'], 4, 1], [(30068271, 1), [['-10000'], ['Sample input, output -']], [[" import numpy as np\n\n# Convert to numpy array\narr = np.asarray(a,float)    \n\n# Pad around the input array to take care of boundary conditions\narr_pad = np.lib.pad(arr, (1,1), 'wrap')\n\nR,C = np.where(arr==0)   # Row, column indices for zero elements in input array\nN = arr_pad.shape[1]     # Number of rows in input array\n\noffset = np.array([-N, -1, 1, N])\nidx = np.ravel_multi_index((R+1,C+1),arr_pad.shape)[:,None] + offset\n\narr_out = arr.copy()\narr_out[R,C] = arr_pad.ravel()[idx].sum(1)/4\n"]], ['Python get get average of neighbours in matrix with na value'], 4, 1], [(30068271, 2), [['Sample input, output -'], ["Approach #2:  This would be a modified version of  convolution based approach listed earlier in  Shot #1 . This is same as that earlier approach, except that at the end, we selectively replace\nthe zero elements with the convolution output. Here's the code -"]], [[' In [587]: arr\nOut[587]: \narray([[ 4.,  0.,  3.,  3.,  3.,  1.,  3.],\n       [ 2.,  4.,  0.,  0.,  4.,  2.,  1.],\n       [ 0.,  1.,  1.,  0.,  1.,  4.,  3.],\n       [ 0.,  3.,  0.,  2.,  3.,  0.,  1.]])\n\nIn [588]: arr_out\nOut[588]: \narray([[ 4.  ,  3.5 ,  3.  ,  3.  ,  3.  ,  1.  ,  3.  ],\n       [ 2.  ,  4.  ,  2.  ,  1.75,  4.  ,  2.  ,  1.  ],\n       [ 1.5 ,  1.  ,  1.  ,  1.  ,  1.  ,  4.  ,  3.  ],\n       [ 2.  ,  3.  ,  2.25,  2.  ,  3.  ,  2.25,  1.  ]])\n']], ['Python get get average of neighbours in matrix with na value'], 4, 0], [(30068271, 3), [["Approach #2:  This would be a modified version of  convolution based approach listed earlier in  Shot #1 . This is same as that earlier approach, except that at the end, we selectively replace\nthe zero elements with the convolution output. Here's the code -"], ['Remarks:   Approach #1  would be the preferred way when you have fewer number of zero elements in input array, otherwise go with  Approach #2 .']], [[" import numpy as np\nfrom scipy import signal\n\n# Inputs\na = [[1,2,3],[3,4,5],[5,6,7],[4,8,9]]\n\n# Convert to numpy array\narr = np.asarray(a,float)\n\n# Define kernel for convolution                                         \nkernel = np.array([[0,1,0],\n                   [1,0,1],\n                   [0,1,0]]) \n\n# Perform 2D convolution with input data and kernel \nconv_out = signal.convolve2d(arr, kernel, boundary='wrap', mode='same')/kernel.sum()\n\n# Initialize output array as a copy of input array\narr_out = arr.copy()\n\n# Setup a mask of zero elements in input array and \n# replace those in output array with the convolution output\nmask = arr==0\narr_out[mask] = conv_out[mask]\n"]], ['Python get get average of neighbours in matrix with na value'], 4, 1], [(30071618, 0), [["You don't need to write out a giant tuple of even or odd numbers; you can have Python do that for you:"], ["I've passed an xrange here, since the usecols parameter can be any sequence type, but even if you needed a tuple, you could just call  tuple :"]], [[' data = numpy.loadtxt(..., usecols=xrange(1, numcols, 2))\n']], ['Numpy loadtxt load every other column'], 2, 1], [(30071618, 1), [["I've passed an xrange here, since the usecols parameter can be any sequence type, but even if you needed a tuple, you could just call  tuple :"], ['-10000']], [[' data = numpy.loadtxt(..., usecols=tuple(xrange(1, numcols, 2)))\n']], ['Numpy loadtxt load every other column'], 2, 1], [(30076583, 0), [["Yes, it is possible.  SWIG only uses the headers to generate wrapper functions. Here's a simple SWIG file:"], ['Then:']], [[' %module mymod\n%{\n#include "myheader.h"\n%}\n\n%include "myheader.h"\n']], ['How to use swig with compiled dll and header file only'], 2, 0], [(30076583, 1), [['Then:'], ['Then compile and link the generated code as a Python extension DLL.  You will also need to link in the .lib for the wrapped DLL. ']], [[' swig -python -c++ mymod.i\n']], ['How to use swig with compiled dll and header file only'], 2, 0], [(30133281, 0), [['For a specific value you can do this:'], ['For the more general case you can get an array of indices where the condition is met']], [[" In [84]:\n\nidx = df[df['preciptotal'] > 1].index[0]\ndf.iloc[idx-3: idx+4]\nOut[84]:\n        date  store_nbr  units  preciptotal\n0 2014-10-11          1      0         0.00\n1 2014-10-12          1      0         0.01\n2 2014-10-13          1      2         0.00\n3 2014-10-14          1      1         2.13\n4 2014-10-15          1      0         0.00\n5 2014-10-16          1      0         0.87\n6 2014-10-17          1      3         0.01\n"]], ['Slicing based on dates Pandas Dataframe'], 3, 1], [(30133281, 1), [['For the more general case you can get an array of indices where the condition is met'], ['then you can generate slices or iterate over the array values:']], [[" idx_vals = df[df['preciptotal'] > 1].index\n"]], ['Slicing based on dates Pandas Dataframe'], 3, 0], [(30133281, 2), [['then you can generate slices or iterate over the array values:'], ['This assumes your index is a 0 based int64 index which your sample is']], [[' for idx in idx_values:\n    df.iloc[idx-3: idx+4]\n']], ['Slicing based on dates Pandas Dataframe'], 3, 0], [(30156357, 0), [['We can make it a bit simpler and use a "CSS selector" via  find_elements_by_css_selector() :'], ['Alternatively, you can check whether an  id  attribute contains  Medications :']], [[' medications = driver.find_elements_by_css_selector("input.medMedications")\n\n# count\nprint len(medications)\n\n# values\nfor medication in medications:\n    print medication.get_attribute("value")\n']], ['Getting value of a class in selenium and python'], 3, 1], [(30156357, 1), [['Alternatively, you can check whether an  id  attribute contains  Medications :'], ['or, in case of XPath:']], [[' medications = driver.find_elements_by_css_selector("input[id*=Medications]")\n']], ['Getting value of a class in selenium and python'], 3, 0], [(30156357, 2), [['or, in case of XPath:'], ['-10000']], [[' medications = driver.find_elements_by_xpath("//input[contains(@id, \'Medications\']")\n']], ['Getting value of a class in selenium and python'], 3, 0], [(30170614, 1), [['If you have multiple dicts in Tuple that have the same key the value will be set to the last dict you encounter. If you wanted the first match you should  break  in the if.'], ['If you want the last match it would be better start at the end of Tuple:']], [[' Dict = {\'1\': \'one\', \'2\': \'three\'}\n\nTuple = ({\'1\': \'one\', \'5\': \'five\'}, {\'4\': \'four\', \'2\': \'two\'})\nfor d in Tuple:\n    if "2" in d:\n        Dict["2"] = d["2"]\n        break # get first match\n']], ['Iteration Through tuple of dictionaries in Python'], 3, 1], [(30170614, 2), [['If you want the last match it would be better start at the end of Tuple:'], ['-10000']], [[' for d in reversed(Tuple):\n    if "2" in d:\n        Dict["2"] = d["2"]\n        break # last dict in Tuple that has the key\n']], ['Iteration Through tuple of dictionaries in Python'], 3, 1], [(30180241, 0), [['You may use  np.where :'], ['Also as @senderle mentioned in comment, to get values in an array, you can use  np.argwhere :']], [[' In [9]: np.where(x == np.min(x))\nOut[9]: (array([2]), array([1]))\n']], ['Numpy: get the column and row index of the minimum value of a 2D array'], 4, 1], [(30180241, 1), [['Also as @senderle mentioned in comment, to get values in an array, you can use  np.argwhere :'], ['-10000']], [[' In [21]: np.argwhere(x == np.min(x))\nOut[21]: array([[2, 1]])\n']], ['Numpy: get the column and row index of the minimum value of a 2D array'], 4, 1], [(30180241, 3), [['Timed them and you will find that extra bits of speed, not much but still an improvement.'], ['If you are really concerned about performance, you may take a look at  cython .']], [[' %timeit find_min_idx(x)\n1000000 loops, best of 3: 1.1 µs per loop\n\n%timeit divmod(x.argmin(), x.shape[1])\n1000000 loops, best of 3: 1.04 µs per loop\n']], ['Numpy: get the column and row index of the minimum value of a 2D array'], 4, 0], [(30185056, 0), [['You can easily compose your query with 2 columns (I guess you already knew that):'], ['and afterwards you can use the method  with_only_columns() , see  api :']], [[' select_query = select([table2.c.col1, table2.c.col2]).where(table1.c.key == table2.c.key)\n']], ['Updating a table from another table with multiple columns in sqlalchemy'], 2, 0], [(30185056, 1), [['and afterwards you can use the method  with_only_columns() , see  api :'], ["But as you see from the update statement, you will be effectivelly doing two selects. (Sorry I did not adapt the output completely to your example, but I'm sure you get the idea)."]], [[' In[52]: print(table.update().values(col1 = select_query.with_only_columns([table2.c.col1]), col2 = select_query.with_only_columns([table2.c.col2])))\nUPDATE table SET a=(SELECT tweet.id \nFROM tweet \nWHERE tweet.id IS NOT NULL), b=(SELECT tweet.user_id \nFROM tweet \nWHERE tweet.id IS NOT NULL)\n']], ['Updating a table from another table with multiple columns in sqlalchemy'], 2, 0], [(30196224, 0), [['Use  $(NF-1)  like so where  NF  is the number fields for that line:'], ['Your posted example has spaces for delimiters. You may need to change the field separator to tabs if you file is truly tab delimited. Then it would be:']], [[" awk  '{print $(NF-1)}' /tmp/genes.txt\nA2M\nACADM\n"]], ['Extracting data from file with differing amounts of columns'], 3, 1], [(30196224, 1), [['Your posted example has spaces for delimiters. You may need to change the field separator to tabs if you file is truly tab delimited. Then it would be:'], ['If you want the number before that name:']], [[" awk  -F $'\\t' {print $(NF-1)}' file_name\n"]], ['Extracting data from file with differing amounts of columns'], 3, 1], [(30196224, 2), [['If you want the number before that name:'], ['-10000']], [[" $ awk  '{print $(NF-2)}' /tmp/genes.txt\n9268558\n76229363\n"]], ['Extracting data from file with differing amounts of columns'], 3, 1], [(30198481, 1), [['gives you:'], ['Since you seem to be having different quotes for key and value string scalars, you can achieve the output you want by overriding  process_scalar  (part of the Emitter in emitter.py) to add the quotes based on the string scalar being a key or not and being an integer or not:']], [[' main:\n  directory:\n    options:\n      directive: options\n      item:\n        options: Stuff OtherStuff MoreStuff\n  directoryindex:\n    item:\n      directoryindex: stuff.htm otherstuff.htm morestuff.html\n  fileetag:\n    item:\n      fileetag: Stuff\n  keepalive:\n    item:\n      keepalive: Stuff\n  keepalivetimeout:\n    item:\n      keepalivetimeout: 400\n']], ['Pyyaml - Using different styles for keys and integers and strings'], 4, 0], [(30198481, 2), [['Since you seem to be having different quotes for key and value string scalars, you can achieve the output you want by overriding  process_scalar  (part of the Emitter in emitter.py) to add the quotes based on the string scalar being a key or not and being an integer or not:'], ['gives you:']], [[' import ruamel.yaml as yaml\n\n# the scalar emitter from emitter.py\ndef process_scalar(self):\n    if self.analysis is None:\n        self.analysis = self.analyze_scalar(self.event.value)\n    if self.style is None:\n        self.style = self.choose_scalar_style()\n    split = (not self.simple_key_context)\n    # VVVVVVVVVVVVVVVVVVVV added\n    try:\n        x = int(self.event.value)  # might need to expand this\n    except:\n        # we have string\n        if split:\n            self.style = "\'"\n        else:\n            self.style = \'"\'\n    # ^^^^^^^^^^^^^^^^^^^^\n    # if self.analysis.multiline and split    \\\n    #         and (not self.style or self.style in \'\\\'\\"\'):\n    #     self.write_indent()\n    if self.style == \'"\':\n        self.write_double_quoted(self.analysis.scalar, split)\n    elif self.style == \'\\\'\':\n        self.write_single_quoted(self.analysis.scalar, split)\n    elif self.style == \'>\':\n        self.write_folded(self.analysis.scalar)\n    elif self.style == \'|\':\n        self.write_literal(self.analysis.scalar)\n    else:\n        self.write_plain(self.analysis.scalar, split)\n    self.analysis = None\n    self.style = None\n    if self.event.comment:\n        self.write_post_comment(self.event)\n\n\ninfile = yaml.load(open(\'yamlfile\'), Loader=yaml.RoundTripLoader)\n\nfor key, value in infile[\'main\'].items():\n    if key == \'keepalivetimeout\':\n        item = value[\'item\']\n        item[\'keepalivetimeout\'] = 400\n\ndd = yaml.RoundTripDumper\ndd.process_scalar = process_scalar\n\nprint \'---\'\nprint yaml.dump(infile, Dumper=dd)\n']], ['Pyyaml - Using different styles for keys and integers and strings'], 4, 1], [(30198481, 3), [['gives you:'], ['which is quite close to what you asked for.']], [[' ---\n"main":\n  "directory":\n    "options":\n      "directive": \'options\'\n      "item":\n        "options": \'Stuff OtherStuff MoreStuff\'\n  "directoryindex":\n    "item":\n      "directoryindex": \'stuff.htm otherstuff.htm morestuff.html\'\n  "fileetag":\n    "item":\n      "fileetag": \'Stuff\'\n  "keepalive":\n    "item":\n      "keepalive": \'Stuff\'\n  "keepalivetimeout":\n    "item":\n      "keepalivetimeout": 400\n']], ['Pyyaml - Using different styles for keys and integers and strings'], 4, 0], [(30209723, 0), [['You can use  read_csv  and specify  header=None  and pass the column names as a list:'], ["You'll have to re-encode the bid column to 1 or 2:"]], [[' In [124]:\n\nt="""time1,stockA,bid,1\n time2,stockA,ask,1.1\n time3,stockB,ask,2.1\n time4,stockB,bid,2.0"""\n\u200b\ndf = pd.read_csv(io.StringIO(t), header=None, names=[\'time\', \'stock\', \'bid\', \'ask\'])\ndf\nOut[124]:\n     time   stock  bid  ask\n0   time1  stockA  bid  1.0\n1   time2  stockA  ask  1.1\n2   time3  stockB  ask  2.1\n3   time4  stockB  bid  2.0\n']], ['Convert column elements to column name in pandas'], 3, 0], [(30209723, 1), [["You'll have to re-encode the bid column to 1 or 2:"], ['Based on your updated sample data and desired output the following works:']], [[" In [126]:\n\ndf['bid'] = df['bid'].replace('bid', 1)\ndf['bid'] = df['bid'].replace('ask', 2)\ndf\nOut[126]:\n     time   stock  bid  ask\n0   time1  stockA    1  1.0\n1   time2  stockA    2  1.1\n2   time3  stockB    2  2.1\n3   time4  stockB    1  2.0\n"]], ['Convert column elements to column name in pandas'], 3, 0], [(30209723, 2), [['Based on your updated sample data and desired output the following works:'], ['-10000']], [[' In [29]:\n\nt="""time1,stockA,bid,1\n time2,stockA,ask,1.1\n time3,stockB,ask,2.1\n time4,stockB,bid,2.0\n time5,stockA,bid,1.1\n time6,stockA,ask,1.2"""\n\u200b\ndf = pd.read_csv(io.StringIO(t), header=None, names=[\'time\', \'stock\', \'bid\', \'ask\'])\ndf\nOut[29]:\n     time   stock  bid  ask\n0   time1  stockA  bid  1.0\n1   time2  stockA  ask  1.1\n2   time3  stockB  ask  2.1\n3   time4  stockB  bid  2.0\n4   time5  stockA  bid  1.1\n5   time6  stockA  ask  1.2\nIn [30]:\n\ndf.loc[df[\'bid\'] == \'bid\', \'bid\'] = df[\'ask\']\ndf.loc[df[\'bid\'] != \'ask\', \'ask\'] = \'\'\ndf.loc[df[\'bid\'] == \'ask\',\'bid\'] = \'\'\ndf\nOut[30]:\n     time   stock  bid  ask\n0   time1  stockA    1     \n1   time2  stockA       1.1\n2   time3  stockB       2.1\n3   time4  stockB    2     \n4   time5  stockA  1.1     \n5   time6  stockA       1.2\n']], ['Convert column elements to column name in pandas'], 3, 1], [(30214489, 0), [['sample.txt:'], ['And the code for reading and recording the frequency of words:']], [[' hello this file is good\nfile is is good excellent\n']], ['Split file and turn it into dictionary in python'], 4, 0], [(30214489, 1), [['And the code for reading and recording the frequency of words:'], ['Output:']], [[' import collections\nwith open("sample.txt", "r") as datafile:\n    lines = datafile.read()\n    words = lines.split()\n    words_hist = collections.Counter(words)\n    print words_hist\n']], ['Split file and turn it into dictionary in python'], 4, 1], [(30214489, 2), [['Output:'], ['As per your posted solution, It seems that, you are incorrectly reading the input file. So I have edited your approach a bit:']], [[" {'is': 3, 'good': 2, 'file': 2, 'this': 1, 'excellent': 1, 'hello': 1}\n"]], ['Split file and turn it into dictionary in python'], 4, 0], [(30229104, 0), [['In Python, if the input is a numpy array, you can use  np.lib.pad  to pad zeros around it -'], ['Sample run -']], [[" import numpy as np\n\nA = np.array([[1, 2 ],[2, 3]])   # Input\nA_new = np.lib.pad(A, ((0,1),(0,2)), 'constant', constant_values=(0)) # Output\n"]], ['python - increase array size and initialize new elements to zero'], 6, 1], [(30229104, 2), [["If you don't want to do the  math  of how many zeros to pad, you can let the code do it for you given the output array size -"], ['Or, you can start off with a zero initialized output array and then put back those input elements from  A  -']], [[" In [29]: A\nOut[29]: \narray([[1, 2],\n       [2, 3]])\n\nIn [30]: new_shape = (3,4)\n\nIn [31]: shape_diff = np.array(new_shape) - np.array(A.shape)\n\nIn [32]: np.lib.pad(A, ((0,shape_diff[0]),(0,shape_diff[1])), \n                              'constant', constant_values=(0))\nOut[32]: \narray([[1, 2, 0, 0],\n       [2, 3, 0, 0],\n       [0, 0, 0, 0]])\n"]], ['python - increase array size and initialize new elements to zero'], 6, 1], [(30229104, 3), [['Or, you can start off with a zero initialized output array and then put back those input elements from  A  -'], ['-10000']], [[' In [38]: A\nOut[38]: \narray([[1, 2],\n       [2, 3]])\n\nIn [39]: A_new = np.zeros(new_shape,dtype = A.dtype)\n\nIn [40]: A_new[0:A.shape[0],0:A.shape[1]] = A\n\nIn [41]: A_new\nOut[41]: \narray([[1, 2, 0, 0],\n       [2, 3, 0, 0],\n       [0, 0, 0, 0]])\n']], ['python - increase array size and initialize new elements to zero'], 6, 1], [(30229104, 4), [['-10000'], ['Sample run -']], [[" A_new  = padarray(A,[1 2],'post')\n"]], ['python - increase array size and initialize new elements to zero'], 6, 1], [(30242208, 1), [["So. First, we have our error function. We'll call this CE (for Cross Entropy. I'll try to use your variables where possible, tho, I'm going to use L1, L2 and L3 instead of layer1, layer2 and layer3.  sigh  (I don't know how to do latex here. It seems to work on the statistics stack exchange. weird.)"], ['We need to take the derivative of this wrt L3, so that we can see how we can move L3 so as to  reduce  this value.']], [[' CE = -(Y log(L3) + (1-Y) log(1-L3))\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 2), [['We need to take the derivative of this wrt L3, so that we can see how we can move L3 so as to  reduce  this value.'], ["Great, but, actually, we can't just alter L3 as we see fit. L3 is a function of Z3 (See my picture)."]], [[' dCE/dL3 = -((Y/L3) - (1-Y)/(1-L3))\n        = -((Y(1-L3) - (1-Y)L3) / (L3(1-L3)))\n        = -(((Y-Y*L3) - (L3-Y*L3)) / (L3(1-L3)))\n        = -((Y-Y3*L3 + Y3*L3 - L3) / (L3(1-L3)))\n        = -((Y-L3) / (L3(1-L3)))\n        = ((L3-Y) / (L3(1-L3)))\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 3), [["Great, but, actually, we can't just alter L3 as we see fit. L3 is a function of Z3 (See my picture)."], ["But, anyway, that's the derivative of L3 wrt Z3, but we want the derivative of CE wrt Z3."]], [[' L3      = sigmoid(Z3)\ndL3/dZ3 = L3(1-L3)\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 4), [["But, anyway, that's the derivative of L3 wrt Z3, but we want the derivative of CE wrt Z3."], ['But this is more complicated.']], [[' dCE/dZ3 = (dCE/dL3) * (dL3/dZ3)\n        = ((L3-Y)/(L3(1-L3)) * (L3(1-L3)) # Hey, look at that. The denominator gets cancelled out and\n        = (L3-Y) # This is why in my comments I was saying what you are computing is the _negative_ derivative.\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 5), [['But this is more complicated.'], ['So, we need to take partial derivatives wrt. L2(1), L2(2) and L2(3)']], [[' Z3 = theta2(0) + theta2(1) * L2(1) + theta2(2) * L2(2) + theta2(3) * L2(3)\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 6), [['So, we need to take partial derivatives wrt. L2(1), L2(2) and L2(3)'], ['Notice that the bias would effectively be']], [[' dZ3/dL2(1) = theta2(1)\ndZ3/dL2(2) = theta2(2)\ndZ3/dL2(3) = theta2(3)\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 7), [['Notice that the bias would effectively be'], ["But, again, we want the derivative wrt Z2(0), Z2(1), Z2(2) (Looks like I drew that badly, unfortunately. Look at the graph, it'll be clearer with it, I think.)"]], [[' dZ3/dBias  = theta2(0)\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 8), [["But, again, we want the derivative wrt Z2(0), Z2(1), Z2(2) (Looks like I drew that badly, unfortunately. Look at the graph, it'll be clearer with it, I think.)"], ['What now is dCE/dZ2(0..2)']], [[' dL2(1)/dZ2(0) = L2(1) * (1-L2(1))\ndL2(2)/dZ2(1) = L2(2) * (1-L2(2))\ndL2(3)/dZ2(2) = L2(3) * (1-L2(3))\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 9), [['What now is dCE/dZ2(0..2)'], ["So. Now, we have derivatives wrt our Z's, but, really, what we can modify are only our thetas."]], [[' dCE/dZ2(0) = dCE/dZ3 * dZ3/dL2(1) * dL2(1)/dZ2(0)\n           = (L3-Y)  * theta2(1)  * L2(1) * (1-L2(1))\n\ndCE/dZ2(1) = dCE/dZ3 * dZ3/dL2(2) * dL2(2)/dZ2(1)\n           = (L3-Y)  * theta2(2)  * L2(2) * (1-L2(2))\n\ndCE/dZ2(2) = dCE/dZ3 * dZ3/dL2(3) * dL2(3)/dZ2(2)\n           = (L3-Y)  * theta2(3)  * L2(3) * (1-L2(3))\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 10), [["So. Now, we have derivatives wrt our Z's, but, really, what we can modify are only our thetas."], ['Once again tho, we want dCE/dtheta2(0) tho, so that becomes']], [[' Z3 = theta2(0) + theta2(1) * L2(1) + theta2(2) * L2(2) + theta2(3) * L2(3)\ndZ3/dtheta2(0) = 1\ndZ3/dtheta2(1) = L2(1)\ndZ3/dtheta2(2) = L2(2)\ndZ3/dtheta2(3) = L2(3)\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 11), [['Once again tho, we want dCE/dtheta2(0) tho, so that becomes'], ['And, similarly:\n    Z2(0) = theta1(0,0) + theta1(1,0) * L1(1) + theta1(2,0) * L1(2)\n    dZ2(0)/dtheta1(0,0) = 1\n    dZ2(0)/dtheta1(1,0) = L1(1)\n    dZ2(0)/dtheta1(2,0) = L1(2)']], [[' dCE/dtheta2(0) = dCE/dZ3 * dZ3/dtheta2(0)\n               = (L3-Y) * 1\ndCE/dtheta2(1) = dCE/dZ3 * dZ3/dtheta2(1)\n               = (L3-Y) * L2(1)\ndCE/dtheta2(2) = dCE/dZ3 * dZ3/dtheta2(2)\n               = (L3-Y) * L2(2)\ndCE/dtheta2(3) = dCE/dZ3 * dZ3/dtheta2(3)\n               = (L3-Y) * L2(3)\n']], ['XOR neural network backprop'], 13, 0], [(30242208, 12), [['And, similarly:\n    Z2(0) = theta1(0,0) + theta1(1,0) * L1(1) + theta1(2,0) * L1(2)\n    dZ2(0)/dtheta1(0,0) = 1\n    dZ2(0)/dtheta1(1,0) = L1(1)\n    dZ2(0)/dtheta1(2,0) = L1(2)'], ["And, we'd have to multiply by dCE/dZ2(0), dCE/dZ2(1) and dCE/dZ2(2) (for each of the three groups up there. But, if you think about that, that then just becomes np.dot(layer1.T, delta2), and that's what I have in theta1d."]], [[' Z2(1) = theta1(0,1) + theta1(1,1) * L1(1) + theta1(2,1) * L1(2)\ndZ2(1)/dtheta1(0,1) = 1\ndZ2(1)/dtheta1(1,1) = L1(1)\ndZ2(1)/dtheta1(2,1) = L1(2)\n\nZ2(2) = theta1(0,2) + theta1(1,2) * L1(1) + theta1(2,2) * L1(2)\ndZ2(2)/dtheta1(0,2) = 1\ndZ2(2)/dtheta1(1,2) = L1(1)\ndZ2(2)/dtheta1(2,2) = L1(2)\n']], ['XOR neural network backprop'], 13, 0], [(30268750, 0), [['The obvious way is to explicitly use the  reverse  parameter which exists precisely for that purpose:'], ["If you're sorting by numbers, you can also just negate them:"]], [[' sorted(alpha_items, key=lambda x: x[1], reverse=True)\n']], ['how to sort a list of tuples with list[i][1] as key from biggest to smallest'], 2, 1], [(30272538, 0), [['This produces the same result:'], ['gives:']], [[' import numpy as np\nmy_array = np.array([80.6, 120.8, -115.6, -76.1, 131.3, 105.1, 138.4, -81.3, -95.3,  \n                     89.2, -154.1, 121.4, -85.1, 96.8, 68.2])\n((my_array[:-1] * my_array[1:]) < 0).sum()\n']], ['Python code for counting number of zero crossings in an array'], 7, 1], [(30272538, 1), [['gives:'], ['and seems to be the fastest solution:']], [[' 8\n']], ['Python code for counting number of zero crossings in an array'], 7, 0], [(30272538, 2), [['and seems to be the fastest solution:'], ['Compared to the fastest so far:']], [[' %timeit ((my_array[:-1] * my_array[1:]) < 0).sum()\n100000 loops, best of 3: 11.6 µs per loop\n']], ['Python code for counting number of zero crossings in an array'], 7, 0], [(30272538, 3), [['Compared to the fastest so far:'], ['Also for larger arrays:']], [[' %timeit (np.diff(np.sign(my_array)) != 0).sum()\n10000 loops, best of 3: 22.2 µs per loop\n']], ['Python code for counting number of zero crossings in an array'], 7, 0], [(30272538, 5), [['this:'], ['vs:']], [[' %timeit ((big[:-1] * big[1:]) < 0).sum()\n10 loops, best of 3: 62.1 ms per loop\n']], ['Python code for counting number of zero crossings in an array'], 7, 0], [(30272538, 6), [['vs:'], ['-10000']], [[' %timeit (np.diff(np.sign(big)) != 0).sum()\n1 loops, best of 3: 97.6 ms per loop\n']], ['Python code for counting number of zero crossings in an array'], 7, 0], [(30296726, 0), [['For just 10 megs, I will definitly go with a in memory sort. I would parse the HTML with  Beautiful Soup , create a array of object with the given class :'], ['And sort the array with :']], [[' class Chat:\n    def __init__(self, user, date, text):\n        self.user = user\n        self.date = date\n        self.text = text\n']], ['python - parsing and sorting dates'], 2, 0], [(30329252, 1), [['Then you can do all kinds of stuff like find the vector by subtracting two points'], ['Or adding an arbitrary unit vector to a point to find a new point (which is the answer to your original question)']], [[' >>> a = Vector(4,5,0)\n>>> b = Vector(5,6,0)\n>>> b - a\n[1, 1, 0]\n']], ['Calculate a point along a line segment one unit from a end of the seg'], 3, 0], [(30329252, 2), [['Or adding an arbitrary unit vector to a point to find a new point (which is the answer to your original question)'], ['You can add more utilities, like allowing Vector/Scalar operations for scaling, etc.']], [[' >>> a = Vector(4,5,0)\n>>> direction = Vector(10, 1, 0).unitVector()\n>>> a + direction\n[4.995037190209989, 5.099503719020999, 0.0]\n']], ['Calculate a point along a line segment one unit from a end of the seg'], 3, 0], [(30338961, 0), [['Data:'], ["I'll use an  itertools  recipe  to get chunks of the message because I'm going to use a generator to flatten the message. There are other ways to flatten a list found in the answers to:  How do you split a list into evenly sized chunks in Python?  "]], [[' key=[[16, 4, 11], [8, 6, 18], [15, 19, 15]]\nmessage=[[0], [12], [8], [6], [15], [2], [15], [13], [3], [21], [2], [20], [15], [18], [8]]\n']], ['3x1 Matrix Multiplication with lists[UPDATED]'], 4, 0], [(30338961, 2), [['zip  is another useful function, it is similar to a transposition:'], ["Now we'll do a matrix multiplication with the key and each, 3 item, chunk of the message."]], [[' >>> zip([1,2],[3,4])\n[(1, 3), (2, 4)]\n>>> \n']], ['3x1 Matrix Multiplication with lists[UPDATED]'], 4, 0], [(30365563, 1), [['If you simply wanted to update all the dictionaries in  list1 , do this:'], ['-10000']], [[' dict2 = {"mask": "255.255.255.255"}\nfor d in list1:\n    d.update(dict2)\n']], ['Join list of dict with a dict in python'], 2, 1], [(30397315, 1), [['When using performing equality comparison this will produce a boolean array:'], ['It will be more performant to just call  .sum()  on the np.array:']], [[' In [166]:\n\nA==B\nOut[166]:\narray([False, False,  True, False,  True], dtype=bool)\n']], ['index by comparision of two numpy arrays in python'], 3, 0], [(30397315, 2), [['It will be more performant to just call  .sum()  on the np.array:'], ['the top-level  sum  is significantly slower which is to be expected.']], [[" In [173]:\n\na=[1,'aaa', 'bbb', 'vvv', 'www']\na *=100\nb=[2,'qqq', 'bbb', 'ppp', 'www']\nb *=100\nA = np.array(a)\nB = np.array(b)\n%timeit (A==B).sum()\n%timeit sum(A==B)\nThe slowest run took 2784.03 times longer than the fastest. This could mean that an intermediate result is being cached \n100000 loops, best of 3: 11.4 µs per loop\n1000 loops, best of 3: 1.34 ms per loop\n"]], ['index by comparision of two numpy arrays in python'], 3, 1], [(30405409, 0), [["In other words, somewhere, you're doing the equivalent of:"], ["Don't do that. You should be doing:"]], [[" u = urllib.unquote(s.decode('utf-8'))\n"]], ['Convert multichar %xx escapes to unicode'], 3, 0], [(30405409, 1), [["Don't do that. You should be doing:"], ['-10000']], [[" u = urllib.unquote(s).decode('utf-8')\n"]], ['Convert multichar %xx escapes to unicode'], 3, 1], [(30405409, 2), [['-10000'], ['But it would be better to not have the framework hand you charset-decoded but still quote-encoded strings in the first place.']], [[" u = urllib.unquote(u.encode('utf-8')).decode('utf-8')\n"]], ['Convert multichar %xx escapes to unicode'], 3, 1], [(30406324, 0), [['In the gurobi python API, you can simply set the vtype attribute on the variable.  It is easy if you save a reference to the variable  In your case, if you create a varaible'], ["You can set it's attribe"]], [[' x = m.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS)\n']], ['Gurobi, How to change a continuous variable to a binary variable'], 3, 0], [(30406324, 1), [["You can set it's attribe"], ['You can see it work in this longer example.']], [[' x.vtype = GRB.BINARY\n']], ['Gurobi, How to change a continuous variable to a binary variable'], 3, 0], [(30406324, 2), [['You can see it work in this longer example.'], ['In the first solve, x was continuous, so the optimal value for x was 0.75.  In the second solve, x was binary, so the optimal value for x was 1.0.']], [[' import gurobipy  as grb\nGRB = grb.GRB\nm = grb.Model()\n\nx = m.addVar(0.0, 1.0, vtype=GRB.CONTINUOUS)\ny = m.addVar(0.0, 1.0, vtype=GRB.CONTINUOUS)\nm.update()\n# add constraints so that y >= |x - 0.75|\nm.addConstr(y >= x-0.75)\nm.addConstr(y >= 0.75 - x)\nm.setObjective(y)\nm.update()\nm.optimize()\nprint x.X\n# 0.75\nx.vtype=GRB.BINARY\nm.optimize()\nprint x.X\n# 1.0\n']], ['Gurobi, How to change a continuous variable to a binary variable'], 3, 1], [(30411388, 0), [["Perhaps  pandas  is what you're looking for:"], ['result:']], [[' d1 = pandas.DataFrame(numpy.array([1, 4]), index=[\'a\', \'b\'], dtype="int32")\nd2 = pandas.DataFrame(numpy.array([2, 2]), index=[\'a\', \'c\'], dtype="int32")\n\nd1.add(d2, fill_value=0)\n']], ['More efficient solution? Dictionary as sparse vector'], 2, 1], [(30411388, 1), [['result:'], ['-10000']], [['    0\na  3\nb  4\nc  2\n']], ['More efficient solution? Dictionary as sparse vector'], 2, 0], [(30414578, 0), [['Simply use'], ['If you actually want to first strip all large files from the repository and lose all information association associated with them (i.e. if your intent is to destroy the large files rather than keep them), first run:']], [[' hg lfconvert --to-normal <old> <new>\n']], ['Is there a mercurial command which can generate a clone without largefiles?'], 3, 1], [(30414578, 2), [['where  <nolf>  is the path to a file containing the single line:'], ['and  <old>  is the original repository and  <new>  the target directory for the conversion.']], [[' exclude .hglf\n']], ['Is there a mercurial command which can generate a clone without largefiles?'], 3, 0], [(30443894, 0), [['This behavior is only supported in Python 3.5+, via asynchronous context managers ( __aenter__ / __aexit__ ), and  async with , both of which were added in  PEP 492 :'], ['Prior to 3.5, you have to use a  try / finally  block with explicit calls to the init/cleanup coroutines, unfortunately:']], [[' class TestRepository:\n   # All your normal methods go here\n\n   async def __aenter__(self):\n      # You can call coroutines here\n      await self.some_init()\n\n   async def __aexit__(self, exc_type, exc, tb):\n      # You can call coroutines here\n      await self.do_persistence()\n      await self.fetch_data()\n\n\nasync def do_work():\n    test_repo = TestRepository()\n\n    async with test_repo:\n        res = await test_repo.get_by_lim_off(\n                page_size=int(length),\n                offset=start,\n                customer_name=customer_name,\n                customer_phone=customer_phone,\n                return_type=return_type\n            )\n\n asyncio.get_event_loop().run_until_complete(do_work())\n']], ['Persist and fetch data in with block'], 2, 1], [(30443894, 1), [['Prior to 3.5, you have to use a  try / finally  block with explicit calls to the init/cleanup coroutines, unfortunately:'], ['-10000']], [[' @asyncio.coroutine\ndef do_work():\n    test_repo = TestRepository()\n\n    yield from test_repo.some_init()\n    try:\n        res = yield from test_repo.get_by_lim_off(\n                page_size=int(length),\n                offset=start,\n                customer_name=customer_name,\n                customer_phone=customer_phone,\n                return_type=return_type\n            )\n    finally:\n        yield from test_repo.do_persistence()\n        yield from test_repo.fetch_data()\n']], ['Persist and fetch data in with block'], 2, 1], [(30447975, 0), [["For very large numbers it's better to avoid using floating point square roots altogether because you will run into too many precision issues and you can't even guarantee that you will be within 1 integer value of the correct answer. Fortunately Python natively supports integers of arbitrary size, so you can write an integer square root checking function, like this:"], ['Then you can run through the integers from 0 to 100 like this:']], [[' def isSquare(x):\n    if x == 1:\n        return True\n    low = 0\n    high = x // 2\n    root = high\n    while root * root != x:\n       root = (low + high) // 2\n       if low + 1 >= high:\n          return False\n       if root * root > x:\n          high = root\n       else:\n          low = root\n    return True\n']], ['Finding if a number is a perfect square'], 2, 0], [(30447975, 1), [['Then you can run through the integers from 0 to 100 like this:'], ['-10000']], [[' n = 0\nwhile n <= 100:\n    x = math.factorial(n) + 1\n    if isSquare(x):\n        print n\n    n = n + 1\n']], ['Finding if a number is a perfect square'], 2, 0], [(30464454, 0), [['Guys I have found the solution myself, in case anyone else gets stuck, it would be helpful.'], ['Now my output is as:']], [[" df = pd.DataFrame(columns=['xAxis', 'yAxis1', 'yAxis2'])\ndf['xAxis'] = pd.to_datetime(weather['Date'])\ndf['yAxis1'] = weather_stn1['Tavg']\ndf['yAxis2'] = weather_stn2['Tavg']\n\nplot_df = plot_df.groupby(plot_df['xAxis']).mean()\n\nprint plot_df.reset_index()\n"]], ['How to apply group by on data frame with neglecting NaN values in Pandas?'], 2, 1], [(30464454, 1), [['Now my output is as:'], ['That simple it was!']], [['          xAxis  yAxis1  yAxis2\n0   2009-05-01      53      55\n1   2009-05-02      55      55\n2   2009-05-03      57      58\n3   2009-05-04      57      60\n4   2009-05-05      60      62\n5   2009-05-06      63      66\n']], ['How to apply group by on data frame with neglecting NaN values in Pandas?'], 2, 0], [(30475558, 0), [['That means the function can be written as:'], ['-10000']], [[' def trp(l, n):\n    return l[:n] + [0]*(n-len(l))\n\ntrp([], 4)\n[0, 0, 0, 0]\n\ntrp([1,2,3,4], 4)\n[1, 2, 3, 4]\n\ntrp([1,2,3,4,5], 4)\n[1, 2, 3, 4]\n\ntrp([1,2,3], 4)\n[1, 2, 3, 0]\n']], ['Padding or truncating a Python list'], 2, 1], [(30475558, 1), [['-10000'], ['-10000']], [[' In [1]: a = [1,2,3]\n\nIn [2]: a[:4]\nOut[2]: [1, 2, 3]\n\nIn [3]: [0]*0\nOut[3]: []\n\nIn [4]: [0]*-1\nOut[4]: []\n']], ['Padding or truncating a Python list'], 2, 0], [(30506746, 0), [['You can use  re.findall()  function within a list comprehension :'], ['For example :']], [[" import re\n[re.findall(r'^\\t(.*)\\t.*: (.*)$',i) for i in my_list]\n"]], ['Use regex backreferences to create array'], 3, 1], [(30506746, 1), [['For example :'], ['You can also use  re.search()  with  groups()  method :']], [[' >>> my_list=["\\tLocation\\tNext Available Appointment: Date\\n","\\tLocation2\\tNext Available Appointment: Date2\\n"]\n>>> [re.findall(r\'^\\t(.*)\\t.*: (.*)$\',i) for i in my_list]\n[[(\'Location\', \'Date\')], [(\'Location2\', \'Date2\')]]\n']], ['Use regex backreferences to create array'], 3, 0], [(30506746, 2), [['You can also use  re.search()  with  groups()  method :'], ["Note that the advantage of  re.search  here is that you'll get a list of tuples instead of list of list of tuples (with  findall() )."]], [[" >>> [re.search(r'^\\t(.*)\\t.*: (.*)$',i).groups() for i in my_list]\n[('Location', 'Date'), ('Location2', 'Date2')]\n"]], ['Use regex backreferences to create array'], 3, 1], [(30507442, 0), [['If your DataFrames look like this:'], ['you could concatenate all the DataFrames:']], [[" import datetime as DT\nimport numpy as np\nimport pandas as pd\n\ndf1 = pd.DataFrame({'id':[1,2,1,2], 'value1':[13,14,15,16]}, index=pd.DatetimeIndex(['2015-5-1', '2015-5-1', '2015-5-2', '2015-5-2']))\ndf2 = pd.DataFrame({'id':[1,1], 'value2':[4,5]}, index=pd.DatetimeIndex(['2015-5-1', '2015-5-2']))\ndf3 = pd.DataFrame({'id':[2,2], 'value2':[7,8]}, index=pd.DatetimeIndex(['2015-5-1', '2015-5-2']))\n"]], ['Pandas: add dataframes to dataframe - match on index and column value'], 5, 0], [(30507442, 1), [['you could concatenate all the DataFrames:'], ["Since the result is being aligned on both the date and the  id , it's natural to set  id  as an index. Then if we stack the DataFrame we get this Series:"]], [[' df = pd.concat([df1,df2,df3])\n#             id  value1  value2\n# 2015-05-01   1      13     NaN\n# 2015-05-01   2      14     NaN\n# 2015-05-02   1      15     NaN\n# 2015-05-02   2      16     NaN\n# 2015-05-01   1     NaN       4\n# 2015-05-02   1     NaN       5\n# 2015-05-01   2     NaN       7\n# 2015-05-02   2     NaN       8\n']], ['Pandas: add dataframes to dataframe - match on index and column value'], 5, 0], [(30507442, 2), [["Since the result is being aligned on both the date and the  id , it's natural to set  id  as an index. Then if we stack the DataFrame we get this Series:"], ['Now if we turn around and unstack the Series, the values are aligned based on the remaining index -- the date and the  id :']], [[" series = df.set_index(['id'], append=True).stack()\n#             id        \n# 2015-05-01  1   value1    13\n#             2   value1    14\n# 2015-05-02  1   value1    15\n#             2   value1    16\n# 2015-05-01  1   value2     4\n# 2015-05-02  1   value2     5\n# 2015-05-01  2   value2     7\n# 2015-05-02  2   value2     8\n# dtype: float64\n"]], ['Pandas: add dataframes to dataframe - match on index and column value'], 5, 0], [(30507442, 3), [['Now if we turn around and unstack the Series, the values are aligned based on the remaining index -- the date and the  id :'], ['yields']], [[' result = series.unstack()\n']], ['Pandas: add dataframes to dataframe - match on index and column value'], 5, 0], [(30507442, 4), [['yields'], ['Note that  unstack()  requires that the remaining index is unique. That means\nthat there are no duplicate  (date, id)  entries. If there are duplicate entries, then its not clear what the desired output should be. One way to address the issue would be to group by the  date  and  id  and aggregate the values. Another option would be to pick one value and drop the others.']], [['                value1  value2\n           id                \n2015-05-01 1       13       4\n           2       14       7\n2015-05-02 1       15       5\n           2       16       8\n']], ['Pandas: add dataframes to dataframe - match on index and column value'], 5, 0], [(30515888, 0), [['You can use the  eqnarray  enivironment as described  here .'], ['-10000']], [[" import matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib.offsetbox as offsetbox\nfrom matplotlib import rc\n\nrc('text', usetex=True)\n\n# Figure top-level container. Weird size is because\n# this is part of a larger code.\nfig = plt.figure(figsize=(30, 25))\ngs = gridspec.GridSpec(10, 12)\nax_t = plt.subplot(gs[4:6, 10:12])\n\n# Some mock values.\ncp_r = [0.001, 8.3, 0.18, 15.2, 5000, 0.3]\ncp_e = [0.0005, 0.2, 0.11, 0.3, 200, 0.1]\n\n# Remove axis from frame.\nax_t.axis('off')\n\n# Text lines.\ntext1 = r'\\begin{eqnarray*} '\ntext2 = r'y &=& ' + str(cp_r[0]) + '\\pm ' + str(cp_e[0]) + '\\\\\\\\'\ntext3 = r'\\log(ret) &=& ' + str(cp_r[1]) + '\\pm ' + str(cp_e[1]) + '\\\\\\\\'\ntext4 = r'A_{{(B-C)}} &=& ' + str(cp_r[2]) + '\\pm ' + str(cp_e[2]) + '\\\\\\\\'\ntext5 = r'(n-N)_o &=& ' + str(cp_r[3]) + '\\pm ' + str(cp_e[3]) + '\\\\\\\\'\ntext6 = r'K_{{\\odot}} &=& ' + str(cp_r[4]) + '\\pm ' + str(cp_e[4]) + '\\\\\\\\'\ntext7 = r'd_{{frac}} &=& ' + str(cp_r[5]) + '\\pm ' + str(cp_e[5])\ntext8 = r'\\end{eqnarray*}'\ntext = text1 + text2 + text3 + text4 + text5 + text6 + text7 + text8\n\n# Draw text box.\nob = offsetbox.AnchoredText(text, pad=1, loc=6, prop=dict(size=13))\nob.patch.set(alpha=0.85)\nax_t.add_artist(ob)\n\nplt.savefig('out.png', dpi=300)\n"]], ['Align LaTeX math text in matplotlib text box'], 2, 1], [(30515888, 1), [['-10000'], ['-10000']], [[' import matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib.offsetbox as offsetbox\ncustom_preamble = {\n    "text.usetex": True,\n    "text.latex.preamble": [\n        r"\\usepackage{amsmath}", # for the align enivironment\n        ],\n    }\nplt.rcParams.update(custom_preamble)\n\n# Figure top-level container. Weird size is because\n# this is part of a larger code.\nfig = plt.figure(figsize=(30, 25))\ngs = gridspec.GridSpec(10, 12)\nax_t = plt.subplot(gs[4:6, 10:12])\n\n# Some mock values.\ncp_r = [0.001, 8.3, 0.18, 15.2, 5000, 0.3]\ncp_e = [0.0005, 0.2, 0.11, 0.3, 200, 0.1]\n\n# Remove axis from frame.\nax_t.axis(\'off\')\n\n# Text lines.\ntext1 = r\'\\begin{align*} \'\ntext2 = r\'y &= \' + str(cp_r[0]) + \'\\pm \' + str(cp_e[0]) + \'\\\\\\\\\'\ntext3 = r\'\\log(ret) &= \' + str(cp_r[1]) + \'\\pm \' + str(cp_e[1]) + \'\\\\\\\\\'\ntext4 = r\'A_{{(B-C)}} &= \' + str(cp_r[2]) + \'\\pm \' + str(cp_e[2]) + \'\\\\\\\\\'\ntext5 = r\'(n-N)_o &= \' + str(cp_r[3]) + \'\\pm \' + str(cp_e[3]) + \'\\\\\\\\\'\ntext6 = r\'K_{{\\odot}} &= \' + str(cp_r[4]) + \'\\pm \' + str(cp_e[4]) + \'\\\\\\\\\'\ntext7 = r\'d_{{frac}} &= \' + str(cp_r[5]) + \'\\pm \' + str(cp_e[5])\ntext8 = r\'\\end{align*}\'\ntext = text1 + text2 + text3 + text4 + text5 + text6 + text7 + text8\n\n# Draw text box.\nob = offsetbox.AnchoredText(text, pad=1, loc=6, prop=dict(size=13))\nob.patch.set(alpha=0.85)\nax_t.add_artist(ob)\n\nplt.savefig(\'out.png\', dpi=300)\n']], ['Align LaTeX math text in matplotlib text box'], 2, 1], [(30528673, 0), [['For example : '], ['which would produce']], [[' import pandas as pd\ndf1 = pd.DataFrame.from_csv("file1.csv", sep=",")\ndf2 = pd.DataFrame.from_csv("file2.csv", sep=",")\nfinal_df = df1.reset_index().merge(df2.reset_index(), how="outer").set_index(\'ID\')\n\nfinal_df.to_csv("result.csv", sep=",")\n']], ['Merge CSVs using Python (or Bash)'], 2, 1], [(30528673, 1), [['which would produce'], ['You would have to play with the  sep  argument to adapt to your files format. ']], [[' ID,Name,ContactNo,Designation\n53,Vikas,9874563210.0, \n23,MyShore,,Software Engineer \n']], ['Merge CSVs using Python (or Bash)'], 2, 0], [(30559807, 0), [['This will do (considering 24 hex chars), using raw keyword before string so no need to escape with double slashes:'], ['Python console:']], [[" r'\\/api\\/v1\\/users\\/([a-f\\d]{24})\\/submissions'\n"]], ['Python - regex to match url with mongo object id'], 2, 1], [(30559807, 1), [['Python console:'], ['-10000']], [[" >>> re.findall(r'\\/api\\/v1\\/users\\/([a-f\\d]{24})\\/submissions','/api/v1/users/556b352f87d4693546d31185/submissions')\n['556b352f87d4693546d31185']\n"]], ['Python - regex to match url with mongo object id'], 2, 1], [(30578068, 0), [['1) First, we define the center of the shape given the X0_{x,y} start  and X1_{x,y} end points of the line.'], ['2) Then find the slope (angle) of the line.']], [[' center_L1 = (X0 + X1) / 2.\n']], ['Pygame draw anti-aliased thick line'], 4, 0], [(30578068, 1), [['2) Then find the slope (angle) of the line.'], ['3) Using the slope and the shape parameters you can calculate the following coordinates of the box ends.']], [[' length = 10 # Line size\nthickness = 2\nangle = math.atan2(X0[1] - X1[1], X0[0] - X1[0])\n']], ['Pygame draw anti-aliased thick line'], 4, 0], [(30578068, 2), [['3) Using the slope and the shape parameters you can calculate the following coordinates of the box ends.'], ['4) Using the computed coordinates we draw an anti-aliased polygon (thanks to @martineau) and then fill it as suggested on the  gfxdraw  website.']], [[' UL = (center_L1[0] + (length / 2.) * cos(angle) - (thickness / 2.) * sin(angle),\n      center_L1[1] + (thickness / 2.) * cos(angle) + (length / 2.) * sin(angle))\nUR = (center_L1[0] - (length / 2.) * cos(angle) - (thickness / 2.) * sin(angle),\n      center_L1[1] + (thickness / 2.) * cos(angle) - (length / 2.) * sin(angle))\nBL = (center_L1[0] + (length / 2.) * cos(angle) + (thickness / 2.) * sin(angle),\n      center_L1[1] - (thickness / 2.) * cos(angle) + (length / 2.) * sin(angle))\nBR = (center_L1[0] - (length / 2.) * cos(angle) + (thickness / 2.) * sin(angle),\n      center_L1[1] - (thickness / 2.) * cos(angle) - (length / 2.) * sin(angle))\n']], ['Pygame draw anti-aliased thick line'], 4, 0], [(30578068, 3), [['4) Using the computed coordinates we draw an anti-aliased polygon (thanks to @martineau) and then fill it as suggested on the  gfxdraw  website.'], ['-10000']], [[' pygame.gfxdraw.aapolygon(window, (UL, UR, BR, BL), color_L1)\npygame.gfxdraw.filled_polygon(window, (UL, UR, BR, BL), color_L1)\n']], ['Pygame draw anti-aliased thick line'], 4, 0], [(30602088, 0), [['As an example (close to what you provided), consider the following class definitions'], ['This can be wrapped to python using Boost.Python']], [[' class Bar\n{\nprivate:\n    int value;\n\npublic:\n    Bar() : value(42){ }\n\n    //Functions to expose to Python:\n    int getValue() const { return value; }\n    void setValue(int newValue) { value = newValue; }\n};\n\nclass Foo\n{\nprivate:\n    //Integer Vector:\n    std::vector<int> fooVector;\n    Bar bar;\n\npublic:\n    //Functions to expose to Python:\n    void pushBack(const int& newInt) { fooVector.push_back(newInt); }\n    int getInt(const int& element) { return fooVector.at(element); }\n    Bar& getBar() { return bar; }\n};\n\ndouble compute() { return 18.3; }\n']], ['Calling C++ class functions from Ruby/Python'], 3, 0], [(30602088, 1), [['This can be wrapped to python using Boost.Python'], ['This code can be compiled to a static library  MyLibrary.pyd  and used like this']], [[' #include <boost/python.hpp>\nBOOST_PYTHON_MODULE(MyLibrary) {\n    using namespace boost::python;\n\n    class_<Foo>("Foo", init<>())\n        .def("pushBack", &Foo::pushBack, (arg("newInt")))\n        .def("getInt", &Foo::getInt, (arg("element")))\n        .def("getBar", &Foo::getBar, return_value_policy<reference_existing_object>())\n    ;\n\n    class_<Bar>("Bar", init<>())\n        .def("getValue", &Bar::getValue)\n        .def("setValue", &Bar::setValue, (arg("newValue")))\n    ;\n\n    def("compute", compute);\n}\n']], ['Calling C++ class functions from Ruby/Python'], 3, 0], [(30602088, 2), [['This code can be compiled to a static library  MyLibrary.pyd  and used like this'], ['-10000']], [[' import MyLibrary\n\nfoo = MyLibrary.Foo()\nfoo.pushBack(10);\nfoo.pushBack(20);\nfoo.pushBack(30);\nprint(foo.getInt(0)) # 10\nprint(foo.getInt(1)) # 20\nprint(foo.getInt(2)) # 30\n\nbar = foo.getBar()\nprint(bar.getValue()) # 42\nbar.setValue(17)\nprint(foo.getBar().getValue()) #17\n\nprint(MyLibrary.compute()) # 18.3\n']], ['Calling C++ class functions from Ruby/Python'], 3, 0], [(30620595, 0), [['Provided your function  bla  can accept arrays instead of scalars, you could use\n meshgrid  to prepare the inputs so that  bla(A, B)  returns the desired output:'], ['yields']], [[' import numpy as np\ndef bla(a, b):\n    f = a + b\n    return f\n\nA, B = np.meshgrid([0.2,0.4], [2,4], sparse=True)\nbla(A, B)\n']], ['Python: obtain multidimensional matrix as results from a function'], 2, 1], [(30620595, 1), [['yields'], ['-10000']], [[' array([[ 2.2,  2.4],\n       [ 4.2,  4.4]])\n']], ['Python: obtain multidimensional matrix as results from a function'], 2, 0], [(30641097, 0), [['Example:'], ['Output:']], [[" final_result = 0\na = '3 4  4 5 6'\ni = 0\nwhile i < len(a):\n    print('iteration')\n    print('i is = ')\n    print(i)\n    if a[i] is ' ' and a[i + 1] is not ' ':\n        if i - 1 is 0:\n            final_result = int(a[i - 1]) + int(a[i + 1])\n            i += 2  # here goes the increment\n            print('1a- m here')\n            print(final_result)\n            print('i is = ')\n            print(i)\n        else:\n            final_result = final_result + int(a[i + 1])\n            i += 2  # here goes the increment\n            print('1b- m here')\n            print(final_result)\n    elif a[i] is ' ' and a[i + 1] is ' ':\n        if i - 1 is 0:\n            final_result = int(a[i - 1]) - int(a[i + 1])\n            i += 3  # here goes the increment\n            print('2a- m here')\n            print(final_result)\n        else:\n            final_result = final_result - int(a[i + 2])\n            i += 3  # here goes the increment\n            print('2b- m here')\n            print(final_result)\n            print('i is = ')\n            print(i)\n    else:\n        i += 1\nprint(final_result)\n"]], ["how to decrement and increment loop range 'i' variable in the execution of loop in python"], 2, 1], [(30641097, 1), [['Output:'], ['-10000']], [[' $ python3.4 foo.py\niteration\ni is = \n0\niteration\ni is = \n1\n1a- m here\n7\ni is = \n3\niteration\ni is = \n3\n2b- m here\n3\ni is = \n6\niteration\ni is = \n6\n1b- m here\n8\niteration\ni is = \n8\n1b- m here\n14\n14\n']], ["how to decrement and increment loop range 'i' variable in the execution of loop in python"], 2, 0], [(30667382, 0), [["Not sure if this is exactly what you want, but it's a start :)"], ['Produces:']], [[" from itertools import combinations\n\n# Assume input is a list of strings called input_list\ninput_list = ['OG_1: A|1 A|3 B|1 C|2','OG_2: A|4 B|6','OG_3: C|8 B|9 A|10']\n\n# Create a dict to store relationships and a list to store OGs\nrels = {}\nspecies = set()\n\n# Populate the dict\nfor item in input_list:\n    params = item.split(': ')\n    og = params[0]\n    raw_species = params[1].split()\n    s = [rs.split('|')[0] for rs in raw_species]\n    rels[og] = s\n\n    for item in s:\n        species.add(item)\n\n# Get the possible combinations of species:\ncombos = [c for limit in range(1, len(l)-1) for c in combinations(species,limit)]\n\ndef combo_in_og(combo, og):\n    for item in combo:\n        if item not in rels[og]:\n            return False\n    return True\n\n# Loop over the combinations and print\nfor combo in combos:\n    valid_ogs = []\n    for og in ogs:\n        if combo_in_og(combo, og):\n            valid_ogs.append(og)\n    print('(species) ' + ','.join(combo) + ' (are in groups) ' + ', '.join(valid_ogs))\n"]], ['modify range in every loop of the range'], 2, 1], [(30667382, 1), [['Produces:'], ["Just a warning: what you're trying to do will start to take forever with large enough numbers of inputs, as its complexity is 2^N. You can't get around it (that's what  the problem demands ), but it's there."]], [[' (species) C (are in groups) OG_1, OG_3\n(species) A (are in groups) OG_1, OG_2, OG_3\n(species) B (are in groups) OG_1, OG_2, OG_3\n(species) C,A (are in groups) OG_1, OG_3\n(species) C,B (are in groups) OG_1, OG_3\n(species) A,B (are in groups) OG_1, OG_2, OG_3\n(species) C,A,B (are in groups) OG_1, OG_3\n']], ['modify range in every loop of the range'], 2, 0], [(30683301, 0), [['This is pretty easy once you figure out what an identical row means. I simply use the hash of the stringifed values. If you have an alternate definition then that would work as well.'], ["Compute a hash for each row. Identical 'rows' yield identical hashes"]], [[" In [37]: df = DataFrame({'A' : [1,1,1,2,3,3], 'B' : [2,2,2,2,3,3]})\n\nIn [38]: df\nOut[38]: \n   A  B\n0  1  2\n1  1  2\n2  1  2\n3  2  2\n4  3  3\n5  3  3\n"]], ['How many times is a particular row present?'], 3, 0], [(30683301, 1), [["Compute a hash for each row. Identical 'rows' yield identical hashes"], ['Map the value counts back to the original indexes. You can pass  take_last=False  to  .drop_duplicates()  if you want the first unique row (rather than the last)']], [[' In [39]: hashed = df.apply(lambda x: hash(str(x.values)), axis=1)\n\nIn [40]: hashed\nOut[40]: \n0    4112993419872972622\n1    4112993419872972622\n2    4112993419872972622\n3    7113020419917972579\n4    6113011419891972603\n5    6113011419891972603\ndtype: int64\n']], ['How many times is a particular row present?'], 3, 0], [(30683301, 2), [['Map the value counts back to the original indexes. You can pass  take_last=False  to  .drop_duplicates()  if you want the first unique row (rather than the last)'], ['-10000']], [[' In [41]: hashed.drop_duplicates().map(hashed.value_counts())\nOut[41]: \n0    3\n3    1\n4    2\ndtype: int64\n']], ['How many times is a particular row present?'], 3, 0], [(30683325, 0), [['Use  subprocess.check_call  redirecting stdout to a file object:'], ['Whatever you what to do when the command returns a non-zero  exit status should be handled in the except. If you want a file for stdout and another to handle stderr open two files:']], [[' from subprocess import check_call, STDOUT, CalledProcessError\n\nwith open("out.txt","w") as f:\n    try:\n        check_call([\'ls\', \'-l\'], stdout=f, stderr=STDOUT)\n    except CalledProcessError as e:\n        print(e.message)\n']], ['How to execute and save result of an OS command to a file'], 2, 1], [(30683325, 1), [['Whatever you what to do when the command returns a non-zero  exit status should be handled in the except. If you want a file for stdout and another to handle stderr open two files:'], ['-10000']], [[' from subprocess import check_call, STDOUT, CalledProcessError, call\n\nwith open("stdout.txt","w") as f, open("stderr.txt","w") as f2:\n    try:\n        check_call([\'ls\', \'-l\'], stdout=f, stderr=f2)\n    except CalledProcessError as e:\n        print(e.message)\n']], ['How to execute and save result of an OS command to a file'], 2, 1], [(30685363, 0), [['For example:'], ['output:']], [[" columns = []\nwith open(file,'rU') as f: \n    reader = csv.reader(f)\n    for row in reader:\n        if columns:\n            for i, value in enumerate(row):\n                columns[i].append(value)\n        else:\n            # first row\n            columns = [[value] for value in row]\n# you now have a column-major 2D array of your file.\nas_dict = {c[0] : c[1:] for c in columns}\nprint(as_dict)\n"]], ['python csv to dictionary columnwise'], 2, 1], [(30685363, 1), [['output:'], ['(some weird spaces, which were in your input "file". Remove spaces before/after commas, or use  value.strip()  if they\'re in your real input.)']], [[" {\n    ' numbers': [' 1', ' 2', ' 3', ' 4'], \n    ' colors ': [' blue', ' red', ' green', ' yellow'],\n    'strings': ['string1', 'string2', 'string3', 'string4']\n}\n"]], ['python csv to dictionary columnwise'], 2, 0], [(30701329, 2), [['To get count for only  2'], ['Alternatively, you could use  np.bincount  method, to count number of occurrences of each value in array of non-negative ints.']], [[' In [5]: [Counter(x)[2] for x in a]\nOut[5]: [3, 0]\n']], ['How to count occurrences of specific element for arrays in a list?'], 5, 1], [(30701329, 3), [['Alternatively, you could use  np.bincount  method, to count number of occurrences of each value in array of non-negative ints.'], ['Extract counts for number  2']], [[' In [6]: [np.bincount(x) for x in a]\nOut[6]: [array([0, 1, 3], dtype=int64), array([0, 1, 0, 1], dtype=int64)]\n']], ['How to count occurrences of specific element for arrays in a list?'], 5, 1], [(30701329, 4), [['Extract counts for number  2'], ['-10000']], [[' In [7]: [np.bincount(x)[2] for x in a]\nOut[7]: [3, 0]\n']], ['How to count occurrences of specific element for arrays in a list?'], 5, 1], [(30727894, 0), [['Another option would be to use a  "headless" browser , such as  PhantomJS . In this case, the change is usually very simple, replacing:'], ['with:']], [[' firefox = webdriver.Firefox()\n']], ['Using selenium at hosted app?'], 4, 0], [(30727894, 2), [['Demo:'], ['-10000']], [[' >>> from selenium import webdriver\n>>> driver = webdriver.PhantomJS()\n>>> driver.get("http://www.hltv.org/match/2296366-gplay-gamers2-acer-predator-masters-powered-by-intel")\n>>> driver.title\nu\'HLTV.org - Hot Match: GPlay vs Gamers2\'\n']], ['Using selenium at hosted app?'], 4, 1], [(30727894, 3), [['-10000'], ['In case of  BrowserStack  or  Sauce Labs  you have an enormous amount of browsers and operating systems to choose from. Note that these are not free services and you would need a  username  and a  key  for this code to work.']], [[' from selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n\ndesired_cap = {\'os\': \'Windows\', \'os_version\': \'xp\', \'browser\': \'IE\', \'browser_version\': \'7.0\' }\n\ndriver = webdriver.Remote(\n    command_executor=\'http://username:key@hub.browserstack.com:80/wd/hub\',\n    desired_capabilities=desired_cap)\n\ndriver.get("http://www.google.com")\nif not "Google" in driver.title:\n    raise Exception("Unable to load google page!")\nelem = driver.find_element_by_name("q")\nelem.send_keys("BrowerStack")\nelem.submit()\nprint driver.title\ndriver.quit()\n']], ['Using selenium at hosted app?'], 4, 1], [(30740326, 0), [['You can easily join the  service_args  to get a string:'], ['and put that before the script:']], [[' saStr = " ".join(service_args)\n']], ['I dont know how to add Proxy to my Phantomjs script'], 2, 0], [(30740326, 1), [['and put that before the script:'], ['-10000']], [[" params = CASPER +' '+ saStr + ' ' + SCRIPT\n"]], ['I dont know how to add Proxy to my Phantomjs script'], 2, 0], [(30777540, 1), [["Consider a slightly larger example with 1000 points of dimension 300, with each point drawn from a gaussian mixture. Each point's value is normally distributed with mean 0 and variance 1 with probability 0.1 and normally distributed with mean 100 and variance 1 with probability 0.9:"], ['The resulting objective values were 1.1e6 for the proposed approach and 1.6e9 for the centroid approach, meaning the proposed approach decreased the objective by more than 99.9%. Obviously the differences in the objective value are heavily affected by the distribution of the points.']], [[' data = []\nfor n in range(1000):\n    d = []\n    for m in range(300):\n        if random.random() <= 0.1:\n            d.append(random.normalvariate(0.0, 1.0))\n        else:\n            d.append(random.normalvariate(100.0, 1.0))\n    data.append(d)\n']], ['Finding a vector that is approximately equally distant from all vectors in a set'], 2, 0], [(30782867, 0), [['Sure. Just write a class and define your  __add__  method to return the RHS unmodified.'], ['Result:']], [[' class DummyItem:\n    def __add__(self, other):\n        return other\n\ns = DummyItem()\ns += 23\nprint s\n']], ['python create empty object of arbitrary type?'], 2, 1], [(30782867, 1), [['Result:'], ['-10000']], [[' 23\n']], ['python create empty object of arbitrary type?'], 2, 0], [(30784217, 0), [['After searching the best way to tackle this problem, using  pyjwkest  seems to be a good one instead of creating my own function.'], ['Then we use  long_to_base64  function for this']], [[' pip install pyjwkest\n']], ['Get the big-endian byte sequence of integer in Python'], 2, 0], [(30784217, 1), [['Then we use  long_to_base64  function for this'], ['-10000']], [[" >>> from jwkest import long_to_base64\n>>> long_to_base64(65537)\n'AQAB'\n"]], ['Get the big-endian byte sequence of integer in Python'], 2, 0], [(30793198, 0), [['Code'], ['And to match desired output']], [[" >>> num = 5270\n>>> pairs = [chr(num/100),chr(num%100)]\n>>> pairs\n['4', 'F']\n"]], ['Best way to Convert pairs of base 10 integers to ascii characters in python'], 2, 1], [(30793198, 1), [['And to match desired output'], ['-10000']], [[" >>> ''.join(pairs)\n'4F'\n"]], ['Best way to Convert pairs of base 10 integers to ascii characters in python'], 2, 0], [(30795450, 0), [["I've got for you another solution, basically what it does, instead of reading whole content of file into memory, you read line by line and check in each line you read if it has one of  elements of list_to_search , then modify it if so:"], ['EDIT: In response to your comment below:']], [[" list_to_search =['TRC_BTM', 'TRC_HCI', 'TRC_L2CAP']\nmyDict = {'TRC_BTM': '6', 'TRC_HCI': '6', 'TRC_L2CAP': '6'}\n\nfilename ='file.conf'\n\nwith open(filename, 'rb+') as f:\n\n    while True:         \n        line = f.readline()\n        if not line: break          \n        for key in list_to_search:\n            if key in line:\n                f.seek(-len(line),1)\n                f.write(key + '=' + myDict[key] + '\\n')\n                f.flush()\n"]], ['how to search values in a file and replace'], 2, 1], [(30795450, 1), [['EDIT: In response to your comment below:'], ['-10000']], [[" with open(filename, 'rb+') as f:\n\n    while True:         \n        line = f.readline()\n        if not line: break        \n        if '=2' in line:\n                f.seek(-len(line),1)\n                f.write(line.split('=2')[0]+'=6')\n                f.flush()\n"]], ['how to search values in a file and replace'], 2, 1], [(30801180, 0), [['You can use  heapq.nsmallest  with  sum  as its key function :'], ['Or as @jonrsharpe said in comment you can use  sorted  :']], [[' >>> import heapq\n>>> heapq.nsmallest(3,c,key=sum)\n[(1, 2), (1, 4), (3, 2)]\n']], ['Find k smallest pairs in two lists'], 2, 1], [(30801180, 1), [['Or as @jonrsharpe said in comment you can use  sorted  :'], ['-10000']], [[' sorted(c, key=sum)[:k]\n']], ['Find k smallest pairs in two lists'], 2, 1], [(30837683, 0), [['You can simply do '], ['or']], [[' x="a85b080040010000"\nprint re.sub(r"(.{2})",r"\\1 ",x)\n']], ['chunk of data into fixed lengths chunks and then add a space and again add them all as a string'], 2, 1], [(30837683, 1), [['or'], ['-10000']], [[' x="a85b080040010000"\n\nprint " ".join([i for i in re.split(r"(.{2})",x) if i])\n']], ['chunk of data into fixed lengths chunks and then add a space and again add them all as a string'], 2, 1], [(30904903, 0), [['Something like this should work for your question:'], ['-10000']], [[' import csv\nimport calendar\nfrom collections import defaultdict\n\nmonths = [calendar.month_name[i] for i in range(0, 13)]\ntotals = defaultdict(int)\n\nwith open("data.csv", "r") as inf, open("data-out.csv", "w") as ouf:\n    reader = csv.DictReader(inf)\n    writer = csv.DictWriter(ouf, [\'Name\'] + months[5:9])\n    writer.writeheader()\n    for row in reader:\n        m1 = months[int(row[\'Date1\'].split(\'/\')[0])]\n        p2 = int(row[\'Price2\'])\n        totals[m1] += p2\n\n        m2 = months[int(row[\'Date2\'].split(\'/\')[0])]\n        p1 = int(row[\'Price1\'])\n        totals[m2] += p1\n\n        writer.writerow({\'Name\': row[\'Name\'], m1: p2, m2: p1})\n\n    totals[\'Name\'] = \'Total\'\n    writer.writerow(totals)\n']], ['writing csv output python'], 4, 1], [(30904903, 1), [['-10000'], ['-10000']], [[' with open("data-out.csv", "r") as f:\n    print(f.read())\n\nName,May,June,July,August\nABC,7500,1000,,\nDEF,500,,3000,\nGHI,,3500,,5000\nTotal,8000,4500,3000,5000\n']], ['writing csv output python'], 4, 0], [(30904903, 2), [['-10000'], ['to ']], [[" writer = csv.DictWriter(ouf, ['Name'] + months[5:9])\n"]], ['writing csv output python'], 4, 0], [(30904903, 3), [['to '], ['-10000']], [[" writer = csv.DictWriter(ouf, ['Name'] + months[1:])\n"]], ['writing csv output python'], 4, 0], [(30909414, 0), [['For the first one, consider the matrix  K :'], ['In your case,  A  and  B  are defined as:']], [[' L = len(X)\nK = np.identity(L) - np.ones((L, L)) / L\n']], ['Loops to minimize function of arrays in python'], 8, 0], [(30909414, 1), [['In your case,  A  and  B  are defined as:'], ['Apply the formula to find C that minimizes the error  A * C - B :']], [[' A = K.dot(np.array([Y, Z]).transpose())\nB = K.dot(np.array([X]).transpose())\n']], ['Loops to minimize function of arrays in python'], 8, 0], [(30909414, 2), [['Apply the formula to find C that minimizes the error  A * C - B :'], ['Then the result is:']], [[' C = np.linalg.inv(np.transpose(A).dot(A))\nC = C.dot(np.transpose(A)).dot(B)\n']], ['Loops to minimize function of arrays in python'], 8, 0], [(30909414, 3), [['Then the result is:'], ['Also, note that numpy already provides  linalg.lstsq  that does the exact same thing:']], [[' a, b = C.reshape(2)\n']], ['Loops to minimize function of arrays in python'], 8, 0], [(30909414, 4), [['Also, note that numpy already provides  linalg.lstsq  that does the exact same thing:'], ['-10000']], [[' a, b = np.linalg.lstsq(A, B)[0].reshape(2)\n']], ['Loops to minimize function of arrays in python'], 8, 0], [(30909414, 5), [['-10000'], ['Then solve it against  X  to get the coefficients and the mean:']], [[' A = np.array([Y, Z, [1]*len(X)]).transpose()\n']], ['Loops to minimize function of arrays in python'], 8, 0], [(30909414, 6), [['Then solve it against  X  to get the coefficients and the mean:'], ['Example:']], [[' a, b, mean = np.linalg.lstsq(A, X)[0]\n']], ['Loops to minimize function of arrays in python'], 8, 0], [(30909414, 7), [['Example:'], ['-10000']], [[' >>> import numpy as np\n>>> X = [5, 7, 9, 5]\n>>> Y = [2, 0, 4, 1]\n>>> Z = [7, 2, 4, 6]\n>>> A = np.array([Y, Z, [1] * len(X)]).transpose()\n>>> a, b, mean = np.linalg.lstsq(A, X)[0]\n>>> print(a, b, mean)\n0.860082304527 -0.736625514403 8.49382716049\n']], ['Loops to minimize function of arrays in python'], 8, 1], [(30925637, 1), [['-10000'], ['-10000']], [[" import numpy as np\nimport scipy.stats as stats\n\ndistrNameList = ['beta', 'expon', 'gamma']\nsample = stats.norm(0, 1).rvs(1000)\nabscissas = np.linspace(0,1, 10)\nfor distrName in distrNameList:\n    distr = getattr(stats.distributions, distrName)\n    param = distr.fit(sample)\n    pdf = distr.pdf(abscissas, *param)\n    print(pdf)\n"]], ['Getting a pdf from scipy.stats in a generic way'], 2, 1], [(30936020, 1), [['-10000'], ['-10000']], [[" line = re.sub(r'(\\W)(?=\\1)', '', line)\n"]], ['replace multiple occurrences of any special character by one in python'], 2, 1], [(30949202, 0), [['You can use simple  map  as with any other RDD:'], ['and the result is:']], [[' elevDF = sqlContext.createDataFrame(sc.parallelize([\n        Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=1, value=638.55),\n        Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=2, value=638.55),\n        Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=3, value=638.55),\n        Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=4, value=638.55),\n        Row(date=datetime.datetime(1984, 1, 1, 0, 0), hour=5, value=638.55)]))\n\n(elevDF\n .map(lambda (date, hour, value): (date.year, date.month, date.day))\n .collect())\n']], ['Spark DataFrame TimestampType - how to get Year, Month, Day values from field?'], 3, 1], [(30949202, 1), [['and the result is:'], ['Since Spark 1.5 you can use a number of date processing functions']], [[' [(1984, 1, 1), (1984, 1, 1), (1984, 1, 1), (1984, 1, 1), (1984, 1, 1)]\n']], ['Spark DataFrame TimestampType - how to get Year, Month, Day values from field?'], 3, 0], [(30955735, 0), [["To get the container widget of a widget that's handling a callback, you can do:"], ["That said, I'm not exactly sure why you're trying to avoid using a custom class. It's a natural solution to your problem."]], [[' def callback(evt):\n    handling_widget = evt.widget\n    parent_of_handling_widget = handling_widget.master\n    # or evt.widget.master\n    parent_of_handling_widget.destroy()\n']], ["How to access a button's parent in Tkinter without writing class?"], 2, 1], [(30960440, 0), [['Notice that if you unstack the  id  index level of  df  then you get:'], ['And we can think of the values above as a boolean array,  arr :']], [[" In [35]: df.unstack(['id'])\nOut[35]: \n       val             \nid       1      2     3\nyear                   \n2001  True  False  True\n2002  True   True  True\n"]], ['pandas count true values in multi-index frame'], 5, 0], [(30960440, 1), [['And we can think of the values above as a boolean array,  arr :'], ['Imagine taking all the rows of the array except the last one:']], [[" arr = df.unstack(['id']).values\n# array([[ True, False,  True],\n#        [ True,  True,  True]], dtype=bool)\n"]], ['pandas count true values in multi-index frame'], 5, 0], [(30960440, 2), [['Imagine taking all the rows of the array except the last one:'], ['and comparing it to all the rows of the array except the first one:']], [[' In [44]: arr[:-1]\nOut[44]: array([[ True, False,  True]], dtype=bool)\n']], ['pandas count true values in multi-index frame'], 5, 0], [(30960440, 3), [['and comparing it to all the rows of the array except the first one:'], ['We want to count in how many locations they are equal and also equal to True:']], [[' In [45]: arr[1:]\nOut[45]: array([[ True,  True,  True]], dtype=bool)\n']], ['pandas count true values in multi-index frame'], 5, 0], [(30960440, 4), [['We want to count in how many locations they are equal and also equal to True:'], ['-10000']], [[' In [41]: ((arr[:-1] == arr[1:]) & (arr[:-1] == True)).sum()\nOut[41]: 2\n']], ['pandas count true values in multi-index frame'], 5, 0], [(30977603, 0), [['The final logstash filter looks something like this:'], ["Alternatively, if you don't want to use the if block to check another grok pattern and remove the  _grokparsefailure , you can use the first grok filter to check for both the message types by including multiple message-pattern checks in the  match  array of grok filter. It can be done like this:"]], [[' filter {\n\n    multiline {\n        pattern => "^[^\\[]"\n        what => "previous"\n    }\n\n\n\n    grok {\n        match => [\n            "message", "\\[pid\\: %{NUMBER:process_id:int}\\|app: 0\\|req: %{NUMBER}/%{NUMBER}\\] %{IPORHOST:clientip} \\(\\) \\{%{NUMBER:vars:int} vars in %{NUMBER:bytes:int} bytes\\} \\[%{GREEDYDATA:timestamp}\\] %{WORD:method} /%{GREEDYDATA:referrer} \\=\\> generated %{NUMBER:generated_bytes:int} bytes in %{NUMBER} msecs \\(HTTP/%{NUMBER} %{NUMBER:status_code:int}\\) %{NUMBER:headers:int} headers in %{NUMBER:header_bytes:int} bytes \\(%{NUMBER:switches:int} switches on core %{NUMBER:core:int}\\)%{GREEDYDATA:traceback}"\n        ]\n    }\n\n    if "_grokparsefailure" in [tags] {\n        grok {\n            match => [\n            "message", "\\[pid\\: %{NUMBER:process_id:int}\\|app: 0\\|req: %{NUMBER}/%{NUMBER}\\] %{IPORHOST:clientip} \\(\\) \\{%{NUMBER:vars:int} vars in %{NUMBER:bytes:int} bytes\\} \\[%{GREEDYDATA:timestamp}\\] %{WORD:method} /%{GREEDYDATA:referrer} \\=\\> generated %{NUMBER:generated_bytes:int} bytes in %{NUMBER} msecs \\(HTTP/%{NUMBER} %{NUMBER:status_code:int}\\) %{NUMBER:headers:int} headers in %{NUMBER:header_bytes:int} bytes \\(%{NUMBER:switches:int} switches on core %{NUMBER:core:int}\\)"\n                ]\n            remove_tag => ["_grokparsefailure"]\n        }\n    }\n\n    else {\n        mutate {\n            convert => {"traceback" => "string"}\n        }\n    }\n\n    date {\n        match => ["timestamp", "dd/MM/YYYY:HH:MM:ss Z"]\n        locale => en\n    }\n    geoip {\n        source => "clientip"\n    }\n    useragent {\n        source => "agent"\n        target => "Useragent"\n    }\n}\n']], ['Parse logs containing python tracebacks using logstash'], 3, 1], [(30992225, 0), [["If you don't necessarily need to use  BeautifulSoup  I think it would be easier to do something like this:"], ['Output:']], [[" import feedparser\n\nurl = feedparser.parse('http://ellywonderland.blogspot.com/feeds/posts/default?alt=rss')\nfor x in url.entries:\n    print str(x.link)\n"]], ['Extract links for certain section only from blogspot using BeautifulSoup'], 2, 1], [(30992225, 1), [['Output:'], ['feedparser  can parse the RSS feed of the blogspot page and can return the data you want, in this case the  href  for the post titles.']], [[' http://ellywonderland.blogspot.com/2011/03/my-vintage-pre-wedding.html\nhttp://ellywonderland.blogspot.com/2011/02/pre-wedding-vintage.html\nhttp://ellywonderland.blogspot.com/2010/12/tissue-paper-flower-crepe-paper.html\nhttp://ellywonderland.blogspot.com/2010/12/menguap-menurut-islam.html\nhttp://ellywonderland.blogspot.com/2010/12/weddings-idea.html\nhttp://ellywonderland.blogspot.com/2010/12/kawin.html\nhttp://ellywonderland.blogspot.com/2010/11/vitamin-c-collagen.html\nhttp://ellywonderland.blogspot.com/2010/11/port-dickson.html\nhttp://ellywonderland.blogspot.com/2010/11/ellys-world.html\n']], ['Extract links for certain section only from blogspot using BeautifulSoup'], 2, 0], [(31009455, 0), [['-10000'], ['Demo:']], [[' for el in elems:\n    try:\n        print el.xpath("preceding::c[@attr1]")[-1].get("attr1")\n    except IndexError:\n        print "No preceding \'c\' element."\n']], ['lxml etree find closest element before'], 2, 1], [(31009455, 1), [['Demo:'], ['-10000']], [[' >>> from lxml import etree\n>>> \n>>> data = """\n... <a>\n...     <b>\n...         <d/>\n...     </b>\n... \n...     <c attr1="important"/>\n...     <b>\n...         <d/>\n...     </b>\n...     <c attr1="so important" />\n...     <b></b>\n... </a>\n... """\n>>> xmltree = etree.fromstring(data)\n>>> elems = xmltree.xpath(\'//d\')\n>>> \n>>> for el in elems:\n...     try:\n...         print el.xpath("preceding::c[@attr1]")[-1].get("attr1")\n...     except IndexError:\n...         print "No preceding \'c\' element."\n... \nNo preceding \'c\' element.\nimportant\n']], ['lxml etree find closest element before'], 2, 1], [(31011179, 0), [['Try the following:'], ["If you don't have  json2html  module:"]], [[' infoFromJson = json.loads(jsonfile)\nprint json2html.convert(json = infoFromJson)\n']], ['Converting JSON to HTML table in Python'], 2, 1], [(31011179, 1), [["If you don't have  json2html  module:"], ['More examples  here .']], [[' $ pip install json2html\n']], ['Converting JSON to HTML table in Python'], 2, 0], [(31011565, 0), [['You need to assign a copy of the list to another variable name, you can use  [:]  to create a shallow copy :'], ['Or use  copy  module :']], [[' >>> D = {"A":[1,2,3]}\n>>> C = D["A"][:]\n>>> C.append(4)\n>>> D["A"]\n[1, 2, 3]\n']], ['Get a value from a dictionary without linking to the memory location'], 2, 1], [(31011565, 1), [['Or use  copy  module :'], ['-10000']], [[' >>> import copy\n>>> C = copy.copy(D["A"])\n>>> C.append(4)\n>>> D["A"]\n[1, 2, 3]\n']], ['Get a value from a dictionary without linking to the memory location'], 2, 1], [(31014848, 0), [['Here is a simple clean solution written in python. You have to replace  input.csv  and  output.csv  with your CSV files.'], ['Here is another shorter solution, which uses piping:']], [[' import csv \n\nlabels = [\n    "Reading Comprehension", "Sentence Skills", "Arithmetic",\n    "College Level Math", "Elementary Algebra"\n]\n\nwith open(\'output.csv\', \'wb\') as outfile, \\\n     open(\'input.csv\', \'rb\') as infile:\n    writer = csv.writer(outfile)\n    reader = csv.reader(infile) \n\n    for row in reader: \n        head = row[:5]\n        tail = []\n        for label in labels:\n            tail.append(next((i for i in row[5:] if i.startswith(label)), ""))\n        writer.writerow(head + tail)\n']], ['Reorder Columns by String Variable'], 3, 1], [(31014848, 1), [['Here is another shorter solution, which uses piping:'], ['If you save this code in a file, for example called  reorder , and make this file executable, you can reformat your CSV file like this:']], [[' #!/usr/bin/python    \nfrom sys import stdin, stdout\n\nlabels = [\n    "Reading Comprehension", "Sentence Skills", "Arithmetic",\n    "College Level Math", "Elementary Algebra"\n]\n\nfor line in stdin: \n    values = line.strip().split(\',\')\n    stdout.write(\',\'.join(values[:5]))\n    for label in labels:\n        stdout.write(\',\')\n        stdout.write(next((i for i in values[5:] if i.startswith(label)), \'\'))\n    stdout.write(\'\\n\')\nstdout.flush()\n']], ['Reorder Columns by String Variable'], 3, 1], [(31014848, 2), [['If you save this code in a file, for example called  reorder , and make this file executable, you can reformat your CSV file like this:'], ['The reformatted csv content is then written to the standard output.']], [[' $ cat input.csv | ./reorder\n']], ['Reorder Columns by String Variable'], 3, 0], [(31021283, 0), [['The simplest, but not very efficient way is:'], ['Output:']], [[" import itertools\n\nnums = [4, 94, 9, 14, 1]\nmax_num = 0\nmax_nums = None\nfor p in itertools.permutations(map(str, nums)):\n    num = int(''.join(p))\n    if num > max_num:\n        max_num = num\n        max_nums = p\nprint map(int, max_nums)\nprint max_num\n"]], ['to get max number after concatenation in list'], 2, 1], [(31021283, 1), [['Output:'], ['-10000']], [[' [9, 94, 4, 14, 1]\n9944141\n']], ['to get max number after concatenation in list'], 2, 0], [(31029467, 0), [['You can make an iterator from  b , then in a list comprehension if the current element of  a  is  None , you can  next(b_iter)  to grab the next item.'], ['As an example']], [[' b_iter = iter(b)\na = [next(b_iter) if i is None else i for i in a]\n']], ['minimize memory consumption when dealing with python list assignment'], 2, 1], [(31029467, 1), [['As an example'], ['-10000']], [[' >>> a = [None, 0, None, None, 0, None, None, None, 0, None, None, None, None, None, 0]\n>>> b = [7, 1, 4, 8, 2, 1, 1, 1, 1, 6, 1]\n>>> b_iter = iter(b)\n>>> [next(b_iter) if i is None else i for i in a]\n[7, 0, 1, 4, 0, 8, 2, 1, 0, 1, 1, 1, 6, 1, 0]\n']], ['minimize memory consumption when dealing with python list assignment'], 2, 1], [(31076841, 1), [['Usage:'], ['Expected conditions are, basically callables, which means you can just write a function instead, but I like to follow the way they are implemented as classes internally in python-selenium.']], [[' wait = WebDriverWait(driver, 10)\nwait.until(wait_for_class((By.ID, \'select-1\'), "ui-state-error"))\n']], ['How can I wait until an element gains or loses a class?'], 2, 0], [(31078921, 0), [['You should use the  get_support  function:'], ['Alternatively, you can get the indices of the support features:']], [[' from sklearn.datasets import load_iris\nfrom sklearn.linear_model import RandomizedLogisticRegression\n\niris = load_iris()\nX, y = iris.data, iris.target\n\nclf = RandomizedLogisticRegression()\nclf.fit(X,y)\nprint clf.get_support()\n\n#prints [False  True  True  True]\n']], ['Find selected features by RandomizedLogisticRegression'], 2, 1], [(31078921, 1), [['Alternatively, you can get the indices of the support features:'], ['-10000']], [[' print clf.get_support(indices=True)\n#prints [1 2 3]\n']], ['Find selected features by RandomizedLogisticRegression'], 2, 0], [(31105362, 0), [['You can use the  get_dummies  function to your advantage here:'], ['This gives us a dataframe which uses "one-hot" encoding to denote whether a user visited on the date:']], [[" users = data.set_index('date')['user_id']\nvisits = pd.get_dummies(users)\n"]], ['Using DataFrame to get matrix of identifiers'], 4, 0], [(31105362, 1), [['This gives us a dataframe which uses "one-hot" encoding to denote whether a user visited on the date:'], ['But the dates are repeated. We therefore group by the date index and aggregate, asking if the user visited on  any  of the entries for that date:']], [['             a1  a15  a3  a4  a5  a8\ndate                               \n2011-01-02   0    0   0   0   0   1\n2011-01-05   1    0   0   0   0   0\n2011-01-05   1    0   0   0   0   0\n2011-01-12   0    0   0   1   0   0\n2011-01-12   0    0   1   0   0   0\n2011-01-12   1    0   0   0   0   0\n2011-01-12   0    1   0   0   0   0\n2011-01-19   0    1   0   0   0   0\n2011-01-19   1    0   0   0   0   0\n2011-01-19   0    0   0   0   1   0\n']], ['Using DataFrame to get matrix of identifiers'], 4, 0], [(31105362, 2), [['But the dates are repeated. We therefore group by the date index and aggregate, asking if the user visited on  any  of the entries for that date:'], ['which gives:']], [[' visits.groupby(visits.index).any().astype(int)\n']], ['Using DataFrame to get matrix of identifiers'], 4, 0], [(31105362, 3), [['which gives:'], ['-10000']], [['             a1  a15  a3  a4  a5  a8\ndate                               \n2011-01-02   0    0   0   0   0   1\n2011-01-05   1    0   0   0   0   0\n2011-01-12   1    1   1   1   0   0\n2011-01-19   1    1   0   0   1   0\n']], ['Using DataFrame to get matrix of identifiers'], 4, 0], [(31124914, 0), [['Locate the element containing  PATTERN:  text, find the  font  parent and get the next  font  sibling element:'], ['Demo:']], [[' soup = BeautifulSoup(data)\n\nfor elm in soup.find_all(text="PATTERN:"):\n    print elm.find_parent("font").find_next_sibling("font").get_text(strip=True)\n']], ['Python extract info from a local html file'], 4, 1], [(31124914, 1), [['Demo:'], ["Note that, since I have  lxml  installed,  BeautifulSoup  uses it as an underlying parser. I've tried with  html.parser  also and it worked for me.  html5lib  does not work as the previous two. Anyway, specify the parser explicitly:"]], [[' >>> from bs4 import BeautifulSoup\n>>>\n>>> data = """\n... <! Created by program ApproxMAP by Hye-Chung(Monica) Kum>\n... <HTML><font size=5 face=\'Helvetica-Narrow\'><b>\n... <font color=\'000000\'> Cluster Support= [Pattern=</font>\n... <font color=\'000000\'> 50</font>\n... <font color=\'000000\'> % : Variation=</font>\n... <font color=\'000000\'> 20</font>\n... <font color=\'000000\'> %]; Database Support= [Min= </font>\n... <font color=\'000000\'> 1</font>\n... <font color=\'000000\'>  seq: Max=</font>\n... <font color=\'000000\'> 50</font>\n... <font color=\'000000\'> %]</font>\n... <BR>\n... <font color=\'a9a9a9\'> cluster=0 size=3</font>\n... <font color=\'000000\'>   =<100:</font>\n... <font color=\'434343\'> 85:</font>\n... <font color=\'767676\'> 70:</font>\n... <font color=\'a9a9a9\'> 50:</font>\n... <font color=\'c8c8c8\'> 35:</font>\n... <font color=\'e1e1e1\'> 20></font>\n... <BR>\n... <font color=\'000000\'> <u>PATTERN:</font>\n... <font color=\'000000\'> {1,} {2,3,} {4,5,}\n... </font>\n... <font color=\'000000\'> =</font>\n... <font color=\'000000\'> 5</font>\n... <font color=\'000000\'> </u></font>\n... <BR>\n... <font color=\'000000\'> {</font>\n... <font color=\'000000\'> 1</font>\n... <font color=\'cbcbcb\'> 12</font>\n... <font color=\'000000\'> }</font>\n... <font color=\'000000\'> {</font>\n... <font color=\'cbcbcb\'> 24</font>\n... <font color=\'000000\'> }</font>\n... <font color=\'000000\'> {</font>\n... <font color=\'7f7f7f\'> 2</font>\n... <font color=\'7f7f7f\'> 3</font>\n... <font color=\'cbcbcb\'> 25</font>\n... <font color=\'000000\'> }</font>\n... <font color=\'000000\'> {</font>\n... <font color=\'cbcbcb\'> 1</font>\n... <font color=\'7f7f7f\'> 4</font>\n... <font color=\'7f7f7f\'> 5</font>\n... <font color=\'000000\'> }</font>\n... <font color=\'000000\'> {</font>\n... <font color=\'cbcbcb\'> 26</font>\n... <font color=\'000000\'> }</font>\n... <BR>\n... <font color=\'000000\'> <u>PATTERN:</font>\n... <font color=\'000000\'> {9,10,} {11,} {12,13,}\n... </font>\n... <font color=\'000000\'> =</font>\n... <font color=\'000000\'> 5</font>\n... <font color=\'000000\'> </u></font>\n... <BR>\n... <font color=\'000000\'> {</font>\n... <font color=\'717171\'> 9</font>\n... <font color=\'989898\'> 10</font>\n... <font color=\'000000\'> }</font>\n... <font color=\'000000\'> {</font>\n... <font color=\'d3d3d3\'> 11</font>\n... <font color=\'000000\'> }</font>\n... <font color=\'000000\'> {</font>\n... <font color=\'404040\'> 11</font>\n... <font color=\'000000\'> }</font>\n... <font color=\'000000\'> {</font>\n... <font color=\'404040\'> 12</font>\n... <font color=\'989898\'> 13</font>\n... <font color=\'000000\'> }</font>\n... <BR>\n... <font color=\'000000\'> TOTAL LEN=</font>\n... <font color=\'000000\'> 10</font>\n... <BR>\n... <BR>\n... </b></font></html>\n... """\n>>> \n>>> soup = BeautifulSoup(data)\n>>> \n>>> for elm in soup.find_all(text="PATTERN:"):\n...     print elm.find_parent("font").find_next_sibling("font").get_text(strip=True)\n... \n{1,} {2,3,} {4,5,}\n{9,10,} {11,} {12,13,}\n']], ['Python extract info from a local html file'], 4, 1], [(31124914, 2), [["Note that, since I have  lxml  installed,  BeautifulSoup  uses it as an underlying parser. I've tried with  html.parser  also and it worked for me.  html5lib  does not work as the previous two. Anyway, specify the parser explicitly:"], ['or:']], [[' soup = BeautifulSoup(data, "lxml")\n']], ['Python extract info from a local html file'], 4, 0], [(31124914, 3), [['or:'], ['-10000']], [[' soup = BeautifulSoup(data, "html.parser")\n']], ['Python extract info from a local html file'], 4, 0], [(31137183, 0), [['Getting the latest message in a thread is no harder than a User.thread: get-request, asking for the id and internalDate of the individual messages, and figuring out which was created last.'], ['Response:']], [[' fields = messages(id,internalDate)\n\nGET https://www.googleapis.com/gmail/v1/users/me/threads/14e92e929dcc2df2?fields=messages(id%2CinternalDate)&access_token={YOUR_API_KEY}\n']], ['GMail API - Get last message of a thread'], 2, 1], [(31137183, 1), [['Response:'], ['-10000']], [[' {\n "messages": [\n  {\n   "id": "14e92e929dcc2df2",\n   "internalDate": "1436983830000" \n  },\n  {\n   "id": "14e92e94a2645355",\n   "internalDate": "1436983839000"\n  },\n  {\n   "id": "14e92e95cfa0651d",\n   "internalDate": "1436983844000"\n  },\n  {\n   "id": "14e92e9934505214",\n   "internalDate": "1436983857000" // <-- This is it!\n  }\n ]\n}\n']], ['GMail API - Get last message of a thread'], 2, 0], [(31137766, 0), [['Considering the structure you want the data to be in, the format file will look like :'], ['And then utilize it in the code like this :']], [[' {\n  "id":"",\n  "name":"", \n  "phone":"",\n  "email":"", \n  "website":"", \n  "location": {\n    "latitude":"", \n    "longitude":"", \n    "address": {\n      "line1":"", \n      "line2":"", \n      "line3":"", \n      "postcode":"",\n      "city":"", \n      "country":""\n     }\n  }\n} \n']], ['Add fields and correct indentation for json file (using python or ruby)'], 3, 0], [(31137766, 2), [['Here is the code to convert the data back to the regular CSV list :'], ['-10000']], [[' data = {\n  :id => 1,\n    :location => {\n      :address => {\n        :line1 => \'line1\'\n      }\n    },\n  :website => \'site\'\n}\n\ndef deconvert(record)\n  ret = {}\n  record.each do |key, value|\n    if value.is_a? Hash\n      ret.merge!( deconvert(value) )\n    else\n       ret.merge!(key => value)\n    end\n  end\n  ret\nend\n\nputs deconvert data\n# => {:id=>1, :line1=>"line1", :website=>"site"} \n']], ['Add fields and correct indentation for json file (using python or ruby)'], 3, 0], [(31146021, 0), [['To write in file  weather.json'], ['And to read from file  weather.json']], [[' import json\nfrom urllib import urlopen\n\nurl = urlopen(\'http://api.openweathermap.org/data/2.5/forecast/daily?q={}&mode=json&units={}\'.format(getname,temp_type)).read()\n#where getname is the name of city.\n#and temp_type is either C(Celsius) or F(Fahrenheit)\nresult = json.loads(url)\nout_file = open("weather.json","w")\njson.dump(result,self.out_file, indent=4)\n#indent = 4, just to make it easy to read.\nout_file.close()\n']], ['Save app data in Weather App'], 4, 0], [(31146021, 1), [['And to read from file  weather.json'], ['And for the icons I used  requests  module and saved each icon with a unique name, then everytime the user did a new search or refresh the application then automatically the file would be updated and new icons would be downloaded and replaced with the existing ones.']], [[' in_file = open("weather.json", "r")\nresult = json.load(self.in_file)\nin_file.close()\n']], ['Save app data in Weather App'], 4, 0], [(31146021, 2), [['And for the icons I used  requests  module and saved each icon with a unique name, then everytime the user did a new search or refresh the application then automatically the file would be updated and new icons would be downloaded and replaced with the existing ones.'], ['And also as I am using  kivy , So I would like to mention that you need to add  json  in  buildozer.spec  file (As you might have tried it in your PC first)']], [[' import requests\nconditions_image1 = "http://openweathermap.org/img/w/{}.png".format(result[\'list\'][1][\'weather\'][0][\'icon\'])\n#or whatever be the name of your image\nresponse1 = requests.get(conditions_image1)\nif response1.status_code == 200:\n    f = open("./icons/wc1.png", \'wb\')\n    f.write(response1.content)\n    f.close()\n']], ['Save app data in Weather App'], 4, 0], [(31146021, 3), [['And also as I am using  kivy , So I would like to mention that you need to add  json  in  buildozer.spec  file (As you might have tried it in your PC first)'], ['-10000']], [[' source.include_exts = py,png,jpg,kv,atlas,json \n']], ['Save app data in Weather App'], 4, 0], [(31149123, 0), [['You could express this as a  groupby/agg operation :'], ['yields']], [[" import pandas as pd\na = [['Lazy', 'Brown', 'Fox'], ['Jumps', 'Over'], ['Big', 'Blue', 'Sea']]\ndf = pd.DataFrame({'Name':list('ABC'), 'Group':[1,1,2]})\ndf['a'] = a\nprint(df.groupby(['Group'])['a'].sum())\n"]], ['Get the indicies of a dataframe to use on a list'], 3, 1], [(31149123, 1), [['yields'], ['Aggregation by summing works because the sum of two lists is a concatenated list:']], [[' Group\n1    [Lazy, Brown, Fox, Jumps, Over]\n2                   [Big, Blue, Sea]\nName: a, dtype: object\n']], ['Get the indicies of a dataframe to use on a list'], 3, 0], [(31149123, 2), [['Aggregation by summing works because the sum of two lists is a concatenated list:'], ['-10000']], [[" In [322]: ['Lazy', 'Brown', 'Fox'] + ['Jumps', 'Over']\nOut[322]: ['Lazy', 'Brown', 'Fox', 'Jumps', 'Over']\n"]], ['Get the indicies of a dataframe to use on a list'], 3, 0], [(31162560, 0), [['One way to do this, is to define multiple routes.'], ['Another way to do this is to use  path :']], [[' @app.route(\'/test/<command>\')\n@app.route(\'/test/<command>/<arg1>\')\n@app.route(\'/test/<command>/<arg1>/<arg2>\')\ndef test(command=None, arg1=None, arg2=None):\n    a = [arg1, arg2]\n    # Remove any args that are None\n    args = [arg for arg in a if arg is not None]\n    if command == "say":\n        return \' \'.join(args)\n    else:\n        return "Unknown Command"\n']], ['Flask route rule as function args'], 2, 1], [(31162560, 1), [['Another way to do this is to use  path :'], ['If you use this, then if you go to  http://127.0.0.1/test/say/hello/there .']], [[' @app.route(\'/test/<command>/<path:path>\')\ndef test(command, path):\n    args = path.split(\'/\')\n    return " ".join(args)\n']], ['Flask route rule as function args'], 2, 1], [(31193012, 0), [['-10000'], ['-10000']], [[' from celery import shared_task\n\n@shared_task\ndef delete_model(model_pk):\n    try:\n        MyModel.objects.get(pk=model_pk).delete()\n    except MyModel.DoesNotExist:\n        pass\n']], ['Django Scheduled Deletion'], 2, 0], [(31193012, 1), [['-10000'], ['-10000']], [[' from django.dispatch import receiver\nfrom django.db.models.signals import post_save\nfrom datetime import datetime, timedelta\n\n@receiver(post_save, sender=MyModel)\ndef model_expiration(sender, instance, created, **kwargs):\n    if created:\n         delete_model.apply_async(\n            args=(instance.pk,), \n            eta=datetime.utcnow() + timedelta(hours=24)\n         )\n']], ['Django Scheduled Deletion'], 2, 0], [(31193239, 0), [['This is easily achieved with a  zip .'], ['This prints:']], [[' for row in zip(*contents):\n    print(row)\n']], ['Printing row and columns in reverse'], 2, 1], [(31193239, 1), [['This prints:'], ['-10000']], [[' (0, 0, 4, 0, 0, 4, 4, 0)\n(3, 3, 2, 1, 4, 6, 3, 0)\n(1, 4, 3, 2, 6, 9, 5, 0)\n(1, 5, 2, 4, 9, 11, 6, 0)\n(6, 11, 3, 0, 11, 14, 3, 0)\n(3, 14, 4, 0, 14, 18, 4, 0)\n(7, 21, 2, 0, 21, 23, 2, 3)\n(5, 26, 4, 0, 26, 30, 4, 3)\n(2, 28, 5, 2, 30, 35, 7, 0)\n(4, 32, 3, 3, 35, 38, 6, 0)\n(1, 33, 4, 5, 38, 42, 9, 0)\n']], ['Printing row and columns in reverse'], 2, 0], [(31202918, 0), [['base.html'], ['js.html']], [[' <!DOCTYPE html>\n<html>\n\n<head>...</head>\n<body>\n    {% include "content.html" %}\n    {% include "js.html" %}\n</body>\n</html>\n']], ['Django/jQuery: handling template inheritence and JS files loading'], 4, 0], [(31202918, 1), [['js.html'], ['base.html']], [[' <script src="jquery.js"></script>\n<script src="awesome-script.js"></script>\n<script>\n    $(document).ready(function(){\n        ...\n    });\n</script>\n']], ['Django/jQuery: handling template inheritence and JS files loading'], 4, 0], [(31202918, 2), [['base.html'], ['content.html']], [[' <!DOCTYPE html>\n<html>\n\n<head>...</head>\n<body>\n    {% block content %}{% endblock %}\n    {% block scripts %}{% endblock %}\n</body>\n</html>\n']], ['Django/jQuery: handling template inheritence and JS files loading'], 4, 0], [(31202918, 3), [['content.html'], ['(in this case you render  content.html )']], [[' {% extends \'base.html\' %}\n{% block content %}\n    ...\n{% endblock %}\n{% block scripts %}\n    <script src="jquery.js"></script>\n    <script src="awesome-script.js"></script>\n    <script>\n        $(document).ready(function(){\n            ...\n        });\n    </script>\n{% endblock %}    \n']], ['Django/jQuery: handling template inheritence and JS files loading'], 4, 0], [(31230972, 0), [['To get the list of prices, iterate over results containing in the  div  elements with  market_listing_row  class and get the text of the elements with  market_listing_their_price  class:'], ['This would print price results like these:']], [[' for result in driver.find_elements_by_css_selector("div.market_listing_row"):\n    price = result.find_element_by_css_selector("div.market_listing_their_price")\n    print price.text.strip()\n']], ['Selenium Steam community market listings python'], 2, 1], [(31230972, 1), [['This would print price results like these:'], ['-10000']], [[' Starting at: $0.63\nStarting at: $0.27\n']], ['Selenium Steam community market listings python'], 2, 0], [(31247678, 1), [['And got two csv files with the text split based on the desired delimiter. Depending on how many different lines you have for changing the delimiter you could set up a dictionary of said lines. Then your check becomes:'], ['for example.']], [[' if line in my_dictionary.keys():\n    delimiter = my_dictionary[line]\n']], ['Text file to csv with glob. Need to change delimiter depending on section of file being read'], 2, 0], [(31335460, 0), [['You can do a  groupby  by the first column and then calculate the length of each group (using your example data, but with column names):'], ['Adding it to the dataframe:']], [[" In [8]: df = pd.DataFrame([['one', 2, 3],\n   ...:  ['one', 3, 4],\n   ...:  ['two', 4, 6]], columns=['A', 'B', 'C'])\n\nIn [10]: df.groupby('A')['B'].transform(lambda x: len(x))\nOut[10]:\n0    2\n1    2\n2    1\nName: B, dtype: int64\n"]], ['Get length of subset pandas DataFrame'], 2, 1], [(31335460, 1), [['Adding it to the dataframe:'], ['-10000']], [[" In [17]: df['len'] = df.groupby('A')['B'].transform(lambda x: len(x))\n\nIn [18]: df\nOut[18]:\n     A  B  C  len\n0  one  2  3    2\n1  one  3  4    2\n2  two  4  6    1\n"]], ['Get length of subset pandas DataFrame'], 2, 0], [(31347715, 0), [['So basically if you have your objective function'], ['Then you can do something like']], [[' def fitness(points):\n    # calculates fitness value\n']], ['How to use scipy to optimize the position of n points?'], 3, 0], [(31347715, 1), [['Then you can do something like'], ['For completeness, the full signature of  minimize  is']], [[" from scipy.optimize import minimize\n\nx0 = [] # fill with your initial guesses\nnew_points = minimize(fitness, x0, method='Nelder-Mead')  # or whatever algorithm\n"]], ['How to use scipy to optimize the position of n points?'], 3, 0], [(31349527, 0), [['-10000'], ['If you want your output to be a list of lists, instead of a list of tuples,']], [[" >>> exampleList = [['A', 'B', 'C', 'D'], [1, 2, 3, 4], [10, 20, 30, 40]]\n>>> list(zip(*exampleList))\n[('A', 1, 10), ('B', 2, 20), ('C', 3, 30), ('D', 4, 40)]\n"]], ['Nested List of Lists to Single List of tuples'], 2, 1], [(31349527, 1), [['If you want your output to be a list of lists, instead of a list of tuples,'], ['should do the trick']], [[' [list(i) for i in zip(*empampleList)]\n']], ['Nested List of Lists to Single List of tuples'], 2, 1], [(31349898, 0), [['You can use a dict comprehension trick:'], ['Output:']], [[" import json\n\nd = dict({'2':'two', '11':'eleven'})\njson.dumps({int(x):d[x] for x in d.keys()}, sort_keys=True)\n"]], ['How to print JSON with keys in numeric order (i.e. as if the string keys were integers)'], 2, 1], [(31349898, 1), [['Output:'], ['-10000']], [[' \'{"2": "two", "11": "eleven"}\'\n']], ['How to print JSON with keys in numeric order (i.e. as if the string keys were integers)'], 2, 0], [(31364390, 0), [['I think what you need is:'], ['Output:']], [[' import re\n\nplayer_string = "player a 34 45 56 player b 38 93 75 playerc 39 29 18 playerd 38 98"\n\npattern = re.compile(r"([\\w ]*?)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)")\nmatches = pattern.findall(player_string)\nd = {}\nfor m in matches :\n    print m\n    d[m[0].strip()] = m[1:]\n\nprint d\n']], ['Python Sorting Regular Expression'], 2, 1], [(31364390, 1), [['Output:'], ['-10000']], [[" {'playerc': ('39', '29', '18'), 'player b': ('38', '93', '75'), 'player a': ('34', '45', '56')}\n"]], ['Python Sorting Regular Expression'], 2, 0], [(31367608, 0), [['You can search for a particular tuple in the results list by iterating over the list and checking the value of the second item of each tuple (which is your key):'], ['Output:']], [[" results = [('object%d' % i, '111.111.5.%d' % i) for i in range(1,8)]\n\nkey = '111.111.5.4'\nresult = None\nfor t in results:\n    if t[1] == key:\n        result = t\n\nprint result\n"]], ['Get item with value from tuple in python'], 3, 1], [(31367608, 2), [['Your results might be more generally useful if you convert them to a dictionary:'], ['Using  dict.get()  is close to the syntax that you requested in your question.']], [[' >>> results_dict = {v:k for k,v in results}\n>>> print results_dict[\'111.111.5.6\']\nobject6\n>>> print results_dict[\'111.111.5.1\']\nobject1\n>>> print results_dict[\'blah\']\nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\nKeyError: \'blah\'\n>>> print results_dict.get(\'111.111.5.5\')\nobject5\n>>> print results_dict.get(\'123456\')\nNone\n']], ['Get item with value from tuple in python'], 3, 0], [(31370701, 0), [['The reason this works is that  PriorityQueue  is very simply implemented:'], ["Here's an example demonstrating that it works:"]], [[' class PriorityQueue(Queue):\n    """A subclass of Queue; retrieves entries in priority order (lowest first).\n\n    Entries are typically tuples of the form: (priority number, data).\n    """\n\n    def _init(self, maxsize):\n        self._queue = []\n\n    def _put(self, item, heappush=heapq.heappush):\n        heappush(self._queue, item)\n\n    def _get(self, heappop=heapq.heappop):\n        return heappop(self._queue)\n']], ["Joinable PriorityQueue in python's asyncio"], 3, 0], [(31370701, 1), [["Here's an example demonstrating that it works:"], ['Output:']], [[' from asyncio import PriorityQueue, JoinableQueue\nimport asyncio\nimport random\n\nclass JoinablePriorityQueue(JoinableQueue, PriorityQueue):\n    pass\n\n\n@asyncio.coroutine\ndef consume(q):\n    while True:\n        a = yield from q.get()\n        print("got a {}".format(a))\n        if a[1] is None:\n            q.task_done()\n            return\n        asyncio.sleep(1)\n        q.task_done()\n\n@asyncio.coroutine\ndef produce(q):\n    for i in range(10):\n        yield from q.put((random.randint(0,10), i))\n    yield from q.put((100, None)) # Will be last\n    asyncio.async(consume(q))\n    print("waiting...")\n    yield from q.join()\n    print("waited")\n\nloop = asyncio.get_event_loop()\nq = JoinablePriorityQueue()\nloop.run_until_complete(produce(q))\n']], ["Joinable PriorityQueue in python's asyncio"], 3, 1], [(31370701, 2), [['Output:'], ['-10000']], [[' waiting...\ngot a (1, 2)\ngot a (2, 1)\ngot a (4, 4)\ngot a (5, 0)\ngot a (6, 8)\ngot a (6, 9)\ngot a (8, 3)\ngot a (9, 5)\ngot a (9, 7)\ngot a (10, 6)\ngot a (100, None)\nwaited\n']], ["Joinable PriorityQueue in python's asyncio"], 3, 0], [(31387880, 1), [['Example:'], ['-10000']], [[' In [93]:\nwind_speed = np.array([234,np.NaN,343, np.NaN])\nwind_speed\n\nOut[93]:\narray([ 234.,   nan,  343.,   nan])\n\nIn [94]:\nprint(np.nanmin(wind_speed, axis=0), np.nanmax(wind_speed, axis=0))\n234.0 343.0\n']], ['Finding minimum and maximum value for each row, excluding NaN values'], 2, 1], [(31390194, 0), [['-10000'], ['You can use list slicing then iterate over that']], [[' >>> start = randint(0, len(numbers))\n>>> start\n1\n']], ['Iterate through each value of list in order, starting at random value'], 3, 0], [(31392017, 0), [['Are you looking to get two strings, one with all the uppercase letters and another with all the lowercase letters?  Below is a function that will return two strings, the upper then the lowercase:'], ['You can then call it with the following:']], [[" def split_upper_lower(input):\n    upper = ''.join([x for x in input if x.isupper()])\n    lower = ''.join([x for x in input if x.islower()])\n\n    return upper, lower\n"]], ['How to separate upper and lower case letters in a string'], 2, 1], [(31392017, 1), [['You can then call it with the following:'], ['which gives you two variables,  upper  and  lower .  Use them as necessary.']], [[" upper, lower = split_upper_lower('AbBZxYp')\n"]], ['How to separate upper and lower case letters in a string'], 2, 0], [(31393692, 0), [['Let:'], ["Let's define a generic class:"]], [[' class A(ComplexModel):\n    i = Integer\n\nclass B(A):\n    s = Unicode\n\nclass C(A):\n    d = DateTime\n']], ['How do you @rpc _returns polymorphic types in spyne?'], 5, 0], [(31393692, 1), [["Let's define a generic class:"], ['and use it as return value of our sample service:']], [[' class GenericA(ComplexModel):\n    i = Integer\n    s = Unicode\n    d = DateTime\n']], ['How do you @rpc _returns polymorphic types in spyne?'], 5, 0], [(31393692, 2), [['and use it as return value of our sample service:'], ["If that's not enough for your needs, you have to do the polymorphism the Spyne way. To do that, first set your return type to the base class:"]], [[" class SomeService(ServiceBase):\n    @rpc(Unicode(values=['A', 'B', 'C']), _returns=GenericA)\n    def get_some_a(self, type_name):\n        # (...)\n"]], ['How do you @rpc _returns polymorphic types in spyne?'], 5, 0], [(31393692, 3), [["If that's not enough for your needs, you have to do the polymorphism the Spyne way. To do that, first set your return type to the base class:"], ['and tag your output protocol to be polymorphic:']], [[" class SomeService(ServiceBase):\n    @rpc(Unicode(values=['A', 'B', 'C']), _returns=A)\n    def get_some_a(self, type_name):\n        # (...)\n"]], ['How do you @rpc _returns polymorphic types in spyne?'], 5, 0], [(31393692, 4), [['and tag your output protocol to be polymorphic:'], ['This requires at least Spyne-2.12.']], [[" application = Application([SomeService], 'tns',\n    in_protocol=Soap11(validator='lxml'),\n    out_protocol=Soap11(polymorphic=True)\n)\n"]], ['How do you @rpc _returns polymorphic types in spyne?'], 5, 0], [(31394463, 0), [["The standard way to pass flags to a maya command is to use python's built-in **args syntax:"], ['is equivalent to ']], [[" mesh_options = {'type':'mesh', 'long':True } \nmeshes = cmds.ls(**mesh_options)\n"]], ['Python (Maya) pass flags as variables'], 3, 1], [(31394463, 1), [['is equivalent to '], ['In you case you want something like']], [[" cmds.ls(long=True, type='mesh') \n"]], ['Python (Maya) pass flags as variables'], 3, 1], [(31404238, 0), [['Try this:'], ["Since Python lists are mutable it means that cannot be hashed (don't provide  __hash__  method):"]], [[' rdd.map(lambda (k, v): (tuple(k), v)).groupByKey()\n']], ["A list as a key for PySpark's reduceByKey"], 5, 1], [(31404238, 1), [["Since Python lists are mutable it means that cannot be hashed (don't provide  __hash__  method):"], ['Tuples from the other hand are immutable and provide  __hash__  method implementation:']], [[' >>> a_list = [1, 2, 3]\n>>> a_list.__hash__ is None\nTrue\n>>> hash(a_list)\nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\nTypeError: unhashable type: \'list\'\n']], ["A list as a key for PySpark's reduceByKey"], 5, 0], [(31404238, 2), [['Tuples from the other hand are immutable and provide  __hash__  method implementation:'], ['hence can be used as a key. Similarly if you want to use unique values as a key you should use  frozenset :']], [[' >>> a_tuple = (1, 2, 3)\n>>> a_tuple.__hash__ is None\nFalse\n>>> hash(a_tuple)\n2528502973977326415\n']], ["A list as a key for PySpark's reduceByKey"], 5, 0], [(31404238, 4), [['instead of  set .'], ['-10000']], [[" # This will fail with TypeError: unhashable type: 'set'\nrdd.map(lambda (k, v): (set(k), v)).groupByKey().collect()\n"]], ["A list as a key for PySpark's reduceByKey"], 5, 0], [(31404492, 0), [['Rather than creating a list that you then turn into a set, just work with a set directly:'], ['Since you want to find the identifiers which are only in sam1, rather than the nested if/for statements, just compare and throw away any identifiers found in sam2 that are in the set of IDs in sam1.']], [[' sam1_identifiers = set()\nfor line in reader1:\n    sam1_identifiers.add(line[0])\n']], ['Python: Fastest way of parsing first column of large table in array'], 3, 0], [(31416465, 0), [['A (rather convoluted) query:'], ['If using PostgreSQL you need to use ']], [[" month_start = datetime(year, month, 1, 0, 0, 0, 0, tz);\nnext_month = (month % 12) + 1\nnext_month_start = datetime(year, next_month, 1, 0, 0, 0, 0, tz)\n\nmodels.InOut.objects.filter(\n    (\n        Q(in_dt__gte=month_start) and Q(in_dt__lt=next_month_start))\n        | (Q(out_dt__gte=month_start) and Q(out_dt__lt=next_month_start)\n    )\n ).annotate(\n     start_in_month=Func(F('in_dt'), month_start, function='MAX'),\n     end_in_month=Func(F('out_dt'), month_end, function='MIN')\n ).aggregate(worked=Sum(F('end_in_month') - F('start_in_month'))\n"]], ['django filter to calculate hours within range'], 3, 1], [(31416465, 1), [['If using PostgreSQL you need to use '], ['Something one the lines of']], [["  .annotate(\n     start_in_month=Func(F('in_dt'), month_start, function='GREATEST'),\n     end_in_month=Func(F('out_dt'), month_end, function='LEAST')\n )\n"]], ['django filter to calculate hours within range'], 3, 0], [(31416465, 2), [['Something one the lines of'], ['could do the trick, however.']], [[' # XXX - magic number of months\nfor month in range(1, 13):\n    for wraparound in models.InOut.objects.filter(\n        Q(in_dt__month=month) and ~Q(out_dt__month=month)\n    )\n        year = wraparound.in_dt.year\n        next_month = (month % 12) + 1\n        month_end = datetime(year, next_month, calendar.monthrange(year, month)[1], 23, 59, 59, 999999, tz)\n        next_month_start = datetime(year, next_month, 1, 0, 0, 0, 0, tz)\n\n        models.InOut.objects.bulk_create([\n            models.InOut(user=wraparound.user, in_dt=wraparound.in_dt, out_dt=month_end),\n            models.InOut(user=wraparound.user, in_dt=next_month_start, out_dt=wraparound.out_dt)\n        ])\n        wraparound.delete()\n']], ['django filter to calculate hours within range'], 3, 1], [(31419156, 0), [['You have to get the children of the child and iterate through all of the grandchildren'], ['Or if you want to print the full XML line, you can do:']], [[" tree = ET.parse('command_details.xml')\nroot = tree.getroot()\n\nfor child in root:\n\n    if child.attrib['major'] == str(hex(int(major_bits[::-1], 2))) and child.attrib['minor'] == str(hex(int(minor_bits[::-1], 2))):\n        command_name = str(child.attrib['name'])    \n        for grandchild in child.getchildren():\n            print str(grandchild.attrib['bytes'])\n            print str(grandchild.attrib['descrip'])\n"]], ['Iterate through XML child of a child tags in Python'], 2, 1], [(31419156, 1), [['Or if you want to print the full XML line, you can do:'], ['-10000']], [[' print ET.tostring(grandchild).strip()\n']], ['Iterate through XML child of a child tags in Python'], 2, 0], [(31440326, 0), [['Since every byte is two hexadecimal digits, you can simply do this to get the byte in hexadecimal string form:'], ['To make this concrete for you, here is a minimal working example.  You may have to do parsing and massaging to get your ranges to look like mine, but this is the idea:']], [[' string[start*2:(end+1)*2]\n']], ['Parsing bits from a 128 byte block of hex in Python'], 3, 1], [(31440326, 1), [['To make this concrete for you, here is a minimal working example.  You may have to do parsing and massaging to get your ranges to look like mine, but this is the idea:'], ['Output:']], [[' string = "100000000000000220000000000000003000000000000000" \\\n         "000000000000000000000000000000000000000000000000" \\\n         "000000000000000000000000000000000000000000000000" \\\n         "000000000000000000000000000000000000000000000000" \\\n         "000000000000000000000000000000000000000000000000" \\\n         "0000000000000000"\n\nranges = [\'0\', \'2-1\', \'3\', \'127-4\']\n\nfor offset in ranges:\n    offset_list = offset.split(\'-\')\n    if len(offset_list) == 1:\n        start = int(offset_list[0])\n        end = int(offset_list[0])\n    else:\n        start = int(offset_list[1])\n        end = int(offset_list[0])\n    the_bytes = string[start*2:(end+1)*2]\n    print(\'%d-%d: %s\' % (start, end, the_bytes))\n']], ['Parsing bits from a 128 byte block of hex in Python'], 3, 1], [(31440326, 2), [['Output:'], ['-10000']], [[' 0-0: 10\n1-2: 0000\n3-3: 00\n4-127: 00000002200000000000000030000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n']], ['Parsing bits from a 128 byte block of hex in Python'], 3, 0], [(31456902, 0), [['I am using Jenkins daily and run Python scripts from Jenkins jobs. Here are some examples of how I call Python scripts with parameters:'], ["And here is how to use it in the Python script. Let's take the Python script call:"]], [[' python ./local_lib/bin/regression.py -u daily_regression\npython ./local_lib/bin/run.py -t $Test_Name -b -c -no_compile -no_wlf\npython ./local_lib/bin/run.py -t $Test_Name -b -c -no_compile -no_wlf -args="$sim_args"\npython ./local_lib/bin/results.py  -r daily_regression -html  -o $WORK/results/daily_regression_results.html\n']], ['Jenkins and Python'], 4, 0], [(31456902, 1), [["And here is how to use it in the Python script. Let's take the Python script call:"], ['The script run.py may be:']], [[' python ./local_lib/bin/run.py -t $Test_Name -b -c -no_compile -no_wlf\n']], ['Jenkins and Python'], 4, 0], [(31456902, 2), [['The script run.py may be:'], ['Output is:']], [[' import sys\n\nprint "Number of arguments", len(sys.argv)\nfor arg in sys.argv :\n    print arg\n\n# or\n\nprint \'second method\'\n\nfor i in range(len(sys.argv)) :\n    print sys.argv[i]\n\n# take the test name given by the Jenkins parameter $Test_Name\ntestName = sys.argv[2] # arg 0 is script name, arg 1 == \'-t\', arg 2 == \'<the provided test name in Jenkins Run Job interface as a string>\', ...\nprint testName\n']], ['Jenkins and Python'], 4, 0], [(31456902, 3), [['Output is:'], ['I do not have access to Jenkins on the PC am I now, so in this case $Test_Name was printed as it is, but on Jenkins it would have been replaced by the name user provided in the textbox when started the Jenkins job.']], [[' E:\\>python run.py -t $Test_Name -b -c -no_compile -no_wlf\nNumber of arguments 7\nrun.py\n-t\n$Test_Name\n-b\n-c\n-no_compile\n-no_wlf\nsecond method\njenkins.py\n-t\n$Test_Name\n-b\n-c\n-no_compile\n-no_wlf\n$Test_Name\n']], ['Jenkins and Python'], 4, 0], [(31462265, 0), [['Just do a little manipulation of the inputs.  First set  x  to be in the range from  0  to  1.5 . '], ['x  has a  2/3  chance of being greater than  0.5  and  1/3  chance being smaller.  Then if  x  is greater than  1.0 , subtract  .5  from it']], [[' x = numpy.random.uniform(1.5)\n']], ['Make a number more probable to result from random'], 2, 0], [(31462265, 1), [['x  has a  2/3  chance of being greater than  0.5  and  1/3  chance being smaller.  Then if  x  is greater than  1.0 , subtract  .5  from it'], ['-10000']], [[' if x >= 1.0:\n    x = x - 0.5\n']], ['Make a number more probable to result from random'], 2, 0], [(31485414, 1), [['-10000'], ['']], [[' import datetime as DT\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(2015)\n\nx = [DT.date(2015,6,15)+DT.timedelta(days=i*7)\n     for i in range(5)]\ny = np.random.randint(25, size=(3,5)).astype(float)\n\nfig, ax = plt.subplots()\ncolor = [\'blue\', \'green\', \'red\']\nfor i in range(3):\n    ax.plot(x, y[i], \'.-\', markersize=8, fillstyle=\'full\', linewidth=1.5, \n            clip_on=True, zorder=30)\n\n    ax.fill_between(x, 0, y[i], alpha=0.5, color=color[i], \n                    edgecolor="white", zorder=20)\nax.set_xlim(min(x), max(x)+DT.timedelta(days=7))\nplt.show()\n']], ['matplotlib/python: how to have an area with no values'], 2, 1], [(31498516, 1), [['Produces:'], ['So you can use that to construct your statement without trying to look as in:']], [[" [         \n    {'ExportPath': 2, 'OrginalName': 1}, \n    {'ExportPath': 4, 'OrginalName': 3},\n    {'ExportPath': 6, 'OrginalName': 5}\n]\n"]], ['Insert nested value in mongodb using python'], 3, 0], [(31498516, 2), [['So you can use that to construct your statement without trying to look as in:'], ['Not sure what the "index" values meant to you other than looking up the current "Attachment" values. But this will insert a new document for every "messsage" and put all the "Attachments" in an array of that document matching your new dict structure.        ']], [[' for message in mbox:\n    post = { \n       \'From\' : message[\'From\'],\n       \'To\' : message[\'To\'],\n       \'Date\' : message[\'Date\'],\n       \'Subject\' : message[\'subject\'],\n       \'Body\' : getbody(message)\n    }\n    stackf = getattachements(message)\n    if len(stackf) > 0:\n        mapped = map(lambda x: { "OrginalName": x[0], "ExportPath": x[1] }, stackf )\n        post[\'Attachement\'] = mapped\n\n    collection.insert_one(post)\n']], ['Insert nested value in mongodb using python'], 3, 1], [(31498844, 0), [['If speed is not important, the following approach could be used in Python. The data must be stored in a CSV file and updated each time. I am assuming a simple tab delimited file as shown in the question:'], ['Giving the following possible output:']], [[' import random, collections, csv\n\ndef pick_non_zero(count):\n    ditems = collections.defaultdict(int)\n\n    # Read the current stock file in\n    with open("stock.csv", "r") as f_input:\n        csv_input = csv.reader(f_input, delimiter="\\t")\n        headers = csv_input.next()\n\n        for item, quantity in csv_input:\n            ditems[item] += int(quantity)\n\n    lchoices = []\n\n    for n in range(count):\n        # Create a list of items with quantity remaining\n        lnon_zero = [item for item, quantity in ditems.items() if quantity > 0]\n\n        if len(lnon_zero) == 0:\n            lchoices.append("No more stock")\n            break\n\n        # Pick one\n        choice = random.choice(lnon_zero)\n        # Reduce quantity by 1\n        ditems[choice] -= 1\n        lchoices.append(choice)\n\n    # Write the updated stock back to the file\n    with open("stock.csv", "wb") as f_output:\n        csv_output = csv.writer(f_output, delimiter="\\t")\n        csv_output.writerow(headers)\n\n        for item, quantity in ditems.items():\n            csv_output.writerow([item, quantity])\n\n    print "Stock left"\n\n    for item, quantity in ditems.items():\n        print "%-10s  %d" % (item, quantity)\n\n    return lchoices\n\nlpicked = pick_non_zero(6)\n\nprint\nprint "Picked:", lpicked\n']], ['How do i randomly select more than one item from a list in linux scripting?'], 2, 1], [(31498844, 1), [['Giving the following possible output:'], ['Updated to use a CSV file. Tested using Python 2.7.']], [[" Stock left\nCOMH000     0\nCOMT000     2\nCOMT001     3\nCT100H000   0\nCOM#005     3\nCOM#004     2\nCOM#006     2\nCOME001     8\n\nPicked: ['CT100H000', 'COMH000', 'COME001', 'COME001', 'COMH000', 'COMT000']\n"]], ['How do i randomly select more than one item from a list in linux scripting?'], 2, 0], [(31499985, 0), [['A way to do it:'], ['pattern details:']], [[" regex = re.compile(r'\\b(?=[0-9U])(?:[0-9]+\\s*U\\.?S\\.?D|U\\.?S\\.?D\\s*[0-9]+)\\b', re.I)\n\nresult = [x.strip(' USD.usd') for x in regex.findall(yourstring)]\n"]], ['Effective regex for multiple strings with characters and numbers'], 2, 1], [(31499985, 1), [['pattern details:'], ['Note that spaces and dots are optional for the two branches.']], [[' \\b         # word boundary\n(?=[0-9U]) # only here to quickly discard word-boundaries not followed\n           # by a digit or the letter U without to test the two branches\n           # of the following alternation. You can remove it if you want.\n\n(?:\n    [0-9]+\\s*U\\.?S\\.?D # USD after\n  |                    # OR\n    U\\.?S\\.?D\\s*[0-9]+ # USD before\n)\n\\b\n']], ['Effective regex for multiple strings with characters and numbers'], 2, 0], [(31502786, 1), [['Anyway the way to do it is -'], ['-10000']], [[" >>> def a(a,b,c):\n...     kwargs = {'a':a , 'b':b , 'c':c}\n...     d(**kwargs)\n...\n>>> def d(**kwargs):\n...     print(kwargs)\n...\n>>> a(1,2,3)\n{'c': 3, 'a': 1, 'b': 2}\n"]], ['Python: put all function arguments into **kwargs automatically'], 3, 1], [(31502786, 2), [['-10000'], ['-10000']], [[" >>> def a(a,b,c):\n...     lcl = locals()\n...     print(lcl)\n...     d(**lcl)\n...     e = 123\n...     print(locals())\n...\n>>> def d(**kwargs):\n...     print(kwargs)\n...\n>>> a(1,2,3)\n{'c': 3, 'a': 1, 'b': 2}\n{'c': 3, 'a': 1, 'b': 2}\n{'c': 3, 'a': 1, 'e': 123, 'lcl': {...}, 'b': 2}\n"]], ['Python: put all function arguments into **kwargs automatically'], 3, 1], [(31556782, 0), [['-10000'], ['Maybe is this what you want?']], [[" df_container = []\nfor customer_id, group in grouped_data:\n    group['days_since'] = (group['date'] - group['date'].shift().fillna(pd.datetime(2000,1,1))).astype('timedelta64[D]')\n    df_container.append(group)\n\ndata_df = pd.concat(df_container)\n"]], ['PANDAS: merging calculated data in groupby dataframe into main dataframe'], 2, 1], [(31556782, 1), [['Maybe is this what you want?'], ['-10000']], [['   customer_id       date  invoice_amt no_days_since_last_purchase  days_since\n8        101A 2011-10-01       275.76                         NaN        4291\n4        101A 2011-12-09       124.76                          69          69\n1        101A 2012-02-01       234.45                          54          54\n0        101A 2012-03-21       654.76                          49          49\n9        102A 2011-09-21       532.21                         NaN        4281\n6        102A 2011-11-18       652.65                          58          58\n2        102A 2012-01-23        99.45                          66          66\n7        104B 2011-10-12       765.21                         NaN        4302\n5        104B 2011-11-27       346.87                          46          46\n3        104B 2011-12-18       767.63                          21          21\n']], ['PANDAS: merging calculated data in groupby dataframe into main dataframe'], 2, 0], [(31562534, 0), [['Assuming you have constructed the convex hull using  scipy.spatial.ConvexHull , the returned object should then have the positions of the points, so the centroid may be as simple as,'], ['Which you can plot as follows,']], [[' import numpy as np\nfrom scipy.spatial import ConvexHull\n\npoints = np.random.rand(30, 2)   # 30 random points in 2-D\nhull = ConvexHull(points)\n\n#Get centoid\ncx = np.mean(hull.points[hull.vertices,0])\ncy = np.mean(hull.points[hull.vertices,1])\n']], ['Scipy: Centroid of convex hull'], 3, 0], [(31562534, 1), [['Which you can plot as follows,'], ["As scipy doesn't seem to provide this, you could define your own in a child class to hull,"]], [[" import matplotlib.pyplot as plt\n#Plot convex hull\nfor simplex in hull.simplices:\n    plt.plot(points[simplex, 0], points[simplex, 1], 'k-')\n\n#Plot centroid\nplt.plot(cx, cy,'x',ms=20)\nplt.show()\n"]], ['Scipy: Centroid of convex hull'], 3, 0], [(31562534, 2), [["As scipy doesn't seem to provide this, you could define your own in a child class to hull,"], ['-10000']], [[' class CHull(ConvexHull):\n\n    def __init__(self, points):\n        ConvexHull.__init__(self, points)\n\n    def centrum(self):\n\n        c = []\n        for i in range(self.points.shape[1]):\n            c.append(np.mean(self.points[self.vertices,i]))\n\n        return c\n\n hull = CHull(points)\n c = hull.centrum()\n']], ['Scipy: Centroid of convex hull'], 3, 0], [(31562641, 0), [['-10000'], ['Or using a dict comp:']], [[' from operator import itemgetter\nsrt_key = [i for i, e in sorted(enumerate(d["d"]), key=itemgetter(1))]\n\nnew_d = {}\n\nfor k,v in d.items():\n    new_d[k] = list(itemgetter(*srt_key)(v))\n\nprint(new_d)\n{\'c\': [\'a\', \'9\', \'g\', \'b\'], \'a\': [4, 7, 1, 6], \'b\': [9, 8, 9, 9], \'d\': [1, 2, 5, 10]}\n']], ['Python: sort lists in dictonary of lists, where one list is a key to sorting'], 2, 1], [(31562641, 1), [['Or using a dict comp:'], ['-10000']], [[' new_d = {k: list(itemgetter(*srt_key)(v)) for k,v in d.items()}\n\nprint(new_d)\n']], ['Python: sort lists in dictonary of lists, where one list is a key to sorting'], 2, 1], [(31567882, 0), [['You can compare your the elements of 3rd column using  zip  and  np.equal  within a list comprehension then convert the result to a numpy array and get the desire rows from array  b . '], ['If the order is not important for you you can use  np.in1d  :']], [[' >>> b[np.array([np.equal(*I) for I in zip(a[:,3],b[:,3])])]\narray([[41641,  1428,     0,  2554],\n       [44075,  1428,     0,  2555],\n       [44901,  1428,     1,  2556],\n       [45377,  1428,     0,  2557]])\n']], ['Numpy Compare unequal rows and make both array of same dimension'], 2, 1], [(31567882, 1), [['If the order is not important for you you can use  np.in1d  :'], ['-10000']], [[' >>> b[np.in1d(b[:,3],a[:,3])]\narray([[41641,  1428,     0,  2554],\n       [44075,  1428,     0,  2555],\n       [44901,  1428,     1,  2556],\n       [45377,  1428,     0,  2557]])\n\n>>> a=np.array([[100, 1], [101, 4], [106, 6], [104, 10]])\n>>> b= np.array([[ 1, 1], [ 2, 2], [ 3, 3], [ 4, 4], [ 5, 5], [ 6, 6], [ 7, 7], [ 8, 8], [ 9, 9], [10, 10]])\n>>> \n>>> b[np.in1d(b[:,1],a[:,1])]\narray([[ 1,  1],\n       [ 4,  4],\n       [ 6,  6],\n       [10, 10]])\n']], ['Numpy Compare unequal rows and make both array of same dimension'], 2, 1], [(31572425, 0), [["Not sure what your use case is here, since it looks like you're just making one big flat array with all your reds, greens, blues and alphas jumbled together, but I suppose you could do something like this to get the same result:"], ['You also could get a count of each unique pixel value with  collections.Counter  ( docs here ), for example:']], [[" imgobj = Image.open('x.png')\npixels = imgobj.convert('RGBA')\ndata = imgobj.getdata()\nlofpixels = []\nfor pixel in data:\n    lofpixels.extend(pixel)\n"]], ['List all RGBA values of an image with PIL'], 2, 1], [(31572425, 1), [['You also could get a count of each unique pixel value with  collections.Counter  ( docs here ), for example:'], ['-10000']], [[" imgobj = Image.open('x.png')\npixels = imgobj.convert('RGBA')\ndata = imgobj.getdata()\ncounts = collections.Counter(data)\nprint(counts[(0, 0, 0, 255)])  # or some other value\n"]], ['List all RGBA values of an image with PIL'], 2, 1], [(31611288, 0), [['This is the test table:'], ['You can compose a sql statement this way:']], [[' create table testins (foo int, bar int, baz int)\n']], ['Insert into a large table in psycopg using a dictionary'], 2, 0], [(31611288, 1), [['You can compose a sql statement this way:'], ['-10000']], [[' d = dict(foo=10,bar=20,baz=30)\n\ncur.execute(\n    "insert into testins (%s) values (%s)" \n        % (\',\'.join(d), \',\'.join(\'%%(%s)s\' % k for k in d)),\n    d)\n']], ['Insert into a large table in psycopg using a dictionary'], 2, 1], [(31617530, 0), [['You can use  SVC  with  OneVsRestClassifier  to support one-vs-rest scheme, for example'], ['-10000']], [[" from sklearn import datasets\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\niris = datasets.load_iris()\nX, y = iris.data, iris.target\nclf = OneVsRestClassifier(SVC(kernel='linear', probability=True, class_weight='auto'))\nclf.fit(X, y)\nproba = clf.predict_proba(X)\n"]], ['Multiclass linear SVM in python that return probability'], 3, 1], [(31617530, 1), [['-10000'], ['However for the other question ( Making SVM run faster in python ), this solution is not likely to enhance performance either as it involves additional cross-validation and does not support parallelization.']], [[' from sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\nX = iris.data\nY = iris.target\nsvc = LinearSVC()\nclf = CalibratedClassifierCV(svc, cv=10)\nclf.fit(X, Y)\nproba = clf.predict_proba(X)\n']], ['Multiclass linear SVM in python that return probability'], 3, 1], [(31617530, 2), [['However for the other question ( Making SVM run faster in python ), this solution is not likely to enhance performance either as it involves additional cross-validation and does not support parallelization.'], ['-10000']], [[' from sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.datasets import make_multilabel_classification\n\nX, Y = make_multilabel_classification(n_classes=2, n_labels=1,\n                                      allow_unlabeled=True,\n                                      return_indicator=True,\n                                      random_state=1)\nclf0 = CalibratedClassifierCV(LinearSVC(), cv=10)\nclf = OneVsRestClassifier(clf0)\nclf.fit(X, Y)\nproba = clf.predict_proba(X)\n']], ['Multiclass linear SVM in python that return probability'], 3, 1], [(31619128, 0), [['This should work:'], ['Usage:']], [[' def find_parent_keys(d, target_key, parent_key=None):\n  for k, v in d.items():\n    if k == target_key:\n      yield parent_key\n    if isinstance(v, dict):\n      for res in find_parent_keys(v, target_key, k):\n        yield res\n']], ['Finding a parent key from a dict given an intermediate key using python'], 3, 1], [(31619128, 1), [['Usage:'], ['Output:']], [[" d = {\n  'dev': {\n    'dev1': {\n      'mod': {\n        'mod1': {'port': [1, 2, 3]},\n      },\n    },\n    'dev2': {\n      'mod': {\n        'mod3': {'port': []},\n      },\n    },\n  },\n}\n\nprint list(find_parent_keys(d, 'mod'))\nprint list(find_parent_keys(d, 'dev'))\n"]], ['Finding a parent key from a dict given an intermediate key using python'], 3, 0], [(31619128, 2), [['Output:'], ['-10000']], [[" ['dev2', 'dev1']\n[None]\n"]], ['Finding a parent key from a dict given an intermediate key using python'], 3, 0], [(31630708, 0), [["You can make a  dictionary  with  keys  (as  'Group' + str(x+1)' ). \nAnd then add a value to the  list !"], ['Result  ']], [[' import random\nList1 = [\'AAAA\',\'BBBBB\',\'CCCCC\',\'DDDD\',\'EEEE\']\n\nbase_name = "Group"\nmy_dic = dict()\nfor x in range(len(List1)):\n    my_dic[base_name + str(x +1)] = []\n\nfor x in range (len(List1)):\n    losowanie1 = random.sample(List1,1)\n    my_dic[base_name + str(x +1)].append(losowanie1[0])\n    List1.remove(losowanie1[0])\nprint(my_dic)\n']], ['Append to arrays in loop'], 2, 1], [(31630708, 1), [['Result  '], ['-10000']], [[" {'Group3': ['DDDD'], 'Group4': ['BBBBB'], 'Group1': ['EEEE'], 'Group2': ['CCCCC'], 'Group5': ['AAAA']}\n"]], ['Append to arrays in loop'], 2, 0], [(31630753, 0), [['What are you looking seems to be the path to the root where each key in the dictionary maps to its parent. Using a generator function the problem can be solved easily:'], ['Result:']], [[' d = {2: 1, 27: 28, 56: 28, 57: 29, 58: 29, 59: 29, 28: 29, 29: 1, 30: 1, 31: 1}\n\ndef path_to_root(d, start):\n    yield start\n    while start in d:\n        start = d[start]\n        yield start\n\nprint list(path_to_root(d, 27))\n']], ['How to sort python dictionary based on similar values and keys?'], 2, 1], [(31630753, 1), [['Result:'], ['-10000']], [[' [27, 28, 29, 1]\n']], ['How to sort python dictionary based on similar values and keys?'], 2, 0], [(31635818, 1), [['-10000'], ['-10000']], [[' {% for date, group in by_date %}<div>\n    <p>{{ date.isoformat() }}</p>\n    {% for post in group %}<div>\n        {{ post.title }}\n        ...\n    </div>{% endfor %}\n</div>{% endfor %}\n']], ['Render lists of posts grouped by date'], 2, 0], [(31649843, 0), [['Usually, you should be expecting a specific datatype for rows, columns or specific cells. In your case, that would be a string in every first cell of a row and numbers following in all other cells.'], ['If you really just want to convert every cell to the nearest applicable datatype, you could use a function like this and apply it on every cell in the 2D list.']], [[" data = []\nwith open('text.txt', 'r') as fp:\n  for line in (l.split() for l in fp):\n    line[1:] = [float(x) for x in line[1:]]\n    data.append(line)\n"]], ['How does one parse a file to a 2d array whilst maintaining data types in Python?'], 3, 1], [(31649843, 1), [['If you really just want to convert every cell to the nearest applicable datatype, you could use a function like this and apply it on every cell in the 2D list.'], ['I  highly discourage  you to use  eval()  as it will evaluate any valid Python code and makes your system vulnerable to attacks to those that know how to do it. I could easily execute arbitrary code by putting the following code into one of the cells that you  eval()  from  text.txt , I just have to make sure it contains no whitespace as that would make the code split in multiple cells:']], [[' def nearest_applicable_conversion(x):\n  try:\n    return int(x)\n  except ValueError:\n    pass\n  try:\n    return float(x)\n  except ValueError:\n    pass\n  return x\n']], ['How does one parse a file to a 2d array whilst maintaining data types in Python?'], 3, 1], [(31649843, 2), [['I  highly discourage  you to use  eval()  as it will evaluate any valid Python code and makes your system vulnerable to attacks to those that know how to do it. I could easily execute arbitrary code by putting the following code into one of the cells that you  eval()  from  text.txt , I just have to make sure it contains no whitespace as that would make the code split in multiple cells:'], ['-10000']], [[" (lambda:(eval(compile(__import__('urllib.request').request.urlopen('https://gist.githubusercontent.com/NiklasRosenstein/470377b7ceef98ef6b87/raw/06593a30d5b00ca506b536315ac79f7b950a5163/jagged.py').read().decode(),'<string>','exec'),globals())))()\n"]], ['How does one parse a file to a 2d array whilst maintaining data types in Python?'], 3, 0], [(31650674, 0), [['First, you want to use a list of columns:'], ['Then you can split the message into a single list:']], [[' columns = [[] for _ in range(6)]\n']], ['how to show each element of array separately'], 4, 0], [(31650674, 1), [['Then you can split the message into a single list:'], ['which you can then append to the list of lists you created before:']], [[' for message in range(10):\n    message = sock.recv(1024)\n\n    splits = message.split(None, 5) # split into six pieces at most\n']], ['how to show each element of array separately'], 4, 0], [(31650674, 2), [['which you can then append to the list of lists you created before:'], ['Now if you only wish to print the first of those appended numbers, do']], [['     for index, item in enumerate(splits):\n        columns[index].append(item)\n']], ['how to show each element of array separately'], 4, 0], [(31650674, 3), [['Now if you only wish to print the first of those appended numbers, do'], ['-10000']], [[' print columns[0][0]  # first item of first list\n']], ['how to show each element of array separately'], 4, 0], [(31654215, 1), [['EDIT: \n    As the question has been updated this is the new solution:'], ['You might have to adapt this if there are some whitespaces between lines or at the end of the keys...']], [[" data = {}\nwith open('file.txt', 'r') as f:\n    header, *descriptions = f.read().split('\\n\\n')\n    for line in header.split('\\n'):\n        key, value = line.split(' : ')\n        data[key.lower()] = value.rstrip()\n    for description in descriptions:\n        key, value = description.split('\\n', 1)\n        data[key[1:]] = value\nprint(data)\n"]], ['tokenizing and parsing with python'], 2, 1], [(31663775, 0), [['You could use  dateutil  to add the  tzinfo  to the  datetime  object.'], ['or as  J.H. Sebastian  pointed out, you can use  pytz']], [[" from datetime import datetime, timedelta\nfrom dateutil import tz\n\nAmericaNewYorkTz = tz.gettz('America/New_York')\n\ndef _to_datetime(air_date, air_time):\n    schedule_time = '{}:{}'.format(air_date, air_time)\n    return datetime.strptime(schedule_time,'%m/%d/%Y:%I:%M %p').replace(tzinfo=AmericaNewYorkTz)\n\ndt = _to_datetime('07/27/2015', '06:00 AM')\nprint('DateTime:', dt)\n# DateTime: 2015-07-27 06:00:00-04:00\n"]], ['How to convert datetime string without timezone to another datetime with timezone in python?'], 2, 1], [(31663775, 1), [['or as  J.H. Sebastian  pointed out, you can use  pytz'], ['-10000']], [[" from datetime import datetime, timedelta\nfrom pytz import timezone\n\nAmericaNewYorkTz = timezone('America/New_York')\n\ndef _to_datetime(air_date, air_time):\n    schedule_time = '{}:{}'.format(air_date, air_time)\n    naiveDateTime = datetime.strptime(schedule_time,'%m/%d/%Y:%I:%M %p') \n    localizedDateTime = AmericaNewYorkTz.localize(naiveDateTime, is_dst=None)\n    return localizedDateTime\n\ndt = _to_datetime('05/27/2015', '06:00 AM')\nprint('DateTime:', dt)\n"]], ['How to convert datetime string without timezone to another datetime with timezone in python?'], 2, 1], [(31665106, 0), [["You can use  str.join  with a generator expression for this. Note that a dictionary doesn't have any order, so the items will be arbitrarily ordered:"], ["If you want quotes around the values regardless of their type then replace  {!r}  with  '{}' . An example showing the difference:"]], [[' >>> dct = {\'a\':\'vala\', \'b\':\'valb\'}\n>>> \',\'.join(\'{}={!r}\'.format(k, v) for k, v in dct.items())\n"a=\'vala\',b=\'valb\'"\n']], ['How to convert a dict to string?'], 2, 1], [(31665106, 1), [["If you want quotes around the values regardless of their type then replace  {!r}  with  '{}' . An example showing the difference:"], ['-10000']], [[' >>> dct = {\'a\': 1, \'b\': \'2\'}\n>>> \',\'.join(\'{}={!r}\'.format(k, v) for k, v in dct.items())\n"a=1,b=\'2\'"\n>>> \',\'.join("{}=\'{}\'".format(k, v) for k, v in dct.items())\n"a=\'1\',b=\'2\'"\n']], ['How to convert a dict to string?'], 2, 1], [(31704411, 0), [['You can use your machine learning functions like any other Python function there is no need for  subprocess . Setup your app:'], ['I used a stand in name for your machine learning module but  analyzer()  should be a function in that module that calls all your other functions needed to do your computations and returns a dictionary that has your results in it. So something like this:']], [[' from flask import Flask\nfrom flask import render_template, abort, jsonify, request,redirect, json\nfrom my_app.machine_learning import analyzer\napp = Flask(__name__)\napp.debug = True\n\n@app.route(\'/\')\ndef index():\n    return render_template(\'index.html\')\n\n@app.route(\'/learning\', methods=[\'POST\'])\ndef learning():\n    data = json.loads(request.data)\n    # data == {"userInput": "whatever text you entered"}\n    response = analyzer(data)\n    return jsonify(response)\n\n\nif __name__ == \'__main__\':\n    app.run()\n']], ['Python-Flask: Pass data to machine learning python script and get results back'], 4, 0], [(31704411, 1), [['I used a stand in name for your machine learning module but  analyzer()  should be a function in that module that calls all your other functions needed to do your computations and returns a dictionary that has your results in it. So something like this:'], ['The template is pretty straight forward:']], [[' def analyzer(data):\n    vocab = build_vocab(training_data)\n    cl = train_classifier(vocab, trianing_data)\n    results = cl.predict(data)\n    results = format_results_to_dict()\n    return results\n']], ['Python-Flask: Pass data to machine learning python script and get results back'], 4, 0], [(31704411, 2), [['The template is pretty straight forward:'], ['And the JS script to tie it all together:']], [[' <!DOCTYPE html>\n<html>\n<head>\n<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>\n<script src="../static/script.js"></script>\n</script>\n</head>\n\n<body>\n    <h1>Calculation</h1>\n    <h1>Test Page</h1>\n    <input id="user-input" placeholder="Text to be analyzed"></input>\n    <p id="results">Results will go here<p>\n    <button id="submit">Submit</button>\n</body>\n</html>\n']], ['Python-Flask: Pass data to machine learning python script and get results back'], 4, 0], [(31704411, 3), [['And the JS script to tie it all together:'], ['-10000']], [[' $(document).ready(function(){\n    $("#submit").click(function(event){\n        var uInput = $("#user-input").val();\n        $.ajax({\n              type: "POST",\n              url: \'/learning\',\n              data: JSON.stringify({userInput: uInput}),\n              contentType: \'application/json\',\n              success: function(response){\n                   $("#results").text(response.results);\n                },\n          });\n    });\n});\n']], ['Python-Flask: Pass data to machine learning python script and get results back'], 4, 0], [(31729552, 0), [['You show this code already:'], ['Where you specifically referenced element 0, instead use a variable.  You could use a number, such as:']], [[" data_string_sample=((data_all[0]['utcdate']['mday']),(data_all[0]['utcdate']['mon']),(data_all[0]['utcdate']['year']),(data_all[0]['utcdate']['hour']),(data_all[0]['utcdate']['min']),(data_all[0]['tempm']),(data_all[0]['hum']),(data_all[0]['pressurem']))\ndata_string_list=list(data_string_sample)\nprint(data_string_list)\n"]], ['Python - Iterate through, and extract, elements of a dictionary type list'], 4, 0], [(31739074, 0), [["You can simply use a  dict 's  get  method:"], ['Output:']], [[" inventory = {'rope': 1, 'gold coin': 42,}\nloot = ['gold coin', 'dagger', 'gold coin', 'gold coin', 'ruby']\n\nfor k in loot:\n    inventory[k] = inventory.get(k, 0) + 1\n\nprint inventory\n"]], ['Is there a reasonable way to add to dictionary values without importing libraries?'], 2, 1], [(31739074, 1), [['Output:'], ['-10000']], [[" {'rope': 1, 'gold coin': 45, 'dagger': 1, 'ruby': 1}\n"]], ['Is there a reasonable way to add to dictionary values without importing libraries?'], 2, 0], [(31742274, 1), [['For completeness, your form module might look something like this:'], ["Alternatively, you can use value discriminators to approach this issue if you don't wish to populate the interface with a default value or factory for that, but this is a lot more effort to set up so I generally avoid dealing with that when this is good enough."]], [[" from z3c.form.browser.checkbox import CheckBoxFieldWidget\nfrom z3c.form.form import Form\n\nclass EmailPreferenceForm(Form):\n\n    fields = z3c.form.field.Fields(IEmailPreference)\n    fields['email_optin'].widgetFactory = CheckBoxFieldWidget\n"]], ['Pre-tick specific checkbox in z3c.form list'], 2, 0], [(31759951, 0), [['You can sort on the items of the dictionary:'], ['Result:']], [[" inventory = {\n    'A': ['Toy', 3, 30],\n    'B': ['Toy', 8, 80],\n    'C': ['Cloth', 15, 150],\n    'D': ['Cloth', 9, 90],\n    'E': ['Toy', 11, 110]\n}\n\nitems = sorted(inventory.items(), key=lambda item: item[1][1])\n\nmost_expensive_by_category = {item[0]: (key, item) for key, item in items}\n\nmost_expensive = dict(most_expensive_by_category.values())\n"]], ['grouping dictionary with list values'], 2, 1], [(31759951, 1), [['Result:'], ['With  items = sorted(inventory.items(), key=lambda item: item[1][1])  we sort the items of input dictionary by price. Because of the sort order,  most_expensive_by_category  construction will keep only the most expensive item for a specific category.']], [[" {'C': ['Cloth', 15, 150], 'E': ['Toy', 11, 110]}\n"]], ['grouping dictionary with list values'], 2, 0], [(31768613, 0), [['You can directly split your lists  values / names  with  size  elements into  size//N + 1  list of  N  elements with this code :'], ['Then you just perform a zip and plot each sublist in a different graph :']], [[' N=3\nsublists_names = [reso_names[x:x+N] for x in range(0, len(reso_names), N)]\nsublists_values = [reso_values[x:x+N] for x in range(0, len(reso_values), N)]\n']], ['Python Matplotlib: Splitting one Large Graph into several Sub-Graphs (Subplot)'], 2, 0], [(31768613, 1), [['Then you just perform a zip and plot each sublist in a different graph :'], ['']], [[" import pandas as pd\nfrom matplotlib import rcParams\nimport matplotlib.pyplot as plt\nfrom operator import itemgetter\n\nrcParams.update({'figure.autolayout': True})\nplt.figure(figsize=(14,9), dpi=600)\n\nreso_names = ['A','B','C','D','E','F','G','H']\nreso_values = [5,7,3,8,2,9,1,3]\n\nN=3\nsublists_names = [reso_names[x:x+N] for x in range(0, len(reso_names), N)]\nsublists_values = [reso_values[x:x+N] for x in range(0, len(reso_values), N)]\n\nsize = int(len(reso_values))\nfig, axs = plt.subplots(nrows=size//N+1, sharey=True, figsize=(14,18), dpi=50)\n\nfig.suptitle('Graph', \n          **{'family': 'Arial Black', 'size': 22, 'weight': 'bold'})\n\nfor ax, names, values in zip(axs, sublists_names, sublists_values):\n    ax.bar(range(len(values)), values, align='center')\n    ax.set_xlabel('X-Axis')\n    ax.set_ylabel('Y-Axis')\n    ax.set_xticks(range(len(names)))\n    ax.set_xticklabels(names, rotation='vertical')\n    ax.set_xlim(0, len(names))\n    #ax.set_xlim(0, N)\n\nfig.subplots_adjust(bottom=0.05, top=0.95)\nplt.show()\n"]], ['Python Matplotlib: Splitting one Large Graph into several Sub-Graphs (Subplot)'], 2, 1], [(31828240, 0), [['This is a really messy way to do this, first use  first_valid_index  to get the valid columns, convert the returned series to a dataframe so we can call  apply  row-wise and use this to index back to original df:'], ['A slightly cleaner way:']], [[' In [160]:\ndef func(x):\n    if x.values[0] is None:\n        return None\n    else:\n        return df.loc[x.name, x.values[0]]\npd.DataFrame(df.apply(lambda x: x.first_valid_index(), axis=1)).apply(func,axis=1)\n\u200b\nOut[160]:\n0     1\n1     3\n2     4\n3   NaN\ndtype: float64\n']], ['First non-null value per row from a list of Pandas columns'], 2, 1], [(31828240, 1), [['A slightly cleaner way:'], ['-10000']], [[' In [12]:\ndef func(x):\n    if x.first_valid_index() is None:\n        return None\n    else:\n        return x[x.first_valid_index()]\ndf.apply(func, axis=1)\n\nOut[12]:\n0     1\n1     3\n2     4\n3   NaN\ndtype: float64\n']], ['First non-null value per row from a list of Pandas columns'], 2, 1], [(31841487, 0), [["So, although I don't think there is a more succinct way to count business days\nthan than the method you propose, there is a far more performant way:\nConvert to  datetime64[D] 's instead of Python  datetime.date  objects:"], ['-10000']], [[" import pandas as pd\nimport numpy as np\ndrg = pd.date_range('2000-07-31', '2015-08-05', freq='B')\ntimestamp = pd.Timestamp('2015-08-05', 'B')\n\ndef using_astype(drg, timestamp):\n    A = drg.values.astype('<M8[D]')\n    B = timestamp.asm8.astype('<M8[D]')\n    return np.busday_count(A, B)\n\ndef using_datetimes(drg, timestamp):\n    A = [d.date() for d in drg]\n    B = pd.Timestamp('2015-08-05', 'B').date()\n    return np.busday_count(A, B)\n"]], ['Pandas number of business days between a DatetimeIndex and a Timestamp'], 2, 1], [(31841487, 1), [['-10000'], ['np.busday_count  converts its input to  datetime64[D] s anyway, so avoiding this extra conversion to and from  datetime.date s is far more efficient.']], [[' In [88]: %timeit using_astype(drg, timestamp)\n10000 loops, best of 3: 95.4 µs per loop\n\nIn [89]: %timeit using_datetimes(drg, timestamp)\n100 loops, best of 3: 10.3 ms per loop\n']], ['Pandas number of business days between a DatetimeIndex and a Timestamp'], 2, 0], [(31842707, 0), [["You'll have to use a custom solution. Split the lines by newlines, and remove empty lines from the start and end:"], ["This handles the case where the 'empty' lines still contain spaces or tabs, apart from the  \\n  line separators:"]], [[" def strip_empty_lines(s):\n    lines = s.splitlines()\n    while lines and not lines[0].strip():\n        lines.pop(0)\n    while lines and not lines[-1].strip():\n        lines.pop()\n    return '\\n'.join(lines)\n"]], ['python - remove empty lines from end and beginning of string'], 3, 1], [(31842707, 1), [["This handles the case where the 'empty' lines still contain spaces or tabs, apart from the  \\n  line separators:"], ["If there is no other whitespace than newlines, then a simple  s.strip('\\n')  will do:"]], [[" >>> strip_empty_lines('''\\\n... \n... \n... \n... \n...         some indentation here\n... \n... lorem ipsum\n... \n... \n... ''')\n'        some indentation here\\n\\nlorem ipsum'\n>>> strip_empty_lines('''\\\n... \\t  \\t\n...     \\n\n...         some indentation here\n... \n... lorem ipsum\n... \n... ''')\n'        some indentation here\\n\\nlorem ipsum'\n"]], ['python - remove empty lines from end and beginning of string'], 3, 0], [(31847577, 0), [['code:'], ['code:']], [[' lst=[{"a":2,"b":3,"c":4},{"b":4}]\n[a for a in lst[0] if a in lst[1]]\n[\'b\']\n']], ['Comparing two dictionaries in list in python'], 5, 1], [(31847577, 1), [['code:'], ['output:']], [[' lst=[{"a":2,"b":3,"c":4},{"b":4}]\nfor a in lst[0]:\n    if a in lst[1]]:\n        print a\n']], ['Comparing two dictionaries in list in python'], 5, 1], [(31847577, 2), [['output:'], ['edit:']], [[' b\n']], ['Comparing two dictionaries in list in python'], 5, 0], [(31847577, 4), [['output:'], ['-10000']], [[' dic0    b       is common to next dic\ndic1    b       is common to next dic\ndic2    d       is common to next dic\n']], ['Comparing two dictionaries in list in python'], 5, 0], [(31869890, 0), [['You can define the string as raw string, by prepending  r  to it, then the  \\  are not treated as escape characters. Example -'], ['After this, your replace should work -']], [[" >>> s = r'C:\\Users\\Client\\tests\\doc_test_hard.docx'\n>>> s\n'C:\\\\Users\\\\Client\\\\tests\\\\doc_test_hard.docx'\n"]], ["How to avoid '\\n' and '\\t' escaping sequence when string is assigned to a variable"], 2, 1], [(31869890, 1), [['After this, your replace should work -'], ['Though you actually may not need to do this, python should be able to handle the correct path separator for the os. If you are creating paths in your program, you should use  os.path.join()  , that would handle the path separators for you correctly.']], [[" >>> s.replace('\\\\','/')\n'C:/Users/Client/tests/doc_test_hard.docx'\n"]], ["How to avoid '\\n' and '\\t' escaping sequence when string is assigned to a variable"], 2, 0], [(31889359, 1), [['html'], ['-10000']], [[' {% for link in links %}\n    {{ link.post_count }}\n{% endfor %}\n']], ['How to count how many posts each link has on a reddit-like app?'], 2, 0], [(31892559, 0), [['Use a list to store the author names.'], ['To achieve your desired output you can add punctuation using  str.join() :']], [[' authors = []\nnum_authors = int(raw_input("How Many Authors? "))\nfor i in range(num_authors):\n    authors.append(raw_input("Enter Author\'s Name ({}): ".format(i+1)))\n']], ['How to format inputted data and output it'], 2, 0], [(31892559, 1), [['To achieve your desired output you can add punctuation using  str.join() :'], ['The inner  str.join()  joins with commas all authors except the last one or, if there are fewer than 2 authors, no join takes place. The outer join adds the ampersand between the final 2 authors if required.']], [[" authors_string = ' & '.join([', '.join(authors[:-1]), authors[-1]]\n                                if len(authors) > 2 else authors)\n"]], ['How to format inputted data and output it'], 2, 0], [(31912253, 0), [['Here is an example.'], ['The  hourly_date_rng  looks like this']], [[' import json\nimport pandas as pd\n\njson_data = [\n    {\n      "amount": 0,\n      "date_closed": "2012-08-04 16:00:00"\n    },\n    {\n      "amount": 0,\n      "date_closed": "2012-08-04 20:00:00"\n    },\n    {\n      "amount": 0,\n      "date_closed": "2012-08-04 22:00:00"\n    }\n]\n\ndf = pd.read_json(json.dumps(json_data), orient=\'records\')\ndf\n\n   amount          date_closed\n0       0  2012-08-03 16:00:00\n1       0  2012-08-04 20:00:00\n2       0  2012-08-04 22:00:00\n']], ['Is there an efficient way to fill date gaps in python?'], 4, 0], [(31912253, 1), [['The  hourly_date_rng  looks like this'], ['To align the index and fill the gaps']], [[" hourly_date_rng = pd.date_range(start='2012-08-04 12:00:00', end='2012-08-4 23:00:00', freq='H')\nhourly_date_rng.name = 'date_closed'\n\nhourly_date_rng\n\nDatetimeIndex(['2012-08-04 12:00:00', '2012-08-04 13:00:00',\n               '2012-08-04 14:00:00', '2012-08-04 15:00:00',\n               '2012-08-04 16:00:00', '2012-08-04 17:00:00',\n               '2012-08-04 18:00:00', '2012-08-04 19:00:00',\n               '2012-08-04 20:00:00', '2012-08-04 21:00:00',\n               '2012-08-04 22:00:00', '2012-08-04 23:00:00'],\n              dtype='datetime64[ns]', name='date_closed', freq='H', tz=None)\n"]], ['Is there an efficient way to fill date gaps in python?'], 4, 0], [(31912253, 2), [['To align the index and fill the gaps'], ['-10000']], [[" # make the column datetime object instead of string\ndf['date_closed'] = pd.to_datetime(df['date_closed'])\n# align the index using .reindex\ndf.set_index('date_closed').reindex(hourly_date_rng).fillna(0).reset_index()\n\n           date_closed  amount\n0  2012-08-04 12:00:00       0\n1  2012-08-04 13:00:00       0\n2  2012-08-04 14:00:00       0\n3  2012-08-04 15:00:00       0\n4  2012-08-04 16:00:00       0\n5  2012-08-04 17:00:00       0\n6  2012-08-04 18:00:00       0\n7  2012-08-04 19:00:00       0\n8  2012-08-04 20:00:00       0\n9  2012-08-04 21:00:00       0\n10 2012-08-04 22:00:00       0\n11 2012-08-04 23:00:00       0\n"]], ['Is there an efficient way to fill date gaps in python?'], 4, 0], [(31912253, 3), [['-10000'], ['-10000']], [[" result = df.set_index('date_closed').reindex(hourly_date_rng).fillna(0).reset_index()\n\n# maybe convert date_closed column to string first\nresult['date_closed'] = pd.DatetimeIndex(result['date_closed']).to_native_types()\n# to json function\njson_result = result.to_json(orient='records')\n\n# print out the data with pretty print\nfrom pprint import pprint\npprint(json.loads(json_result))\n\n\n[{'amount': 0.0, 'date_closed': '2012-08-04 12:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 13:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 14:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 15:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 16:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 17:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 18:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 19:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 20:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 21:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 22:00:00'},\n {'amount': 0.0, 'date_closed': '2012-08-04 23:00:00'}]\n"]], ['Is there an efficient way to fill date gaps in python?'], 4, 0], [(31919765, 0), [["As a basic example, let's interactively highlight points inside a rectangle (this is an inefficient way to do that, but we'll need to build on this example to do what you want). After the figure window is closed, this will print out the points  not  selected ( ~  operates as  logical_not  on numpy arrays):"], ["However, you have an additional wrinkle, as you have two linked plots.  You want a selection on the X-Y plot to also select things on the X-Z plot.  Let's modify things to handle that:"]], [[' import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.widgets import RectangleSelector\n\ndef main():\n    x, y = np.random.random((2, 100))\n    fig, ax = plt.subplots()\n    ax.scatter(x, y, color=\'black\')\n    highlighter = Highlighter(ax, x, y)\n    plt.show()\n\n    selected_regions = highlighter.mask\n    # Print the points _not_ selected\n    print x[~selected_regions], y[~selected_regions]\n\nclass Highlighter(object):\n    def __init__(self, ax, x, y):\n        self.ax = ax\n        self.canvas = ax.figure.canvas\n        self.x, self.y = x, y\n        self.mask = np.zeros(x.shape, dtype=bool)\n\n        self._highlight = ax.scatter([], [], s=200, color=\'yellow\', zorder=10)\n\n        self.selector = RectangleSelector(ax, self, useblit=True)\n\n    def __call__(self, event1, event2):\n        self.mask |= self.inside(event1, event2)\n        xy = np.column_stack([self.x[self.mask], self.y[self.mask]])\n        self._highlight.set_offsets(xy)\n        self.canvas.draw()\n\n    def inside(self, event1, event2):\n        """Returns a boolean mask of the points inside the rectangle defined by\n        event1 and event2."""\n        # Note: Could use points_inside_poly, as well\n        x0, x1 = sorted([event1.xdata, event2.xdata])\n        y0, y1 = sorted([event1.ydata, event2.ydata])\n        mask = ((self.x > x0) & (self.x < x1) &\n                (self.y > y0) & (self.y < y1))\n        return mask\n\nmain()\n']], ['Choosing a box of data points from a plot'], 2, 1], [(31919765, 1), [["However, you have an additional wrinkle, as you have two linked plots.  You want a selection on the X-Y plot to also select things on the X-Z plot.  Let's modify things to handle that:"], ['-10000']], [[" import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.widgets import RectangleSelector\n\ndef main():\n    x, y, z = np.random.random((3, 100))\n    z *= 10\n    fig, axes = plt.subplots(figsize=(6, 8), nrows=2, sharex=True)\n    axes[0].scatter(x, y, color='black')\n    axes[1].scatter(x, z, color='black')\n    axes[0].set(ylabel='Y')\n    axes[1].set(xlabel='X', ylabel='Y')\n\n    highlighter = Highlighter(axes, x, y, z)\n    plt.show()\n\n    selected_regions = highlighter.mask\n    print x[~selected_regions], y[~selected_regions], z[~selected_regions]\n\nclass Highlighter(object):\n    def __init__(self, axes, x, y, z):\n        self.axes = axes\n        self.canvas = axes[0].figure.canvas\n        self.x, self.y, self.z = x, y, z\n        self.mask = np.zeros(x.shape, dtype=bool)\n\n        self._highlights = [ax.scatter([], [], s=200, color='yellow', zorder=10)\n                               for ax in axes]\n\n        self._select1 = RectangleSelector(axes[0], self.select_xy, useblit=True)\n        self._select2 = RectangleSelector(axes[1], self.select_xz, useblit=True)\n\n    def select_xy(self, event1, event2):\n        self.mask |= self.inside(event1, event2, self.x, self.y)\n        self.update()\n\n    def select_xz(self, event1, event2):\n        self.mask |= self.inside(event1, event2, self.x, self.z)\n        self.update()\n\n    def update(self):\n        xy = np.column_stack([self.x[self.mask], self.y[self.mask]])\n        self._highlights[0].set_offsets(xy)\n\n        xz = np.column_stack([self.x[self.mask], self.z[self.mask]])\n        self._highlights[1].set_offsets(xz)\n\n        self.canvas.draw()\n\n    def inside(self, event1, event2, x, y):\n        x0, x1 = sorted([event1.xdata, event2.xdata])\n        y0, y1 = sorted([event1.ydata, event2.ydata])\n        return (x > x0) & (x < x1) & (y > y0) & (y < y1)\n\nmain()\n"]], ['Choosing a box of data points from a plot'], 2, 1], [(31920197, 2), [['You can then assign the function and call it as you normally would:'], ['-10000']], [[' >>> b, = ns.values()  # this will only work if only one name was defined\n>>> b()\n5\n']], ['Read python function from a text file and assign it to variable'], 3, 0], [(31936573, 0), [["I'm assuming you mean the function is going to be some kind of mathematical function, for example:"], ['Then I would define variables for the number of points to plot, and the x range, and then create lists using  map , as below.']], [[' import math\ndef function(x, A, B):\n    return math.exp(A*x) * math.sin(B*x)\n']], ['Python - Plot function over a range PYPLOT'], 2, 0], [(31941020, 1), [['Then your code will work fine'], ['-10000']], [[" for ccy in ccys:\n    ccy[13] += 10\n\n>>> audcad\n['audcad', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10]\n>>> audchf\n['audchf', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10]\n>>> audjpy\n['audjpy', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10]\n"]], ['How to reference/iterate multiple lists in Python'], 2, 0], [(31957215, 0), [['You can pass in a custom  key  to the  sorted  function with  reverse=True  to get the descending order:'], ['You can also sort it in place using the  .sort  method of the list (use  reverse=True  for descending order):']], [[' >>> res = [{\'cpunumber\': \'40.0\', \'servername\': \'f02wn01\', \'cpucore_sum\': \'5.0\',   \'cpucore_00\': \'0.399414\', \'datetime\': \'1438887255\'}, \n...   {\'cpunumber\': \'40.0\', \'servername\': \'f02wn01\', \'cpucore_sum\': \'9.375\', \'cpucore_00\': \'1.597656\', \'datetime\': \'1438887250\'}, \n...   {\'cpunumber\': \'40.0\', \'servername\': \'f02wn01\', \'cpucore_sum\': \'3.195312\', \'cpucore_00\': \'0.0\', \'datetime\': \'1438887240\'}, \n...   {\'cpunumber\': \'40.0\', \'servername\': \'f02wn01\', \'cpucore_sum\': \'5.59375\', \'cpucore_00\': \'1.0\', \'datetime\': \'1438887245\'}]\n>>> sorted(res, key=lambda x: x["datetime"], reverse=True)\n[{\'cpucore_00\': \'0.399414\',\n  \'cpucore_sum\': \'5.0\',\n  \'cpunumber\': \'40.0\',\n  \'datetime\': \'1438887255\',\n  \'servername\': \'f02wn01\'},\n {\'cpucore_00\': \'1.597656\',\n  \'cpucore_sum\': \'9.375\',\n  \'cpunumber\': \'40.0\',\n  \'datetime\': \'1438887250\',\n  \'servername\': \'f02wn01\'},\n {\'cpucore_00\': \'1.0\',\n  \'cpucore_sum\': \'5.59375\',\n  \'cpunumber\': \'40.0\',\n  \'datetime\': \'1438887245\',\n  \'servername\': \'f02wn01\'},\n {\'cpucore_00\': \'0.0\',\n  \'cpucore_sum\': \'3.195312\',\n  \'cpunumber\': \'40.0\',\n  \'datetime\': \'1438887240\',\n  \'servername\': \'f02wn01\'}]\n']], ['Order a list of dictionaries in python'], 2, 1], [(31957215, 1), [['You can also sort it in place using the  .sort  method of the list (use  reverse=True  for descending order):'], ['In case all your  dict s are not guranteed to have the  "datetime"  key, you can use  x.get("datetime")  instead of  x["datetime"] .']], [[' >>> res.sort(key=lambda x: x["datetime"])\n>>> res\n[{\'cpucore_sum\': \'3.195312\', \'cpucore_00\': \'0.0\', \'servername\': \'f02wn01\', \'cpunumber\': \'40.0\', \'datetime\': \'1438887240\'}, {\'cpucore_sum\': \'5.59375\', \'cpucore_00\': \'1.0\', \'servername\': \'f02wn01\', \'cpunumber\': \'40.0\', \'datetime\': \'1438887245\'}, {\'cpucore_sum\': \'9.375\', \'cpucore_00\': \'1.597656\', \'servername\': \'f02wn01\', \'cpunumber\': \'40.0\', \'datetime\': \'1438887250\'}, {\'cpucore_sum\': \'5.0\', \'cpucore_00\': \'0.399414\', \'servername\': \'f02wn01\', \'cpunumber\': \'40.0\', \'datetime\': \'1438887255\'}]\n']], ['Order a list of dictionaries in python'], 2, 1], [(31978879, 0), [['Lastly, I have added adjusted your plot code to use an  axis  object, which is required to have a colorbar.'], ['Snippet, demonstrating  ColorbarBase']], [[' import numpy as np\nimport matplotlib.pyplot as plt\n# This is needed to iterate over your data files\nimport glob \n\n# Loop over all your data files to get the maximum value for \'vel\'. \n# You will have to adjust this for your code\n"""max_vel = 0\nfor i in glob.glob(<your files>,\'r\') as fr:\n    # Iterate over all lines\n    if <vel value> > max_vel:\n        max_vel = <vel_value>"""\n\n# Create Map\ncm = plt.cm.get_cmap(\'RdYlBu\')\nx,y,vel = np.loadtxt(\'finaldata_temp.txt\', skiprows=0, unpack=True)\n\n# Plot the data\nfig=plt.figure()\nfig.patch.set_facecolor(\'white\')\n# Here we switch to an axis object\n# Additionally, you can plot several of your files in the same figure using\n# the subplot option.\nax=fig.add_subplot(111)\ns = ax.scatter(x,y,c=vel,edgecolor=\'\'))\n# Here we assign the color bar to the axis object\ncb = plt.colorbar(mappable=s,ax=ax,cmap=cm)\n# Here we set the range of the color bar based on the maximum observed value\n# NOTE: This line only changes the calculated color and not the display \n# \'range\' of the legend next to the plot, for that we need to switch to \n# ColorbarBase (see second code snippet).\ncb.setlim(0,max_vel)\ncb.set_label(\'Value of \\\'vel\\\'\')\nplt.show()\n']], ['2D Color coded scatter plot with user defined color range and static colormap'], 2, 1], [(32018206, 0), [['You can simply sum how many times an element is the the range 3-4:'], ['import numpy as np']], [[' l = [3.4,4.5,3.2,5.6]\n\nprint(sum(3 <= ele <= 4  for ele in l))\n2\n']], ['python- finding total number of items of certain range in a list'], 4, 1], [(32018206, 3), [['If you actually want to count the total number of floats in between two actual integers:'], ['-10000']], [[' l = [1.3, 3, 3.4, 34.5, 3.2, 4, 5.6]\n\n\ndef find_fs(l, i, j):\n    try:\n        start, end = l.index(i), l.index(j)\n        return sum(isinstance(ele, float) for ele in islice(l, start + 1, end))\n    except IndexError:\n        return 0\nprint(find_fs(l,3, 4))\n3\n']], ['python- finding total number of items of certain range in a list'], 4, 1], [(32026028, 0), [["Let's say we have two functions who calculate the value of Pi,  calculate1()  and  calculate2() . In this case  calculate2()  is faster."], ['This outputs:']], [[' import multiprocessing\nimport time\n\ndef calculate1(result_queue):\n    print "calculate1 started"\n    time.sleep(10)\n    result = 3.14\n    result_queue.put(result)\n    print "calculate1 found the result!"\n\ndef calculate2(result_queue):\n    print "calculate2 started"\n    time.sleep(2)\n    result = 3.14\n    result_queue.put(result)\n    print "calculate2 found the result!"\n\nresult_queue = multiprocessing.Queue()\n\nprocess1 = multiprocessing.Process(target=calculate1, args=[result_queue])\nprocess2 = multiprocessing.Process(target=calculate2, args=[result_queue])\n\nprocess1.start()\nprocess2.start()\n\nprint "Calculating the result with 2 threads."\n\nresult = result_queue.get() # waits until any of the proccess have `.put()` a result\n\nfor process in [process1, process2]: # then kill them all off\n    process.terminate()\n\nprint "Got result:", result\n']], ['Run multiple threads until one exits in python'], 2, 1], [(32026028, 1), [['This outputs:'], ['-10000']], [[' calculate1 started\ncalculate2 started\ncalculate2 found the result!\nGot result: 3.14\n']], ['Run multiple threads until one exits in python'], 2, 0], [(32077660, 0), [["You need to pass two keys to sorted, the name and date, then use  str.join  to concat the ip's and times"], ['Or without sorting using  dict to group:']], [[' from itertools import groupby\nfrom operator import itemgetter\n\nout = []\n\nfor _, v in groupby(sorted(data, key=itemgetter(0, 3)),key=itemgetter(0,3)):\n    v = list(v)    \n    ips = ", ".join([sub[1] for sub in v])\n    tmes = ", ".join([sub[2] for sub in v])\n    out.append([v[0][0], ips, tmes, v[0][-1]])\n\nprint(out)\n\n[\'blah\', \'172.18.74.149, 172.18.74.146\', \'11:18:33.846, 12:27:38.985\', \'2015_08_12\'], \n[\'test\', \'172.18.74.146, 172.18.74.148\', \'13:05:43.834, 12:27:39.016\', \'2015_08_07\']]\n']], ['Combine multidimensional array by group python'], 3, 1], [(32077660, 1), [['Or without sorting using  dict to group:'], ['Output:']], [[' d = {}\n\nfor nm, ip, tm, dte in data:\n    key = nm, dte\n    if key in d:\n        v = d[key]\n        v[1] += ", {}".format(ip)\n        v[2] += ", {}".format(dte)\n    else:\n        d[key] = [nm, ip, tm, dte]\n\nprint(list(d.values()))\n']], ['Combine multidimensional array by group python'], 3, 1], [(32077660, 2), [['Output:'], ['-10000']], [[" [['test', '172.18.74.146, 172.18.74.148', '13:05:43.834, 2015_08_07', '2015_08_07'], \n['blah', '172.18.74.149, 172.18.74.146', '11:18:33.846, 2015_08_12', '2015_08_12']]\n"]], ['Combine multidimensional array by group python'], 3, 0], [(32102801, 1), [['More efficiently, iterate through the items and avoid the extra lookup:'], ['-10000']], [[' for key, value in myDict.items():\n    for eachValue in value:\n        for char in eachValue:\n            do something\n']], ['Step through items in dictionary in python'], 2, 1], [(32148804, 0), [['Use the  with  construct.'], ['If the file is very large, I suggest iterating over it and printing it a line at a time:']], [[" with open('file.txt', 'r') as f:\n    print(f.read())\n"]], ['Python: Opening a file within a print() function'], 2, 1], [(32148804, 1), [['If the file is very large, I suggest iterating over it and printing it a line at a time:'], ["Of course, if the file is that large, it's probably not useful to print it to an ordinary console, but this practice is very useful for  processing  large files."]], [[" with open('file.txt', 'r') as f:\n    for line in f:\n        print(line, end='')\n"]], ['Python: Opening a file within a print() function'], 2, 1], [(32161369, 0), [['To express the idea of "element  1  of element  2  of each row of  e ", you should use a  list comprehension :'], ['-10000']], [[' f = [x[2][1] for x in e]\n']], ['How to get a vector from a list in list in python?'], 4, 0], [(32161369, 1), [['-10000'], ['Then you can use it like this:']], [[' class Comprehension(object):\n    def __init__(self, iterable):\n        self._iterable = iterable\n\n    def __iter__(self):\n        return iter(self._iterable)\n\n    def __getattr__(self, name):\n        return Comprehension(getattr(elt, name) for elt in self._iterable)\n\n    def __getitem__(self, item):\n        return Comprehension(elt[item] for elt in self._iterable)\n\n    def __call__(self, *args, **kwargs):\n        return Comprehension(elt(*args, **kwargs) for elt in self._iterable)\n']], ['How to get a vector from a list in list in python?'], 4, 1], [(32161369, 2), [['Then you can use it like this:'], ['This class also supports attribute lookup and function calls.']], [[' f = list(Comprehension(e)[2][1])\n']], ['How to get a vector from a list in list in python?'], 4, 0], [(32161369, 3), [['This class also supports attribute lookup and function calls.'], ['-10000']], [[' >>> list(Comprehension(range(10)).bit_length())\n[0, 1, 2, 2, 3, 3, 3, 3, 4, 4]\n']], ['How to get a vector from a list in list in python?'], 4, 0], [(32174535, 0), [['You would first need to transform the nested dictionary into a list of dictionaries or a dictionary of lists, and then only you can convert it to a DataFrame. Example (converting to a list of dictionaries) -'], ['Example/Demo -']], [[" list_of_dict = []\nfor key, value in nested_dict.items():\n    for key1, value1 in value.items():\n        for key2,value2 in value1.items():\n            list_of_dict.append({'A':key,'B':key1,'C':key2,'D':value2})\n\ndf = pd.DataFrame(list_of_dict)\n"]], ['Converting dictionary of dictionary of dictionary to pandas data frame'], 2, 1], [(32174535, 1), [['Example/Demo -'], ['-10000']], [[" In [2]: nested_dict = {'2': {'lagtime': {'darkgreen': 210,\n   ...:    'darkorange': 141,\n   ...:    'pink': 142,\n   ...:    'red': 141}}}\n\nIn [4]: list_of_dict = []\n\nIn [7]: for key, value in nested_dict.items():\n   ...:     for key1, value1 in value.items():\n   ...:         for key2,value2 in value1.items():\n   ...:             list_of_dict.append({'A':key,'B':key1,'C':key2,'D':value2})\n   ...:\n\nIn [8]: df = pd.DataFrame(list_of_dict)\n\nIn [9]: df\nOut[9]:\n   A        B           C    D\n0  2  lagtime   darkgreen  210\n1  2  lagtime        pink  142\n2  2  lagtime  darkorange  141\n3  2  lagtime         red  141\n"]], ['Converting dictionary of dictionary of dictionary to pandas data frame'], 2, 1], [(32182116, 0), [['Please use assignment tag if you are using django < 1.9. The doc is  here . I posted the example in the docs here:'], ['Then in template:']], [[' @register.assignment_tag\ndef get_current_time(format_string):\n    return datetime.datetime.now().strftime(format_string)\n']], ['Put the result of simple tag into a variable'], 2, 0], [(32182116, 1), [['Then in template:'], ['You can see that the template tag result becomes a variable using  as  statement. You can use  the_time  however you like, including  if  statement.']], [[' {% get_current_time "%Y-%m-%d %I:%M %p" as the_time %}\n<p>The time is {{ the_time }}.</p>\n']], ['Put the result of simple tag into a variable'], 2, 0], [(32214596, 0), [['Fortunately, this is not hard, as Python includes a built-in  set  type.\nSo the first step is to construct the two sets:'], ['Now, we can easily (and efficiently) determine if an element  e  is in one of the sets:']], [[' a = set((1, 3))\nb = set((2, 5))\n']], ['How can I quickly compare a list and a set?'], 3, 0], [(32214596, 1), [['Now, we can easily (and efficiently) determine if an element  e  is in one of the sets:'], ['Now, we just need to loop over the input list and accumulate the result:']], [[' e = 1\ne in a # => True\ne in b # => False\n']], ['How can I quickly compare a list and a set?'], 3, 0], [(32214596, 2), [['Now, we just need to loop over the input list and accumulate the result:'], ['-10000']], [[' l = [1, 1, 3, 2, 5, 7, 8, 3, 2, 1]\nresult = 0 # accumulator for result\nfor e in l:\n  if e in a:\n    result += 1\n  elif e in b:\n    result -= 1\n\nprint result # prints "2"\n']], ['How can I quickly compare a list and a set?'], 3, 0], [(32215965, 1), [["I'm not sure if you really wanted to output the fruits and not their associated color though, this will output:"], ["If you change any of the fruits values though, (for example 'red' to 'green') this will not automatically update the value in the 'fruits' list, in case you wanted that."]], [[" ['red', 'orange', 'yellow']\n"]], ['dict of internal keys'], 2, 0], [(32231491, 0), [['You can try'], ['If you need the original order preserved, use  collections.OrderedDict , which is a hash map (just like regular  dict ) and therefore works similarly to  frozenset / set']], [[" In [3]: [value for _, value in frozenset((type(x), x) for x in l)]\nOut[3]: [1.0, '1', 1, 'dsa', 'asd']\n"]], ['Python removing duplicates in list and 1==1.0 True'], 2, 1], [(32231491, 1), [['If you need the original order preserved, use  collections.OrderedDict , which is a hash map (just like regular  dict ) and therefore works similarly to  frozenset / set'], ['-10000']], [[" In [16]: from collections import OrderedDict\n\nIn [17]: [value for _, value in OrderedDict.fromkeys((type(x), x) for x in l)]\nOut[17]: ['asd', 'dsa', 1, '1', 1.0]\n"]], ['Python removing duplicates in list and 1==1.0 True'], 2, 1], [(32244565, 1), [['The library  imread  also have a method  imread_from_blob  which accept a string as input. So you may pass your data directly to this function.'], ['The second parameter is the extension typically associated with this blob. If None is given, then  detect_format  is used to auto-detect.']], [[" from imread import imread_from_blob\nimg_data = imread_from_blob(data, 'jpg')\n\n>>> img_data\narray([[[ 23, 123, 149],\n[ 22, 120, 147],\n[ 22, 118, 143],\n...,\n"]], ['Load JPEG from URL to skimage without temporary file'], 2, 1], [(32256393, 0), [['You can try like this:'], ['Example:']], [[' def to_nested_dict(list_dict):\n    d = {}                                   # initialize the outer dict\n    for k, lst in list_dict.items():\n        d[k] = {}                            # initialize inner dicts\n        for x, y in lst:\n            d[k].setdefault(x, []).append(y) # initialize and populate innermost list\n    return d\n']], ['create dictionary from list same values'], 2, 1], [(32256393, 1), [['Example:'], ['Not that this assumes that the inner-most lists will always have two elements, a key and a value, and that the key can be the same in different lists, but can also differ, resulting in more than one entry in the created dictionaries.']], [[" >>> to_nested_dict({'abc': [['aaa', '123'], ['aaa', '321']]})\n{'abc': {'aaa': ['123', '321']}}\n>>> to_nested_dict({'abc': [['aaa', '123'], ['aaa', '321'], ['bbb', '456']]})\n{'abc': {'aaa': ['123', '321'], 'bbb': ['456']}}\n>>> to_nested_dict({'abc': [['aaa', '123'], ['aaa', '321'], ['bbb', '456']], 'efg': [['eee', '789']]})\n{'abc': {'aaa': ['123', '321'], 'bbb': ['456']}, 'efg': {'eee': ['789']}}\n"]], ['create dictionary from list same values'], 2, 0], [(32262334, 0), [['Like this:'], ['Example:']], [[' *[[0, 4], [2], [3]]\n']], ['Remove outer list from list of list in python'], 3, 1], [(32262334, 1), [['Example:'], ['In your case:']], [[' >>> def f(a, b, c):\n...    print(a, b, c)\n...\n>>> f(*[1, 2, 3])\n1 2 3\n']], ['Remove outer list from list of list in python'], 3, 1], [(32262334, 2), [['In your case:'], ['-10000']], [[' for element in itertools.product(*d.values()):\n    sortedList = sorted(list(element))\n']], ['Remove outer list from list of list in python'], 3, 1], [(32295637, 0), [['BTW, you can define your constants using exponential notation:'], ['and']], [[' m_sun = 1.989e+30\nG = 6.67e-11\n']], ['Extracting Data From Python Classes'], 2, 0], [(32295637, 1), [['and'], ['which is more readable (important) and saves a few calculations for the definition of your class (less/not important).']], [[' pluto = Planet(4495978707000, 0, 0, 4670, 1.305e+22)\n']], ['Extracting Data From Python Classes'], 2, 0], [(32298978, 0), [['You can use  collections.Counter .'], ['Output:']], [[" from collections import Counter\n\nd = {'brown dogs':3, 'dog of white':4, 'white cats':1, 'white cat':9}\nsubstrings = ['dog', 'cat']\n\ncounter = Counter()\n\nfor substring in substrings:\n    for key in d:\n        if substring in key:\n            counter[substring] += d[key]\n\nprint(counter.items())\n"]], ['Searching and counting dictionary key value pairs'], 2, 1], [(32298978, 1), [['Output:'], ['-10000']], [[" [('dog', 7), ('cat', 10)]\n"]], ['Searching and counting dictionary key value pairs'], 2, 0], [(32308382, 0), [['If you use the  yield from  syntax, the function is actually a  coroutine  and it has to be decorated accordingly:'], ['Then you can schedule the coroutine as a task using  ensure_future :']], [[" @asyncio.coroutine\ndef hello_world(loop):\n    print('Hello')\n    yield from asyncio.sleep(5, loop=loop)\n    print('World')\n    loop.stop()\n"]], ['Execute coroutine from `call_soon` callback function'], 5, 0], [(32308382, 1), [['Then you can schedule the coroutine as a task using  ensure_future :'], ['Or equivalently, using  run_until_complete :']], [[' loop = asyncio.get_event_loop()\ncoro = hello_world(loop)\nasyncio.ensure_future(coro)\nloop.run_forever()\nloop.close()\n']], ['Execute coroutine from `call_soon` callback function'], 5, 0], [(32308382, 2), [['Or equivalently, using  run_until_complete :'], ['-10000']], [[' loop = asyncio.get_event_loop()\ncoro = hello_world(loop)\nloop.run_until_complete(coro)\n']], ['Execute coroutine from `call_soon` callback function'], 5, 0], [(32308382, 3), [['-10000'], ['-10000']], [[" async def hello_world(loop):\n    print('Hello')\n    await asyncio.sleep(5, loop=loop)\n    print('World')\n"]], ['Execute coroutine from `call_soon` callback function'], 5, 0], [(32308382, 4), [['-10000'], ['-10000']], [[' loop = asyncio.get_event_loop()\ncoro = hello_world(loop)\ncallback = lambda: asyncio.ensure_future(coro)\nloop.call_soon(callback)\nloop.run_forever()\nloop.close()\n']], ['Execute coroutine from `call_soon` callback function'], 5, 0], [(32314712, 0), [['The following approach should work, it first calculates 6 minutes into the future and starts your "script" executing 500 times. It then simply waits in a loop until the wake up time is reached. So your script can take any amount of time. If it takes longer, then the next 500 will start immediately.'], ['Try the following demo version: The following version runs every 6 seconds (not minutes) and tries to do the  for  loop 20 times. I slow it down by 0.5 seconds each iteration to simulate work.']], [[' import time\n\nwakeup = time.time()\n\nwhile True:\n    wakeup += 6 * 60\n\n    for i in range(500):\n        # something \n\n        # Has it taken longer the 6 minutes?\n        if time.time() > wakeup:\n            break\n\n    while time.time() < wakeup:\n        time.sleep(1)\n']], ['Restart a script after 6 minutes'], 3, 1], [(32314712, 1), [['Try the following demo version: The following version runs every 6 seconds (not minutes) and tries to do the  for  loop 20 times. I slow it down by 0.5 seconds each iteration to simulate work.'], ['You will see the following output:']], [[' import time\n\nwakeup = time.time()\n\nwhile True:\n    wakeup += 6 \n    print "start",\n\n    for i in range(20):\n        time.sleep(0.5)   # simulate work\n        print i,\n\n        if time.time() > wakeup:\n            break\n\n    print "finished"\n\n    while time.time() < wakeup:\n        time.sleep(1)\n']], ['Restart a script after 6 minutes'], 3, 1], [(32314712, 2), [['You will see the following output:'], ['As you can see, the loop is aborted when 6 seconds are up and before all 20 iterations are reached and it is then restarted.']], [[' start 0 1 2 3 4 5 6 7 8 9 10 11 12 finished\nstart 0 1 2 3 4 5 6 7 8 9 10 finished\nstart 0 1 2 3 4 5 6 7 8 9 10 11 finished\n']], ['Restart a script after 6 minutes'], 3, 0], [(32316244, 0), [['This does what you want, to use an df.apply method'], ['Output:']], [[" import pandas as pd\n\ncols = ['page', 'hour', 'count']\ndata = [\n    (3727441,    1,  2003),\n    (3727441,    2,   654),\n    (3727441,    3,  5434),\n    (3727458,    1,   326),\n    (3727458,    2,  2348),\n    (3727458,    3,  4040),\n    (3727458,    4,   374),\n    (3727458,    5,  2917),\n    (3727458,    6,  3937),\n    (3735634,    1,  1957),\n    (3735634,    2,  2398),\n    (3735634,    3,  2812),\n    (3768433,    1,   499),\n    (3768433,    2,  4924),\n    (3768433,    3,  5460),\n    (3768433,    4,  1710),\n    (3768433,    5,  3877),\n    (3768433,    6,  1912),\n    (3768433,    7,  1367),\n    (3768433,    8,  1626),\n    (3768433,    9,  4750),\n]\n\ndf = pd.DataFrame.from_records(data, columns=cols)\n\ndef f(row):\n    n = (row.hour - 1) / 3 \n    if n > 0:\n        return str(row.page) + '_{0}'.format(int(n))\n    else:\n        return row.page\n\ndf['page'] = df.apply(f, axis=1)\n\nprint df\n"]], ['Slicing pandas groupby groups into equal lengths'], 2, 1], [(32316244, 1), [['Output:'], ['-10000']], [['  #       page  hour  count\n # 0     3727441     1   2003\n # 1     3727441     2    654\n # 2     3727441     3   5434\n # 3     3727458     1    326\n # 4     3727458     2   2348\n # 5     3727458     3   4040\n # 6   3727458_1     4    374\n # 7   3727458_1     5   2917\n # 8   3727458_1     6   3937\n # 9     3735634     1   1957\n # 10    3735634     2   2398\n # 11    3735634     3   2812\n # 12    3768433     1    499\n # 13    3768433     2   4924\n # 14    3768433     3   5460\n # 15  3768433_1     4   1710\n # 16  3768433_1     5   3877\n # 17  3768433_1     6   1912\n # 18  3768433_2     7   1367\n # 19  3768433_2     8   1626\n # 20  3768433_2     9   4750\n']], ['Slicing pandas groupby groups into equal lengths'], 2, 0], [(32344022, 0), [['You could use numpy and vectorization, something like it below'], ['example output of pairs']], [[' import numpy as np\n\nphi = 0.5\ntheta = 1\nn1 = 10\nn2 = 20\n\nN1 = np.random.randint(-100, 100, size=100)\nN2 = np.random.randint(-100, 100, size=100)\n\nN1 = N1[(N1 >= 0) & (N1 <= n1)]\nN2 = N2[(N2 >= 0) & (N2 <= n2)]\n\na = N2 * theta + phi\nres = N1.reshape(N1.shape[0], 1) - a.reshape(1, a.shape[0])\n\nindices = np.argwhere(res >= 0)\npairs = zip(N1[indices[:,0]], N2[indices[:,1]])\n']], ['Finding combinations that meet a threshold relation'], 3, 1], [(32344022, 1), [['example output of pairs'], ['per @dbliss request, here is the modualized version and its test']], [[' [(8, 3),\n (8, 6),\n (8, 5),\n (8, 1),\n (3, 1),\n (9, 3),\n (9, 8),\n (9, 8),\n (9, 6),\n (9, 5),\n (9, 6),\n (9, 6),\n (9, 5),\n (9, 8),\n (9, 1)]\n']], ['Finding combinations that meet a threshold relation'], 3, 0], [(32344022, 2), [['per @dbliss request, here is the modualized version and its test'], ['-10000']], [[' import numpy as np\n\n\ndef calc_combination(N1, N2, n1, n2, theta, phi):\n    N1 = N1[(N1 >= 0) & (N1 <= n1)]\n    N2 = N2[(N2 >= 0) & (N2 <= n2)]\n\n    a = N2 * theta + phi\n    res = N1.reshape(N1.shape[0], 1) - a.reshape(1, a.shape[0])\n\n    indices = np.argwhere(res >= 0)\n    pairs = zip(N1[indices[:,0]], N2[indices[:,1]])\n    return pairs\n\n\ndef test_case():\n    n1 = 5\n    n2 = 1\n    theta = 2\n    phi = 2\n\n    N1 = np.arange(n1 + 1)\n    N2 = np.arange(n2 + 1)\n\n    assert (calc_combination(N1, N2, n1, n2, theta, phi) ==\n            [(2, 0), (3, 0), (4, 0), (4, 1), (5, 0), (5, 1)])\n\ntest_case()\n']], ['Finding combinations that meet a threshold relation'], 3, 1], [(32346156, 0), [['As you are using  DictWriter , you would need to construct a per row dictionary as follows:'], ['This will create you an output CSV file as follows:']], [[' import csv\n\nsymbol = ["msft", "cvx", "baba"]\nheader = ["symbol","ev_ebitda","asset"]\n\nwith open(\'output.csv\', \'wb\') as f_output:\n    csv_output = csv.DictWriter(f_output, fieldnames=header)\n    csv_output.writeheader()\n\n    for s in symbol:\n        row = {\'asset\': 60, \'ev_ebitda\': 40, \'symbol\': s}\n        csv_output.writerow(row)\n']], ['Outputting Multi-row CSV Files from Multiple Dictionaries'], 2, 1], [(32346156, 1), [['This will create you an output CSV file as follows:'], ['-10000']], [[' symbol,ev_ebitda,asset\nmsft,40,60\ncvx,40,60\nbaba,40,60\n']], ['Outputting Multi-row CSV Files from Multiple Dictionaries'], 2, 0], [(32358269, 1), [['So if you had a  userID.txt  file containing the following names, with one name per line:'], ['You would get a one line output file as follows:']], [[' fred\nwilma\n']], ['appending a single string to each element of a list in python'], 3, 0], [(32358269, 2), [['You would get a one line output file as follows:'], ['-10000']], [[' fred@wherever.com, wilma@wherever.com\n']], ['appending a single string to each element of a list in python'], 3, 0], [(32365358, 2), [['and in action...'], ['-10000']], [[' >>> z = listify([[(1, 0.97456828373415116)],\n                 [(0, 0.91883125256489728), (1, 0.020225186991467976), (2, 0.020314851937259213), (3, 0.020382294889184499), (4, 0.020246413617191008)],\n                 [(2, 0.98493696818505228)]])\n>>> pprint(z)\n[[(0, 0), (1, 0.9745682837341512), (2, 0), (3, 0), (4, 0)],\n [(0, 0.9188312525648973),\n  (1, 0.020225186991467976),\n  (2, 0.020314851937259213),\n  (3, 0.0203822948891845),\n  (4, 0.020246413617191008)],\n [(0, 0), (1, 0), (2, 0.9849369681850523), (3, 0), (4, 0)]]\n']], ['Python lists with irregular format'], 3, 0], [(32379895, 1), [['You could sort each row:'], ['But how do you identify the unique values in each row without iterating?  Counting the number of nonzero differences might just do the trick:']], [[' np.sort(data.reshape(N,-1))\n\narray([[1, 2, 2, 3, 3, 5, 5, 5, 6, 6],\n       [1, 1, 1, 2, 2, 2, 3, 3, 5, 7],\n       [0, 0, 2, 3, 4, 4, 4, 5, 5, 9],\n       [2, 2, 3, 3, 4, 4, 5, 7, 8, 9],\n       [0, 2, 2, 2, 2, 5, 5, 5, 7, 9]])\n']], ['vectorize numpy unique for subarrays'], 6, 0], [(32379895, 3), [['I was going to add a warning about floats, but if  np.unique  is working for your data, my approach should work just as well.'], ['In [585]: data.shape\nOut[585]: (10000, 400)']], [[' [(np.bincount(i)>0).sum() for i in data]\n']], ['vectorize numpy unique for subarrays'], 6, 1], [(32379895, 4), [['In [585]: data.shape\nOut[585]: (10000, 400)'], ['I just found a faster way to use  bincount ,  np.count_nonzero']], [[' In [586]: timeit [(np.bincount(i)>0).sum() for i in data]\n1 loops, best of 3: 248 ms per loop\n\nIn [587]: %%timeit                                       \nsdata=np.sort(data,axis=1)\n(np.diff(sdata)>0).sum(axis=1)+1\n   .....: \n1 loops, best of 3: 280 ms per loop\n']], ['vectorize numpy unique for subarrays'], 6, 0], [(32390539, 0), [["Update . Let's look at your second attempt, the one that you say has worked. You have:"], ['Presumably this is in some partial (say  _index.html ). A view that has  py_fn  in scope, loads  _index.html , evaluates the string "py_fn(\'some_string\')", and replaces  {{ py_fn(\'some_string\') }}  with the result of that evaluation. Let\'s say  py_fn  is the identity function on strings: it\'s a unary function that takes a string and immediately returns it. Then, the result of evaluating "py_fn(\'some_string\')" will be the string  \'some_string\' , which will be substituted back, obtaining the final, so-called "rendered" template:']], [[' <body>\n    <button onclick="js_fn(\'{{ py_fn(\'some_string\') }}\')">Click me</button>\n    <script>\n        function js_fn(variable) {\n            alert(variable);\n        }\n    </script>\n</body>\n']], ['How to pass javascript variable to macros in jinja2 template'], 2, 0], [(32403846, 0), [['Just split on the colon then map the rest to int after splitting on a comma:'], ['Output:']], [[' with open("in.txt") as f:\n    for line in f:\n        a, rest = line.split(":",1)\n        print([a] + map(int,rest.split(",")))\n']], ['List Comprehensions - How to have strings and integers in one list?'], 2, 1], [(32403846, 1), [['Output:'], ['-10000']], [[" ['min', 1, 2, 3, 5, 6]\n['max', 1, 2, 3, 5, 6]\n['avg', 1, 2, 3, 5, 6]\n"]], ['List Comprehensions - How to have strings and integers in one list?'], 2, 0], [(32424555, 1), [["re.split  doesn't split on empty string match."], ['-10000']], [[" >>> re.split('', 'abcabc')\n['abcabc']\n"]], ['Python-Getting contents between current and next occurrence of pattern in a string'], 5, 0], [(32424555, 2), [['-10000'], ['-10000']], [[" >>> re.split(r'(.)(?!\\1)', 'aaaaaakkkkkkbbbbbsssss')\n['aaaaa', 'a', 'kkkkk', 'k', 'bbbb', 'b', 'ssss', 's', '']\n"]], ['Python-Getting contents between current and next occurrence of pattern in a string'], 5, 0], [(32424555, 4), [['Sample run:'], ["(In the last example,  (?<=(.))(?!\\1)  matches the empty string at the end of the string, so  'kkkkkkk'  is included in the list of results)"]], [[" >>> findbetween('abc', 'abcabcabcabc')\n['', '', '']\n>>> findbetween(r'', 'abcdef')\n['a', 'b', 'c', 'd', 'e', 'f']\n>>> findbetween(r'ab', 'abcabcabc')\n['c', 'c']\n>>> findbetween(r'b', 'abcabcabc')\n['ca', 'ca']\n>>> findbetween(r'(?<=(.))(?!\\1)', 'aaaaaaaaaaaabbbbbbbbbbbbkkkkkkk')\n['bbbbbbbbbbbb', 'kkkkkkk']\n"]], ['Python-Getting contents between current and next occurrence of pattern in a string'], 5, 0], [(32458370, 1), [['Note that it is more pythonic use  property  objects instead of explicit getters and setters:'], ['then use']], [[' class Palette(list):\n    def __init__(self, name=None, description=None, colors=None, *args):\n        super(Palette, self).__init__(args)   \n        self.name = name\n        self.description = description\n        self.extend(colors)\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        self._name = name\n\n    @name.deleter\n    def name(self):\n        self.name = None\n\n    @property\n    def description(self):\n        return self._description\n\n    @description.setter\n    def description(self, description):\n        self._description = description\n\n    @description.deleter\n    def description(self):\n        self.description = None\n']], ['How can a class that inherits from list and uses keyword arguments be made to work in both Python 2 and Python 3?'], 7, 0], [(32458370, 2), [['then use'], ["Note that in both Python 2 and Python 3, you cannot pass in positional arguments; the following doesn't work:"]], [[' palette1.description = "This is palette 1."\n']], ['How can a class that inherits from list and uses keyword arguments be made to work in both Python 2 and Python 3?'], 7, 0], [(32458370, 3), [["Note that in both Python 2 and Python 3, you cannot pass in positional arguments; the following doesn't work:"], ['because the first positional argument will be assigned to the  name  argument:']], [[" Palette('#F1E1BD', '#EEBA85', name='palette2')\n"]], ['How can a class that inherits from list and uses keyword arguments be made to work in both Python 2 and Python 3?'], 7, 0], [(32458370, 4), [['because the first positional argument will be assigned to the  name  argument:'], ['To support that use case, you need to  not  name the keyword arguments in the signature, and only use  **kwargs , then retrieve your keyword arguments from that. Pass in any positional arguments as  one argument  so that  list()  takes any number of positional arguments as the contents for the new list:']], [[' >>> Palette(\'#F1E1BD\', \'#EEBA85\', name=\'palette2\')\nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\nTypeError: __init__() got multiple values for argument \'name\'\n']], ['How can a class that inherits from list and uses keyword arguments be made to work in both Python 2 and Python 3?'], 7, 0], [(32458370, 5), [['To support that use case, you need to  not  name the keyword arguments in the signature, and only use  **kwargs , then retrieve your keyword arguments from that. Pass in any positional arguments as  one argument  so that  list()  takes any number of positional arguments as the contents for the new list:'], ['Demo:']], [[" class Palette(list):\n    def __init__(self, *args, **kwargs):\n        super(Palette, self).__init__(args)\n        self.name = kwargs.pop('name', None)\n        self.description = kwargs.pop('description', None)\n        self.extend(kwargs.pop('colors', []))\n        if kwargs:\n            raise TypeError('{} does not take {} as argument(s)'.format(\n                type(self).__name__, ', '.join(kwargs)))\n"]], ['How can a class that inherits from list and uses keyword arguments be made to work in both Python 2 and Python 3?'], 7, 0], [(32471239, 0), [['Try something like this.'], ['After this you should now be able to use the objects in your html.']], [[" def listallcams():\n   camtab = SVSIpCamReg.query.filter_by(u_id = current_user.id).all()\n   for rec in camtab:\n      dkey = rec.key\n      bdkey=bytes(dkey)\n      f = Fernet(bdkey)\n      bcamurl = bytes(rec.camurl_hash)\n      camurl =f.decrypt(bcamurl)\n      rec.camurl = camurl\n   return render_template('cam/viewallcam.html',allcam = camtab)\n"]], ['How to loop through object return by SQLALchemy and process each row and display it to HTML'], 2, 1], [(32471239, 1), [['After this you should now be able to use the objects in your html.'], ['-10000']], [[' {% for cam in allcam %}\n   <p>{{ cam.camurl }}</p>\n   <p>{{ cam.sitename }}</p>\n{% endfor %}\n']], ['How to loop through object return by SQLALchemy and process each row and display it to HTML'], 2, 0], [(32480553, 0), [['There might be a faster, but this do the work:'], ['will print:']], [[' import numpy as np\n\nC = [[1,1], [10,10]]\nX = [[1,2], [1,3], [2,1], [10,11], [10,12], [11,11], [12,11], [9,11]]\n\ndef F(C,X):\n    Carr = np.array(C)\n    Xarr = np.array(X)\n    distances = [np.sum( (Xarr - Carr[i])**2, axis=1) for i in range(len(C))]\n    closests = np.argmin( np.array(distances), axis=0 )\n    return list( np.bincount(closests) )\n\nprint(F(C,X))\n']], ['finding nearest points in python'], 2, 1], [(32480553, 1), [['will print:'], ['-10000']], [[' [3, 5]\n']], ['finding nearest points in python'], 2, 0], [(32497161, 0), [['Just pass  nrows=1  and then get the columns:'], ['Example:']], [[' pd.read_csv(file_path, nrows=1).columns\n']], ['take column headers only from ASCII file in python'], 2, 1], [(32497161, 1), [['Example:'], ['You can ignore the  io  bit, and you may need to modify the  read_csv  params depending on your file path and separator character']], [[' In [83]:\nimport io\nimport pandas as pd\nt="""index,col1,col2,col3\n0,1,2,3"""\npd.read_csv(io.StringIO(t), nrows=1).columns\n\nOut[83]:\nIndex([\'index\', \'col1\', \'col2\', \'col3\'], dtype=\'object\')\n']], ['take column headers only from ASCII file in python'], 2, 1], [(32537153, 0), [["You create first the HTML of the document, this is a template it won't move, so you only have to do it once, here is a basic template:"], ['This script will write a file called  input.html  with the the  {{ text }}  area replaced by content of the text file. Mind the fact that you can add support for bold, italic even tables using markdown.']], [[' <html>\n  <body>\n    <h1>Trademark</h1>\n    <div id="container">\n      <div id="photos">\n        <img src="photo.jpg">\n      </div>\n      <div id="text">\n        {{ text }}\n      </div>\n    </div>\n  </body>\n</html>\n']], ['Assistance on automated image/text Document'], 3, 0], [(32537153, 1), [['This script will write a file called  input.html  with the the  {{ text }}  area replaced by content of the text file. Mind the fact that you can add support for bold, italic even tables using markdown.'], ['Once you have a  photo.jpg  and the text you can execute the above script followed by the following command:']], [[" with open('card.html') as f:\n    card = f.read()\n\nwith open('text.txt') as f:\n    text = f.read()\n\nwith open('input.html', 'w') as f:\n    f.write(card.replace('{{ text }}', text))\n"]], ['Assistance on automated image/text Document'], 3, 0], [(32537153, 2), [['Once you have a  photo.jpg  and the text you can execute the above script followed by the following command:'], ['This will generate something similar to:']], [['  weasyprint -f png -s styles.css input.html output.png\n']], ['Assistance on automated image/text Document'], 3, 0], [(32623285, 0), [['Okay. Try doing something like this.'], ["Don't know what's wrong with  CrawlSpider  but  Spider  could work anyway."]], [[" def start_requests(self):\n    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36'}\n    for i,url in enumerate(self.start_urls):\n        yield Request(url,cookies={'over18':'1'}, callback=self.parse_item, headers=headers)\n"]], ['How to send cookie with scrapy CrawlSpider requests?'], 2, 0], [(32623285, 1), [["Don't know what's wrong with  CrawlSpider  but  Spider  could work anyway."], ['-10000']], [[' #!/usr/bin/env python\n# encoding: utf-8\nimport scrapy\n\n\nclass MySpider(scrapy.Spider):\n    name = \'redditscraper\'\n    allowed_domains = [\'reddit.com\', \'imgur.com\']\n    start_urls = [\'https://www.reddit.com/r/nsfw\']\n\n    def request(self, url, callback):\n        """\n         wrapper for scrapy.request\n        """\n        request = scrapy.Request(url=url, callback=callback)\n        request.cookies[\'over18\'] = 1\n        request.headers[\'User-Agent\'] = (\n            \'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, \'\n            \'like Gecko) Chrome/45.0.2454.85 Safari/537.36\')\n        return request\n\n    def start_requests(self):\n        for i, url in enumerate(self.start_urls):\n            yield self.request(url, self.parse_item)\n\n    def parse_item(self, response):\n        titleList = response.css(\'a.title\')\n\n        for title in titleList:\n            item = {}\n            item[\'url\'] = title.xpath(\'@href\').extract()\n            item[\'title\'] = title.xpath(\'text()\').extract()\n            yield item\n        url = response.xpath(\'//a[@rel="nofollow next"]/@href\').extract_first()\n        if url:\n            yield self.request(url, self.parse_item)\n        # you may consider scrapy.pipelines.images.ImagesPipeline :D\n']], ['How to send cookie with scrapy CrawlSpider requests?'], 2, 1], [(32625593, 0), [['First point: a python  db-api.cursor  is an iterator, so unless you really  need  to load a whole batch in memory at once, you can just start with using this feature, ie instead of:'], ['you could just:']], [[' cursor.execute("SELECT * FROM mytable")\nrows = cursor.fetchall()\nfor row in rows:\n   do_something_with(row)\n']], ['Retrieving Data from MySQL in batches via Python'], 3, 0], [(32652039, 0), [["I've coded something for you. It extracts all the videos from POPSCI episodes pages:"], ['This code works for any POPSCI episodes page, try changing POPSCI_URL to...']], [[' import re\nimport requests\nfrom lxml import html\n\ndef getVideosLinks(content):\n    videos = re.findall(\'(http://[\\.\\w/_]+\\.mp[34])\', content)\n    return videos\n\ndef prepareJSONurl(episode_hash):\n    json_url = "http://pepto.portico.net2.tv/playlist/{hash}".format(hash=episode_hash)\n    return json_url\n\ndef extractEpisodeHash(content):\n    tree = html.fromstring(content)\n    video_url = tree.xpath(\'//meta[contains(@http-equiv, "refresh")]/@content\')[0].split(\'=\',1)[1]\n    episode_hash = re.findall(\'episode=([\\w]+)\', video_url)\n    return episode_hash[0]\n\ndef extractIframeURL(content):\n    iframe_url = None\n    tree = html.fromstring(content)\n    try:\n        iframe_url = tree.xpath(\'//iframe/@src\')[0]\n        is_video = True\n    except:\n        is_video = False\n    return is_video, iframe_url\n\n\nPOPSCI_URL = "http://www.popsci.com/thorium-dream"\n\nresponse = requests.get(POPSCI_URL)\nis_video, iframe_url = extractIframeURL(response.content)\n\nif is_video:\n    response_from_iframe_url = requests.get(iframe_url)\n    episode_hash = extractEpisodeHash(response_from_iframe_url.content)\n\n    json_url = prepareJSONurl(episode_hash)\n    final_response = requests.get(json_url)\n\n    for video in getVideosLinks(final_response.content):\n        print "Video: {}".format(video)\nelse:\n    print "This is not a POPSCI video page :|"\n']], ['How to scrape the video src url from video tag which is injected via javascript?'], 3, 1], [(32652039, 1), [['This code works for any POPSCI episodes page, try changing POPSCI_URL to...'], ['... and it will still work.']], [[' POPSCI_URL = "http://www.popsci.com/maker-faire-2015"\n']], ['How to scrape the video src url from video tag which is injected via javascript?'], 3, 0], [(32652039, 2), [['... and it will still work.'], ['Hope this helps']], [[' import re\nimport requests\n\ndef getVideosLinks(content):\n    videos = re.findall(\'(http://[\\.\\w/_]+\\.mp[34])\', content)\n    return videos\n\ndef prepareJSONurl(episode_hash):\n    json_url = "http://pepto.portico.net2.tv/playlist/{hash}".format(hash=episode_hash)\n    return json_url\n\ndef extractEpisodeHash(content):\n    episode_hash = re.findall(\'<meta http-equiv="refresh" content="0; url=http:\\/\\/player\\.net2\\.tv\\?episode=([\\w]+)&restart\', content)[0]\n    return episode_hash\n\ndef extractIframeURL(content):\n    iframe_url = None\n    try:\n        iframe_url = re.findall(\'<iframe src="(.*)" style\', content)[0]\n        is_video = True\n    except:\n        is_video = False\n    return is_video, iframe_url\n\n\nPOPSCI_URL = "http://www.popsci.com/thorium-dream"\n\nresponse = requests.get(POPSCI_URL)\nis_video, iframe_url = extractIframeURL(response.content)\n\nif is_video:\n    response_from_iframe_url = requests.get(iframe_url)\n    episode_hash = extractEpisodeHash(response_from_iframe_url.content)\n\n    json_url = prepareJSONurl(episode_hash)\n    final_response = requests.get(json_url)\n\n    for video in getVideosLinks(final_response.content):\n        print "Video: {}".format(video)\nelse:\n    print "This is not a POPSCI video page :|"\n']], ['How to scrape the video src url from video tag which is injected via javascript?'], 3, 1], [(32659345, 0), [['argparse.parse_args()  takes an iterable of strings; you are passing a single string. Try'], ['A string, being iterable itself, is treated like a list of the characters in the string. That is, ']], [[' def create():\n    author_parse = argparse.ArgumentParser()\n    author_parse.add_argument(\'name\', type=str, nargs=2)\n    name = raw_input("Provide your first and last name: ")\n    auth_args = auth_parse.parse_args(name.split())\n']], ['How to use argparse during runtime to conditionally get further input?'], 3, 1], [(32659345, 1), [['A string, being iterable itself, is treated like a list of the characters in the string. That is, '], ['produces the same result as ']], [[' auth_parse.parse_args("John Smith")\n']], ['How to use argparse during runtime to conditionally get further input?'], 3, 0], [(32659345, 2), [['produces the same result as '], ['-10000']], [[' auth_parse.parse_args(["J", "o", "h", "n", " ", "S", "m", "i", "t", "h"])\n']], ['How to use argparse during runtime to conditionally get further input?'], 3, 0], [(32665833, 0), [['Yes, there is a simple way, using  re.sub() :'], ['Demo:']], [[" result = re.sub(r'(\\d+)', r'[\\1]', inputstring)\n"]], ['Add [] around numbers in strings'], 2, 1], [(32665833, 1), [['Demo:'], ['-10000']], [[' >>> import re\n>>> inputstring = "pixel1blue pin10off output2high foo9182bar"\n>>> re.sub(r\'(\\d+)\', r\'[\\1]\', inputstring)\n\'pixel[1]blue pin[10]off output[2]high foo[9182]bar\'\n']], ['Add [] around numbers in strings'], 2, 1], [(32670153, 0), [['From the  documentation of the Variable Class , you can get a reference to the variable by name  or  by index:'], ['So in your case:']], [[" # Create a Variable object, specifying the variable by name\nvarObj = datasetObj.varlist['bdate']\n# Create a Variable object, specifying the variable by index\nvarObj = datasetObj.varlist[3]\n"]], ['How to find the index value of a variable in SPSS Python'], 3, 1], [(32670153, 1), [['So in your case:'], ['You can, if needed, get the index of the variable by its name,  using the  index  property :']], [[" varObj = datasetObj.varlist['ID']\n"]], ['How to find the index value of a variable in SPSS Python'], 3, 1], [(32670153, 2), [['You can, if needed, get the index of the variable by its name,  using the  index  property :'], ['-10000']], [[" varIndex = datasetObj.varlist['ID'].index\n"]], ['How to find the index value of a variable in SPSS Python'], 3, 1], [(32678322, 0), [['To  count the frequency of words in an array of strings , you can use  Counter  from  collections :'], ['-10000']], [[" In [89]: from collections import Counter\n\nIn [90]: s=r'So I have an array of words, stored as key value pairs. Now I am trying to count the frequency of words in an array of strings, tokens. I have tried the following but this doesnt find the index of x as it is only a string. I do not have the corresponding value, if any, of x in tokens array. Is there any way to directly access it rather than adding one more loop to find it first?'\n\nIn [91]: tokens=s.split()\n\nIn [92]: c=Counter(tokens)\n\nIn [93]: print c\nCounter({'of': 5, 'I': 4, 'the': 4, 'it': 3, 'have': 3, 'to': 3, 'an': 2, 'as': 2, 'in': 2, 'array': 2, 'find': 2, 'x': 2, 'value,': 1, 'words': 1, 'do': 1, 'there': 1, 'is': 1, 'am': 1, 'frequency': 1, 'if': 1, 'string.': 1, 'index': 1, 'one': 1, 'directly': 1, 'tokens.': 1, 'any': 1, 'access': 1, 'only': 1, 'array.': 1, 'way': 1, 'doesnt': 1, 'Now': 1, 'words,': 1, 'more': 1, 'a': 1, 'corresponding': 1, 'tried': 1, 'than': 1, 'adding': 1, 'strings,': 1, 'but': 1, 'tokens': 1, 'So': 1, 'key': 1, 'first?': 1, 'not': 1, 'trying': 1, 'pairs.': 1, 'count': 1, 'this': 1, 'Is': 1, 'value': 1, 'rather': 1, 'any,': 1, 'stored': 1, 'following': 1, 'loop': 1})\n\nIn [94]: c['of']\nOut[94]: 5\n"]], ['Updating a dict which is stored in an array'], 2, 1], [(32679481, 0), [["If you're OK with using plots instead of histograms, that's what you can do. "], ['If you want to make a plot look like a histogram you should do that:']], [[' import matplotlib.pyplot as plt\n\nlists = [data[project]["tweets"] for project in data] # Collect all lists into one\nsum_list = [sum(x) for x in zip(*lists)] # Create a list with sums of tweets for each day\n\nplt.plot(sum_list) # Create a plot for sum_list\nplt.show() # Show the plot\n']], ['How to plot histogram of multiple lists?'], 2, 1], [(32679481, 1), [['If you want to make a plot look like a histogram you should do that:'], ['instead of plt.plot.']], [[' plt.bar(range(0, len(sum_list)), sum_list)\n']], ['How to plot histogram of multiple lists?'], 2, 0], [(32687664, 0), [['You can create an intermediate dictionary of {category_name: dict} and then use update:'], ["But this isn't guaranteed to preserve the order of the lists. If order is important:"]], [[" temp = {a['category_name']: dict(a) for a in a_list}\nfor b in b_list:\n    temp[b['category_name']].update(b)\nc_list = list(temp.values())    # list() unnecessary in py2.X\n"]], ['Combine two lists which have the same item in dict'], 2, 1], [(32687664, 1), [["But this isn't guaranteed to preserve the order of the lists. If order is important:"], ['-10000']], [[" c_list = [temp[a['category_name']] for a in a_list]\n"]], ['Combine two lists which have the same item in dict'], 2, 0], [(32690945, 0), [['You are close in your fist code but you need to use  or  between conditions not objects, so you can change it to following :'], ['But instead of that you can use built-in function  any  :']], [[" with open('file_name') as f:\n    fi = f.read()\n    if 'string' in fi or 'string2' in fi or 'string3' in fi:\n"]], ['Filtering for multiple strings on f.read'], 3, 1], [(32690945, 1), [['But instead of that you can use built-in function  any  :'], ['And if you are dealing with a huge file instead of loading the whole of file content in memory you can check the existence of strings in each line with a function :']], [[" with open('file_name') as f:\n    fi = f.read()\n    if any(i in fi for i in word_set)\n"]], ['Filtering for multiple strings on f.read'], 3, 1], [(32690945, 2), [['And if you are dealing with a huge file instead of loading the whole of file content in memory you can check the existence of strings in each line with a function :'], ['-10000']], [[" def my_func(word_set):\n    with open('file_name') as f:\n        for line in f:\n            if any(i in line for i in word_set):\n                return True\n        return False\n"]], ['Filtering for multiple strings on f.read'], 3, 1], [(32700996, 0), [['numba  often works well for these type of problems. You could also a get a similar result with  cython  with more annotations.'], ['A bit verbose, but very fast.']], [[' @numba.jit(nopython=True)\ndef generate_values(mins, maxs, vals):\n    N = len(vals)\n    ans = np.empty(N)\n\n    for i in range(N):\n        for j in range(i, N):\n            if vals[j] < mins[i] or vals[j] > maxs[i]:\n                ans[i] = vals[j]\n                break\n        else:\n            ans[i] = np.nan\n    return ans\n']], ['Optimizing time series generation'], 2, 1], [(32700996, 1), [['A bit verbose, but very fast.'], ['-10000']], [[" In [278]: %%time\n     ...: LIMIT = len(df)\n     ...: for i in range(LIMIT):\n     ...:     df['shift'] = df['shift'].shift(-1)\n     ...:     df['result'].update(df['shift'][((df['shift'] < df['min']) | \\\n     ...:                                      (df['shift'] > df['max'])) & \\\n     ...:                                     (df['result'].isnull())])\nWall time: 62 ms\n\n\nIn [281]: %timeit generate_values(df['min'].values, df['max'].values, df['val'].values)\n10000 loops, best of 3: 20.6 µs per loop\n"]], ['Optimizing time series generation'], 2, 0], [(32719686, 1), [["My  ModelForm  now just needs to redefine the fields in question as  DenormalizedChoiceField .  I need to specify the choices explicitly, though, for some reason it doesn't pick this up from the model if you override the field."], ['-10000']], [[" class PersonForm(forms.ModelForm):\n    favorite_color = DenormalizedChoiceField(choices=Person.COLORS)\n    class Meta:\n        model = Person\n        fields = '__all__'\n"]], ['Importing Denormalized data into django models via modelforms'], 2, 0], [(32772190, 1), [['Output on your test matrix:'], ["Calling library functions like  find  can occasionally be useful, but it's also a habit from slower languages that's worth leaving behind. In julia, you can write your own loops and they will be fast; better yet, often the resulting algorithm is much easier to understand.  collect(zip(ind2sub(size(mat),find( x -> x == value, mat))...))  does not exactly roll off the tongue."]], [[' 2-element Array{Array{Int64,1},1}:\n [1,2,5,6] \n [16,19,20]\n']], ['How to find connected components in a matrix using Julia'], 2, 0], [(32792411, 0), [["You can use  itertools.product .  For example, let's define the preliminaries:"], ["Now, let's compute the result:"]], [[" >>> import itertools\n>>> s = 'kfc'\n>>> d = {'k':'1', 'c':'3'}\n"]], ['Get ALL results of a word mapping with a dictionary'], 5, 0], [(32792411, 1), [["Now, let's compute the result:"], ['-10000']], [[" >>> [ ''.join(x) for x in itertools.product( *[(c, d.get(c)) if d.get(c) else c for c in s] ) ]\n['kfc', 'kf3', '1fc', '1f3']\n"]], ['Get ALL results of a word mapping with a dictionary'], 5, 1], [(32792411, 2), [['-10000'], ['Next, we use itertools to create all the possible products:']], [[" >>> [(c, d.get(c)) if d.get(c) else c for c in s]\n[('k', '1'), 'f', ('c', '3')]\n"]], ['Get ALL results of a word mapping with a dictionary'], 5, 0], [(32792411, 3), [['Next, we use itertools to create all the possible products:'], ["The above has the answers that we need.  We just need to re-assemble the strings using  ''.join :"]], [[" >>> list( itertools.product( *[(c, d.get(c)) if d.get(c) else c for c in s] ) )\n[('k', 'f', 'c'), ('k', 'f', '3'), ('1', 'f', 'c'), ('1', 'f', '3')]\n"]], ['Get ALL results of a word mapping with a dictionary'], 5, 0], [(32798908, 0), [['-10000'], ['We define a function  some_function  having arguments as the keys of the dictionary. We call this function and pass it the dictionary  dct  using  **kwargs  option. This will give us access to the keys  key1  and  key2  as variables inside that function.']], [[" In [1]: dct = {'key1': 1, 'key2': 2}\n\nIn [2]: vars().update(dct) # creates variables with name as keys and value as their corresponding value of 'dct' dictionary\n\nIn [3]: key1 # access 'key1' as variable\nOut[3]: 1\n\nIn [4]: key2 # access 'key2' as variable\nOut[4]: 2\n"]], ['Dictionary items to variables'], 2, 1], [(32798908, 1), [['We define a function  some_function  having arguments as the keys of the dictionary. We call this function and pass it the dictionary  dct  using  **kwargs  option. This will give us access to the keys  key1  and  key2  as variables inside that function.'], ['-10000']], [[" In [1]: dct = {'key1': 1, 'key2': 2}\n\nIn [2]: def some_func(key1, key2): # define keys as function parameters\n   ...:     print key1 # print value of variable 'key1'\n   ...:     print key2 # print value of variable 'key2'\n   ...:  \n\nIn [3]: some_func(**dct) # pass 'dct' dictionary using '**kwargs'\n1 # Value of variable 'key1'\n2 # Value of variable 'key2'\n"]], ['Dictionary items to variables'], 2, 1], [(32802833, 0), [["I don't think that there is a pythonic™ way to solve the question. But in my code it's quite a common situation, so I've written my own function for that:"], ['In your case I would use it the following way:']], [[' def applyfs(funcs, args):\n    """\n    Applies several functions to single set of arguments. This function takes\n    a list of functions, applies each to given arguments, and returns the list\n    of obtained results. For example:\n\n        >>> from operator import add, sub, mul\n        >>> list(applyfs([add, sub, mul], (10, 2)))\n        [12, 8, 20]\n\n    :param funcs: List of functions.\n    :param args:  List or tuple of arguments to apply to each function.\n    :return:      List of results, returned by each of `funcs`.\n    """\n    return map(lambda f: f(*args), funcs)\n']], ['Selecting a subset of functions from a list of functions in python'], 3, 1], [(32802833, 1), [['In your case I would use it the following way:'], ['Or possibly, it would be more pythonic to use list comprehension instead of  map :']], [[' applyfs([mean, std, var, fxn4 ...], mylist)\n']], ['Selecting a subset of functions from a list of functions in python'], 3, 0], [(32821122, 0), [['You can use the  make_aware  function from django on your naive datetime objects. You will then have to specify the time zone of your naive timestamps.'], ['On the other hand, you could also use the  make_naive  function to remove the timezone information from your now() timestamp:']], [[" now_ts = datetime.now(pytz.timezone('Europe/Istanbul'))\nnow_ts > make_aware(campaingObject.publish_end, pytz.timezone('Europe/Istanbul'))\n"]], ['How to make a time object TZ aware without changing the value?'], 2, 1], [(32821122, 1), [['On the other hand, you could also use the  make_naive  function to remove the timezone information from your now() timestamp:'], ['https://docs.djangoproject.com/en/1.8/ref/utils/#django.utils.timezone.make_naive']], [[" now_ts = datetime.now(pytz.timezone('Europe/Istanbul'))\nnow_naive = make_naive(now_ts, pytz.timezone('Europe/Istanbul'))\nnow_naive > campaingObject.publish_end\n"]], ['How to make a time object TZ aware without changing the value?'], 2, 1], [(32896987, 2), [['a1  is a view, as shown by the data buffer pointer'], ['The sum']], [[" In [507]: a1.__array_interface__['data']\nOut[507]: (164774704, False)\nIn [508]: a.__array_interface__['data']\nOut[508]: (164774704, False)\n"]], ['numpy tile without memory allocation'], 5, 0], [(32896987, 3), [['The sum'], ['a1  has, effectively, been tiled without copying']], [[' In [509]: a1+b1\nOut[509]: \narray([[ 2.04663934,  1.02951915,  1.30616273,  1.75154236],\n       [ 1.79237632,  1.08252741,  1.17031265,  1.2675438 ]])\n']], ['numpy tile without memory allocation'], 5, 0], [(32896987, 4), [['a1  has, effectively, been tiled without copying'], ["Look at the  np.lib.stride_tricks.py  file for more details on this sort of broadcasting.   np.lib.stride_tricks.as_strided  is the underlying function that lets you construct a view with new shape and strides.  It's been used most often on SO to construct sliding windows."]], [[' In [511]: a1.shape\nOut[511]: (2, 4)\nIn [512]: a1.strides\nOut[512]: (0, 8)\n']], ['numpy tile without memory allocation'], 5, 0], [(32900442, 1), [['The above is doing  matrix[i] * points[i]  (i.e. multiplying on the right), but I just reread the question and noticed that your code uses  points[i] * matrix[i] .  You can do that by switching the indices and arguments of  einsum :'], ['-10000']], [[" In [76]: lp = np.einsum('ij,ijk->ik', points, matrices)\n\nIn [77]: lp[0]\nOut[77]: array([ 1.39510822,  1.12011057,  1.05704609])\n\nIn [78]: points[0].dot(matrices[0])\nOut[78]: array([ 1.39510822,  1.12011057,  1.05704609])\n\nIn [79]: lp[1]\nOut[79]: array([ 0.49750324,  0.70664634,  0.7142573 ])\n\nIn [80]: points[1].dot(matrices[1])\nOut[80]: array([ 0.49750324,  0.70664634,  0.7142573 ])\n"]], ['Large point-matrix array multiplication in numpy'], 2, 1], [(32902648, 0), [["This seems to be a case for the union-find, or  disjoint-set  algorithm. Here's an implementation I use to keep in my toolbox:"], ['And here how to apply it to your data:']], [[' from collections import defaultdict\n\nclass UnionFind:\n    def __init__(self):\n        self.leaders = defaultdict(lambda: None)\n\n    def find(self, x):\n        l = self.leaders[x]\n        if l is not None:\n            l = self.find(l)\n            self.leaders[x] = l\n            return l\n        return x\n\n    def union(self, x, y):\n        lx, ly = self.find(x), self.find(y)\n        if lx != ly:\n            self.leaders[lx] = ly\n\n    def get_groups(self):\n        groups = defaultdict(set)\n        for x in self.leaders:\n            groups[self.find(x)].add(x)\n        return groups\n']], ['Python list comparison to create trees'], 3, 0], [(32902648, 1), [['And here how to apply it to your data:'], ['Output is:']], [[' # parse data\ndata = """Group  Item-1  Item-2\n0       7       13\n0      10        4\n1       2        8\n1       3        1\n1       4        3\n1       6       28\n1       8        6"""\ndata = [[int(x) for x in line.split()] for line in data.splitlines()[1:]]\n\n# get mapping {group_number: [list of pairs]}\ngroups = defaultdict(list)\nfor g, x, y in data:\n    groups[g].append((x, y))\n\n# for each group, add pairs to union find structure and get groups\nfor group, links in groups.items():\n    union = UnionFind()\n    for x, y in links:\n        union.union(x, y)\n    print group, union.get_groups().values()\n']], ['Python list comparison to create trees'], 3, 0], [(32902648, 2), [['Output is:'], ['-10000']], [[' 0 [set([10, 4]), set([13, 7])]\n1 [set([1, 3, 4]), set([8, 2, 28, 6])]\n']], ['Python list comparison to create trees'], 3, 0], [(32907015, 0), [['First lets define some helpers:'], ['and create an example RDD:']], [[' def swap(x):\n    """Given a tuple (x1, x2) return (x2, 1)"""\n    return (x[1], 1)\n\ndef filter_source(x):\n    """Check if s1 < s2 in (x, (s1, s2))"""\n    return x[1][0] < x[1][1]\n\ndef reshape(kv):\n    """Reshape ((k1, k2), v) to get final result"""\n    ((k1, k2), v) = kv\n    return (k1, (k2, v))\n']], ['Alternatives to cartesian in Spark?'], 3, 0], [(32907015, 1), [['and create an example RDD:'], ['Finally you can do something like this:']], [[' rdd = sc.parallelize([\n    (1, [3, 10, 11]), (2, [3, 4, 10, 11]),\n    (3, [1, 4]), (4, [2, 3, 10])])\n']], ['Alternatives to cartesian in Spark?'], 3, 0], [(32907015, 2), [['Finally you can do something like this:'], ['-10000']], [[' from operator import add\n\nflattened = rdd.flatMap(lambda kv: ((v, kv[0]) for v in kv[1])) # Flatten input\nflattened.first()\n# (1, 3) <- from (3, [1, 4])\n\nresult = (flattened \n    .join(flattened) # Perform self join using value from input as key\n    .filter(filter_source) # Remove pairs from the same source\n    .map(swap)\n    .reduceByKey(add)\n    .map(reshape)) # Get final output\n']], ['Alternatives to cartesian in Spark?'], 3, 0], [(32910848, 1), [['and then simply type:'], ['each time to use it.']], [[' simple()\n']], ['A simple looping command In Python'], 2, 0], [(32921049, 0), [['The  csv  module will add  "..."  quotes around values that contain the separator, so in principle you don\'t need to replace the  |  pipe symbols in the values. To replace the original file, write to a new (temporary) outputfile then move that back into place.'], ['For an input file containing:']], [[" import csv\nimport os\n\noutputfile = inputfile + '.tmp'\nwith open(inputfile, 'rb') as inf, open(outputfile, 'wb') as outf:\n    reader = csv.reader(inf)\n    writer = csv.writer(outf, delimiter='|')\n    writer.writerows(reader)\nos.remove(inputfile)\nos.rename(outputfile, inputfile)\n"]], ['Pipe delimiter file, but no pipe inside data'], 5, 1], [(32921049, 1), [['For an input file containing:'], ['this produces']], [[' foo,bar|baz,spam\n']], ['Pipe delimiter file, but no pipe inside data'], 5, 0], [(32921049, 2), [['this produces'], ['If you do need to replace the  |  characters in the values, you can do so as you copy the rows:']], [[' foo|"bar|baz"|spam\n']], ['Pipe delimiter file, but no pipe inside data'], 5, 0], [(32921049, 4), [['Now the output for my example becomes:'], ['-10000']], [[' foo|bar baz|spam\n']], ['Pipe delimiter file, but no pipe inside data'], 5, 0], [(32935232, 0), [['Visit all nested values recursively:'], ["In some cases it's desired to  modify  the original dict object (to avoid re-creating it):"]], [[" import collections\n\ndef map_nested_dicts(ob, func):\n    if isinstance(ob, collections.Mapping):\n        return {k: map_nested_dicts(v, func) for k, v in ob.iteritems()}\n    else:\n        return func(ob)\n\nmap_nested_dicts(x, lambda v: v + 7)\n# Creates a new dict object:\n#    {'a': 8, 'b': {'c': 13, 'g': {'h': 10, 'i': 16}, 'd': 14}, 'e': {'f': 10}}\n"]], ['Python: Apply function to values in nested dictionary'], 2, 1], [(32935232, 1), [["In some cases it's desired to  modify  the original dict object (to avoid re-creating it):"], ["If you're using Python 3:"]], [[" import collections\n\ndef map_nested_dicts_modify(ob, func):\n    for k, v in ob.iteritems():\n        if isinstance(v, collections.Mapping):\n            map_nested_dicts_modify(v, func)\n        else:\n            ob[k] = func(v)\n\nmap_nested_dicts_modify(x, lambda v: v + 7)\n# x is now\n#    {'a': 8, 'b': {'c': 13, 'g': {'h': 10, 'i': 16}, 'd': 14}, 'e': {'f': 10}}\n"]], ['Python: Apply function to values in nested dictionary'], 2, 1], [(32935585, 0), [['When rendering the form for the delete view, you can add a hidden form element named  next :'], ['Then in your route:']], [[' <form ...>\n    <input type="hidden" name="next" value="{{ request.path }}">\n    ...\n</form>\n']], ['Returning user to referrer in flask in smartest pythonic way'], 2, 0], [(32935585, 1), [['Then in your route:'], ['Note: your redirect handling should take care to prevent the next parameter from being an absolute URL to an arbitrary site (see  https://www.owasp.org/index.php/Open_redirect ).']], [[" ...\nreturn redirect(request.form.get('next', '/'))\n"]], ['Returning user to referrer in flask in smartest pythonic way'], 2, 0], [(32940738, 0), [['-10000'], ["It dynamically builds a query that'll fetch the objects whose  name  starts with  1.01  or  1.02 :"]], [[" >>> from django.db.models import Q\n\n>>> values = ['1.01', '1.02']\n\n>>> query = Q()\n>>> for value in values:\n...     query |= Q(name__startswith=value)\n\n>>> Inventary.objects.filter(query)\n"]], ['Filtering in Django by a set of String'], 2, 1], [(32940738, 1), [["It dynamically builds a query that'll fetch the objects whose  name  starts with  1.01  or  1.02 :"], ['-10000']], [[" >>> Inventary.objects.filter(Q(name__startswith='1.01') | Q(name__startswith='1.02'))\n"]], ['Filtering in Django by a set of String'], 2, 1], [(32946908, 0), [['Hope I understood the question correctly. After grouping both groups as you did:'], ["You can update the columns' names for both groups:"]], [[" MvT101group = MvT101.groupby('Order',sort=True).sum()\nMvT102group = MvT102.groupby('Order',sort=True).sum()\n"]], ['How should I subtract two dataframes and in Pandas and diplay the required output?'], 4, 0], [(32946908, 1), [["You can update the columns' names for both groups:"], ['Then merge all 3 tables so that you will have all 3 columns in the main table:']], [[" MvT101group.columns = MvT101group.columns.map(lambda x: str(x) + '_101')\nMvT102group.columns = MvT102group.columns.map(lambda x: str(x) + '_102')\n"]], ['How should I subtract two dataframes and in Pandas and diplay the required output?'], 4, 0], [(32946908, 2), [['Then merge all 3 tables so that you will have all 3 columns in the main table:'], ['And then you can add the calculated column:']], [[" df = df.merge(MvT101group, left_on=['Order'], right_index=True, how='left')\ndf = df.merge(MvT102group, left_on=['Order'], right_index=True, how='left')\n"]], ['How should I subtract two dataframes and in Pandas and diplay the required output?'], 4, 0], [(32946908, 3), [['And then you can add the calculated column:'], ['-10000']], [[" df['calc'] = (df['Order_101']-df['Order_102']) / 100\n"]], ['How should I subtract two dataframes and in Pandas and diplay the required output?'], 4, 0], [(32953680, 1), [['I just did this, that would give you the mean (or anything you need) of every subgroup. '], ['-10000']], [[" for z in range(len(results)):\n    sub =  df.iloc[results[z]]\n    print sub['three'].mean()  \n"]], ['Get statistics from subgroups in pandas'], 2, 1], [(32966627, 0), [['-10000'], ['is equivalent to']], [[" np.einsum('nr,mr,lr->nml', A, B, C)\n"]], ['Matrix triple product with theano'], 3, 1], [(32966627, 1), [['is equivalent to'], ['which can be implemented in Theano as']], [[' np.dot(A[:, None, :] * B[None, :, :], C.T)\n']], ['Matrix triple product with theano'], 3, 1], [(32966627, 2), [['which can be implemented in Theano as'], ['-10000']], [[' theano.dot(A[:, None, :] * B[None, :, :], C.T)\n']], ['Matrix triple product with theano'], 3, 1], [(32975636, 0), [['test.py'], ['spark-shell (scala)']], [[' #!/usr/bin/python\n\nimport sys\n\nfor line in sys.stdin:\n  print "hello " + line\n']], ['How to Use both Scala and Python in a same Spark project?'], 2, 0], [(32975636, 1), [['spark-shell (scala)'], ['Output']], [[' val data = List("john","paul","george","ringo")\n\nval dataRDD = sc.makeRDD(data)\n\nval scriptPath = "./test.py"\n\nval pipeRDD = dataRDD.pipe(scriptPath)\n\npipeRDD.foreach(println)\n']], ['How to Use both Scala and Python in a same Spark project?'], 2, 0], [(32981875, 0), [['Something like this should work:'], ["If you prefer only single pass and don't care about introduced zeros you can modify above code like this:"]], [[' from pyspark.mllib.linalg import Vectors, SparseVector, DenseVector\nimport numpy as np\n\ndef add(v1, v2):\n    """Add two sparse vectors\n    >>> v1 = Vectors.sparse(3, {0: 1.0, 2: 1.0})\n    >>> v2 = Vectors.sparse(3, {1: 1.0})\n    >>> add(v1, v2)\n    SparseVector(3, {0: 1.0, 1: 1.0, 2: 1.0})\n    """\n    assert isinstance(v1, SparseVector) and isinstance(v2, SparseVector)\n    assert v1.size == v2.size \n    # Compute union of indices\n    indices = set(v1.indices).union(set(v2.indices))\n    # Not particularly efficient but we are limited by SPARK-10973\n    # Create index: value dicts\n    v1d = dict(zip(v1.indices, v1.values))\n    v2d = dict(zip(v2.indices, v2.values))\n    zero = np.float64(0)\n    # Create dictionary index: (v1[index] + v2[index])\n    values =  {i: v1d.get(i, zero) + v2d.get(i, zero)\n       for i in indices\n       if v1d.get(i, zero) + v2d.get(i, zero) != zero}\n\n    return Vectors.sparse(v1.size, values)\n']], ['How to add two Sparse Vectors in Spark using Python'], 4, 1], [(32981875, 1), [["If you prefer only single pass and don't care about introduced zeros you can modify above code like this:"], ['If you want you can try monkey patch  SparseVector :']], [[' from collections import defaultdict\n\ndef add(v1, v2):\n    assert isinstance(v1, SparseVector) and isinstance(v2, SparseVector)\n    assert v1.size == v2.size\n    values = defaultdict(float) # Dictionary with default value 0.0\n    # Add values from v1\n    for i in range(v1.indices.size):\n        values[v1.indices[i]] += v1.values[i]\n    # Add values from v2\n    for i in range(v2.indices.size):\n        values[v2.indices[i]] += v2.values[i]\n    return Vectors.sparse(v1.size, dict(values))\n']], ['How to add two Sparse Vectors in Spark using Python'], 4, 1], [(32981875, 3), [['Alternatively you should be able to use  scipy.sparse . '], ['-10000']], [[' from scipy.sparse import csc_matrix\nfrom pyspark.mllib.regression import LabeledPoint\n\nm1 = csc_matrix((\n   v1.values,\n   (v1.indices, [0] * v1.numNonzeros())),\n   shape=(v1.size, 1))\n\nm2 = csc_matrix((\n   v2.values,\n   (v2.indices, [0] * v2.numNonzeros())),\n   shape=(v2.size, 1))\n\nLabeledPoint(0, m1 + m2)\n']], ['How to add two Sparse Vectors in Spark using Python'], 4, 1], [(32998355, 0), [['IIUC you can just call  apply  and pass  value_counts :'], ['As @DSM has pointed out if you have columns with all  True / False  then it will insert  NaN  for the non-existing values in which case you can call  fillna(0)  like so:']], [[" In [13]:\ndf.ix[:,:'q3'].apply(pd.Series.value_counts)\n\nOut[13]:\n       q1  q2  q3\nTrue    4   3   4\nFalse   2   3   2\n"]], ['Pandas: Dealing with Boolean in Pivot Table'], 2, 1], [(33003547, 0), [['First, create a multi-indexed dataframe:'], ['For me, the easiest way to slice this type of dataframe is to use a combination of  .loc  and  IndexSlice .  So, to slice the above df where  i2=3  and  i3=5 :']], [[" df = pd.DataFrame({'i1': [1, 1, 1, 1], 'i2': [2, 2, 3, 3], 'i3': [4, 5, 4, 5], 'v1': [10] * 4, 'v2': [20] * 4}).set_index(['i1', 'i2', 'i3'])\n>>> df\n          v1  v2\ni1 i2 i3        \n1  2  4   10  20\n      5   10  20\n   3  4   10  20\n      5   10  20\n"]], ['How to filter through pandas pivot table'], 2, 0], [(33003547, 1), [['For me, the easiest way to slice this type of dataframe is to use a combination of  .loc  and  IndexSlice .  So, to slice the above df where  i2=3  and  i3=5 :'], ['The  :  inside  IndexSlice  signifies to select all rows of  i1 .  The very last  :  inside the  loc  function signifies to select all columns in the dataframe ( v1  and  v2 ).']], [[' >>> df.loc[pd.IndexSlice[:, 3, 5], :]\n\n          v1  v2\ni1 i2 i3        \n1  3  5   10  20\n']], ['How to filter through pandas pivot table'], 2, 0], [(33010861, 0), [['This is because  list  is not hashable.\nYou need to convert the elements of your  list  in  tuples  (which are hashable) before applying  set() .'], ['Updated  with your new data:']], [[' >>> my_list = [[1, 2], [1, 2], [3, 4]]\n>>> result = [list(el) for el in set(tuple(el) for el in my_list)]\n[[1, 2], [3, 4]]\n']], ['Removing repetitive lists in a list of list'], 2, 1], [(33010861, 1), [['Updated  with your new data:'], ['-10000']], [[' >>> [list(list(y) for y in el) \n        for el in set([tuple(tuple(x) for x in el) for el in my_list])]\n\n[[[26, 28, 80.0], [25, 40, 80.0]],\n [[10, 12, 80.0]],\n [[40, 42, 80.0], [40, 41, 80.0]],\n [[44, 45, 80.0]],\n [[5, 10, 80.0], [6, 9, 80.0], [5, 8, 80.0]],\n [[22, 24, 80.0]],\n [[14, 16, 80.0], [13, 20, 81.0]],\n [[2, 5, 71.1], [1, 3, 70.0]]]\n']], ['Removing repetitive lists in a list of list'], 2, 1], [(33019600, 0), [['For example'], ['However that gets kind of long so I would use a regex, for example:']], [[' elem = browser.find_elements_by_tag_name("option") \nfor ele in elem:\n  if ele.get_attribute("innerHTML").find(\'Red\') > -1 and ele.get_attribute("innerHTML").find(\'wolly\') > -1 and ele.get_attribute("innerHTML").find(\'small\') > -1 and ele.get_attribute("innerHTML").find(\'small\') > -1:\n    #TODO\n']], ['Python selenium and fuzzy matching'], 2, 1], [(33019600, 1), [['However that gets kind of long so I would use a regex, for example:'], ['if  .get_attribute("innerHTML")  doesn\'t get the inner text try .text()']], [[' import re\nelem = browser.find_elements_by_tag_name("option") \nfor ele in elem:\n  m = re.search(r\'(Red,.+wooly,.+small,.+UK)\', ele.get_attribute("innerHTML"))\n  if m:\n    print m.group(1)\n']], ['Python selenium and fuzzy matching'], 2, 1], [(33021916, 0), [['Building the patterns seems to be of some concern, so here is some code which builds all legal i-patterns, and n-patterns to be used.'], ['Output for  n=5  as it stands are:']], [[' import collections\n\ndef make_ngram_ipatterns(n):\n    """Make all needed patterns used by *gramCollocationFinder up to n words"""\n\n    i_patterns = []\n\n    for i in xrange(1, n+1):\n        if i <= 2:\n            i_patterns.append(\'i\' * i)\n\n        else:\n            for j in xrange(2**(i-2)):\n                 bin_str = \'{0:0{1}b}\'.format(j, i-2)\n                 ix_pattern = bin_str.replace(\'0\', \'x\').replace(\'1\', \'i\')\n                 i_patterns.append(\'i{}i\'.format(ix_pattern))\n\n    return i_patterns\n\ndef make_ngram_npatterns(n):\n    """Make all needed n-patterings used by *gramCollocationFinder up to n words"""\n    all_ipatterns = make_ngram_ipatterns(n)\n\n    npatterns = []\n\n    for ipattern in all_ipatterns:\n         i_order = sum(c == \'i\' for c in ipattern)\n         i_length = len(ipattern)\n         for j in xrange(n - i_length+1):\n             npattern = \'n_{}{}{}\'.format(\'x\'* j,\n                                           ipattern ,\n                                           \'x\'* (n - i_length - j))\n\n             npatterns.append((i_order, ipattern, npattern))\n\n    return sorted(npatterns)\n\n\ndef main():\n\n    n = 5\n\n    all_ipatterns = make_ngram_ipatterns(n)\n\n    print \'\\n\'.join(make_ngram_ipatterns(n))\n\n    for order, ipattern, npattern in make_ngram_npatterns(n):\n         wparams = \', \'.join(\'w{}\'.format(i+1)\n                                for i, c in enumerate(npattern[2:])\n                                if c == \'i\'\n                            )\n         print(\'order: {1:2}   ipattern: {2:{0}s}   npattern: {3}\'\n               \' ->  {3} = self.{2}({4})\'.format(\n                   n, order, ipattern, npattern, wparams))\n\n\nif __name__ == \'__main__\':\n    main()\n']], ['Transform QuadgramCollationFinder into PentagramCollationFinder'], 2, 1], [(33021916, 1), [['Output for  n=5  as it stands are:'], ['Changing to a new dimension is now a matter of using and setting all i-patterns as a lower order class, replacing the n-patterns, and collating all n-patterns of same order into  score_fn()  sets.']], [[' i\nii\nixi\niii\nixxi\nixii\niixi\niiii\nixxxi\nixxii\nixixi\nixiii\niixxi\niixii\niiixi\niiiii\norder:  1   ipattern: i       npattern: n_ixxxx ->  n_ixxxx = self.i(w1)\norder:  1   ipattern: i       npattern: n_xixxx ->  n_xixxx = self.i(w2)\norder:  1   ipattern: i       npattern: n_xxixx ->  n_xxixx = self.i(w3)\norder:  1   ipattern: i       npattern: n_xxxix ->  n_xxxix = self.i(w4)\norder:  1   ipattern: i       npattern: n_xxxxi ->  n_xxxxi = self.i(w5)\norder:  2   ipattern: ii      npattern: n_iixxx ->  n_iixxx = self.ii(w1, w2)\norder:  2   ipattern: ii      npattern: n_xiixx ->  n_xiixx = self.ii(w2, w3)\norder:  2   ipattern: ii      npattern: n_xxiix ->  n_xxiix = self.ii(w3, w4)\norder:  2   ipattern: ii      npattern: n_xxxii ->  n_xxxii = self.ii(w4, w5)\norder:  2   ipattern: ixi     npattern: n_ixixx ->  n_ixixx = self.ixi(w1, w3)\norder:  2   ipattern: ixi     npattern: n_xixix ->  n_xixix = self.ixi(w2, w4)\norder:  2   ipattern: ixi     npattern: n_xxixi ->  n_xxixi = self.ixi(w3, w5)\norder:  2   ipattern: ixxi    npattern: n_ixxix ->  n_ixxix = self.ixxi(w1, w4)\norder:  2   ipattern: ixxi    npattern: n_xixxi ->  n_xixxi = self.ixxi(w2, w5)\norder:  2   ipattern: ixxxi   npattern: n_ixxxi ->  n_ixxxi = self.ixxxi(w1, w5)\norder:  3   ipattern: iii     npattern: n_iiixx ->  n_iiixx = self.iii(w1, w2, w3)\norder:  3   ipattern: iii     npattern: n_xiiix ->  n_xiiix = self.iii(w2, w3, w4)\norder:  3   ipattern: iii     npattern: n_xxiii ->  n_xxiii = self.iii(w3, w4, w5)\norder:  3   ipattern: iixi    npattern: n_iixix ->  n_iixix = self.iixi(w1, w2, w4)\norder:  3   ipattern: iixi    npattern: n_xiixi ->  n_xiixi = self.iixi(w2, w3, w5)\norder:  3   ipattern: iixxi   npattern: n_iixxi ->  n_iixxi = self.iixxi(w1, w2, w5)\norder:  3   ipattern: ixii    npattern: n_ixiix ->  n_ixiix = self.ixii(w1, w3, w4)\norder:  3   ipattern: ixii    npattern: n_xixii ->  n_xixii = self.ixii(w2, w4, w5)\norder:  3   ipattern: ixixi   npattern: n_ixixi ->  n_ixixi = self.ixixi(w1, w3, w5)\norder:  3   ipattern: ixxii   npattern: n_ixxii ->  n_ixxii = self.ixxii(w1, w4, w5)\norder:  4   ipattern: iiii    npattern: n_iiiix ->  n_iiiix = self.iiii(w1, w2, w3, w4)\norder:  4   ipattern: iiii    npattern: n_xiiii ->  n_xiiii = self.iiii(w2, w3, w4, w5)\norder:  4   ipattern: iiixi   npattern: n_iiixi ->  n_iiixi = self.iiixi(w1, w2, w3, w5)\norder:  4   ipattern: iixii   npattern: n_iixii ->  n_iixii = self.iixii(w1, w2, w4, w5)\norder:  4   ipattern: ixiii   npattern: n_ixiii ->  n_ixiii = self.ixiii(w1, w3, w4, w5)\norder:  5   ipattern: iiiii   npattern: n_iiiii ->  n_iiiii = self.iiiii(w1, w2, w3, w4, w5)\n']], ['Transform QuadgramCollationFinder into PentagramCollationFinder'], 2, 0], [(33037416, 0), [['You can try this:'], ['EDIT2: I improved the solution to handle the case when a letter is  \'y\'  or  \'z\'  and without "rotation" should begin a not alphabetic character, eg:']], [[' >>> offset = 2\n>>> aString = raw_input("digit a letter: ")\n>>> aString\n\'a\'\n>>> chr(ord(aString)+offset)\n\'c\'\n']], ['Returning the value of an index in a python list based on other values'], 5, 1], [(33037416, 2), [['The code solution:'], ['The output of this code for the entire lowercase alphabet:']], [[' offset = 2\naString = raw_input("digit the string to convert: ")\n#aString = "abz"\nnewString = ""\n\nfor letter in aString:\n    ord_letter = ord(letter)+offset\n    ord_letter_rotated = ((ord_letter - 97) % 26) + 97\n    newString += chr(ord_letter_rotated)\n\nprint newString\n']], ['Returning the value of an index in a python list based on other values'], 5, 1], [(33037416, 3), [['The output of this code for the entire lowercase alphabet:'], ['Note: you can obtain the lowercase alphabet for free also this way:']], [[' cdefghijklmnopqrstuvwxyzab\n']], ['Returning the value of an index in a python list based on other values'], 5, 0], [(33037416, 4), [['Note: you can obtain the lowercase alphabet for free also this way:'], ['See the wikipedia page to learn something about  ROT13 :']], [[" >>> import string\n>>> string.lowercase\n'abcdefghijklmnopqrstuvwxyz'\n"]], ['Returning the value of an index in a python list based on other values'], 5, 0], [(33042988, 0), [['1) assign a handle to the plot with the ydata of your curve'], ['2) update the the ydata with your handle ']], [[' self.h,=self.axes.plot(data,"-g")\n']], ['How to add/remove said a curve to/from a plot in Python with Matplotlib'], 2, 0], [(33042988, 1), [['2) update the the ydata with your handle '], ['-10000']], [[' self.h.set_ydata(newdata)\n']], ['How to add/remove said a curve to/from a plot in Python with Matplotlib'], 2, 0], [(33062288, 0), [['One way you can do this would be to use list comprehension to create the sub-list instead of  [choice((0, 1))]  . Example -'], ['Demo -']], [[" from random import choice\n\ndef Number_recursive(N,initialN=None):\n    initialN = initialN or N\n    if N < 0:\n        raise ValueError('N must be positive')\n    if N == 0:\n        return []\n    return [[choice((0, 1)) for _ in range(initialN)]] + Number_recursive(N-1,initialN)\n"]], ['Recursive List containing Lists'], 2, 1], [(33062288, 1), [['Demo -'], ['-10000']], [[" >>> from random import choice\n>>>\n>>> def Number_recursive(N,M=None):\n...     M = M or N\n...     if N < 0:\n...         raise ValueError('N must be positive')\n...     if N == 0:\n...         return []\n...     return [[choice((0, 1)) for _ in range(M)]] + Number_recursive(N-1,M)\n...\n>>> Number_recursive(4)\n[[0, 0, 1, 0], [0, 1, 1, 1], [1, 1, 0, 0], [1, 0, 1, 0]]\n"]], ['Recursive List containing Lists'], 2, 1], [(33069366, 0), [['For a fixed point in time, you can utilize the following interpolation function:'], ['So the code would be:']], [[' g(a) = cc[0]*abs(a-aa[0]) + cc[1]*abs(a-aa[1]) + cc[2]*abs(a-aa[2])\n']], ['Fast linear interpolation in Numpy / Scipy "along a path"'], 5, 0], [(33069366, 2), [['Measuring the time gives:'], ["Furthermore, as requested for comparison, @moarningsun's benchmark code block on my machine:"]], [[' In [2]: %timeit doit()\n10000 loops, best of 3: 107 µs per loop\n']], ['Fast linear interpolation in Numpy / Scipy "along a path"'], 5, 0], [(33069366, 3), [["Furthermore, as requested for comparison, @moarningsun's benchmark code block on my machine:"], ['Note that  N=1000  is a relatively small number. Using  N=100000  produces the results:']], [[' 10 loops, best of 3: 110 ms per loop  \ninterp_checked\n10000 loops, best of 3: 83.9 µs per loop\nscipy_interpn\n1000 loops, best of 3: 678 µs per loop\nOutput allclose:\n[True, True, True]\n']], ['Fast linear interpolation in Numpy / Scipy "along a path"'], 5, 0], [(33069366, 4), [['Note that  N=1000  is a relatively small number. Using  N=100000  produces the results:'], ['This shows that this approach scales better for large  N  than the  interp_checked  approach.']], [[' interp_checked\n100 loops, best of 3: 8.37 ms per loop\n\n%timeit doit()\n100 loops, best of 3: 5.31 ms per loop\n']], ['Fast linear interpolation in Numpy / Scipy "along a path"'], 5, 0], [(33099417, 0), [["I've to add a root element  <Emps>  (to make a valid xml doc, requiring root element), i've also chosen to filter the location to edit by the  <city>  tag (but may be everyfield):"], ['This is a possible implementation using the lazy modifier  .*?  and dot all  (?s) :']], [[' #!/usr/bin/python\n# Alternative Implementation with ElementTree XML Parser\n\nxml = \'\'\'\\\n<Emps>\n    <Emp>\n        <Name>Raja</Name>\n        <Location>\n            <city>ABC</city>\n            <geocode>123</geocode>\n            <state>XYZ</state>\n        </Location>\n        <sal>100</sal>\n        <type>temp</type>\n    </Emp>\n    <Emp>\n        <Name>GsusRecovery</Name>\n        <Location>\n            <city>Torino</city>\n            <geocode>456</geocode>\n            <state>UVW</state>\n        </Location>\n        <sal>120</sal>\n        <type>perm</type>\n    </Emp>\n</Emps>\n\'\'\'\n\nfrom xml.etree import ElementTree as ET\n# tree = ET.parse(\'input.xml\')  # decomment to parse xml from file\ntree = ET.ElementTree(ET.fromstring(xml))\nroot = tree.getroot()\n\nfor location in root.iter(\'Location\'):\n    if location.find(\'city\').text == \'Torino\':\n        location.set("isupdated", "1")\n        location.find(\'city\').text = \'MyCity\'\n        location.find(\'geocode\').text = \'10.12\'\n        location.find(\'state\').text = \'MyState\'\n\nprint ET.tostring(root, encoding=\'utf8\', method=\'xml\')\n# tree.write(\'output.xml\') # decomment if you want to write to file\n']], ['Replace xml tag contents using python'], 3, 1], [(33099417, 1), [['This is a possible implementation using the lazy modifier  .*?  and dot all  (?s) :'], ['Caveat : if there are more than one  <Location>  tag in the xml input the regex replace them all with  locUpdate . You have to use:']], [[' #!/usr/bin/python\n\nimport re\n\nxml = \'\'\'\\\n<Emp>\n<Name>Raja</Name>\n<Location>\n     <city>ABC</city>\n     <geocode>123</geocode>\n     <state>XYZ</state>\n</Location>\n</Emp>\'\'\'\n\nlocUpdate = \'\'\'\\\n    <Location isupdated=1>\n         <city>MyCity</city>\n         <geocode>10.12</geocode>\n         <state>MyState</state>\n    </Location>\'\'\'\n\noutput = re.sub(r"(?s)<Location>.*?</Location>", r"%s" % locUpdate, xml)\n\nprint output\n']], ['Replace xml tag contents using python'], 3, 1], [(33099417, 2), [['Caveat : if there are more than one  <Location>  tag in the xml input the regex replace them all with  locUpdate . You have to use:'], ['-10000']], [[' # (note the last ``1`` at the end to limit the substitution only to the first occurrence)\noutput = re.sub(r"(?s)<Location>.*?</Location>", r"%s" % locUpdate, xml, 1)\n']], ['Replace xml tag contents using python'], 3, 0], [(33103802, 0), [['It would be easier/make more sense to send a PNG instead of sending raw data and encode it at the receiving end to a PNG image.  Here a  BytesIO  object actually is necessary to avoid a temporary file.  Sending side:'], ['Then send  data  over the socket and on the receiving side simply save it:']], [[' screen = ScreenShot()\nimage = screen.get_screenshot()\npng_file = BytesIO()\nimage.save_to_callback(png_file.write)\ndata = png_file.getvalue()\n']], ['Re-Construct a png image from a GDK Pixbuf'], 2, 0], [(33103802, 1), [['Then send  data  over the socket and on the receiving side simply save it:'], ['-10000']], [[" with open('result.png', 'wb') as png_file:\n    png_file.write(data)\n"]], ['Re-Construct a png image from a GDK Pixbuf'], 2, 0], [(33105265, 0), [['-10000'], ['Output:']], [[" text = 'user = bob'\na = re.match(r'(?P<key>.*?) ?(?P<operator>NOT LIKE|LIKE|<=>|>=|<=|!=|<>|=|>|<) ?(?P<values>.*)',text)\nprint a.group()\n"]], ['Python Regex: Optional White Space Around Matching Group'], 4, 1], [(33105265, 1), [['Output:'], ['if you want spaces to be part of your second group. You could do below. ']], [[' user = bob\n']], ['Python Regex: Optional White Space Around Matching Group'], 4, 0], [(33105265, 3), [['Output:'], ['Since you mentioned whitespace(space, tab etc.) you can replace space with  \\s']], [['  = \n']], ['Python Regex: Optional White Space Around Matching Group'], 4, 0], [(33139927, 0), [['As I understand it, your goal is to start a background process in subprocess but not have the main program wait for it to finish.  Here is an example program that does that:'], ['Here is an example of that program in operation:']], [[' $ cat script.py\nimport subprocess\nsubprocess.Popen("sleep 3; echo \'Done!\';", shell=True)\n']], ['Running program/function in background in Python'], 4, 1], [(33139927, 1), [['Here is an example of that program in operation:'], ['In some cases, a child process that lives after its parent exits may leave a zombie process.  For instructions on how to avoid that, see  here .']], [[' $ python script.py\n$ \n$ \n$ Done!\n']], ['Running program/function in background in Python'], 4, 0], [(33139927, 2), [['In some cases, a child process that lives after its parent exits may leave a zombie process.  For instructions on how to avoid that, see  here .'], ['Here is an example its output:']], [[' $ cat script.py\nimport subprocess\np = subprocess.Popen("sleep 3; echo \'Done!\';", shell=True)\np.wait()\n']], ['Running program/function in background in Python'], 4, 1], [(33139927, 3), [['Here is an example its output:'], ['As you can see, because we called  wait , python waited until subprocess completed before exiting.']], [[' $ python script.py\nDone!\n$ \n$ \n']], ['Running program/function in background in Python'], 4, 0], [(33140945, 0), [['First to navigate a tree, see  How to iterate through all nodes of a tree?  and  How to navigate a nltk.tree.Tree?  :'], ["And what you're looking for is  https://github.com/nltk/nltk/blob/develop/nltk/tree.py#L341 :"]], [[' >>> from nltk.tree import Tree\n>>> bracket_parse = "(S (VP (VB get) (NP (PRP me)) (ADVP (RB now))))"\n>>> ptree = Tree.fromstring(bracket_parse)\n>>> ptree\nTree(\'S\', [Tree(\'VP\', [Tree(\'VB\', [\'get\']), Tree(\'NP\', [Tree(\'PRP\', [\'me\'])]), Tree(\'ADVP\', [Tree(\'RB\', [\'now\'])])])])\n>>> for subtree in ptree.subtrees():\n...     print subtree\n... \n(S (VP (VB get) (NP (PRP me)) (ADVP (RB now))))\n(VP (VB get) (NP (PRP me)) (ADVP (RB now)))\n(VB get)\n(NP (PRP me))\n(PRP me)\n(ADVP (RB now))\n(RB now)\n']], ['Grammar rule extraction from parsed result'], 4, 0], [(33140945, 1), [["And what you're looking for is  https://github.com/nltk/nltk/blob/develop/nltk/tree.py#L341 :"], ['If you want a string form of the grammar rules, you can either do:']], [[" >>> ptree.productions()\n[S -> VP, VP -> VB NP ADVP, VB -> 'get', NP -> PRP, PRP -> 'me', ADVP -> RB, RB -> 'now']\n"]], ['Grammar rule extraction from parsed result'], 4, 0], [(33140945, 2), [['If you want a string form of the grammar rules, you can either do:'], ['Or ']], [[" >>> for rule in ptree.productions():\n...     print rule\n... \nS -> VP\nVP -> VB NP ADVP\nVB -> 'get'\nNP -> PRP\nPRP -> 'me'\nADVP -> RB\nRB -> 'now'\n"]], ['Grammar rule extraction from parsed result'], 4, 0], [(33140945, 3), [['Or '], ['-10000']], [[' >>> rules = [str(p) for p in ptree.productions()]\n>>> rules\n[\'S -> VP\', \'VP -> VB NP ADVP\', "VB -> \'get\'", \'NP -> PRP\', "PRP -> \'me\'", \'ADVP -> RB\', "RB -> \'now\'"]\n']], ['Grammar rule extraction from parsed result'], 4, 0], [(33144460, 0), [['-10000'], ['Then runnning this:']], [[' import collections\n\n\nclass PrivateList(collections.MutableSequence):\n    def __init__(self, initial=None):\n        self._list = initial or []\n\n    def __repr__(self):\n        return repr(self._list)\n\n    def __getitem__(self, item):\n        print("Accessed element {}".format(item))\n        return self._list[item]\n\n    def __setitem__(self, key, value):\n        print("Set element {} to {}".format(key, value))\n        self._list[key] = value\n\n    def __delitem__(self, key):\n        print("Deleting element {}".format(key))\n        del self._list[key]\n\n    def __len__(self):\n        print("Getting length")\n        return len(self._list)\n\n    def insert(self, index, item):\n        print("Inserting item {} at {}".format(item, index))\n        self._list.insert(index, item)\n\n\nclass Foo(object):\n    def __init__(self, a_list):\n        self.list = PrivateList(a_list)\n']], ['Create a list property in Python'], 3, 1], [(33144460, 1), [['Then runnning this:'], ['Outputs:']], [[' foo = Foo([1,2,3])\nprint(foo.list)\nprint(foo.list[1])\nfoo.list[1] = 12\nprint(foo.list)\n']], ['Create a list property in Python'], 3, 0], [(33144460, 2), [['Outputs:'], ['-10000']], [[' [1, 2, 3]\nAccessed element 1\n2\nSet element 1 to 12\n[1, 12, 3]\n']], ['Create a list property in Python'], 3, 0], [(33201383, 0), [["If you want to store the original starting position you used when creating the  Sprite , you'll have to create a member in the initializer:"], ['Then in  update :']], [[' #TODO: respect naming convention\nclass sprite_to_place(pygame.sprite.Sprite):\n    # you can use a single parameter instead of two\n    def __init__(self, pos):\n        pygame.sprite.Sprite.__init__(self)\n        self.image = pygame.image.load("a_picture.png")\n        # you can pass the position directly to get_rect to set it\'s position\n        self.rect = self.image.get_rect(topleft=pos)\n        # I don\'t know if you actually need this\n        self.start_pos = pos\n']], ['Pygame- Sprite set position with mouseclick'], 2, 0], [(33201383, 1), [['Then in  update :'], ['-10000']], [[' def update(self): \n    # current position is self.rect.topleft\n    # starting position is self.start_pos\n    # to move the Sprite/Rect, you can also use the move functions\n    self.rect.move_ip(10, 20) # moves the Sprite 10px vertically and 20px horizontally\n']], ['Pygame- Sprite set position with mouseclick'], 2, 0], [(33203746, 0), [['You can just do:'], ['If you want to get exactly what your header was stored then you can do the following:']], [[" In [6]:\n' '.join(df)\n\nOut[6]:\n'Col_A Col_B Col_C'\n"]], ['Get header row in pandas dataframe'], 2, 1], [(33203746, 1), [['If you want to get exactly what your header was stored then you can do the following:'], ["So this doesn't specify a separator so it will look for commas which there are none so the entire header row is read as a single column value, you can then get just the row value by indexing it as shown above"]], [[" In [8]:\ndf = pd.read_table(io.StringIO(t), skiprows=3, header=None, nrows=1)\ndf\n\nOut[8]:\n                        0\n0  Col_A    Col_B   Col_C\n\nIn [10]:\ndf.iloc[0][0]\n\nOut[10]:\n'Col_A    Col_B   Col_C'\n"]], ['Get header row in pandas dataframe'], 2, 1], [(33223682, 0), [['in python 2:'], ["in python 3 almost the same, just unicode is call 'str', and bytes are called 'bytes'"]], [[" def test_if_ascii(text):\n    if isinstance(test, unicode):\n        raise TypeError('hey man, dont feed me unicode plz')\n    return all(32 <= ord(c) <= 126 for c in text)\n"]], ["How to decode() with a subset of 'ascii'?"], 2, 1], [(33223682, 1), [["in python 3 almost the same, just unicode is call 'str', and bytes are called 'bytes'"], ['-10000']], [[" def test_if_ascii(text):\n    if isinstance(test, str):\n        raise TypeError('hey man, dont feed me unicode plz')\n    return all(32 <= ord(c) <= 126 for c in text)\n"]], ["How to decode() with a subset of 'ascii'?"], 2, 1], [(33252350, 0), [["Here's an example:"], ['The output is:']], [[" import pprint\n\n# Define the keywords I want to see first\npreferred_projects = ['one', 'two', 'three']\n\n# example data\nAllMyProjectsFromaDatasource = [{ 'name': 'project two', 'id': 5, 'otherkey': 'othervalue'},\n                                { 'name': 'project three', 'id': 1, 'otherkey': 'othervalue'},\n                                { 'name': 'project one', 'id': 3, 'otherkey': 'othervalue'},\n                                { 'name': 'abc project', 'id': 6, 'otherkey': 'othervalue'},\n                                { 'name': 'one project', 'id': 9, 'otherkey': 'othervalue'}\n                               ]    \n\ndef keyfunc(x):\n    # keyword primary key\n    # (add index to list comprehension when keyword is in name)\n    preferred_key = [float(idx) \n                     for idx, i in enumerate(preferred_projects)\n                     if i in x['name']]\n    # found at least one match in preferred keywords, use first if any, else infinity\n    keyword_sortkey = preferred_key[0] if preferred_key else float('inf')\n    # return tuple to sort according to primary and secondary key\n    return keyword_sortkey, x['name']\n\nAllMyProjectsFromaDatasource.sort(key=keyfunc)\n\npprint.pprint(AllMyProjectsFromaDatasource)\n"]], ['Sorting list of dictionaries with primary key from list of keywords and alphabetical order as secondary key'], 2, 1], [(33252350, 1), [['The output is:'], ['-10000']], [[" [{'id': 9, 'name': 'one project', 'otherkey': 'othervalue'},\n {'id': 3, 'name': 'project one', 'otherkey': 'othervalue'},\n {'id': 5, 'name': 'project two', 'otherkey': 'othervalue'},\n {'id': 1, 'name': 'project three', 'otherkey': 'othervalue'},\n {'id': 6, 'name': 'abc project', 'otherkey': 'othervalue'}]\n"]], ['Sorting list of dictionaries with primary key from list of keywords and alphabetical order as secondary key'], 2, 0], [(33270388, 0), [["The fact that you 'pulled' the data from the list in variables x and y doesn't help at all, since those variables have no connection anymore with the items from the list. But why don't you swap them directly:"], ['But, there is no need to create a list from the original string. Instead, you can use the slicing operator to achieve the result you want. Note that you cannot swap the string elements as you did with lists, since in Python strings are immutable. However, you can do the following:']], [[' original[0], original[9] = original[9], original[0]\n']], ['Switching positions of two strings within a list'], 2, 1], [(33270388, 1), [['But, there is no need to create a list from the original string. Instead, you can use the slicing operator to achieve the result you want. Note that you cannot swap the string elements as you did with lists, since in Python strings are immutable. However, you can do the following:'], ['-10000']], [[' >>> a = "1234567890"\n>>> a[9] + a[5:9] + a[1:5] + a[0]\n\'0678923451\'\n>>>\n']], ['Switching positions of two strings within a list'], 2, 1], [(33270413, 0), [['You could use an infinite loop with some sort of sentinel for the user to indicate "Okay no more." How about:'], ['Then you can prompt for the countries if you wanted to do that separately for some reason.']], [[' cities = []\nwhile True:\n    city = raw_input("Enter a city you\'ve been to (or press enter to exit): ")\n    if city == \'\':  # no input -- this is your sentinel\n        break  # leave the loop\n    else:\n        cities.append(city)\n']], ['How to index a user input list in Python 2.x?'], 3, 0], [(33270413, 1), [['Then you can prompt for the countries if you wanted to do that separately for some reason.'], ['Maybe you need a dictionary then?']], [[' countries = []\nfor idx, city in enumerate(cities):\n    country = raw_input("Where is " + city + " located? ")\n    countries.append(country)\n    # why did you need the index? enumerate is the way to go now....\n']], ['How to index a user input list in Python 2.x?'], 3, 0], [(33270413, 2), [['Maybe you need a dictionary then?'], ['-10000']], [[' cities_to_countries = dict(zip(cities, countries))\n']], ['How to index a user input list in Python 2.x?'], 3, 0], [(33288420, 0), [["You can use a dictionary comprehension to extract the data in the parameters per parameter.  I'm not sure if you wanted the final values in list form.  If not, it would be easy to extract it."], ['or...']], [[" >>> pd.DataFrame({p: [d.get(p) for d in params] \n                  for p in ['param1', 'param2', 'param3', 'param4']})\n     param1    param2    param3    param4\n0   [apple]  [tomato]  [carrot]      None\n1  [banana]      None  [potato]   [berry]\n2      None   [apple]  [tomato]  [carrot]\n"]], ['Extracting URL parameters into Pandas DataFrame'], 2, 1], [(33288420, 1), [['or...'], ['-10000']], [[" >>> pd.DataFrame({p: [d[p][0] if p in d else None for d in params] \n                  for p in ['param1', 'param2', 'param3', 'param4']})\n   param1  param2  param3  param4\n0   apple  tomato  carrot    None\n1  banana    None  potato   berry\n2    None   apple  tomato  carrot\n"]], ['Extracting URL parameters into Pandas DataFrame'], 2, 1], [(33296707, 0), [['Repeat the procedure a random number of times:'], ['Demo:']], [[" [random.choice(['[', ']', '[]']) for _ in range(random.randint(1, 10))]\n"]], ['which random am i looking for to achieve this:'], 3, 1], [(33296707, 1), [['Demo:'], ['If you need this as one string, use  str.join()  to concatenate the results:']], [[" >>> import random\n>>> [random.choice(['[', ']', '[]']) for _ in range(random.randint(1, 10))]\n[']', '[]']\n>>> [random.choice(['[', ']', '[]']) for _ in range(random.randint(1, 10))]\n['[', '[]', ']', '[]', '[]', '[]', '[]']\n"]], ['which random am i looking for to achieve this:'], 3, 1], [(33296707, 2), [['If you need this as one string, use  str.join()  to concatenate the results:'], ["Note that this'll produce a string between 1 and 20 characters long, as you concatenate a random selection of up to 10 strings each 1 or 2 characters long. Use  random.choice('[]')  if you need a string up to 10 characters long instead."]], [[" ''.join([random.choice(['[', ']', '[]']) for _ in range(random.randint(1, 10))])\n"]], ['which random am i looking for to achieve this:'], 3, 1], [(33304356, 0), [["If you'd like save some data such as  list ,  dict  or  tuple , etc. to a file. And you want to edit them or you just want them be  readable  . Use  json  module like this:"], ['Now you could save these data to a file. If you want to load them, use  json.loads()  like this:']], [[' >>> import json\n>>> d = {\'apple\': 1, \'bear\': 2}\n\n>>> print(d)\n{\'bear\': 2, \'apple\': 1}\n\n>>> print(json.dumps(d))\n{"bear": 2, "apple": 1}  # these are json data\n>>> \n']], ['Import a exported dict into python'], 2, 1], [(33304356, 1), [['Now you could save these data to a file. If you want to load them, use  json.loads()  like this:'], ['-10000']], [[' >>> json_data = \'{"bear": 2, "apple": 1}\'\n>>> d = json.loads(json_data)\n>>> d[\'bear\']\n2\n>>>\n']], ['Import a exported dict into python'], 2, 0], [(33319664, 0), [['First, install the  prerequisites:'], ['swr3.py:']], [[' pip install beautifulsoup4\npip install requests\npip install lxml\n']], ['Extracting text from HTML file using Python (Music Artist / Title)'], 3, 0], [(33319664, 2), [['The  output:'], ['-10000']], [[" (swr3)macbook:swr3 joeyoung$ python swr3.py\nArtist: Vaya Con Dios   Title: Nah neh nah\nArtist: Genesis Title: No son of mine\nArtist: Genesis Title: No son of mine\nArtist: Double You  Title: Please don't go\nArtist: Stereo MC's Title: Step it up\nArtist: Cranberries Title: Zombie\nArtist: La Bouche   Title: Sweet dreams\nArtist: Die Prinzen Title: Du mußt ein Schwein sein\nArtist: Bad Religion    Title: Punk rock song\nArtist: Bellini Title: Samba de Janeiro\nArtist: Dion, Celine; Bee Gees  Title: Immortality\nArtist: Jones, Tom; Mousse T.   Title: Sex bomb\nArtist: Yanai, Kate Title: Bacardi feeling (Summer dreamin')\nArtist: Heroes Del Silencio Title: Entre dos tierras\n"]], ['Extracting text from HTML file using Python (Music Artist / Title)'], 3, 0], [(33341000, 0), [['This script:'], ['Will print:']], [[" import re\n\n\ntest_string = '44.5MB\\n12b\\n6.5GB\\n12pb'\n\nregex = re.compile(r'(\\d+(?:\\.\\d+)?)\\s*([kmgtp]?b)', re.IGNORECASE)\n\norder = ['b', 'kb', 'mb', 'gb', 'tb', 'pb']\n\nfor value, unit in regex.findall(test_string):\n    print(int(float(value) * (1024**order.index(unit.lower()))))\n"]], ['Extract Numbers and Size Information (KB, MB, etc) from a String in Python'], 2, 1], [(33341000, 1), [['Will print:'], ['Which is the sizes it found in bytes.']], [[' 46661632\n12\n6979321856\n13510798882111488\n']], ['Extract Numbers and Size Information (KB, MB, etc) from a String in Python'], 2, 0], [(33347648, 0), [['You can easily define  Worker  threads that work in parallel till a queue is empty. '], ['One could also write a simple Pool class to get rid of the noise in the main function:']], [[" from threading import Thread\nfrom collections import deque\nimport time\n\n\n# Create a new class that inherits from Thread\nclass Worker(Thread):\n\n    def __init__(self, inqueue, outqueue, func):\n        '''\n        A worker that calls func on objects in inqueue and\n        pushes the result into outqueue\n\n        runs until inqueue is empty\n        '''\n\n        self.inqueue = inqueue\n        self.outqueue = outqueue\n        self.func = func\n        super().__init__()\n\n    # override the run method, this is starte when\n    # you call worker.start()\n    def run(self):\n        while self.inqueue:\n            data = self.inqueue.popleft()\n            print('start')\n            result = self.func(data)\n            self.outqueue.append(result)\n            print('finished')\n\n\ndef test(x):\n    time.sleep(x)\n    return 2 * x\n\n\nif __name__ == '__main__':\n    data = 12 * [1, ]\n    queue = deque(data)\n    result = deque()\n\n    # create 3 workers working on the same input\n    workers = [Worker(queue, result, test) for _ in range(3)]\n\n    # start the workers\n    for worker in workers:\n        worker.start()\n\n    # wait till all workers are finished\n    for worker in workers:\n        worker.join()\n\n    print(result)\n"]], ['How to process input in parallel with python, but without processes?'], 2, 1], [(33347648, 1), [['One could also write a simple Pool class to get rid of the noise in the main function:'], ['-10000']], [[" from threading import Thread\nfrom collections import deque\nimport time\n\n\nclass Pool():\n\n    def __init__(self, n_threads):\n        self.n_threads = n_threads\n\n    def map(self, func, data):\n        inqueue = deque(data)\n        result = deque()\n\n        workers = [Worker(inqueue, result, func) for i in range(self.n_threads)]\n\n        for worker in workers:\n            worker.start()\n\n        for worker in workers:\n            worker.join()\n\n        return list(result)\n\n\nclass Worker(Thread):\n\n    def __init__(self, inqueue, outqueue, func):\n        '''\n        A worker that calls func on objects in inqueue and\n        pushes the result into outqueue\n\n        runs until inqueue is empty\n        '''\n\n        self.inqueue = inqueue\n        self.outqueue = outqueue\n        self.func = func\n        super().__init__()\n\n    # override the run method, this is starte when\n    # you call worker.start()\n    def run(self):\n        while self.inqueue:\n            data = self.inqueue.popleft()\n            print('start')\n            result = self.func(data)\n            self.outqueue.append(result)\n            print('finished')\n\n\ndef test(x):\n    time.sleep(x)\n    return 2 * x\n\n\nif __name__ == '__main__':\n    data = 12 * [1, ]\n\n    pool = Pool(6)\n    result = pool.map(test, data)\n\n    print(result)\n"]], ['How to process input in parallel with python, but without processes?'], 2, 1], [(33354950, 0), [['this'], ['produces']], [[" s = '20101002  100224   1    1044      45508  1001  1002  1003  1004  1005  1006'\nnew_s = ' '.join(s.split())\nprint(new_s)\n"]], ['Python: Removing random whitespace from a string of numbers'], 3, 1], [(33354950, 1), [['produces'], ['first we split the string into words with  s.split() , which returns this list']], [[' 20101002 100224 1 1044 45508 1001 1002 1003 1004 1005 1006\n']], ['Python: Removing random whitespace from a string of numbers'], 3, 0], [(33354950, 2), [['first we split the string into words with  s.split() , which returns this list'], ["then we pass the list to  ' '.join , which joins all the elements of the list using the space character between them"]], [[" ['20101002', '100224', '1', '1044', '45508', '1001', '1002', '1003', '1004', '1005', '1006']\n"]], ['Python: Removing random whitespace from a string of numbers'], 3, 0], [(33371558, 0), [['You can define yourself dictionary object using python  ABC s which provides the infrastructure for defining  abstract base classes . And then overload the  pop  attribute of python dictionary objects based on your need:'], ['Demo:']], [[' from collections import Mapping\n\nclass MyDict(Mapping):\n    def __init__(self, *args, **kwargs):\n        self.update(dict(*args, **kwargs))\n\n    def __setitem__(self, key, item): \n        self.__dict__[key] = item\n\n    def __getitem__(self, key): \n        return self.__dict__[key]\n\n    def __delitem__(self, key): \n        del self.__dict__[key]\n\n    def pop(self, k, d=None):\n        return k,self.__dict__.pop(k, d)\n\n    def update(self, *args, **kwargs):\n        return self.__dict__.update(*args, **kwargs)\n\n    def __iter__(self):\n        return iter(self.__dict__)\n\n    def __len__(self):\n        return len(self.__dict__)\n\n    def __repr__(self): \n        return repr(self.__dict__)\n']], ['Neat way of popping key, value PAIR from dictionary?'], 2, 1], [(33371558, 1), [['Demo:'], ['Note  : As @chepner suggested in comment as a better choice you can override  popitem , which already returns a key/value pair.']], [[" d=MyDict()\n\nd['a']=1\nd['b']=5\nd['c']=8\n\nprint d\n{'a': 1, 'c': 8, 'b': 5}\n\nprint d.pop(min(d, key=d.get))\n('a', 1)\n\nprint d\n{'c': 8, 'b': 5}\n"]], ['Neat way of popping key, value PAIR from dictionary?'], 2, 0], [(33385238, 0), [['You can simply index the series you want. Example -'], ['Demo -']], [[" tdf['s1']\n"]], ['How to convert pandas single column data frame to series or numpy vector'], 3, 1], [(33385238, 1), [['Demo -'], ['If you want the values in the series as numpy array, you can use  .values  accessor , Example -']], [[" In [24]: tdf =  pd.DataFrame({'s1' : [0,1,23.4,10,23]})\n\nIn [25]: tdf['s1']\nOut[25]:\n0     0.0\n1     1.0\n2    23.4\n3    10.0\n4    23.0\nName: s1, dtype: float64\n\nIn [26]: tdf['s1'].shape\nOut[26]: (5,)\n"]], ['How to convert pandas single column data frame to series or numpy vector'], 3, 1], [(33385238, 2), [['If you want the values in the series as numpy array, you can use  .values  accessor , Example -'], ['-10000']], [[" In [27]: tdf['s1'].values\nOut[27]: array([  0. ,   1. ,  23.4,  10. ,  23. ])\n"]], ['How to convert pandas single column data frame to series or numpy vector'], 3, 1], [(33401529, 0), [['You can use  dict.setdefault  method to create your expected dictionary :'], ['If you are using python 3.X you can use unpacking assingement in your loop  : ']], [[" my_dict={}\nwith open('file.dat', 'rb') as csvfile:\n    dataReader=csv.reader(csvfile)\n    for name,item1,item2 in dataReader:\n         my_dict.setdefault(name,[]).append([item1,item2])\n"]], ['Parse a file into a dictionary of arrays'], 2, 1], [(33402355, 0), [['A couple of different ways using itertools and numpy:'], ['Or using python3 and yield from:']], [[' from itertools import groupby, tee, cycle\n\nx = [17, 17, 19, 20, 21, 22, 0, 1, 2, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 28, 29, 30, 31, 32, 33, 34, 35,\n     36, 1, 2, 3, 4,34,54]\n\n\ndef sequences(l):\n    x2 = cycle(l)\n    next(x2)\n    grps = groupby(l, key=lambda j: j + 1 == next(x2))\n    for k, v in grps:\n        if k:\n            yield tuple(v) + (next((next(grps)[1])),)\n\n\nprint(list(sequences(x)))\n\n[(19, 20, 21, 22), (0, 1, 2), (4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14), (28, 29, 30, 31, 32, 33, 34, 35, 36), (1, 2, 3, 4)]\n']], ['Finding groups of increasing numbers in a list'], 6, 1], [(33402355, 1), [['Or using python3 and yield from:'], ['Using a variation of my answer  here  with numpy.split :']], [[' def sequences(l):\n    x2 = cycle(l)\n    next(x2)\n    grps = groupby(l, key=lambda j: j + 1 == next(x2))\n    yield from (tuple(v) + (next((next(grps)[1])),) for k,v in grps if k)\n\nprint(list(sequences(x)))\n']], ['Finding groups of increasing numbers in a list'], 6, 1], [(33402355, 2), [['Using a variation of my answer  here  with numpy.split :'], ["And similar to ekhumoro's answer:"]], [[' out = [tuple(arr) for arr in np.split(x, np.where(np.diff(x) != 1)[0] + 1) if arr.size > 1]\n\nprint(out)\n\n[(19, 20, 21, 22), (0, 1, 2), (4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14), (28, 29, 30, 31, 32, 33, 34, 35, 36), (1, 2, 3, 4)]\n']], ['Finding groups of increasing numbers in a list'], 6, 1], [(33402355, 3), [["And similar to ekhumoro's answer:"], ['To get the length and the tuple:']], [[' def sequences(x):\n    it = iter(x)\n    prev, temp = next(it), []\n    while prev is not None:\n        start = next(it, None)\n        if prev + 1 == start:\n            temp.append(prev)\n        elif temp:\n            yield tuple(temp + [prev])\n            temp = []\n        prev = start\n']], ['Finding groups of increasing numbers in a list'], 6, 1], [(33402355, 4), [['To get the length and the tuple:'], ['Output will be the same for all three:']], [[' def sequences(l):\n    x2 = cycle(l)\n    next(x2)\n    grps = groupby(l, key=lambda j: j + 1 == next(x2))\n    for k, v in grps:\n        if k:\n            t = tuple(v) + (next(next(grps)[1]),)\n            yield t, len(t)\n\n\ndef sequences(l):\n    x2 = cycle(l)\n    next(x2)\n    grps = groupby(l, lambda j: j + 1 == next(x2))\n    yield from ((t, len(t)) for t in (tuple(v) + (next(next(grps)[1]),)\n                                      for k, v in grps if k))\n\n\n\ndef sequences(x):\n        it = iter(x)\n        prev, temp = next(it), []\n        while prev is not None:\n            start = next(it, None)\n            if prev + 1 == start:\n                temp.append(prev)\n            elif temp:\n                yield tuple(temp + [prev]), len(temp) + 1\n                temp = []\n            prev = start\n']], ['Finding groups of increasing numbers in a list'], 6, 1], [(33402355, 5), [['Output will be the same for all three:'], ['-10000']], [[' [((19, 20, 21, 22), 4), ((0, 1, 2), 3), ((4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14), 11)\n, ((28, 29, 30, 31, 32, 33, 34, 35, 36), 9), ((1, 2, 3, 4), 4)]\n']], ['Finding groups of increasing numbers in a list'], 6, 0], [(33404038, 1), [["It's also an iterable object, so you can do the following:"], ['-10000']], [[' for chunk in chunks:\n    #do something to each chunk\n']], ['Python pandas to get specified rows from a CSV file'], 2, 0], [(33431816, 0), [['Try using something like this for a single file. Following is the directory structure:'], ['-10000']], [[' .\n├── example.py\n├── LICENSE\n├── README.md\n└── setup.py\n\n0 directories, 4 files\n']], ['How can a Python module single file be installed using pip and PyPI?'], 4, 0], [(33431816, 2), [['The above worked for me. This is how example file would look like.'], ['This can also be imported like so:']], [[' def example():\n    # Note: You can use sys.argv here\n    print "Hi! I\'m a command written in python."\n']], ['How can a Python module single file be installed using pip and PyPI?'], 4, 0], [(33431816, 3), [['This can also be imported like so:'], ['Hope this helps.']], [[' import example\nexample.example()\n# or\nfrom example import example\nexample()\n']], ['How can a Python module single file be installed using pip and PyPI?'], 4, 0], [(33466627, 1), [['However, placing a python script in  /etc/cron.hourly  etc., there is no way to set the umask except in the python script itself:'], ['-10000']], [[' import os\nos.umask(002)\n']], ['Cron Job File Creation - Created File Permissions'], 2, 0], [(33477811, 0), [['Do you want to compute a graph (DIF) with the edges that are in your reference (R) graph, but not in your input graph (S)? \nOr do you want to calculate a graph with the edges that are different between R and S? I included both options, one is commented out.'], ['As @Joel noticed, in undirected Graphs, there is no guaranty (at least: I did not find it in the source or the documentation) that the order of the nodes will be consistent. If that is an issue, you could convert the tuples into frozensets first, so the order does not matter. You need frozensets, and not sets or lists, because these are hashable (and that is a requirement for members of a set)']], [[' import networkx as nx\n\nS = nx.DiGraph()#S-sample graph\nS.add_nodes_from([0, 1, 2])\nS.add_edge(0, 2)\nS.add_edge(1, 2)\n\nR = nx.DiGraph()#R-reference graph\nR.add_nodes_from([0, 1, 2])\nR.add_edge(1, 2)\n\n\ndef difference(S, R):\n    DIF = nx.create_empty_copy(R)\n    DIF.name = "Difference of (%s and %s)" % (S.name, R.name)\n    if set(S) != set(R):\n        raise nx.NetworkXError("Node sets of graphs is not equal")\n\n    r_edges = set(R.edges_iter())\n    s_edges = set(S.edges_iter())\n\n    # I\'m not sure what the goal is: the difference, or the edges that are in R but not in S\n    # In case it is the difference:\n    diff_edges = r_edges.symmetric_difference(s_edges)\n\n    # In case its the edges that are in R but not in S:\n    # diff_edges = r_edges - s_edges\n\n    DIF.add_edges_from(diff_edges)\n\n    return DIF\n\nprint(difference(S, R).edges())\n']], ["Computing the Difference between two graphs 'edge wise' in networkx"], 2, 1], [(33477811, 1), [['As @Joel noticed, in undirected Graphs, there is no guaranty (at least: I did not find it in the source or the documentation) that the order of the nodes will be consistent. If that is an issue, you could convert the tuples into frozensets first, so the order does not matter. You need frozensets, and not sets or lists, because these are hashable (and that is a requirement for members of a set)'], ['-10000']], [[' set([frozenset(x) for x in S.edges()])\n']], ["Computing the Difference between two graphs 'edge wise' in networkx"], 2, 0], [(33518124, 0), [["As I don't know what  PartMaster  is, the following should work:"], ["If all you're doing is calculating the square root of some result then use the  np.sqrt  method this is vectorised and will be significantly faster:"]], [[" def EOQ(D,p,ck,ch):\n    p,D = Partmaster\n    Q = math.sqrt((2*D*ck)/(ch*p))\n    return Q\nch=0.2\nck=5\ndf['Q'] = df.apply(lambda row: EOQ(row['D'], row['p'], ck, ch), axis=1)\ndf\n"]], ['How to apply a function on every row on a dataframe?'], 3, 1], [(33519408, 0), [['You could use  enumerate , which generates tuples that pair the index of an item with the item itself:'], ['Or you could store the Numpy arrays in a  dictionary  that is indexed directly by the associated file name:']], [[' for i, file in enumerate(os.listdir(directoryPath)):\n    if file.endswith(".csv"):\n       array1[i] = numpy.genfromtxt(file, delimiter=\',\')[:,2]\n']], ['On using a string as an integer counter (aka index) in a for loop'], 3, 1], [(33519408, 1), [['Or you could store the Numpy arrays in a  dictionary  that is indexed directly by the associated file name:'], ['Or with an  OrderedDict :']], [[' arrays = {}\nfor file in os.listdir(directoryPath):\n    if file.endswith(".csv"):\n       arrays[file] = numpy.genfromtxt(file, delimiter=\',\')[:,2]\n']], ['On using a string as an integer counter (aka index) in a for loop'], 3, 1], [(33519408, 2), [['Or with an  OrderedDict :'], ['-10000']], [[' from collections import OrderedDict\n\narrays = OrderedDict()\nfor file in os.listdir(directoryPath):\n    if file.endswith(".csv"):\n       arrays[file] = numpy.genfromtxt(file, delimiter=\',\')[:,2]\n']], ['On using a string as an integer counter (aka index) in a for loop'], 3, 1], [(33553826, 3), [['As an example of where it differs:'], ['-10000']], [[" >>> ListA = ['stop', 'kill']\n>>> ListB = ['stoppable', 'killable', 'stopkill']\n\n>>> sum(a.lower() in b.lower() for a in ListA for b in ListB)\n4\n>>> len(set(b for a in ListA for b in ListB if a.lower() in b.lower()))\n3\n"]], ['Given two lists of strings, find the total number of strings in the second list which contains any string in the first list as substring'], 4, 1], [(33554230, 0), [['Here it should work with:'], ['For rpy2 < 2.7, you should use do_slot_assign :']], [[" from rpy2.robjects.vectors import FloatVector, IntVector\npot = FloatVector((2.0, 3.2, 4, 5, 6, 7))\nts = IntVector((1,6,7,19,20,30))\npot.slots['times'] = ts\n"]], ['How to set an attribute to a vector in rpy2'], 2, 1], [(33554230, 1), [['For rpy2 < 2.7, you should use do_slot_assign :'], ['-10000']], [[' pot.do_slot_assign("times",ts)\n']], ['How to set an attribute to a vector in rpy2'], 2, 0], [(33569374, 0), [['I think you can what you want with  einsum :'], ['e.g.']], [[" import numpy as np\nsummed = 0\n\ndim1 = 2  # this is 81 in your case\ndim2 = 4  # this is 990000 in your case\narray = np.random.random(size=(dim1, dim2, 3))\n\nNt = dim2\ni = Nt // 2\n\nfor k in xrange(dim1):\n    summed = 0\n    for j in xrange(dim2-i):\n        vec1 = array[k][j]\n        vec2 = array[k][j+i]\n        summed += np.dot(vec1,vec2)\n    print summed\n\nprint '='*70\n\nfor k in xrange(dim1):\n    summed = np.einsum('ij,ij', array[k][:Nt//2], array[k][Nt//2:])\n    print summed\n"]], ['Take dot product of first and middle entry, second and middle+1 entries until middle-1 and last entry python/numpy'], 4, 1], [(33569374, 1), [['e.g.'], ["Doubtless you can even remove the outer loop as well (though in your case it probably won't speed things up much):"]], [[' 2.0480375425\n1.89065215839\n======================================================================\n2.0480375425\n1.89065215839\n']], ['Take dot product of first and middle entry, second and middle+1 entries until middle-1 and last entry python/numpy'], 4, 0], [(33569374, 3), [['gives'], ['-10000']], [[' [ 2.0480375425  1.89065215839]\n']], ['Take dot product of first and middle entry, second and middle+1 entries until middle-1 and last entry python/numpy'], 4, 0], [(33575575, 0), [['Use pure  SQL  and one  UPDATE :'], ['You can update records that contains at least one space:']], [[" UPDATE companies \nSET ico = REPLACE(ico, ' ', '');\n"]], ['Modify all rows in table'], 2, 1], [(33575575, 1), [['You can update records that contains at least one space:'], ['-10000']], [[" UPDATE companies \nSET ico = REPLACE(ico, ' ', '')\nWHERE ico LIKE '% %';\n"]], ['Modify all rows in table'], 2, 1], [(33577686, 0), [['use e.g.  subprocess.call  like this'], ['The signature of the function ']], [[' subprocess.call(["ls",  "-lrt"], stdout=open("foo.txt",\'w\'))\n']], ['calling linux shell in python with writing output in a text file'], 2, 1], [(33578676, 0), [['Iterable'], ['Dictionary']], [[' v = (item for item in propadd if item[0]==row1[8] and harversine(custx,custy,item[2],item[3])<1500)\nk = (item for item in custadd if item[0]==row1[4])\nm = (item for item in numlist if re.search(r"^[0-9]+(?=\\s)",row1[0]) is not None and item[0]==re.search(r"^[0-9]+(?=\\s)",row1[0]).group())\nextraValues = (\'value 1\', \'value 2\', \'value3\')\nfor ind, gen in enumerate((v, k, m)):\n    l = list(gen) \n    if len(l) == 1:\n        row1[1] = l[0][1]\n        row1[2] = l[0][2]\n        row1[3] = extraValues[ind]\n        break\n']], ['Assign differing values to list generator results'], 2, 1], [(33578676, 1), [['Dictionary'], ['You could also have some complex scenario where the extra value could be generated by some function other than a dictionary lookup or tuple index.']], [[' v = (item for item in propadd if item[0]==row1[8] and harversine(custx,custy,item[2],item[3])<1500)\nk = (item for item in custadd if item[0]==row1[4])\nm = (item for item in numlist if re.search(r"^[0-9]+(?=\\s)",row1[0]) is not None and item[0]==re.search(r"^[0-9]+(?=\\s)",row1[0]).group())\nextraValues = {v: \'value 1\',\n               k: \'value 2\',\n               m: \'value3\')\nfor gen in (v, k, m):\n    l = list(gen) \n    if len(l) == 1:\n        row1[1] = l[0][1]\n        row1[2] = l[0][2]\n        row1[3] = extraValues[gen]\n        break\n']], ['Assign differing values to list generator results'], 2, 1], [(33587404, 0), [['Use the builtin functions  max  and  list.index'], ['This can be done in a single line as ']], [[' >>> list1=[34,5,1,7,5,3,8,512,8,43]\n>>> max_ele = max(list1)\n>>> print(list1.index(max_ele))\n7\n']], ['How to count how many positions away an element is in a list?'], 2, 1], [(33587404, 1), [['This can be done in a single line as '], ['-10000']], [[' print(list1.index(max(list1)))\n']], ['How to count how many positions away an element is in a list?'], 2, 1], [(33595664, 0), [['If that is waht you are asking the answer will be:'], ['If inside keygrid you have a list of keys you can do this:']], [[' for row in range(HEIGHT):\n    for col in range(WIDTH):\n        if keygrid[row][col] in stockgrid[row][col]:\n           stockgrid[row][col][keygrid[row][col]]+=1\n']], ['Retreiving data from a nested deep.copy dictionary made by list comprehension in Python'], 2, 1], [(33607716, 0), [['In your form view add the following code:'], ['Then we need to generate the requested reports from  js  using python code whithout using :']], [[' <button string="Reports_print" name="print_reports" type="object"/>\n']], ['Print two report in Odoo8'], 7, 0], [(33607716, 1), [['Then we need to generate the requested reports from  js  using python code whithout using :'], ["For that your method `print_reports' should be:"]], [[" return {\n        'type': 'ir.actions.report.xml',\n        'report_name': 'my_report',\n        'datas': datas,\n        'nodestroy': True\n    }\n"]], ['Print two report in Odoo8'], 7, 0], [(33607716, 2), [["For that your method `print_reports' should be:"], ['In your js script  /modulename/static/js/script.js  do this:']], [[' def print_reports(self, cr, uid, ids, context):\n    """DO NOT EDIT !"""\n']], ['Print two report in Odoo8'], 7, 0], [(33607716, 3), [['In your js script  /modulename/static/js/script.js  do this:'], ['we call python method  get_reports  from  js  and the result is reports as  64 base string \nThe  get_reports  method generate and format reports before sending \nthem to  js . \nDo it as bellow:   ']], [[" openerp.MODULENAME=function(instance)\n{\n\n    var QWEB=instance.web.qweb,_t=instance.web._t;\n    instance.web.DataSet.include({\n        call_button:function(method, args){\n            var id = args[0];\n            if(String(method)=='print_reports'){\n                //get_reports should be created in modele_name class\n                new instance.web.Model('modele_name',this.get_context()).ca    ll('get_reports',[id],{context:this.get_context()}).done(function(reports){\n                    for(var b=0; b<reports.length; b+=2)\n                          download('data:application/pdf;base64,'+reports[b],reports[b+1]+'.pdf','application/pdf');\n                    });\n            }\n            return this._super(method, args);\n        }\n    });\n};\n"]], ['Print two report in Odoo8'], 7, 0], [(33607716, 4), [['we call python method  get_reports  from  js  and the result is reports as  64 base string \nThe  get_reports  method generate and format reports before sending \nthem to  js . \nDo it as bellow:   '], ['To download them, i used  download.js  script,\nThere are many ways to do that, but i found that download.js is the easiest way. \nThe content of  download.js :']], [[' def get_reports(self, cr, uid, ids, context):\n    #Get datas used in the reports from modele\n\n    datas = {\n        \'ids\': ids,\n        \'model\': \'modele_name\',\n        \'form\': {\n            \'key\': value,\n             ...\n        }\n    }\n    pdf1 = self.pool.get(\'ir.actions.report.xml\').render_report(cr,\n                                                                uid,\n                                                                ids,\n                                                                "report_name1",\n                                                                datas,\n                                                                context=None)\n\n\n    pdf2 = self.pool.get(\'ir.actions.report.xml\').render_report(cr,\n                                                                uid,\n                                                                ids,\n                                                                "report_name2",\n                                                                datas,\n                                                                context=None)\n    ...\n\n    #We send \'report naem \' to name downloaded report (\'reports[b+1]+\'.pdf\')\n    return pdf1[0].encode(\'base64\'), \'report_name1\', pdf2[0].encode(\n        \'base64\'), \'report_name2\',...\n']], ['Print two report in Odoo8'], 7, 0], [(33607716, 5), [['To download them, i used  download.js  script,\nThere are many ways to do that, but i found that download.js is the easiest way. \nThe content of  download.js :'], ['To be able to call  download  method in your script you must load  download.js  file, to do that modify MODULENAME_view.xml to add a new line']], [[' //download.js v3.0, by dandavis; 2008-2014. [CCBY2] see     http://danml.com/download.html for tests/usage\n// v1 landed a FF+Chrome compat way of downloading strings to     local un-named files, upgraded to use a hidden frame and     optional mime\n// v2 added named files via a[download], msSaveBlob, IE (10+)     support, and window.URL support for larger+faster saves     than dataURLs\n// v3 added dataURL and Blob Input, bind-toggle arity, and     legacy dataURL fallback was improved with force-download mime and     base64 support\n\n// data can be a string, Blob, File, or dataURL\n\n\n\n\nfunction download(data, strFileName, strMimeType) {\n    var self = window, // this script is only for browsers     anyway...\n        u = "application/octet-stream", // this default mime     also triggers iframe downloads\n        m = strMimeType || u, \n        x = data,\n        D = document,\n        a = D.createElement("a"),\n        z = function(a){return String(a);},\n\n\n        B = self.Blob || self.MozBlob || self.WebKitBlob || z,\n        BB = self.MSBlobBuilder || self.WebKitBlobBuilder ||     self.BlobBuilder,\n        fn = strFileName || "download",\n        blob, \n        b,\n        ua,\n        fr;\n\n    //if(typeof B.bind === \'function\' ){ B=B.bind(self); }\n\n    if(String(this)==="true"){ //reverse arguments, allowing     download.bind(true, "text/xml", "export.xml") to act as a callback\n        x=[x, m];\n        m=x[0];\n        x=x[1]; \n    }\n\n\n\n    //go ahead and download dataURLs right away\n    if(String(x).match(/^data\\:[\\w+\\-]+\\/[\\w+\\-]+[,;]/)){\n        return navigator.msSaveBlob ?  // IE10 can\'t do a[download], only Blobs:\n            navigator.msSaveBlob(d2b(x), fn) : \n            saver(x) ; // everyone else can save dataURLs un-processed\n    }//end if dataURL passed?\n\n    try{\n\n        blob = x instanceof B ? \n            x : \n            new B([x], {type: m}) ;\n    }catch(y){\n        if(BB){\n            b = new BB();\n            b.append([x]);\n            blob = b.getBlob(m); // the blob\n        }\n\n    }\n\n\n\n    function d2b(u) {\n        var p= u.split(/[:;,]/),\n        t= p[1],\n        dec= p[2] == "base64" ? atob : decodeURIComponent,\n        bin= dec(p.pop()),\n        mx= bin.length,\n        i= 0,\n        uia= new Uint8Array(mx);\n\n        for(i;i<mx;++i) uia[i]= bin.charCodeAt(i);\n\n        return new B([uia], {type: t});\n     }\n\n    function saver(url, winMode){\n\n\n        if (\'download\' in a) { //html5 A[download]          \n            a.href = url;\n            a.setAttribute("download", fn);\n            a.innerHTML = "downloading...";\n            D.body.appendChild(a);\n            setTimeout(function() {\n            a.click();\n            D.body.removeChild(a);\n            if(winMode===true){setTimeout(function(){     self.URL.revokeObjectURL(a.href);}, 250 );}\n            }, 66);\n            return true;\n        }\n\n        //do iframe dataURL download (old ch+FF):\n        var f = D.createElement("iframe");\n        D.body.appendChild(f);\n        if(!winMode){ // force a mime that will download:\n            url="data:"+url.replace(/^data:([\\w\\/\\-\\+]+)/, u);\n        }\n\n\n        f.src = url;\n        setTimeout(function(){ D.body.removeChild(f); }, 333);\n\n    }//end saver \n\n\n    if (navigator.msSaveBlob) { // IE10+ : (has Blob, but not     a[download] or URL)\n        return navigator.msSaveBlob(blob, fn);\n    }   \n\n    if(self.URL){ // simple fast and modern way using Blob and     URL:\n        saver(self.URL.createObjectURL(blob), true);\n    }else{\n        // handle non-Blob()+non-URL browsers:\n        if(typeof blob === "string" || blob.constructor===z ){\n            try{\n                return saver( "data:" +  m   + ";base64,"  +      self.btoa(blob)  ); \n            }catch(y){\n                return saver( "data:" +  m   + "," +     encodeURIComponent(blob)  ); \n            }\n        }\n\n        // Blob but not URL:\n        fr=new FileReader();\n        fr.onload=function(e){\n            saver(this.result); \n        };\n        fr.readAsDataURL(blob);\n    }   \n    return true;\n} /* end download() */\n']], ['Print two report in Odoo8'], 7, 0], [(33607716, 6), [['To be able to call  download  method in your script you must load  download.js  file, to do that modify MODULENAME_view.xml to add a new line'], ['-10000']], [[' <?xml version="1.0" encoding="utf-8"?>\n<openerp>\n    <data>\n        <template id="assets_backend_MODULENAME" name="MODULENAME assets" inherit_id="web.assets_backend">\n            <xpath expr="." position="inside">\n                ...\n                <!-- The new line-->\n                <script type="text/javascript" src="/MODULENAME/static/src/js/download.js"></script>\n                ...\n            </xpath>\n        </template>\n    </data>\n</openerp> \n']], ['Print two report in Odoo8'], 7, 0], [(33613596, 1), [['Which gives us:'], ["So we have MultiIndexes on both the rows and columns. Assuming you don't want that, I would just do:"]], [['        Val     \nBC       b    c\nXY UV          \nx  u   222  111\n   v   444  333\ny  u    22   11\n   v    44   33\n']], ['Pandas dataframe - transform column values into individual columns'], 4, 0], [(33613596, 3), [["And that'll give you:"], ['-10000']], [[' BC XY UV    b    c\n0   x  u  222  111\n1   x  v  444  333\n2   y  u   22   11\n3   y  v   44   33\n']], ['Pandas dataframe - transform column values into individual columns'], 4, 0], [(33705180, 0), [['We could use  ._get_numeric_data()'], ['Or another option is  select_dtypes()']], [[" import pandas as pd #import the pandas library\n#creating a small dataset for testing\ndf1 = pd.DataFrame({'PassengerId' :  [1, 2, 3], \n        'Name' : ['Abbing, Mr. Anthony', 'Ann, C', 'John, H'], \n        'Fare' : [7.25, 71.28, 7.92]})\n#extract only the numeric column types\ndf2 = df1._get_numeric_data()\nprint(df2)\n"]], ['how to exclude the non numerical integers from a data frame in Python'], 2, 1], [(33705180, 1), [['Or another option is  select_dtypes()'], ['-10000']], [[" df3 = df1.select_dtypes(include = ['int64', 'float64'])\nprint(df3)\n"]], ['how to exclude the non numerical integers from a data frame in Python'], 2, 1], [(33706780, 0), [["I assume you'd rather get this kind of structure:"], ['The following code will do the trick:']], [[' files = {folder1: [file1, file2], folder2: [file3], ...}\n']], ['How to read folder structure and assign it to datastructure?'], 2, 0], [(33706780, 1), [['The following code will do the trick:'], ['-10000']], [[" import os\n\nrootDir = '.'\nfiles = {}\nfor dirName, subdirList, fileList in os.walk(rootDir):\n    files[dirName] = fileList\n"]], ['How to read folder structure and assign it to datastructure?'], 2, 1], [(33711511, 1), [[''], ['']], [[' pill.show()\n']], ['Rotate photo via python'], 3, 0], [(33711511, 2), [[''], ['will result in']], [[' rotated_img = pill_img.rotate(90)\nrotated_img.show()\n']], ['Rotate photo via python'], 3, 0], [(33729888, 0), [['Code:'], ['Output:']], [[" lst=[\n{'field_id': u'36908'},{'field_name': u'Code'},{'field_value': u'900321'},\n{'field_id': u'36909'},{'field_name': u'Description'}, {'field_value': u'TIG 2.4MM TUNGSTEN (EACH ROD)'},\n{'field_id': u'36910'}, {'field_name': u'Quantity'}, {'field_value': u'2'},\n{'field_id': u'36911'}, {'field_name': u'Price'}, {'field_value': u'21.00'},\n{'field_id': u'36912'}, {'field_name': u'Line Total'}, {'field_value': u'42.00'},\n{'field_id': u'36908'}, {'field_name': u'Code'}, {'field_value': u'92.01.15.08'},\n{'field_id': u'36909'}, {'field_name': u'Description'}, {'field_value': u'BINZEL .8MM MIG TIPS MB15'},\n{'field_id': u'36910'}, {'field_name': u'Quantity'}, {'field_value': u'6'},\n{'field_id': u'36911'}, {'field_name': u'Price'}, {'field_value': u'2.60'},\n{'field_id': u'36912'}, {'field_name': u'Line Total'}, {'field_value': u'15.60'}]\n\nnew_lst=[] # List to save output\ndic={} # Temporary dictionary to create output dictionary \ncount=0 # Count variable to count the list element\ndef iterating_list(lst): # Function to iterate over list\n    for value in lst:\n        yield value\niterating=iterating_list(lst)\n\nfor value in iterating :\n    if value.get('field_name'): # If `field_name` matches in the given lists \n    #By default get method return `None` when there is no given key\n        dic.update({value.get('field_name'):next(iterating).get('field_value')})\n        count+=1\n    if count==5: # Resetting when count reaches to 5 \n        count=0\n        new_lst.append(dic)\n        dic={}\nprint new_lst\n"]], ['Merge every Every 6 dictionary into single dictionary of List'], 2, 1], [(33729888, 1), [['Output:'], ['-10000']], [[" [{u'Price': u'21.00', u'Code': u'900321', u'Description': u'TIG 2.4MM TUNGSTEN (EACH ROD)', u'Line Total': u'42.00', u'Quantity': u'2'},\n{u'Price': u'2.60', u'Code': u'92.01.15.08', u'Description': u'BINZEL .8MM MIG TIPS MB15', u'Line Total': u'15.60', u'Quantity': u'6'}]\n"]], ['Merge every Every 6 dictionary into single dictionary of List'], 2, 0], [(33733189, 0), [["The script below runs the  'vode'  solver with both methods, and it\nruns the  'lsoda'  solver.  In each case, it runs the solver with and without the Jacobian function.  Here's the output it generates:"], ['The script:']], [[' vode   adams    jac=None  len(tvals) = 517992\nvode   adams    jac=jac   len(tvals) = 195\nvode   bdf      jac=None  len(tvals) = 516284\nvode   bdf      jac=jac   len(tvals) = 55\nlsoda           jac=None  len(tvals) = 49\nlsoda           jac=jac   len(tvals) = 49\n']], ['Stiff ODE-solver'], 2, 0], [(33733189, 1), [['The script:'], ['-10000']], [[' from __future__ import print_function\n\nimport numpy as np\nfrom scipy.integrate import ode\n\n\ndef func(t, u, mu):\n    tvals.append(t)\n    u1 = u[1]\n    u2 = mu*(1 - u[0]*u[0])*u[1] - u[0]\n    return np.array([u1, u2])\n\n\ndef jac(t, u, mu):\n    j = np.empty((2, 2))\n    j[0, 0] = 0.0\n    j[0, 1] = 1.0\n    j[1, 0] = -mu*2*u[0]*u[1] - 1\n    j[1, 1] = mu*(1 - u[0]*u[0])\n    return j\n\n\nmu = 10000.0\nu0 = [2, 0]\nt0 = 0.0\ntf = 10\n\nfor name, kwargs in [(\'vode\', dict(method=\'adams\')),\n                     (\'vode\', dict(method=\'bdf\')),\n                     (\'lsoda\', {})]:\n    for j in [None, jac]:\n        solver = ode(func, jac=j)\n        solver.set_integrator(name, atol=1e-8, rtol=1e-6, **kwargs)\n        solver.set_f_params(mu)\n        solver.set_jac_params(mu)\n        solver.set_initial_value(u0, t0)\n\n        tvals = []\n        i = 0\n        while solver.successful() and solver.t < tf:\n            solver.integrate(tf, step=True)\n            i += 1\n\n        print("%-6s %-8s jac=%-5s " %\n              (name, kwargs.get(\'method\', \'\'), j.func_name if j else None),\n              end=\'\')\n\n        tvals = np.unique(tvals)\n        print("len(tvals) =", len(tvals))\n']], ['Stiff ODE-solver'], 2, 1], [(33759539, 0), [["This is what list slicing is about, you can take part of your list from i'th element through"], ['thus']], [[' lst[i:]\n']], ['For loop syntax in Python without using range() or xrange()'], 2, 0], [(33759539, 1), [['thus'], ['-10000']], [[' for ind, i in enumerate(lst):\n    for j in lst[ind+1: ]: \n        #Do Something\n']], ['For loop syntax in Python without using range() or xrange()'], 2, 1], [(33795081, 0), [['The first step is to modify your classes to save a reference to the controller:'], ['Now, you can call  show_frame  wherever you want:']], [[' class Login(tk.Frame):\n    def __init__(self, parent, controller):\n        self.controller = controller\n        ...\n\nclass WelcomePage(tk.Frame):\n    def __init__(self, parent, controller):\n        self.controller = controller\n        ...\n']], ['Python Tkinter GUI Frame: How to call a class method from inside a function of another class?'], 2, 0], [(33795081, 1), [['Now, you can call  show_frame  wherever you want:'], ['For more information on the controller see this answer:  https://stackoverflow.com/a/32865334/7432']], [[' if actNum == act_num and pinNum == pin_num:\n    ...\n    self.controller.show_frame(WelcomePage)\n    ...\n']], ['Python Tkinter GUI Frame: How to call a class method from inside a function of another class?'], 2, 0], [(33800210, 0), [['Basically, you are selecting the second axis elements with  indices_array  corresponding to each position along the first axis for all the elements along the third axis. As such, you can do -'], ['Sample run -']], [[' list_arr[np.arange(list_arr.shape[0]),indices_array,:]\n']], ['numpy get values in array of arrays of arrays for array of indices'], 2, 1], [(33811240, 0), [['Either shuffle a list of 16 1s and 48 0s:'], ['or fill the board with 0s and pick a random sample of 16 positions to put 1s in:']], [[' board = [1]*16 + 48*[0]\nrandom.shuffle(board)\nboard = [board[i:i+8] for i in xrange(0, 64, 8)]\n']], ["Python — Randomly fill 2D array with set number of 1's"], 2, 1], [(33811240, 1), [['or fill the board with 0s and pick a random sample of 16 positions to put 1s in:'], ['-10000']], [[' board = [[0]*8 for i in xrange(8)]\nfor pos in random.sample(xrange(64), 16):\n    board[pos//8][pos%8] = 1\n']], ["Python — Randomly fill 2D array with set number of 1's"], 2, 1], [(33857555, 0), [["Your code examples are a bit confusing to me: if you have  vx ,  vy  vector field coordinates, then you should have  two  meshes:  x  and  y . Using these you can indeed use  scipy.interpolate.griddata  to obtain a smooth vector field for integration, however that seemed to eat up too much memory when I tried to do that. Here's a similar solution based on  scipy.interpolate.interp2d :"], ['']], [[" import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.interpolate as interp\nimport scipy.integrate as integrate\n\n#dummy input from the streamplot demo\ny, x = np.mgrid[-3:3:100j, -3:3:100j]\nvx = -1 - x**2 + y\nvy = 1 + x - y**2\n\n#dfun = lambda x,y: [interp.griddata((x,y),vx,np.array([[x,y]])), interp.griddata((x,y),vy,np.array([[x,y]]))]\ndfunx = interp.interp2d(x[:],y[:],vx[:])\ndfuny = interp.interp2d(x[:],y[:],vy[:])\ndfun = lambda xy,t: [dfunx(xy[0],xy[1])[0], dfuny(xy[0],xy[1])[0]]\n\np0 = (0.5,0.5)\ndt = 0.01\nt0 = 0\nt1 = 1\nt = np.arange(t0,t1+dt,dt)\n\nstreamline=integrate.odeint(dfun,p0,t)\n\n#plot it\nplt.figure()\nplt.plot(streamline[:,0],streamline[:,1])\nplt.axis('equal')\nmymask = (streamline[:,0].min()*0.9<=x) & (x<=streamline[:,0].max()*1.1) & (streamline[:,1].min()*0.9<=y) & (y<=streamline[:,1].max()*1.1)\nplt.quiver(x[mymask],y[mymask],vx[mymask],vy[mymask])\nplt.show()\n"]], ['Integrating a vector field (a numpy array) using scipy.integrate'], 2, 1], [(33857555, 1), [[''], ["which is compatible with  odeint . It computes the interpolated values for each  p  point given to it by  odeint . This solution doesn't consume excessive memory, however it takes  much much  longer to run with the above parameters. This is probably due to a lot of evaluations of  dfun  in  odeint , much more than what would be evident from the 100 time points given to it as input."]], [[' xyarr = np.array(zip(x.flatten(),y.flatten()))\ndfun = lambda p,t: [interp.griddata(xyarr,vx.flatten(),np.array([p]))[0], interp.griddata(xyarr,vy.flatten(),np.array([p]))[0]]\n']], ['Integrating a vector field (a numpy array) using scipy.integrate'], 2, 0], [(33869234, 0), [['Did you try'], ['for example']], [[' fig, axes = plt.subplots(2)\n\nplt.subplot2grid((1,5), (0,0), colspan=3)\n# here plot something\n\nplt.subplot2grid((1,5), (0,3), colspan=2)\n# here plot something\n\nplt.show()\n']], ['Creating a subplot instead of separate plots'], 3, 0], [(33869234, 1), [['for example'], ['-10000']], [[' import matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2)\n\nplt.subplot2grid((1,5), (0,0), colspan=3)\nplt.plot([1,2,3]) # plot something\n\nplt.subplot2grid((1,5), (0,3), colspan=2)\nplt.plot([1,2,1]) # plot something\n\nplt.show()\n']], ['Creating a subplot instead of separate plots'], 3, 0], [(33869234, 2), [['-10000'], ['']], [[" import pandas as pd\nimport numpy as np\n\ndef plot_bar(corr_df):\n\n    dfstacked = corr_df.stack().order()\n    dfstacked.plot(kind='bar', rot=60)\n\ndef plot_heatmap(corr_df):\n\n    corr_df = corr_df.fillna(value=0)\n    plt.pcolormesh(corr_df.values, cmap=plt.cm.Blues)\n    plt.yticks(np.arange(0.5, len(corr_df.index), 1), corr_df.index)\n    plt.xticks(np.arange(0.5, len(corr_df.columns), 1), corr_df.columns)\n\n\ndf = pd.DataFrame(range(10))\n\nfig, axes = plt.subplots(2)\n\nplt.subplot2grid((1,5), (0,0), colspan=3)\nplot_bar(df)\n\nplt.subplot2grid((1,5), (0,3), colspan=2)\nplot_heatmap(df)\n\nplt.show()\n"]], ['Creating a subplot instead of separate plots'], 3, 1], [(33875238, 0), [["I don't think it is currently possible to pass XlsxWriter constructor options via the Pandas API but you can workaround the  strings_to_url  issue as follows:"], ['Update : In recent version of Pandas you can pass XlsxWriter constructor options to  ExcelWriter()  directly and you do not need to set  writer.book.strings_to_urls  indirectly:']], [[" import pandas as pd\n\ndf = pd.DataFrame({'Data': ['http://python.org']})\n\n# Create a Pandas Excel writer using XlsxWriter as the engine.\nwriter = pd.ExcelWriter('pandas_simple.xlsx', engine='xlsxwriter')\n\n# Don't convert url-like strings to urls.\nwriter.book.strings_to_urls = False\n\n# Convert the dataframe to an XlsxWriter Excel object.\ndf.to_excel(writer, sheet_name='Sheet1')\n\n# Close the Pandas Excel writer and output the Excel file.\nwriter.save()\n"]], ['Export Pandas data frame with text column containg utf-8 text and URLs to Excel'], 2, 1], [(33875238, 1), [['Update : In recent version of Pandas you can pass XlsxWriter constructor options to  ExcelWriter()  directly and you do not need to set  writer.book.strings_to_urls  indirectly:'], ['-10000']], [[" writer = pd.ExcelWriter('pandas_simple.xlsx', \n                        engine='xlsxwriter', \n                        options={'strings_to_urls': False})\n"]], ['Export Pandas data frame with text column containg utf-8 text and URLs to Excel'], 2, 0], [(33907941, 1), [["For example, if  data = ['a','b','c','d','e','f','g','h']  then:"], ['and']], [[' >>> write_cols(data,3)\na   b   c\nd   e   f\ng   h\n']], ['python, zip:Discard extra elements'], 3, 0], [(33927174, 0), [['When you create a  one to one field  to your user model,'], ['you can access the user from the profile']], [[' class Profile(models.Model):\n    user = models.OneToOneField(User)\n']], ['Django reverse url to onetoonefield on success'], 3, 0], [(33927174, 1), [['you can access the user from the profile'], ['and you can also access the  profile  from the user']], [[' profile.user\n']], ['Django reverse url to onetoonefield on success'], 3, 0], [(33927174, 2), [['and you can also access the  profile  from the user'], ['In your view,  self.object  is the user, so  self.object.profile.id  will give you the profile id.']], [[' user.profile\n']], ['Django reverse url to onetoonefield on success'], 3, 0], [(33928554, 0), [['-10000'], ['-10000']], [['Code import numpy as np\n\nclass CustomIndexTable:\n    def __init__(self, rows, columns, elements):\n        self.rows = rows\n        self.columns = columns\n        self.data = np.array(elements, dtype=object)\n        self.data = self.data.reshape((len(rows), len(columns)))\n\n    def __getitem__(self, index):\n        x, y = index[:2], index[2:]\n        return self.data[self.rows.index(x),self.columns.index(y)]\n\n    def __setitem__(self, index, element):\n        x, y = index[:2], index[2:]\n        self.data[self.rows.index(x),self.columns.index(y)] = element\n\n    def _where(self, element):\n        x, y = np.where(self.data == element)\n        return self.rows[x] + self.columns[y]\n\n    def transpose(self):\n        self.rows, self.columns = self.columns, self.rows\n        self.data = self.data.T\n\n    def where(self, sequence):\n        elements = []\n        start = 0\n        for end in xrange(1, len(sequence)+1):\n            if sequence[start:end] in self.data:\n                elements.append(sequence[start:end])\n                start = end\n        return \'\'.join(self._where(e) for e in elements)\n\ndef input_matrix_data(text):\n    return raw_input(text).split()\n\ncol_indices = input_matrix_data("Column indices: ")\nrow_indices = input_matrix_data("Row indices: ")\ndata = input_matrix_data("All data, sorted by row: ")\n\ntable = CustomIndexTable(row_indices, col_indices, data)\n']], ['two dimensional array for encryption in python'], 8, 1], [(33928554, 1), [['-10000'], ['and for the data']], [[' 23 54 34 75\n']], ['two dimensional array for encryption in python'], 8, 0], [(33928554, 2), [['and for the data'], ['The structure of the class makes a few assumptions required for functionality, which are implicit from your question.']], [[' AM h 9 C 56 in 13 ok\n']], ['two dimensional array for encryption in python'], 8, 0], [(33928554, 3), [['The structure of the class makes a few assumptions required for functionality, which are implicit from your question.'], ['access a specific element,']], [[" >>> table.data\narray([['AM', 'h', '9', 'C'],\n       ['56', 'in', '13', 'ok']], dtype=object)\n"]], ['two dimensional array for encryption in python'], 8, 0], [(33928554, 4), [['access a specific element,'], ['set a new value for an element,']], [[" >>> table['7834']\n'13'\n"]], ['two dimensional array for encryption in python'], 8, 0], [(33928554, 5), [['set a new value for an element,'], ['find where an element resides,']], [[" >>> table['7834']  = 'B'\n>>> table['7834']\n'B'\n"]], ['two dimensional array for encryption in python'], 8, 0], [(33928554, 6), [['find where an element resides,'], ['or permanently transpose the array.']], [[" >>> table.where('9')   # this should work equally well for '9C'\n'6534'\n"]], ['two dimensional array for encryption in python'], 8, 0], [(33928554, 7), [['or permanently transpose the array.'], ['Finally, you can add more methods to this class as they serve your needs, e.g. adding/deleting a whole row of elements after the table has been created.']], [[" >>> table.transpose()\n>>> table.where('9')\n'3465'\n"]], ['two dimensional array for encryption in python'], 8, 0], [(33948731, 0), [["You can override your class's  __get__  method to make it a descriptor. The  __get__  method will be called when someone gets the decorated method from within its containing object, and is passed the containing object, which you will then be able to pass to the original method. It returns an object which implements the functionality you need."], ['The  Wrapper  object implements  __call__ , and any properties you want, so move those implementations into that object. It would look like:']], [[' def __get__(self, obj, objtype):\n    return Wrapper(self, obj)\n']], ['Modifying a cooldown decorator to work for methods instead of functions'], 2, 0], [(33948731, 1), [['The  Wrapper  object implements  __call__ , and any properties you want, so move those implementations into that object. It would look like:'], ['-10000']], [[' class Wrapper:\n    def __init__(self, cdfunc, obj):\n        self.cdfunc = cdfunc\n        self.obj = obj\n    def __call__(self, *args, **kwargs):\n        #do stuff...\n        self.cdfunc._func(self.obj, *args, **kwargs)\n    @property\n    def remaining(self):\n        #...get needed things from self.cdfunc\n']], ['Modifying a cooldown decorator to work for methods instead of functions'], 2, 0], [(33970546, 0), [['You can use regular expressions'], ['But the best way to do this is using a generator function:']], [[" >>> import re\n>>> l = ['A','B','A','A','B','B','A']\n>>> pat = re.compile(r'BAA')\n>>> sequences = pat.findall(''.join(l))\n>>> sequences\n['BAA']\n>>> len(sequences)\n1\n>>> \n"]], ['How to find defined sequence in the list?'], 2, 1], [(33970546, 1), [['But the best way to do this is using a generator function:'], ['-10000']], [[" >>> def find_sequences(sequences, events):\n...     i = 0\n...     events_len = len(events)\n...     sequences_len = len(sequences)\n...     while i < sequences_len:\n...             if sequences[i:i+events_len] == events: \n...                 yield True\n...             i = i + 1\n... \n>>> list(find_sequences(lst, events))\n>>> sum(find_sequences(['AB', 'A', 'BA', 'A', 'BA'], ['A', 'BA']))\n2\n"]], ['How to find defined sequence in the list?'], 2, 1], [(33972303, 0), [['First, you can create group numbers by comparing the value column to zero and then taking a cumulative sum of these boolean values.'], ['Next, you can use a dictionary comprehension together with  loc  to select the relevant  group_no  dataframe. To get the last group number, I get the last value using  iat  for location based indexing.']], [[" df['group_no'] = (df.val == 0).cumsum()\n>>> df.head(6)\n      EndDate       val  group_no\n0  2007-10-31  0.000000         1\n1  2007-11-30 -0.033845         1\n2  2007-12-31 -0.033630         1\n3  2008-01-31 -0.009449         1\n4  2008-02-29  0.000000         2\n5  2008-03-31 -0.057450         2\n"]], ['Splitting a dataframe based on column values'], 3, 0], [(33972303, 1), [['Next, you can use a dictionary comprehension together with  loc  to select the relevant  group_no  dataframe. To get the last group number, I get the last value using  iat  for location based indexing.'], ['EDIT  \nAs suggested by @DSM, using groupby appears to be about 6x faster based on a sample dataframe with 15k rows.']], [[" d = {i: df.loc[df.group_no == i, ['EndDate', 'val']] \n     for i in range(1, df.group_no.iat[-1])}\n\n>>> d\n{1:       EndDate       val\n 0  2007-10-31  0.000000\n 1  2007-11-30 -0.033845\n 2  2007-12-31 -0.033630\n 3  2008-01-31 -0.009449, \n 2:       EndDate       val\n 4  2008-02-29  0.000000\n 5  2008-03-31 -0.057450\n 6  2008-04-30 -0.038694, \n 3:       EndDate       val\n 7  2008-05-31  0.000000\n 8  2008-06-30 -0.036245\n 9  2008-07-31 -0.005286}\n"]], ['Splitting a dataframe based on column values'], 3, 0], [(33972303, 2), [['EDIT  \nAs suggested by @DSM, using groupby appears to be about 6x faster based on a sample dataframe with 15k rows.'], ['-10000']], [[" d = {n: df2.ix[rows] \n     for n, rows in enumerate(df2.groupby('group_no').groups)}\n"]], ['Splitting a dataframe based on column values'], 3, 0], [(33978569, 0), [['This is easy to do without regular expressions:'], ['Alternatively, if you must use regular expressions:']], [[" >>> s = 'Four score and seven years ago.'\n>>> ss = s + 5*' '; [ss[i:i+6] for i in range(0, len(s) - 1, 6)]\n['Four s', 'core a', 'nd sev', 'en yea', 'rs ago', '.     ']\n"]], ['greedy regex split python every nth line'], 2, 1], [(33978569, 1), [['Alternatively, if you must use regular expressions:'], ['The key in both cases is creating the string  ss  which has enough blank space at the end.']], [[" >>> import re\n>>> re.findall('.{6}', ss)\n['Four s', 'core a', 'nd sev', 'en yea', 'rs ago', '.     ']\n"]], ['greedy regex split python every nth line'], 2, 1], [(34008175, 0), [['You can access elements from .ui designs by their names. E.g. there is a design for main window with one button:'], ['You init widget object with it:']], [[' <?xml version="1.0" encoding="UTF-8"?>\n<ui version="4.0">\n <class>MainWindow</class>\n <widget class="QMainWindow" name="MainWindow">\n  ...\n  <widget class="QPushButton" name="btn"/>\n  ...\n </widget>\n</ui>\n']], ['PyQt change element in .ui file'], 3, 0], [(34008175, 1), [['You init widget object with it:'], ['Then from your method you can get access to that button:']], [[" class MainWindow(QMainWindow):\n    def __init__(self):\n        QMainWindow.__init__(self)\n        uic.loadUi('window.ui', self)\n\nmain_window = MainWindow()\n"]], ['PyQt change element in .ui file'], 3, 0], [(34008175, 2), [['Then from your method you can get access to that button:'], ['-10000']], [[' @pyqtSlot()\ndef click_my_btn(self, sender):\n    main_window.btn.hide()\n']], ['PyQt change element in .ui file'], 3, 0], [(34014527, 0), [['You could use  expand_grid  which is mentioned in  docs cookbook :'], ['For existing dataframes you first will need to create one dictionary from your dataframes. You could combine to one with one of the answers to that  question . Example for your case:']], [[" def expand_grid(data_dict):\n  rows = itertools.product(*data_dict.values())\n  return pd.DataFrame.from_records(rows, columns=data_dict.keys())\n\nexpand_grid({'val_1': [0.00789, 0.01448, 0.03157], 'val_2' : [0.5, 1.0]})\n\nIn [107]: expand_grid({'val_1': [0.00789, 0.01448, 0.03157], 'val_2' : [0.5, 1.0]})\nOut[107]:\n     val_1  val_2\n0  0.00789    0.5\n1  0.00789    1.0\n2  0.01448    0.5\n3  0.01448    1.0\n4  0.03157    0.5\n5  0.03157    1.0\n"]], ['Python Create Combinations from Multiple Data Frames'], 2, 1], [(34014527, 1), [['For existing dataframes you first will need to create one dictionary from your dataframes. You could combine to one with one of the answers to that  question . Example for your case:'], ['-10000']], [[" expand_grid(dict(var_1.to_dict('list'), **var_2.to_dict('list')))\n\nIn [122]: expand_grid(dict(var_1.to_dict('list'), **var_2.to_dict('list')))\nOut[122]:\n     val_1  val_2\n0  0.00789    0.5\n1  0.00789    1.0\n2  0.01448    0.5\n3  0.01448    1.0\n4  0.03157    0.5\n5  0.03157    1.0\n"]], ['Python Create Combinations from Multiple Data Frames'], 2, 1], [(34016799, 0), [['The following will extract your two columns using the  span  tag inside the  li  elements:'], ['This would give you the following output:']], [[' html = """\n<table id="detailBody" width="100%" cellspacing="0" cellpadding="0" border="0" class="tab2" style="display: block;">\n<tbody>\n<tr>\n    <td>\n    <ul>\n    <li><span>15:00:19</span><span class="red">11.750</span><span class="red">5392</span><span class="fr red">?</span></li>\n    <li><span>14:56:55</span><span class="red">11.750</span><span class="red">17</span><span class="fr red">?</span></li>\n    <li><span>14:56:52</span><span class="red">11.750</span><span class="red">479</span><span class="fr red">?</span></li>\n    <li><span>14:56:49</span><span class="">11.740</span><span class="green">6</span><span class="fr green">?</span></li>\n    <li><span>14:56:46</span><span class="">11.740</span><span class="green">333</span><span class="fr green">?</span></li>\n    <li><span>14:56:43</span><span class="">11.740</span><span class="green">21</span><span class="fr green">?</span></li>\n    <li><span>14:56:40</span><span class="">11.740</span><span class="green">15</span><span class="fr green">?</span></li>\n    <li><span>14:56:37</span><span class="">11.740</span><span class="green">35</span><span class="fr green">?</span></li>\n    <li><span>14:56:34</span><span class="red">11.750</span><span class="red">11</span><span class="fr red">?</span></li>\n    <li><span>14:56:31</span><span class="">11.740</span><span class="green">3</span><span class="fr green">?</span></li>\n    <li><span>14:56:28</span><span class="">11.740</span><span class="green">24</span><span class="fr green">?</span></li>\n    <li><span>14:56:22</span><span class="red">11.750</span><span class="red">291</span><span class="fr red">?</span></li>\n    <li><span>14:56:19</span><span class="">11.740</span><span class="red">198</span><span class="fr red">?</span></li>\n    <li><span>14:56:16</span><span class="green">11.730</span><span class="green">15</span><span class="fr green">?</span></li>\n    </ul>\n    </td>\n</tr>\n</tbody></table>"""\n\nsoup = BeautifulSoup(html)\n\ncol_3 = []\ncol_4 = []\n\nfor li in soup.find_all(\'table\')[0].find_all("li"):\n    cols = li.find_all("span")\n    col_3.append(cols[2].text)\n    col_4.append(cols[3].text)\n\nprint col_3 \nprint col_4\n']], ['Python, using BeautifulSoup parsing values from a table'], 2, 1], [(34016799, 1), [['This would give you the following output:'], ['-10000']], [[" [u'5392', u'17', u'479', u'6', u'333', u'21', u'15', u'35', u'11', u'3', u'24', u'291', u'198', u'15']\n[u'?', u'?', u'?', u'?', u'?', u'?', u'?', u'?', u'?', u'?', u'?', u'?', u'?', u'?']\n"]], ['Python, using BeautifulSoup parsing values from a table'], 2, 0], [(34030902, 1), [['You could convert the year seconds to your sample index using:'], ['So maybe you need to go the other way. You have the index (sample number) and want the corresponding date. You can calculate that using:']], [[' index = yearSeconds / (60*60*6) # / 60 sec/min * 60 min/hour * 6 hours\n']], ['Writing NetCDF time variable from start of year'], 3, 0], [(34030902, 2), [['So maybe you need to go the other way. You have the index (sample number) and want the corresponding date. You can calculate that using:'], ['Be sure you have set the correct yearStart for your data.']], [[' sampleDateTime = yearStart + datetime.timedelta(0, index * 60 * 60 * 6)\n']], ['Writing NetCDF time variable from start of year'], 3, 0], [(34057756, 1), [['-10000'], ['This will store the cached values of  foo  for every  Example  instance your program generates - in other words, it can leak memory.  lru_cache  is a bit smarter, since it limits the size of the cache, but then you might end up re-computing some of the values you needed if they go out of the cache. A better solution is to attach the cached values to instances of  Example  they belong to, like done by  cached_property .']], [[' CACHE = {}\n\nclass Example(object):\n    @property\n    def foo(self):\n        if self not in CACHE:\n            CACHE[self] = ...  # do the actual computation\n        return CACHE[self]\n']], ["How to combine SQLAlchemy's @hybrid_property decorator with Werkzeug's cached_property decorator?"], 2, 0], [(34066053, 0), [['You can do this easily with  pandas :'], ['To convert a NumPy array into a dictionary you can use:']], [[' import pandas as pd\nlistOfDicts = [{"key1":10, "key3":19},\n               {"key1":20, "key2":25, "key3":29},\n               {"key1":30, "key2":35, "key3":39},\n               {"key1":40, "key2":45, "key3":49}]\n\ndf = pd.DataFrame(listOfDicts)\nvals = df.values\nvals\n\narray([[10, nan, 19],\n       [20, 25,  29],\n       [30, 35,  39],\n       [40, 45,  49]])\n']], ['From list of dictionaries to np array of arrays and vice-versa'], 2, 0], [(34066053, 1), [['To convert a NumPy array into a dictionary you can use:'], ['-10000']], [[" df2 = pd.DataFrame(vals, columns=df.columns)\ndf2.to_dict(orient='records')\n\n[{'key1': 10.0, 'key2': nan, 'key3': 19.0},\n {'key1': 20.0, 'key2': 25.0, 'key3': 29.0},\n {'key1': 30.0, 'key2': 35.0, 'key3': 39.0},\n {'key1': 40.0, 'key2': 45.0, 'key3': 49.0}]\n"]], ['From list of dictionaries to np array of arrays and vice-versa'], 2, 0], [(34069642, 0), [['Ideally, use  contextlib.contextmanager . For the case of deriving:'], ['For the case of holding another object:']], [[" import contextlib\n\nclass context_mixin:\n    def __enter__(self):\n         self.__context = self.context()\n         return self.__context.__enter__()\n    def __exit__(self, *args):\n         return self.__context.__exit__(*args)\n\nclass class_a(context_mixin):\n    @contextlib.contextmanager\n    def context(self):\n         print('class_a enter')\n         try:\n             yield self\n         finally:\n             print('class_a exit')\n\nclass class_b(class_a):\n    @contextlib.contextmanager\n    def context(self):\n        with super().context():\n            print('class_b enter')\n            try:\n                yield self\n            finally:\n                print('class_b exit')\n"]], ["Pythons 'with'-statement: correctly nest/derive classes with __enter__/__exit__"], 2, 1], [(34069642, 1), [['For the case of holding another object:'], ['-10000']], [[" class class_b(context_mixin):\n    def __init__(self):\n        self.a = class_a()\n    @contextlib.contextmanager\n    def context(self):\n        with self.a:\n            print('class_b enter')\n            try:\n                yield self\n            finally:\n                print('class_b exit')\n"]], ["Pythons 'with'-statement: correctly nest/derive classes with __enter__/__exit__"], 2, 0], [(34073053, 0), [['Use some index trickery:'], ['the major part of this is  colors[i*chunks//len(nums)%len(colors)]  which can be broken down like this:']], [[' >>> nums = [1, 2, 3, 4, 5, 6, 7, 8]\n>>> colors = [\'red\', \'green\', \'orange\', \'blue\']\n>>> chunks = 4\n>>> for i,num in enumerate(nums):\n    print("%s:%s"%(num,colors[i*chunks//len(nums)%len(colors)]))\n1:red\n2:red\n3:green\n4:green\n5:orange\n6:orange\n7:blue\n8:blue\n']], ['Python: separate list of values into x number of sections, and give each value in x a variable'], 3, 1], [(34073053, 1), [['the major part of this is  colors[i*chunks//len(nums)%len(colors)]  which can be broken down like this:'], ['high value of  chunks  example:']], [[' colors[i*chunks//len(nums)%len(colors)]\n       ^                              index of num in nums\n        ^      ^                      multiply by chunks then later dividing by len is the\n                                      same as dividing by len/chunks\n               ^                      explicit integer divide is important for indexing\n                          ^           ensures that there is no index error if \n                                      chunks>len(colors) (check example)\n']], ['Python: separate list of values into x number of sections, and give each value in x a variable'], 3, 0], [(34079643, 0), [['Lets say you have the current time in String format:'], ['You can use the  split  method to split this string at every instance of a colon (":"). This returns a list with 3 elements.']], [[' timeString = "10:59:16"\n']], ['Changing an input from an integer to a string back to an integer'], 4, 0], [(34079643, 1), [['You can use the  split  method to split this string at every instance of a colon (":"). This returns a list with 3 elements.'], ['You can store these elements and do whatever calculations you choose with them.']], [[' timeList = timeString.split(":")\nprint(timeList) -> ["10","59","16"]\n']], ['Changing an input from an integer to a string back to an integer'], 4, 0], [(34079643, 2), [['You can store these elements and do whatever calculations you choose with them.'], ['Once you have finished your calculations, or adjusted the variables, you can combine them back into a string by concatenating.']], [[' hours = int(timeList[0]) -> 10\nminutes = int(timeList[1]) -> 59\nseconds = int(timeList[2]) -> 16\n']], ['Changing an input from an integer to a string back to an integer'], 4, 0], [(34079643, 3), [['Once you have finished your calculations, or adjusted the variables, you can combine them back into a string by concatenating.'], ['I hope this helps. Good luck Cameron!']], [[' timeString = str(hours) + ":" + str(minutes) + ":" + str(seconds)\nprint(timeString) -> "10:59:16"\n']], ['Changing an input from an integer to a string back to an integer'], 4, 0], [(34082065, 0), [['The solution which you mentioned in a comment from answer to  question :'], ['Some test performance to compare with @Colonel Beauvel solution:']], [[" df.groupby(['id'])['purchased_item'].apply(list).values.tolist()\n\nIn [434]: df.groupby(['id'])['purchased_item'].apply(list).values.tolist()\nOut[434]:\n[['apple', 'banana', 'carrot'],\n ['banana'],\n ['apple'],\n ['apple', 'carrot', 'diet_coke'],\n ['banana', 'carrot'],\n ['banana', 'carrot']]\n"]], ['Convert a pandas dataframe in a transactional data format to a list - Python'], 2, 1], [(34082065, 1), [['Some test performance to compare with @Colonel Beauvel solution:'], ['-10000']], [[" In [472]: %timeit [gr['purchased_item'].tolist() for n, gr in df.groupby('id')]\n100 loops, best of 3: 2.1 ms per loop\n\nIn [473]: %timeit df.groupby(['id'])['purchased_item'].apply(list).values.tolist()\n1000 loops, best of 3: 1.36 ms per loop\n"]], ['Convert a pandas dataframe in a transactional data format to a list - Python'], 2, 0], [(34114554, 0), [["Here's some code to generate all possible neighbors of a key:"], ['So, for example:']], [[' def generate_neighbors(key, alphabet):\n    for i in range(len(key)):\n        left, right = key[:i], key[i+1:]\n        for char in alphabet:\n            if char != key[i]:\n                yield left + char + right\n']], ['Faster alternative to for loop in for loop'], 5, 0], [(34114554, 1), [['So, for example:'], ['Now we compute the neighborhoods of each key:']], [[" >>> set(generate_neighbors('ab', {'a', 'b', 'c', 'd'}))\n{'aa', 'ac', 'ad', 'bb', 'cb', 'db'}\n"]], ['Faster alternative to for loop in for loop'], 5, 0], [(34114554, 2), [['Now we compute the neighborhoods of each key:'], ['Now an example. Suppose']], [[' def compute_neighborhoods(data, alphabet):\n    keyset = set(data.keys())\n    for key in data:\n        possible_neighbors = set(generate_neighbors(key, alphabet))\n        neighbors = possible_neighbors & keyset\n\n        identifier = data[key][0]\n\n        for neighbor in neighbors:\n            data[neighbor][1].append(identifier)\n']], ['Faster alternative to for loop in for loop'], 5, 0], [(34114554, 3), [['Now an example. Suppose'], ['Then:']], [[" data = {\n '0a': [4, []],\n '1f': [9, []],\n '27': [3, []],\n '32': [8, []],\n '3f': [6, []],\n '47': [1, []],\n '7c': [2, []],\n 'a1': [0, []],\n 'c8': [7, []],\n 'e2': [5, []]\n}\n"]], ['Faster alternative to for loop in for loop'], 5, 0], [(34114554, 4), [['Then:'], ["There are a few more optimizations that I haven't implemented here. First, you say that the keys mostly differ on their later characters, and that they differ at 11 positions, at most. This means that we can be smarter about computing the intersection  possible_neighbors & keyset  and in generating the neighborhood. First, we amend  generate_neighbors  to modify the  trailing  characters of the key first. Then, instead of generating the whole set of neighbors at once, we generate them one at a time and check for inclusion in the  data  dictionary. We keep track of how many we find, and if we find 11 we break."]], [[" >>> alphabet = set('abcdef01234567890')\n>>> compute_neighborhoods(data, alphabet)\n>>> data\n{'0a': [4, []],\n '1f': [9, [6]],\n '27': [3, [1]],\n '32': [8, [5, 6]],\n '3f': [6, [8, 9]],\n '47': [1, [3]],\n '7c': [2, []],\n 'a1': [0, []],\n 'c8': [7, []],\n 'e2': [5, [8]]}\n"]], ['Faster alternative to for loop in for loop'], 5, 0], [(34117408, 0), [['-10000'], ['-10000']], [[' FEMALE = \'F\'\nMALE = \'M\' \nclass Teacher(models.Model): \n    GENDER_CHOICES = ( \n        (MALE, _(\'Male\')), \n        (FEMALE, _(\'Female\')), \n        )  \n    gender = models.CharField(max_length=1, verbose_name=_(\'Gender\'), choices=GENDER_CHOICES) \n    civil_id = models.CharField(max_length=12, verbose_name=_(\'Civil ID\')) \n    phone_number = models.CharField(max_length=15, verbose_name=_(\'Phone Number\')) \n    job_title = models.CharField(max_length=15, verbose_name=_(\'Title\')) \n    user = models.OneToOneField(to=User, related_name=\'teacher_profile\') \n\n    def enable(self): \n    """ \n    Enable teacher profile \n    :return: \n    """ \n    self.user.is_active = True \n    self.user.save() \n\n    def disable(self): \n    """ \n    Disable teacher profile \n    :return: \n    """ \n    self.user.is_active = False \n    self.user.save() \n\n    def get_absolute_url(self): \n       return reverse(\'teacher_details\', args=(self.pk,))\n']], ['Django User Model one-to-one with other model and Forms'], 6, 0], [(34117408, 1), [['-10000'], ['Now I’m passing one form for Teacher model and the second form is for User model, and in the template display both forms. ']], [[" def get_context_data(self, **kwargs): \n    #Get the context \n    context = super(TeacherCreation, self).get_context_data(**kwargs) \n    #Adding the second form \n    context['user_form'] = self.second_form_class \n    return context \n"]], ['Django User Model one-to-one with other model and Forms'], 6, 0], [(34117408, 2), [['Now I’m passing one form for Teacher model and the second form is for User model, and in the template display both forms. '], ['The first issue solved. ']], [[' <form method="post"> {% csrf_token %} \n    <div class="panel panel-default"> \n        <div class="panel-heading"> \n            <h3 class="panel-title"> Teacher Information </h3> \n            </div> \n        <div class="panel-body"> \n            {{ user_form }} \n            {{ form }} \n            <button class="btn btn-primary" type="submit">Save</button>\n        </div>\n    </div>\n</form>\n']], ['Django User Model one-to-one with other model and Forms'], 6, 0], [(34117408, 3), [['The first issue solved. '], ["The second issue solved but what about the update, it's easy and almost the same as  CreateView , so let's see How er can do it "]], [[' def form_valid(self, form): \n    user_form = UserCreationForm(self.request.POST) \n    if user_form.is_valid(): \n        user = user_form.save() \n        teacher = form.save(commit=False) \n        teacher.user_id = user.id \n        teacher.save() \n        return HttpResponseRedirect(self.get_success_url())\n']], ['Django User Model one-to-one with other model and Forms'], 6, 0], [(34117408, 4), [["The second issue solved but what about the update, it's easy and almost the same as  CreateView , so let's see How er can do it "], ['-10000']], [[" def get_context_data(self, **kwargs): \n    context = super(TeacherUpdate, self).get_context_data(**kwargs) \n    context['user_form'] = self.second_form_class(self.request.POST or None, instance=self.object.user) \n    return context \n\ndef form_valid(self, form): \n    user_form = UserChangeForm(self.request.POST, instance=self.object.user) \n    if user_form.is_valid(): \n        user_form.save() \n        return super(TeacherUpdate, self).form_valid(form)\n"]], ['Django User Model one-to-one with other model and Forms'], 6, 0], [(34117408, 5), [['-10000'], ['I posted  the solution  on my blog.']], [[' ########################\n# models.py\n########################\nFEMALE = \'F\'\nMALE = \'M\'\n\nclass Teacher(models.Model):\n    """\n    Halaqat teachers information\n    """\n    GENDER_CHOICES = (\n        (MALE, _(\'Male\')),\n        (FEMALE, _(\'Female\')),\n    )\n    gender = models.CharField(max_length=1, verbose_name=_(\'Gender\'),\n                              choices=GENDER_CHOICES)\n    civil_id = models.CharField(max_length=12, verbose_name=_(\'Civil ID\'))\n    phone_number = models.CharField(max_length=15,\n                                    verbose_name=_(\'Phone Number\'))\n    job_title = models.CharField(max_length=15, verbose_name=_(\'Title\'))\n    user = models.OneToOneField(to=User, related_name=\'teacher_profile\')\n\n    def enable(self):\n        """\n        Enable teacher profile\n        :return:\n        """\n        self.user.is_active = True\n        self.user.save()\n\n    def disable(self):\n        """\n        Disable teacher profile\n        :return:\n        """\n        self.user.is_active = False\n        self.user.save()\n\n    def get_absolute_url(self):\n        return reverse(\'teacher_details\', args=(self.pk,))\n\n########################\n# views.py\n########################\nclass TeacherCreation(SuccessMessageMixin, CreateView):\n    """\n    Creates new teacher\n    """\n    template_name = \'back_office/teacher_form.html\'\n    form_class = TeacherForm\n    model = Teacher\n    second_form_class = UserCreationForm\n    success_message = \'Teacher profile saved successfully\'\n\n    def get_context_data(self, **kwargs):\n        context = super(TeacherCreation, self).get_context_data(**kwargs)\n\n        context[\'user_form\'] = self.second_form_class\n\n        return context\n\n    def form_valid(self, form):\n        user_form = UserCreationForm(self.request.POST)\n        if user_form.is_valid():\n            user = user_form.save()\n            teacher = form.save(commit=False)\n            teacher.user_id = user.id\n            teacher.save()\n        return HttpResponseRedirect(self.get_success_url())\n\nclass TeacherUpdate(SuccessMessageMixin, UpdateView):\n    """\n    Update teacher profile\n    """\n    model = Teacher\n    template_name = \'back_office/teacher_form.html\'\n    form_class = TeacherForm\n    second_form_class = UserChangeForm\n    success_message = \'Teacher profile saved successfully\'\n\n    def get_context_data(self, **kwargs):\n        context = super(TeacherUpdate, self).get_context_data(**kwargs)\n\n        context[\'user_form\'] = self.second_form_class(self.request.POST or None, instance=self.object.user)\n\n        return context\n\n    def form_valid(self, form):\n        user_form = UserChangeForm(self.request.POST, instance=self.object.user)\n        if user_form.is_valid():\n            user_form.save()\n        return super(TeacherUpdate, self).form_valid(form)\n\n########################\n# teacher_form.html\n########################\n{% extends \'back_office/back_office_base.html\' %}\n{% load crispy_forms_tags %}\n{% block title %}\n    New Teacher Form\n{% endblock %}\n{% block container %}\n    <form method="post">{% csrf_token %}\n        <div class="panel panel-default">\n            <div class="panel-heading">\n                <h3 class="panel-title">Teacher Information</h3>\n            </div>\n            <div class="panel-body">\n                {{ user_form|crispy }}\n                {{ form|crispy }}\n                <button class="btn btn-primary" type="submit">\n                    <span class="glyphicon glyphicon-floppy-disk" aria-hidden="true"></span>\n                            Save\n                </button>\n            </div>\n        </div>\n    </form>\n{% endblock %}\n']], ['Django User Model one-to-one with other model and Forms'], 6, 1], [(34124733, 1), [['The trick is to get unique indexes for each weekday (not just 1-7, but incrementing by one each time there is a new weekday).'], ['These  week_counter  values are then used in  groupby  to create groups of records, and  transorm  is used (to maintain the same shape as the original dataframe) taking both the first and last  records  of each group.']], [[" df['week_counter'] = (df.weekday != df.weekday.shift()).cumsum()\n>>> df\n    records    weekday  week_counter\n0         1     Monday             1\n1         2     Monday             1\n2         3     Monday             1\n3         4    Tuesday             2\n4         6    Tuesday             2\n5         7  Wednesday             3\n6         8   Thursday             4\n7        12   Thursday             4\n8        14   Thursday             4\n...\n16       43    Tuesday             9\n17       59  Wednesday            10\n18       61  Wednesday            10\n"]], ['pandas: detect the first/last record number from a time stamp of weekday only'], 2, 0], [(34137398, 0), [["It's not quite clear what you're going for, but maybe this will work. You're currently re-using the variable name 'row', and the indentation is all wacky. Also, you shouldn't be including the first row (the headers) in your loops."], ["I just realized that I think you had your x's and y's swapped in a couple places. Try this instead:"]], [[" import csv\nimport math\n\nf = open('citydata.csv')\n\ncsv_f = csv.reader(f)\ncontent = [row for row in csv_f]\n\nfor row in content[1:]:\n    x1 = float(row[2])\n    x2 = float(row[3])\n    for rowOther in content[1:]:\n        y1 = float(rowOther[2])\n        y2 = float(rowOther[3])\n\n        answer = (x1-(math.pow(x2,2))) - (y1-(math.pow(y2,2)))\n\n        print(answer)\n"]], ['Manipulating rows of csv file in python'], 2, 0], [(34137398, 1), [["I just realized that I think you had your x's and y's swapped in a couple places. Try this instead:"], ['-10000']], [[" import csv\nimport math\n\nf = open('citydata.csv')\n\ncsv_f = csv.reader(f)\ncontent = [row for row in csv_f]\n\nfor row in content[1:]:\n    x1 = float(row[2])\n    y1 = float(row[3])\n    for rowOther in content[1:]:\n        x2 = float(rowOther[2])\n        y2 = float(rowOther[3])\n\n        answer = (x1-(math.pow(x2,2))) - (y1-(math.pow(y2,2)))\n\n        print(answer)\n"]], ['Manipulating rows of csv file in python'], 2, 1], [(34137572, 0), [['Part one  would be python script to just get command output and bypass it properly to  part two . It should be as easy to hadle as usual  grep  case:'], ["Tricky but easier than you think will be to create a Node.js cript as  part three . As a single instance script it should be able to receive input and bypass it to users as events. I've commited comething like this before:"]], [[' tail -f /var/log/apache2/access.log | /usr/share/bin/myharvester \n']], ['python, how to run commands on remote hosts and show output in GUI in real time?'], 2, 0], [(34137572, 1), [["Tricky but easier than you think will be to create a Node.js cript as  part three . As a single instance script it should be able to receive input and bypass it to users as events. I've commited comething like this before:"], ['This scrap is basic example of not filled with logic what-you-need. Script should be able to open UDP listener on given port and to listen for users running into it within websockets. Honestly, once you become good in Node.js, you may want to fix both  part two + part three  with it, what will take UDP part off you as harvester will push output directly to script, that maintains websocket inside it. But it has a drawback of duplicating some logic from other back-end as CRM.']], [[" var config = {};\nvar app = require('http').createServer().listen(config.server.port);\n\nvar io = require('socket.io').listen(app);\n\nvar listenerDgram = require('dgram').createSocket('udp4');\nlistenerDgram.bind(config.listeners.udp.port);\n\nvar sprintf = require('sprintf').sprintf;\n\nvar users = [];\n\napp.on('error', function(er) {\n    console.log(sprintf('[%s] [ERROR] HTTP Server at port %s has thrown %s', Date(), config.server.port, er.toString()));\n    process.exit();\n});\n\nlistenerDgram.on('error', function(er) {\n    console.log(sprintf('[%s] [ERROR] UDP Listener at port %s has thrown %s', Date(), config.listeners.udp.port, er.toString()));\n    process.exit();\n});\n\nlistenerDgram.on('message', function(msg, rinfo) {\n    // handling, let's say, JSONized msg from part two script,\n    // buildinf a var frame and finally\n    if(user) {\n        // emit to single user based on what happened\n        // inside this method\n        users[user].emit('notification', frame);\n    } else {\n        // emit to all users\n        io.emit('notification', frame);\n    }\n\n});\n\nio.sockets.on('connection', function(socket) {\n    // handling user connection here and pushing users' sockets to\n    // users aray.\n});\n"]], ['python, how to run commands on remote hosts and show output in GUI in real time?'], 2, 0], [(34141855, 0), [['If you have a list of numbers:'], ['you can access them via index, starting with  0 :']], [[' >>> one = [1, 2, 3, 4]\n']], ['How do I take an integer from a list intending to use it?'], 5, 0], [(34141855, 1), [['you can access them via index, starting with  0 :'], ['the last one:']], [[' >>> one[0]\n1\n>>> one[2]\n2\n']], ['How do I take an integer from a list intending to use it?'], 5, 1], [(34141855, 2), [['the last one:'], ['You can calculate with them:']], [[' >>> one[-1]\n4\n']], ['How do I take an integer from a list intending to use it?'], 5, 1], [(34141855, 3), [['You can calculate with them:'], ['or store under a different name:']], [[' >>> one[1] + one[1]\n4\n']], ['How do I take an integer from a list intending to use it?'], 5, 1], [(34141855, 4), [['or store under a different name:'], ['-10000']], [[' >>> a = one[1]\n>>> a\n2\n>>> a + a\n4\n']], ['How do I take an integer from a list intending to use it?'], 5, 1], [(34146679, 0), [['This is useless text that is required to keep an answer from being downvoted by the moderators.  Here is the data I used:'], ['-10000']], [[' "Date","Information","Type"\n"2015-12-07","First: Jim, Last: Jones, School: MCAA; First: Jane, Last: Jones,  School: MCAA;","Old"\n"2015-12-06","First: Tom, Last: Smith, School: MCAA; First: Tammy, Last: Smith, School: MCAA;","New"\n']], ['Python/ Pandas CSV Parsing'], 2, 0], [(34146679, 1), [['-10000'], ['-10000']], [[' import pandas as pd\nimport numpy as np\nimport csv\nimport re\nimport itertools as it\nimport pprint\nimport datetime as dt\n\nrecords = [] #Construct a complete record for each person\n\ncolon_pairs = r"""\n    (\\w+)   #Match a \'word\' character, one or more times, captured in group 1, followed by..\n    :       #A colon, followed by...\n    \\s*     #Whitespace, 0 or more times, followed by...\n    (\\w+)   #A \'word\' character, one or more times, captured in group 2.\n"""\n\ncolon_pairs_per_person = 3\n\nwith open("csv1.csv", encoding=\'utf-8\') as f:\n    next(f) #skip header line\n    record = {}\n\n    for date, info, the_type in csv.reader(f):\n        info_parser = re.finditer(colon_pairs, info, flags=re.X)\n\n        for i, match_obj in enumerate(info_parser):\n            key, val = match_obj.groups()\n            record[key] = val\n\n            if (i+1) % colon_pairs_per_person == 0: #then done with info for a person\n                record[\'Date\'] = dt.datetime.strptime(date, \'%Y-%m-%d\') #So that you can sort the DataFrame rows by date.\n                record[\'Type\'] = the_type\n\n                records.append(record)\n                record = {}\n\npprint.pprint(records)\ndf = pd.DataFrame(\n        sorted(records, key=lambda record: record[\'Date\'])\n)\nprint(df)\ndf.set_index(\'Date\', inplace=True)\nprint(df)\n\n--output:--\n[{\'Date\': datetime.datetime(2015, 12, 7, 0, 0),\n  \'First\': \'Jim\',\n  \'Last\': \'Jones\',\n  \'School\': \'MCAA\',\n  \'Type\': \'Old\'},\n {\'Date\': datetime.datetime(2015, 12, 7, 0, 0),\n  \'First\': \'Jane\',\n  \'Last\': \'Jones\',\n  \'School\': \'MCAA\',\n  \'Type\': \'Old\'},\n {\'Date\': datetime.datetime(2015, 12, 6, 0, 0),\n  \'First\': \'Tom\',\n  \'Last\': \'Smith\',\n  \'School\': \'MCAA\',\n  \'Type\': \'New\'},\n {\'Date\': datetime.datetime(2015, 12, 6, 0, 0),\n  \'First\': \'Tammy\',\n  \'Last\': \'Smith\',\n  \'School\': \'MCAA\',\n  \'Type\': \'New\'}]\n\n        Date  First   Last School Type\n0 2015-12-06    Tom  Smith   MCAA  New\n1 2015-12-06  Tammy  Smith   MCAA  New\n2 2015-12-07    Jim  Jones   MCAA  Old\n3 2015-12-07   Jane  Jones   MCAA  Old\n\n            First   Last School Type\nDate                                \n2015-12-06    Tom  Smith   MCAA  New\n2015-12-06  Tammy  Smith   MCAA  New\n2015-12-07    Jim  Jones   MCAA  Old\n2015-12-07   Jane  Jones   MCAA  Old\n']], ['Python/ Pandas CSV Parsing'], 2, 1], [(34146928, 0), [['-10000'], ['Or you can use  map']], [[' >>> s = "39401.99865    7292.4753   8541.03675  6098.54185  106352.218  7300.4485   5699.983    5538.44755  5934.8514   7477.62475  5956.7409   9170.98 9481.5082   6063.4508   9380.92255" \n>>> [float(item) for item in s.split()]\n[39401.99865, 7292.4753, 8541.03675, 6098.54185, 106352.218, 7300.4485, 5699.983, 5538.44755, 5934.8514, 7477.62475, 5956.7409, 9170.98, 9481.5082, 6063.4508, 9380.92255]\n']], ['how can I have commas instead of space in a given set of number'], 2, 1], [(34146928, 1), [['Or you can use  map'], ['-10000']], [[' >>> map(float, s.split())\n[39401.99865, 7292.4753, 8541.03675, 6098.54185, 106352.218, 7300.4485, 5699.983, 5538.44755, 5934.8514, 7477.62475, 5956.7409, 9170.98, 9481.5082, 6063.4508, 9380.92255]\n']], ['how can I have commas instead of space in a given set of number'], 2, 1], [(34155132, 0), [['You could also for a few number of records append some field to the model query result the will be accessible from the template '], ['In template']], [[' class Team(models.Model): \n    team_name = models.CharField(max_length=200)\n\n\ndef get_teams(request):\n    teams = Team.objects.all()\n    for team in teams:\n        team.team_win_percent = calculate_team_win(team)\n        team.team_lose_percent = calculate_team_loss(team)\n    ....\n']], ['Relating/adding data to a django object list'], 2, 0], [(34155132, 1), [['In template'], ['-10000']], [[' {% for team in teams %}\n    team win percentage = {{ team.team_win_percent }}\n    team lose percentage = {{ team.team_lose_percent }}\n\n{% endfor %}\n']], ['Relating/adding data to a django object list'], 2, 0], [(34168264, 0), [['If you want this to work for any arbitrary key(s) you can use a defaultdict of OrderedDicts..'], ['And if you want all the results that had multiple values']], [[" from collections import defaultdict, OrderedDict\nresult_dict = defaultdict(OrderedDict)\ndata = [('Han Decane','12333'),('Can Decane','12333'),('AlRight','10110')]\nfor (v,k) in data:\n   result_dict[k][v]=True\n\n\n>>> list(result_dict['12333'].keys())\n['Han Decane', 'Can Decane']\n"]], ['Python:how to get keys with same values?'], 2, 1], [(34193415, 1), [['Here is how to use them'], ['If you are in need of finding other players, the helper method should be easy again. ']], [[" >>> set_sim(['Player3', 'Player1'], 2)\n>>> set_sim(['Player1', 'Player2'], 3)\n>>> set_sim(['Player2', 'Player3'], 3)\n>>> get_sim(['Player3','Player2'])\n3\n>>> similarities\n{('Player1', 'Player2'): 3, ('Player2', 'Player3'): 3, ('Player1', 'Player3'): 2}\n"]], ['How to make array of array of dictionaries in python'], 4, 0], [(34193415, 2), [['If you are in need of finding other players, the helper method should be easy again. '], ['logs:']], [[' def get_other_players(player):\n    for pair in similarities.keys():\n        try:\n            other_player = pair[(pair.index(player)+1)%2]\n            print other_player, "=", similarities[pair]\n        except ValueError:\n            pass\n']], ['How to make array of array of dictionaries in python'], 4, 0], [(34193415, 3), [['logs:'], ['-10000']], [[" >>> set_sim(['Player9','Player4'], .02)\n>>> set_sim(['Player3','Player4'], .8)\n>>> set_sim(['Player12','Player4'], 1.5)\n\n>>> get_other_players('Player4')\nPlayer9 = 0.02\nPlayer3 = 0.8\nPlayer12 = 1.5\n"]], ['How to make array of array of dictionaries in python'], 4, 0], [(34206921, 0), [['You need to convert to  str  if necessary, then  zfill  the month col and pass this with a valid format to  to_datetime :'], ['If the conversion is unnecessary then the following should work:']], [[" In [303]:\ndf['date'] = pd.to_datetime(df['year'].astype(str) + df['month'].astype(str).str.zfill(2), format='%Y%m')\ndf\n\nOut[303]:\n   year  month       pl       date\n0  2010      1  27.4376 2010-01-01\n1  2010      2  29.2314 2010-02-01\n2  2010      3  33.5714 2010-03-01\n3  2010      4  37.2986 2010-04-01\n4  2010      5  36.6971 2010-05-01\n5  2010      6  35.9329 2010-06-01\n"]], ['Converting date using to_datetime'], 3, 1], [(34206921, 2), [['Your attempt failed as it treated the value as epoch time:'], ['-10000']], [[" In [305]:\npd.to_datetime(20101, format='%Y-%m')\n\nOut[305]:\nTimestamp('1970-01-01 00:00:00.000020101')\n"]], ['Converting date using to_datetime'], 3, 0], [(34243214, 0), [['The trick is to assign a race number (e.g. either 1 or 2) to each row depending on whether it should be associated with Race#1 or Race#2:'], ['Then the desired DataFrame can be expressed as the result of a  set_index/unstack  operation:']], [[" df['race'] = df.groupby('Athlete').cumcount()+1\n#      Athlete Distance Race  Rank    Time  race\n# 0    M.Smith     400m    A     1   48.57     1\n# 1    A.Moyet     400m    A     2   49.00     1\n# 2  C.Marconi     800m    B     5  104.12     1\n# 3    M.Smith     800m    B     3  102.66     2\n"]], ['Pivot Pandas Dataframe with a Mix of Numeric and Text Fields'], 4, 0], [(34243214, 1), [['Then the desired DataFrame can be expressed as the result of a  set_index/unstack  operation:'], ['That, along with a little touching up to get the columns in the desired format:']], [[" result = df.set_index(['Athlete', 'race']).unstack('race')\n#           Distance       Race      Rank        Time        \n# race             1     2    1    2    1   2       1       2\n# Athlete                                                    \n# A.Moyet       400m   NaN    A  NaN    2 NaN   49.00     NaN\n# C.Marconi     800m   NaN    B  NaN    5 NaN  104.12     NaN\n# M.Smith       400m  800m    A    B    1   3   48.57  102.66\n"]], ['Pivot Pandas Dataframe with a Mix of Numeric and Text Fields'], 4, 0], [(34243214, 3), [['yields'], ['-10000']], [['           Distance#1 Race#1  Rank#1  Time#1 Distance#2 Race#2  Rank#2  Time#2\nAthlete                                                                      \nA.Moyet         400m      A       2   49.00        NaN    NaN     NaN     NaN\nC.Marconi       800m      B       5  104.12        NaN    NaN     NaN     NaN\nM.Smith         400m      A       1   48.57       800m      B       3  102.66\n']], ['Pivot Pandas Dataframe with a Mix of Numeric and Text Fields'], 4, 0], [(34244726, 0), [['Let try some code:'], ['Code should be called like this :']], [[' def build_pseudo_header(src_ip, dest_ip, payload_len):\n    source_ip_bytes = bytearray.fromhex(src_ip)\n    dest_ip_bytes = bytearray.fromhex(dest_ip)\n    next_header = struct.pack(">I", 58)\n    upper_layer_len = struct.pack(">I", payload_len)\n    return source_ip_bytes + dest_ip_bytes + upper_layer_len + next_header\n']], ['Computing 16-bit checksum of ICMPv6 header'], 7, 0], [(34244726, 1), [['Code should be called like this :'], ['In this case I use the  type  and  code  fields from ICMPv6 as a signle 16-bit value. The checksum field is removed and the remainder of the packet is simply called "remainder":']], [[' SOURCE_IP = "fe80000000000000020086fffe0580da"\nDEST_IP = "fe80000000000000026097fffe0769ea"\npseudo_header = build_pseudo_header(SOURCE_IP, DEST_IP, 32)\n']], ['Computing 16-bit checksum of ICMPv6 header'], 7, 0], [(34244726, 2), [['In this case I use the  type  and  code  fields from ICMPv6 as a signle 16-bit value. The checksum field is removed and the remainder of the packet is simply called "remainder":'], ['Building the ICMPv6 part of the packet for checksum calculation:']], [[' TYPE_CODE = "8700"\nREMAINDER = "00000000fe80000000000000026097fffe0769ea01010000860580da"\n']], ['Computing 16-bit checksum of ICMPv6 header'], 7, 0], [(34244726, 3), [['Building the ICMPv6 part of the packet for checksum calculation:'], ['Called as follow:']], [[' def build_icmpv6_chunk(type_and_code, other):\n    type_code_bytes = bytearray.fromhex(type_and_code)\n    checksum = struct.pack(">I", 0)  # make sure checksum is set to 0 here\n    other_bytes = bytearray.fromhex(other)\n    return type_code_bytes + checksum + other_bytes\n']], ['Computing 16-bit checksum of ICMPv6 header'], 7, 0], [(34244726, 4), [['Called as follow:'], ['Python example:']], [[' TYPE_CODE = "8700"\nREMAINDER = "00000000fe80000000000000026097fffe0769ea01010000860580da"\nicmpv6_chunk = build_icmpv6_chunk(TYPE_CODE, REMAINDER)\n']], ['Computing 16-bit checksum of ICMPv6 header'], 7, 0], [(34251684, 0), [['The standard way to make python GUI and graphics is with the tkinter package,  this  tutorial should get you started. As for full screen graphics,\nadd the fullscreen attribute to your tk object:'], ['If you want to stick with graphics.py, I would give the window the same height and width as your resolution, on windows:']], [[' Tk.attributes("-fullscreen", True)\n']], ['Python full-screen graphics'], 2, 1], [(34260522, 1), [['By the way, you can simplify your condition a bit:'], ['-10000']], [["  df_total_data[df_total_data['BBBlink'].apply(lambda x: 'secure' not in  x)]\n"]], ['Selection of rows by condition'], 2, 0], [(34271014, 0), [['Another method would include  pivot . Starting from your dataframe  df , I would set the index to  Date :'], ['and then pivot the table according to your values:']], [[" df = df.set_index('Date')\n"]], ['Using pandas to plot data'], 4, 0], [(34271014, 1), [['and then pivot the table according to your values:'], ['This returns this structure:']], [[" d = pd.pivot_table(df,index=df.index, columns='Name', values='Activity').fillna(0)\n"]], ['Using pandas to plot data'], 4, 0], [(34271014, 2), [['This returns this structure:'], ['And in base of your needs you can simply plot it with:']], [[' Name        A    B  C\nDate                 \n2015-01-02  1  1.5  0\n2015-01-03  2  1.0  0\n2015-01-04  2  5.0  0\n2015-01-31  0  0.0  1\n']], ['Using pandas to plot data'], 4, 0], [(34271014, 3), [['And in base of your needs you can simply plot it with:'], ['Actually you have some duplicate values in the example, but now the plot looks like the following. Hope that helps.']], [[' d.plot()\n']], ['Using pandas to plot data'], 4, 0], [(34286165, 0), [['Just sending standalone_mode as a keyword argument worked for me:'], ['Output:']], [[' from __future__ import print_function\nimport click\n\n@click.command()\n@click.option(\'--name\', help=\'Enter Name\')\n@click.pass_context\ndef gatherarguments(ctx, name):\n    return ctx\n\ndef usectx(ctx):\n    print("Name is %s" % ctx.params[\'name\'])\n\nif __name__ == \'__main__\':\n    ctx = gatherarguments(standalone_mode=False)\n    print(ctx)\n    usectx(ctx)\n']], ['python click usage of standalone_mode'], 2, 1], [(34286165, 1), [['Output:'], ['-10000']], [[' ./clickme.py --name something\n<click.core.Context object at 0x7fb671a51690>\nName is something\n']], ['python click usage of standalone_mode'], 2, 0], [(34300499, 0), [['create CBV for publish and override post method:'], ['-10000']], [[' class PublishView(UpdateView):\n\n    model = Blog\n\n    def post(self, request, *args, **kwargs):\n        pk = self.kwargs.get(\'pk\', None)\n        Blog.objects.filter(pk=pk).update(publish_date=datetime.datetime.now())\n        return HttpResponseRedirect("/blogs/" + pk)\n']], ["Django permissions mixin on CBV, how to apply on 'publish blog' method"], 3, 0], [(34300499, 1), [['-10000'], ['\n in urls you access your function directly your publish method']], [['      class BlogUpdateView(UpdateView):\n\n            model = Blog\n\n            @staticmethod\n            def publish(request, pk):\n               if request.method == "GET":\n               Blog.objects.filter(pk=pk).update(publish_date=datetime.datetime.now())\n               return HttpResponseRedirect("/blogs/" + pk)\n']], ["Django permissions mixin on CBV, how to apply on 'publish blog' method"], 3, 0], [(34300499, 2), [['\n in urls you access your function directly your publish method'], ['-10000']], [[' url(r"^(?P<pk>[0-9]+)/publish/$", views.BlogUpdateView.publish, name="publish"),\n']], ["Django permissions mixin on CBV, how to apply on 'publish blog' method"], 3, 0], [(34301088, 0), [['Here is how I will store it in CSV'], ['This code explains what happens inside the list comrpehension.']], [[' value1 = \'one\'\nvalue2 = \'two\'\nd = { \n        \'key1\': (value1, value2), \n        \'key2\': (value1, value2), \n        \'key3\': (value1, value2)\n    }\nCSV ="\\n".join([k+\',\'+",".join(v) for k,v in d.items()]) \nprint CSV #You can store this string variable to file as you wish\n# with open("filename.csv", "w") as file:\n    # file.write(CSV)\n']], ['Reading/Writing out a dictionary to csv file in python'], 2, 1], [(34301088, 1), [['This code explains what happens inside the list comrpehension.'], ['-10000']], [[' CSV = ""\nfor k,v in d.items():\n    line = "{},{}\\n".format(k, ",".join(v))\n    CSV+=line\nprint CSV \n']], ['Reading/Writing out a dictionary to csv file in python'], 2, 0], [(34371807, 0), [['You could use the  fractions  module  to check if a given fraction can be represented:'], ["Because floating point numbers use  binary fractions , you'll soon find that this can be simplified to checking for a denominator that is a power of two:"]], [[' from fractions import Fraction\n\ndef can_be_represented(num, den):\n    f = Fraction(num, den)\n    return Fraction.from_float(float(f)) == f\n']], ['How to determine if a decimal fraction can be represented exactly as Python float?'], 2, 1], [(34371807, 1), [["Because floating point numbers use  binary fractions , you'll soon find that this can be simplified to checking for a denominator that is a power of two:"], ['-10000']], [[' def can_be_represented(num, den):\n    f = Fraction(num, den)\n    return f.denominator & (f.denominator - 1) == 0\n']], ['How to determine if a decimal fraction can be represented exactly as Python float?'], 2, 1], [(34374393, 0), [['I think, you can do this really easy with'], ['After the OP has rephrased his question, I would suggest something like']], [[" words = 'the horse and the rider'.split(' ')\nlook_for = 'the'\nindices = [i for i, word in enumerate(words) if word == look_for]\nprint(indices)\n"]], ['Python find which order element is in in a list'], 2, 0], [(34374393, 1), [['After the OP has rephrased his question, I would suggest something like'], ['-10000']], [[' text = "My name is Alice and his name is Bob"\nwords = text.split(\' \')\nindices = [i+2 for i, word in enumerate(words) if word == \'name\']\nnames = [words[i] for i in indices if i < len(words)]\n']], ['Python find which order element is in in a list'], 2, 1], [(34382144, 0), [['That said, the CPython sys module has a  displayhook  function.  For 3.5:'], ['That actually should be  __builtins__._ , as in the example below.  Note that the input is any Python object.  For IDLE, the default  sys.displayhook  is a function defined in  idlelib/rpc.py .  Here is an example relevant to your question.']], [[' >>> help(sys.displayhook)\nHelp on built-in function displayhook in module sys:\n\ndisplayhook(...)\n    displayhook(object) -> None\n\n    Print an object to sys.stdout and also save it in builtins._\n']], ['Changing number representation in IDLE'], 2, 0], [(34400455, 0), [['You could just nest loops:'], ['Or you could create a whole new copy of the structure, with the alterations made:']], [[" for contact_dict in list_of_dicts:\n    for phone_dict in contact_dict['phoneNumbers']:\n        phone_dict['phone'] = phone_dict['phone'].replace('-', '')\n"]], ['Updating a value in a dictionary inside a dictionary'], 3, 1], [(34400455, 1), [['Or you could create a whole new copy of the structure, with the alterations made:'], ['Demo:']], [[" [dict(contact, phoneNumbers=[\n    dict(phone_dict, phone=phone_dict['phone'].replace('-', '')) \n    for phone_dict in contact['phoneNumbers']])\n for contact in list_of_dicts]\n"]], ['Updating a value in a dictionary inside a dictionary'], 3, 1], [(34403494, 0), [['Your lat lines would look like this:'], ['In addition, to remove the annoying comma at the end, you can consider']], [[' thefile.write("%s " % name)\nfor item in thelist:\n  thefile.write("%s,"% item)\n']], ['How to write variable and array on the same line for a text file?'], 2, 1], [(34419926, 0), [['The basic idea is this:'], ['The output you get is something like this, showing how it takes turns at doing the long calculation and updating the main loop:']], [[' # load modules\nimport time\n\nfrom PySide import QtCore, QtGui\n\n\n# APPLICATION STUFF\n# -----------------\n\nAPP = QtGui.QApplication([])\n\n\n# THREADS\n# -------\n\n\nclass WorkerThread(QtCore.QThread):\n    \'\'\'Does the work\'\'\'\n\n    def __init__(self):\n        super(WorkerThread, self).__init__()\n\n        self.running = True\n\n    def run(self):\n        \'\'\'This starts the thread on the start() call\'\'\'\n\n        # this goes over 1000 numbers, at 10 a second, will take\n        # 100 seconds to complete, over a minute\n        for i in range(1000):\n            print(i)\n            time.sleep(0.1)\n\n        self.running = False\n\n\nclass BackgroundThread(QtCore.QThread):\n    \'\'\'Keeps the main loop responsive\'\'\'\n\n    def __init__(self, worker):\n        super(BackgroundThread, self).__init__()\n\n        self.worker = worker\n\n    def run(self):\n        \'\'\'This starts the thread on the start() call\'\'\'\n\n        while self.worker.running:\n            APP.processEvents()\n            print("Updating the main loop")\n            time.sleep(0.1)\n\n\n# MAIN\n# ----\n\n\ndef main():\n    # make threads\n    worker = WorkerThread()\n    background = BackgroundThread(worker)\n\n    # start the threads\n    worker.start()\n    background.start()\n    # wait until done\n    worker.wait()\n\nif __name__ == \'__main__\':\n    main()\n']], ['How to make QtGui window process events whenever it is brought forward on the screen?'], 3, 1], [(34419926, 1), [['The output you get is something like this, showing how it takes turns at doing the long calculation and updating the main loop:'], ['As for overriding the QFocusEvent you can do something as follows:']], [[' 0\n Updating the main loop\n1\nUpdating the main loop\n2\nUpdating the main loop\n3\nUpdating the main loop\n4\nUpdating the main loop\n5\nUpdating the main loop\n6\nUpdating the main loop\nUpdating the main loop7\n\n8\nUpdating the main loop\n9\n']], ['How to make QtGui window process events whenever it is brought forward on the screen?'], 3, 0], [(34419926, 2), [['As for overriding the QFocusEvent you can do something as follows:'], ['And if you choose to implement threads to avoid GUI blocking, you should read about the  basics of threading  (as threads have a lot of nuances unless you know about their potential pitfalls).']], [[' def focusInEvent(self, event):\n    event.accept()\n\n    # insert your code here\n']], ['How to make QtGui window process events whenever it is brought forward on the screen?'], 3, 0], [(34428730, 0), [['You can use the replace method:'], ["Note: there's a  format  for that day of the month:"]], [[" In [11]: d\nOut[11]: datetime.datetime(2004, 3, 28, 0, 0)\n\nIn [12]: d.replace(day=1 if d.day < 15 else 15)\nOut[12]: datetime.datetime(2004, 3, 15, 0, 0)\n\nIn [13]: t = pd.Timestamp(d)\n\nIn [14]: t.replace(day=1 if t.day < 15 else 15)\nOut[14]: Timestamp('2004-03-15 00:00:00')\n"]], ['In python convert day of year to month and fortnight'], 2, 1], [(34439723, 0), [["Your problem isn't completely specified but seems fun. I took a stab at it. I wrote a function which takes a list of phrases and returns a dictionary where the abbreviations function as keys. It starts by taking the first two letters of each word and joining them for a candidate abbreviation. If that abbreviation has been used before it gradually brings into play more and more letters from the beginning of each word until you get a unique abbreviation. I then tested it on your sample data. You will almost certainly want to modify it but it should give you some ideas:"], ['Output:']], [[' def makeAbbreviations(headers):\n    abbreviations = {}\n    for header in headers:\n        header = header.lower()\n        words = header.split()\n        n = max(len(w) for w in words)\n        i = 2\n        starts = [w[:i] for w in words]\n        abbrev = \'\'.join(starts)\n\n        while abbrev in abbreviations and i <= n:\n            i += 1\n            for j,w in enumerate(words):\n                starts[j] = w[:i]\n                abbrev = \'\'.join(starts)\n                if not abbrev in abbreviations: break\n        abbreviations[abbrev] = header\n    return abbreviations\n\nmyHeaders = [\'Ad Group\', \'Annuity Calculator\', \'Tax Deferred Annuity\',\n             \'Annuity Tables\', \'annuities calculator\', \'annuity formula\',\n             \'Annuities Explained\', \'Deferred Annuies Calculator\',\n             \'Current Annuity Rates\', \'Forbes.com\', \'Annuity Definition\',\n             \'fixed income\', \'Immediate fixed Annuities\',\n             \'Deferred Variable Annuities\', \'401k Rollover\',\n             \'Deferred Annuity Rates\', \'Deferred Annuities\',\n             \'Immediate Annuities Definition\', \'Immediate Variable Annuities\',\n             \'Variable Annuity\', \'Aig Annuities\', \'Retirement Income\', \'retirment system\',\n             \'Online Financial Planner\', \'Certified Financial Planner\']\n\nd = makeAbbreviations(myHeaders)\nfor (k,v) in d.items(): print(k,v,sep = " = ")\n']], ['setting unique abbreviation for every column in python'], 2, 1], [(34439723, 1), [['Output:'], ['-10000']], [[' imande = immediate annuities definition\nadgr = ad group\nfiin = fixed income\n40ro = 401k rollover\nresy = retirment system\nvaan = variable annuity\ndevaan = deferred variable annuities\nrein = retirement income\nimvaan = immediate variable annuities\nfo = forbes.com\nimfian = immediate fixed annuities\ndean = deferred annuities\nanca = annuity calculator\ncuanra = current annuity rates\nannca = annuities calculator\nonfipl = online financial planner\naian = aig annuities\nande = annuity definition\nanfo = annuity formula\ncefipl = certified financial planner\ntadean = tax deferred annuity\ndeanca = deferred annuies calculator\nanex = annuities explained\nanta = annuity tables\ndeanra = deferred annuity rates\n']], ['setting unique abbreviation for every column in python'], 2, 0], [(34444319, 0), [['You can use the following regex with  re.findall :'], ['Python  code demo :']], [[" ((?:(?!\\band\\b)[^'])*(?:'[^'\\\\]*(?:\\\\.[^'\\\\]*)*'(?:(?!\\band\\b)[^'])*)*)(?:and|$)\n"]], ['How to split a string by a string except when the string is in quotes in python?'], 2, 1], [(34444319, 1), [['Python  code demo :'], ['-10000']], [[' import re\np = re.compile(r\'((?:(?!\\band\\b)[^\\\'])*(?:\\\'[^\\\'\\\\]*(?:\\\\.[^\\\'\\\\]*)*\\\'(?:(?!\\band\\b)[^\\\'])*)*)(?:and|$)\')\ns = "section_category_name = \'computer and equipment expense\' and date >= 2015-01-01 and date <= 2015-03-31"\nprint([x for x in p.findall(s) if x])\n']], ['How to split a string by a string except when the string is in quotes in python?'], 2, 1], [(34445707, 0), [['There are two productions. Use two separate functions. (There is no extra cost :-) )'], ['Note: I fixed your grammar to use left-recursion. With bottom-up parsing, left-recursion is almost always what you want, because it avoids unnecessary parser stack usage, and more importantly because it often simplifies actions. In this case, I could have written the second function as:']], [[" def p_type_list_1(p):\n    '''type_list : type'''\n    p[0] = [p[1]]\n\ndef p_type_list_2(p):\n    '''type_list : type_list COMMA type'''\n    p[0] = p[1] + [p[3]]\n"]], ['PLY YACC pythonic syntax for accumulating list of comma-separated values'], 2, 1], [(34452644, 0), [['First of all, I called the  csv library  to reduce the job of putting commas and quotes.'], ["Then I made a function that takes a single line from your log file and outputs a dictionary with the fields passed in the header. If the current line hasn't a particular field from header, it will stay filled with an empty string."]], [[' import csv\n']], ['Parse Specific Text File to CSV Format with Headers'], 6, 0], [(34452644, 1), [["Then I made a function that takes a single line from your log file and outputs a dictionary with the fields passed in the header. If the current line hasn't a particular field from header, it will stay filled with an empty string."], ["Since the header and the number of fields can vary between your files, I made a function extracting them. For this, I employed a set, a collection of unique elements, but also unordered. So I converted to a  list  and used the  sorted  function. Don't forget that  seek(0)  call, to rewind the file!"]], [[" def convert_to_dict(line, header):\n    d = {}\n    for cell in header:\n        d[cell] = ''\n\n    row = line.strip().split(';')    \n    for cell in row:\n        if cell:\n            key, value = cell.split('=')\n            d[key] = value\n\n    return d\n"]], ['Parse Specific Text File to CSV Format with Headers'], 6, 0], [(34452644, 2), [["Since the header and the number of fields can vary between your files, I made a function extracting them. For this, I employed a set, a collection of unique elements, but also unordered. So I converted to a  list  and used the  sorted  function. Don't forget that  seek(0)  call, to rewind the file!"], ['Lastly, I made the main piece of code, in which open both the log file to read and the csv file to write. Then, it extracts and writes the header, and writes each converted line.']], [[" def extract_fields(logfile):\n    fields = set()\n    for line in logfile:\n        row = line.strip().split(';')\n        for cell in row:\n            if cell:\n                key, value = cell.split('=')\n                fields.add(key)\n\n    logfile.seek(0)\n    return sorted(list(fields))\n"]], ['Parse Specific Text File to CSV Format with Headers'], 6, 0], [(34452644, 3), [['Lastly, I made the main piece of code, in which open both the log file to read and the csv file to write. Then, it extracts and writes the header, and writes each converted line.'], ['report.log']], [[" if __name__ == '__main__':\n    with open('report.log', 'r') as logfile:\n        with open('report.csv', 'wb') as csvfile:\n            csvwriter = csv.writer(csvfile)\n\n            header = extract_fields(logfile)\n            csvwriter.writerow(header)\n\n            for line in logfile:\n                d = convert_to_dict(line, header)\n                csvwriter.writerow([d[cell] for cell in header])\n"]], ['Parse Specific Text File to CSV Format with Headers'], 6, 0], [(34452644, 4), [['report.log'], ['report.csv  ']], [[' Sequence=3433;Status=true;Report=223313;Profile=xxxx;\nSequence=0323;Status=true;Header=The;Report=43838;Profile=xxxx;\nSequence=5323;Status=true;Report=6541998;Profile=xxxx;\n']], ['Parse Specific Text File to CSV Format with Headers'], 6, 0], [(34452644, 5), [['report.csv  '], ['I hope it helps! :D']], [[' Header,Profile,Report,Sequence,Status\n,xxxx,223313,3433,true\nThe,xxxx,43838,0323,true\n,xxxx,6541998,5323,true\n']], ['Parse Specific Text File to CSV Format with Headers'], 6, 0], [(34456661, 0), [['First, you should iterate directly over the list rather than using a counter and a while loop:'], ['Second, if you do  x=Label(...).grid(...) ,  x  will always be None. Best practice is to use two different statements. In this case the point is moot since you never use  currentClient , but you should get in the habit of always separating them. Group your widget creation together, and your layout together, and your GUI will be much easier to manage:']], [[" for client in dict_list:\n    currentClient = Label(text='Client: ' + client['Client']).grid(row=[i], column=1)\n    ...\n"]], ['Checkbox to determine if an action is completed or not'], 3, 0], [(34456661, 1), [['Second, if you do  x=Label(...).grid(...) ,  x  will always be None. Best practice is to use two different statements. In this case the point is moot since you never use  currentClient , but you should get in the habit of always separating them. Group your widget creation together, and your layout together, and your GUI will be much easier to manage:'], ['Third -- and this is the answer to your question -- you can create an instance of  IntVar  for each checkbutton, and store them either in a separate data structure or right along with your data. For example, to store them by business name you might do it like this:']], [[' for client in dict_list:\n    clientLabel = Label(...)\n    contactLabel = Label(...)\n    emailLabel = Label(...)\n\n    clientLabel.grid(...)\n    contactLabel.grid(...)\n    emailLabel.grid(...)\n']], ['Checkbox to determine if an action is completed or not'], 3, 0], [(34463966, 1), [['Property objects do have  .fget  and  .fset  attributes, and the property object itself can be accessed on the class:'], ["You could use those functions too, but then you'd have to bind them to your instance first:"]], [[' Player.health.fset\nPlayer.health.fget\n']], ['How do I obtain the reference of a getter/setter method created through @property in Python?'], 3, 0], [(34463966, 2), [["You could use those functions too, but then you'd have to bind them to your instance first:"], ['The  __get__  method  on the function (which is a  descriptor ) to provide you with a bound method which passes in the  self  argument for you (the  player  instance object in this case).']], [[' someWidget.valueChanged.connect(Player.health.fset.__get__(player))\n']], ['How do I obtain the reference of a getter/setter method created through @property in Python?'], 3, 0], [(34468751, 0), [['Just call  .xpath("@href|text()")  on every element this way:'], ['Demo:']], [[' for item in list:\n    href, text = item.xpath("@href|text()")\n    print(href, text)\n']], ['Get value to 2 attribute from a xpath node for anchor tag'], 2, 1], [(34478011, 0), [['This would allow only the initial setting of a  Computations  descriptor:'], ['The trick is to generate a new attribute on the instance:']], [[" class Computations(object):\n    def __init__(self, name):\n        self.name = name   # default value for area, circumference, distance to origin\n\n    def __get__(self, instance, cls):\n        if instance is None:\n            print('this is the __get__ if statement running')\n            return self\n        else:\n            print('this is the __get__ else statement running')\n            return instance.__dict__[self.name]\n\n    def __set__(self, instance, value):\n        if hasattr(instance, self.name + '_is_set'):\n            raise ValueError('Cannot set {} again.'.format(self.name[1:]))\n        if isinstance(value, int):\n            raise RuntimeError('Cant set formulas')\n        else:\n            instance.__dict__[self.name] = value\n            setattr(instance, self.name + '_is_set', True)\n"]], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34478011, 1), [['The trick is to generate a new attribute on the instance:'], ['For the instance  circle  and the attribute  circumference  this means:']], [[" setattr(instance, self.name + '_is_set', True) \n"]], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34478011, 2), [['For the instance  circle  and the attribute  circumference  this means:'], ['This checks if this attribute exists:']], [[' circle._circumference_is_set = True \n']], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34478011, 3), [['This checks if this attribute exists:'], ['Again for our case this means:']], [[" if hasattr(instance, self.name + '_is_set')\n"]], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34478011, 4), [['Again for our case this means:'], ['The first time  __set__  is called for  circumference  is in the class  Circle :']], [[" if hasattr(circle, '_circumference_is_set')\n"]], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34478011, 5), [['The first time  __set__  is called for  circumference  is in the class  Circle :'], ['Now  _circumference_is_set  exists and the next try to set it will result in an exception.']], [[' self.circumference = 2 * pi * self.r \n']], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34478011, 7), [['-10000'], ['Output:']], [[" # Testing code\nif __name__ == '__main__':\n\n    circle = Circle(x=3, y=4, r=5)\n    print('circumference', circle.circumference)\n\n    print('try setting circumference')\n    circle.circumference = 12.5\n"]], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34478011, 8), [['Output:'], ['Your tests:']], [[" this is the __get__ else statement running\ncircumference 31.41592653589793\ntry setting circumference\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-227-316199bab738> in <module>()\n     64 \n     65     print('try setting circumference')\n---> 66     circle.circumference = 12.5\n\n<ipython-input-227-316199bab738> in __set__(self, instance, value)\n     31     def __set__(self, instance, value):\n     32         if hasattr(instance, self.name + 'is_set'):\n---> 33             raise ValueError('Cannot set {} again.'.format(self.name[1:]))\n     34         if isinstance(value, int):\n     35             raise RuntimeError('Cant set formulas')\n\nValueError: Cannot set circumference again.\n"]], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34478011, 9), [['Your tests:'], ['generate this output:']], [[' if __name__ == \'__main__\':\n\n    circle = Circle(x=3, y=4, r=5)\n    print(circle.x)\n    print(circle.y)\n    print(circle.r)\n    print(circle.area)\n   # circle.area = 12\n    print(circle.area)\n    print(circle.circumference)\n    print(circle.distance_to_origin)\n    tests = [(\'circle.x = 12.3\', "print(\'Setting circle.x to non-integer fails\')"),\n             (\'circle.y = 23.4\', "print(\'Setting circle.y to non-integer fails\')"),\n             (\'circle.area = 23.4\', "print(\'Setting circle.area fails\')"),\n             (\'circle.circumference = 23.4\', "print(\'Setting circle.circumference fails\')"),\n             (\'circle.distance_to_origin = 23.4\', "print(\'Setting circle.distance_to_origin fails\')"),\n             (\'circle.z = 5.6\', "print(\'Setting circle.z fails\')"),\n             (\'print(circle.z)\', "print(\'Printing circle.z fails\')")]\n    for test in tests:\n        try:\n            exec(test[0])\n        except:\n            exec(test[1])\n']], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34478011, 10), [['generate this output:'], ['-10000']], [[' 3\n4\n5\nthis is the __get__ else statement running\n78.53981633974483\nthis is the __get__ else statement running\n78.53981633974483\nthis is the __get__ else statement running\n31.41592653589793\nthis is the __get__ else statement running\n0.0\nSetting circle.x to non-integer fails\nSetting circle.y to non-integer fails\nSetting circle.area fails\nSetting circle.circumference fails\nSetting circle.distance_to_origin fails\n5.6\n']], ["Using descriptor class to raise RuntimeError when user tries to change object's value"], 11, 0], [(34503246, 0), [['If all you really want to do is avoid importing pandas then the following works fine for me:'], ['producing']], [[' from sqlalchemy import create_engine\nengine = create_engine(\'mssql+pymssql://sa:saPassword@localhost:52865/myDb\')\nconn = engine.connect()\nrows = conn.execute("select name FROM sys.databases;")\nfor row in rows:\n    print(row["name"])\n']], ['List names of all available MS SQL databases on server using python'], 2, 1], [(34503246, 1), [['producing'], ['-10000']], [[' master\ntempdb\nmodel\nmsdb\nmyDb\n']], ['List names of all available MS SQL databases on server using python'], 2, 0], [(34505283, 0), [["I'm not sure about your case, but maybe the code you are looking for is:"], ['The sorted function sorts a list. The key parameter is a function to apply to each element before sorting. For example:']], [[' return sorted(fights, key=(lambda fight:fight["Date"]))\n']], ['Sorting a list with a dictionary at items'], 2, 1], [(34505283, 1), [['The sorted function sorts a list. The key parameter is a function to apply to each element before sorting. For example:'], ['Would return,  [3, 2, 1] , because it sorts [-1, -2, -3], but then uses the original numbers in the output, if that makes any sense. (Although in that particular case, using reversed=True) would be better.']], [[' sorted([1, 2, 3], key=(lambda x:(-x)))\n']], ['Sorting a list with a dictionary at items'], 2, 1], [(34512219, 0), [['Bottle can run multiple bottle apps as a single instance.\nYou can use something like this on main.py'], ['and on configure/config.py something like this:']], [[' import bottle\nfrom web.bottleApp import app\nfrom configure.config import configure_app\n\nmain = bottle.Bottle()\nmain.mount("/config/",configure)\nmain.mount("/",app)\n\nmain.run(host = \'localhost\', port=8080)\n']], ['Inserting a folder containing specific routes to a bottle application in Python'], 2, 0], [(34512219, 1), [['and on configure/config.py something like this:'], ['-10000']], [[" import bottle\n\nconfig_app = bottle.Bottle()\n\n@config_app.route('/config1')\ndef config1():    \n    return 'some config data'\n"]], ['Inserting a folder containing specific routes to a bottle application in Python'], 2, 0], [(34514629, 0), [['You do this, which will just return messages.'], ['But can do this to search for messages sent yesterday, by passing the  q  keyword argument, and a query specifying the  before:  and  after:  keywords.']], [[" message = service.users().messages().list(userId='me').execute()\n"]], ['New Python Gmail API - Only Retrieve Messages from Yesterday'], 2, 0], [(34514629, 1), [['But can do this to search for messages sent yesterday, by passing the  q  keyword argument, and a query specifying the  before:  and  after:  keywords.'], ['You can also try this against their  GMail  messages.list  reference page .']], [[' from datetime import date, timedelta\n\ntoday = date.today()\nyesterday = today - timedelta(1)\n\n# do your setup...\n\nuser_id = \'user email address\'\n\n# Dates have to formatted in YYYY/MM/DD format for gmail\nquery = "before: {0} after: {1}".format(today.strftime(\'%Y/%m/%d\'),\n                                        yesterday.strftime(\'%Y/%m/%d\'))\n\nresponse = service.users().messages().list(userId=user_id,\n                                           q=query).execute()\n# Process the response for messages...\n']], ['New Python Gmail API - Only Retrieve Messages from Yesterday'], 2, 1], [(34521703, 0), [["How's about this:"], ['You could do this as a comprehension, or function, more generally:']], [[' In [11]: df1 = df[["Misc", "Year"] + [c for c in df.columns if c[-1] == "1"]]\n\nIn [12]: df1 = df1.rename(columns=lambda x: x[:-1] if x[-1] == "1" else x)\n\nIn [13]: df1\nOut[13]:\n  Misc  Year   a  b    c\n0    A  1991  10  h  4.1\n1    R  1992  20  i  4.2\n2    B  1993  30  j  4.3\n\nIn [14]: df2 = df[["Misc", "Year"] + [c for c in df.columns if c[-1] == "2"]]\n\nIn [15]: df2 = df2.rename(columns=lambda x: x[:-1] if x[-1] == "2" else x)\n\nIn [16]: pd.concat([df1, df2])\nOut[16]:\n  Misc  Year   a  b    c\n0    A  1991  10  h  4.1\n1    R  1992  20  i  4.2\n2    B  1993  30  j  4.3\n0    A  1991  40  k  4.4\n1    R  1992  50  l  4.5\n2    B  1993  60  m  4.6\n']], ['Python Flatten Dataframe With Multiple Columns all n-length'], 2, 1], [(34546949, 0), [["Here's a simple example, which I tested on Python 2.6, but it should work ok on Python 3, too."], ["Here's a hexdump of its output:"]], [[" hdr = b'\\x00' * 4\nblocksize = 51\nleds = (\n    #LED off\n    hdr + b'\\x80\\x00' * blocksize,\n    #LED on\n    hdr + b'\\xff\\xff' * blocksize,\n)\n\nfname = '/dev/stdout'\nwith open(fname, 'wb') as f:\n    f.write(leds[0])\n"]], ['Send HEX values to SPI on a Raspberry PI B+'], 2, 1], [(34546949, 1), [["Here's a hexdump of its output:"], ['-10000']], [[' 00000000  00 00 00 00 80 00 80 00  80 00 80 00 80 00 80 00  |................|\n00000010  80 00 80 00 80 00 80 00  80 00 80 00 80 00 80 00  |................|\n00000020  80 00 80 00 80 00 80 00  80 00 80 00 80 00 80 00  |................|\n00000030  80 00 80 00 80 00 80 00  80 00 80 00 80 00 80 00  |................|\n00000040  80 00 80 00 80 00 80 00  80 00 80 00 80 00 80 00  |................|\n00000050  80 00 80 00 80 00 80 00  80 00 80 00 80 00 80 00  |................|\n00000060  80 00 80 00 80 00 80 00  80 00                    |..........|\n0000006a\n']], ['Send HEX values to SPI on a Raspberry PI B+'], 2, 0], [(34556645, 0), [['There are 8 types in  Lua : nil, boolean, number, string, function, thread,  table  and  userdata . You can find out which of these basic types your object belongs to using built-in  type()  function:'], ['It would be great if custom objects had some mechanism (a method or something) to see their custom types. And guess what? Torch objects have one:']], [[" type('Hello world')                    == 'string'\ntype(3.14)                             == 'number'\ntype(true)                             == 'boolean'\ntype(nil)                              == 'nil'\ntype(print)                            == 'function'\ntype(coroutine.create(function() end)) == 'thread'\ntype({})                               == 'table'\ntype(torch.Tensor())                   == 'userdata'\n"]], ['how to get the class type in lua / translation from python'], 3, 1], [(34556645, 1), [['It would be great if custom objects had some mechanism (a method or something) to see their custom types. And guess what? Torch objects have one:'], ['Speaking of  Torch . It has its own object system emulator, and you are free to create some torch classes yourself and check their types the same way. For  Lua , however, such classes/objects are nothing more than ordinary tables.']], [[" t = torch.Tensor()\ntype(t)       == 'userdata' # Because the class was written in C\ntorch.type(t) == 'torch.DoubleTensor'\n# or\nt:type()      == 'torch.DoubleTensor'\n"]], ['how to get the class type in lua / translation from python'], 3, 1], [(34556645, 2), [['Speaking of  Torch . It has its own object system emulator, and you are free to create some torch classes yourself and check their types the same way. For  Lua , however, such classes/objects are nothing more than ordinary tables.'], ['-10000']], [[" local A = torch.class('ClassA')\nfunction A:__init(val)\n    self.val = val\nend\n\nlocal B, parent = torch.class('ClassB', 'ClassA')\nfunction B:__init(val)\n    parent.__init(self, val)\nend\n\nb = ClassB(5)\ntype(b)       == 'table' # Because the class was written in Lua\ntorch.type(b) == 'ClassB'\nb:type() # exception; Custom Torch classes have no :type() method by defauld\n"]], ['how to get the class type in lua / translation from python'], 3, 1], [(34563454, 0), [['In  url.py  '], ['And render it like this:  ']], [[' from django.conf.urls.static import static\nfrom django.conf import settings\nurlpatterns = [....\n]+ static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)\n']], ['Django ImageField upload_to path'], 2, 0], [(34563454, 1), [['And render it like this:  '], ['-10000']], [[' {% for img in your_object %}\n<img src="{{ img.image.url }}" >\n{% endfor %}\n']], ['Django ImageField upload_to path'], 2, 0], [(34569966, 0), [['Use  enumerate  to keep track of the index and a set to keep track of element seen:'], ['If you want both:']], [[' l = [1, 1, 2, 3]\ninds = []\nseen = set()\nfor i, ele in enumerate(l):\n    if ele not in seen:\n        inds.append(i)\n    seen.add(ele)\n']], ['Remove duplicates in python list but remember the index'], 5, 1], [(34569966, 1), [['If you want both:'], ['Or if you want both in different lists:']], [[' inds = []\nseen = set()\nfor i, ele in enumerate(l):\n    if ele not in seen:\n        inds.append((i,ele))\n    seen.add(ele)\n']], ['Remove duplicates in python list but remember the index'], 5, 1], [(34569966, 2), [['Or if you want both in different lists:'], ['Using a set is by far the best approach:']], [[' l = [1, 1, 2, 3]\ninds, unq = [],[]\nseen = set()\nfor i, ele in enumerate(l):\n    if ele not in seen:\n        inds.append(i)\n        unq.append(ele)\n    seen.add(ele)\n']], ['Remove duplicates in python list but remember the index'], 5, 1], [(34569966, 3), [['Using a set is by far the best approach:'], ['If you want to get a value at a time you can use a generator function:']], [[' In [13]: l = [randint(1,10000) for _ in range(10000)]     \n\nIn [14]: %%timeit                                         \ninds = []\nseen = set()\nfor i, ele in enumerate(l):\n    if ele not in seen:\n        inds.append((i,ele))\n    seen.add(ele)\n   ....: \n100 loops, best of 3: 3.08 ms per loop\n\nIn [15]: timeit  OrderedDict((x, l.index(x)) for x in l)\n1 loops, best of 3: 442 ms per loop\n\nIn [16]: l = [randint(1,10000) for _ in range(100000)]      \nIn [17]: timeit  OrderedDict((x, l.index(x)) for x in l)\n1 loops, best of 3: 10.3 s per loop\n\nIn [18]: %%timeit                                       \ninds = []\nseen = set()\nfor i, ele in enumerate(l):\n    if ele not in seen:\n        inds.append((i,ele))\n    seen.add(ele)\n   ....: \n10 loops, best of 3: 22.6 ms per loop\n']], ['Remove duplicates in python list but remember the index'], 5, 1], [(34569966, 4), [['If you want to get a value at a time you can use a generator function:'], ['-10000']], [[' def yield_un(l):\n    seen = set()\n    for i, ele in enumerate(l):\n        if ele not in seen:\n            yield (i,ele)\n        seen.add(ele)\n']], ['Remove duplicates in python list but remember the index'], 5, 1], [(34576433, 0), [['You could reshape with  np.reshape  & then re-arrange dimensions with  np.transpose , like so -'], ['Instead of  np.transpose , one can also use  np.swapaxes  as basically we are swapping  axes 1,2  there, like so -']], [[' H = data.reshape(N,Nt,N).transpose(0,2,1)\n']], ['Copy 2D array to a 3D one - Python / NumPy'], 4, 1], [(34576433, 1), [['Instead of  np.transpose , one can also use  np.swapaxes  as basically we are swapping  axes 1,2  there, like so -'], ['Sample run -']], [[' H = data.reshape(N,Nt,N).swapaxes(1,2)\n']], ['Copy 2D array to a 3D one - Python / NumPy'], 4, 1], [(34576433, 2), [['Sample run -'], ['Runtime test -']], [[' In [300]: N = 2\n     ...: Nt = 3\n     ...: data = np.random.randint(0,9,(N*Nt,N))\n     ...: \n\nIn [301]: data\nOut[301]: \narray([[3, 6],\n       [7, 4],\n       [8, 1],\n       [8, 7],\n       [4, 8],\n       [2, 3]])\n\nIn [302]: H = np.zeros((N,N,Nt),dtype=data.dtype)\n     ...: for k in np.arange(N):\n     ...:     for l in np.arange(N):            \n     ...:         for m in np.arange(Nt):    \n     ...:             H[k,l,m] = data[m+Nt*k,l]\n     ...:             \n\nIn [303]: H\nOut[303]: \narray([[[3, 7, 8],\n        [6, 4, 1]],\n\n       [[8, 4, 2],\n        [7, 8, 3]]])\n\nIn [304]: data.reshape(N,Nt,N).transpose(0,2,1)\nOut[304]: \narray([[[3, 7, 8],\n        [6, 4, 1]],\n\n       [[8, 4, 2],\n        [7, 8, 3]]])\n']], ['Copy 2D array to a 3D one - Python / NumPy'], 4, 1], [(34585582, 0), [['Create a function that can determine whether a point at coordinates  (x, y)  is or is not in the area. See  here  for more details on how to rasterize your shapefile into an array of the same dimensions as your target mask'], ['Step 2. Create your mask']], [[' def point_is_in_mask(mask, point):\n    # this is just pseudocode\n    return mask.contains(point) \n']], ['how to mask the specific array data based on the shapefile'], 2, 0], [(34585582, 1), [['Step 2. Create your mask'], ['-10000']], [[' mask = np.zeros((height, width))\nvalue = np.zeros((height, width))\nfor y in range(height):\n    for x in range(width):\n        if not point_is_in_mask(mask, (x, y)):\n            value[y][x] = np.nan\n']], ['how to mask the specific array data based on the shapefile'], 2, 0], [(34596082, 0), [['This could be done with simple string formatting:'], ['If items in your array are not only strings but also numbers it will still work, though you will probably want them left aligned (strings are by default):']], [[' arr = [\'ABCD\', \'1\', \'P\', \'15-06-2015\', \'0\', \'Name of the account\']\nprint "{:16}{:3}{:3}{:29}{:3}{:40}".format(*arr)\n']], ['Writing to a specific column of a text file in python'], 2, 1], [(34596082, 1), [['If items in your array are not only strings but also numbers it will still work, though you will probably want them left aligned (strings are by default):'], ["Here's  doc ."]], [[' arr = [\'ABCD\', 1, \'P\', \'15-06-2015\', 0, \'Name of the account\']\nprint "{:16}{:<3}{:3}{:29}{:<3}{:40}".format(*arr)\n']], ['Writing to a specific column of a text file in python'], 2, 1], [(34598020, 0), [["A pure NumPy solution could work like this (I've named your starting array  a ):"], ['A solution in  pandas  is possible in fewer lines (and potentially uses less additional memory than the NumPy method):']], [[' >>> b = a[np.argsort(a[:, 0])]\n>>> grps, idx = np.unique(b[:, 0], return_index=True)\n>>> counts = np.add.reduceat(b[:, 1:], idx)\n>>> np.column_stack((grps, counts))\narray([[117,   1,   1,   0,   0,   1],\n       [120,   0,   1,   1,   0,   0],\n       [163,   1,   0,   0,   0,   0],\n       [189,   0,   0,   0,   1,   0]])\n']], ['Consolidate duplicate rows of an array'], 2, 1], [(34598020, 1), [['A solution in  pandas  is possible in fewer lines (and potentially uses less additional memory than the NumPy method):'], ['The  sort=False  parameter means that the rows are returned in the order the unique labels were first encountered.']], [[' >>> df = pd.DataFrame(a)\n>>> df.groupby(0, sort=False, as_index=False).sum().values\narray([[117,   1,   1,   0,   0,   1],\n       [163,   1,   0,   0,   0,   0],\n       [120,   0,   1,   1,   0,   0],\n       [189,   0,   0,   0,   1,   0]])\n']], ['Consolidate duplicate rows of an array'], 2, 1], [(34600056, 0), [['Select the relevant  rows  using  boolean indexing   (see docs) , and  map  your  dictionary  to translate  A  to  B  values where necessary:'], ['mask  looks as follows:']], [[' na_map = {"Red": 123, "Green": 456, "Blue": 789}\nmask = df.B.isnull()\n']], ['Using Pandas to fill NaN entries based on values in a different column, using a dictionary as a guide'], 3, 0], [(34600056, 1), [['mask  looks as follows:'], ['Finally:']], [[' 0    False\n1    False\n2     True\n3    False\n4    False\n5     True\n6    False\n7     True\n']], ['Using Pandas to fill NaN entries based on values in a different column, using a dictionary as a guide'], 3, 0], [(34600056, 2), [['Finally:'], ['-10000']], [[" df.loc[mask, 'B'] = df.loc[mask, 'A'].map(na_map)\n\n       A    B\n0    Red  628\n1    Red  149\n2    Red  123\n3  Green  575\n4  Green  687\n5  Green  456\n6   Blue  159\n7   Blue  789\n"]], ['Using Pandas to fill NaN entries based on values in a different column, using a dictionary as a guide'], 3, 0], [(34601770, 0), [['Assuming you mean the magnitude of the difference relative to  arr_a , use:'], ['If you want the magnitude of the difference relative to  arr_b , use:']], [[' import numpy as np \n\narr_a = np.random.rand(10) \narr_b = np.random.rand(10)\n\narr_c = np.where((abs(arr_a - arr_b)/arr_a) > 0.3, 1, 0) \n']], ['Create numpy array based on magnitude of difference between arrays'], 2, 1], [(34601770, 1), [['If you want the magnitude of the difference relative to  arr_b , use:'], ['-10000']], [[' arr_c = np.where((abs(arr_a - arr_b)/arr_b) > 0.3, 1, 0) \n']], ['Create numpy array based on magnitude of difference between arrays'], 2, 1], [(34607271, 0), [['Using this API you can download APKs using their package name:'], ['For finding relevant APKs you can use the search or even parse subcategories']], [[' python download.py com.google.android.gm\n']], ['Is it possible to download apk from google play programmatically to PC?'], 2, 1], [(34637002, 0), [['So, I decided to just  timeit , and find which one was the fastest. Note that the final function is a cleaner version of your own  pythonicPalindrome . It is defined as follows:'], ['-10000']], [[' def palindrome(s, o):\n    return re.sub("[ ,.;:?!]", "", s.lower()) == re.sub("[ ,.;:?!]", "", o.lower())[::-1]\n']], ['Fast and pythonic way to find out if a string is a palindrome'], 2, 1], [(34637002, 1), [['-10000'], ['It would appear that the cleaner version of your  pythonicPalindrome  is marginally faster, but both functions clearly outclass the alternatives.']], [['             palindrom       iteratorPalindrome      pythonicPalindrome      palindrome  \n1           0.131656638            0.108762937             0.071676536      0.072031984\n2           0.140950052            0.109713793             0.073781851      0.071860462\n3           0.126966087            0.109586756             0.072349792      0.073776719\n4           0.125113136            0.108729573             0.094633969      0.071474645\n5           0.130878159            0.108602964             0.075770395      0.072455015\n6           0.133569472            0.110276694             0.072811747      0.071764222\n7           0.128642812            0.111065438             0.072170571      0.072285204\n8           0.124896702            0.110218949             0.071898959      0.071841214\n9           0.123841905            0.109278358             0.077430437      0.071747112\n10          0.124083576            0.108184210             0.080211147      0.077391086\n\nAVG         0.129059854            0.109441967             0.076273540      0.072662766\nSTDDEV      0.005387429            0.000901370             0.007030835      0.001781309\n']], ['Fast and pythonic way to find out if a string is a palindrome'], 2, 0], [(34638457, 0), [['One way to do it by hand would be:'], ['This prints:']], [[' def type_spec_iterable(obj, name):\n    tps = set(type_spec(e) for e in obj)\n    if len(tps) == 1:\n        return name + "<" + next(iter(tps)) + ">"\n    else:\n        return name + "<?>"\n\n\ndef type_spec_dict(obj):\n    tps = set((type_spec(k), type_spec(v)) for (k,v) in obj.iteritems())\n    keytypes = set(k for (k, v) in tps)\n    valtypes =  set(v for (k, v) in tps)\n    kt = next(iter(keytypes)) if len(keytypes) == 1 else "?"\n    vt = next(iter(valtypes)) if len(valtypes) == 1 else "?"\n    return "dict<%s, %s>" % (kt, vt)\n\n\ndef type_spec_tuple(obj):\n    return "tuple<" + ", ".join(type_spec(e) for e in obj) + ">"\n\n\ndef type_spec(obj):\n    t = type(obj)\n    res = {\n        int: "int",\n        str: "str",\n        bool: "bool",\n        float: "float",\n        type(None): "(none)",\n        list: lambda o: type_spec_iterable(o, \'list\'),\n        set: lambda o: type_spec_iterable(o, \'set\'),\n        dict: type_spec_dict,\n        tuple: type_spec_tuple,\n    }.get(t, lambda o: type(o).__name__)\n    return res if type(res) is str else res(obj)\n\n\nif __name__ == "__main__":\n    class Foo(object):\n        pass\n    for obj in [\n        1,\n        2.3,\n        None,\n        False,\n        "hello",\n        [1, 2, 3],\n        ["a", "b"],\n        [1, "h"],\n        (False, 1, "2"),\n        set([1.2, 2.3, 3.4]),\n        [[1,2,3],[4,5,6],[7,8,9]],\n        [(1,\'a\'), (2, \'b\')],\n        {1:\'b\', 2:\'c\'},\n        [Foo()], # todo - inheritance?\n    ]:\n        print repr(obj), ":", type_spec(obj)\n']], ['How to determine type of nested data structures in Python?'], 2, 1], [(34638457, 1), [['This prints:'], ["There's a question of how far you want to take it, and how deeply to check, with trade-offs between speed and accuracy. For example, do you want to go through all the items in a large list? Do you want to handle custom types (and tracking down common ancestors of those types)?"]], [[" 1 : int\n2.3 : float\nNone : (none)\nFalse : bool\n'hello' : str\n[1, 2, 3] : list<int>\n['a', 'b'] : list<str>\n[1, 'h'] : list<?>\n(False, 1, '2') : tuple<bool, int, str>\nset([2.3, 1.2, 3.4]) : set<float>\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]] : list<list<int>>\n[(1, 'a'), (2, 'b')] : list<tuple<int, str>>\n{1: 'b', 2: 'c'} : dict<int, str>\n[<__main__.Foo object at 0x101de6c50>] : list<Foo>\n"]], ['How to determine type of nested data structures in Python?'], 2, 0], [(34672986, 0), [['Assuming you want to check literally for "would" followed by "be", followed by some adjective, you can do this:'], ['You can do something very similar for the second type of sentence:']], [[" def would_be(tagged):\n    return any(['would', 'be', 'JJ'] == [tagged[i][0], tagged[i+1][0], tagged[i+2][1]] for i in xrange(len(tagged) - 2))\n"]], ['detecting POS tag pattern along with specified words'], 4, 0], [(34672986, 1), [['You can do something very similar for the second type of sentence:'], ["Here's a driver for the program:"]], [[" def am_able_to(tagged):\n    return any(['am', 'able', 'to', 'VB'] == [tagged[i][0], tagged[i+1][0], tagged[i+2][0], tagged[i+3][1]] for i in xrange(len(tagged) - 3))\n"]], ['detecting POS tag pattern along with specified words'], 4, 0], [(34672986, 2), [["Here's a driver for the program:"], ['This correctly outputs:']], [[' s1 = [(\'This\', \'DT\'), (\'feature\', \'NN\'), (\'would\', \'MD\'), (\'be\', \'VB\'), (\'nice\', \'JJ\'), (\'to\', \'TO\'), (\'have\', \'VB\')]\ns2 = [(\'I\', \'PRP\'), (\'am\', \'VBP\'), (\'able\', \'JJ\'), (\'to\', \'TO\'), (\'delete\', \'VB\'), (\'the\', \'DT\'), (\'group\', \'NN\'), (\'functionality\', \'NN\')]\n\ndef would_be(tagged):\n   return any([\'would\', \'be\', \'JJ\'] == [tagged[i][0], tagged[i+1][0], tagged[i+2][1]] for i in xrange(len(tagged) - 2))\n\ndef am_able_to(tagged):\n    return any([\'am\', \'able\', \'to\', \'VB\'] == [tagged[i][0], tagged[i+1][0], tagged[i+2][0], tagged[i+3][1]] for i in xrange(len(tagged) - 3))\n\nsent1 = \' \'.join(s[0] for s in s1)\nsent2 = \' \'.join(s[0] for s in s2)\n\nprint("Is \'{1}\' of type \'would be\' + adj? {0}".format(would_be(s1), sent1))\nprint("Is \'{1}\' of type \'am able to\' + verb? {0}".format(am_able_to(s1), sent1))\n\nprint("Is \'{1}\' of type \'would be\' + adj? {0}".format(would_be(s2), sent2))\nprint("Is \'{1}\' of type \'am able to\' + verb? {0}".format(am_able_to(s2), sent2))\n']], ['detecting POS tag pattern along with specified words'], 4, 1], [(34672986, 3), [['This correctly outputs:'], ["If you'd like to generalize this, you can change whether you're checking the literal words or their POS tag. "]], [[" Is 'This feature would be nice to have' of type 'would be' + adj? True\nIs 'This feature would be nice to have' of type 'am able to' + verb? False\nIs 'I am able to delete the group functionality' of type 'would be' + adj? False\nIs 'I am able to delete the group functionality' of type 'am able to' + verb? True\n"]], ['detecting POS tag pattern along with specified words'], 4, 0], [(34683678, 0), [['This should work:'], ['So:']], [[' multi_dicts(*list_of_dicts)\n']], ['Python - list of dicts into function that only accepts *dicts'], 3, 1], [(34683678, 1), [['So:'], ['Will print:']], [[" def foo(*bars):\n    for bar in bars:\n        print(bar)\n\nlist_of_things = ['one', 'two', 'three']\n\nfoo(*list_of_things)\n"]], ['Python - list of dicts into function that only accepts *dicts'], 3, 1], [(34683678, 2), [['Will print:'], ['This works just as well if the list contains dictionaries.']], [[' one\ntwo\nthree\n']], ['Python - list of dicts into function that only accepts *dicts'], 3, 0], [(34686485, 0), [['Indeed concatenating string will just result in another string. To run string containing python codes as python expression, you need to use  exec()  function, for example  :'], ['or if you expect the expression to return value, you can use  eval()  instead of  exec()  :']], [[' ....\nelse:\n    exec(ui_application.tag)\n']], ['Execute parsed xml data as command in python'], 2, 1], [(34686485, 1), [['or if you expect the expression to return value, you can use  eval()  instead of  exec()  :'], ['-10000']], [[' ....\nelse:\n    result = eval(ui_application.tag)\n']], ['Execute parsed xml data as command in python'], 2, 1], [(34687883, 2), [['Now you can do exactly what you told:'], ['This  daemon module  is very useful:']], [[' mynohup myscript.py             # will automatically continue running in\n                                # background even if I log out\n\n# two days later, even if I logged out / logged in again the meantime\nmykill myscript.py\n']], ['Starting/stopping a background Python process wtihout nohup + ps aux grep + kill'], 4, 0], [(34701261, 0), [['You can do'], ['Since you are just returning the truth value, you can do']], [[' if A in ["a", "b", "c"]:\n    # do the thing\n']], ["What's the convinient way to evaluate multiple string equality in Python?"], 2, 1], [(34701261, 1), [['Since you are just returning the truth value, you can do'], ['The  in  operator returns a boolean.']], [[' def f(A):\n    return A in ["a", "b", "c"]\n']], ["What's the convinient way to evaluate multiple string equality in Python?"], 2, 1], [(34715227, 0), [['Use  zip'], ['output:']], [[" x= [['first sentence'],['second sentence'],['third sentence']]\ny= [1,0,1]\n\nfor zx,zy in zip(x, y):\n    print('{}, {}'.format(zx[0], zy))\n"]], ['how to write two elements into one row in Python'], 2, 1], [(34715227, 1), [['output:'], ['-10000']], [[' first sentence, 1\nsecond sentence, 0\nthird sentence, 1\n']], ['how to write two elements into one row in Python'], 2, 0], [(34734933, 0), [['You can access the elements the same way you would another dictionary:'], ['If you want to print the keys and values you can do this:']], [[" >>> from collections import Counter\n>>> theList = ['blue', 'red', 'blue', 'yellow', 'blue', 'red']\n>>> newList = Counter(theList)\n>>> newList['blue']\n3\n"]], ['Python - Access contents of list after applying Counter from collections module'], 2, 1], [(34755636, 0), [['One option would be to manually specify the x-axis based on the DataFrame index, and then plot directly using matplotlib.'], ['Another option would be to concatenate your DataFrames and plot using Pandas. If you give your "FishEffort" field the correct label name when loading the data or via  DataFrame.rename  then the labels will be specified automatically. ']], [[' import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# make up some data\nn = 100\ndates = pd.date_range(start = "2015-01-01", periods = n, name = "yearDate")\n\ndfs = []\n\nfor i in range(3):\n    df = pd.DataFrame(data = np.random.random(n)*(i + 1), index = dates,\n                      columns = ["FishEffort"] )\n    df.df_name = str(i)\n    dfs.append(df)\n\n# plot it directly using matplotlib instead of through the DataFrame\nfig = plt.figure()\nax = fig.add_subplot()\n\nfor df in dfs:\n    plt.plot(df.index,df["FishEffort"], label = df.df_name)\n\nplt.legend()\nplt.show()\n']], ['Date removed from x axis on overlaid plots matplotlib'], 2, 1], [(34755636, 1), [['Another option would be to concatenate your DataFrames and plot using Pandas. If you give your "FishEffort" field the correct label name when loading the data or via  DataFrame.rename  then the labels will be specified automatically. '], ['']], [[' import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nn = 100\ndates = pd.date_range(start = "2015-01-01", periods = n, name = "yearDate")\n\ndfs = []\n\nfor i in range(3):\n    df = pd.DataFrame(data = np.random.random(n)*(i + 1), index = dates,\n                      columns = ["DataFrame #" + str(i) ] )\n    df.df_name = str(i)\n    dfs.append(df)\n\ndf = pd.concat(dfs, axis = 1)\ndf.plot()\n']], ['Date removed from x axis on overlaid plots matplotlib'], 2, 1], [(34769801, 0), [['Both work for list of non-unique elements as well:'], ['or']], [[' def choice_without_repetition(lst):\n    prev = None\n    while True:\n        i = random.randrange(len(lst))\n        if i != prev:\n            yield lst[i]\n            prev = i\n']], ['how to pick random items from a list while avoiding picking the same item in a row'], 3, 1], [(34769801, 1), [['or'], ['Usage:']], [[' def choice_without_repetition(lst):\n    i = 0\n    while True:\n        i = (i + random.randrange(1, len(lst))) % len(lst)\n        yield lst[i]\n']], ['how to pick random items from a list while avoiding picking the same item in a row'], 3, 1], [(34769801, 2), [['Usage:'], ['-10000']], [[' lst = [1,2,3,4,5,6,7,8]\nfor x in choice_without_repetition(lst):\n    print x\n']], ['how to pick random items from a list while avoiding picking the same item in a row'], 3, 0], [(34773317, 0), [["Here is one solution that is quite a bit faster than your current solution, I'm not convinced that there wouldn't be something faster though"], ['Fasted solution I can come up with is using  replace  as mentioned in another answer:']], [[" In [13]: import numpy as np\n         import pandas as pd\n         n = 1000\n         testing  = pd.DataFrame({'NAME':[\n         'FIRST', np.nan, 'NAME2', 'NAME3', \n         'NAME4', 'NAME5', 'NAME6']*n, 'FULL_NAME':['FIRST LAST', np.nan, 'FIRST  LAST', 'FIRST NAME3', 'FIRST NAME4 LAST', 'ANOTHER NAME', 'LAST NAME']*n})\n"]], ['Python Pandas removing substring using another column'], 4, 1], [(34773317, 1), [['Fasted solution I can come up with is using  replace  as mentioned in another answer:'], ['Original answer:']], [[" In [37]: %timeit testing ['NEW2'] = [e.replace(k, '') for e, k in zip(testing.FULL_NAME.astype('str'), testing.NAME.astype('str'))]\n100 loops, best of 3: 4.67 ms per loop\n"]], ['Python Pandas removing substring using another column'], 4, 1], [(34773317, 2), [['Original answer:'], ['compared to your current solution:']], [[" In [14]: %timeit testing ['NEW'] = [''.join(str(e).split(k)) for e, k in zip(testing.FULL_NAME.astype('str'), testing.NAME.astype('str'))]\n100 loops, best of 3: 7.24 ms per loop\n"]], ['Python Pandas removing substring using another column'], 4, 0], [(34773317, 3), [['compared to your current solution:'], ['These get you the same answer as your current solution']], [[" In [16]: %timeit testing['NEW1'] = testing.apply(address_remove, axis=1)\n10 loops, best of 3: 166 ms per loop\n"]], ['Python Pandas removing substring using another column'], 4, 0], [(34777323, 0), [['It is easier to use the tools Python provides:'], ['Edit:  to match the updated question, here is the updated solution ;-)']], [[' from itertools import groupby\nfrom operator import itemgetter\n\nitems = [\n    (\'name1\', 10), (\'name1\', 30),\n    (\'name2\', 5), (\'name2\', 7), (\'name2\', 3),\n    (\'name3\', 10)\n]\n\nfor name, rows in groupby(items, itemgetter(0)):\n    with open(name + ".txt", "w") as outf:\n        outf.write("\\n".join(str(row[1]) for row in rows))\n']], ['Opening and closing files in a loop'], 2, 1], [(34793225, 0), [["It isn't recommended to use regex to parse XML - you should use a library such as  lxml , which you can install using  pip install lxml . Then, you could select the appropriate elements to output using  lxml  and  XPath  as follows (I have taken the liberty of closing the  <Iteration_hit>  tags in your XML):"], ['Output']], [[' content = \'\'\'\n<root>\n<Iteration>\n  <Iteration_hit>Elememt1 Element1\n    abc1 hit 1\n  </Iteration_hit>\n</Iteration>\n<Iteration>\n  <Iteration_hit>Elememt2 Element2\n    abc2 hit 1\n  </Iteration_hit>\n</Iteration>\n<Iteration>\n  <Iteration_hit>Elememt3 Element3\n    abc3 hit 1\n  </Iteration_hit>\n</Iteration>\n<Iteration>\n  <Iteration_hit>Elememt4 Element4\n    abc4 hit 1\n  </Iteration_hit>\n</Iteration>\n</root>\n\'\'\'\n\nfrom lxml import etree\n\ntree = etree.XML(content)\ntarget_elements = tree.xpath(\'//Iteration_hit[contains(., "Element2") or contains(., "Element4")]\')\n\nfor element in target_elements:\n    print(etree.tostring(element))\n']], ['Extract from a match to next match if patten found in between'], 2, 1], [(34793225, 1), [['Output'], ['-10000']], [[' <Iteration_hit>Elememt2 Element2\n    abc2 hit 1\n  </Iteration_hit>\n\n<Iteration_hit>Elememt4 Element4\n    abc4 hit 1\n  </Iteration_hit>\n']], ['Extract from a match to next match if patten found in between'], 2, 0], [(34799167, 0), [['OK here it goes, this is one way of solving your problem.  I used a dictionary to hold the values for each combination.'], ["Then, for each 'connection' combination, the first letter was always that same as the first letter for  fld1 .  the second letter was always  not   fld1 .  So here is an exhaustive and maybe not pythonic way of calculating your values and storing the combinations' connections values in a dictionary for later use."]], [[' xyzdict = {"xx":0.25,\n          "xy":0.25,\n          "xz":0.5,\n          "yx":0.33,\n          "yy":0.33,\n          "yz":0.33,\n          "zx":0.5,\n          "zy":0.5}\n']], ['Conditionally and interatively calculate column based on value of three columns'], 5, 0], [(34799167, 1), [["Then, for each 'connection' combination, the first letter was always that same as the first letter for  fld1 .  the second letter was always  not   fld1 .  So here is an exhaustive and maybe not pythonic way of calculating your values and storing the combinations' connections values in a dictionary for later use."], ['Almost there, define a function  check  that will pull out your  fld1  and  fld2  and return the calculated values from  cnxn  above.']], [[' cnxn = {}\nxyz = ["x","y","z"]\n\nfor combo in xyzdict.keys():\n    #print "the combo is %s" % (combo) #xyzdict[two] #actual value\n    first_letter = combo[0]\n\n    not_second = [combo[0],combo[1]]\n    not_second_letter = list(set(xyz) - set(not_second))\n\n    if len(not_second_letter) > 1:\n        multi_cnxn = []\n        for each_not_second_letter in not_second_letter:\n\n            fwd = \'\'.join((first_letter,each_not_second_letter))\n            rev = \'\'.join((each_not_second_letter,first_letter))\n            cnxnval = xyzdict[fwd] * xyzdict[rev]\n\n            multi_cnxn.append(cnxnval)\n\n        rowvalue = xyzdict[combo] + sum(multi_cnxn)\n        cnxn[combo] =rowvalue\n    else:\n        fwd = \'\'.join((first_letter,not_second_letter[0]))\n        rev = \'\'.join((not_second_letter[0],first_letter))\n        cnxnval = xyzdict[fwd] * xyzdict[rev]\n\n        rowvalue = xyzdict[combo] + cnxnval\n        cnxn[combo] = rowvalue\n']], ['Conditionally and interatively calculate column based on value of three columns'], 5, 0], [(34799167, 2), [['Almost there, define a function  check  that will pull out your  fld1  and  fld2  and return the calculated values from  cnxn  above.'], ['Finally, a little pandas  apply  to bring it all home.']], [[" def check(fld1,fld2,cnxn_sub):\n    rowpair = ''.join((fld1,fld2))\n    return cnxn_sub[rowpair]\n"]], ['Conditionally and interatively calculate column based on value of three columns'], 5, 0], [(34799167, 3), [['Finally, a little pandas  apply  to bring it all home.'], ['Here are my results, our "yz" connection is a little off, idk if that is on your end or mine...']], [[" df['connection'] = df.apply(lambda row: check(row['fld1'], row['fld2'],cnxn), axis=1)\n"]], ['Conditionally and interatively calculate column based on value of three columns'], 5, 0], [(34799167, 4), [['Here are my results, our "yz" connection is a little off, idk if that is on your end or mine...'], ['Good Luck!']], [[' fld1    fld2    relationship    connection\n0   x   x   0.25    0.5825\n1   x   y   0.25    0.5000\n2   x   z   0.50    0.5825\n3   y   x   0.33    0.4950\n4   y   y   0.33    0.5775\n5   y   z   0.33    0.4125\n6   z   x   0.50    0.6650\n7   z   y   0.50    0.7500\n']], ['Conditionally and interatively calculate column based on value of three columns'], 5, 0], [(34818228, 0), [['If you can accept slightly different output, this might work for you:'], ['Alternatively:']], [[" from collections import Counter\n\ndicts = [\n    {1: 'url1', 3: 'url2', 7: 'url3', 5: 'url4'},\n    {1: 'url1', 7: 'url3'},\n    {5: 'url4', 10: 'url5'},\n]\n\nresult = Counter()\nfor d in dicts:\n    result.update(d.keys())\n\nprint dict(result)\n"]], ['How to count number of repeated keys in several dictionaries?'], 3, 1], [(34818228, 1), [['Alternatively:'], ['Final version: this one produces exactly your requested output:']], [[" from collections import Counter\nfrom itertools import chain\n\ndicts = [\n    {1: 'url1', 3: 'url2', 7: 'url3', 5: 'url4'},\n    {1: 'url1', 7: 'url3'},\n    {5: 'url4', 10: 'url5'},\n]\n\nresult = Counter(chain.from_iterable(dicts))\n\nprint dict(result)\n"]], ['How to count number of repeated keys in several dictionaries?'], 3, 1], [(34818228, 2), [['Final version: this one produces exactly your requested output:'], ['-10000']], [[" from collections import Counter\nfrom itertools import chain\n\ndicts = [\n    {1: 'url1', 3: 'url2', 7: 'url3', 5: 'url4'},\n    {1: 'url1', 7: 'url3'},\n    {5: 'url4', 10: 'url5'},\n]\n\nresult = Counter(chain.from_iterable(d.items() for d in dicts))\nresult = {k:[n,v] for ((k,v),n) in result.items()}\n\nprint dict(result)\n"]], ['How to count number of repeated keys in several dictionaries?'], 3, 1], [(34824864, 0), [['I am just using it like this, and it works fine (Python 3.3+):'], ['If you want to save it or send for other application without converting the types you can think about to use the timestamp rather:']], [[' from datetime import datetime\ntime_list = []\ntime_list.append(datetime.now())\n']], ['Python list and time'], 2, 1], [(34824864, 1), [['If you want to save it or send for other application without converting the types you can think about to use the timestamp rather:'], ['-10000']], [[' from datetime import datetime\ntime_list = []\ntime_list.append(datetime.now().timestamp())\n']], ['Python list and time'], 2, 1], [(34837194, 0), [["Here's something I put together, based on some old Python scripts I once wrote:"], ['You can run it from the command line, using the prefix of your map stack and the number of the first output map as arguments, e.g.:']], [[' #! /usr/bin/env python\n# Rename PCRaster map stack with names following prefix.yyymmmdd to stack with valid\n# PCRaster time step numbers\n# Johan van der Knijff\n#\n# Example input stack:\n#\n# precip.19810101\n# precip.19810102\n# precip.19810103\n# precip.19810104\n# precip.19810105\n#\n# Then run script with following arguments:\n#\n# python renpcrstack.py precip 1\n#\n# Result:\n#\n# precip00.001\n# precip00.002\n# precip00.003\n# precip00.004\n# precip00.005\n#\n\nimport sys\nimport os\nimport argparse\nimport math\nimport datetime\nimport glob\n\n# Create argument parser\nparser = argparse.ArgumentParser(\n    description="Rename map stack")\n\ndef parseCommandLine():\n    # Add arguments\n    parser.add_argument(\'prefix\',\n                        action="store",\n                        type=str,\n                        help="prefix of input map stack (also used as output prefix)")\n    parser.add_argument(\'stepStartOut\',\n                        action="store",\n                        type=int,\n                        help="time step number that is assigned to first map in output stack")\n\n    # Parse arguments\n    args = parser.parse_args()\n\n    return(args)\n\ndef dateToJulianDay(date):\n\n    # Calculate Julian Day from date\n    # Source: https://en.wikipedia.org/wiki/Julian_day#Converting_Julian_or_Gregorian_calendar_date_to_Julian_day_number\n\n    a = (14 - date.month)/12\n    y = date.year + 4800 - a\n    m = date.month +12*a - 3\n\n    JulianDay = date.day + math.floor((153*m + 2)/5) + 365*y + math.floor(y/4) \\\n        - math.floor(y/100) + math.floor(y/400) - 32045\n\n    return(JulianDay)\n\ndef genStackNames(prefix,start,end, stepSize):\n    # Generate list with names of all maps\n    # map name is made up of 11 characters, and chars 8 and 9 are\n    # separated by a dot. Name starts with prefix, ends with time step\n    # number and all character positions in between are filled with zeroes\n\n    # define list that will contain map names\n    listMaps = []\n\n    # Count no chars prefix\n    charsPrefix = len(prefix)\n\n    # Maximum no chars needed for suffix (end step)\n    maxCharsSuffix = len(str(end))\n\n    # No of free positions between pre- and suffix\n    noFreePositions = 11 - charsPrefix - maxCharsSuffix\n\n    # Trim prefix if not enough character positions are available \n    if noFreePositions < 0:\n        # No of chars to cut from prefix if 11-char limit is exceeded\n        charsToCut = charsPrefix + maxCharsSuffix - 11\n        charsToKeep = charsPrefix - charsToCut\n\n        # Updated prefix\n        prefix = prefix[0:charsToKeep]\n\n        # Updated prefix length\n        charsPrefix = len(prefix)\n\n    # Generate name for each step\n\n    for i in range(start,end + 1,stepSize):\n\n        # No of chars in suffix for this step\n        charsSuffix = len(str(i))\n\n        # No of zeroes to fill\n        noZeroes = 11 - charsPrefix - charsSuffix\n\n        # Total no of chars right of prefix\n        charsAfterPrefix = noZeroes + charsSuffix\n\n        # Name of map\n\n        thisName = prefix + (str(i)).zfill(charsAfterPrefix)\n        thisFile = thisName[0:8]+"." + thisName[8:11]\n\n        listMaps.append(thisFile)\n\n    return listMaps    \n\ndef main():\n    # Parse command line arguments\n    args = parseCommandLine()\n    prefix = args.prefix\n    stepStartOut = args.stepStartOut\n\n    # Glob pattern for input maps: prefix + dot + 8 char extension\n    pattern = prefix + ".????????"\n\n    # Get list of all input maps based on glob pattern\n    mapsIn = glob.glob(pattern)\n\n    # Set time format\n    tfmt = "%Y%m%d"\n\n    # Set up dictionary that will act as lookup table between Julian Days (key) \n    # and Date string\n    jDayDate = {}\n\n    for map in mapsIn:\n        baseNameIn = os.path.splitext(map)[0]\n        dateIn = os.path.splitext(map)[1].strip(".")\n\n        # Convert to date / time format\n        dt = datetime.datetime.strptime(dateIn, tfmt)\n\n        # Convert date to Julian day number\n        jDay = int(dateToJulianDay(dt))\n\n        # Store as key-value pair in dictionary\n        jDayDate[jDay] = dateIn\n\n    # Number of input maps (equals number of key-value pairs)\n    noMaps = len(jDayDate)\n\n    # Create list of names for output files \n    mapNamesOut = genStackNames(prefix, stepStartOut, noMaps + stepStartOut -1, 1)\n\n    # Iterate over Julian Days (ascending order)\n\n    i = 0\n\n    for key in sorted(jDayDate):\n        # Name of input file\n        fileIn = prefix + "."+ jDayDate[key]\n\n        # Name of output file\n        fileOut = mapNamesOut[i]\n\n        # Rename file\n        os.rename(fileIn, fileOut)\n\n        print("Renamed " + fileIn + " ---> " + fileOut)\n\n        i += 1\n\nmain()\n']], ['renaming pcraster mapstack'], 2, 1], [(34837194, 1), [['You can run it from the command line, using the prefix of your map stack and the number of the first output map as arguments, e.g.:'], ['Please note that the script renames the files in place, so make sure to make a copy of your original map stack in case something goes wrong (I only did some  very  limited testing on this!).']], [[' python renpcrmaps.py precip 1\n']], ['renaming pcraster mapstack'], 2, 0], [(34845096, 0), [['Assume values stored row-by-row in list, like that:'], ['To sort this array you can use following code:']], [[" a = [['D', 'C', 'B', 'A'],\n     ['1', '3', '2', '0'],\n     ['1', '3', '2', '0']]\n"]], ['How can I sort a 2D list?'], 3, 0], [(34845096, 2), [['Output:'], ['Note :\nIf you are working with pretty big arrays and execution time does matter, consider using numpy, it has appropriate method:  NumPy sort']], [[" [('A', 'B', 'C', 'D'),\n ('0', '2', '3', '1'),\n ('0', '2', '3', '1')]\n"]], ['How can I sort a 2D list?'], 3, 0], [(34859683, 0), [['Starting with a  dict  of two names and 10 different  links  each:'], ['You could create a  DataFrame   .from_dict() ,  .stack() , and clean up the  index :']], [[" d = {'Name 1': ['link{}'.format(l) for l in list(range(10))], 'Name 2': ['link{}'.format(l) for l in list(range(10, 20))]}\n\n{'Name 1': ['link0', 'link1', 'link2', 'link3', 'link4', 'link5', 'link6', 'link7', 'link8', 'link9'], 'Name 2': ['link10', 'link11', 'link12', 'link13', 'link14', 'link15', 'link16', 'link17', 'link18', 'link19']}\n"]], ['Reorder a dictionary to fit a data frame'], 3, 0], [(34859683, 1), [['You could create a  DataFrame   .from_dict() ,  .stack() , and clean up the  index :'], ['to get: ']], [[" df = pd.DataFrame.from_dict(d, orient='index').stack().reset_index(1, drop=True).to_frame().reset_index()\ndf.columns = ['name', 'link']\n"]], ['Reorder a dictionary to fit a data frame'], 3, 1], [(34859683, 2), [['to get: '], ['-10000']], [['       name    link\n0   Name 1   link0\n1   Name 1   link1\n2   Name 1   link2\n3   Name 1   link3\n4   Name 1   link4\n5   Name 1   link5\n6   Name 1   link6\n7   Name 1   link7\n8   Name 1   link8\n9   Name 1   link9\n10  Name 2  link10\n11  Name 2  link11\n12  Name 2  link12\n13  Name 2  link13\n14  Name 2  link14\n15  Name 2  link15\n16  Name 2  link16\n17  Name 2  link17\n18  Name 2  link18\n19  Name 2  link19\n']], ['Reorder a dictionary to fit a data frame'], 3, 0], [(34871024, 0), [['It may be easier to just combine the storage into a dictionary within your own class ...'], ['Then, use one function ...']], [[" self.storage = {'key_A':[], 'key_B':[]}\n"]], ['Combine methods with identical structure but different parameters'], 2, 0], [(34871024, 1), [['Then, use one function ...'], ['-10000']], [[" def method(self, key):\n    some_list = list(irrelevant_extraction_function(key, self.some_dict))\n    self.storage[key] = [item['address'] for item in some_list]\n"]], ['Combine methods with identical structure but different parameters'], 2, 0], [(34906231, 0), [['your client (web browser) expects one string as response:'], ['or use JSON for the response:']], [[' return HttpResponse("a string: {}".format(val))\n']], ['How to return both string and value within HttpResponse?'], 3, 1], [(34906231, 1), [['or use JSON for the response:'], ['or, to send a variable to the next Django view:']], [[" return JsonResponse({'message': 'a string', 'val': val})\n"]], ['How to return both string and value within HttpResponse?'], 3, 1], [(34906231, 2), [['or, to send a variable to the next Django view:'], ['More about Django session here.']], [[" def my_view(request):\n    if request.session.get('val', None):\n        # do something with the 'val' variable.\n    else:\n        request.session['val'] = 'somevalue'\n        return HttpResponse('some message')\n"]], ['How to return both string and value within HttpResponse?'], 3, 1], [(34906286, 0), [["But from the code you posted, it looks like you don't really need to group, you just want to count, right? Then you may better use  collections.Counter . Note that it requires the items to be hashable so you'd want to convert those lists into tuples."], ['About the averages, if you really want to use  groupby  then you could do something like this:']], [[" >>> lst = [tuple(i) for i in ls]\n>>> collections.Counter(lst)\nCounter({('A', 4): 2, ('F', 3): 1, ('B', 1): 1, ('B', 4): 1})\n"]], ['Groupby in a list for python'], 2, 0], [(34910228, 1), [['and when using it in the class:'], ['Do the same for  frenchman() .']], [[' enemies.knightofni(self)\n']], ["Change object's variable from different file"], 5, 0], [(34910228, 2), [['Do the same for  frenchman() .'], ['and  enemies.py :']], [[' import enemies\n\nclass Encounter:\n    def __init__(self):\n        self.counter = 1\n        self.number = 0\n        self.who = "We\'ve encountered no one."\n\n    def forward(self):\n        if self.counter == 1:\n            enemies.knightofni(self)\n        elif self.counter == 2:\n            enemies.frenchman(self)\n        else:\n            self.number = 42\n            self.who = "We\'ve found the Grail!"\n        self.counter += 1\n\nknight = Encounter()\nfor i in range(4):\n    print(str(knight.number) + " " + knight.who)\n    knight.forward()\n']], ["Change object's variable from different file"], 5, 0], [(34910228, 3), [['and  enemies.py :'], ['Output:']], [[' def knightofni(obj):\n    obj.number = 1\n    obj.who = "We\'ve encountered Knight of Ni."\n\ndef frenchman(obj):\n    obj.number = 4\n    obj.who = "We\'ve encountered French."\n']], ["Change object's variable from different file"], 5, 0], [(34910228, 4), [['Output:'], ['-10000']], [[" 0 We've encountered no one.\n1 We've encountered Knight of Ni.\n4 We've encountered French.\n42 We've found the Grail!\n"]], ["Change object's variable from different file"], 5, 0], [(34914655, 0), [['If a  boost::python::object  references a type, then invoking it will construct an object with the referenced type:'], ['The following  type_object  C++ type represents a Python object that is a  Py_TYPE .']], [[' boost::python::object type = /* Py_TYPE */;\nboost::python::object object = type(); // isinstance(object, type) == True\n']], ['Python C API - How to construct object from PyObject'], 5, 0], [(34914655, 1), [['The following  type_object  C++ type represents a Python object that is a  Py_TYPE .'], ['The following custom converter will only construct a  type_object  instance if it is provided a  PyObject*  that is a  Py_TYPE :']], [[' /// @brief boost::python::object that refers to a type.\nstruct type_object: \n  public boost::python::object\n{\n  /// @brief If the object is a type, then refer to it.  Otherwise,\n  ///        refer to the instance\'s type.\n  explicit\n  type_object(boost::python::object object):\n    boost::python::object(object)\n  {\n    if (!PyType_Check(object.ptr()))\n    {\n      throw std::invalid_argument("type_object requires a Python type");\n    }\n  }\n};\n\n...\n\n// Only accepts a Python type.\nvoid add_component(type_object type) { ... }\n']], ['Python C API - How to construct object from PyObject'], 5, 0], [(34914655, 4), [['Interactive usage:'], ['-10000']], [[' >>> import example\n>>> game = example.GameObject()\n>>> component = game.add_component(example.CameraComponent)\nCameraComponent()\n>>> assert(isinstance(component, example.CameraComponent))\n>>> try:\n...     game.add_component(component) # throws Boost.Python.ArgumentError\n...     assert(False)\n... except TypeError:\n...     assert(True)\n...\n']], ['Python C API - How to construct object from PyObject'], 5, 0], [(34929717, 0), [['You can select them by building an appropriate Series and then using it to index into  df :'], ['and then']], [[' >>> df < 0\n    fld1   fld2   fld3   fld4   fld5   fld6   fld7\n0  False  False   True  False  False  False  False\n1  False  False  False  False  False   True  False\n2  False  False  False  False  False  False  False\n3   True   True  False  False  False  False  False\n4  False  False  False  False  False  False  False\n5   True  False  False  False  False  False  False\n6  False  False   True  False  False  False  False\n7  False  False  False  False  False  False  False\n8  False  False  False  False  False   True  False\n9  False  False  False  False  False  False  False\n>>> (df < 0).any()\nfld1     True\nfld2     True\nfld3     True\nfld4    False\nfld5    False\nfld6     True\nfld7    False\ndtype: bool\n']], ['Get list of column names for columns that contain negative values'], 4, 0], [(34930630, 0), [["You can use  nargs=4  with an  'append'  action:"], ["It'd be called as:"]], [[" import argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--group', nargs=4, action='append')\n\nprint parser.parse_args()\n"]], ['grouping an unknown number of arguments with argparse'], 3, 1], [(34930630, 1), [["It'd be called as:"], ["Another option is to use a custom action to do the parsing -- Here's a simple one which accepts arguments of the form  --group key:value key2:value2 ... --group ..."]], [[" $ python ~/sandbox/test.py --group 1 2 3 4 --group 1 2 3 4\nNamespace(group=[['1', '2', '3', '4'], ['1', '2', '3', '4']])\n"]], ['grouping an unknown number of arguments with argparse'], 3, 0], [(34930630, 2), [["Another option is to use a custom action to do the parsing -- Here's a simple one which accepts arguments of the form  --group key:value key2:value2 ... --group ..."], ["This has no checking (so the user could get funny  TypeError s if the  key:value  are not formatted properly) and if you want to restrict it to specified keys, you'll need to build that in as well... but those details should be easy enough to add.  You could also require that they provide 4 values using  self.nargs = 4  in  DictAction.__init__ ."]], [[" import argparse\n\nclass DictAction(argparse.Action):\n    def __init__(self, *args, **kwargs):\n        super(DictAction, self).__init__(*args, **kwargs)\n        self.nargs = '*'\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        # The default value is often set to `None` rather than an empty list.\n        current_arg_vals = getattr(namespace, self.dest, []) or []\n        setattr(namespace, self.dest, current_arg_vals)\n        arg_vals = getattr(namespace, self.dest)\n        arg_vals.append(dict(v.split(':') for v in values))\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--group', action=DictAction)\n\nprint parser.parse_args()\n"]], ['grouping an unknown number of arguments with argparse'], 3, 1], [(34931548, 0), [['To make a column which is a running count which resets each year, you could use groupby/cumcount:'], ['-10000']], [[" df['C'] = df.groupby(df.index.year).cumcount(1)+1\n"]], ["How to get the 'cardinal' day of the year in Pandas?"], 3, 1], [(34931548, 1), [['-10000'], ['yields']], [[" df = pd.DataFrame({\n    'Close': [16.66, 16.85, 16.93, 16.98, 17.08, 17.03, 17.09, 16.76, 16.67, 16.71, 20],\n    'Date': ['1950-01-03', '1950-01-04', '1950-01-05', '1950-01-06', '1950-01-09', \n             '1950-01-10', '1950-01-11', '1950-01-12', '1950-01-13', '1950-01-16',\n             '1951-01-01'], })\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.set_index('Date')\n\ndf['O'] = df.index.day\ndf['C'] = df.groupby(df.index.year).cumcount(1)+1\n"]], ["How to get the 'cardinal' day of the year in Pandas?"], 3, 1], [(34931548, 2), [['yields'], ['-10000']], [['             Close   O   C\nDate                     \n1950-01-03  16.66   3   1\n1950-01-04  16.85   4   2\n1950-01-05  16.93   5   3\n1950-01-06  16.98   6   4\n1950-01-09  17.08   9   5\n1950-01-10  17.03  10   6\n1950-01-11  17.09  11   7\n1950-01-12  16.76  12   8\n1950-01-13  16.67  13   9\n1950-01-16  16.71  16  10\n1951-01-01  20.00   1   1\n']], ["How to get the 'cardinal' day of the year in Pandas?"], 3, 0], [(34936864, 0), [['If you just want to remove all instances of square brackets from a string, you can do the following:'], ['-10000']], [[' s = "[[ hello] [there]]"\ns = s.replace("[", "")\ns = s.replace("]", "")\n']], ['Remove double and single square brackets from text file generated from python'], 2, 1], [(34936864, 1), [['-10000'], ['-10000']], [[' with open(\'/path/to/my_file.txt\', \'r\') as my_file:\n    text = my_file.read()\n    text = text.replace("[", "")\n    text = text.replace("]", "")\n\n# If you wish to save the updates back into a cleaned up file\nwith open(\'/path/to/my_file_clean.txt\', \'w\') as my_file:\n    my_file.write(text)\n']], ['Remove double and single square brackets from text file generated from python'], 2, 1], [(34950064, 0), [['So you could do:'], ['Output']], [[" x = '20.06.2009 05:00:00        2.6'\ny = '20.06.2009 06:00:00       21.5'\nitems = [x, y]\n\nvalue = 0\nfor item in items:\n    value += float(item.rsplit(' ', 1)[1])\n\nprint(value)\n"]], ['String slicing with delimiter changing in length'], 2, 1], [(34950064, 1), [['Output'], ['-10000']], [[' 24.1\n']], ['String slicing with delimiter changing in length'], 2, 0], [(34959948, 0), [['You can locate the start of the JSON by checking the presence of  {  or  [  and then save everything to the end of the string into a capturing group:'], ["Or, you may use  re.split()  to split the string by a space followed by a  {  or  [  (with a positive look ahead) and get the last item. It works for the sample input you've provided, but not sure if this is reliable in general:"]], [[' >>> import re\n>>> string1 = \'bob1: The ceo of the company {"salary": 100000}\'\n>>> string2 = \'bob1: The ceo of the company ["10001", "10002"]\'\n>>> \n>>> re.search(r"\\s([{\\[].*?[}\\]])$", string1).group(1)\n\'{"salary": 100000}\'\n>>> re.search(r"\\s([{\\[].*?[}\\]])$", string2).group(1)\n\'["10001", "10002"]\'\n']], ['Parse valid JSON object or array from a string'], 2, 1], [(34959948, 1), [["Or, you may use  re.split()  to split the string by a space followed by a  {  or  [  (with a positive look ahead) and get the last item. It works for the sample input you've provided, but not sure if this is reliable in general:"], ['-10000']], [[' >>> re.split(r"\\s(?=[{\\[])", string1)[-1]\n\'{"salary": 100000}\'\n>>> re.split(r"\\s(?=[{\\[])", string2)[-1]\n\'["10001", "10002"]\'\n']], ['Parse valid JSON object or array from a string'], 2, 1], [(34970283, 0), [['You can sort it twice (Python uses a stable sort that performs well on already-sorted portions):'], ['Or you can use  ord()  to get an integer and negate it:']], [[" >>> l = [ ['a','b'], ['x','y'], ['a','y'], ['x', 'b'] ]\n>>> sorted(sorted(l, key=lambda x: x[1]), key=lambda x: x[0], reverse=True)\n[['x', 'b'], ['x', 'y'], ['a', 'b'], ['a', 'y']]\n"]], ['What is the pythonic way to sort a list with multiple attributes, such that the first is sorted reversely but the second is not?'], 2, 1], [(34970283, 1), [['Or you can use  ord()  to get an integer and negate it:'], ['-10000']], [[" >>> l = [ ['a','b'], ['x','y'], ['a','y'], ['x', 'b'] ]\n>>> sorted(l, key=lambda x: (-ord(x[0]), x[1]))\n[['x', 'b'], ['x', 'y'], ['a', 'b'], ['a', 'y']]\n"]], ['What is the pythonic way to sort a list with multiple attributes, such that the first is sorted reversely but the second is not?'], 2, 1], [(34977252, 0), [['numba version: 0.23.1'], ['I see similar results for python 2.7.11 and numba 0.23']], [[' import numba as nb\nimport numpy as np\n\ndef neumann_laplacian_1d(u,dx2):\n    """Return finite difference Laplacian approximation of 2d array.\n    Uses Neumann boundary conditions and a 2nd order approximation.\n    """\n    laplacian = np.zeros(u.shape)\n    laplacian[1:-1] =  ((1.0)*u[2:] \n                       +(1.0)*u[:-2]\n                       -(2.0)*u[1:-1])\n    # Neumann boundary conditions\n    # edges\n    laplacian[0]  =  ((2.0)*u[1]-(2.0)*u[0])\n    laplacian[-1] =  ((2.0)*u[-2]-(2.0)*u[-1])\n\n    return laplacian/ dx2\n\n@nb.autojit(nopython=True)\ndef neumann_laplacian_1d_numba(u,dx2):\n    """Return finite difference Laplacian approximation of 2d array.\n    Uses Neumann boundary conditions and a 2nd order approximation.\n    """\n    laplacian = np.zeros(u.shape)\n    laplacian[1:-1] =  ((1.0)*u[2:] \n                       +(1.0)*u[:-2]\n                       -(2.0)*u[1:-1])\n    # Neumann boundary conditions\n    # edges\n    laplacian[0]  =  ((2.0)*u[1]-(2.0)*u[0])\n    laplacian[-1] =  ((2.0)*u[-2]-(2.0)*u[-1])\n\n    return laplacian/ dx2\n\na = np.random.random(252)\n#run once to make the JIT do it\'s work before timing\nneumann_laplacian_1d_numba(a, 1.0)\n\n\n%timeit neumann_laplacian_1d(a, 1.0)\n%timeit neumann_laplacian_1d_numba(a, 1.0)\n\n>>10000 loops, best of 3: 21.5 µs per loop\n>>The slowest run took 4.49 times longer than the fastest. This could mean that an intermediate result is being cached \n>>100000 loops, best of 3: 3.53 µs per loop\n']], ['Using Numba to improve finite-differences laplacian'], 2, 1], [(34977252, 1), [['I see similar results for python 2.7.11 and numba 0.23'], ['-10000']], [[' >>100000 loops, best of 3: 19.1 µs per loop\n>>The slowest run took 8.55 times longer than the fastest. This could mean that an intermediate result is being cached \n>>100000 loops, best of 3: 2.4 µs per loop\n']], ['Using Numba to improve finite-differences laplacian'], 2, 0], [(34980059, 0), [['here is a working code:'], ['For your example:']], [[' numbers = [1,3,7,11,25,36,57,678,999]\ncount = sum([numbers[i] == numbers[i+1] for i in range(len(numbers)-1)])\n>>> count\n8\n']], ['Difference of elements to find same adjacent'], 2, 1], [(34982928, 1), [['which works because we have'], ['and so']], [[' >>> df.groupby("Category")["Boolean"].all()\nCategory\nA    False\nB    False\nC     True\nD     True\nName: Boolean, dtype: bool\n']], ['Return rows only if all items of category are True'], 3, 0], [(35011168, 0), [['Call the base version via  super() :'], ['However, consider using a  property  instead of intercepting  all  attribute setting:']], [[' class MyClass(object):\n    myattrib = None\n\n    def __setattr__(self, prop, val):\n        super().__setattr__(\'myattrib\', val)\n        print("setting myattrib")\n']], ['How to call __setattr__() correctly in Python3 as part of a class?'], 2, 1], [(35011168, 1), [['However, consider using a  property  instead of intercepting  all  attribute setting:'], ['I added  object  as a base-class; this is the default in Python 3, but a requirement for  super()  and  property  objects to work in Python 2.']], [[' class MyClass(object):\n    _myattrib = None\n\n    @property:\n    def myattrib(self):\n        return self._myattrib\n\n    @myattrib.setter\n    def myattrib(self, val):\n        self._myattrib = val\n        print("setting myattrib")\n']], ['How to call __setattr__() correctly in Python3 as part of a class?'], 2, 1], [(35020513, 0), [['You could use  extract  to remove the  em  tag as follows:'], ['This would display:']], [[' from bs4 import BeautifulSoup\n\nhtml = """<div class=\'div_name_class\'>\n<p>\n   <span class=\'class_name_1\' title=\'title1\'>val1</span>\n   <span class=\'class_name_1\' title=\'title2\'>val2</span>\n</p>\n<p><span class=\'class_name_2\'><em>text of no interest</em></span>text of interest</p>"""\n\nsoup = BeautifulSoup(html)\np = soup.find(\'span\', attrs={\'class\': \'class_name_2\'}).parent\np.span.em.extract()\nprint p.text\n']], ['Python & Beautifulsoup web scraping - select a paragraph with a specific child tag'], 2, 1], [(35020513, 1), [['This would display:'], ['-10000']], [[' text of interest\n']], ['Python & Beautifulsoup web scraping - select a paragraph with a specific child tag'], 2, 0], [(35025400, 0), [['You can use the key argument of  sorted  function:'], ['Result:']], [[" filenames = [\n    '1.0.0.0.py',\n    '0.0.0.0.py',\n    '1.1.0.0.py'\n]\n\nprint sorted(filenames, key=lambda f: map(int, f.split('.')[:-1]))\n"]], ['Sort list with multiple criteria in python'], 2, 1], [(35025400, 1), [['Result:'], ['The lambda splits the filename into parts, removes the last part and converts the remaining ones into integers. Then  sorted  uses this value as the sorting criterion.']], [[" ['0.0.0.0.py', '1.0.0.0.py', '1.1.0.0.py']\n"]], ['Sort list with multiple criteria in python'], 2, 0], [(35061363, 0), [['You could do this in Python as follows. This will take all the  xlsx  files from a single folder and write them using the same name in  xls  format:'], ['To do this on a whole directory structure, you could use  os.walk  as follows:']], [[" import win32com.client as win32\nimport glob\nimport os\n\nexcel = win32.gencache.EnsureDispatch('Excel.Application')\n\nfor excel_filename in glob.glob(r'c:\\excel_files_folder\\*.xlsx'):\n    print excel_filename\n    wb = excel.Workbooks.Open(excel_filename)\n    wb.SaveAs(os.path.splitext(excel_filename)[0] + '.xls', FileFormat=56, ConflictResolution=2) \n\nexcel.Application.Quit()\n"]], ['convert xlsx files to xls inside folders and subfolders in Excel VBA or Python'], 2, 1], [(35061363, 1), [['To do this on a whole directory structure, you could use  os.walk  as follows:'], ['-10000']], [[" import win32com.client as win32\nimport os\n\nexcel = win32.gencache.EnsureDispatch('Excel.Application')\n\nfor dirpath, dirnames, filenames in os.walk(r'c:\\excel_files_folder'):\n    for filename in filenames:\n        name, ext = os.path.splitext(filename)\n        if ext == '.xlsx':\n            wb = excel.Workbooks.Open(os.path.join(dirpath, filename))\n            wb.DoNotPromptForConvert = True\n            wb.CheckCompatibility = False\n            excel.DisplayAlerts = False\n            wb.SaveAs(os.path.join(dirpath, name + '.xls'), FileFormat=56, ConflictResolution=2) \n\nexcel.Application.Quit()\n"]], ['convert xlsx files to xls inside folders and subfolders in Excel VBA or Python'], 2, 1], [(35083540, 0), [["Anyway, here's a way to make a dictionary that handles both converting a bitstring to a character and vice versa. I just loop over  range(65, 70)  to keep the output small."], ['output']], [[' from pprint import pprint\n\nbinary2ascii = {}\nfor i in range(65, 70):\n    bits = format(i, "08b")\n    char = chr(i)\n    binary2ascii[bits] = char\n    binary2ascii[char] = bits\n\npprint(binary2ascii)    \n']], ['Using a loop to make a dictionary'], 2, 1], [(35083540, 1), [['output'], ['-10000']], [[" {'01000001': 'A',\n '01000010': 'B',\n '01000011': 'C',\n '01000100': 'D',\n '01000101': 'E',\n 'A': '01000001',\n 'B': '01000010',\n 'C': '01000011',\n 'D': '01000100',\n 'E': '01000101'}\n"]], ['Using a loop to make a dictionary'], 2, 0], [(35104102, 0), [["Here's a basic example:"], ['Or using the csv module (which is more flexible for different types of CSV formatting):']], [[' num_headers = 5\nwith open("input.csv", \'r\') as file_in, open("output.csv", \'w\') as file_out:\n    for i, line in enumerate(file_in):\n        if len(line.split(",")) == num_headers:\n            file_out.write(line)\n        else:\n            print "line %d is malformed" % i\n']], ['eliminate malformed records from a large .csv file'], 2, 1], [(35104102, 1), [['Or using the csv module (which is more flexible for different types of CSV formatting):'], ['-10000']], [[' import csv\nnum_headers = 5\nwith open("input.csv", \'r\') as file_in, open("output.csv", \'w\') as file_out:\n    csv_in = csv.reader(file_in)\n    csv_out = csv.writer(file_out)\n    for i, row in enumerate(csv_in):\n        if len(row) == num_headers:\n            csv_out.writerow(row)\n        else:\n            print "line %d is malformed" % i\n']], ['eliminate malformed records from a large .csv file'], 2, 1], [(35108136, 0), [['You could use a mixin to achieve something similar.'], ["Edit: a different mixin, which feels bit hacky, but closer to what you want. I haven't tested it, but I think it should work."]], [[" class ContextMixin:\n    extra_context = {}\n\n    def get_context_data(self, **kwargs):\n        context = super(ContextMixin, self).get_context_data(**kwargs)\n        context.update(self.extra_context)\n        return context \n\nclass FooUpdate(ContextMixin, UpdateView):\n    model = Foo\n    extra_context={'page_title': 'foo-objects name should go here'}\n"]], ['Get object attribute in class based view'], 2, 1], [(35108136, 1), [["Edit: a different mixin, which feels bit hacky, but closer to what you want. I haven't tested it, but I think it should work."], ['-10000']], [[" class AutoContextMixin:\n\n    def get_context_data(self, **kwargs):\n        context = super(AutoContextMixin, self).get_context_data(**kwargs)\n        for key in dir(self):\n            value = getattr(self, key)\n            if isinstance(value, str) and not key.startswith('_'):\n                context[key] = value\n        return context \n\nclass FooUpdate(AutoContextMixin, UpdateView):\n    model = Foo\n    page_title = 'foo-objects name should go here'\n"]], ['Get object attribute in class based view'], 2, 1], [(35115138, 1), [['then'], ['-10000']], [[' is_subnet_of("10.11.12.0/24", "10.11.0.0/16")   # => True\n']], ['How do I check if a network is contained in another network in Python?'], 2, 0], [(35119291, 0), [['Also, this directly modifies  list0  , so feel free to change the references to  list1  if you wish.'], ['Outputs']], [[' list0 = ["text","text","","","text","","text","text","","text"]\n\n# Find the "gap" - the first consectutive empty strings\n# gap_pos remains 0 if no gap is found\ngap_pos = 0\ngap_size = 2\nfor i in range(len(list0)-gap_size):\n    if all(x == \'\' for x in  list0[i:i+gap_size]):\n        gap_pos = i+1\n        break # remove this if you want the last gap\n\n# Find the non-empty strings that are detected after the gap\nafter_gap = filter(lambda x : x != \'\', list0[gap_pos+1:])\n\n# allocate this group starting at a specific index (e.g. index 5)\nspecific_index = 5\nfor i in range(len(after_gap)):\n    allocate_at = i + specific_index\n    # Make sure not to go out-of-bounds\n    if allocate_at < len(list0):\n        list0[allocate_at] = after_gap[i]\n']], ['find an empty value gap in a list and allocate a group of strings'], 2, 1], [(35119291, 1), [['Outputs'], ['-10000']], [[" ['text', 'text', '', '', 'text', 'text', 'text', 'text', 'text', 'text']\n"]], ['find an empty value gap in a list and allocate a group of strings'], 2, 0], [(35153942, 1), [['3) Run the below command from your machine.'], ['You can find more details in App Engine documentation -  Management commands  and  Alternate development database and settings .']], [[' $ SETTINGS_MODE=prod python manage.py migrate\n']], ['How to run Django management commands against Google Cloud SQL'], 2, 0], [(35159791, 0), [['Check the following code:  '], ['If youn want to use 2 Toplevel windows for login and main app,  root window  should be hidden:  ']], [[' from Tkinter import *\n\n\nclass loginWindow(Toplevel):\n    def __init__(self, title, parent):\n        Toplevel.__init__(self, parent)\n        # Save parent reference to use it \n        self.parent = parent\n        self.parent.title(u"Geometry Calc - Login")\n        Button(self, text="Login", command=self.login).pack()\n\n    def login(self):\n\n        access =  True # Used to test if a user can login.\n\n        if access:\n            # Close Toplevel window and show root window\n            self.destroy()\n            self.parent.deiconify()\n        else:\n            self.parent.quit()\n\n\n\nclass main(Tk):\n    def __init__(self, *args, **kwargs):\n        Tk.__init__(self, *args, **kwargs)\n        self.title(u"Geometry Calc")  # Nadpis\n        self.geometry("695x935")  # Rozmery v px\n        self.config(background="white")\n        self.resizable(width=FALSE, height=FALSE)  # Zakážeme změnu rozměrů uživatelem - zatím..\n\n        menubar = Menu(self)\n\n        helpmenu = Menu(menubar, tearoff=0)\n        helpmenu.add_command(label="Konec", command=self.quit)\n        menubar.add_cascade(label="Soubor", menu=helpmenu)\n        helpmenu = Menu(menubar, tearoff=0)\n        helpmenu.add_command(label="O programu", command=self.createAbout)\n        menubar.add_cascade(label="Pomoc", menu=helpmenu)\n        self.config(menu=menubar)\n\n        canvas = Canvas(self, width=691, height=900)\n        canvas.pack(expand=1, fill=BOTH)\n\n        # Hide root window\n        self.withdraw()\n\n        #\xa0Lunch login window\n        loginWindow(\'Frame\', self)\n\n\n    def createAbout(self):\n        pass\n\n    def quit(self):\n        self.destroy()\n\n\n\napp = main()\n\napp.mainloop()\n']], ['Two windows: First Login after that main program'], 2, 1], [(35159791, 1), [['If youn want to use 2 Toplevel windows for login and main app,  root window  should be hidden:  '], ['-10000']], [[" class loginWindow(Toplevel):\n    def __init__(self, title, parent):\n        Toplevel.__init__(self, parent)\n        ...\n\n    def login(self):\n       if access:\n            # Close Toplevel window and lunch root window\n            self.destroy()\n            main()\n\n\n\nclass main(Toplevel):\n    def __init__(self, *args, **kwargs):\n        Toplevel.__init__(self, *args, **kwargs)\n        ...\n\n\n\nroot = Tk()\nroot.withdraw()\n\nloginWindow('title', root)\n\nroot.mainloop()  \n"]], ['Two windows: First Login after that main program'], 2, 1], [(35164333, 0), [['A numpy solution could be :'], ['Which seems significantly faster than the python way :']], [[' X,Y = np.meshgrid(np.arange(0,100), np.arange(0,100))\nresult = np.vstack((Y.ravel(), X.ravel())).T\nresult\n# array([[ 0,  0],\n#        [ 0,  1],\n#        [ 0,  2],\n#           ..., \n']], ['Efficient way of creating a permutated 2D array with a range of integers'], 2, 1], [(35197854, 1), [['Otherwise, you can create a copy of params with  built-in locals()  at function start and  return  that copy:'], ['-10000']], [[" def generate_student_dict(first_name=None, last_name=None , birthday=None, gender =None):\n     # It's important to copy locals in first line of code (see @MuhammadTahir comment).\n     args_passed = locals().copy()\n     # some code\n     return args_passed\n\ngenerate_student_dict()\n"]], ['Python keyword arguments unpack and return dictionary'], 2, 1], [(35199556, 0), [['That is, unless you hook into the echoing mechanism. You can do so with overriding the  __repr__  method :'], ['Demo:']], [[' class EvaluatingName(object):\n    def __init__(self, callable):\n        self._callable = callable\n    def __call__(self):\n        return self._callable()\n    def __repr__(self):\n        return repr(self())\n\nls = EvaluatingName(os.getcwd)\n']], ['call function through variable or without parentheses in python'], 4, 1], [(35199556, 1), [['Demo:'], ['This will work:']], [[" >>> import os\n>>> class EvaluatingName(object):\n...     def __init__(self, callable):\n...         self._callable = callable\n...     def __call__(self):\n...         return self._callable()\n...     def __repr__(self):\n...         return repr(self())\n...\n>>> ls = EvaluatingName(os.getcwd)\n>>> os.chdir('/')\n>>> ls\n'/'\n>>> os.chdir('/tmp')\n>>> ls\n'/private/tmp'\n"]], ['call function through variable or without parentheses in python'], 4, 1], [(35199556, 2), [['This will work:'], ['but this  will not :']], [[" os.path.join(ls(), 'foo.txt')  # produce the value first\n"]], ['call function through variable or without parentheses in python'], 4, 0], [(35199556, 3), [['but this  will not :'], ['-10000']], [[" os.path.join(ls, 'foo.txt')    # throws an AttributeError.\n"]], ['call function through variable or without parentheses in python'], 4, 0], [(35205400, 0), [['you have four forced choices, then two free choices.  set  is a good help here.'], ['10 samples :']], [[' from random import choice\na = [1,2,3]\nb = [9]\nc = [5,6]\nd = [11,12,4]\n\nl=a+b+c+d #ordered candidates\n\ndef select():\n    e=set(l)\n    for s in (a,b,c,d,e,e):              # 4 forced choices and 2 frees.\n        e.remove(choice(tuple(s)))       # sets have no index.\n    return [x for x in l if x not in e]\n']], ['How to randomly pick numbers from ranked groups in python, to create a list of specific length'], 2, 1], [(35205400, 1), [['10 samples :'], ['-10000']], [[' >>> for _ in range(10) : print (select())\n[1, 9, 5, 11, 12, 4]\n[1, 3, 9, 6, 11, 4]\n[1, 3, 9, 5, 6, 12]\n[1, 2, 9, 6, 11, 4]\n[1, 2, 9, 5, 6, 4]\n[2, 9, 5, 6, 11, 4]\n[1, 2, 9, 5, 11, 12]\n[1, 3, 9, 6, 11, 12]\n[3, 9, 6, 11, 12, 4]\n[1, 2, 9, 5, 12, 4]\n']], ['How to randomly pick numbers from ranked groups in python, to create a list of specific length'], 2, 0], [(35208832, 0), [['The way to do this is to use the (currently experimental, but available in the next release)  tf.cond() * operator. This operator is able to test a value computed at runtime, and execute one of two branches based on that value.'], ["*\xa0 To access the operator in the current released version, you'll need to import the following:"]], [[' shape = tf.shape(image)\nheight = shape[0]\nwidth = shape[1]\nnew_shorter_edge = 400\nheight_smaller_than_width = tf.less_equal(height, width)\n\nnew_shorter_edge = tf.constant(400)\nnew_height, new_width = tf.cond(\n    height_smaller_than_width,\n    lambda: new_shorter_edge, (width / height) * new_shorter_edge,\n    lambda: new_shorter_edge, (height / width) * new_shorter_edge)\n']], ['TensorFlow Resize image tensor to dynamic shape'], 2, 1], [(35208832, 1), [["*\xa0 To access the operator in the current released version, you'll need to import the following:"], ['...and then use  control_flow_ops.cond()  instead of  tf.cond() .']], [[' from tensorflow.python.ops import control_flow_ops\n']], ['TensorFlow Resize image tensor to dynamic shape'], 2, 0], [(35208997, 0), [['First you should make a function to get your visually selected text. I brought it from  https://stackoverflow.com/a/6271254/3108885 :'], ['Then, add an  autocmd  for Visual mode.']], [[' function! s:GetVisualSelection()\n  let [lnum1, col1] = getpos("\'<")[1:2]\n  let [lnum2, col2] = getpos("\'>")[1:2]\n  let lines = getline(lnum1, lnum2)\n  let lines[-1] = lines[-1][:col2 - (&selection == \'inclusive\' ? 1 : 2)]\n  let lines[0] = lines[0][col1 - 1:]\n  return join(lines, "\\n")\nendfunction\n']], ['Running blocks of code inside vim'], 2, 0], [(35208997, 1), [['Then, add an  autocmd  for Visual mode.'], ["Note that  <C-U>  is for cleaning  '<,'>  things when  :  is pressed on Visual mode. Also we use  python -c  to pass a program as a string."]], [[" autocmd FileType python vnoremap <buffer> <F9> :<C-U>exec '!clear; python -c' shellescape(<SID>GetVisualSelection(), 1)<CR>\n"]], ['Running blocks of code inside vim'], 2, 0], [(35209114, 0), [["I don't know if it is  faster  but this is easier to read (to me anyway):"], ['-10000']], [[' sets={frozenset(e) for e in fruits}  \nus=set()\nwhile sets:\n    e=sets.pop()\n    if any(e.issubset(s) for s in sets) or any(e.issubset(s) for s in us):\n        continue\n    else:\n        us.add(e)   \n']], ['Fastest way to remove subsets of lists from a list in Python'], 3, 1], [(35209114, 1), [['-10000'], ['On my machine on Python 2.7:']], [[' fruits = [[\'apple\', \'pear\'],\n        [\'apple\', \'pear\', \'banana\'],\n        [\'banana\', \'pear\'],\n        [\'pear\', \'pineapple\'],\n        [\'apple\', \'pear\', \'banana\', \'watermelon\']]\n\nfrom itertools import imap, ifilter, compress    \n\ndef f1():              \n    sets={frozenset(e) for e in fruits}  \n    us=[]\n    while sets:\n        e=sets.pop()\n        if any(e.issubset(s) for s in sets) or any(e.issubset(s) for s in us):\n            continue\n        else:\n            us.append(list(e))   \n    return us           \n\ndef f2():\n    supersets = imap(lambda a: list(ifilter(lambda x: len(a) < len(x) and set(a).issubset(x), fruits)), fruits)\n    new_list = list(compress(fruits, imap(lambda x: 0 if x else 1, supersets)))\n    return new_list\n\ndef f3():\n    return filter(lambda f: not any(set(f) < set(g) for g in fruits), fruits)\n\ndef f4():              \n    sets={frozenset(e) for e in fruits}  \n    us=[]\n    for e in sets:\n        if any(e < s for s in sets):\n            continue\n        else:\n            us.append(list(e))   \n    return us              \n\nif __name__==\'__main__\':\n    import timeit     \n    for f in (f1, f2, f3, f4):\n        print f.__name__, timeit.timeit("f()", setup="from __main__ import f, fruits"), f()  \n']], ['Fastest way to remove subsets of lists from a list in Python'], 3, 1], [(35209114, 2), [['On my machine on Python 2.7:'], ['-10000']], [[" f1 8.09958791733 [['watermelon', 'pear', 'apple', 'banana'], ['pear', 'pineapple']]\nf2 15.5085151196 [['pear', 'pineapple'], ['apple', 'pear', 'banana', 'watermelon']]\nf3 11.9473619461 [['pear', 'pineapple'], ['apple', 'pear', 'banana', 'watermelon']]\nf4 5.87942910194 [['watermelon', 'pear', 'apple', 'banana'], ['pear', 'pineapple']]\n"]], ['Fastest way to remove subsets of lists from a list in Python'], 3, 0], [(35220031, 0), [['How many such strings are there?  It might be quickest to define them by hand yourself:'], ['Or you could put them in a  dict .  I put them in static attributes of a  class  because it\'s about the neatest way of letting you refer to them in a way that "feels like"  enum  constants:']], [[' class MaxVal:\n    SI8  = 2 ** 7  - 1\n    UI8  = 2 ** 8  - 1\n    SI16 = 2 ** 15 - 1\n    UI16 = 2 ** 16 - 1\n    SI32 = 2 ** 31 - 1\n    UI32 = 2 ** 32 - 1\n    SI64 = 2 ** 63 - 1\n    UI64 = 2 ** 64 - 1\n']], ['retrive minimum maximum values of a ctype'], 3, 0], [(35220031, 1), [['Or you could put them in a  dict .  I put them in static attributes of a  class  because it\'s about the neatest way of letting you refer to them in a way that "feels like"  enum  constants:'], ['More programmatically, if your type string is a variable, you could use it like this:']], [[' print( MaxVal.UI32 )\n']], ['retrive minimum maximum values of a ctype'], 3, 0], [(35220031, 2), [['More programmatically, if your type string is a variable, you could use it like this:'], ['The corresponding  MinVal  definitions are left as an exercise for the reader..']], [[" dt = 'UI32'\nprint( getattr(MaxVal, dt) )\n"]], ['retrive minimum maximum values of a ctype'], 3, 0], [(35232897, 0), [['As Padric said in his comment,  itertools.groupby()  needs ordered data to do what you want. The simplest solution (as in least code edits) would be:'], ["If your data is relatively big, you may want to consider something more efficient that doesn't require a duplicate sorted copy in memory.  defaultdict  mentioned in the comment may be a good choice."]], [[' import itertools\n\nkey_func = lambda item: item["teamID"]\n\nfor key, group in itertools.groupby(sorted(batting, key=key_func), key_func):\n    print key, sum([item["R"] for item in group])\n']], ['Grouping in Python'], 2, 1], [(35232897, 1), [["If your data is relatively big, you may want to consider something more efficient that doesn't require a duplicate sorted copy in memory.  defaultdict  mentioned in the comment may be a good choice."], ['The code may need slight adjustments for Python 3.']], [[" from collections import defaultdict\n\nd = defaultdict(int)\n\nfor item in batting:\n  d[item['teamID']] += item.get('R', 0) or 0\n\nfor team, r_sum in sorted(d.items(), key=lambda x: x[0]):\n  print team, r_sum\n"]], ['Grouping in Python'], 2, 1], [(35234823, 0), [["Not sure if this is the best solution, but maybe it's enough to help you."], ['Will give you:']], [[' import re\nimport numpy\n\n# open the file? \ntest_string = " a lot of text read from file ... Department of Something is called (DoS) and then more texts and more text..."\nregex_acronym = r\'\\b[A-Z][a-zA-Z\\.]*[A-Z]\\b\\.?\'\n\nra = re.compile(regex_acronym)\nfor m in ra.finditer(test_string):\n    print m.start(), m.group(), m.span()\n    n = len(m.group()) * 2\n    regex_pre_post = r"((?:[a-zA-Z\'-]+[^a-zA-Z\'-]+){0,%d})(" % n\n    regex_pre_post += regex_acronym \n    regex_pre_post += ")((?:[^a-zA-Z\'-]+[a-zA-Z\'-]+){0,%d})" % n\n    found= re.findall(regex_pre_post, test_string)\n    print found\n\n    found = found[0] # For a single match, just do this.\n    pre = found[0]\n    acro = found[1]\n    post = found[2]\n    print pre, acro, post\n']], ['Python Find n words before and after a certain words'], 2, 1], [(35234823, 1), [['Will give you:'], ['-10000']], [[" 69 DoS (69, 72)\n[('file ... Department of Something is called (', 'DoS', ') and then more texts and more')]\nfile ... Department of Something is called ( DoS ) and then more texts and more\n"]], ['Python Find n words before and after a certain words'], 2, 0], [(35242055, 0), [["I'd suggest:"], ['Output:']], [[" dict(i.strip().split('\\n') for i in text.split('\\n\\n') if len(i.strip().split('\\n')) == 2)\n"]], ['Getting crawled information in dictionary format'], 2, 1], [(35242055, 1), [['Output:'], ['-10000']], [[" {'Job ID': 'EE-1213256', \n 'Manages Others': 'Not Specified', \n 'Job Type': 'Information Technology,  Engineering,  Professional Services', \n 'Relocation': 'No', \n 'Education': '4 Year Degree', \n 'Base Pay': '$140,000.00 - $160,000.00 /Year', \n 'Experience': 'At least 5 year(s)', \n 'Industry': 'Computer Software, Banking - Financial Services, Biotechnology', \n 'Employment Type': 'Full-Time', \n 'Required Travel': 'Not Specified'}\n"]], ['Getting crawled information in dictionary format'], 2, 0], [(35252265, 0), [['This works:'], ['-10000']], [[" ids = df.groupby(['FName', 'LName']).id.apply(lambda x: list(x)[-1])\ndf.Usedid = df.apply(lambda x: int(ids[x.UsedFName, x.UsedLName]), axis=1)\n"]], ['matching between two columns and taking value from another in pandas'], 7, 1], [(35252265, 1), [['-10000'], ['They look like this:']], [[" ids = df.groupby(['FName', 'LName']).id.apply(lambda x: list(x)[-1])\n"]], ['matching between two columns and taking value from another in pandas'], 7, 0], [(35252265, 2), [['They look like this:'], ['Here  groupby()  groups by two columns, the first and the last names. To "see" anything, you need to "do" something with it. Let\'s convert all ids per group into a list:']], [[' FName        LName   \nAndreas      Kai         2006\nConstantine  Pape         NaN\nKoethe       Talukdar    2005\nManual       Hausman     2005\nMax          Weber       2007\nNadia        Alam        2002\nPia          Naime       2003\nPlank        Ingo        2009\nTanvir       Hossain     2001\nWeber        Mac         2008\nName: id, dtype: float64\n']], ['matching between two columns and taking value from another in pandas'], 7, 0], [(35252265, 3), [['Here  groupby()  groups by two columns, the first and the last names. To "see" anything, you need to "do" something with it. Let\'s convert all ids per group into a list:'], ['We want only the last id per group. So, instead of  list()  we use a  lambda  function:']], [[" >>> df.groupby(['FName', 'LName']).id.apply(list)\n\nFName        LName   \nAndreas      Kai                         [2006.0]\nConstantine  Pape                      [nan, nan]\nKoethe       Talukdar    [2004.0, 2004.0, 2005.0]\nManual       Hausman             [2005.0, 2005.0]\nMax          Weber               [2007.0, 2007.0]\nNadia        Alam                [2002.0, 2002.0]\nPia          Naime       [2003.0, 2003.0, 2003.0]\nPlank        Ingo                        [2009.0]\nTanvir       Hossain             [2001.0, 2001.0]\nWeber        Mac         [2008.0, 2008.0, 2008.0]\nName: id, dtype: object\n"]], ['matching between two columns and taking value from another in pandas'], 7, 0], [(35252265, 4), [['We want only the last id per group. So, instead of  list()  we use a  lambda  function:'], ['In the second step we use our  ids :']], [[' lambda x: list(x)[-1]\n']], ['matching between two columns and taking value from another in pandas'], 7, 0], [(35252265, 5), [['In the second step we use our  ids :'], ['We apply a function to the dataframe going line by line ( axis=1 ). Here  x  is a line. We use the values in the columns  UsedFName  and  UsedLName  to get the appropriate id and assign it to the result column with  df.Usedid = . ']], [[' df.apply(lambda x: int(ids[x.UsedFName, x.UsedLName]), axis=1)\n']], ['matching between two columns and taking value from another in pandas'], 7, 0], [(35252265, 6), [['We apply a function to the dataframe going line by line ( axis=1 ). Here  x  is a line. We use the values in the columns  UsedFName  and  UsedLName  to get the appropriate id and assign it to the result column with  df.Usedid = . '], ['-10000']], [['           FName     LName    id UsedFName UsedLName  Usedid\n0        Tanvir   Hossain  2001    Tanvir   Hossain    2001\n1         Nadia      Alam  2002    Tanvir   Hossain    2001\n2           Pia     Naime  2003    Tanvir   Hossain    2001\n3        Koethe  Talukdar  2004    Koethe  Talukdar    2005\n4        Manual   Hausman  2005    Koethe  Talukdar    2005\n5   Constantine      Pape   NaN       Max     Weber    2007\n6       Andreas       Kai  2006       Max     Weber    2007\n7           Max     Weber  2007    Manual   Hausman    2005\n8         Weber       Mac  2008    Manual   Hausman    2005\n9         Plank      Ingo  2009    Manual   Hausman    2005\n10       Tanvir   Hossain  2001       Pia     Naime    2003\n11        Weber       Mac  2008       Pia     Naime    2003\n12       Manual   Hausman  2005    Tanvir   Hossain    2001\n13          Max     Weber  2007    Tanvir   Hossain    2001\n14        Nadia      Alam  2002    Manual   Hausman    2005\n15        Weber       Mac  2008    Manual   Hausman    2005\n16          Pia     Naime  2003    Koethe  Talukdar    2005\n17          Pia     Naime  2003    Koethe  Talukdar    2005\n18  Constantine      Pape   NaN    Koethe  Talukdar    2005\n19       Koethe  Talukdar  2004    Koethe  Talukdar    2005\n20       Koethe  Talukdar  2005    Manual   Hausman    2005\n21          NaN       NaN   NaN    Manual   Hausman    2005\n22          NaN       NaN   NaN    Manual   Hausman    2005\n23          NaN       NaN   NaN    Manual   Hausman    2005\n24          NaN       NaN   NaN    Manual   Hausman    2005\n25          NaN       NaN   NaN    Manual   Hausman    2005\n26          NaN       NaN   NaN    Manual   Hausman    2005\n27          NaN       NaN   NaN    Manual   Hausman    2005\n']], ['matching between two columns and taking value from another in pandas'], 7, 0], [(35254886, 0), [['If you just want the values of your dict, use somethink like:'], ['which prints:']], [[' sozluk_ata = {20225: 17, 20232: 9, 20233: 22, 20234: 3, 20235: 28, 20236: 69}\n\nfor key in sozluk_ata:\n    print(key, sozluk_ata[key])\n']], ['Obtaining dictionary value in Python'], 2, 1], [(35254886, 1), [['which prints:'], ['-10000']], [[' 20225 17\n20232 9\n20233 22\n20234 3\n20235 28\n20236 69\n']], ['Obtaining dictionary value in Python'], 2, 0], [(35261899, 0), [['Implementation:'], ['Prints:']], [[' from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\nimport pandas as pd\n\n\nurls = [\n    \'http://www.oddsportal.com/hockey/austria/ebel-2014-2015/results/#/page/\',\n    \'http://www.oddsportal.com/hockey/austria/ebel-2013-2014/results/#/page/\'\n]\n\ndata = []\n\ndriver = webdriver.PhantomJS()\ndriver.implicitly_wait(10)\nwait = WebDriverWait(driver, 10)\n\nfor url in urls:\n    for page in range(1, 8):\n        driver.get(url + str(page))\n        # wait for the page to load\n        wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "div#tournamentTable tr.deactivate")))\n\n        for match in driver.find_elements_by_css_selector("div#tournamentTable tr.deactivate"):\n            home, away = match.find_element_by_class_name("table-participant").text.split(" - ")\n            date = match.find_element_by_xpath(".//preceding::th[contains(@class, \'first2\')][1]").text\n\n            if " - " in date:\n                date, event = date.split(" - ")\n            else:\n                event = "Not specified"\n\n            data.append({\n                "home": home.strip(),\n                "away": away.strip(),\n                "date": date.strip(),\n                "event": event.strip()\n            })\n\ndriver.close()\n\ndf = pd.DataFrame(data)\nprint(df)\n']], ['Selenium scraping with multiple urls'], 2, 1], [(35261899, 1), [['Prints:'], ['-10000']], [['                    away         date          event                home\n0              Salzburg  14 Apr 2015      Play Offs     Vienna Capitals\n1       Vienna Capitals  12 Apr 2015      Play Offs            Salzburg\n2              Salzburg  10 Apr 2015      Play Offs     Vienna Capitals\n3       Vienna Capitals  07 Apr 2015      Play Offs            Salzburg\n4       Vienna Capitals  31 Mar 2015      Play Offs         Liwest Linz\n5              Salzburg  29 Mar 2015      Play Offs          Klagenfurt\n6           Liwest Linz  29 Mar 2015      Play Offs     Vienna Capitals\n7            Klagenfurt  26 Mar 2015      Play Offs            Salzburg\n8       Vienna Capitals  26 Mar 2015      Play Offs         Liwest Linz\n9           Liwest Linz  24 Mar 2015      Play Offs     Vienna Capitals\n10             Salzburg  24 Mar 2015      Play Offs          Klagenfurt\n11           Klagenfurt  22 Mar 2015      Play Offs            Salzburg\n12      Vienna Capitals  22 Mar 2015      Play Offs         Liwest Linz\n13              Bolzano  20 Mar 2015      Play Offs         Liwest Linz\n14        Fehervar AV19  18 Mar 2015      Play Offs     Vienna Capitals\n15          Liwest Linz  17 Mar 2015      Play Offs             Bolzano\n16      Vienna Capitals  16 Mar 2015      Play Offs       Fehervar AV19\n17              Villach  15 Mar 2015      Play Offs            Salzburg\n18           Klagenfurt  15 Mar 2015      Play Offs              Znojmo\n19              Bolzano  15 Mar 2015      Play Offs         Liwest Linz\n20          Liwest Linz  13 Mar 2015      Play Offs             Bolzano\n21        Fehervar AV19  13 Mar 2015      Play Offs     Vienna Capitals\n22               Znojmo  13 Mar 2015      Play Offs          Klagenfurt\n23             Salzburg  13 Mar 2015      Play Offs             Villach\n24           Klagenfurt  10 Mar 2015      Play Offs              Znojmo\n25      Vienna Capitals  10 Mar 2015      Play Offs       Fehervar AV19\n26              Bolzano  10 Mar 2015      Play Offs         Liwest Linz\n27              Villach  10 Mar 2015      Play Offs            Salzburg\n28          Liwest Linz  08 Mar 2015      Play Offs             Bolzano\n29               Znojmo  08 Mar 2015      Play Offs          Klagenfurt\n..                  ...          ...            ...                 ...\n670       TWK Innsbruck  28 Sep 2013  Not specified              Znojmo\n671         Liwest Linz  27 Sep 2013  Not specified            Dornbirn\n672             Bolzano  27 Sep 2013  Not specified          Graz 99ers\n673          Klagenfurt  27 Sep 2013  Not specified  Olimpija Ljubljana\n674       Fehervar AV19  27 Sep 2013  Not specified            Salzburg\n675       TWK Innsbruck  27 Sep 2013  Not specified     Vienna Capitals\n676             Villach  27 Sep 2013  Not specified              Znojmo\n677            Salzburg  24 Sep 2013  Not specified  Olimpija Ljubljana\n678            Dornbirn  22 Sep 2013  Not specified       TWK Innsbruck\n679          Graz 99ers  22 Sep 2013  Not specified          Klagenfurt\n680     Vienna Capitals  22 Sep 2013  Not specified             Villach\n681       Fehervar AV19  21 Sep 2013  Not specified             Bolzano\n682            Dornbirn  20 Sep 2013  Not specified             Bolzano\n683             Villach  20 Sep 2013  Not specified          Graz 99ers\n684              Znojmo  20 Sep 2013  Not specified          Klagenfurt\n685  Olimpija Ljubljana  20 Sep 2013  Not specified         Liwest Linz\n686       Fehervar AV19  20 Sep 2013  Not specified       TWK Innsbruck\n687            Salzburg  20 Sep 2013  Not specified     Vienna Capitals\n688             Villach  15 Sep 2013  Not specified          Klagenfurt\n689         Liwest Linz  15 Sep 2013  Not specified            Dornbirn\n690     Vienna Capitals  15 Sep 2013  Not specified       Fehervar AV19\n691       TWK Innsbruck  15 Sep 2013  Not specified            Salzburg\n692          Graz 99ers  15 Sep 2013  Not specified              Znojmo\n693  Olimpija Ljubljana  14 Sep 2013  Not specified            Dornbirn\n694             Bolzano  14 Sep 2013  Not specified       Fehervar AV19\n695          Klagenfurt  13 Sep 2013  Not specified          Graz 99ers\n696              Znojmo  13 Sep 2013  Not specified            Salzburg\n697  Olimpija Ljubljana  13 Sep 2013  Not specified       TWK Innsbruck\n698             Bolzano  13 Sep 2013  Not specified     Vienna Capitals\n699         Liwest Linz  13 Sep 2013  Not specified             Villach\n\n[700 rows x 4 columns]\n']], ['Selenium scraping with multiple urls'], 2, 0], [(35281863, 0), [['Can you just create your own permission class and use that?\nFor example:'], ['Then, import this new class into your view, and use it like this:']], [[' from rest_framework import permissions\n\nclass HasNiceHatOrHasNicePants(permissions.BasePermission):\n    """\n    Permission to check if user has a Nice Hat or has Nice Pants.\n    If both are False do not return anything.\n    """\n    def has_permission(self, request, view):\n\n        if request.user.has_nicehat() or request.user.has_nicepants():\n            return True\n']], ['OR style permissions for DjangoRestFramework'], 2, 0], [(35281863, 1), [['Then, import this new class into your view, and use it like this:'], ['-10000']], [[' permission_classes = (HasNiceHatOrHasNicePants,)\n']], ['OR style permissions for DjangoRestFramework'], 2, 0], [(35288428, 0), [['This will split your list into 2 lists of equal length (6):'], ['If you want to split a list to  many  smaller lists use:']], [[" >>> my_list = [1, 'ab', '', 'No', '', 'NULL', 2, 'bc', '','Yes' ,'' ,'Null']\n>>> x = my_list[:len(my_list)//2]\n>>> y = my_list[len(my_list)//2:]\n>>> x\n[1, 'ab', '', 'No', '', 'NULL']\n>>> y\n[2, 'bc', '', 'Yes', '', 'Null']\n"]], ['How to create sub list with fixed length from given number of inputs or list in Python?'], 3, 0], [(35288428, 1), [['If you want to split a list to  many  smaller lists use:'], ['Where  size  is the size of the smaller lists you want, example:']], [[' chunks = [my_list[x:x+size] for x in range(0, len(my_list), size)]\n']], ['How to create sub list with fixed length from given number of inputs or list in Python?'], 3, 1], [(35293171, 0), [['in the model'], ['in the view']], [[" computed_field = fields.Char(compute='comp', inverse='inv', store=True)\nboolean_field = fields.Boolean()\n\n@api.one\ndef comp(self):\n    ...\n\n@api.one\ndef inv(self):\n    ...\n"]], ['How to make a field computed only if some condition is fulfilled in Odoo 8?'], 5, 0], [(35293171, 1), [['in the view'], ['then you need another 2 fields']], [[' <field name="boolean_field" />\n<field name="computed_field" attrs="{\'readonly\': [(\'boolean_field\',\'=\',True)]}" />\n']], ['How to make a field computed only if some condition is fulfilled in Odoo 8?'], 5, 0], [(35293171, 2), [['then you need another 2 fields'], ['plus']], [[" value_manual = fields.Float()\nmanual = fields.Boolean(compute='_is_manual', default=True)\n\n@api.one\n@api.depends('child_ids')\ndef _is_manual(self):\n    self.manual = len(self.child_ids) == 0\n"]], ['How to make a field computed only if some condition is fulfilled in Odoo 8?'], 5, 0], [(35293171, 3), [['plus'], ['in the view:']], [[" @api.one\n@api.depends('child_ids', 'child_ids.value')\ndef _compute_value(self):\n    if self.child_ids:\n        self.value = sum(\n            [child.value for child in self.child_ids])\n    else:\n        self.value = self.value_manual\n"]], ['How to make a field computed only if some condition is fulfilled in Odoo 8?'], 5, 0], [(35293171, 4), [['in the view:'], ['There could be another solution that avoid this double field, maybe using the inverse, but I am not sure.']], [[' <field name="manual" invisible="1" />\n<field name="value" attrs="{\'invisible\': [(\'manual\',\'=\',True)]}" />\n<field name="value_manual" attrs="{\'invisible\': [(\'manual\',\'=\',False)]}" />\n']], ['How to make a field computed only if some condition is fulfilled in Odoo 8?'], 5, 0], [(35300343, 0), [['In:'], ['Out: ']], [[" df = df.reset_index() #Make your index into a column\ndf = pd.melt(df, id_vars = ['index']) #Reshape data\ndf = df[df['index'] <= df['variable']].sort_values(by = 'value') #Remove duplicates, sort\ndf ['col'] = df['index'] +','+ df['variable'] #Concatenate strings\ndf = df[['col','value']] #Remove unnecessary columns\ndf = df.set_index('col') #Set strings to index\ndf\n"]], ['Transposing dataframe and sorting'], 2, 1], [(35300343, 1), [['Out: '], ['-10000']], [['                 value\ncol \nArnston,Arnston 0\nBerg,Berg       0\nCarlson,Carlson 0\nArnston,Berg    1\nArnston,Carlson 2\nBerg,Carlson    3\n']], ['Transposing dataframe and sorting'], 2, 0], [(35306419, 0), [['Try using:'], ['To list installed packages:']], [[' pip show <package name>\n']], ['Where is the configuration information of installed packages?'], 3, 1], [(35306419, 2), [['And of course most importantly:'], ['-10000']], [[' pip help\n']], ['Where is the configuration information of installed packages?'], 3, 1], [(35318700, 0), [['Maybe you can use  iloc  or  loc  for selecting column and then  tolist :'], ['Or maybe:']], [[' print df\n   a\n0  2\n1  0\n2  1\n3  0\n4  1\n5  0\n\nprint df.values\n[[2]\n [0]\n [1]\n [0]\n [1]\n [0]]\n\nprint df.iloc[:, 0].tolist()\n[2, 0, 1, 0, 1, 0]\n']], ['Convert dataFrame to list'], 3, 1], [(35318700, 1), [['Or maybe:'], ['But maybe you need  flatten :']], [[" print df.values.tolist()\n[[2L], [0L], [1L], [0L], [1L], [0L]]\n\nprint df.iloc[:, 0].values.tolist()\n[2L, 0L, 1L, 0L, 1L, 0L]\n\nprint df.loc[:, 'a'].tolist()\n[2, 0, 1, 0, 1, 0]\n\nprint df['a'].tolist()\n[2, 0, 1, 0, 1, 0]\n"]], ['Convert dataFrame to list'], 3, 1], [(35318700, 2), [['But maybe you need  flatten :'], ['-10000']], [[' print df.values.flatten()\n[2 0 1 0 1 0]\n\nprint df.iloc[:, 0].values.flatten()\n[2 0 1 0 1 0]\n']], ['Convert dataFrame to list'], 3, 1], [(35322452, 0), [['To implement the approach add the following  Dockerfile  to the top folder of the project you want to test next to the  requirements.txt  and  setup.py  files:'], ['Build the image once with:']], [[' FROM python:3\n\n# setup pytest user\nRUN adduser --disabled-password --gecos "" --uid 7357 pytest\nCOPY ./ /home/pytest\nWORKDIR /home/pytest\n\n# setup the python and pytest environments\nRUN pip install --upgrade pip setuptools pytest\nRUN pip install --upgrade -r requirements.txt\nRUN python setup.py develop\n\n# setup entry point\nUSER pytest\nENTRYPOINT ["py.test"]\n']], ['Is there a way to sandbox test execution with pytest, especially filesystem access?'], 4, 0], [(35322452, 1), [['Build the image once with:'], ['Run py.test inside the container mounting the project folder as volume on /home/pytest with:']], [[' docker build -t pytest .\n']], ['Is there a way to sandbox test execution with pytest, especially filesystem access?'], 4, 0], [(35322452, 2), [['Run py.test inside the container mounting the project folder as volume on /home/pytest with:'], ['Update:  If you also run the test on the host you may need to remove the python and pytest caches that are not writable inside the container. On the host run:']], [[' docker run --rm -it -v `pwd`:/home/pytest pytest [USUAL_PYTEST_OPTIONS]\n']], ['Is there a way to sandbox test execution with pytest, especially filesystem access?'], 4, 0], [(35322452, 3), [['Update:  If you also run the test on the host you may need to remove the python and pytest caches that are not writable inside the container. On the host run:'], ['-10000']], [[' rm -rf .cache/ && find . -name __pycache__  | xargs rm -rf\n']], ['Is there a way to sandbox test execution with pytest, especially filesystem access?'], 4, 0], [(35344237, 0), [['Assuming you want to locate the '], ['element, based on the text in']], [[' <span class="linkhover" title="view" style="white-space:nowrap;overflow:hidden;text-overflow:ellipsis;empty-cells:show;display:block;color:#00A;cursor:pointer;">view</span>\n']], ['Selenium Python select the link from 3rd column from a table'], 3, 0], [(35344237, 1), [['element, based on the text in'], ['you can use the  following  axis:']], [[' <span class="linkhover" title="Selenium_LADEMO_CRM_DONOTCHANGE" style="white-space:nowrap;overflow:hidden;text-overflow:ellipsis;empty-cells:show;display:block;color:#00A;cursor:pointer;">Selenium_CRM_For_Edit_Test</span>\n']], ['Selenium Python select the link from 3rd column from a table'], 3, 0], [(35346425, 0), [['box should look like:'], ['and character should look like:']], [['     def __str__(self):\n        result = ""\n        for i in range(self.x):\n            for j in range(self.y):\n                result += \'*\' if i in [0, self.x - 1] or j in [0, self.y - 1] else \' \'\n            result += \'\\n\'\n        return result\n']], ['Printing inherited class in Python'], 2, 0], [(35346425, 1), [['and character should look like:'], ['Compare these to your code, and see how you could implement displayCharacter and createBox using the implementations of  __str__ . :)']], [["     def __str__(self):\n        return 'Name :' + self.name + ', Occupation:' + self.occupation + ', Affiliation:' + self.affiliation + ', Species:' + self.species\n"]], ['Printing inherited class in Python'], 2, 0], [(35354005, 1), [["Let's work on a smaller dataset so that it is easier to understand:"], ['-10000']], [[' np.random.seed(0)\nvalues = np.random.uniform(0, 100, 10)\nvalues.sort()\n>>> values\narray([ 38.34415188,  42.36547993,  43.75872113,  54.4883183 ,\n        54.88135039,  60.27633761,  64.58941131,  71.51893664,\n        89.17730008,  96.36627605])\n\n# Histogram using e.g. 10 buckets\nperc, edges = np.histogram(values, bins=10,\n                           weights=np.zeros_like(values) + 100./values.size)\n\n>>> perc\narray([ 30.,   0.,  20.,  10.,  10.,  10.,   0.,   0.,  10.,  10.])\n\n>>> edges\narray([ 38.34415188,  44.1463643 ,  49.94857672,  55.75078913,\n        61.55300155,  67.35521397,  73.15742638,  78.9596388 ,\n        84.76185122,  90.56406363,  96.36627605])\n\nm = 0; M = 50\nmask = (m <= edges) & (edges < M)\n>>> mask\narray([ True,  True,  True, False, False, False, False, False, False,\n       False, False], dtype=bool)\n\n>>> edges[mask]\narray([ 38.34415188,  44.1463643 ,  49.94857672])\n\n>>> perc[mask[:-1]][:-1]\narray([ 30.,   0.])\n\nm = 40; M = 60\nmask = (m < edges) & (edges < M)\n>>> edges[mask]\narray([ 44.1463643 ,  49.94857672,  55.75078913])\n>>> perc[mask[:-1]][:-1]\narray([  0.,  20.])\n']], ['Filtering histogram edges and counts'], 2, 1], [(35373082, 0), [['Assuming there is at most one row per key in each  DataFrame  and all keys are of primitive types you can try an union with an aggregation. Lets start with some imports and example data:'], ['Next we can extract common schema:']], [[' from itertools import chain\nfrom functools import reduce\nfrom pyspark.sql.types import StructType\nfrom pyspark.sql.functions import col, lit, max\nfrom pyspark.sql import DataFrame\n\ndf1 = sc.parallelize([\n    ("U1", 0, 1), ("U2", 1, 1)\n]).toDF(["Key", "FeatureA", "FeatureB"])\n\ndf2 = sc.parallelize([\n  ("U1", 0, 0, 1)\n]).toDF(["Key", "FeatureC", "FeatureD", "FeatureE"])\n\ndf3 = sc.parallelize([("U2", 1)]).toDF(["Key", "FeatureF"])\n\ndfs = [df1, df2, df3]\n']], ["What's the most efficient way to accumulate dataframes in pyspark?"], 4, 0], [(35373082, 1), [['Next we can extract common schema:'], ['and transform all  DataFrames :']], [[' output_schema = StructType(\n  [df1.schema.fields[0]] + list(chain(*[df.schema.fields[1:] for df in dfs]))\n)\n']], ["What's the most efficient way to accumulate dataframes in pyspark?"], 4, 0], [(35373082, 2), [['and transform all  DataFrames :'], ['Finally an union and dummy aggregation:']], [[' transformed_dfs = [df.select(*[\n  lit(None).cast(c.dataType).alias(c.name) if c.name not in df.columns \n  else col(c.name)\n  for c in output_schema.fields\n]) for df in dfs]\n']], ["What's the most efficient way to accumulate dataframes in pyspark?"], 4, 0], [(35373082, 3), [['Finally an union and dummy aggregation:'], ['If there is more than one row per key but individual columns are still atomic you can try to replace  max  with  collect_list  /  collect_set  followed by  explode .']], [[' combined = reduce(DataFrame.unionAll, transformed_dfs)\nexprs = [max(c).alias(c) for c in combined.columns[1:]]\nresult = combined.repartition(col("Key")).groupBy(col("Key")).agg(*exprs)\n']], ["What's the most efficient way to accumulate dataframes in pyspark?"], 4, 0], [(35389648, 0), [['You can do it with the shortest way as below, since the empty dictionary is  False , and do it through  Boolean Operators .  '], ['Or without  str']], [[" >>> d = {}\n>>> str(d or '')\n''\n"]], ['Convert empty dictionary to empty string'], 3, 1], [(35389648, 1), [['Or without  str'], ['If  d  is not an empty dictionary, convert it to string with  str()']], [[" >>> d = {}\n>>> d or ''\n''\n"]], ['Convert empty dictionary to empty string'], 3, 1], [(35389648, 2), [['If  d  is not an empty dictionary, convert it to string with  str()'], ['-10000']], [[' >>> d[\'f\'] = 12\n>>> str(d or \'\')\n"{\'f\': 12}"\n']], ['Convert empty dictionary to empty string'], 3, 1], [(35428388, 0), [['Features with  DictVectorizer  are mapped to  numpy  arrays, which represents the feature as  NxM  numerical matrix (dictionary is lost). However, the class  DictVectorizer  preserves the mapping function internally, and you can recover it using  .inverse_transform . From the documentation of   DictVectorizer :'], ['Thus, for a single instance  x_i  (row) belonging to  X , you can recover the mapping as:']], [[" from sklearn.feature_extraction import DictVectorizer\n>>> v = DictVectorizer(sparse=False)\n>>> D = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\n>>> X = v.fit_transform(D)\n>>> X\narray([[ 2.,  0.,  1.],\n       [ 0.,  1.,  3.]])\n>>> v.inverse_transform(X) == [{'bar': 2.0, 'foo': 1.0}, {'baz': 1.0, 'foo': 3.0}]\nTrue\n"]], ['Extracting a feature by feature name in scikit dict vectorizer'], 6, 0], [(35428388, 1), [['Thus, for a single instance  x_i  (row) belonging to  X , you can recover the mapping as:'], ['The last bit  [None, :]  converts the  M  length row  X[i]  in a  1xM  row vector. Is not entirely needed, but scikits-learn throws a warning. The following should also work:']], [[' >>> v.inverse_transform(X[i][None, :])\n']], ['Extracting a feature by feature name in scikit dict vectorizer'], 6, 0], [(35428388, 2), [['The last bit  [None, :]  converts the  M  length row  X[i]  in a  1xM  row vector. Is not entirely needed, but scikits-learn throws a warning. The following should also work:'], ['-10000']], [[' >>> v.inverse_transform(X[i])\n']], ['Extracting a feature by feature name in scikit dict vectorizer'], 6, 0], [(35428388, 3), [['-10000'], ['Thus, you could do something like:']], [[" >>> v.feature_names_\n['bar', 'baz', 'foo']\n"]], ['Extracting a feature by feature name in scikit dict vectorizer'], 6, 0], [(35431172, 0), [['like'], ['Returns: ']], [[' your_list = [\'bread\', \'milk\', \'sugar\', \'tea\']\n\nprint("{0:20}    {1:20}    {2:20}    {3:20}\\n".format(\'Column 1\', \'Column 2\', \'Column 3\', \'Column 4\'))\nprint("{0:20}    {1:20}    {2:20}    {3:20}\\n".format(your_list[0], your_list[1], your_list[2], your_list[3]))\n']], ['Creating a table out of data in python'], 7, 1], [(35431172, 1), [['Returns: '], ['With a for loop example getting closer to what you might be wanting to do:']], [[' Column 1                Column 2                Column 3                Column 4            \n\nbread                   milk                    sugar                   tea   \n']], ['Creating a table out of data in python'], 7, 0], [(35431172, 2), [['With a for loop example getting closer to what you might be wanting to do:'], ['Output:']], [[' your_list = [\'bread\', \'milk\', \'sugar\', \'tea\', \'eggs\', \'shampoo\', \'clothes\', \'tiger\', \'beads\', \'washing machine\', \'juice\', \'mixed herbs\']\n\nprint("{0:20}    {1:20}    {2:20}    {3:20}\\n".format(\'Column 1\', \'Column 2\', \'Column 3\', \'Column 4\'))\ni = 0\nfor x in range(0, 3):\n    print("{0:20}    {1:20}    {2:20}    {3:20}\\n".format(your_list[i], your_list[i + 1], your_list[i + 2], your_list[i + 3]))\n    i += 4\n']], ['Creating a table out of data in python'], 7, 1], [(35431172, 3), [['Output:'], ['EDIT:']], [[' Column 1                Column 2                Column 3                Column 4            \n\nbread                   milk                    sugar                   tea                 \n\neggs                    shampoo                 clothes                 tiger               \n\nbeads                   washing machine         juice                   mixed herbs    \n']], ['Creating a table out of data in python'], 7, 0], [(35431172, 4), [['EDIT:'], ['Output:']], [[' your_list = [\'10\', 10, \'20\', 20]\nprint("{0:20}    {1:20}    {2:20}    {3:20}\\n".format(\'Column 1\', \'Column 2\', \'Column 3\', \'Column 4\'))\nprint("{0:20}    {1:20}    {2:20}    {3:20}\\n".format(your_list[0], your_list[1], your_list[2], str(your_list[3])))\n']], ['Creating a table out of data in python'], 7, 1], [(35431172, 5), [['Output:'], ["If you convert the integers in your list to Strings demonstrated by the last element in my format statement using the Str() method then this won't happen :)"]], [[' Column 1                Column 2                Column 3                Column 4            \n\n10                                        10    20                      20      \n']], ['Creating a table out of data in python'], 7, 0], [(35431172, 6), [["If you convert the integers in your list to Strings demonstrated by the last element in my format statement using the Str() method then this won't happen :)"], ['https://docs.python.org/2/library/string.html']], [[' str(your_list[3])\n']], ['Creating a table out of data in python'], 7, 0], [(35432378, 0), [['An easy solution is to shape the list into a (100, 28) array and then transpose it:'], ['Update regarding the updated example:']], [[' x = np.reshape(list_data, (100, 28)).T\n']], ['Python reshape list to ndim array'], 2, 1], [(35432378, 1), [['Update regarding the updated example:'], ['-10000']], [[' np.reshape([0, 0, 1, 1, 2, 2, 3, 3], (4, 2)).T\n# array([[0, 1, 2, 3],\n#        [0, 1, 2, 3]])\n\nnp.reshape([0, 0, 1, 1, 2, 2, 3, 3], (2, 4))\n# array([[0, 0, 1, 1],\n#        [2, 2, 3, 3]])\n']], ['Python reshape list to ndim array'], 2, 0], [(35469417, 1), [['Complete example:'], ['Prints:']], [[' from bs4 import BeautifulSoup\n\nhtml = """\n<div>\n     <div class="A">test1</div>\n     <div class="A B">test2</div>\n     <div class="A X Y">test3</div>\n</div>\n"""\n\nsoup = BeautifulSoup(html, "lxml")\n\ndef filter_function(elm):\n    return elm and "class" in elm.attrs and "A" in elm["class"] and "Y" not in elm["class"]\n\nfor div in soup.find_all(filter_function):\n    print(div.text)\n']], ['Selecting Tags With Multiple Part Class in BeautifulSoup'], 3, 1], [(35469417, 2), [['Prints:'], ['-10000']], [[' test1\ntest2\n']], ['Selecting Tags With Multiple Part Class in BeautifulSoup'], 3, 0], [(35481842, 0), [['This example uses a  deque  to implement the rotation:'], ['when run:']], [[' import os\nimport collections\n\nsubnets_file = "subnets.txt"\n\n# Load the subnets file into a deque\nwith open(subnets_file, \'r\') as f:\n    subnets = collections.deque(f.read().splitlines())\n\n# Print the top subnet\nprint subnets[0]\n\n# Rotate the subnets\nsubnets.rotate(-1)\n\n# Save the rotated subnets\nwith open(subnets_file, \'w\') as f:\n    for s in subnets:\n        f.write("%s\\n" % s)\n']], ['python: how can I get a new value in round robin style every time i invoke the script'], 2, 1], [(35481842, 1), [['when run:'], ['-10000']], [[' $ python next_available_subnet.py \nsubnet1\n$ python next_available_subnet.py \nsubnet2\n$ python next_available_subnet.py \nsubnet3\n$ python next_available_subnet.py \nsubnet1\n']], ['python: how can I get a new value in round robin style every time i invoke the script'], 2, 0], [(35485675, 0), [['Before entering your time loop, create an empty list:'], ['Then, after creating your flow map:']], [[' listOfFlowMaps = []\n']], ['How to create a vector of Matrices in python'], 2, 0], [(35485675, 1), [['Then, after creating your flow map:'], ['-10000']], [[' flowmap = np.array([...]) # your flow map\nlistOfFlowMaps.append(flowmap) # add the flow map to the list\n']], ['How to create a vector of Matrices in python'], 2, 0], [(35488781, 0), [["Just use where to choose between the value in 'a' or 'b'"], ['-10000']], [[" df['a'].where(df['a'].abs() < df['b'].abs(), df['b'])\n"]], ['Selecting the value in a row closest to zero in a pandas DataFrame'], 2, 1], [(35489107, 0), [['You can add  {140}  to specify the length, and add  \\s  to match spaces, to your URL regex:'], ["Here's how you can test it out, I've reduced it to 10 length to make it easy:"]], [[" url(r'^home/(?P<text>[\\w\\s]{140})$',....),\n"]], ['Django URL matching any 140 characters'], 5, 1], [(35489107, 2), [['and if you exceed the length, e.g.'], ['and if you go below the length, e.g.']], [[' >>> re.search(regex, "home/ abcd fghizzz")\n# Doesn\'t match, returns None\n']], ['Django URL matching any 140 characters'], 5, 0], [(35489107, 3), [['and if you go below the length, e.g.'], ['-10000']], [[' >>> re.search(regex, "home/ abc")\n# Doesn\'t match, returns None\n']], ['Django URL matching any 140 characters'], 5, 0], [(35489107, 4), [['-10000'], ['-10000']], [[' >>> regex = r\'^home/(?P<text>(.){10})$\'\n>>> re.search(regex, "home/1@#$%^& &*").group(1)\n\'1@#$%^& &*\'\n>>> re.search(regex, "home/1@bcd^& &*").group(1)\n\'1@bcd^& &*\'\n']], ['Django URL matching any 140 characters'], 5, 1], [(35493086, 0), [["The key is  pandas.Series.isin()  which checks for membership of each element in the calling  pandas.Series  in the object passed to  pandas.Series.isin() .  You want to check for membership of each of element in  b_received  with  c_consumed , but only within each group as defined by  a_id . When using  groupby  with  apply  pandas will index the object by the grouping variable as well as its original index.  In your case, you don't need the grouping variable in the index, so you can reset the index back to what it was originally with  reset_index  using  drop=True ."], ['Your  DataFrame  is now ...']], [[" df['output'] = (df.groupby('a_id')\n               .apply(lambda x : x['b_received'].isin(x['c_consumed']).astype('i4'))\n               .reset_index(level='a_id', drop=True))\n"]], ['Compare values in 2 columns and output the result in a third column in pandas'], 2, 1], [(35493086, 1), [['Your  DataFrame  is now ...'], ['Have a look a the documentation for  split-apply-combine  with pandas for a more thorough explanation.']], [['     a_id b_received c_consumed  output\n0    sam       soap        oil       1\n1    sam        oil        NaN       1\n2    sam      brush       soap       0\n3  harry        oil      shoes       1\n4  harry      shoes        oil       1\n5  alice       beer       eggs       0\n6  alice      brush      brush       1\n7  alice       eggs        NaN       1\n']], ['Compare values in 2 columns and output the result in a third column in pandas'], 2, 0], [(35510590, 0), [['In the past I had a similar use case.\nI solved it by declaring the path inside the zope.conf:'], ['This zope configuration can then be interpreted with this code:']], [[' zope-conf-additional +=\n  <product-config pd.prenotazioni>\n    logfile ${buildout:directory}/var/log/prenotazioni.log\n  </product-config>\n']], ['How to get the location of a Zope installation from inside an instance?'], 4, 0], [(35510590, 1), [['This zope configuration can then be interpreted with this code:'], ['It is specified in the zope.conf. You should have something like this:']], [[" from App.config import getConfiguration\n\nproduct_config = getattr(getConfiguration(), 'product_config', {})\nconfig = product_config.get('pd.prenotazioni', {})\nlogfile = config.get('logfile')\n"]], ['How to get the location of a Zope installation from inside an instance?'], 4, 0], [(35510590, 2), [['It is specified in the zope.conf. You should have something like this:'], ['I was able to obtain the path with this code:']], [[' <eventlog>\n  level INFO\n  <logfile>\n    path /path/to/plone/var/log/instance.log\n    level INFO\n  </logfile>\n</eventlog>\n']], ['How to get the location of a Zope installation from inside an instance?'], 4, 0], [(35510590, 3), [['I was able to obtain the path with this code:'], ['Probably looking at in the App module code you will find a more straightforward way of getting this value.']], [[' from App.config import getConfiguration \nimport os\n\neventlog = getConfiguration().eventlog\nlogpath = eventlog.handler_factories[0].instance.baseFilename\nlogfolder = os.path.split(logpath)[0] \n']], ['How to get the location of a Zope installation from inside an instance?'], 4, 1], [(35526501, 0), [["Similar to Anton's answer, but using apply"], ['result:']], [[" users = df.groupby('buyer_id').apply(lambda r: r['item_id'].unique().shape[0] > 1 and \n                                               r['date'].unique().shape[0] > 1 )*1\ndf.set_index('buyer_id', inplace=True)\ndf['good_user'] = users\n"]], ['how to groupby pandas dataframe on some condition'], 4, 1], [(35526501, 1), [['result:'], ['EDIT  because I thought of another case: suppose the data shows a buyer buys the same two (or more) goods on two different days. Should this user be flagged as 1 or 0? Because effectively, he/she does not actually choose anything different on the second date.\nSo take buyer 81 in the following table. You see they only buy 49 and 50 on both dates.']], [['           item_id  order_id        date  good_user\nbuyer_id\n139            57       387  2015-12-28          1\n140             9       388  2015-12-28          1\n140            57       389  2015-12-28          1\n36              9       390  2015-12-28          0\n64             49       404  2015-12-29          0\n146            49       405  2015-12-29          0\n81             49       406  2015-12-29          0\n140            80       407  2015-12-30          1\n139            81       408  2015-12-30          1\n']], ['how to groupby pandas dataframe on some condition'], 4, 0], [(35526501, 2), [['EDIT  because I thought of another case: suppose the data shows a buyer buys the same two (or more) goods on two different days. Should this user be flagged as 1 or 0? Because effectively, he/she does not actually choose anything different on the second date.\nSo take buyer 81 in the following table. You see they only buy 49 and 50 on both dates.'], ["To accomodate this, here's what I came up with (kinda ugly but should work)"]], [['     buyer_id   item_id order_id    date\n         139        57      387    2015-12-28\n         140         9      388    2015-12-28\n         140        57      389    2015-12-28\n          36         9      390    2015-12-28\n          64        49      404    2015-12-29\n         146        49      405    2015-12-29\n          81        49      406    2015-12-29\n         140        80      407    2015-12-30\n         139        81      408    2015-12-30\n          81        50      406    2015-12-29\n          81        49      999    2015-12-30\n          81        50      999    2015-12-30\n']], ['how to groupby pandas dataframe on some condition'], 4, 0], [(35526501, 3), [["To accomodate this, here's what I came up with (kinda ugly but should work)"], ['This works on buyer 81 setting it to 0 because once you group by date, both dates at which a purchase was made will have the same "49-50" combination of items purchased, hence the number of combinations = 1 and the buyer will be flagged 0.']], [[" # this function is applied to all buyers\ndef find_good_buyers(buyer):\n    # which dates the buyer has made a purchase\n    buyer_dates = buyer.groupby('date')\n    # a string representing the unique items purchased at each date\n    items_on_date = buyer_dates.agg({'item_id': lambda x: '-'.join(x.unique())})\n    # if there is more than 1 combination of item_id, then it means that\n    # the buyer has purchased different things in different dates\n    # so this buyer must be flagged to 1\n    good_buyer = (len(items_on_date.groupby('item_id').groups) > 1) * 1\n    return good_buyer\n\n\ndf['item_id'] = df['item_id'].astype('S')\nbuyers = df.groupby('buyer_id') \n\ngood_buyer = buyers.apply(find_good_buyers)\ndf.set_index('buyer_id', inplace=True)\ndf['good_buyer'] = good_buyer\ndf.reset_index(inplace=True)\n"]], ['how to groupby pandas dataframe on some condition'], 4, 1], [(35559958, 0), [["You could use Python's  filter  function for this as follows:"], ['Giving:']], [[" l = [('A', 2), ('A', 1), ('B', 0.2)]\nprint filter(lambda x: x[0] == 'A', l)\n"]], ['Check list of tuples where first element of tuple is specified by defined string'], 2, 1], [(35559958, 1), [['Giving:'], ['-10000']], [[" [('A', 2), ('A', 1)]\n"]], ['Check list of tuples where first element of tuple is specified by defined string'], 2, 0], [(35560606, 0), [['BeautifulSoup  would get you quite close to your desired behavior:'], ['Prints:']], [[' from bs4 import BeautifulSoup\n\nhtml_table_string = """\n<table>\n    <tr>\n        <td>Something else</td>\n    </tr>\n</table>\n"""\ntable = BeautifulSoup(html_table_string, "html.parser")\n\n# Select first td element and set it\'s content to \'Something\'\ntable.select_one(\'td\').string = \'Something\'  # or table.find(\'td\').string = \'Something\'\n\nprint(table.prettify())\n']], ['Modifying HTML using python html package'], 2, 1], [(35560606, 1), [['Prints:'], ['-10000']], [[' <table>\n <tr>\n  <td>\n   Something\n  </td>\n </tr>\n</table>\n']], ['Modifying HTML using python html package'], 2, 0], [(35561635, 1), [['Configuration:'], ['-10000']], [[' python 2.7\naltgraph==0.9\napptools==4.3.0\nbbfreeze==1.1.3\nbbfreeze-loader==1.1.0\nconfigobj==5.0.6\ncx-Freeze==4.3.3\nCython==0.23.4\nmatplotlib==1.4.3\nmayavi==4.4.3\nMySQL-python==1.2.5\nnatgrid==0.2.1\nnumpy==1.10.0b1\nopencv-python==2.4.12\npandas==0.16.2\npefile==1.2.10.post114\nPillow==3.1.1\nplyfile==0.4\npsutil==4.1.0\npyface==5.0.0\nPygments==2.0.2\npygobject==2.28.6\npygtk==2.22.0\nPyInstaller==3.1\npyparsing==2.0.3\npypiwin32==219\nPySide==1.2.2\npython-dateutil==2.4.2\npytz==2015.4\nscipy==0.16.0\nsix==1.9.0\nsubprocess32==3.2.7\ntraits==4.5.0\ntraitsui==5.0.0\ntransforms3d==0.2.1\nVTK==6.2.0\n']], ['Packaging a python application ( with enthought, matplotlib, wxpython) into executable'], 2, 0], [(35580801, 0), [['Funcy  (a library offering various useful utilities, supporting both Python 2 and 3) offers a  chunks  function  that does exactly this:'], ['Alternatively, you could include a simple implementation of this in your program (compatible with both Python 2.7 and 3):']], [[" >>> import funcy\n>>> data = b'abcdefghijklmnopqrstuvwxyz'\n>>> list(funcy.chunks(6, data))\n[b'abcdef', b'ghijkl', b'mnopqr', b'stuvwx', b'yz']   # Python 3\n['abcdef', 'ghijkl', 'mnopqr', 'stuvwx', 'yz']        # Python 2.7\n"]], ['Chunking bytes (not strings) in Python 2 and 3'], 3, 1], [(35580801, 1), [['Alternatively, you could include a simple implementation of this in your program (compatible with both Python 2.7 and 3):'], ["It behaves the same (at least for your data; Funcy's  chunks  also works with iterators, this doesn't):"]], [[' def chunked(size, source):\n    for i in range(0, len(source), size):\n        yield source[i:i+size]\n']], ['Chunking bytes (not strings) in Python 2 and 3'], 3, 1], [(35580801, 2), [["It behaves the same (at least for your data; Funcy's  chunks  also works with iterators, this doesn't):"], ['-10000']], [[" >>> list(chunked(6, data))\n[b'abcdef', b'ghijkl', b'mnopqr', b'stuvwx', b'yz']   # Python 3\n['abcdef', 'ghijkl', 'mnopqr', 'stuvwx', 'yz']        # Python 2.7\n"]], ['Chunking bytes (not strings) in Python 2 and 3'], 3, 0], [(35595836, 0), [['pysvn.Client.info  will raise  pysvn.ClientError  if you pass non working copy directory:'], ['You can use that behavior. By catching the exception:']], [[' >>> import pysvn\n>>> client = pysvn.Client()\n>>> client.info(\'/tmp\')\nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\npysvn._pysvn_2_7.ClientError: \'/tmp\' is not a working copy\n']], ['pysvn: How to find out if local dir is under version control?'], 2, 1], [(35596269, 0), [['Try to do it like this:'], ['Note that what you do here is to split the line first into list of string. ']], [[' file = open(\'1qib.pdb\', \'r\')\nfile2 = open(\'new.pdb\', \'w\')\n\nfor i, line in enumerate(file):\n    spl = line.split() #1\n    spl[4] = spl[4].replace("A", "B") #2\n    newline = " ".join(spl) #3\n    file2.write(newline) #4\n\nfile.close()\nfile2.close()\n']], ['Replacing strings in specific positions into a text and then rewriting all the text'], 5, 1], [(35596269, 1), [['Note that what you do here is to split the line first into list of string. '], ['-10000']], [[' spl = line.split()\n']], ['Replacing strings in specific positions into a text and then rewriting all the text'], 5, 0], [(35596269, 2), [['-10000'], ['-10000']], [[' spl[4] = spl[4].replace("A", "B")\n']], ['Replacing strings in specific positions into a text and then rewriting all the text'], 5, 0], [(35596269, 3), [['-10000'], ['-10000']], [[' newline = " ".join(spl)\n']], ['Replacing strings in specific positions into a text and then rewriting all the text'], 5, 0], [(35596269, 4), [['-10000'], ['-10000']], [[' file2.write(newline)\n']], ['Replacing strings in specific positions into a text and then rewriting all the text'], 5, 0], [(35608326, 1), [['The code below works, taken from  Examples . '], ['-10000']], [[' rdd = sc.textFile("file:///path/*.txt")\ncounts = rdd.flatMap(lambda line: line.split(" ")) \\\n...              .map(lambda word: (word, 1)) \\\n...              .reduceByKey(lambda a, b: a + b)\n\ncounts.coalesce(1).saveAsTextFile("res.csv")\n']], ['pyspark - multiple input files into one RDD and one output file'], 2, 1], [(35609991, 0), [['-10000'], ['\xa0']], [[" >>> class1 = { 'Ethan':'9','Ian':'3','Helen':'8','Holly':'6' }\n>>> print(sorted(class1.items()))\n[('Ethan', '9'), ('Helen', '8'), ('Holly', '6'), ('Ian', '3')]\n"]], ['How do I print a sorted Dictionary in Python 3.4.3'], 3, 1], [(35609991, 1), [['\xa0'], ['\xa0']], [[' >>> for k,v in sorted(class1.items()):\n...     print(k, v)\n...\nEthan 9\nHelen 8\nHolly 6\nIan 3\n']], ['How do I print a sorted Dictionary in Python 3.4.3'], 3, 1], [(35609991, 2), [['\xa0'], ['-10000']], [[' >>> for k,v in sorted(class1.items(), key=lambda p:p[1]):\n...     print(k,v)\n...\nIan 3\nHolly 6\nHelen 8\nEthan 9\n\n>>> for k,v in sorted(class1.items(), key=lambda p:p[1], reverse=True):\n...     print(k,v)\n...\nEthan 9\nHelen 8\nHolly 6\nIan 3\n']], ['How do I print a sorted Dictionary in Python 3.4.3'], 3, 1], [(35611992, 0), [['Every time you return, you are quitting the function.  Here is the updated code:'], ['Output:']], [[' def listcleaner(lst):\n    if not lst:   # If list is empty\n        return [] # Go no further\n    if isinstance(lst[0], list):\n        if lst[0]: # If the list has something in it, we want to run listcleaner() on it.\n            return [listcleaner(lst[0])] + listcleaner(lst[1:])\n        else: # Otherwise, just skip that list\n            return listcleaner(lst[1:])\n    else:\n        return [lst[0]] + listcleaner(lst[1:]) # If it is not a list, return it unchanged plus listcleaner() on the rest.\n\na = listcleaner([1, [], [2, []], 5]) \nprint(a)\n']], ['recursive way to go through a nested list and remove all of a select value'], 2, 1], [(35611992, 1), [['Output:'], ['-10000']], [[' [1, [2], 5]\n']], ['recursive way to go through a nested list and remove all of a select value'], 2, 0], [(35619038, 0), [['Something like this will do:'], ['To test:']], [[' s = set(range(0, 100))\nlast5 = []\ndef get_next_number():\n    reduced_list = list(s - set(last5))\n    i = randint(0, len(reduced_list) - 1)\n    last5.append(reduced_list[i])\n    if len(last5) > 5:\n        last5.pop(0)\n    return reduced_list[i]\n']], ['Generate random numbers without using the last n values in Python'], 7, 1], [(35619038, 1), [['To test:'], ['-10000']], [[' result = []\nfor i in range(0, 5000):\n    result.append(get_next_number())\nprint(result)\n']], ['Generate random numbers without using the last n values in Python'], 7, 0], [(35619038, 2), [['-10000'], ['-10000']], [[' s = set(range(0, 100))\nlast5 = []\n']], ['Generate random numbers without using the last n values in Python'], 7, 0], [(35619038, 3), [['-10000'], ['-10000']], [[' reduced_list = list(s - set(last5))\n']], ['Generate random numbers without using the last n values in Python'], 7, 0], [(35619038, 4), [['-10000'], ['-10000']], [[' i = randint(0, len(reduced_list) - 1) #get any valid index. -1 is needed because randint upperbound is inclusive\nlast5.append(reduced_list[i]) #the number is as what it pointed by the index: reduced_list[i], append that number to the last 5 list\n']], ['Generate random numbers without using the last n values in Python'], 7, 0], [(35619038, 5), [['-10000'], ['-10000']], [[' if len(last5) > 5:\n    last5.pop(0)\n']], ['Generate random numbers without using the last n values in Python'], 7, 0], [(35619038, 6), [['-10000'], ['-10000']], [[' return reduced_list[i]\n']], ['Generate random numbers without using the last n values in Python'], 7, 0], [(35631192, 0), [['The first constraint  x > 0  can be expressed very simply:'], ["The second constraint is an equality constraint, which COBYLA doesn't natively support. However, you could express it as two separate inequality constraints instead:"]], [[" {'type':'ineq', 'fun': lambda x: x}\n"]], ['Element-wise constraints in scipy.optimize.minimize'], 2, 0], [(35631192, 1), [["The second constraint is an equality constraint, which COBYLA doesn't natively support. However, you could express it as two separate inequality constraints instead:"], ['Otherwise you could try SLSQP instead, which does support equality constraints.']], [[" {'type':'ineq', 'fun': lambda x: np.sum(x, 0) - 1}  # row sum >= 1\n{'type':'ineq', 'fun': lambda x: 1 - np.sum(x, 0)}  # row sum <= 1\n"]], ['Element-wise constraints in scipy.optimize.minimize'], 2, 0], [(35633421, 0), [["As for removing a few contour lines, here's a solution which is based on directly removing contour lines individually. You have to loop over the  collections  of the object returned by  contour() , and for each element check each  Path , and delete the ones you don't need. Redrawing the  figure 's canvas will get rid of the unnecessary lines:"], ['All in all it seems quite reasonable.']], [[' # dummy example based on matplotlib.pyplot.clabel example:\nimport matplotlib\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx = np.arange(-3.0, 3.0, delta)\ny = np.arange(-2.0, 2.0, delta)\nX, Y = np.meshgrid(x, y)\nZ1 = mlab.bivariate_normal(X, Y, 1.0, 1.0, 0.0, 0.0)\nZ2 = mlab.bivariate_normal(X, Y, 1.5, 0.5, 1, 1)\n# difference of Gaussians\nZ = 10.0 * (Z2 - Z1)\n\n\nplt.figure()\nCS = plt.contour(X, Y, Z)\n\nfor level in CS.collections:\n    for kp,path in reversed(list(enumerate(level.get_paths()))):\n        # go in reversed order due to deletions!\n\n        # include test for "smallness" of your choice here:\n        # I\'m using a simple estimation for the diameter based on the\n        #    x and y diameter...\n        verts = path.vertices # (N,2)-shape array of contour line coordinates\n        diameter = np.max(verts.max(axis=0) - verts.min(axis=0))\n\n        if diameter<1: # threshold to be refined for your actual dimensions!\n            del(level.get_paths()[kp])  # no remove() for Path objects:(\n\n# this might be necessary on interactive sessions: redraw figure\nplt.gcf().canvas.draw()\n']], ['How to remove/omit smaller contour lines using matplotlib'], 3, 1], [(35633421, 2), [[' '], ["You can freely play around with the grids used for interpolation, in this case I just used the original mesh, as it was at hand. You can also play around with different kinds of interpolation: the default  'linear'  one will be faster, but less smooth."]], [[" import scipy.interpolate as interp   #the new one\n\n# assume you have X,Y,Z,levels defined as before\n\n# start resampling stuff\ndN = 10 # use every dN'th element of the gridded input data\nmy_slice = [slice(None,None,dN),slice(None,None,dN)]\n\n# downsampled data\nX2,Y2,Z2 = X[my_slice],Y[my_slice],Z[my_slice]\n# same as X2 = X[::dN,::dN] etc.\n\n# upsampling with griddata over original mesh\nZsmooth = interp.griddata(np.array([X2.ravel(),Y2.ravel()]).T,Z2.ravel(),(X,Y),method='cubic')\n\n# plot\nplt.figure()\nCS = plt.contour(X, Y, Zsmooth, colors='b', linewidths=2, levels=levels)\n"]], ['How to remove/omit smaller contour lines using matplotlib'], 3, 0], [(35636806, 0), [['Register a dynamic authorizer for the user role that session was assigned when joining/authenticating:'], ['Write a class']], [['            {\n              "name": "authorizer",\n              "permissions": [\n                {\n                  "uri": "com.example.authorize",\n                  "register": true\n                }\n              ]\n            },\n            {\n              "name": "authenticator",\n              "permissions": [\n                {\n                  "uri": "com.example.authenticate",\n                  "register": true\n                }\n              ]\n            },\n            {\n              "name": "user",\n              "authorizer": "com.example.authorize"\n            },\n...\n"components": [\n    {\n      "type": "class",\n      "classname": "example.AuthenticatorSession",\n      "realm": "realm1",\n      "role": "authenticator",\n      "extra": {\n        "backend_base_url": "http://localhost:8080/ws"\n      }\n    },\n    {\n      "type": "class",\n      "classname": "example.AuthorizerSession",\n      "realm": "realm1",\n      "role": "authorizer"\n    }\n  ]\n']], ['Authentication to use for user notifications using Crossbar/Autobahn?'], 2, 0], [(35636806, 1), [['Write a class'], ['-10000']], [[' class AuthorizerSession(ApplicationSession):\n    @inlineCallbacks\n    def onJoin(self, details):\n        print("In AuthorizerSession.onJoin({})".format(details))\n        try:\n            yield self.register(self.authorize, \'com.example.authorize\')\n            print("AuthorizerSession: authorizer registered")\n        except Exception as e:\n            print("AuthorizerSession: failed to register authorizer procedure ({})".format(e))\n\n    def authorize(self, session, uri, action):\n        print("AuthorizerSession.authorize({}, {}, {})".format(session, uri, action))\n        if session[\'authrole\'] == u\'backend\':  # backnend can do whatever\n            return True\n        [Authorization logic here]\n        return authorized\n']], ['Authentication to use for user notifications using Crossbar/Autobahn?'], 2, 0], [(35656186, 0), [['Step 1: Add a complex values to your cluster. Run'], ['Add a line like']], [[' qconf -mc\n']], ['Sun Grid Engine, force one job per node'], 4, 0], [(35656186, 1), [['Add a line like'], ['Step 2: For each of your nodes, define a value for that complex value.']], [[' exclusive        excl      INT         <=    YES         YES        0        0\n']], ['Sun Grid Engine, force one job per node'], 4, 0], [(35656186, 2), [['Step 2: For each of your nodes, define a value for that complex value.'], ['Here we set exclusive to 1. Then, when you launch jobs, request "1" of that resource. Eg.:']], [[' qconf -rattr exechost complex_values exclusive=1 <nodename>\n']], ['Sun Grid Engine, force one job per node'], 4, 0], [(35656186, 3), [['Here we set exclusive to 1. Then, when you launch jobs, request "1" of that resource. Eg.:'], ['If you were willing to have 2 jobs per node, you could define that value to 2 at step 2.']], [[' qrsh -l exclusive=1 <myjob>\n']], ['Sun Grid Engine, force one job per node'], 4, 0], [(35664103, 0), [['-10000'], ['To use it:']], [[" class PushbackWrapper(object):\n\n    def __init__(self, iterator):\n        self.__dict__['_iterator'] = iterator\n        self.__dict__['_pushed'] = []\n\n    def next(self):\n        if len(self._pushed):\n            return self._pushed.pop()\n        else:\n            return self._iterator.next()\n\n    def pushback(self, item):\n        self._pushed.append(item)\n\n    def __getattr__(self, attr):\n        return getattr(self._iterator, attr)\n\n    def __setattr__(self, attr, value):\n        return setattr(self._iterator, attr, value)\n"]], ['Iterator that supports pushback'], 2, 1], [(35664103, 1), [['To use it:'], ['-10000']], [[' pushback_enabled_iterator = PushbackWrapper(original_iterator)\n\nitem = next(pushback_enabled_iterator)\nif went_too_far(item):\n    pushback_enabled_iterator.pushback(item)\n    break;\n']], ['Iterator that supports pushback'], 2, 0], [(35667931, 0), [['Create the set union of all tuples, then sort the result:'], ['Demo:']], [[' sorted(set().union(*input_list))\n']], ['How to transform a pair of values into a sorted unique array?'], 2, 1], [(35667931, 1), [['Demo:'], ['-10000']], [[' >>> input_list = [(196, 128), (196, 128), (196, 128), (128, 196),\n...  (196, 128), (128, 196), (128, 196), (196, 128),\n...  (128, 196), (128, 196)]\n>>> sorted(set().union(*input_list))\n[128, 196]\n']], ['How to transform a pair of values into a sorted unique array?'], 2, 1], [(35668472, 0), [["Assuming the inputs are NumPy arrays and that there are no duplicates within each row of  A , here's an approach using  np.in1d  -"], ['Sample run -']], [[' A[np.in1d(A,B).reshape(A.shape).sum(1) == len(B)]\n']], ['How can i search a array from a large array by numpy'], 2, 1], [(35668472, 1), [['Sample run -'], ['-10000']], [[" In [23]: A\nOut[23]: \narray([['03', '04', '18', '22', '25', '29', '30'],\n       ['02', '04', '07', '09', '14', '29', '30'],\n       ['06', '08', '11', '13', '17', '19', '30'],\n       ['04', '08', '22', '23', '27', '29', '30'],\n       ['03', '05', '15', '22', '24', '25', '30']], \n      dtype='|S2')\n\nIn [24]: B\nOut[24]: \narray(['04', '22'], \n      dtype='|S2')\n\nIn [25]: A[np.in1d(A,B).reshape(A.shape).sum(1) == len(B)]\nOut[25]: \narray([['03', '04', '18', '22', '25', '29', '30'],\n       ['04', '08', '22', '23', '27', '29', '30']], \n      dtype='|S2')\n"]], ['How can i search a array from a large array by numpy'], 2, 1], [(35678083, 0), [['The list comprehension approach is:'], ['The other approach is to use the  str.contains  method to check whether the values of the  Series  column contain a given string or match a given regular expression (used in this case as we are using multiple strings):']], [[" vc = df['Series'].value_counts()\nu  = [i not in set(vc[vc==1].index) for i in df['Series']]\ndf = df[u]\n"]], ['Pandas: Delete rows of a DataFrame if total count of a particular column occurs only 1 time'], 2, 1], [(35678083, 1), [['The other approach is to use the  str.contains  method to check whether the values of the  Series  column contain a given string or match a given regular expression (used in this case as we are using multiple strings):'], ["Using this regular expressions approach is a bit more hackish and may require some extra processing (character escaping, etc) on  pat  in case you have regex metacharacters in the strings you want to filter out (which requires some basic regex knowledge). However, it's worth noting this approach is about 4x faster than using the list comprehension approach (tested on the data provided in the question)."]], [[" vc  = df['Series'].value_counts()\npat = r'|'.join(vc[vc==1].index)          #Regular expression\ndf  = df[~df['Series'].str.contains(pat)] #Tilde is to negate boolean\n"]], ['Pandas: Delete rows of a DataFrame if total count of a particular column occurs only 1 time'], 2, 1], [(35707475, 0), [['This can help you.....'], ['Example:']], [[" def calc(x=0, y=0, z=0):\n    expression = raw_input('Enter an expression: ')\n\n    return eval(expression, None, locals())\n"]], ['Sum of calculation in a variable'], 2, 1], [(35707475, 1), [['Example:'], ['-10000']], [[' >>> calc()\nEnter an expression: 8 + 5 - 7\n6\n']], ['Sum of calculation in a variable'], 2, 0], [(35720234, 0), [['You can use  concat with  str.get_dummies :'], ['Or as  Edchum  mentioned in comments -  pd.get_dummies :']], [[" print pd.concat([df['ID'], df['Word'].str.get_dummies()], axis=1)\n   ID  and  it  long  road  take  the  walk\n0   1    0   0     0     0     1    0     0\n1   2    0   0     0     0     0    1     0\n2   3    0   0     1     0     0    0     0\n3   4    0   0     1     0     0    0     0\n4   5    0   0     0     1     0    0     0\n5   6    1   0     0     0     0    0     0\n6   7    0   0     0     0     0    0     1\n7   8    0   1     0     0     0    0     0\n8   9    0   0     0     0     0    0     1\n9  10    0   1     0     0     0    0     0\n"]], ['Pivotting via Python and Pandas'], 2, 1], [(35720234, 1), [['Or as  Edchum  mentioned in comments -  pd.get_dummies :'], ['-10000']], [[" print pd.concat([df['ID'], pd.get_dummies(df['Word'])], axis=1)\n   ID  and  it  long  road  take  the  walk\n0   1    0   0     0     0     1    0     0\n1   2    0   0     0     0     0    1     0\n2   3    0   0     1     0     0    0     0\n3   4    0   0     1     0     0    0     0\n4   5    0   0     0     1     0    0     0\n5   6    1   0     0     0     0    0     0\n6   7    0   0     0     0     0    0     1\n7   8    0   1     0     0     0    0     0\n8   9    0   0     0     0     0    0     1\n9  10    0   1     0     0     0    0     0\n"]], ['Pivotting via Python and Pandas'], 2, 1], [(35720330, 0), [['Just filter and select:'], ['or with  col']], [[' result = users_df.where(users_df._id == chosen_user).select("gender")\n']], ['Getting specific field from chosen Row in Pyspark DataFrame'], 4, 0], [(35720330, 1), [['or with  col'], ['Finally PySpark  Row  is just a  tuple  with some extensions so you can for example  flatMap :']], [[' from pyspark.sql.functions import col\n\nresult = users_df.where(col("_id") == chosen_user).select(col("gender"))\n']], ['Getting specific field from chosen Row in Pyspark DataFrame'], 4, 0], [(35720330, 2), [['Finally PySpark  Row  is just a  tuple  with some extensions so you can for example  flatMap :'], ['or  map  with something like this:']], [[' result.rdd.flatMap(list).first()\n']], ['Getting specific field from chosen Row in Pyspark DataFrame'], 4, 0], [(35720330, 3), [['or  map  with something like this:'], ['-10000']], [[' result.rdd.map(lambda x: x.gender).first()\n']], ['Getting specific field from chosen Row in Pyspark DataFrame'], 4, 0], [(35734026, 1), [['Sample output:'], ['The following function generalizes that to choosing  m  balls given an array  colors  holding the number of each color:']], [[' red:    6\ngreen:  1\nblue:   8\n']], ['Numpy drawing from urn'], 4, 0], [(35734026, 3), [['For example,'], ['-10000']], [[' >>> sample(10, [2, 4, 8, 16])\narray([2, 3, 1, 4])\n']], ['Numpy drawing from urn'], 4, 0], [(35774261, 0), [['A test text list, equivalent to a file:'], ['Process it line by line']], [[' In [840]: txt=b"""1,0,0,2,3\n0,0,0,0,0\n4,0,0,0,0\n0,0,0,3,0\n""".splitlines()\nIn [841]: \nIn [841]: np.loadtxt(txt,delimiter=\',\',dtype=int)\nOut[841]: \narray([[1, 0, 0, 2, 3],\n       [0, 0, 0, 0, 0],\n       [4, 0, 0, 0, 0],\n       [0, 0, 0, 3, 0]])\n']], ['Read a dense matrix from a file directly into a sparse numpy array?'], 5, 0], [(35774261, 1), [['Process it line by line'], ['Now turn each array into a  coo  matrix:']], [[" In [842]: ll=[]\nIn [843]: for line in txt:\n    ll.append(np.loadtxt([line],delimiter=','))\n   .....:     \nIn [844]: ll\nOut[844]: \n[array([ 1.,  0.,  0.,  2.,  3.]),\n array([ 0.,  0.,  0.,  0.,  0.]),\n array([ 4.,  0.,  0.,  0.,  0.]),\n array([ 0.,  0.,  0.,  3.,  0.])]\n"]], ['Read a dense matrix from a file directly into a sparse numpy array?'], 5, 0], [(35774261, 2), [['Now turn each array into a  coo  matrix:'], ["and assemble the list with  bmat  (a 'cover' for  bsr_matrix ):"]], [[" In [845]: lc=[[sparse.coo_matrix(l)] for l in ll]\nIn [846]: lc\nOut[846]: \n[[<1x5 sparse matrix of type '<class 'numpy.float64'>'\n    with 3 stored elements in COOrdinate format>],\n [<1x5 sparse matrix of type '<class 'numpy.float64'>'\n    with 0 stored elements in COOrdinate format>],\n [<1x5 sparse matrix of type '<class 'numpy.float64'>'\n    with 1 stored elements in COOrdinate format>],\n [<1x5 sparse matrix of type '<class 'numpy.float64'>'\n    with 1 stored elements in COOrdinate format>]]\n"]], ['Read a dense matrix from a file directly into a sparse numpy array?'], 5, 0], [(35774261, 3), [["and assemble the list with  bmat  (a 'cover' for  bsr_matrix ):"], ['To process the text in 2 line chunks:']], [[" In [847]: B=sparse.bmat(lc)\nIn [848]: B\nOut[848]: \n<4x5 sparse matrix of type '<class 'numpy.float64'>'\n    with 5 stored elements in COOrdinate format>\nIn [849]: B.A\nOut[849]: \narray([[ 1.,  0.,  0.,  2.,  3.],\n       [ 0.,  0.,  0.,  0.,  0.],\n       [ 4.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  3.,  0.]])\n"]], ['Read a dense matrix from a file directly into a sparse numpy array?'], 5, 0], [(35775207, 0), [['The broadest solution is to set  trim_blocks  and  lstrip_blocks  on the env.'], ['You can use control characters to modify how the whitespace around a block works.   -  always removes whitespace,  +  always preserves it, overriding the env settings for that block.  The character can go at the beginning or end (or both) of a block to control the whitespace in that direction.']], [[' app.jinja_env.trim_blocks = True\napp.jinja_env.lstrip_blocks = True\n']], ['Remove unnecessary whitespace from Jinja rendered template'], 2, 1], [(35775207, 1), [['You can use control characters to modify how the whitespace around a block works.   -  always removes whitespace,  +  always preserves it, overriding the env settings for that block.  The character can go at the beginning or end (or both) of a block to control the whitespace in that direction.'], ['Note that the control characters only apply to templates  you  write.  If you include a template or use a macro from a 3rd party, however they wrote the template will apply to that part.']], [[' {%- if ... %} strips before\n{% if ... +%} preserves after\n{%+ if ... -%} preserves before and strips after\nremember that `{% endif %}` is treated separately\n']], ['Remove unnecessary whitespace from Jinja rendered template'], 2, 0], [(35781083, 0), [['A solution that should work for an arbitrary length of  one :'], ['Or with a dict-comp:']], [[' d = {}\n\n# Create a 1-to-1 mapping for the first n-1 items in `one`\nfor i in one[:-1]:\n    d[i] = [elements.pop(0)]\n\n# Append the remainder of `elements`\nd[one[-1]] = [elements]\n']], ['python- combining list and making them a dictionary'], 3, 1], [(35781083, 1), [['Or with a dict-comp:'], ['Or in one nice easy-to-read line:']], [[' d = {i:[elements.pop(0)] for i in one[:-1]}.\nd[one[-1]] = [elements]\n']], ['python- combining list and making them a dictionary'], 3, 1], [(35781083, 2), [['Or in one nice easy-to-read line:'], ['-10000']], [[' d = {i:[elements.pop(0)] for i in one[:-1]}.update({one[-1]:[elements]})\n']], ['python- combining list and making them a dictionary'], 3, 1], [(35787294, 1), [['Test script:'], ['Output:']], [[' import hello\n\na1 = hello.A(1,2)\na2 = hello.A(3,4)\nret = hello.get_a(a1, a2)\nprint "size:", len(ret)\nprint "values:"\nfor x in ret:\n  print x.a, x.b \n']], ['expose C++ function to python'], 3, 0], [(35787294, 2), [['Output:'], ['-10000']], [[' size: 2\nvalues:\n1 2\n3 4\n']], ['expose C++ function to python'], 3, 0], [(35805891, 0), [['I would split it into two functions: one which checks if a list contains only even numbers, and the other one is your main function (I renamed it to  get_even_lists() ), which gets all the even lists from a list of lists:'], ['Although, this  could  be done with  for / else :']], [[' def only_even_elements(l):\n    """ (list of int) -> bool\n\n    Return a whether a list contains only even integers.\n\n    >>> only_even_elements([1, 2, 4])  # 1 is not even\n    False\n    """\n    for e in l:\n        if e % 2 == 1:\n            return False\n    return True\n\ndef get_even_lists(lst):\n    """ (list of list of int) -> list of list of int\n\n    Return a list of the lists in lst that contain only even integers. \n\n    >>> only_evens([[1, 2, 4], [4, 0, 6], [22, 4, 3], [2]])\n    [[4, 0, 6], [2]]\n    """\n    # return [l for l in lst if only_even_elements(l)]\n    even_lists = []\n    for sublist in lst:\n        if only_even_elements(sublist):\n            even_lists.append(sublist)\n    return even_lists\n']], ['How to get only even numbers from list'], 3, 1], [(35805891, 1), [['Although, this  could  be done with  for / else :'], ['Or as others have suggested, a one-liner:']], [[' def get_even_lists(lst):\n    """ (list of list of int) -> list of list of int\n\n    Return a list of the lists in lst that contain only even integers. \n\n    >>> only_evens([[1, 2, 4], [4, 0, 6], [22, 4, 3], [2]])\n    [[4, 0, 6], [2]]\n    """\n    even_lists = []\n    for sublist in lst:\n        for i in sublist:\n            if i % 2 == 1:\n                break\n        else:\n            even_lists.append(sublist)\n    return even_lists\n']], ['How to get only even numbers from list'], 3, 1], [(35805891, 2), [['Or as others have suggested, a one-liner:'], ['But let\'s be honest here: while it\'s arguable that using two functions might be a bit longer and not as "cool" as the other two solutions, it\'s reusable, easy to read and understand, and it\'s maintainable. I\'d argue it\'s much better than any other option out there.']], [[' def get_even_lists(lst):\n    """ (list of list of int) -> list of list of int\n\n    Return a list of the lists in lst that contain only even integers. \n\n    >>> only_evens([[1, 2, 4], [4, 0, 6], [22, 4, 3], [2]])\n    [[4, 0, 6], [2]]\n    """\n    return [sublst for sublst in lst if all(i % 2 == 0 for i in sublst)]\n']], ['How to get only even numbers from list'], 3, 1], [(35840403, 0), [['Just a straight  for  loop is probably easier than a list comprehension:'], ['Slightly shorter (and including a list comprehension):']], [[' data = [(0.0, 287999.70000000007),\n(1.0, 161123.23000000001),\n(2.0, 93724.140000000014),\n(3.0, 60347.309999999983),\n(4.0, 55687.239999999998),\n(5.0, 29501.349999999999),\n(6.0, 14993.920000000002),\n(7.0, 14941.970000000001),\n(8.0, 13066.229999999998),\n(9.0, 10101.040000000001),\n(10.0, 4151.6900000000005),\n(11.0, 2998.8899999999999),\n(12.0, 1548.9300000000001),\n(15.0, 1595.54),\n(16.0, 1435.98),\n(17.0, 1383.01)]\n\nresult = []\nlast = 0.0\nfor d in data:\n    while last < d[0]:\n        result.append((last, 0))\n        last += 1\n    result.append(d)\n    last = d[0]+1\n']], ['Python - filling a list of tuples with zeros in places of missing indexes'], 2, 1], [(35840403, 1), [['Slightly shorter (and including a list comprehension):'], ['-10000']], [[' result, last = [], 0.0\nfor d in data:\n    result.extend((r,0) for r in range(int(last), int(d[0])))\n    result.append(d)\n    last = d[0]+1\n']], ['Python - filling a list of tuples with zeros in places of missing indexes'], 2, 1], [(35847865, 0), [['You can add parameter  sort=False  in  value_counts :'], ['Or add  sort_index :']], [[' print df.value_counts()\nawful    2\ngood     2\nbad      2\nok       1\ndtype: int64\n\nprint df.value_counts(sort=False)\nbad      2\nok       1\ngood     2\nawful    2\ndtype: int64\n\nprint df.value_counts(sort=False).plot.bar()\n']], ['Retaining category order when charting/plotting ordered categorical Series'], 2, 1], [(35867650, 0), [['A simple way to parallelize that code would be to use a  Pool  of processes:'], ['It looks like you are running an outdated version of python. You can replace  starmap  with plain  map  but then you have to provide a function that takes a single parameter:']], [[' pool = multiprocessing.Pool()\nresults = pool.starmap(get_sub_matrix_C, ((i, other_args) for i in range(10)))\n\nfor i, res in enumerate(results):\n    C[i*10:(i+1)*10,:10] = res\n']], ['Python multiprocessing and shared numpy array'], 2, 1], [(35867650, 1), [['It looks like you are running an outdated version of python. You can replace  starmap  with plain  map  but then you have to provide a function that takes a single parameter:'], ['-10000']], [[' def f(args):\n    return get_sub_matrix_C(*args)\n\npool = multiprocessing.Pool()\nresults = pool.map(f, ((i, other_args) for i in range(10)))\n\nfor i, res in enumerate(results):\n    C[i*10:(i+1)*10,:10] = res\n']], ['Python multiprocessing and shared numpy array'], 2, 1], [(35890697, 0), [['Write a function to extract the date from your string with a regular expression, and use that as key to  sorted :'], ['prints:']], [[" import re\n\nl = ['',\n     'q//Attachments/Swoop_coverletter_311386_20120103.doc',\n     'q//Attachments/Swoop_RESUME_311386_20091012.doc',\n     'q//Attachments/Swoop_Resume_311386_20100901.doc',\n     'q//Attachments/Swoop_reSume_311386_20120103.doc',\n     'q//Attachments/Swoop_coverletter_311386_20100901.doc',\n     'q//Attachments/Swoop_coverletter_311386_20091012.doc']\n\ndef get_date(line):\n    pattern = '.*_(\\d{8}).doc'\n    m = re.match(pattern, line)\n    if m:\n        return int(m.group(1))\n    else:\n        return -1 # or do something else with lines that contain no date\n\n\nprint sorted(l, key=get_date, reverse=True)\n"]], ['Python sorting array according to date'], 2, 1], [(35890697, 1), [['prints:'], ['-10000']], [[" ['q//Attachments/Swoop_coverletter_311386_20120103.doc', \n 'q//Attachments/Swoop_reSume_311386_20120103.doc', \n 'q//Attachments/Swoop_Resume_311386_20100901.doc', \n 'q//Attachments/Swoop_coverletter_311386_20100901.doc', \n 'q//Attachments/Swoop_RESUME_311386_20091012.doc', \n 'q//Attachments/Swoop_coverletter_311386_20091012.doc', \n '']\n"]], ['Python sorting array according to date'], 2, 0], [(35913509, 0), [['Yes it is possible. The interpolation returns a  callable  so you can just call it with your wanted grid:'], ['That was just to create some test data. To get what you want you need to evaluate the interpolation  b  on a grid of your choosing:']], [[' from scipy.interpolate import interp2d\nimport numpy as np\n\nx = 50\ny = 150\n\na = np.random.uniform(0,10,(y, x))\nb = interp2d(np.arange(x), np.arange(y), a)\n']], ['Array from interpolated plot in python'], 2, 0], [(35913509, 1), [['That was just to create some test data. To get what you want you need to evaluate the interpolation  b  on a grid of your choosing:'], ['That creates a grid with 2 times the number of elements that your original array had.']], [[' upsample_factor = 2\nc = b(np.linspace(0,x,x*upsample), np.linspace(0,y,y*upsample))\n']], ['Array from interpolated plot in python'], 2, 0], [(35952815, 0), [['I suppose you are using Python 2 but if not you should change the division when calculating the step to  //  (floor division) otherwise numpy will be annoyed that it cannot interpret floats as step.'], ['A completly vectorized approach could be used by defining a grid that knows which stars are in which bin:']], [[' binwidth = numpy.max(rev_count)//10 # Changed this to floor division\nrevbin = range(0, numpy.max(rev_count), binwidth)\nrevbinnedstars = [None]*len(revbin)\n\nfor i in range(0, len(revbin)-1):\n    # I actually don\'t know what you wanted to do but I guess you wanted the\n    # "logical and" combination in that bin (you don\'t need to use np.where here)\n    # You can put that all in one statement but it gets crowded so I\'ll split it:\n    index1 = revbin[i]-binwidth/2 < rev_count\n    index2 = rev_count < revbin[i]+binwidth/2)\n    revbinnedstars[i] = numpy.mean(stars[np.logical_and(index1, index2)])\n']], ['Python: Binning one coordinate and averaging another based on these bins'], 6, 1], [(35952815, 1), [['A completly vectorized approach could be used by defining a grid that knows which stars are in which bin:'], ['an even better approach for defining the bins would be. Beware that you have to add one to the maximum since you want to include it and one to the number of bins because you are interested in the bin-start and end-points not the center of the bins:']], [[' bins = 10\nbinwidth = numpy.max(rev_count)//bins\nrevbin = np.arange(0, np.max(rev_count)+binwidth+1, binwidth)\n']], ['Python: Binning one coordinate and averaging another based on these bins'], 6, 0], [(35952815, 2), [['an even better approach for defining the bins would be. Beware that you have to add one to the maximum since you want to include it and one to the number of bins because you are interested in the bin-start and end-points not the center of the bins:'], ['and then you can setup the grid:']], [[' number_of_bins = 10\nrevbin = np.linspace(np.min(rev_count), np.max(rev_count)+1, number_of_bins+1)\n']], ['Python: Binning one coordinate and averaging another based on these bins'], 6, 0], [(35952815, 3), [['and then you can setup the grid:'], ['So we can get the Y coordinates of the stars in the appropriate bin by just multiplying these with this grid:']], [[' grid = np.logical_and(rev_count[None, :] >= revbin[:-1, None], rev_count[None, :] < revbin[1:, None])\n']], ['Python: Binning one coordinate and averaging another based on these bins'], 6, 0], [(35952815, 4), [['So we can get the Y coordinates of the stars in the appropriate bin by just multiplying these with this grid:'], ['To calculate the mean we need the sum of the coordinates in this bin and divide it by the number of stars in that bin (bins are along the  axis=1 , stars that are not in this bin only have a value of zero along this axis):']], [[' stars * grid\n']], ['Python: Binning one coordinate and averaging another based on these bins'], 6, 0], [(35952815, 5), [['To calculate the mean we need the sum of the coordinates in this bin and divide it by the number of stars in that bin (bins are along the  axis=1 , stars that are not in this bin only have a value of zero along this axis):'], ["I actually don't know if that's more efficient. It'll be a lot more expensive in memory but maybe a bit less expensive in CPU."]], [[' revbinnedstars = np.sum(stars * grid, axis=1) / np.sum(grid, axis=1)\n']], ['Python: Binning one coordinate and averaging another based on these bins'], 6, 0], [(35962295, 0), [['Here are two ways to create this. First, the traditional  dict'], ['or using a  defaultdict :']], [[" dic = {}\ndic['New York'] = {}\ndic['New York']['Chicago'] = 25\n"]], ['How to create a Dictionary in Python with 2 string keys to access an integer?'], 2, 1], [(35962295, 1), [['or using a  defaultdict :'], ['-10000']], [[" from collections import defaultdict\ndic2 = defaultdict(dict)\ndic2['New York']['Chicago'] = 25\n"]], ['How to create a Dictionary in Python with 2 string keys to access an integer?'], 2, 1], [(35966940, 0), [['An example with a random input array, showing that you can take the  max  in either axis easily with one command.'], ['Output:']], [[' import numpy as np\n\naa= np.random.random([4,3]) \nprint aa\nprint\nprint np.max(aa,axis=0)\nprint\nprint np.max(aa,axis=1)\n']], ['finding the max of a column in an array'], 2, 1], [(35966940, 1), [['Output:'], ['-10000']], [[' [[ 0.51972266  0.35930957  0.60381998]\n [ 0.34577217  0.27908173  0.52146593]\n [ 0.12101346  0.52268843  0.41704152]\n [ 0.24181773  0.40747905  0.14980534]]\n\n[ 0.51972266  0.52268843  0.60381998]\n\n[ 0.60381998  0.52146593  0.52268843  0.40747905]\n']], ['finding the max of a column in an array'], 2, 0], [(36017497, 0), [['Sample Code'], ['Output']], [[' import random\ndef binarySearch(alist, item):\n        first = 0\n        last = len(alist) - 1\n        found = False\n\n        while first<=last and not found:\n            midpoint = (first + last)//2            \n            if alist[midpoint] == item:\n                found = True\n            else:\n                if item < alist[midpoint]:\n                    last = midpoint-1\n                else:\n                    first = midpoint+1  \n        return found\n\ndef findThisNum(mynum):\n\n    testlist = [x for x in range(listlength)]\n\n    print "testlist = ", testlist\n    print "finding number ", mynum\n\n    if (binarySearch(testlist, findnum)) == True:\n        print "found %d" %mynum\n    else:\n        print "Not found %d" %mynum\n\n\n\n\n#### Main_Function ####\n\nif __name__ == "__main__":\n    #\n\n    #Search 1 [ Even numbered list ]\n    listlength = 10    \n    findnum = random.randrange(0,listlength)\n    findThisNum(findnum)     \n\n    #Search 2 [ [ Odd numbered list ]\n    listlength = 13    \n    findnum = random.randrange(0,listlength)\n    findThisNum(findnum)\n\n    #search 3  [ find item not in the list ]\n\n    listlength = 13    \n    findnum = random.randrange(0,listlength) + listlength\n    findThisNum(findnum)\n']], ['Binary search of a number within a list in Python'], 2, 1], [(36017497, 1), [['Output'], ['-10000']], [[' Python 2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)] on win32\nType "copyright", "credits" or "license()" for more information.\n>>> ================================ RESTART ================================\n>>> \ntestlist =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nfinding number  4\nfound 4\ntestlist =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\nfinding number  9\nfound 9\ntestlist =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\nfinding number  21\nNot found 21\n']], ['Binary search of a number within a list in Python'], 2, 0], [(36041797, 0), [["The second option of  open ,  w , will overwrite the file's contents. Use  a  to append instead, but also put a newline character  \\n  after each line."], ['The other, more efficient way to do it is to move your file-writing code outside the loop, like this:']], [[' def random_grid(file):\n    grid = []\n    num_rows = raw_input("How many raws would you like in your grid? ")\n    num_columns = raw_input("How many columns would you like in your grid? ")\n    min_range = raw_input("What is the minimum number you would like in your grid? ")\n    max_range = raw_input("what is the maximum number you would like in your grid? ")\n    for row in range(int(num_rows)):\n        grid.append([])\n        for column in range(int(num_columns)):\n            grid[row].append(random.randint((int(min_range)),(int(max_range))))         \n    for row in grid:\n        x = (\' \'.join([str(x) for x in row])) \n        print x\n\n        with open(r"test.txt", \'a\') as text_file:\n            text_file.write(x)\n            text_file.write("\\n")\n']], ['Python list to txt'], 2, 1], [(36041797, 1), [['The other, more efficient way to do it is to move your file-writing code outside the loop, like this:'], ['-10000']], [[' def random_grid(file):\n    grid = []\n    num_rows = raw_input("How many raws would you like in your grid? ")\n    num_columns = raw_input("How many columns would you like in your grid? ")\n    min_range = raw_input("What is the minimum number you would like in your grid? ")\n    max_range = raw_input("what is the maximum number you would like in your grid? ")\n    for row in range(int(num_rows)):\n        grid.append([])\n        for column in range(int(num_columns)):\n            grid[row].append(random.randint((int(min_range)),(int(max_range))))    \n    x = ""\n    for row in grid:\n        x += (\' \'.join([str(x) for x in row])) + "\\n" \n        print x\n\n    with open(r"test.txt", \'w\') as text_file:\n        text_file.write(x)\n']], ['Python list to txt'], 2, 1], [(36050713, 0), [['You can use  PyList_New() ,  PyTuple_New() ,  PyList_Append() , and  PyTuple_SetItem()  to accomplish this...'], ['That will create a list of the form...']], [[' const Py_ssize_t tuple_length = 4;\nconst unsigned some_limit = 4;\n\nPyObject *my_list = PyList_New(0);\nif(my_list == NULL) {\n    // ...\n}\n\nfor(unsigned i = 0; i < some_limit; i++) {\n    PyObject *the_tuple = PyTuple_New(tuple_length);\n    if(the_tuple == NULL) {\n        // ...\n    }\n\n    for(Py_ssize_t j = 0; i < tuple_length; i++) {\n        PyObject *the_object = PyLong_FromSsize_t(i * tuple_length + j);\n        if(the_object == NULL) {\n            // ...\n        }\n\n        PyTuple_SET_ITEM(the_tuple, j, the_object);\n    }\n\n    if(PyList_Append(my_list, the_tuple) == -1) {\n        // ...\n    }\n}\n']], ['Using Py_BuildValue() to create a list of tuples in C'], 2, 1], [(36050713, 1), [['That will create a list of the form...'], ['-10000']], [[' [(0, 1, 2, 3), (4, 5, 6, 7), (8, 9, 10, 11), (12, 13, 14, 15)]\n']], ['Using Py_BuildValue() to create a list of tuples in C'], 2, 0], [(36061608, 0), [['You can use list comprehension:'], ["That will work only when there are single words in  b , but because of your edit and comment, I now know that you really do need  _find_word_and_remove() .  Your recursion way isn't really too bad, but if you don't want recursion, do this:"]], [[' def find_words_and_remove(words, strings):\n    return [" ".join(word for word in string.split() if word not in words) for string in strings]\n']], ['Erasing list of phrases from list of texts in python'], 2, 1], [(36061608, 1), [["That will work only when there are single words in  b , but because of your edit and comment, I now know that you really do need  _find_word_and_remove() .  Your recursion way isn't really too bad, but if you don't want recursion, do this:"], ['-10000']], [[' def find_words_and_remove(words, strings):\n    strings_copy = strings[:]\n    for i, word in enumerate(words):\n        for string in strings:\n            strings_copy[i] = _find_word_and_remove(word, string)\n    return strings_copy\n']], ['Erasing list of phrases from list of texts in python'], 2, 1], [(36066726, 0), [['Since the first character at each line is a string you\'ll have to use a more flexible type in numpy called "object". Try with this function and see if this is what you are looking for:'], ['The results are:']], [["     def readCSVToNumpyArray(dataset):\n        values = [[]]\n        with open(dataset) as f:\n            counter = 0\n            for i in csv.reader(f):\n                for j in i:\n                    try:\n                        values[counter].append(float(j))\n                    except ValueError:\n                        values[counter].append(j)\n                counter = counter + 1\n                values.append([])\n\n        data = numpy.array(values[:-1],dtype='object')\n\n        return data\n\n    numpyArray = readCSVToNumpyArray('test_data.csv')\n    print(numpyArray)\n"]], ['python - numpy: read csv into numpy with proper value type'], 2, 1], [(36066726, 1), [['The results are:'], ['-10000']], [["     [['A' 1.0 2.0 3.0 4.0 5.0]\n     ['B' 6.0 7.0 8.0 9.0 10.0]\n     ['C' 11.0 12.0 13.0 14.0 15.0]\n     ['A' 16.0 17.0 18.0 19.0 20.0]]\n"]], ['python - numpy: read csv into numpy with proper value type'], 2, 0], [(36071592, 0), [['You can use two dicts and find the  set difference  of the keys, where the keys are each first element:'], ['Output:']], [[' a = [["greg", 1.2, 400, 234], ["top", 9.0, 5.1, 2300], ["file", 5.7, 2.2, 900], ["stop", 1.6, 6.7, 200]]\n\nb = [["hall", 5.2, 460, 234], ["line", 5.3, 5.91, 100], ["file", 2.7, 3.3, 6.4], ["stop", 6.6, 5.7, 230]]\n\nd1 = {sub[0]: sub for sub in a}\nd2 = {sub[0]: sub for sub in b}\n\nprint([d2[k] for k in d2.keys() - d1])\nprint([d1[k] for k in d1.keys() - d2])\n']], ['Find difference between two multi dimensional lists'], 3, 1], [(36071592, 1), [['Output:'], ['The equivalent python 2 code would use need to use  viewkeys :']], [[" [['hall', 5.2, 460, 234], ['line', 5.3, 5.91, 100]]\n[['top', 9.0, 5.1, 2300], ['greg', 1.2, 400, 234]]\n"]], ['Find difference between two multi dimensional lists'], 3, 0], [(36071592, 2), [['The equivalent python 2 code would use need to use  viewkeys :'], ['-10000']], [[' print([d2[k] for k in d2.viewkeys() - d1])\nprint([d1[k] for k in d1.viewkeys() - d2])\n']], ['Find difference between two multi dimensional lists'], 3, 0], [(36086075, 0), [['Something like:'], ['Then you need a function to decide if two arrays match:']], [[" candidates = []\nresults = []\nfor line in my_file:\n    candidates.append(line.split('\\t'))\nfor line in candidates:\n    seen = false\n    for possible_match in results:\n        if matching_line(possible_match, line):\n            seen = true\n    if seen:\n        continue\n    else:\n        results.append(line)\n"]], ['Unique duplicate rows with range'], 2, 0], [(36086075, 1), [['Then you need a function to decide if two arrays match:'], ['-10000']], [[' function matching_line(array1, array2):\n    if array1[0] = array2[0]\n    ..etc\n']], ['Unique duplicate rows with range'], 2, 0], [(36144303, 0), [["You're better off making a dictionary. If you really want to make a bunch of variables, you'll have to use  globals() , which isn't really recommended."], ['OR']], [[' a = [["aa",1,3]\n     ["aa",3,3]\n     ["sdsd",1,3]\n     ["sdsd",6,0]\n     ["sdsd",2,5]\n     ["fffffff",1,3]]\n\nd = {}\nfor sub in a:\n    key = sub[0]\n    if key not in d: d[key] = []\n    d[key].append(sub)\n']], ['Python - split list of lists by value'], 2, 1], [(36144303, 1), [['OR'], ['-10000']], [[' import collections\n\nd = collections.defaultdict(list)\nfor sub in a:\n    d[sub[0]].append(sub)\n']], ['Python - split list of lists by value'], 2, 1], [(36149707, 0), [["As multiple comments have already suggested, don't do that.  Change the Python script so that it accepts a second parameter instead.  Modifying your code on the fly is brittle and complex, and the standard solution to that is to parametrize the things you want to change."], ['Then run the loop something like']], [[" QUERY = 'www.foo.com' + '/bar?' \\\n        + '&title=%(title)s' \\\n        + '&start=%(start)i' \\\n        + '&num=%(num)s'\n"]], ['Modify a python script with bash and execute it with the changes'], 2, 0], [(36149707, 1), [['Then run the loop something like'], ['-10000']], [[' start=0\nfor ... in ...\ndo\n    echo "Foo:$foo"\n    echo "Bar:$bar"\n    ./pythonScript.py --argument1 "arg" --start "$start"\n    ((start += 20))  # bash only\ndone    \n']], ['Modify a python script with bash and execute it with the changes'], 2, 0], [(36165854, 0), [['Iterate over every track and make context specific searches:'], ['Prints:']], [[' from pprint import pprint\n\nfrom bs4 import BeautifulSoup\n\ndata = """\n<div>\n    <div class="audioBoxWrap clearBoth">\n        <h3>Title 1</h3>\n        <p>Description 1</p>\n        <div class="info" style="line-height: 1px; height: 1px; font-size: 1px;"></div>\n        <div class="audioBox" style="display: none;">\n            stuff\n        </div>\n        <div> [ <a href="link1.mp3">Right-click to download</a>] </div>\n    </div>\n    <div class="audioBoxWrap clearBoth">\n        <h3>Title 2</h3>\n        <p>Description 2</p>\n        <div class="info" style="line-height: 1px; height: 1px; font-size: 1px;"></div>\n        <div class="audioBox" style="display: none;">\n            stuff\n        </div>\n        <div> [ <a href="link2.mp3">Right-click to download</a>] </div>\n    </div>\n</div>"""\n\nsoup = BeautifulSoup(data, "html.parser")\n\ntracks = soup.find_all(\'div\', {\'class\':"audioBoxWrap clearBoth"})\nresult = {\n    "podcasts": [\n        {\n            "title": track.h3.get_text(strip=True),\n            "description": track.p.get_text(strip=True),\n            "link": track.a["href"]\n        }\n        for track in tracks\n    ]\n}\npprint(result)\n']], ['BeautifulSoup scraping information from multiple divs using loops into JSON'], 2, 1], [(36165854, 1), [['Prints:'], ['-10000']], [[" {'podcasts': [{'description': 'Description 1',\n               'link': 'link1.mp3',\n               'title': 'Title 1'},\n              {'description': 'Description 2',\n               'link': 'link2.mp3',\n               'title': 'Title 2'}]}\n"]], ['BeautifulSoup scraping information from multiple divs using loops into JSON'], 2, 0], [(36170581, 0), [['You can read in all the text files like this:'], ['This will populate file_contents with the contents of each file, so now you can write them all to the output file:']], [[' import os\n\nfile_contents = []\nfor file in os.listdir("directory_to_search"):\n    if file.endswith(".txt"):\n        with open(\'input.txt\', \'rb\') as f:\n            file_contents.append(" ".join(line.strip() for line in f))\n']], ['How to find the all text files from the path and combine all the lines in that text files to one text file'], 2, 0], [(36170581, 1), [['This will populate file_contents with the contents of each file, so now you can write them all to the output file:'], ['Note that if there is more than one word in each of your files, you will need to loop through the file_contents list and join all the lines up before you make the single big string from them.']], [[" with open('output.txt', 'w+b') as f1:\n    all_files_as_one_string = ' '.join(file_contents)\n    f1.write(all_files_as_one_string)\n"]], ['How to find the all text files from the path and combine all the lines in that text files to one text file'], 2, 0], [(36186624, 1), [['Function : '], ['output :']], [["     def comparePackages(package_dictionary):\n     #loop in keys and values of package_dictionary\n        for package_name, list_versions in zip(package_dictionary.keys(), package_dictionary.values()) :\n            #loop on each sublist\n            for position in xrange(len(list_versions)) :\n                a = str(list_versions[position])\n                b = str(list_versions[position-1])\n                #the only way it worked was by using a and b\n                vc = apt_pkg.version_compare(a,b)\n                if vc > 0:\n                    #a>b\n                    max_version = a\n                elif vc == 0:\n                    #a==b\n                    max_version = a         \n                elif vc < 0:\n                    #a<b\n                    max_version = b\n\n            del list_versions[:]\n            if(max_version is '') :\n                max_version = 'Not Specified'\n\n            package_dictionary[package_name] = max_version\n"]], ['parse list of tuple in python and eliminate doubles'], 3, 1], [(36186624, 2), [['output :'], ['-10000']], [['     lib32c-dev : Not Specified\n    libc6-x32 : 2.16\n    libc6-i386 : 2.16\n    libncurses5-dev : 5.9+20150516-2ubuntu1\n    libc6-dev : Not Specified\n    libc-dev : Not Specified\n    libncursesw5-dev : 5.9+20150516-2ubuntu1\n    libc6-dev-x32 : Not Specified\n']], ['parse list of tuple in python and eliminate doubles'], 3, 0], [(36193225, 0), [["That's a routine work for  np.unique  with its optional argument  return_inverse  that tags each element based on the uniqueness among other elements, like so -"], ['Sample run -']], [[' _,id = np.unique(anArray,return_inverse=True)\nout = (id.max() - id + 1).reshape(anArray.shape)\n']], ['Numpy Array Rank All Elements'], 2, 1], [(36226959, 0), [['It should be pretty straightforward:'], ['UPDATE:']], [[" In [10]: df\nOut[10]:\n     a  b  c\n0  NaN  9  7\n1  1.0  7  6\n2  5.0  9  1\n3  7.0  4  0\n4  NaN  2  3\n5  2.0  4  6\n6  6.0  3  6\n7  0.0  2  7\n8  9.0  1  4\n9  2.0  9  3\n\nIn [11]: df.loc[df['a'].isnull(), 'b']\nOut[11]:\n0    9\n4    2\nName: b, dtype: int32\n"]], ['Collect values of pandas dataframe column A if column B is NaN (Python)'], 2, 1], [(36226959, 1), [['UPDATE:'], ['-10000']], [[" In [166]: df\nOut[166]:\n     a    b  c\n0  NaN  5.0  3\n1  7.0  NaN  8\n2  4.0  9.0  7\n3  8.0  NaN  9\n4  3.0  0.0  5\n5  NaN  3.0  5\n6  9.0  0.0  3\n7  0.0  2.0  6\n8  7.0  8.0  7\n9  1.0  7.0  6\n\n\nIn [163]: df[['a','b']].isnull().any(axis=1)\nOut[163]:\n0     True\n1     True\n2    False\n3     True\n4    False\n5     True\n6    False\n7    False\n8    False\n9    False\ndtype: bool\n\nIn [164]: df.loc[df[['a','b']].isnull().any(axis=1)]\nOut[164]:\n     a    b  c\n0  NaN  5.0  3\n1  7.0  NaN  8\n3  8.0  NaN  9\n5  NaN  3.0  5\n\nIn [165]: df.loc[df[['a','b']].isnull().any(axis=1), 'c']\nOut[165]:\n0    3\n1    8\n3    9\n5    5\nName: c, dtype: int32\n"]], ['Collect values of pandas dataframe column A if column B is NaN (Python)'], 2, 1], [(36241474, 0), [['You need to use a generator to produce your y data. This works:'], ['']], [[" import numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib import animation\n\n# First set up the figure, the axis, and the plot element we want to animate\nfig = plt.figure()\nax = plt.axes(xlim=(0, 2), ylim=(-2, 2))\nline, = ax.plot([], [], ' o', lw=2)\ng = 9.81\nh = 2\ntc = 200\nxs = [1] # the vertical position is fixed on x-axis\nys = [h, h]\n\n\n# animation function.  This is called sequentially\ndef animate(y):\n    ys[-1] = y\n    line.set_data(xs, ys)\n    return line,\n\ndef get_y():\n  for step in range(tc):\n    t = step / 100.0\n    y = -0.5*g*t**2 + h  # the equation of diver's displacement on y axis\n    yield y\n\n# call the animator.  blit=True means only re-draw the parts that have changed.\nanim = animation.FuncAnimation(fig, animate, frames=get_y, interval=100)\n\nplt.show()\n"]], ['How to plot real-time graph, with both axis dependent on time?'], 3, 1], [(36241474, 1), [[''], ['This is the most important part:']], [[' # -*- coding: utf-8 -*-\n\nfrom math import *\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib import animation\n\n\ndef Plongeon():\n    h = float(input("height = "))\n    g = 9.81\n\n    #calculate air time, Tc\n    Tc = sqrt(2 * h / g)\n\n    # First set up the figure, the axis, and the plot element we want to animate\n    fig = plt.figure()\n    ax = plt.axes(xlim=(0, 2), ylim=(-2, h+1))  #ymax : initial height+1\n    line, = ax.plot([], [], \' o\', lw=2)\n\n    step = 0.01  # animation step\n    xs = [1]  # the vertical position is fixed on x-axis\n    ys = [h]\n\n\n    # animation function.  This is called sequentially\n    def animate(y):\n        ys[-1] = y\n        line.set_data(xs, ys)\n        return line,\n\n    def get_y():\n        t = 0\n        while t <= Tc:\n            y = -0.5 * g * t**2 + h  # the equation of diver\'s displacement on y axis\n            yield y\n            t += step\n\n    # call the animator.  blit=True means only re-draw the parts that have changed.\n    anim = animation.FuncAnimation(fig, animate, frames=get_y, interval=100)\n\n    plt.show()\nPlongeon()\n']], ['How to plot real-time graph, with both axis dependent on time?'], 3, 1], [(36241474, 2), [['This is the most important part:'], ['You need to advance your time by an increment.']], [[' def get_y():\n     t = 0\n     while t <= Tc:\n         y = -0.5 * g * t**2 + h \n         yield y\n         t += step\n']], ['How to plot real-time graph, with both axis dependent on time?'], 3, 0], [(36242061, 0), [["The nearest equivalent to the tcl  string map  would be  str.translate , but unfortunately it can only map single characters. So it would be necessary to use a regexp to get a similarly compact example. This can be done with  look-behind/look-ahead assertions , but the  \\r 's have to be replaced first:"], ['output:']], [[' import re\n\noldtext = """\\\nThis would keep paragraphs separated.\nThis would keep paragraphs separated.\n\nThis would keep paragraphs separated.\n\\tThis would keep paragraphs separated.\n\n\\rWhen, in the course\nof human events,\nit becomes necessary\n\\rfor one people\n"""\n\nnewtext = re.sub(r\'(?<!\\n)\\n(?![\\n\\t])\', \' \', oldtext.replace(\'\\r\', \'\'))\n']], ['Most efficient way to delete needless newlines in Python'], 5, 1], [(36242061, 1), [['output:'], ["I did a little test using this  Project Gutenberg EBook of War and Peace  (Plain Text UTF-8, 3.1 MB). Here's my tcl script:"]], [[' This would keep paragraphs separated. This would keep paragraphs separated.\n\nThis would keep paragraphs separated.\n    This would keep paragraphs separated.\n\nWhen, in the course of human events, it becomes necessary for one people\n']], ['Most efficient way to delete needless newlines in Python'], 5, 0], [(36242061, 2), [["I did a little test using this  Project Gutenberg EBook of War and Peace  (Plain Text UTF-8, 3.1 MB). Here's my tcl script:"], ['and my python equivalent:']], [[' set fp [open "gutenberg.txt" r]\nset oldtext [read $fp]\nclose $fp\n\nset newtext [string map "{\\r} {} {\\n\\n} {\\n\\n} {\\n\\t} {\\n\\t} {\\n} { }" $oldtext]\n\nputs $newtext\n']], ['Most efficient way to delete needless newlines in Python'], 5, 0], [(36242061, 3), [['and my python equivalent:'], ['Crude performance test:']], [[" import re\n\nwith open('gutenberg.txt') as stream:\n    oldtext = stream.read()\n\n    newtext = re.sub(r'(?<!\\n)\\n(?![\\n\\t])', ' ', oldtext.replace('\\r', ''))\n\n    print(newtext)\n"]], ['Most efficient way to delete needless newlines in Python'], 5, 1], [(36242061, 4), [['Crude performance test:'], ['So, as expected, the tcl version is more efficient. However, the output from the python version seems somewhat cleaner (no extra spaces inserted at the beginning of lines). ']], [[" $ /usr/bin/time -f '%E' tclsh gutenberg.tcl > output1.txt\n0:00.18\n$ /usr/bin/time -f '%E' python gutenberg.py > output2.txt\n0:00.30\n"]], ['Most efficient way to delete needless newlines in Python'], 5, 0], [(36282772, 0), [['I would not change your own approach but to answer your question:'], ["It does the assignment in place but you are basically using map for side effects and creating a list of None's:"]], [[' lol = [[1,3],[3,4]]\nfrom operator import setitem\n\nmap(lambda x: setitem(x, 1, -2), lol)\nprint(lol)\n[[1, -2], [3, -2]]\n']], ["How to perform a 'one-liner' assignment on all elements of a list of lists in python"], 3, 1], [(36282772, 1), [["It does the assignment in place but you are basically using map for side effects and creating a list of None's:"], ['They simple loop is also the more performant:']], [[' In [1]: lol = [[1, 3], [3, 4]]\n\n\nIn [2]: from operator import setitem\n\nIn [3]: map(lambda x: setitem(x, 1, -2), lol)\nOut[3]: [None, None]\n\nIn [4]: lol\nOut[4]: [[1, -2], [3, -2]]\n']], ["How to perform a 'one-liner' assignment on all elements of a list of lists in python"], 3, 1], [(36282772, 2), [['They simple loop is also the more performant:'], ['The only time map. filter etc.. really do well is if you can call them with a builtin function or method i.e  map(str.strip, iterable) , once you include a lambda the performance will usually take a big hit.']], [[' In [13]: %%timeit                                          \nlol = [[1,2,3,4,5,6,7,8] for _ in range(100000)]\nmap(lambda x: setitem(x, 1, -2), lol)\n   ....: \n\n10 loops, best of 3: 45.4 ms per loop\n\nIn [14]: \n\nIn [14]: %%timeit                                          \nlol = [[1,2,3,4,5,6,7,8] for _ in range(100000)]\nfor sub in lol:\n    sub[1] = -2\n   ....: \n10 loops, best of 3: 31.7 ms per \n']], ["How to perform a 'one-liner' assignment on all elements of a list of lists in python"], 3, 1], [(36336637, 0), [['You can get column types from  column_descriptions'], ['Or if you need to know Python types:']], [[" [c['type'] for c in query.column_descriptions]\n"]], ['how to know the type of sql query result before it is executed in sqlalchemy'], 2, 1], [(36336637, 1), [['Or if you need to know Python types:'], ['-10000']], [[" [c['type'].python_type for c in query.column_descriptions]\n"]], ['how to know the type of sql query result before it is executed in sqlalchemy'], 2, 1], [(36344619, 0), [['If you just want a particular value and you know the key:'], ['You can access all pairs with  f._pairs() :']], [[' In [18]: response = br.open("http://www.w3schools.com/html/html_forms.asp")\n\nIn [19]: f = list(br.forms())\n\nIn [20]: f[0].get_value("firstname")\nOut[20]: \'Mickey\'\nIn [21]: f[0].get_value("lastname")\nOut[21]: \'Mouse\'\n']], ['Getting the key and value of br.forms() in Mechanize'], 3, 1], [(36344619, 2), [['You see it gives you key,value pairs:'], ['-10000']], [[" <GET http://www.w3schools.com/html/action_page.php application/x-www-form-urlencoded\n  <TextControl(firstname=Mickey)>\n  <TextControl(lastname=Mouse)>\n  <SubmitControl(<None>=Submit) (readonly)>>\n[('firstname', 'Mickey'), ('lastname', 'Mouse')]\n<GET http://www.w3schools.com/html/action_page.php application/x-www-form-urlencoded\n  <TextControl(firstname=Mickey)>\n  <TextControl(lastname=Mouse)>\n  <SubmitControl(<None>=Submit) (readonly)>>\n[('firstname', 'Mickey'), ('lastname', 'Mouse')]\n<GET http://www.w3schools.com/html/html_forms.asp application/x-www-form-urlencoded\n  <TextControl(err_email=)>\n  <TextControl(err_url=) (disabled)>\n  <TextareaControl(err_desc=)>\n  <IgnoreControl(<None>=<None>)>>\n[('err_email', ''), ('err_desc', '')]\n"]], ['Getting the key and value of br.forms() in Mechanize'], 3, 0], [(36364188, 0), [['try this:'], ['or if you need a plain list instead of numpy array:']], [[" In [334]: df\nOut[334]:\n               close_price  short_lower_band  long_lower_band\nEquity(8554)        180.53        184.235603       183.964306\nEquity(2174)        166.83        157.450404       157.160282\nEquity(23921)       124.67        127.243468       126.072039\nEquity(26807)       117.91        108.761587       107.190081\nEquity(42950)       108.07         97.491851        96.868036\nEquity(4151)         97.38         98.954371        98.335786\n\nIn [335]:\n\nIn [335]: df[(df.close_price < df.short_lower_band) & \\\n   .....:    (df.close_price < df.long_lower_band)].index.values\nOut[335]: array(['Equity(8554)', 'Equity(23921)', 'Equity(4151)'], dtype=object)\n"]], ['Python - dataframe conditional index value selection'], 2, 1], [(36364188, 1), [['or if you need a plain list instead of numpy array:'], ['-10000']], [[" In [336]: df[(df.close_price < df.short_lower_band) & \\\n   .....:    (df.close_price < df.long_lower_band)].index.tolist()\nOut[336]: ['Equity(8554)', 'Equity(23921)', 'Equity(4151)']\n"]], ['Python - dataframe conditional index value selection'], 2, 1], [(36364512, 0), [['There are a few ways that you can do something like this. One way would be to have the options have a default value that indicates that you want the default. This could look like this:'], ['initializing the default would then look like']], [[' class MyClass:\n    def __init__(self, options=None):\n        if options is None:\n            options = create_default_parser()\n        self.options = options\n\n    def create_default_parser(self):\n        parser = argparse.ArgumentParser(description=\'something\')\n        parser.add_argument(\'-v\', \'--victor\', dest=\'vic\', default="winning")\n        options = parser.parse_args()\n        return options\n']], ['alternate for multiple constructors'], 4, 1], [(36364512, 1), [['initializing the default would then look like'], ['Another method would be to use a class method like this:']], [[' default = MyClass()\n']], ['alternate for multiple constructors'], 4, 0], [(36364512, 2), [['Another method would be to use a class method like this:'], ['and the default would be created like this:']], [[' class MyClass:\n    def __init__(self, options):\n        self.options = options\n\n    @classmethod\n    def create_default_parser(cls):\n        parser = argparse.ArgumentParser(description=\'something\')\n        parser.add_argument(\'-v\', \'--victor\', dest=\'vic\', default="winning")\n        options = parser.parse_args()\n        return cls(options)\n']], ['alternate for multiple constructors'], 4, 1], [(36364512, 3), [['and the default would be created like this:'], ['-10000']], [[' default = MyClass.create_default_parser()\n']], ['alternate for multiple constructors'], 4, 0], [(36408096, 0), [["Python's standard library comes with  functools.wraps , which can be really handy in this case:"], ['Now the function  g(func)  returns a wrapper wrapping  func  post-processing its output:']], [[' def g(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        func_value = func(*args, **kwargs)\n        return -func_value\n    return wrapper\n']], ["is there a way to change the return value of a function without changing the function's body?"], 2, 1], [(36408096, 1), [['Now the function  g(func)  returns a wrapper wrapping  func  post-processing its output:'], ['This works with  any  function  func  with any number of positional or keyword arguments.']], [[' >>> new_func = g(f)  # your original f(x)\n>>> print(new_func(1))\n0.5\n']], ["is there a way to change the return value of a function without changing the function's body?"], 2, 0], [(36409213, 0), [['The idea is exactly the same as your function, except that you return a tuple of coordinates instead of increasing a counter by 1 when you reach the bottom. By making it a generator you only create the paths as you need them.'], ['Examples.']], [[' def generate_paths(depth, x=0, y=0):\n    if x == depth:\n        yield ((x, y),)\n    else:\n        for path in generate_paths(depth, x+1, y):\n            yield ((x, y),) + path\n        for path in generate_paths(depth, x+1, y+1):\n            yield ((x, y),) + path\n']], ['Modifying a recursive function that counts no. of paths, to get sequence of all paths'], 2, 1], [(36409213, 1), [['Examples.'], ["This generates all the paths in less than a second. However, just as the problem suggests, you're encouraged to find a more efficient because the complexity is exponential and for longer depths this will be infeasible."]], [[' >>> for path in generate_paths(3):\n...    print(path)\n\n((0, 0), (1, 0), (2, 0), (3, 0))\n((0, 0), (1, 0), (2, 0), (3, 1))\n((0, 0), (1, 0), (2, 1), (3, 1))\n((0, 0), (1, 0), (2, 1), (3, 2))\n((0, 0), (1, 1), (2, 1), (3, 1))\n((0, 0), (1, 1), (2, 1), (3, 2))\n((0, 0), (1, 1), (2, 2), (3, 2))\n((0, 0), (1, 1), (2, 2), (3, 3))\n>>> print(len(tuple(generate_paths(14))))\n16384\n']], ['Modifying a recursive function that counts no. of paths, to get sequence of all paths'], 2, 0], [(36436065, 0), [["You should be splitting on your delimiter to get each column's value for that row:"], ["Or if you're a fan of obnoxious and ugly one-liners:"]], [[" for line in fileinput.readlines():\n    a, b, c = line.split('\\t')      # Variable unpacking; assumes each line has three columns\n    if a == '?':\n        function_a()\n    if b == '?':\n        function_b()\n    if c == '?':\n        function_c()\n"]], ['Parsing through a file'], 2, 1], [(36436065, 1), [["Or if you're a fan of obnoxious and ugly one-liners:"], ['-10000']], [[" [(function_a, function_b, function_c)[line.split('\\t').index('?')]() for line in fileinput.readlines()]\n"]], ['Parsing through a file'], 2, 1], [(36436953, 2), [['If you want to preserve only numbers you can do it this way:'], ['-10000']], [[" In [183]: df.replace({'DSFS': {r'(\\d+)\\s*\\-\\s*(\\d+).*': r'\\1_\\2'}}, regex=True)\nOut[183]:\n   MemberID Year  DSFS DrugCount\n0  48925661   Y2  9_10        7+\n1  90764620   Y3   8_9         3\n2  61221204   Y1   2_3         1\n"]], ['Removing word and replacing character in a column of strings'], 3, 1], [(36445193, 0), [['I suggest you not inventing a wheel. There is existing solution. Source  here  '], ['Use it like:         ']], [[" import os\n\n\ndef split(filehandler, delimiter=',', row_limit=1000,\n          output_name_template='output_%s.csv', output_path='.', keep_headers=True):\n    import csv\n    reader = csv.reader(filehandler, delimiter=delimiter)\n    current_piece = 1\n    current_out_path = os.path.join(\n        output_path,\n        output_name_template % current_piece\n    )\n    current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n    current_limit = row_limit\n    if keep_headers:\n        headers = reader.next()\n        current_out_writer.writerow(headers)\n    for i, row in enumerate(reader):\n        if i + 1 > current_limit:\n            current_piece += 1\n            current_limit = row_limit * current_piece\n            current_out_path = os.path.join(\n                output_path,\n                output_name_template % current_piece\n            )\n            current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n            if keep_headers:\n                current_out_writer.writerow(headers)\n        current_out_writer.writerow(row)\n"]], ['splitting one csv into multiple files in python'], 2, 1], [(36445193, 1), [['Use it like:         '], ['-10000']], [[" split(open('/your/pat/input.csv', 'r'));\n"]], ['splitting one csv into multiple files in python'], 2, 0], [(36458482, 0), [["Jinja2 has truncate filter  truncate(s, length=255, killwords=False, end='...') . Example usage"], ['Or']], [[' <div>{{ blogpost.text|truncate }}</div>\n']], ['How to not render a entire string with jinja2'], 2, 1], [(36458482, 1), [['Or'], ['-10000']], [[' <div>{{ blogpost.text|truncate(1024, True) }}</div>\n']], ['How to not render a entire string with jinja2'], 2, 1], [(36459148, 0), [['You can start by setting the  grp_idx :'], ['Now  id  and  grp_idx  create the grouping you want:']], [[' df["grp_idx"] = np.where(df.groupby("id").cumcount()<3, 0, df["grp_idx"])\n']], ['Pandas: Collapse first n rows in each group by aggregation'], 2, 0], [(36459148, 1), [['Now  id  and  grp_idx  create the grouping you want:'], ["I assumed the type cannot be different for the same id as you didn't give any conditions for that column. I also assumed the df is sorted by id. If not, you can first sort it for  grp_idx  to be correct."]], [[' df.groupby(["id", "type", "grp_idx"]).sum().reset_index()\n\n    id  type    grp_idx col_1   col_2   flag\n0   283 A       0       12      18      0\n1   283 A       4       8       12      0\n2   283 A       5       10      15      0\n3   283 A       6       12      18      0\n4   283 A       7       14      21      1\n5   756 X       0       30      6       1\n']], ['Pandas: Collapse first n rows in each group by aggregation'], 2, 0], [(36464357, 0), [['ui.py:'], ['main.py:']], [[' from PySide import QtCore, QtGui\n\nclass Ui_Form(object):\n    def setupUi(self, Form):\n        Form.setObjectName("Form")\n        Form.resize(533, 497)\n        self.mplvl = QtGui.QWidget(Form)\n        self.mplvl.setGeometry(QtCore.QRect(150, 150, 251, 231))\n        self.mplvl.setObjectName("mplvl")\n        self.vLayout = QtGui.QVBoxLayout()\n        self.mplvl.setLayout(self.vLayout)\n        self.retranslateUi(Form)\n        QtCore.QMetaObject.connectSlotsByName(Form)\n\n    def retranslateUi(self, Form):\n        Form.setWindowTitle(QtGui.QApplication.translate("Form", "Form", None, QtGui.QApplication.UnicodeUTF8))\n']], ['Matplotlib in Pyside with Qt designer (PySide)'], 2, 0], [(36464357, 1), [['main.py:'], ["Now what's left is probably to tweak the  FigureCanvas  to make it the right size and proportions, so you should be able to get what you want looking at  this example  or  the other ."]], [[' import matplotlib\nmatplotlib.use(\'Qt4Agg\')\nmatplotlib.rcParams[\'backend.qt4\'] = \'PySide\'\nfrom matplotlib.backends.backend_qt4agg import (\n    FigureCanvasQTAgg as FigureCanvas,\n    NavigationToolbar2QT as NavigationToolbar)\nfrom matplotlib.figure import Figure\nfrom PySide import QtGui, QtCore\nimport random\n\nfrom weakref import proxy\nfrom ui import Ui_Form\n\n\nclass Plotter(FigureCanvas):\n    def __init__(self, parent):\n        \'\'\' plot some random stuff \'\'\'\n        self.parent = proxy(parent)\n        # random data\n        data = [random.random() for i in range(10)]\n        fig = Figure()\n        super(Plotter,self).__init__(fig)\n        # create an axis\n        self.axes = fig.add_subplot(111)\n        # discards the old graph\n        self.axes.hold(False)\n        # plot data\n        self.axes.plot(data, \'*-\')\n\n    def binding_plotter_with_ui(self):\n        self.parent.vLayout.insertWidget(1, self)\n\nif __name__ == "__main__":\n    import sys\n    app = QtGui.QApplication(sys.argv)\n    Form = QtGui.QWidget()\n    ui = Ui_Form()\n    ui.setupUi(Form)\n    # plotter logic and binding needs to be added here\n    plotter = Plotter(ui)\n    plotter.binding_plotter_with_ui()\n    plotter2 = Plotter(ui)\n    plotter2.binding_plotter_with_ui()\n    Form.show()\n    sys.exit(app.exec_())\n']], ['Matplotlib in Pyside with Qt designer (PySide)'], 2, 0], [(36479374, 0), [['numpy  has nice support for this  without having to write a  for  loop:'], ['If you insist on a  for  loop, just iterate over the elements to bin, and the bins:']], [[' import numpy as np\n\ndata = np.array([0.2, 6.4, 3.0, 1.6])\nbins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])\ncats = np.digitize(data, bins)\ncats\n# array([1, 4, 3, 2])\n']], ['Python identify in which interval the numbers are'], 2, 1], [(36479374, 1), [['If you insist on a  for  loop, just iterate over the elements to bin, and the bins:'], ["The above uses tuples to specify the bin ranges (like your example), but that's not technically necessary (e.g. the  numpy  code). You could store just the cutoffs and compare adjacent elements from  cutoffs[:-1] ."]], [[" data = [0.2, 6.4, 3.0]\nbins = [(0.0, 1.0), (1.0, 4.0), (4.0, 10.0)]  # assumed (lower, upper] format\ncats = []\n\nfor elem in data:\n    for idx, bounds in enumerate(bins, start=1):\n        if bounds[0] < elem <= bounds[1]:\n            cats.append(idx)\n            break\n    else:\n        raise ValueError('No bin for {}'.format(elem))\n"]], ['Python identify in which interval the numbers are'], 2, 1], [(36495903, 0), [['If you just want a new string representation then use  dt.strftime :'], ['If you want the  datetime.time  component then use  dt.time :']], [[" In [7]:\ndf['Time'] = df['Date'].dt.strftime('%H:%M:%S')\ndf\n\nOut[7]:\n            Timestamp                    Date      Time\n0  20160208_095900.51 2016-02-08 09:59:00.510  09:59:00\n1  20160208_095901.51 2016-02-08 09:59:01.510  09:59:01\n2  20160208_095902.51 2016-02-08 09:59:02.510  09:59:02\n3  20160208_095903.51 2016-02-08 09:59:03.510  09:59:03\n4  20160208_095904.51 2016-02-08 09:59:04.510  09:59:04\n5  20160208_095905.51 2016-02-08 09:59:05.510  09:59:05\n6  20160208_095906.51 2016-02-08 09:59:06.510  09:59:06\n7  20160208_095907.51 2016-02-08 09:59:07.510  09:59:07\n8  20160208_095908.51 2016-02-08 09:59:08.510  09:59:08\n9  20160208_095909.51 2016-02-08 09:59:09.510  09:59:09\n"]], ['Convert pandas datetime objects'], 2, 1], [(36495903, 1), [['If you want the  datetime.time  component then use  dt.time :'], ['-10000']], [[" In [8]:\ndf['Time'] = df['Date'].dt.time\ndf\n\nOut[8]:\n            Timestamp                    Date             Time\n0  20160208_095900.51 2016-02-08 09:59:00.510  09:59:00.510000\n1  20160208_095901.51 2016-02-08 09:59:01.510  09:59:01.510000\n2  20160208_095902.51 2016-02-08 09:59:02.510  09:59:02.510000\n3  20160208_095903.51 2016-02-08 09:59:03.510  09:59:03.510000\n4  20160208_095904.51 2016-02-08 09:59:04.510  09:59:04.510000\n5  20160208_095905.51 2016-02-08 09:59:05.510  09:59:05.510000\n6  20160208_095906.51 2016-02-08 09:59:06.510  09:59:06.510000\n7  20160208_095907.51 2016-02-08 09:59:07.510  09:59:07.510000\n8  20160208_095908.51 2016-02-08 09:59:08.510  09:59:08.510000\n9  20160208_095909.51 2016-02-08 09:59:09.510  09:59:09.510000\n"]], ['Convert pandas datetime objects'], 2, 1], [(36524627, 0), [["the problem was I considered  each item from the result of collect operation as a key value pair, but instead it's a  Tuple  with key as first entry and value, the second. So I iterated upon then using the following   lambda , and I got the result. "], ['Final result:']], [[' def append_values_inside(key, value):\n    temp = []\n    for v in value:\n        for entry in v:\n            temp.append(entry)\n    return (key, temp)\nfor entry in ratings_and_users.map(lambda a: append_values_inside(a[0], a[1])).collect() :\n        print(entry)\n']], ['combining lists inside values in pyspark'], 2, 1], [(36524627, 1), [['Final result:'], ['-10000']], [[' (b\'"20599"\', [7.0, b\'"349802972X"\', \'bamberg, franken, germany\', \'NULL\'])\n(b\'"120675"\', [0.0, b\'"0972189408"\', \'crescent city, california, usa\', 45])\n(b\'"166487"\', [6.0, b\'"8422626993"\', \'santander, n/a, spain\', 103])\n(b\'"166487"\', [7.0, b\'"8440639228"\', \'santander, n/a, spain\', 103])\n']], ['combining lists inside values in pyspark'], 2, 0], [(36549666, 0), [['zip  lets you combine multiple iterators:'], ['you can also use  enumerate  on a range object:']], [[' for i,j in zip(range(0,len(A)-1), range(1,len(A))):\n    #some operation between A[i] and A[j]\n']], ['Pythonic way of comparing all adjacent elements in a list'], 3, 1], [(36549666, 1), [['you can also use  enumerate  on a range object:'], ['Note that unlike the other answers this gives you access to the  indices  of A not just the items, this is necessary if you want to use any  assignment  to  A[i]  or  A[j] , for example here is a very basic bubble sort:']], [[' for i,j in enumerate(range(1,len(A)):\n    #some operation between A[i] and A[j]\n']], ['Pythonic way of comparing all adjacent elements in a list'], 3, 1], [(36550795, 0), [['First, you might want to include different types (rather than  list ) in your check, and a quick way of doing that would be:'], ['-10000']], [[' def is_iterable(x):\n    return type(x) in [list, tuple] # or just isinstance(x, list)\n']], ['Pythonic way of looping over variable that is either an element or a list'], 4, 0], [(36550795, 1), [['-10000'], ['Or if you expect any return:']], [[' if is_iterable(test):\n    for x in test:\n        do_stuff(x)\nelse:\n    do_stuff(test)\n']], ['Pythonic way of looping over variable that is either an element or a list'], 4, 0], [(36550795, 2), [['Or if you expect any return:'], ["Another last option, if your  do_stuff  is not defined as a function, and thus you don't want to copy-paste code (never do that), would be to just get the assignment out:"]], [[' if is_iterable(test):\n    return [do_stuff(x) for x in test]\nelse:\n    return [do_stuff(test)]\n']], ['Pythonic way of looping over variable that is either an element or a list'], 4, 0], [(36550795, 3), [["Another last option, if your  do_stuff  is not defined as a function, and thus you don't want to copy-paste code (never do that), would be to just get the assignment out:"], ['But this is in essence the same as what you already have. In my personal experience, it is usually useful to get all the  preprocessing  out of the  calculation  step and make sure all the parameters have valid types. Then just perform whatever operation you need to do on them.']], [[' test = test if is_iterable(test) else [test]\nfor x in test:\n    do_stuff\n    ...\n']], ['Pythonic way of looping over variable that is either an element or a list'], 4, 0], [(36554940, 1), [['to apply the function  P(x)  to your data. To write the calculated values to a file, wrap the plot command in  set/unset table  pair:'], ['The generated file contains three columns, the values as given by the  using  statement, and in the third column a character which indicates if the values were in range ( i ), out of range ( o ) or undefined ( u ).']], [[' plot "energy_vs_volume.dat" using 1:(P($1))\nset table "output.dat"\nreplot\nunset table\n']], ['Gnuplot: use a function to transform a column of a data file and plot the transformed data and the function'], 2, 1], [(36558005, 0), [['A basic example. Note that the  meshgrid  is not needed for the interpolation, but only to make a fast  ufunc  to generate an example function  A=f(x,y,z) , here  A=x+y+z .'], ['Output: ']], [[" from scipy.interpolate import interpn\nimport numpy as np\n\n#make up a regular 3d grid \nX=np.linspace(-5,5,11)\nY=np.linspace(-5,5,11)\nZ=np.linspace(-5,5,11)\nxv,yv,zv = np.meshgrid(X,Y,Z)\n\n# make up a function   \n# see http://docs.scipy.org/doc/numpy/reference/ufuncs.html\nA = np.add(xv,np.add(yv,zv))   \n#this one is easy enough for us to know what to expect at (.5,.5,.5)\n\n# usage : interpn(points, values, xi, method='linear', bounds_error=True, fill_value=nan) \ninterpn((X,Y,Z),A,[0.5,0.5,0.5])\n"]], ['Interpolating 3d data at a single point in space (Python 2.7)'], 2, 1], [(36558005, 1), [['Output: '], ['If you pass in an array of points of interest, it will give you multiple answers.']], [[' array([ 1.5])\n']], ['Interpolating 3d data at a single point in space (Python 2.7)'], 2, 0], [(36559053, 0), [["This is the solution I came to. It doesn't pop any items (again because I don't know exactly why you are doing that)."], ['This could be cleaner and more reusable if it is put into a function, like so:']], [[" import csv\nfrom collections import OrderedDict\n\nfile = open('example.csv', mode='r')\n\ncsvReader = csv.reader(file)\n\n# get rid of header row\nheader = next(csvReader)\n# print(header)\n\nodict = OrderedDict()\nfor row in csvReader:\n    odict[row[0]] = row[1:]\n    # print(row)\n\nprint(odict)\n"]], ['Creating an OrderedDict from a csv file'], 2, 1], [(36559053, 1), [['This could be cleaner and more reusable if it is put into a function, like so:'], ['-10000']], [[" import csv\nfrom collections import OrderedDict\n\ndef parse_csv(filename):\n\n    file = open(filename, mode='r')\n\n    csvReader = csv.reader(file)\n\n    # get rid of header row\n    header = next(csvReader)\n    # print(header)\n\n    odict = OrderedDict()\n    for row in csvReader:\n        odict[row[0]] = row[1:]\n        # print(row)\n\n    return odict\n\nparse_csv('example.csv')\n"]], ['Creating an OrderedDict from a csv file'], 2, 1], [(36572221, 0), [['If your data is like'], ['You could use the  CountVectorizer  of the package  sklearn :']], [[" import pandas as pd\ndf = pd.DataFrame([\n    'must watch. Good acting',\n    'average movie. Bad acting',\n    'good movie. Good acting',\n    'pathetic. Avoid',\n    'avoid'], columns=['description'])\n"]], ['How to find ngram frequency of a column in a pandas dataframe?'], 3, 0], [(36572221, 1), [['You could use the  CountVectorizer  of the package  sklearn :'], ['Which gives you :']], [[" from sklearn.feature_extraction.text import CountVectorizer\nword_vectorizer = CountVectorizer(ngram_range=(1,2), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(df['description'])\nfrequencies = sum(sparse_matrix).toarray()[0]\npd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n"]], ['How to find ngram frequency of a column in a pandas dataframe?'], 3, 1], [(36572221, 2), [['Which gives you :'], ['EDIT']], [['                 frequency\ngood            3\npathetic        1\naverage movie   1\nmovie bad       2\nwatch           1\ngood movie      1\nwatch good      3\ngood acting     2\nmust            1\nmovie good      2\npathetic avoid  1\nbad acting      1\naverage         1\nmust watch      1\nacting          1\nbad             1\nmovie           1\navoid           1\n']], ['How to find ngram frequency of a column in a pandas dataframe?'], 3, 0], [(36579996, 1), [['then you will get an output something like:'], ["Although I'm not sure how useful this is since you have a lot of duplicate keys like  @name , I'd like to offer a function I created a while ago to traverse nested  json  data of nested  dict s and  list s:"]], [[' ...\nKey :@name,  Value: Employee\nKey :@isMandotory,  Value: True\nKey :#text,  Value: Jake Roberts\nKey :@name,  Value: Section\nKey :@isOpen,  Value: True\nKey :@isMandotory,  Value: False\nKey :#text,  Value: 5\n...\n']], ['Python: Loop through all nested key-value pairs created by xmltodict'], 7, 0], [(36579996, 2), [["Although I'm not sure how useful this is since you have a lot of duplicate keys like  @name , I'd like to offer a function I created a while ago to traverse nested  json  data of nested  dict s and  list s:"], ['Then you can traverse the data with:']], [[' def traverse(obj, prev_path = "obj", path_repr = "{}[{!r}]".format)\n    if isinstance(obj,dict):\n        it = obj.items()\n    elif isinstance(obj,list):\n        it = enumerate(obj)\n    else:\n        yield prev_path,obj\n        return\n    for k,v in it:\n        for data in traverse(v, path_repr(prev_path,k), path_repr):\n            yield data\n']], ['Python: Loop through all nested key-value pairs created by xmltodict'], 7, 0], [(36579996, 3), [['Then you can traverse the data with:'], ['with the default values for  prev_path  and  path_repr  it gives output like this:']], [[' for path,value in traverse(doc):\n    print("{} = {}".format(path,value))\n']], ['Python: Loop through all nested key-value pairs created by xmltodict'], 7, 0], [(36579996, 4), [['with the default values for  prev_path  and  path_repr  it gives output like this:'], ['although you can write a function for  path_repr  to take the value of  prev_path  (determined by recursively calling  path_repr ) and the new key, for example if you want to get the indices as a tuple you could do this:']], [[" obj[u'session'][u'@id'] = 2934\nobj[u'session'][u'@name'] = Valves\nobj[u'session'][u'@docVersion'] = 5.0.1\nobj[u'session'][u'docInfo'][u'field'][0][u'@name'] = Employee\nobj[u'session'][u'docInfo'][u'field'][0][u'@isMandotory'] = True\nobj[u'session'][u'docInfo'][u'field'][0]['#text'] = Jake Roberts\nobj[u'session'][u'docInfo'][u'field'][1][u'@name'] = Section\nobj[u'session'][u'docInfo'][u'field'][1][u'@isOpen'] = True\nobj[u'session'][u'docInfo'][u'field'][1][u'@isMandotory'] = False\nobj[u'session'][u'docInfo'][u'field'][1]['#text'] = 5\nobj[u'session'][u'docInfo'][u'field'][2][u'@name'] = Location\nobj[u'session'][u'docInfo'][u'field'][2][u'@isOpen'] = True\nobj[u'session'][u'docInfo'][u'field'][2][u'@isMandotory'] = False\nobj[u'session'][u'docInfo'][u'field'][2]['#text'] = Munchen\n"]], ['Python: Loop through all nested key-value pairs created by xmltodict'], 7, 0], [(36579996, 5), [['although you can write a function for  path_repr  to take the value of  prev_path  (determined by recursively calling  path_repr ) and the new key, for example if you want to get the indices as a tuple you could do this:'], ['then the output would be:']], [[' def add_to_tuple(prev,new):\n    return prev+(new,) #prev is a tuple, add in the new element to the tuple\n\nfor path,value in traverse(doc,(),add_to_tuple): #prev_path is initially an empty tuple\n    print("{} = {}".format(path,value))\n']], ['Python: Loop through all nested key-value pairs created by xmltodict'], 7, 0], [(36579996, 6), [['then the output would be:'], ["I found this particularly useful when dealing with my json data but I'm not really sure what you want to do with your xml."]], [[" ...\n(u'session', u'docInfo', u'field', 0, '#text') = Jake Roberts\n(u'session', u'docInfo', u'field', 1, u'@name') = Section\n(u'session', u'docInfo', u'field', 1, u'@isOpen') = True\n(u'session', u'docInfo', u'field', 1, u'@isMandotory') = False\n(u'session', u'docInfo', u'field', 1, '#text') = 5\n...\n"]], ['Python: Loop through all nested key-value pairs created by xmltodict'], 7, 0], [(36597386, 0), [['You can grab all the string literals with the following regex:'], ['Sample  Python demo :']], [[' r\'(?P<prefix>(?:\\bu8|\\b[LuU])?)(?:"(?P<dbl>[^"\\\\]*(?:\\\\.[^"\\\\]*)*)"|\\\'(?P<sngl>[^\\\'\\\\]*(?:\\\\.[^\\\'\\\\]*)*)\\\')|R"([^"(]*)\\((?P<raw>.*?)\\)\\4"\'\n']], ['Match C++ Strings and String Literals using regex in Python'], 2, 1], [(36597386, 1), [['Sample  Python demo :'], ['-10000']], [[' import re\n\np = re.compile(r\'(?P<prefix>(?:\\bu8|\\b[LuU])?)(?:"(?P<dbl>[^"\\\\]*(?:\\\\.[^"\\\\]*)*)"|\\\'(?P<sngl>[^\\\'\\\\]*(?:\\\\.[^\\\'\\\\]*)*)\\\')|R"([^"(]*)\\((?P<raw>.*?)\\)\\4"\')\ns = "\\"text\'\\\\\\"here\\"\\nL\'text\\\\\'\\"here\'\\nu8\\"text\'\\\\\\"here\\"\\nu\'text\\\\\'\\"here\'\\nU\\"text\'\\\\\\"here\\"\\nR\\"delimiter(text\\"\'\\"here)delimiter\\""\nprint(s)\nprint(\'--------- Regex works below ---------\')\nfor x in p.finditer(s):\n    if x.group("dbl"):\n        print(x.group("dbl"))\n    elif x.group("sngl"):\n        print(x.group("sngl"))\n    else:\n        print(x.group("raw"))\n']], ['Match C++ Strings and String Literals using regex in Python'], 2, 1], [(36633059, 1), [['or, an apply:'], ['nb, I would be surprised if the  apply  is any faster than the comprehension']], [[" import music21\nimport pandas as pd\nimport numpy as np\n\ns1 = pd.Series(['C4', 'E-4', 'G4', 'A-4'])\ndf = pd.DataFrame({0:s1, 1:s1.shift(1)})\n\ndef myfunc(x):\n    if not any([pd.isnull(x[0]), pd.isnull(x[1])]):\n        return music21.interval.Interval(music21.note.Note(x[0]),music21.note.Note(x[1])).name\n\n\ndf.apply(myfunc, axis = 1)\n"]], ['Make a pandas series by running a function on all adjacent values'], 2, 1], [(36672440, 0), [['A simple way is to solve for parameters which will cause the expressions to be equal at a number of points in time. Given that the forms are in fact the same, this will work fine:'], ['The answer I get is']], [[" V_Ci, tau, V_Cf = symbols('V_Ci, tau, V_Cf')\n\ntarget = V_Ci*exp(-t/tau) + Heaviside(t)*V_Cf*(1 - exp(-t/tau))\n\nsolve([(eqVc.rhs - target).subs(t, ti) for ti in [0, 1, 2]],\n      [V_Ci, tau, V_Cf], dict=True)\n"]], ['How to force sympy to extract specific subexpressions?'], 3, 1], [(36672440, 1), [['The answer I get is'], ["That  log(exp())  is not simplified away because of the way the variables are defined. Defining everything as real ( V_Ci, tau, V_Cf = symbols('V_Ci, tau, V_Cf', real=True)  and similar modification in your code) simplifies the soluion to"]], [[' [{V_Cf: R_S/(R_1 + R_S),\n  tau: 1/log(exp((1/R_S + 1/R_1)/(C_1 + C_S))),\n  V_Ci: k_1}]\n']], ['How to force sympy to extract specific subexpressions?'], 3, 0], [(36672440, 2), [["That  log(exp())  is not simplified away because of the way the variables are defined. Defining everything as real ( V_Ci, tau, V_Cf = symbols('V_Ci, tau, V_Cf', real=True)  and similar modification in your code) simplifies the soluion to"], ['-10000']], [[' [{V_Ci: k_1, \n  V_Cf: R_S/(R_1 + R_S), \n   tau: R_1*R_S*(C_1 + C_S)/(R_1 + R_S)}]\n']], ['How to force sympy to extract specific subexpressions?'], 3, 0], [(36709837, 1), [['For storing  you can use  dictionary  of  DataFrames :    '], ['-10000']], [[' dfs={i: g.dropna(axis=1)         \n    for i, g in df1.groupby(df1.apply(lambda x: x.notnull().sum() - 2 , axis=1))}\n\n#select DataFrame with len=2    \nprint dfs[2]\n    id channel  p1  p2\n1  213    paid  b2  b1\n\n#select DataFrame with len=3       \nprint dfs[3]\n     id channel    p1    p2   p3\n2  2222  direct  as25  dw46  32q\n']], ['Slicing and arranging dataframe in pandas'], 2, 0], [(36719792, 0), [['I tested this code with  pyinstaller --onefile filename.py  and \nit worked fine without any manual changes to settings/specs/paths etc. '], ['I turned the images into base64 strings like so:']], [[' import os\nimport hashlib\nimport pygame\nimport time\nimport base64\n\ndef create_assets(asset_dict, asset_dir):\n\n    """ \n    hand this function a dictionary of assets (images, mp3s, whatever)\n    and an absolute path to the data/asset folder. \n    The function creates the folder and files from the base64 strings\n    if they don\'t exist. If the files exist, an md5 check is run\n    instead to ensure integrity \n    """\n\n    first_run = False\n    if not os.path.isdir(asset_dir):\n        os.mkdir(asset_dir)\n        first_run = True\n    for label in asset_dict:\n        asset = asset_dict[label]\n        filename = os.path.join(asset_dir, asset["filename"])\n        rewrite = False\n        # no need to check file if we just created the data folder\n        if not first_run:\n            if not os.path.isfile(filename):\n                # the file doesn\'t exist\n                rewrite = True\n            else:\n                # file exists - make sure it\'s intact via md5\n                with open(filename, "rb") as f:\n                    if not hashlib.md5(f.read()).hexdigest() == asset["md5"]:\n                        # the filename exists but the contents is wrong\n                        rewrite = True\n        if first_run or rewrite:\n            # one of our checks failed or first run - write file\n            print ("Writing file: ",filename)\n            with open(filename, "wb") as f:\n                f.write(base64.b64decode(asset["data"]))\n        else:\n            print ("File exists: ",filename)\n\n\n""" \nThis the data dictionary. It\'s very easy to save \nthe whole thing as json should you feel like it.\nThe images are just small, random icons at the moment \n\n"""\n\nassets = {\n    "background": {\n        "filename": "bg1.png", \n        "data": "iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAACOUlEQVQ4je2VQUhTcRzHP3szJyHiwbH5aCzpMCJ6NHIjWmzFtCBwKkEX7RYN2g4eAyF2jLRLzE5GoIegOgQNEarJCBwtYeQgPEQ0dC+fDNK5yFD3OuR7zL13WNCx7/ED3x8/vr8/379FVVWVA5WVZZY/TCEXMxxtdxLou082PU61sgpgYKI7hFzM4BD99A/PACBog9KpKPMvruvDwpEnlJUC4YFp2jtcpkzyxQBQ5BxKKQeANdj7LZHPTrK9VQTA7vTiD95lfe09+ewEtrZOTp29xbHjlwysyyFR3iiwvVXkR6XEiZPDtMjFjD5I8sfpdgV4OdtPeGCa/b2f9HgGWUhFqdV2DSwyMofkiyEXM/qWgt3pJRx5zJVrT+l2BQCoVlZ5++omojvIQipKZfOLKQPockiI7hAAy7kkltmkRzU7QLNq9ApmYQMIwhEkXxyr1aabG5mZ1/ow+SzRGPbnT8853XsbyR9HEFpZX1sEMLCLVx8ZDmUNnPma8J4bw9bWSY9nkHfzY/za+U5Z+YggtFJYmqJW2z14p4fZhrxEo9cym/So7R0uLlx+wOKbO3rYzarRKwDUarvs7+3om/yNGr3/j/IPjiK6Q1Qrq+QXJ4mMzDEaW9Hz6R+a0TM1Y6OxFYZuvKbLIXG+7x6iO4RgVkHN1tefGA5Xn0VVVTWdih4qSqWUo6wUyGcnkHxxRHeQ/b0dA9PKWJPd6aUFMFRQNj3eVH1peddXn0X7Auq3VOScIWyzA9QP0vQbENbTigXxO1gAAAAASUVORK5CYII=",\n        "md5": "12f7eb2eea8992a2644de649dfaf00b3"\n        },\n    "player_sprite": {\n        "filename": "player_img.png", \n        "data": "iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAACh0lEQVQ4jZWUS2gTURiFv5lkmiZpk5KmNWmbIFratLWlCiq2blwILly4EFSsG3EjCK5EFITiQhFXbgRBXbXgouBe3GkRKTaYvtLWR01sa5M0j8nDpK9xEWZIwqStZ3nuzLmX/7v3CIE7HxR5KobvwUkaB9wApAIx7H1O5h5+Jv5pFYAjT05r3maygHfIR8OxZlTJs+uERoKI3iEf1kN2HKdc2mJoJEjme1ILK/WyP1IcvNFTFpZfy7H0coaUP4qgKIqSC6exeOrJr2YxuSxM3x1nM5Hn7+8MpTK31Wme/WgTnsud2Puc2npyMlIMVI3p++O0XDiM44SLVCDGt2d+8itZdpOt10n77X7MrXUAGEtnkPJH2c5uItlNLI8t7hlW19FA68V2alusmickv0aVSgD7lR4oUQ8AgGAU8Vz1IdaIVT09UIabg9eHo+9DbMkbZYGeK514h3wIkkjKH9X1CpEcciBGfjVL5F0IeXa9CEUPgFgj4rnWRXg0yE5+u6pXKUEOxpXwaJDExNp/za+ahI/n3ip7f7a36rscRShVd9oHFFWmZosGxWjrdSJPxYoLLguFPzkA2i51FHesNfDr1UxVD6AQybHw9AtmtxXD8/HXw/Y+J/LsOu23+tlKb5BfyZKZjyNIIuHRIMpWcSp6nirfveNkFpIY0/MJlscWkRpMxXtklUhMrLGzsVN2CkDXU+en/lv2ltUKUu9dNakAwm8WqKw+7S2rFZSei+8apgKwdTciGEV+vpgqqz7tLatKTka0naEclBbqsmB2W+l5NEhl9RnOLw0MpwIxbN0OJFsNtW4rB8560QOlSgXQdMaDZDcBEHw8gWSrwahXQdVAVQIonb1aff8A8A1zY9iTMCcAAAAASUVORK5CYII=",\n        "md5": "79f25f0784a7849415f9c3d0d9d05267"\n        },\n    "weapon": {\n        "filename": "sword1.png", \n        "data": "iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAACzUlEQVQ4jZWVX0hTYRjGfydHZJb5J03SrIarrQaNEhKERgT25yaiIjEGQUWB0U03BUHWRVS3BUUOHGkUFg2LjW5bQkUjs6bNHcskJZRVplHTzs7bxdphy0Ot5+Ycnu99n3O+5/l4P+Q32u7FxO0JyOWOPvkbWjujouu68e72BOTqrX5j3UIG9mxdQXOTA4BI7AvB0Aca6itxOUoNruPBW5y2Yupc5RzauxoALakbGkrbvZgA1FQXUr++HEVR8PlVfH7VKGrcYeVoo51L3lcEQyNsql3CueMbjPWnL8eJDn0FIG9i7raWmuWF7G5YgaIoALgcpThtRWiacGSfnZ1bqlEUhYJ8Cw+7Rzm8dzXVSxcYglUVBYQjcW50DcLljj7Dk1zwt/rWzqgoIiL8gSs3+4m+myCiTmC3LqJ27WISM8lZXNpD750BDu5ZldqhiMjrgc9ysbVXevrjIiJy5Ey36Louw6NTouu6nLjwzJRL97o9AXnSM5ZKOTOAYGiExh1Wou++MjQyhXVZIeOffhDuiwOYcsHQB+NZ5yrHcmCXDaetiOCjERrqK9m4roxwJM7KqoWMf/pBeWk+LnsJ375rsziAhvpKgqFUL4Cph9duv2FweIpwXxyXvQSXo5TEtDaLO7DLZnje3ORAURTmpEW8dwZIa2tJITGjAZCYSaJpuimXxrH9a4wjh5mx/xtKZqAWM2NzDcUsUIuZsTXVhTmFYhaoEUqmsf8bShZaO6M5japc0N6lSt7kvO0tmqazfu3irA9FYl+44H2Fw1pEVUWBwfn8KgX5FirK5mfVd9wfxHs3Rt7JU6dbdBE0TYxGAJ9fRR2eZOZnks0bl+Lzq5y/3os6PMnD7lES00lqnamfCEfivB+dwmkrTh0bkdTEztx+T39c3J6APA5/NLjnr8fl7JUX8qRnzLCivUvNmthZgm5PIEv0X6OtvUuddQX8Ag5COzDf7kUwAAAAAElFTkSuQmCC",\n        "md5": "92485d36b8ac414cc758d9a6c6f28d23"\n        },\n}\n\n# get absolute path to asset directory\nasset_dir = "data"\nasset_dir_path = os.path.join(os.getcwd(), asset_dir)\n\n# create files in asset directory using the assets dictionary\ncreate_assets(assets, asset_dir_path)\n\npygame.init()\n\nWIDTH = 800\nHEIGHT = 600\n\nSCREEN = pygame.display.set_mode((WIDTH, HEIGHT))\n\nloaded_images = {}\n\n# initalize/load all the newly created images\nfor label in assets:\n    file_path = os.path.join(asset_dir_path,assets[label]["filename"])\n    loaded_images[label] = pygame.image.load(file_path)\n\npos1 = 0\npos2 = 0\nt_start = time.time()\n\nwhile time.time() - t_start < 5:\n    for img in loaded_images:\n        SCREEN.blit(loaded_images[img], (pos1, pos2))\n        time.sleep(0.2)\n        pos1 += 20\n        pos2 += 20\n        pygame.display.update()\n']], ['How can I pack images? -Pygame -PyInstaller'], 2, 1], [(36719792, 1), [['I turned the images into base64 strings like so:'], ['-10000']], [[' import base64\n\nwith open(img_input, "rb") as f:\n    with open(img_output_b64, "wb") as f2:\n        f2.write(base64.b64encode(f.read()))\n']], ['How can I pack images? -Pygame -PyInstaller'], 2, 0], [(36731365, 0), [['isinstance  will work just fine:'], ['but single dispatch is much more elegant approach:']], [[' from pyspark.sql import DataFrame\nfrom pyspark.rdd import RDD\n\ndef foo(x):\n    if isinstance(x, RDD):\n        return "RDD"\n    if isinstance(x, DataFrame):\n        return "DataFrame"\n\nfoo(sc.parallelize([]))\n## \'RDD\'\nfoo(sc.parallelize([("foo", 1)]).toDF())\n## \'DataFrame\'\n']], ['Check Type: How to check if something is a RDD or a dataframe?'], 4, 1], [(36731365, 1), [['but single dispatch is much more elegant approach:'], ["If you don't mind additional dependencies  multipledispatch  is also an interesting option:"]], [[' from functools import singledispatch\n\n@singledispatch\ndef bar(x):\n    pass \n\n@bar.register(RDD)\ndef _(arg):\n    return "RDD"\n\n@bar.register(DataFrame)\ndef _(arg):\n    return "DataFrame"\n\nbar(sc.parallelize([]))\n## \'RDD\'\n\nbar(sc.parallelize([("foo", 1)]).toDF())\n## \'DataFrame\'\n']], ['Check Type: How to check if something is a RDD or a dataframe?'], 4, 1], [(36731365, 2), [["If you don't mind additional dependencies  multipledispatch  is also an interesting option:"], ['Finally the most Pythonic approach is to simply check an interface:']], [[' from multipledispatch import dispatch\n\n@dispatch(RDD)\ndef baz(x):\n    return "RDD"\n\n@dispatch(DataFrame)\ndef baz(x):\n    return "DataFrame"\n\nbaz(sc.parallelize([]))\n## \'RDD\'\n\nbaz(sc.parallelize([("foo", 1)]).toDF())\n## \'DataFrame\'\n']], ['Check Type: How to check if something is a RDD or a dataframe?'], 4, 1], [(36744627, 0), [['I am using a proxy for this'], ['installing on Linux:']], [[' from selenium import webdriver\nfrom browsermobproxy import Server\n\nserver = Server(environment.b_mob_proxy_path)\nserver.start()\nproxy = server.create_proxy()\nservice_args = ["--proxy-server=%s" % proxy.proxy]\ndriver = webdriver.PhantomJS(service_args=service_args)\n\nproxy.new_har()\ndriver.get(\'url_to_open\')\nprint proxy.har  # this is the archive\n# for example:\nall_requests = [entry[\'request\'][\'url\'] for entry in proxy.har[\'log\'][\'entries\']]\n']], ['Network capturing with Selenium/PhantomJS'], 2, 1], [(36744627, 1), [['installing on Linux:'], ['-10000']], [[' pip install browsermob-proxy\n']], ['Network capturing with Selenium/PhantomJS'], 2, 0], [(36753799, 0), [["B. M.'s solution utilizing numpy is much faster - i would recommend to use his approach:"], ['try  itertools.product :']], [[" In [88]: %timeit pd.DataFrame({'col1':np.repeat(aa,bb.size),'col2':np.tile(bb,aa.size)})\n10 loops, best of 3: 25.4 ms per loop\n\nIn [89]: %timeit pd.DataFrame(list(product(aa,bb)), columns=['col1', 'col2'])\n1 loop, best of 3: 1.28 s per loop\n\nIn [90]: aa.size\nOut[90]: 1000\n\nIn [91]: bb.size\nOut[91]: 1000\n"]], ['Join unique values into new data frame (python, pandas)'], 2, 1], [(36753799, 1), [['try  itertools.product :'], ['-10000']], [[" In [56]: a\nOut[56]:\narray(['a', 'b', 'c', 'd'],\n      dtype='<U1')\n\nIn [57]: b\nOut[57]: array([1, 2, 3])\n\nIn [63]: pd.DataFrame(list(product(a,b)), columns=['col1', 'col2'])\nOut[63]:\n   col1  col2\n0     a     1\n1     a     2\n2     a     3\n3     b     1\n4     b     2\n5     b     3\n6     c     1\n7     c     2\n8     c     3\n9     d     1\n10    d     2\n11    d     3\n"]], ['Join unique values into new data frame (python, pandas)'], 2, 1], [(36765952, 0), [['You could use generators to find all positions, and  min()  to locate the left-most:'], ["This does scan the string 3 times; if the number of substrings tested is large enough, you'd want to build a  trie structure  instead, loop over indices into  s  and test if the characters at that position are present in the trie:"]], [[' positions = (s.find(sub), sub) for sub in (s1, s2, s3))\nleftmost = min((pos, sub) for pos, sub in positions if pos > -1)[1]\n']], ['Python: Is there a shortcut to finding which substring(from a set of substrings) comes first in a string?'], 2, 1], [(36765952, 1), [["This does scan the string 3 times; if the number of substrings tested is large enough, you'd want to build a  trie structure  instead, loop over indices into  s  and test if the characters at that position are present in the trie:"], ['The trie can be re-used for multiple strings.']], [[" def make_trie(*words):\n     root = {}\n     for word in words:\n         current = root\n         for letter in word:\n             current = current.setdefault(letter, {})\n         # insert sentinel at the end\n         current[None] = None\n     return root\n\ndef find_first(s, trie):\n    for i in range(len(s)):\n        pos, current, found = i, trie, []\n        while pos < len(s) and s[pos] in current:\n            found.append(s[pos])\n            current = current[s[pos]]\n            if None in current:  # whole substring detected\n                return ''.join(found)\n            pos += 1\n\nleftmost = find_first(s, make_trie(s1, s2, s3))\n"]], ['Python: Is there a shortcut to finding which substring(from a set of substrings) comes first in a string?'], 2, 1], [(36779891, 0), [['I would just build a new list by constantly appending to it rather than inserting into an existing list.  This should work:'], ['-10000']], [[' n = len(list_a)\nnewList = []\nfor i in range(0,n, 6):\n    newList.append(list_a[i:i+6] ) \n\n    newTuple1 = (newList[-1][1], newList[i][0])\n    newList.append(newTuple1)\n    try:\n        newTuple2 = (newTuple1[0] + 1, list_a[i+6][0])\n        newList.append(newTuple2)\n    except IndexError:\n        print "There was no next tuple"\n\nprint newList\n']], ['Insert values in lists following a pattern'], 2, 1], [(36779891, 1), [['-10000'], ['Note that your example did not indicate what to do in case two if there are no additional tuples.  Supposed there are 12 tuples in list_a.  Then when you get to the second group of 2, there is no  next  tuple.']], [[' There was no next tuple\n[(1, 6), (6, 66), (66, 72), (72, 78), (78, 138), (138, 146), (146, 1), (147, 154), (154, 208), (208, 217), (217, 225), (225, 279), (279, 288), (300, 400), (400, 146)]\n']], ['Insert values in lists following a pattern'], 2, 0], [(36783166, 0), [['This one also uses zip so you have a reference of the color being counted:'], ['The way to use reduce to count the elements was giving me some thought, the only way I found of doing it was this:']], [[' zip(colours, map(lambda x: len(filter(lambda y: y==x, c)), colours))\n']], ['Use map over a list of 50 generated colours to count, using filter, and reduce, or len, the frequency of occurence'], 2, 0], [(36783166, 1), [['The way to use reduce to count the elements was giving me some thought, the only way I found of doing it was this:'], ['-10000']], [[' map(lambda color: reduce(lambda x,y: x+y, map(lambda y: 1,filter(lambda x: x==color, c))), colours)\n']], ['Use map over a list of 50 generated colours to count, using filter, and reduce, or len, the frequency of occurence'], 2, 0], [(36785204, 0), [['If I understood your question correctly, you just need  .loc  ( ix  would also work):'], ['For assignment:']], [[' df.loc[df.DEFAULT, special]\nOut[40]: \n          A         D         G         I\n2  0.629427  0.532373  0.529779  0.274649\n4  0.226196  0.467896  0.851469  0.971351\n7  0.666459  0.351840  0.414972  0.451190\n8  0.238104  0.277630  0.943198  0.293356\n']], ['Conditionally replace several columns with default values in Pandas'], 2, 1], [(36785204, 1), [['For assignment:'], ['-10000']], [[' df.loc[df.DEFAULT, special] = default\n\ndf\nOut[44]: \n          A         B         C         D         E         F         G  \\\n0  0.513798  0.138073  0.685051  0.173045  0.964050  0.245352  0.360657   \n1  0.286920  0.464747  0.301910  0.857810  0.957686  0.684297  0.381671   \n2  1.000000  0.454802  0.707585  2.000000  0.777142  0.738670  3.000000   \n3  0.894643  0.987747  0.162569  0.430214  0.205933  0.651764  0.361578   \n4  1.000000  0.859582  0.014823  2.000000  0.658297  0.875474  3.000000   \n5  0.075581  0.848288  0.819145  0.429341  0.718035  0.275785  0.951492   \n6  0.984910  0.858093  0.665032  0.138201  0.006561  0.282801  0.050243   \n7  1.000000  0.215375  0.594164  2.000000  0.666909  0.598950  3.000000   \n8  1.000000  0.931840  0.568436  2.000000  0.911106  0.727052  3.000000   \n9  0.140491  0.181527  0.436082  0.617412  0.468370  0.496973  0.426825   \n\n          H         I         J DEFAULT  \n0  0.964239  0.422831  0.660515   False  \n1  0.650808  0.112612  0.897050   False  \n2  0.537366  4.000000  0.243392    True  \n3  0.377302  0.341089  0.488061   False  \n4  0.074656  4.000000  0.317079    True  \n5  0.990471  0.634703  0.141121   False  \n6  0.026650  0.731152  0.589984   False  \n7  0.570956  4.000000  0.762232    True  \n8  0.828288  4.000000  0.359620    True  \n9  0.701504  0.050273  0.427838   False  \n']], ['Conditionally replace several columns with default values in Pandas'], 2, 1], [(36794619, 0), [['Instead we need to create a new datetime object.\nConsider this as a guide:'], ['outputs:']], [[' from datetime import datetime\nfrom dateutil import relativedelta\n\norig_start = datetime.now()\norig_end = datetime.now() + relativedelta.relativedelta(months=1)\n\nprint(orig_start)\nprint(orig_end)\n\nmod_start = datetime(year=orig_start.year,\n                     month=orig_start.month,\n                     day=orig_start.day,\n                     hour=0, minute=0, second=0)\n\nmod_end = datetime(year=orig_end.year,\n                   month=orig_end.month,\n                   day=orig_end.day,\n                   hour=23, minute=59, second=59)\n\n# or even better as suggested in the comments:\nmod_end = orig_end.replace(hour=23, minute=59, second=59, microsecond=0)\n\nprint(mod_start)\nprint(mod_end)\n']], ['Customizing time of the datetime object in python'], 2, 1], [(36794619, 1), [['outputs:'], ['-10000']], [[' 2016-04-22 16:11:08.171845\n2016-05-22 16:11:08.171845\n2016-04-22 00:00:00\n2016-05-22 23:59:59\n']], ['Customizing time of the datetime object in python'], 2, 0], [(36798227, 0), [['-10000'], ['-10000']], [[' reference,name,house\n2348A,john,37\n5648R,bill,3\nRT48,kate,88\n76A,harry ,433\n']], ['Python CSVkit compare CSV files'], 4, 0], [(36798227, 1), [['-10000'], ['-10000']], [[' reference\n2348A\n76A\n']], ['Python CSVkit compare CSV files'], 4, 0], [(36798227, 2), [['-10000'], ['-10000']], [[" import pandas as pd\ndf1 = pd.read_csv(r'd:\\temp\\data1.csv')\ndf2 = pd.read_csv(r'd:\\temp\\data2.csv')\ndf3 = pd.merge(df1,df2, on= 'reference', how='inner')\ndf3.to_csv('outpt.csv')\n"]], ['Python CSVkit compare CSV files'], 4, 1], [(36798227, 3), [['-10000'], ['-10000']], [[' ,reference,name,house\n0,2348A,john,37\n1,76A,harry ,433\n']], ['Python CSVkit compare CSV files'], 4, 0], [(36799190, 0), [['Here is how I resolved this using  explode :'], ['Final Output of the above (after dropping irrelevant columns) resulted in this:']], [[" df = df.withColumn('temp', split(df.fieldList, ','))\ndf = df.withColumn('cols', explode(df.temp))\ndf = df.withColumn('col_value', split(df.cols, '='))\ndf = df.withColumn('deltaCol', df.col_value[0])\n       .withColumn('deltaValue',df.col_value[1])\n"]], ['Update a Pyspark DF Column based on an Array in another column'], 5, 1], [(36799190, 1), [['Final Output of the above (after dropping irrelevant columns) resulted in this:'], ['After this I registered it as a table and performed SQL operation to pivot the data:']], [[" +------+-----+--------+--------------------+--------+----------+\n|    id|table|    user|          changeDate|deltaCol|deltaValue|\n+------+-----+--------+--------------------+--------+----------+\n|555555| TAB2| user11 | 2016-01-24 19:10...| value2 |       100|\n|  1111| TAB1| user01 | 2015-12-31 13:12...|  value |      0.34|\n|  1111| TAB1| user01 | 2015-12-31 13:12...|   name | 'newName'|\n+------+-----+--------+--------------------+--------+----------+\n"]], ['Update a Pyspark DF Column based on an Array in another column'], 5, 0], [(36799190, 2), [['After this I registered it as a table and performed SQL operation to pivot the data:'], ['The result of this was:']], [[' >>> res = sqlContext.sql("select id, table, user, changeDate, max(value2) as value2, max(value) as value, max(name) as name \\\n... from (select id, table, user, changeDate, case when trim(deltaCol) == \'value2\' then deltaValue else Null end value2,\\\n... case when trim(deltaCol) == \'value\' then deltaValue else Null end value,\\\n... case when trim(deltaCol) == \'name\' then deltaValue else Null end name from delta) t group by id, table, user, changeDate")\n']], ['Update a Pyspark DF Column based on an Array in another column'], 5, 0], [(36799190, 3), [['The result of this was:'], ['For usage of this code with different tables, I used the columns of the master DF(my eventual target table) to prepare a string of columns:']], [[" +------+-----+--------+--------------------+------+-----+----------+\n|    id|table|    user|          changeDate|value2|value|      name|\n+------+-----+--------+--------------------+------+-----+----------+\n|555555| TAB2| user11 | 2016-01-24 19:10...|   100| null|      null|\n|  1111| TAB1| user01 | 2015-12-31 13:12...|  null| 0.34| 'newName'|\n+------+-----+--------+--------------------+------+-----+----------+\n"]], ['Update a Pyspark DF Column based on an Array in another column'], 5, 0], [(36799190, 4), [['For usage of this code with different tables, I used the columns of the master DF(my eventual target table) to prepare a string of columns:'], ['-10000']], [[' >>> string = [(", max(" + c + ") as " + c) for c in masterDF.columns]\n>>> string = "".join(string)\n>>> string\n\', max(id) as id, max(value) as value, max(name) as name, max(value2) as value2\'\n']], ['Update a Pyspark DF Column based on an Array in another column'], 5, 0], [(36804141, 2), [['the result:'], ['-10000']], [[' 0   2012-01-05 10:30:00\n1   2013-03-20 20:40:30\ndtype: datetime64[ns]\n']], ['Vectorized construction of DatetimeIndex in Pandas'], 3, 0], [(36804586, 0), [["I have tried an approach for solving this problem. It tries to create a list of characters and fill it with characters from the original string, in the order of their frequency. For example, for a string 'babac' with given distance 2, it fills in the order:"], ['Here is the code, hope its useful:']], [[" most common:  ('b', 3)  # character b with frequency 3\n['-', '-', '-', '-', '-', '-']\nupdated o:  ['b', '-', '-', '-', '-', '-']\n['b', '-', '-', '-', '-', '-']\nupdated o:  ['b', '-', 'b', '-', '-', '-']\n['b', '-', 'b', '-', '-', '-']\nupdated o:  ['b', '-', 'b', '-', 'b', '-']\nmost common:  ('c', 2)\n['b', '-', 'b', '-', 'b', '-']\nupdated o:  ['b', 'c', 'b', '-', 'b', '-']\n['b', 'c', 'b', '-', 'b', '-']\nupdated o:  ['b', 'c', 'b', 'c', 'b', '-']\nmost common:  ('a', 1)\n['b', 'c', 'b', 'c', 'b', '-']\nupdated o:  ['b', 'c', 'b', 'c', 'b', 'a']\n"]], ['Reordering same characters such that the characters are at least distance d from each other'], 2, 0], [(36804586, 1), [['Here is the code, hope its useful:'], ['-10000']], [[' import collections\nimport math\n\ndef printMyString():\n  # get inputs\n  myStr = raw_input("enter string: ")\n  dist = int(raw_input("enter dist: "))\n\n  #create a dict, where each key is a character from myStr and corresponding value is its frequency\n  counter = collections.Counter(list(myStr))\n\n  # create an empty list where we will fill our characters to get final string\n  o = [\'-\']*len(myStr)\n\n  # get the most common character\n  most_common_char_freq = counter.most_common(1)[0][1]\n\n  # sep is the maximum distance at which repeated instances of the most frequent character m can be located from each other in the final string.\n  sep = int(math.ceil(len(myStr)*1.0/most_common_char_freq))\n\n  # if sep is less than given distance, then it is not possible to have such a string.\n\n  if(sep < dist):\n    print "such a string is not possible"\n    return\n  #print "sep", sep\n\n\n  j = 0 # this marks index at which we can write into the list\n\n  # while we still have characters left, we will continue to fill our output list o \n  while len(counter) > 0:\n   current_most_common_char = counter.most_common(1)[0][0]       # get the most common character left in counter        \n   current_most_common_char_freq = counter.most_common(1)[0][1]   \n\n   #print "most common: ", current_most_common_char\n   while o[j] != \'-\':  # Go to the next position in the output list where a character is yet to be written.\n     j += 1  \n     if(j == len(o)):  # We are out of places to write, this is bad!\n      # print "breaking, o = ", o\n      return\n\n   for i in range(current_most_common_char_freq): # For multiple occurences of the current most freq char, we write them one after the other, a distance of \'sep\' apart\n    #print o\n    if (j+i*sep) >= len(o): # If we have to go beyond the length of the output list/string to write a character, then such a string is not possible\n      #print "not possible, o, char is ", o, current_most_common_char\n      print "such a string is not possible"\n      return\n    o[j+i*sep] = current_most_common_char # Write to the output list\n    #print "updated o: ", o\n\n   del counter[current_most_common_char] # remove the most common character. lets move on to next one in the loop.\n   j += 1 # update before moving on\n\n  print \'\'.join(o) # merge the characters in the output list to get final string\n\nprintMyString()\n']], ['Reordering same characters such that the characters are at least distance d from each other'], 2, 1], [(36806340, 0), [['The following code will do the job for your specific use-case, though can make it more general purpose re-namer.'], ['Pre-assumptions:\nnewnames.txt -  comma ']], [[' import os # os is a library that gives us the ability to make OS changes\n\ndef file_renamer(list_of_files, new_file_name_list):\n    for file_name in list_of_files:\n        for (new_filename, barcode_infile) in new_file_name_list:\n            # as per the mentioned filename pattern -> xxxx.1.xxxx.[barcode]\n            barcode_current = file_name[12:19] # extracting the barcode from current filename\n            if barcode_current == barcode_infile:\n                os.rename(file_name, new_filename)  # renaming step\n                print \'Successfully renamed %s to %s \' % (file_name, new_filename)\n\n\nif __name__ == "__main__":\n    path = os.getcwd()  # preassuming that you\'ll be executing the script while in the files directory\n    file_dir = os.path.abspath(path)\n    newname_file = raw_input(\'enter file with new names - or the complete path: \')\n    path_newname_file = os.path.join(file_dir, newname_file)\n    new_file_name_list = []\n    with open(path_newname_file) as file:\n        for line in file:\n            x = line.strip().split(\',\')\n            new_file_name_list.append(x)\n\n    list_of_files = os.listdir(file_dir)\n    file_renamer(list_of_files, new_file_name_list)\n']], ['Python3 Rename files in a directory importing the new names from a txt file'], 5, 1], [(36806340, 1), [['Pre-assumptions:\nnewnames.txt -  comma '], ['Files ']], [[' 0000.1.0000.1234567,1234567\n0000.1.0000.1234568,1234568\n0000.1.0000.1234569,1234569\n0000.1.0000.1234570,1234570\n0000.1.0000.1234571,1234571\n']], ['Python3 Rename files in a directory importing the new names from a txt file'], 5, 0], [(36806340, 2), [['Files '], ['were renamed to ']], [[' 1111.1.0000.1234567\n1111.1.0000.1234568\n1111.1.0000.1234569 \n']], ['Python3 Rename files in a directory importing the new names from a txt file'], 5, 0], [(36806340, 3), [['were renamed to '], ['The terminal output:']], [[' 0000.1.0000.1234567\n0000.1.0000.1234568\n0000.1.0000.1234569\n']], ['Python3 Rename files in a directory importing the new names from a txt file'], 5, 0], [(36806340, 4), [['The terminal output:'], ['-10000']], [[" >python file_renamer.py\nenter file with new names: newnames.txt\nThe list of files -  ['.git', '.idea', '1111.1.0000.1234567', '1111.1.0000.1234568', '1111.1.0000.1234569', 'file_renamer.py', 'newnames.txt.txt']\nSuccessfully renamed 1111.1.0000.1234567 to 0000.1.0000.1234567\nSuccessfully renamed 1111.1.0000.1234568 to 0000.1.0000.1234568\nSuccessfully renamed 1111.1.0000.1234569 to 0000.1.0000.1234569\n"]], ['Python3 Rename files in a directory importing the new names from a txt file'], 5, 0], [(36835793, 0), [['A way to do that :'], ['Use  cut  to make groups :']], [[" df = pd.DataFrame([[1,3,10], [4,10,7], [11,17,6], [18,26, 12],\n[27,30, 15], [31,40,6], [41, 42, 6]], columns=['start','end', 'height'])\n"]], ['Pandas - group by consecutive ranges'], 6, 0], [(36835793, 1), [['Use  cut  to make groups :'], ['Find break points :']], [[" df['groups']=pd.cut(df.height,[-1,0,5,10,15,1000])\n"]], ['Pandas - group by consecutive ranges'], 6, 0], [(36835793, 2), [['Find break points :'], ['Then  df  is :']], [[" df['categories']=(df.groups!=df.groups.shift()).cumsum()\n"]], ['Pandas - group by consecutive ranges'], 6, 0], [(36835793, 3), [['Then  df  is :'], ['Define interesting data :']], [[' """\n   start  end  height    groups  categories\n0      1    3      10   (5, 10]           0\n1      4   10       7   (5, 10]           0\n2     11   17       6   (5, 10]           0\n3     18   26      12  (10, 15]           1\n4     27   30      15  (10, 15]           1\n5     31   40       6   (5, 10]           2\n6     41   42       6   (5, 10]           2\n"""\n']], ['Pandas - group by consecutive ranges'], 6, 0], [(36835793, 4), [['Define interesting data :'], ['And use the  groupby.agg  function :']], [[" f = {'start':['first'],'end':['last'], 'groups':['first']}\n"]], ['Pandas - group by consecutive ranges'], 6, 0], [(36835793, 5), [['And use the  groupby.agg  function :'], ['-10000']], [[' df.groupby(\'categories\').agg(f)\n"""\n              groups  end start\n               first last first\ncategories                     \n0            (5, 10]   17     1\n1           (10, 15]   30    18\n2            (5, 10]   42    31\n"""\n']], ['Pandas - group by consecutive ranges'], 6, 0], [(36845683, 0), [['I guess you want to do something like this:'], ['This:']], [[" data_copy = list(data)  # you can replace any appearance of data_copy with data if you don't care if it is changed\nwhile data_copy:  # this is equivalent to: while len(data_copy) != 0:\n    to = min(10, len(data_copy))  # If there are less then 10 entries left, the length will be smaller than ten, so that it is either 10 or the (smaller) length. This is the amount of data that's processed\n    f(data_copy[:to])  # make the function call with any value up to 'to'\n    del data_copy[:to]  # delete the data, because we already processed it\n"]], ["Adding 'n' values in list using for-loop and step-loop for that 'n' values in python"], 3, 1], [(36845683, 1), [['This:'], ['yields the expected output of']], [[' def f(x): print(x)\ndata = list(range(53))  # list from 0 (included) to 52 (included)\n# here is the top part\n']], ["Adding 'n' values in list using for-loop and step-loop for that 'n' values in python"], 3, 0], [(36845683, 2), [['yields the expected output of'], ['-10000']], [[' [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n[50, 51, 52]\n']], ["Adding 'n' values in list using for-loop and step-loop for that 'n' values in python"], 3, 0], [(36849151, 0), [["UPDATE2:  here is  ayhan 's solution which will work  properly :"], ['Here is an example:']], [[' In [135]: df[df.Distance.astype("int64")>=df.Distance.astype("int64").cummax()]\nOut[135]:\n  Area  Distance\n0    1  19626207\n1    2  20174412\n2    3  20174412\n7    8  20195112\n8    9  21127633\n']], ['Compare rows then take rows out if neccessary'], 4, 1], [(36849151, 3), [['Explanation:'], ['-10000']], [[' In [98]: df.Distance.cummax()\nOut[98]:\n0    19626207\n1    20174412\n2    20175112\n3    20175112\n4    20175112\n5    20175112\n6    20175112\n7    20195112\n8    21127633\n9    21127633\nName: Distance, dtype: object\n']], ['Compare rows then take rows out if neccessary'], 4, 0], [(36921573, 0), [['However, NumPy does have a helper function,  np.vectorize , which can make the syntax prettier.  np.vectorize  returns a function which can take arrays as input and return an array as output.  np.vectorize  is mainly  "for convenience, not for performance" . Under the hood it performs a  for-loop  much like the one you wrote. Thus, the explicit  for-loop  can be replaced by'], ['-10000']], [[' binom_test = np.vectorize(stats.binom_test)\nresult = binom_test(x, x+y)\n']], ['Given two numpy arrays of same size, how to apply a function two each pair of elements at identical position?'], 3, 0], [(36921573, 1), [['-10000'], ['yields']], [[' import numpy as np\nfrom scipy import stats\nnp.random.seed(2016)\nh, w = 3, 4\n\nx=np.random.random_integers(4,9,(h,w))\ny=np.random.random_integers(4,9,(h,w))\n\nresult = np.ones((h,w))\nfor row in range(h):\n    result[row,:] = np.array([stats.binom_test(x[row,_], x[row,_]+y[row,_]) \n                              for _ in range(w)])\n\nbinom_test = np.vectorize(stats.binom_test)\nresult2 = binom_test(x, x+y)\n\nassert np.allclose(result, result2)\nprint(result2)\n']], ['Given two numpy arrays of same size, how to apply a function two each pair of elements at identical position?'], 3, 1], [(36921573, 2), [['yields'], ['-10000']], [[' [[ 1.          0.75390625  0.77441406  0.60723877]\n [ 1.          0.79052734  0.77441406  0.77441406]\n [ 1.          1.          1.          1.        ]]\n']], ['Given two numpy arrays of same size, how to apply a function two each pair of elements at identical position?'], 3, 0], [(36923865, 0), [['models.py'], ['admin.py']], [[" class Router(models.Model):\n    specifications = models.FileField(upload_to='router_specifications')\n"]], ['Uploading files using Django Admin'], 3, 0], [(36923865, 1), [['admin.py'], ["When rendering a view to a user, pass the model(s) in the view's context and use the field's  url  property to link to the file. "]], [[' from django.contrib import admin\nfrom my_app import models\n\nadmin.site.register(models.Router)\n']], ['Uploading files using Django Admin'], 3, 0], [(36923865, 2), [["When rendering a view to a user, pass the model(s) in the view's context and use the field's  url  property to link to the file. "], ['-10000']], [[' <a href="{{ my_model_instance.specifications.url }}">Download PDF</a>\n']], ['Uploading files using Django Admin'], 3, 0], [(36928577, 0), [['You can look up packages in the PyPI using the  XMLRPC API :'], ['Prints:']], [[' try:\n    import xmlrpclib  # Python 2\nexcept ImportError:\n    import xmlrpc.client as xmlrpclib  # Python 3\n\npypi = xmlrpclib.ServerProxy(\'http://pypi.python.org/pypi\')\n\npackage_name = "Flask-Login"\n\npackages = pypi.search({"name": package_name})\npackage = next(package for package in packages if package["name"] == package_name)\nrelease_data = pypi.release_data(package_name, package["version"])\n\nprint(package_name)\nprint(package["version"])\nprint(release_data["summary"])\nprint(release_data["home_page"])\n']], ['How can I get a list of package locations from a PIP requirements file?'], 2, 1], [(36928577, 1), [['Prints:'], ['-10000']], [[' Flask-Login\n0.3.0\nUser session management for Flask\nhttps://github.com/maxcountryman/flask-login\n']], ['How can I get a list of package locations from a PIP requirements file?'], 2, 0], [(36935617, 1), [['seen.add(x)  adds  x  to the set  seen . The  seen.add  method returns  None . So\nin a boolean context, (since  bool(None)  is  False ),  not seen.add(x)  is always  True . Therefore the condition'], ['has a boolean value equal to ']], [[' x not in seen and not seen.add(x)\n']], ['Remove following duplicates in a tuple'], 6, 0], [(36935617, 2), [['has a boolean value equal to '], ['which is equivalent to ']], [[' x not in seen and True\n']], ['Remove following duplicates in a tuple'], 6, 0], [(36935617, 3), [['which is equivalent to '], ['So the conditional expression']], [[' x not in seen\n']], ['Remove following duplicates in a tuple'], 6, 0], [(36935617, 5), [['This could also be written, not as succinctly, but without the complexity, as'], ['-10000']], [[" def replace_dupes(ax):\n    result = []\n    seen = set()\n    for x in ax:\n        if x in seen:\n            result.append('')\n        else:\n            seen.add(x)\n            result.append(x)\n    return result\n\nax = ('0','1','1','1','2','2','2','3')\nprint(replace_dupes(ax))\n# ['0', '1', '', '', '2', '', '', '3']\n"]], ['Remove following duplicates in a tuple'], 6, 1], [(36939122, 0), [['You can use  zip  and  numpy  functions  mean  and  round  for this task:'], ['Version with "less" parenthesis:']], [[" In [8]: import numpy as np\n\nIn [9]:  [dict(zip(d.keys(), [int(np.round(np.mean(d.values())))])) for d in L]\n\n#Out[9]: [{'Eva': 5}, {'Ana': 53}, {'Ada': 12}]\n"]], ['Average of key values in a list of dictionaries'], 2, 1], [(36939122, 1), [['Version with "less" parenthesis:'], ['-10000']], [[' [dict(zip(d.keys(), [np.array(d.values()).mean().round().astype(int)])) for d in L]\n']], ['Average of key values in a list of dictionaries'], 2, 1], [(36949277, 0), [['You could use  Counter  to order the key pairs based on their frequency. It also provides an easy way to get x most frequent items:'], ['Output:']], [[" from collections import Counter\n\nd = {\n    'KEY1': {\n        'key2_1': 5,\n        'key2_2': 1,\n        'key2_3': 3\n    },\n    'KEY2': {\n        'key2_1': 2,\n        'key2_2': 3,\n        'key2_3': 4\n    }\n}\n\nc = Counter()\nfor k, v in d.iteritems():\n    c.update({(k, k1): v1 for k1, v1 in v.iteritems()})\n\nprint c.most_common(3)\n"]], ['Ordering a nested dictionary by the frequency of the nested value'], 7, 1], [(36949277, 1), [['Output:'], ['If you only care about the most common key pairs and have no other reason to build nested dictionary you could just use the following code:']], [[" [(('KEY1', 'key2_1'), 5), (('KEY2', 'key2_3'), 4), (('KEY2', 'key2_2'), 3)]\n"]], ['Ordering a nested dictionary by the frequency of the nested value'], 7, 0], [(36949277, 2), [['If you only care about the most common key pairs and have no other reason to build nested dictionary you could just use the following code:'], ['Short explanation :  ((v[:3], v[3:]) for v in l)  is a  generator expression  that will generate  tuples  where first item is the same as top level key in your original  dict  and second item is the same as key in nested  dict .']], [[" from collections import Counter\n\nl = ['foobar', 'foofoo', 'foobar', 'barfoo']\nD = Counter((v[:3], v[3:]) for v in l)\nprint D.most_common() # [(('foo', 'bar'), 2), (('foo', 'foo'), 1), (('bar', 'foo'), 1)]\n"]], ['Ordering a nested dictionary by the frequency of the nested value'], 7, 1], [(36949277, 3), [['Short explanation :  ((v[:3], v[3:]) for v in l)  is a  generator expression  that will generate  tuples  where first item is the same as top level key in your original  dict  and second item is the same as key in nested  dict .'], ['Counter  is a subclass of  dict . It accepts an  iterable  as an argument and each unique element in  iterable  will be used as key and value is the count of element in the  iterable .']], [[" >>> x = list((v[:3], v[3:]) for v in l)\n>>> x\n[('foo', 'bar'), ('foo', 'foo'), ('foo', 'bar'), ('bar', 'foo')]\n"]], ['Ordering a nested dictionary by the frequency of the nested value'], 7, 0], [(36949277, 4), [['Counter  is a subclass of  dict . It accepts an  iterable  as an argument and each unique element in  iterable  will be used as key and value is the count of element in the  iterable .'], ['The  if  statements you asked about are checking if the key exists in  dict :']], [[" >>> c = Counter(x)\n>>> c\nCounter({('foo', 'bar'): 2, ('foo', 'foo'): 1, ('bar', 'foo'): 1})\n"]], ['Ordering a nested dictionary by the frequency of the nested value'], 7, 0], [(36949277, 5), [['The  if  statements you asked about are checking if the key exists in  dict :'], ["So the following code will check if key with value of  id  exists in dict  D  and if it doesn't it will assign empty dict there."]], [[" >>> d = {1: 'foo'}\n>>> 1 in d\nTrue\n>>> 2 in d\nFalse\n"]], ['Ordering a nested dictionary by the frequency of the nested value'], 7, 0], [(36949277, 6), [["So the following code will check if key with value of  id  exists in dict  D  and if it doesn't it will assign empty dict there."], ['The second  if  does exactly the same for nested dictionaries.']], [[' if id not in D:\n    D[id] = {}\n']], ['Ordering a nested dictionary by the frequency of the nested value'], 7, 0], [(36950503, 0), [['It was quite tricky for me but works anyhow. Expecting more elegant solution from others.'], ['Result,']], [[" import pandas as pd\nimport datetime\n\ndateparse = lambda x: pd.datetime.strptime(x, '%m/%d/%Y')\ndf = pd.read_csv('Sample.csv',index_col='date', parse_dates=[0], date_parser=dateparse)\n\nexpd_gb = df.reset_index().groupby(['wholesaler', 'product'])['sales'].apply(pd.Series.expanding)\nidx = df.reset_index().groupby(['wholesaler', 'product', 'date'])['sales'].count().index\n\ncnct = pd.concat([expd_gb.iloc[n].mean().shift(1) for n in range(len(expd_gb))])\ncnct.index = idx\n\ncnct.to_csv('TotalAvg.csv')\n"]], ['How to find the average of previous sales at each time in python'], 2, 1], [(36950503, 1), [['Result,'], ['-10000']], [[' wholesaler  product  date      \n11209       UME24    2013-12-31     NaN\n13131       UPE55    2012-12-31     NaN\n                     2013-02-23     1.0\n                     2013-04-24     578.5\n52237       UPE54    2013-12-18     NaN\n                     2013-12-31     9.0\n53929       UME24    2013-12-19     NaN\n            UPE54    2012-12-31     NaN\n82204       UPE55    2012-12-31     NaN\n83389       UPE54    2013-12-01     NaN\n                     2013-12-17     9.0\n']], ['How to find the average of previous sales at each time in python'], 2, 0], [(36967883, 0), [['Expanding on the last one you can total up the scores as well as the number of entries for each name like this:'], ['Then you can calculate the average score for each person with  total_scores[name] / entries[name]']], [[' import csv\nimport collections\n...\nwith open(path) as f:\n    entries = collections.Counter()\n    total_scores = collections.Counter()\n    for name,score in csv.reader(f):\n        total_scores[name] += int(score)\n        entries[name] += 1\n']], ['Sorting data from a csv alphabetically, highest to lowest and average'], 4, 0], [(36967883, 1), [['Then you can calculate the average score for each person with  total_scores[name] / entries[name]'], ['the other two actions are quite simple with a few of the steps listed above.']], [[' for name in sorted(entries):\n    ave_score = total_scores[name] / entries[name]\n    print(name,ave_score) #sep=", ")\n']], ['Sorting data from a csv alphabetically, highest to lowest and average'], 4, 0], [(36967883, 2), [['the other two actions are quite simple with a few of the steps listed above.'], ['If you want to apply the highest to lowest to the average scores then you will need to make a reference to all the averages such as a  dict :']], [[' import csv\nimport collections\nfrom operator import itemgetter\n\n...\n\nif sort_int == 1:\n    with open(path) as f:\n        reader = csv.reader(f)\n        for name, score in sorted(reader):\n            print(name,score)\n\nelif sort_int == 2:\n    with open(path) as f:\n        entries = sorted(csv.reader(f), \n                         key=itemgetter(1), \n                         reverse=True)\n        for name,score in entries:\n            print(name,score)\n\nelif sort_int == 3:\n    with open(path) as f:\n        entries = collections.Counter()\n        total_scores = collections.Counter()\n        for name,score in csv.reader(f):\n            score = int(score)\n            total_scores[name] += score\n            entries[name] += 1\n\n        for name in sorted(entries):\n            ave_score = total_scores[name] / entries[name]\n            print(name,ave_score)\n']], ['Sorting data from a csv alphabetically, highest to lowest and average'], 4, 0], [(36967883, 3), [['If you want to apply the highest to lowest to the average scores then you will need to make a reference to all the averages such as a  dict :'], ['-10000']], [[' ave_scores = {}\nfor name in sorted(entries):\n    ave_score = total_scores[name] / entries[name]\n    ave_scores[name] = ave_score\n\nfor name,ave_score in sorted(ave_scores.items(), key = itemgetter(1), reversed=True):\n    print(name,ave_score)\n']], ['Sorting data from a csv alphabetically, highest to lowest and average'], 4, 0], [(36971201, 0), [['Here is an efficient solution and a comparison with the solution using  index  (the  index  solution is also not correct with the added (edit 3) restriction to the question)'], ['Comparison results']], [[' import numpy as np\n\ndef rank1(x):\n    # Sort values i = 0, 1, 2, .. using x[i] as key\n    y = sorted(range(len(x)), key = lambda i: x[i])\n    # Map each value of x to a rank. If a value is already associated with a\n    # rank, the rank is updated. Iterate in reversed order so we get the\n    # smallest rank for each value.\n    rank = { x[y[i]]: i for i in xrange(len(y) -1, -1 , -1) }\n    # Remove gaps in the ranks\n    kv = sorted(rank.iteritems(), key = lambda p: p[1])\n    for i in range(len(kv)):\n        kv[i] = (kv[i][0], i)\n    rank = { p[0]: p[1] for p in kv }\n    # Pre allocate a array to fill with ranks\n    r = np.zeros((len(x),), dtype=np.int)\n    for i, v in enumerate(x):\n        r[i] = rank[v]\n    return r\n\ndef rank2(x):\n    x_sorted = sorted(x)\n    # creates a new list to preserve x\n    rank = list(x)\n    for v in x_sorted:\n        rank[rank.index(v)] = x_sorted.index(v)\n    return rank\n']], ['map array of numbers to rank efficiently in Python'], 2, 1], [(36971201, 1), [['Comparison results'], ['The problem with the  index  solution is that the time complexity is O(n^2). The time complexity of my solution is O(n lg n), that is, the sort time.']], [[' >>> d = np.arange(1000)\n>>> random.shuffle(d)\n>>> %timeit rank1(d)\n100 loops, best of 3: 1.97 ms per loop\n>>> %timeit rank2(d)\n1 loops, best of 3: 226 ms per loop\n\n>>> d = np.arange(10000)\n>>> random.shuffle(d)\n>>> %timeit rank1(d)\n10 loops, best of 3: 32 ms per loop\n>>> %timeit rank2(d)\n1 loops, best of 3: 24.4 s per loop\n\n>>> d = np.arange(100000)\n>>> random.shuffle(d)\n>>> %timeit rank1(d)\n1 loops, best of 3: 433 ms per loop\n\n>>> d = np.arange(2000000)\n>>> random.shuffle(d)\n>>> %timeit rank1(d)\n1 loops, best of 3: 11.2 s per loop\n']], ['map array of numbers to rank efficiently in Python'], 2, 0], [(36971758, 0), [['You can use  str.encode :'], ['Given your example:']], [[" with open('test.cpp', 'a') as out:\n    print(test_str.encode('unicode_escape').decode('utf-8'), file=out)\n"]], ['Python handling newline and tab characters when writing to file'], 2, 1], [(36971758, 1), [['Given your example:'], ['-10000']], [[' >>> test_str = "/*\\n test.cpp\\n *\\n *\\n *\\n\\t2013.02.30\\n *\\n */\\n"\n>>> test_str.encode(\'unicode_escape\')\nb\'/*\\\\n test.cpp\\\\n *\\\\n *\\\\n *\\\\n\\\\t2013.02.30\\\\n *\\\\n */\\\\n\'\n']], ['Python handling newline and tab characters when writing to file'], 2, 0], [(36974140, 0), [['Considering that Scrapy uses  lxml  under the hood, it might worth inspecting how  lxml  handles this kind of HTML, which contains XML special character  <  in one of the text nodes :'], ["Notice in the above demo, as you suspected, text node  '<1 hour'  is gone completely from the  root  element source. As a workaround, consider using  BeautifulSoup  since it is more reasonable in handling this HTML case (you can pass  response.body_as_unicode()  to create the  soup  from Scrapy response) :"]], [[' >>> from lxml import html\n>>> raw = \'\'\'<div class="details_wrapper">\n... <div class="detail">\n...     <b>Recommended length of visit:</b>\n...     <1 hour\n... </div>\n... <div class="detail">\n...     <b>Fee:</b>\n...     No\n... </div>\n... </div>\'\'\'\n... \n>>> root = html.fromstring(raw)\n>>> print html.tostring(root)\n<div class="details_wrapper">\n<div class="detail">\n    <b>Recommended length of visit:</b>\n\n<div class="detail">\n    <b>Fee:</b>\n    No\n</div>\n</div></div>\n']], ['Scrapy xpath get text of an element that starts with <'], 3, 0], [(36974140, 1), [["Notice in the above demo, as you suspected, text node  '<1 hour'  is gone completely from the  root  element source. As a workaround, consider using  BeautifulSoup  since it is more reasonable in handling this HTML case (you can pass  response.body_as_unicode()  to create the  soup  from Scrapy response) :"], ['Finding the target text node using BS can be done as follow :']], [[' >>> from bs4 import BeautifulSoup\n>>> soup = BeautifulSoup(raw, "html.parser")\n>>> print soup.prettify()\n<div class="details_wrapper">\n <div class="detail">\n  <b>\n   Recommended length of visit:\n  </b>\n  &lt;1 hour\n </div>\n <div class="detail">\n  <b>\n   Fee:\n  </b>\n  No\n </div>\n</div>\n']], ['Scrapy xpath get text of an element that starts with <'], 3, 0], [(36974140, 2), [['Finding the target text node using BS can be done as follow :'], ['-10000']], [[" >>> soup.find('b', text='Recommended length of visit:').next_sibling\nu'\\n    <1 hour\\n'\n"]], ['Scrapy xpath get text of an element that starts with <'], 3, 0], [(36988306, 0), [['-10000'], ['-10000']], [['Setup from StringIO import StringIO\nimport pandas as pd\n\ntext = """id      date        item\n1    2000-01-01     \'foo\'\n1    2000-01-02     \'pants\'\n1    2000-01-03     \'bar\'\n2    2000-01-02     \'organ\'\n2    2000-02-01     \'beef\'\n3    2000-01-01     \'pants\'\n3    2000-01-10     \'oranges\'\n3    2000-02-20     \'pants\'"""\n\ndf = pd.read_csv(StringIO(text), delim_whitespace=True, parse_dates=[1])\n']], ['Pandas check for future condition by group'], 4, 0], [(36988306, 2), [['-10000'], ['This works for one group but the checking I do works on a  DataFrame  so I perform a nested  apply  with another checking function  check_df_pants .']], [["Demonstration / Explanation # Let's start with a sub-group\ndf1 = df[df.id == 1].copy()\n\nprint df1.apply(lambda x: check_future_pants(x, df1), axis=1)\n\n0     True\n1    False\n2    False\ndtype: bool\n"]], ['Pandas check for future condition by group'], 4, 0], [(36988306, 3), [['This works for one group but the checking I do works on a  DataFrame  so I perform a nested  apply  with another checking function  check_df_pants .'], ['-10000']], [[" df['will_buy_pants'] = df.groupby('id', group_keys=False).apply(check_df_pants)\npring df\n\n   id       date       item will_buy_pants\n0   1 2000-01-01      'foo'           True\n1   1 2000-01-02    'pants'          False\n2   1 2000-01-03      'bar'          False\n3   2 2000-01-02    'organ'          False\n4   2 2000-02-01     'beef'          False\n5   3 2000-01-01    'pants'           True\n6   3 2000-01-10  'oranges'           True\n7   3 2000-02-20    'pants'          False\n"]], ['Pandas check for future condition by group'], 4, 0], [(37018019, 0), [['So, it seems that a simple solution to my problem is to use  threading.local  to store a per-thread "session" (in the mockup below, just a random int).  Perhaps not the cleanest I guess but for now it will do.  Here is a mockup (Python 3.5.1):'], ['Produces the following output, showing that "sessions" are indeed local to each thread and reused:']], [[' import time\nimport threading\nimport concurrent.futures\nimport random\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG, format=\'(%(threadName)-0s) %(relativeCreated)d - %(message)s\')\n\nx = [0.1, 0.1, 0.2, 0.4, 1.0, 0.1, 0.0]\n\nmydata = threading.local()\n\ndef do_work(secs):\n    if \'session\' in mydata.__dict__:\n        logging.debug(\'re-using session "{}"\'.format(mydata.session))\n    else:\n        mydata.session = random.randint(0,1000)\n        logging.debug(\'created new session: "{}"\'.format(mydata.session))\n    time.sleep(secs)\n    logging.debug(\'slept for {} seconds\'.format(secs))\n    return secs\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n    y = executor.map(do_work, x)\n\nprint(list(y))\n']], ['Python 3 concurrent.futures and per-thread initialization'], 3, 1], [(37018019, 1), [['Produces the following output, showing that "sessions" are indeed local to each thread and reused:'], ['Minor note about logging: in order to use this in an IPython notebook, the logging setup needs to be slightly modified (since IPython has already setup a root logger). A more robust logging setup would be:']], [[' (Thread-1) 29 - created new session: "855"\n(Thread-2) 29 - created new session: "58"\n(Thread-3) 30 - created new session: "210"\n(Thread-1) 129 - slept for 0.1 seconds\n(Thread-1) 130 - re-using session "855"\n(Thread-2) 130 - slept for 0.1 seconds\n(Thread-2) 130 - re-using session "58"\n(Thread-3) 230 - slept for 0.2 seconds\n(Thread-3) 230 - re-using session "210"\n(Thread-3) 331 - slept for 0.1 seconds\n(Thread-3) 331 - re-using session "210"\n(Thread-3) 331 - slept for 0.0 seconds\n(Thread-1) 530 - slept for 0.4 seconds\n(Thread-2) 1131 - slept for 1.0 seconds\n[0.1, 0.1, 0.2, 0.4, 1.0, 0.1, 0.0]\n']], ['Python 3 concurrent.futures and per-thread initialization'], 3, 0], [(37018019, 2), [['Minor note about logging: in order to use this in an IPython notebook, the logging setup needs to be slightly modified (since IPython has already setup a root logger). A more robust logging setup would be:'], ['-10000']], [[" IN_IPYNB = 'get_ipython' in vars()\n\nif IN_IPYNB:\n    logger = logging.getLogger()\n    logger.setLevel(logging.DEBUG)\n    for h in logger.handlers:\n        h.setFormatter(logging.Formatter(\n                '(%(threadName)-0s) %(relativeCreated)d - %(message)s'))\nelse:\n    logging.basicConfig(level=logging.DEBUG, format='(%(threadName)-0s) %(relativeCreated)d - %(message)s')\n"]], ['Python 3 concurrent.futures and per-thread initialization'], 3, 0], [(37042635, 0), [['Try this:'], ['Then execute your test function. If all test are correct, you should get something like:']], [[' def test_added():\n    assert added(4, 6, 7) == (13, 11, 10)\n']], ['How to make a test function using pytest'], 2, 1], [(37042635, 1), [['Then execute your test function. If all test are correct, you should get something like:'], ['Check the  docs  for more help.']], [[' 1 passed in x.xx seconds\n']], ['How to make a test function using pytest'], 2, 0], [(37048689, 0), [['define a face set on the part or assembly:'], ['then after meshing you can access the elements attached to that face, something like:']], [["   part.Set('facename',faces=part.faces.findAt(((1,0,0),),))\n"]], ['Abaqus: script to select elements on a surface'], 3, 0], [(37048689, 1), [['then after meshing you can access the elements attached to that face, something like:'], ['note if you want to get those elements on the odb after running an analysis it is a little different:']], [["   instance.sets['facename'].elements\n"]], ['Abaqus: script to select elements on a surface'], 3, 0], [(37048689, 2), [['note if you want to get those elements on the odb after running an analysis it is a little different:'], ['note that the set name is upcased on the odb..']], [["   instance.elementSets['FACENAME'].elements\n"]], ['Abaqus: script to select elements on a surface'], 3, 0], [(37079175, 0), [['You can create a new data type containing just the fields that you want, with the same field offsets and the same itemsize as the original array\'s data type, and then use this new data type to create a view of the original array.  The  dtype  function handles arguments with many formats; the relevant one is described in the section of the documentation called  "Specifying and constructing data types" . Scroll down to the subsection that begins with'], ['Here are a couple convenience functions that use this idea.']], [[" {'names': ..., 'formats': ..., 'offsets': ..., 'titles': ..., 'itemsize': ...}\n"]], ['How to remove a column from a structured numpy array *without copying it*?'], 5, 0], [(37079175, 2), [['For example,'], ["Verify that  b  is a view (not a copy) of  a  by changing  b[0]['x'] ..."]], [[" In [297]: a\nOut[297]: \narray([(10.0, 13.5, 1248, -2), (20.0, 0.0, 0, 0), (30.0, 0.0, 0, 0),\n       (40.0, 0.0, 0, 0), (50.0, 0.0, 0, 999)], \n      dtype=[('x', '<f8'), ('y', '<f8'), ('i', '<i8'), ('j', '<i8')])\n\nIn [298]: b = remove_fields(a, ['i', 'j'])\n\nIn [299]: b\nOut[299]: \narray([(10.0, 13.5), (20.0, 0.0), (30.0, 0.0), (40.0, 0.0), (50.0, 0.0)], \n      dtype={'names':['x','y'], 'formats':['<f8','<f8'], 'offsets':[0,8], 'itemsize':32})\n"]], ['How to remove a column from a structured numpy array *without copying it*?'], 5, 0], [(37079175, 3), [["Verify that  b  is a view (not a copy) of  a  by changing  b[0]['x'] ..."], ['and seeing that  a  is also changed:']], [[" In [300]: b[0]['x'] = 3.14\n"]], ['How to remove a column from a structured numpy array *without copying it*?'], 5, 0], [(37079175, 4), [['and seeing that  a  is also changed:'], ['-10000']], [[' In [301]: a[0]\nOut[301]: (3.14, 13.5, 1248, -2)\n']], ['How to remove a column from a structured numpy array *without copying it*?'], 5, 0], [(37083117, 0), [['Add an  onchange  attribute to the  casier_judiciare  field and then pass all the other fields you want to check as arguments to the method like this'], ["In your model file define the method like this and use an if statement to check if they're all True (That means they have all been checked), if so then you can return a dictionary with any value you want for the selection field, in this case  etat_dos  will change to  Dossier Complet"]], [[' <group col=\'4\' name="doss_grp" string="Dossier de Soumission" colspan="4" >\n    <field name="casier_judiciare" on_change="onchange_casier_judiciare(casier_judiciare, certificat_qual, extrait_role, reference_pro)"/> \n    <field name="certificat_qual"/> \n    <field name="extrait_role"/> \n    <field name="reference_pro"/> \n    <field name="statut_entre" style="width:20%%"/> \n    <field name="etat_dos"/> \n</group>\n']], ['How to Change selection field automatically in odoo'], 2, 0], [(37088428, 0), [['You could use  ticker.FuncFormatter  to create a  custom tick label :'], ['To also control the location of the ticks, you could use a  ticker.MultipleLocator . \nFor example, to place a tick mark every 4 inches, add']], [[" import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nx = np.linspace(0, 1, 100)\ny = (np.random.random(100) - 0.5).cumsum()\n\nfig, ax = plt.subplots()\nax.plot(x, y)\n\ndef imperial(x, pos):\n    ft, inches = divmod(round(x*12), 12)\n    ft, inches = map(int, [ft, inches])\n    return ('{} ft'.format(ft) if not inches \n            else '{} {} in'.format(ft, inches) if ft\n            else '{} in'.format(inches))\n\nax.yaxis.set_major_formatter(ticker.FuncFormatter(imperial))\n\nplt.show()\n"]], ['Python Matplotlib: plotting feet and inches'], 2, 1], [(37088428, 1), [['To also control the location of the ticks, you could use a  ticker.MultipleLocator . \nFor example, to place a tick mark every 4 inches, add'], ['to the code above.\n']], [[' loc = ticker.MultipleLocator(4./12)\nax.yaxis.set_major_locator(loc)\n']], ['Python Matplotlib: plotting feet and inches'], 2, 0], [(37091273, 0), [['In your  main.py :'], ["Here you have the tinted blue(the  background_normal  isn't necessary, it's set like that by default by kivy)"]], [[' from functools import partial\nimport rotinas\nWindow.clearcolor = (1, 1, 1, 1) <-----\nimport sqlite3 as sql\nfrom datetime import *\n']], ['Changing color TabbedPannelHeader in Kivy'], 3, 0], [(37106934, 0), [["You could use  randrange  to generate row and column index and add enemies there. If there's already a enemy or some other object in given cell just skip it and randomize a new coordinate:"], ['Usage:']], [[" import random\n\ndef add(grid, char, count):\n    while count:\n        row = random.randrange(len(grid))\n        column = random.randrange(len(grid[0]))\n        if world[row][column] == 'g':\n            world[row][column] = char\n            count -= 1\n"]], ['How to create a random multidimensional array from existing variables'], 2, 1], [(37106934, 1), [['Usage:'], ['This approach makes only sense if your world is sparse, i.e. most of the world is grass. If world is going to be filled with different objects then tracking the free space and randomly selecting a tile from there would be better approach.']], [[" world = [['g'] * 60 for _ in xrange(60)]\nadd(world, 'e', 25)\nadd(world, 't', 5)\n"]], ['How to create a random multidimensional array from existing variables'], 2, 0], [(37113173, 0), [['The following approach should get you started:'], ['This will display any cells which are different between the two files. For your given two files, this will display:']], [[' from itertools import izip_longest\nimport xlrd\n\nrb1 = xlrd.open_workbook(\'file1.xlsx\')\nrb2 = xlrd.open_workbook(\'file2.xlsx\')\n\nsheet1 = rb1.sheet_by_index(0)\nsheet2 = rb2.sheet_by_index(0)\n\nfor rownum in range(max(sheet1.nrows, sheet2.nrows)):\n    if rownum < sheet1.nrows:\n        row_rb1 = sheet1.row_values(rownum)\n        row_rb2 = sheet2.row_values(rownum)\n\n        for colnum, (c1, c2) in enumerate(izip_longest(row_rb1, row_rb2)):\n            if c1 != c2:\n                print "Row {} Col {} - {} != {}".format(rownum+1, colnum+1, c1, c2)\n    else:\n        print "Row {} missing".format(rownum+1)\n']], ['Compare 2 excel files using Python'], 2, 1], [(37113173, 1), [['This will display any cells which are different between the two files. For your given two files, this will display:'], ['-10000']], [[' Row 3 Col 2 - 0.235435 != 0.23546\n']], ['Compare 2 excel files using Python'], 2, 0], [(37116967, 0), [["In the Mongo shell, using the  '$slice'  and the  $arrayElemAt  operators:"], ['And in Python:']], [[' db.order.aggregate([{ $project: {last_status: { $arrayElemAt: [{ $slice: [ "$status", -1 ] }, 0 ]} }}, {$match: {\'last_status.status_code\':"scode"}} ])\n']], ['Mongoengine filter query on list embedded field based on last index'], 2, 0], [(37116967, 1), [['And in Python:'], ['The trick here is that  objects.aggregate  provides a  PyMongo  cursor, not a  MongoEngine  cursor, so if you need  MongoEngine  objects, you can proceed in two steps: first filter using the aggregation framework to get the ids of matched items, then get them through a  MongoEngine  query.']], [[' pipeline = [\n    {\'$project\': {\'last_status\': { \'$arrayElemAt\': [{ \'$slice\': [ "$status", -1 ] }, 0 ]} }},\n    {\'$match\': {\'last_status.status_code\':\'scode\'}}\n]\n\nagg_cursor = Order.objects.aggregate(*pipeline)\n\nresult = [ Order.objects.get(id=order[\'_id\']) for order in agg_cursor ]\n']], ['Mongoengine filter query on list embedded field based on last index'], 2, 0], [(37119071, 0), [['So to "clip" the edges you can simply call  scipy.ndimage.rotate(img, ..., reshape=False) .'], ['-10000']], [[' from scipy.ndimage import rotate\nfrom scipy.misc import face\nfrom matplotlib import pyplot as plt\n\nimg = face()\nrot = rotate(img, 30, reshape=False)\n\nfig, ax = plt.subplots(1, 2)\nax[0].imshow(img)\nax[1].imshow(rot)\n']], ['Scipy rotate and zoom an image without changing its dimensions'], 3, 0], [(37119071, 2), [['For example:'], ['']], [[' zm1 = clipped_zoom(img, 0.5)\nzm2 = clipped_zoom(img, 1.5)\n\nfig, ax = plt.subplots(1, 3)\nax[0].imshow(img)\nax[1].imshow(zm1)\nax[2].imshow(zm2)\n']], ['Scipy rotate and zoom an image without changing its dimensions'], 3, 0], [(37119314, 0), [['you can use a generator:'], ['outputs:']], [[' from random import randint\n\ndef getNum1To4(runs):\n    occurences = {n+1:0 for n in range(4)}\n    for i in range(runs):\n        options = [n for n in occurences if occurences[n] < runs / 4]\n        choice = options[randint(0, len(options) - 1)]\n        occurences[choice] += 1\n        yield choice\n']], ['How do I generate a sequence of integer numbers in a uniform distribution?'], 2, 1], [(37119314, 1), [['outputs:'], ['-10000']], [[' >>> runs = 8\n>>> gen = getNum1To4(8)\n>>> for n in range(runs): print gen.next()\n2\n1\n3\n1\n3\n4\n4\n2\n']], ['How do I generate a sequence of integer numbers in a uniform distribution?'], 2, 0], [(37122210, 1), [['To get all policies:'], ['To create a new  PagerDuty  object for bob, butting him in Team 1:']], [[' PagerDutyPolicy.objects.all()\n']], ['django object get two fields into a list from a model'], 3, 0], [(37128072, 0), [['List elements:'], ['Dictionary values using generator expression:']], [[' my_list = [1,4,7,4,5,7,1,3]\nprint my_list.count(4)\n']], ['How to find number of matches in the array or dictionary?'], 3, 1], [(37128072, 1), [['Dictionary values using generator expression:'], ['As pointed out by zondo, the last line can be more simply written as:']], [[' my_dict = {0: 1, 2: 1, 4: 5, 6: 3, 8: 4, 10: 4, 12: 1}\nprint sum(1 for x in my_dict.values() if x == 4)\n']], ['How to find number of matches in the array or dictionary?'], 3, 1], [(37136697, 1), [['Or in my case, the code looks like:'], ['Thanks again to all that were taking their time to read this. I hope this helps to anyone, who will have the same problem as I did.']], [[' koef = [logt_a, a_0, T_a*a_0, a_1, T_a*a_1, a_2, T_a*a_2]\nM = expand(A)\nK = zeros(len(koef), len(koef))\ndef odvod_mat(par):\n    for j in range(len(par)):\n        for i in range(len(par)):\n            type(par[i])._diff_wrt = True\n            P = diff(M, par[i])/2\n            B = P.coeff(par[j])\n            K[i,j] = B\n\n            #Removal of T_a\n            K[i,j] = K[i,j].subs(T_a, 0)\n    return K  \nodvod_mat(koef)\n']], ['Partial symbolic derivative in Python'], 2, 1], [(37154201, 0), [['you can use  itertools.groupby :'], ['output ']], [[' with open("your_file.csv") as f:\n    for x,y in itertools.groupby(sorted(map(str.split, f.read().strip().split("\\n"))), key = lambda x:x[0]):\n        print x,len(list(y))\n']], ['Get the count of the each date entry from onr of the raw from CSV file'], 3, 1], [(37154201, 1), [['output '], ['Another way: if csv contains empty lines']], [[' 4/14/2016 2\n6/14/2016 1\n']], ['Get the count of the each date entry from onr of the raw from CSV file'], 3, 0], [(37154201, 2), [['Another way: if csv contains empty lines'], ['-10000']], [[' with open("your_file.csv") as f:\n    my_list = []\n    for line in f:\n        if line:\n            my_list.append(line.strip().split())\n    for x,y in itertools.groupby(sorted(my_list, key=lambda x:x[0]), key=lambda x:x[0]):\n        print x, len(list(y))\n']], ['Get the count of the each date entry from onr of the raw from CSV file'], 3, 1], [(37177688, 0), [['You can use np.where to preserve the shape:'], ["It will take the corresponding values from arr_a when arr_b's value is greater than 0, otherwise it will use np.nan."]], [[' np.where(arr_b > 0.0, arr_a, np.nan)\n']], ['Subsetting 2D array based on condition in numpy python'], 2, 1], [(37212307, 0), [["You can solve it with  BeautifulSoup  alone, but I'd use  pandas  and it's  pandas.read_html()  to parse the HTML table into a convenient dataframe:"], ['Prints:']], [[' from StringIO import StringIO\n\nimport pandas as pd\n\ndata = """\n<table>\n        <tr>\n            <th>Class</th>\n            <th class="failed">Fail</th>\n            <th class="failed">Error</th>\n            <th>Skip</th>\n            <th>Success</th>\n            <th>Total</th>\n        </tr>\n            <tr>\n                <td>Regression_TestCase</td>\n                <td class="failed">1</td>\n                <td class="failed">9</td>\n                <td>0</td>\n                <td>219</td>\n                <td>229</td>\n            </tr>\n        <tr>\n            <td><strong>Total</strong></td>\n            <td class="failed">1</td>\n            <td class="failed">9</td>\n            <td>0</td>\n            <td>219</td>\n            <td>229</td>\n        </tr>\n    </table>"""\n\ndf = pd.read_html(StringIO(data))\nprint(df)\n']], ['HTML data from Beautiful Soup needs formatting'], 2, 1], [(37212307, 1), [['Prints:'], ['-10000']], [[' [                     0     1      2     3        4      5\n0                Class  Fail  Error  Skip  Success  Total\n1  Regression_TestCase     1      9     0      219    229\n2                Total     1      9     0      219    229]\n']], ['HTML data from Beautiful Soup needs formatting'], 2, 0], [(37219219, 0), [["itertools.permutations  is just what you're looking for:"], ["EDIT: \nOr, as @wflynny pointed out, you can save the list comprehension by just calling  list 's constructor:"]], [[' >>> from itertools import permutations\n>>> [i for i in permutations(range(1, 5), 4)]\n[(1, 2, 3, 4), (1, 2, 4, 3), (1, 3, 2, 4), (1, 3, 4, 2), (1, 4, 2, 3), (1, 4, 3, 2), (2, 1, 3, 4), (2, 1, 4, 3), (2, 3, 1, 4), (2, 3, 4, 1), (2, 4, 1, 3), (2, 4, 3, 1), (3, 1, 2, 4), (3, 1, 4, 2), (3, 2, 1, 4), (3, 2, 4, 1), (3, 4, 1, 2), (3, 4, 2, 1), (4, 1, 2, 3), (4, 1, 3, 2), (4, 2, 1, 3), (4, 2, 3, 1), (4, 3, 1, 2), (4, 3, 2, 1)]\n']], ['Go through every possible combination of an array python'], 2, 1], [(37219219, 1), [["EDIT: \nOr, as @wflynny pointed out, you can save the list comprehension by just calling  list 's constructor:"], ['-10000']], [[' >>> from itertools import permutations\n>>> list(permutations(range(1, 5), 4))\n[(1, 2, 3, 4), (1, 2, 4, 3), (1, 3, 2, 4), (1, 3, 4, 2), (1, 4, 2, 3), (1, 4, 3, 2), (2, 1, 3, 4), (2, 1, 4, 3), (2, 3, 1, 4), (2, 3, 4, 1), (2, 4, 1, 3), (2, 4, 3, 1), (3, 1, 2, 4), (3, 1, 4, 2), (3, 2, 1, 4), (3, 2, 4, 1), (3, 4, 1, 2), (3, 4, 2, 1), (4, 1, 2, 3), (4, 1, 3, 2), (4, 2, 1, 3), (4, 2, 3, 1), (4, 3, 1, 2), (4, 3, 2, 1)]\n']], ['Go through every possible combination of an array python'], 2, 1], [(37232279, 0), [['You can find all rows ( tr  elements) except the first one (to skip the headers) and the last one - the "total" row. Sample implementation that produces a list of dictionaries as a result:'], ['Prints:']], [[' from pprint import pprint\n\nfrom bs4 import BeautifulSoup\n\n\ndata = """\n<table>\n    <tr>\n        <th>Class</th>\n        <th class="failed">Fail</th>\n        <th class="failed">Error</th>\n        <th>Skip</th>\n        <th>Success</th>\n        <th>Total</th>\n    </tr>\n        <tr>\n            <td>Regression_TestCase.RegressionProject_TestCase2.RegressionProject_TestCase2</td>\n            <td class="failed">1</td>\n            <td class="failed">9</td>\n            <td>0</td>\n            <td>219</td>\n            <td>229</td>\n        </tr>\n    <tr>\n        <td><strong>Total</strong></td>\n        <td class="failed">1</td>\n        <td class="failed">9</td>\n        <td>0</td>\n        <td>219</td>\n        <td>229</td>\n    </tr>\n</table>"""\n\nsoup = BeautifulSoup(data, "html.parser")\n\nheaders = [header.get_text(strip=True) for header in soup.find_all("th")]\nrows = [dict(zip(headers, [td.get_text(strip=True) for td in row.find_all("td")]))\n        for row in soup.find_all("tr")[1:-1]]\n\npprint(rows)\n']], ['BeautifulSoup my for loop is printing all the data from the td tag. I would like to exclude the last section of the td tag'], 2, 1], [(37232279, 1), [['Prints:'], ['-10000']], [[" [{u'Class': u'Regression_TestCase.RegressionProject_TestCase2.RegressionProject_TestCase2',\n  u'Error': u'9',\n  u'Fail': u'1',\n  u'Skip': u'0',\n  u'Success': u'219',\n  u'Total': u'229'}]\n"]], ['BeautifulSoup my for loop is printing all the data from the td tag. I would like to exclude the last section of the td tag'], 2, 0], [(37246418, 0), [['If I understand your question you either want '], ['or']], [[' abs(z)\n']], ['How to avoid getting imaginary/complex number python'], 2, 1], [(37246418, 1), [['or'], ['-10000']], [[' z.real\n']], ['How to avoid getting imaginary/complex number python'], 2, 1], [(37256540, 0), [['Just use  numpy.sqrt()  ( see docs ) on the resulting  pd.Series :'], ['But there are of course several ways to accomplish the same result - see below for illustration:']], [[" import numpy as np\nnp.sqrt(football[['wins', 'losses']].sum(axis=1))\n"]], ['Applying sqrt function on a column'], 2, 1], [(37258152, 0), [["If you open your output file as 'wb', then it accepts a byte stream rather than unicode arguments:"], ['This seems to do what you want:']], [[" s = 'слово'\nwith open('data.txt','wb') as f:\n    f.write(s.encode('unicode_escape'))\n    f.write(b'\\n')  # add a line feed\n"]], ['More efficient way to make unicode escape codes'], 3, 1], [(37258152, 1), [['This seems to do what you want:'], ["%timeit reports that it is quite a bit faster than encode('ascii', 'backslashreplace'):"]], [[' $ cat data.txt\n\\u0441\\u043b\\u043e\\u0432\\u043e\n']], ['More efficient way to make unicode escape codes'], 3, 0], [(37258152, 2), [["%timeit reports that it is quite a bit faster than encode('ascii', 'backslashreplace'):"], ["Curiously, the lag from timeit for encode('unicode_escape') is a lot longer than that from encode('ascii', 'backslashreplace') even though the per loop time is faster, so be sure to test both in your environment."]], [[" In [18]: f = open('data.txt', 'wb')\n\nIn [19]: %timeit f.write(s.encode('unicode_escape'))\nThe slowest run took 224.43 times longer than the fastest. This could mean that an intermediate result is being cached.\n100000 loops, best of 3: 1.55 µs per loop\n\nIn [20]: %timeit f.write(s.encode('ascii','backslashreplace'))\nThe slowest run took 9.13 times longer than the fastest. This could mean that an intermediate result is being cached.\n100000 loops, best of 3: 2.37 µs per loop\n\nIn [21]: f.close()\n"]], ['More efficient way to make unicode escape codes'], 3, 0], [(37262062, 0), [['EDIT:  I agree with MRule. There would be 51,874,849,202 single-letter mappings in total. Consider the following approach (in python 2.7):'], ['UPDATE:   To only calculate the possible dictionaries where every mapped letter is unique , you could do:']], [[" import itertools\nfrom collections import OrderedDict\nimport string\nseed = {\n'A' : ['A'],\n'B' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'],\n'C' : ['C'],\n'D' : ['D'],\n'E' : ['E'],\n'F' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'],\n'G' : ['G', 'W'],\n'H' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'],\n'I' : ['I'],\n'J' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'],\n'K' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'],\n'L' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'],\n'M' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'],\n'N' : ['N'],\n'O' : ['O'],\n'P' : ['P'],\n'Q' : ['Q'],\n'R' : ['R'],\n'S' : ['S'],\n'T' : ['T'],\n'U' : ['U'],\n'V' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'],\n'W' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'],\n'X' : ['X'],\n'Y' : ['Y'],\n'Z' : ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z'] \n}\nd = OrderedDict(sorted(seed.items(), key=lambda t: t[0]))\nlistOfList = d.values()\nfor i in itertools.product(* listOfList):\n    # print the possible dict\n    print dict(zip(string.ascii_uppercase, i))\n"]], ['PYTHON: How do I create a list of every possible letter mapping using a dictionary that stores every possible letter mapping combination?'], 2, 1], [(37262062, 1), [['UPDATE:   To only calculate the possible dictionaries where every mapped letter is unique , you could do:'], ['-10000']], [[" import itertools\nimport string\nothers = ['B', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'V', 'W', 'Z']\n# this dict is fixed\ndict1 = {k : [k] for k in string.uppercase if k not in others}\n# iterate all possibles in others, then merge two dicts into one\nfor i in itertools.permutations(others):\n    dict2 = dict(zip(others, i))\n    print dict(dict1.items() + dict2.items())\n"]], ['PYTHON: How do I create a list of every possible letter mapping using a dictionary that stores every possible letter mapping combination?'], 2, 1], [(37299064, 0), [['One good option would be to use a dictionary to reference each instance of  football , which would avoid a massive  if ,  elif  structure at the end:'], ["Another approach is to do away with the class altogether, and simply have a dictionary whose values are tuples containing the quarterback's name and their number as elements. The code would look a little like this:"]], [[' class football:\n    def __init__(self,qb,num):\n        self.qb = qb\n        self.num = num\n\n    def __str__(self):\n        return self.qb + ", " + self.num\nteams = {\n"Niners" : football("Gabbert", "02" ),\n"Bears" : football("CUTLER, JAY","06"),\n"Bengals" : football ("Dalton, Andy","14"),\n"Bills" : football (" Taylor, Tyrod", "05")} #etc\n#I didn\'t include the whole dictionary for brevity\'s sake\n\ndef decor(func):\n    def wrap():\n        print("===============================")\n        func()\n        print("===============================")\n    return wrap\n\ndef print_text():\n    print("Who\\s your NFL Quarterback? ")\n\ndecorated = decor(print_text)\ndecorated()\n\nteam = input("Enter your teams name here:").capitalize()\nprint(teams[team])\n']], ['calling class with user input'], 2, 1], [(37299064, 1), [["Another approach is to do away with the class altogether, and simply have a dictionary whose values are tuples containing the quarterback's name and their number as elements. The code would look a little like this:"], ["This time  teams[team]  is a tuple. The last line is printing the first element (the quarterback's name), then the second element (the number)."]], [[' teams = {\n"Niners" : ("Gabbert", "02" ),\n"Bears" : ("CUTLER, JAY","06"),\n"Bengals" : ("Dalton, Andy","14"),\n"Bills" : (" Taylor, Tyrod", "05")} #etc\n# Again, not including the whole dictionary for brevity\'s sake\n\ndef decor(func):\n    def wrap():\n        print("===============================")\n        func()\n        print("===============================")\n    return wrap\n\ndef print_text():\n    print("Who\\s your NFL Quarterback? ")\n\ndecorated = decor(print_text)\ndecorated()\n\nteam = input("Enter your teams name here:").capitalize()\nprint(teams[team][0], teams[team][1])\n']], ['calling class with user input'], 2, 1], [(37316698, 0), [['If you must have a string with  all  characters replaced by  \\xhh  escapes, you need to do so manually:'], ["If you need quotes around that, you'd need to add those manually too:"]], [[" ''.join(r'\\x{0:02x}'.format(ord(c)) for c in value)\n"]], ['Python binary conversion to hex'], 2, 1], [(37316698, 1), [["If you need quotes around that, you'd need to add those manually too:"], ['-10000']], [[' "\'{0}\'".format(\'\'.join(r\'\\x{:02x}\'.format(ord(c)) for c in value))\n']], ['Python binary conversion to hex'], 2, 1], [(37340568, 0), [['In this example, the subprocess is a shell script that writes a line of output, and then echoes whatever you give it until it reads EOF.'], ['Gives:']], [[' import subprocess\n\nCOMMAND_LINE = \'echo "Hello World!" ; cat\'\n\nprocess = subprocess.Popen(COMMAND_LINE, shell=True,\n                           stdin=subprocess.PIPE,\n                           stdout=subprocess.PIPE)\n\ns = process.stdout.readline().strip()\nprint(s)\ns2 = process.communicate(s)[0]\nprint(s2)\n']], ['Interactive shell program wrapper in python'], 2, 1], [(37340568, 1), [['Gives:'], ['For more complicated cases, you might think about looking at something like  pexpect .']], [[' Hello World!\nHello World!\n']], ['Interactive shell program wrapper in python'], 2, 0], [(37348050, 0), [['As Display Name said,  os.path.isabs  along with  sys.argv  is probably the best:'], ['output']], [[' import sys\nimport os\n\nfpath = sys.argv[-1]\n\nprint(os.path.isabs(fpath))\nprint(fpath)\n']], ['Getting file path from command line arguments in python'], 3, 1], [(37348050, 1), [['output'], ['some cmd stuff']], [[' >>> \nTrue\nC:\\Users\\310176421\\Desktop\\Python\\print.py\n>>>\n']], ['Getting file path from command line arguments in python'], 3, 0], [(37348050, 2), [['some cmd stuff'], ['-10000']], [[' C:\\Users\\310176421\\Desktop\\Python>python print.py C:\\Users\\310176421\\Desktop\\tes\nt.txt\nTrue\nC:\\Users\\310176421\\Desktop\\test.txt\n\nC:\\Users\\310176421\\Desktop\\Python>python print.py whatever\nFalse\nwhatever\n']], ['Getting file path from command line arguments in python'], 3, 0], [(37365033, 0), [["I once needed some function to draw boxes, so for documentation reasons I'm posting a cleaned version here:"], ['The result will look like this:']], [[" UL, UR = '╔', '╗'\nSL, SR = '╠', '║'\nDL, DR = '╚', '╝'\nAL, AR = '═', '>'\n\n\ndef padded(\n    line, info=None, width=42, intro='>', outro='<', filler='.', chopped='..'\n):\n    # cleanup input\n    line = ''.join([' ', line.strip()]) if line else ''\n    info = info.strip() if info else ''\n\n    # determine available width\n    width -= sum([len(intro), len(outro), len(line), len(info)])\n    if width < 0:\n        # chop off overflowing text\n        line = line[:len(line)+width]\n        if chopped:\n            # place chopped characters (if set)\n            chopped = chopped.strip()\n            line = ' '.join([line[:len(line)-(len(chopped)+1)], chopped])\n\n    return ''.join(e for e in [\n        intro,\n        info,\n        line,\n        ''.join(filler for _ in range(width)),\n        outro\n    ] if e)\n\n\ndef box(rnum, nbeds, *extras):\n    arrow = (AL+AR)\n    res = [\n        # head line\n        padded(\n            'Stanza n. {:03d} <'.format(rnum), (AL+AL+arrow),\n            intro=UL, outro=UR, filler=AL\n        ),\n        # first line\n        padded(\n            'Num letti: {:3d}'.format(nbeds), arrow,\n            intro=SL, outro=SR, filler=' '\n        ),\n    ]\n    # following lines\n    res.extend(padded(e, arrow, intro=SL, outro=SR, filler=' ') for e in extras)\n    # bottom line\n    res.append(padded(None, None, intro=DL, outro=DR, filler=AL))\n\n    return '\\n'.join(res)\n\n\nprint(\n    box(485, 3, 'Fumatori', 'Televisione')\n)\nprint(\n    box(123, 4, 'Fumatori', 'Televisione', 'Aria Condizionata')\n)\nprint(\n    box(1, 1, 'this is so much text it will be chopped off')\n)\n"]], ['How to print framed strings'], 2, 1], [(37365033, 1), [['The result will look like this:'], ['-10000']], [[' ╔═══> Stanza n. 485 <════════════════════╗\n╠═> Num letti:   3                       ║\n╠═> Fumatori                             ║\n╠═> Televisione                          ║\n╚════════════════════════════════════════╝\n╔═══> Stanza n. 123 <════════════════════╗\n╠═> Num letti:   4                       ║\n╠═> Fumatori                             ║\n╠═> Televisione                          ║\n╠═> Aria Condizionata                    ║\n╚════════════════════════════════════════╝\n╔═══> Stanza n. 001 <════════════════════╗\n╠═> Num letti:   1                       ║\n╠═> this is so much text it will be ch ..║\n╚════════════════════════════════════════╝\n']], ['How to print framed strings'], 2, 0], [(37374947, 0), [['Code -'], ['Output -']], [[" from collections import defaultdict\n\narr = ['a', 1, 2, 3, 'b', 4, 5, 6]\n\nd = defaultdict(list)\n\ncur_key = arr[0]\n\nfor value in arr[1:]:\n    if type(value) != type(cur_key):\n        d[cur_key].append(value)\n    else:\n        cur_key = value\n\nprint(d)\n"]], ['Elegant way to split list on particular values'], 2, 1], [(37374947, 1), [['Output -'], ['-10000']], [[" defaultdict(<class 'list'>, {'b': [4, 5, 6], 'a': [1, 2, 3]})\n"]], ['Elegant way to split list on particular values'], 2, 0], [(37397296, 0), [['Code -'], ['Output -']], [[" from collections import defaultdict\n\nT1 = (('a', 'b', 2),\n ('a', 'c', 4),\n ('b', 'c', 1),\n ('a', 'b', 8),)\n\nd = defaultdict(int)\n\nfor x, y, z in T1:\n    d[(x, y)] += z\n\nT2 = tuple([(*k, v) for k, v in d.items()])\n\nprint(T2)\n"]], ['Summing similar elements within a tuple-of-tuples'], 5, 1], [(37397296, 1), [['Output -'], ["If you're interested in maintaining the original order, then -"]], [[" (('a', 'c', 4), ('b', 'c', 1), ('a', 'b', 10))\n"]], ['Summing similar elements within a tuple-of-tuples'], 5, 0], [(37397296, 2), [["If you're interested in maintaining the original order, then -"], ['Output -']], [[" from collections import OrderedDict\n\nT1 = (('a', 'b', 2), ('a', 'c', 4), ('b', 'c', 1), ('a', 'b', 8),)\n\nd = OrderedDict()\n\nfor x, y, z in T1:\n    d[(x, y)] = d[(x, y)] + z if (x, y) in d else z\n\nT2 = tuple((*k, v) for k, v in d.items())\n\nprint(T2)\n"]], ['Summing similar elements within a tuple-of-tuples'], 5, 1], [(37397296, 3), [['Output -'], ['In Python 2, you should use this -']], [[" (('a', 'b', 10), ('a', 'c', 4), ('b', 'c', 1))\n"]], ['Summing similar elements within a tuple-of-tuples'], 5, 0], [(37399461, 0), [['You could use  df.crosstab  to create a frequency table:'], ['yields']], [[" import pandas as pd\n\ndf = pd.DataFrame(\n    {'Component': ['Air conditioner', 'Air conditioner', 'airbag', 'engine with 150 H/P', 'airbag',\n                   '1-year concierge assistance', 'ABS breaks', 'ABS breaks', 'airbag', \n                   'air conditioner', 'engine with 250 H/P'], \n     'Vehicle': ['Ford', 'Ford', 'Ford', 'Ford', 'Toyota', 'Toyota', 'Toyota',\n                 'Chrysler', 'Chrysler', 'Chrysler', 'Chrysler']})\n\nresult = pd.crosstab(index=[df['Vehicle']], columns=[df['Component']]).clip(upper=1)\nprint(result)\n"]], ['vectorized implementation for pseudo pivot table in python'], 2, 1], [(37399461, 1), [['yields'], ['Since the frequency table may contain values greater than 1 if  df  contains duplicate rows,  clip(upper=1)  is used to reduce those values back to 1.']], [[' Component  1-year concierge assistance  ABS breaks  Air conditioner  \\\nVehicle                                                               \nChrysler                             0           1                0   \nFord                                 0           0                1   \nToyota                               1           1                0   \n\nComponent  air conditioner  airbag  engine with 150 H/P  engine with 250 H/P  \nVehicle                                                                       \nChrysler                 1       1                    0                    1  \nFord                     0       1                    1                    0  \nToyota                   0       1                    0                    0  \n']], ['vectorized implementation for pseudo pivot table in python'], 2, 0], [(37417157, 0), [['You can index your data based on the column "Trans" and "Num" like so:'], ["Next, we'll grab each index that is unique so we can replace them all (I'm pretty sure this part and the iteration below can be done in bulk, but I just did this quickly.  If you are having efficiency problems look into how to not not loop over all the indexes probably.)"]], [[' #Change how we index the frame\ndf.set_index(["Trans", "Num"], inplace=True)\n']], ['Changing the columns in DataFrame with respect to values in other columns'], 5, 0], [(37417157, 1), [["Next, we'll grab each index that is unique so we can replace them all (I'm pretty sure this part and the iteration below can be done in bulk, but I just did this quickly.  If you are having efficiency problems look into how to not not loop over all the indexes probably.)"], ['Then we can iterate through and apply what you want.']], [[" #Get only unique indexes\nunique_trans = list(set(df.index.get_level_values('Trans')))\n"]], ['Changing the columns in DataFrame with respect to values in other columns'], 5, 0], [(37417157, 2), [['Then we can iterate through and apply what you want.'], ['The result I got from this when running your data was:']], [[' # Access each index\nfor trans in unique_trans:\n\n    # Get the higher number in "Num" for each so we know which to set to NaN\n    max_num = max(df.ix[trans].index.values)\n\n    # Copy your start column as a temp variable\n    start = df.ix[trans]["Start"].copy()\n\n    # Apply the transform to the start column (Equal to end + 10)        \n    df.loc[trans, "Start"] = np.array(df.ix[trans]["End"]) + 10\n\n    # Apply the transform to the end column\n    df.loc[trans, "End"] = np.array(start.shift(-1) - 10)\n\n    # By passing a tuple as a row index, we get the element that is both in trans and the max number, \n    #which is the one you want to set to NaN\n    df.loc[(trans, max_num), "End"] = np.nan\n\nprint(df)\n']], ['Changing the columns in DataFrame with respect to values in other columns'], 5, 0], [(37417157, 3), [['The result I got from this when running your data was:'], ['The full code I used to generate your test case is this:']], [['                 Head  Chr     Start      End\nTrans      Num                             \nENST473358 1      A    1   30049.0  30554.0\n           2      A    1   30677.0  30966.0\n           3      A    1   31107.0      NaN\nENST417324 1      B    1   35277.0  35481.0\n           2      B    1   34554.0  35174.0\n           3      B    1   35721.0      NaN\nENST461467 1      B    1   35245.0  35481.0\n           2      B    1  120775.0      NaN\n']], ['Changing the columns in DataFrame with respect to values in other columns'], 5, 0], [(37423445, 0), [['You can call  operator.itemgetter()  as a  sort_key  value. Note that  sortby  still needs to be given for the  sort_key  to be applied:'], ['Prints:']], [[' import operator\nfrom prettytable import PrettyTable\n\n\ntable = PrettyTable(["Name", "Grade"])\ntable.add_row(["Joe", 90])\ntable.add_row(["Sally", 100])\ntable.add_row(["Bill", 90])\ntable.add_row(["Alice", 90])\nprint table.get_string(sort_key=operator.itemgetter(1, 0), sortby="Grade")\n']], ['Python prettytable Sort by Multiple Columns'], 2, 1], [(37423445, 1), [['Prints:'], ['-10000']], [[' +-------+-------+\n|  Name | Grade |\n+-------+-------+\n| Alice |   90  |\n|  Bill |   90  |\n|  Joe  |   90  |\n| Sally |  100  |\n+-------+-------+\n']], ['Python prettytable Sort by Multiple Columns'], 2, 0], [(37425477, 0), [['Just call  normalize-space(.)  on each node.'], ['Output:']], [[' import lxml.etree as et\n\nxml = et.parse("feed.xml")\nns = {"ns": \'http://www.w3.org/2005/Atom\'}\nfor n in xml.xpath("//ns:category", namespaces=ns):\n    t  = n.xpath("./../ns:summary", namespaces=ns)[0]\n    print(t.xpath("normalize-space(.)"))\n']], ['remove newline and whitespace parse XML with python Xpath'], 4, 0], [(37425477, 1), [['Output:'], ['Part two of your question is asking for the  title  tag as that is the only tag with the text you are looking for, but to specifically find the title with that exact text, that is simply:']], [[' Putting an entire chapter on one page sounds bloated, but consider this &mdash; my longest chapter so far would be 75 printed pages, and it loads in under 5 seconds&hellip; On dialup.\nPutting an entire chapter on one page sounds bloated, but consider this &mdash; my longest chapter so far would be 75 printed pages, and it loads in under 5 seconds&hellip; On dialup.\nPutting an entire chapter on one page sounds bloated, but consider this &mdash; my longest chapter so far would be 75 printed pages, and it loads in under 5 seconds&hellip; On dialup.\nThe accessibility orthodoxy does not permit people to question the value of features that are rarely useful and rarely used.\nThese notes will eventually become part of a tech talk on video encoding.\nThese notes will eventually become part of a tech talk on video encoding.\nThese notes will eventually become part of a tech talk on video encoding.\nThese notes will eventually become part of a tech talk on video encoding.\nThese notes will eventually become part of a tech talk on video encoding.\nThese notes will eventually become part of a tech talk on video encoding.\nThese notes will eventually become part of a tech talk on video encoding.\nThese notes will eventually become part of a tech talk on video encoding.\n']], ['remove newline and whitespace parse XML with python Xpath'], 4, 0], [(37425477, 2), [['Part two of your question is asking for the  title  tag as that is the only tag with the text you are looking for, but to specifically find the title with that exact text, that is simply:'], ['If you wanted any node that contained the text, you would just replace  ns:title  with a wildcard:']], [[' xml.xpath("//ns:title[text()=\'dive into mark\']", namespaces=ns)\n']], ['remove newline and whitespace parse XML with python Xpath'], 4, 0], [(37425477, 3), [['If you wanted any node that contained the text, you would just replace  ns:title  with a wildcard:'], ['-10000']], [[' xml.xpath("//*[text()=\'dive into mark\']", namespaces=ns)\n']], ['remove newline and whitespace parse XML with python Xpath'], 4, 0], [(37444512, 0), [['You can use an instance of the built-in  string.Template  class. Note the  $user1  I added.'], ["An even simpler way is to use the  str.format  method common to all strings. The syntax for replacement fields is slightly different ( {user1}  instead of  $user1 ), but it has the advantage that you don't have to  import  anything to use it and it plays well with all the other  format string  options."]], [[" from string import Template\n\ntemplate = Template('''\\\nURL GOTO=https://www.url.com/$user1\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27''')\n\nwith open('users.txt') as file:\n    for line in file:\n        print(template.substitute({'user1': line.strip()}))\n"]], ['Print from txt file'], 3, 1], [(37444512, 1), [["An even simpler way is to use the  str.format  method common to all strings. The syntax for replacement fields is slightly different ( {user1}  instead of  $user1 ), but it has the advantage that you don't have to  import  anything to use it and it plays well with all the other  format string  options."], ['Both will product the following output when run with the data in your sample  users.txt  file:']], [[" template = '''\\\nURL GOTO=https://www.url.com/{user1}\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27'''\n\nwith open('users.txt') as file:\n    for line in file:\n        print(template.format(user1=line.strip()))\n"]], ['Print from txt file'], 3, 1], [(37444512, 2), [['Both will product the following output when run with the data in your sample  users.txt  file:'], ['-10000']], [[' URL GOTO=https://www.url.com/rrralu\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27\nURL GOTO=https://www.url.com/rebeccamacavei\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27\nURL GOTO=https://www.url.com/corinnaco_\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27\nURL GOTO=https://www.url.com/andrew1996_\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27\nURL GOTO=https://www.url.com/thisisme_r\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27\nURL GOTO=https://www.url.com/zabiburuziga\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27\nURL GOTO=https://www.url.com/be_real_00\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27\nURL GOTO=https://www.url.com/officiel_14_leo\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27\nURL GOTO=https://www.url.com/thefullersgroup\nTAG POS=1 TYPE=BUTTON ATTR=TXT:Follow\nWAIT SECONDS= 27\n']], ['Print from txt file'], 3, 0], [(37482313, 0), [['This is the initial dataframe:'], ['And the new list:']], [[' mac_list\n\n    mac_address  frequency\n0  20c9d0892feb          2\n1  28e34789c4c2          1\n2  3480b3d51d5f          1\n3  4480ebb4e28c          1\n4  4c60de5dad72          1\n5  4ca56dab4550          1\n']], ['Comparing List and get indices in python'], 6, 0], [(37482313, 1), [['And the new list:'], ["I'd first set the index of mac_list as mac_address:"]], [[" new_mac_list = ['20c9d0892feb', '3480b3d51d5f', '20c9d0892feb', '249cji39fj4g']\n"]], ['Comparing List and get indices in python'], 6, 0], [(37482313, 2), [["I'd first set the index of mac_list as mac_address:"], ['And then calculate the frequencies in the new list:']], [[' mac_list = mac_list.set_index("mac_address")\n']], ['Comparing List and get indices in python'], 6, 0], [(37482313, 3), [['And then calculate the frequencies in the new list:'], ['You can then use the  add  method on the series:']], [[' new_freq = pd.Series(new_mac_list).value_counts()\n']], ['Comparing List and get indices in python'], 6, 0], [(37482313, 4), [['You can then use the  add  method on the series:'], ['Back to the original format:']], [[' res = mac_list["frequency"].add(new_freq, fill_value=0)\n\n20c9d0892feb    4.0\n249cji39fj4g    1.0\n28e34789c4c2    1.0\n3480b3d51d5f    2.0\n4480ebb4e28c    1.0\n4c60de5dad72    1.0\n4ca56dab4550    1.0\ndtype: float64\n']], ['Comparing List and get indices in python'], 6, 0], [(37482313, 5), [['Back to the original format:'], ['-10000']], [[' mac_list = pd.DataFrame(res, columns = ["frequency"])\nprint(mac_list)\n\n              frequency\n20c9d0892feb        4.0\n249cji39fj4g        1.0\n28e34789c4c2        1.0\n3480b3d51d5f        2.0\n4480ebb4e28c        1.0\n4c60de5dad72        1.0\n4ca56dab4550        1.0\n']], ['Comparing List and get indices in python'], 6, 0], [(37492239, 0), [['As Andy Hayden already suggested, pandas could be a very good option here:'], ["Added the next line to plot the area you put in the example. Notice that for each x-value, you plot  only  3 y-values: max, min & mean. Or whatever, you may of course want to plot the Q1 & Q3, or confidence intervals. My point is that you don't actually need the 500 points anymore (summary statistics are so great ^_^)"]], [[' from datetime import date, timedelta as td, datetime\nd1 = datetime.strptime(\'1/1/2015\', "%m/%d/%Y")\nd2 = datetime.strptime(\'12/31/2015\', "%m/%d/%Y")\n\nAllDays = []\nwhile(d1<=d2):\n    AllDays.append(d1)\n    d1 = d1 + td(days=1)\n\ntemps = np.random.normal( 20, 0.5, size=(500,365) )\ntemps = pd.DataFrame( temps.T, index=AllDays )\n\nfig, ax = plt.subplots( 1, 1, figsize=(16,8) )\nax.plot( temps.index, temps.T.mean(), color=\'blue\', linewidth=2 )\n']], ['python plot distribution across mean'], 2, 1], [(37501075, 0), [["Yes, the parameters used to create a frozen distribution are available within the instance of the distribution. They are stored within the  args  &  kwds  attribute . This will be dependent on if the distribution's instance was created with positional arguments or keyword arguments."], ['-10000']], [[" import scipy.stats as stats\n\n# Parameters for this particular alpha distribution\na, loc, scale = 3.14, 5.0, 2.0\n\n# Create frozen distribution\nrv1 = stats.gamma(a, loc, scale)\nrv2 = stats.gamma(a, loc=loc, scale=scale)\n\n# Do something with frozen parameters\nprint 'positional and keyword'\nprint 'frozen args : {}'.format(rv1.args)\nprint 'frozen kwds : {}'.format(rv1.kwds)\nprint\nprint 'positional only'\nprint 'frozen args : {}'.format(rv2.args)\nprint 'frozen kwds : {}'.format(rv2.kwds)\n"]], ['How to get parameter arguments from a frozen spicy.stats distribution?'], 4, 1], [(37501075, 1), [['-10000'], ['-10000']], [[" positional and keyword\nfrozen args : (3.14, 5.0, 2.0)\nfrozen kwds : {}\n\npositional only\nfrozen args : (3.14,)\nfrozen kwds : {'loc': 5.0, 'scale': 2.0}\n"]], ['How to get parameter arguments from a frozen spicy.stats distribution?'], 4, 0], [(37501075, 2), [['-10000'], ['-10000']], [[" # Get the original parameters regardless of argument type\nshape1, loc1, scale1 = rv1.dist._parse_args(*rv1.args, **rv1.kwds)\nshape2, loc2, scale2 = rv2.dist._parse_args(*rv2.args, **rv2.kwds)\n\nprint 'positional and keyword'\nprint 'frozen parameters: shape={}, loc={}, scale={}'.format(shape1, loc1, scale1)\nprint\nprint 'positional only'\nprint 'frozen parameters: shape={}, loc={}, scale={}'.format(shape2, loc2, scale2)\n"]], ['How to get parameter arguments from a frozen spicy.stats distribution?'], 4, 0], [(37501075, 3), [['-10000'], ['-10000']], [[' positional and keyword\nfrozen parameters: shape=(3.14,), loc=5.0, scale=2.0\n\npositional only\nfrozen parameters: shape=(3.14,), loc=5.0, scale=2.0\n']], ['How to get parameter arguments from a frozen spicy.stats distribution?'], 4, 0], [(37546552, 0), [['The file contains. '], ["Here is the python code.It's very simple logic."]], [[' rahul@HP-EliteBook ~/Projects/Stackoverflow $ cat abc.txt \nhai am here\n']], ["Make a variable from what's in a text file"], 2, 0], [(37605612, 0), [['The following example shows how to define a module from a C string:'], ['output:']], [[' #include <stdio.h>\n#include <Python.h>\nint main(int argc, char *argv[])\n{\n    Py_Initialize();\n    PyRun_SimpleString("print(\'hello from python\')");\n\n    // fake module\n    char *source = "__version__ = \'2.0\'";\n    char *filename = "test_module.py";\n\n    // perform module load\n    PyObject *builtins = PyEval_GetBuiltins();\n    PyObject *compile = PyDict_GetItemString(builtins, "compile");\n    PyObject *code = PyObject_CallFunction(compile, "sss", source, filename, "exec");\n    PyObject *module = PyImport_ExecCodeModule("test_module", code);\n\n    PyRun_SimpleString("import test_module; print(test_module.__version__)");\n\n    Py_Finalize();\n    return 0;\n}\n']], ['PyImport_ImportModule, possible to load module from memory?'], 3, 0], [(37605612, 1), [['output:'], ['You can read about  import hooks  in the docs.  You will need to define a class with  find_module  and  load_module  methods.  Something like the following should work:']], [[' hello from python\nversion: 2.0\n']], ['PyImport_ImportModule, possible to load module from memory?'], 3, 0], [(37630714, 0), [['Use  None  everywhere the syntax-based  slice  uses a blank value:'], ['is equivalent to:']], [[' someseq[slice(2, None)]\n']], ['Creating a slice object in python'], 2, 1], [(37659598, 0), [['As following works perfectly.'], ['And you extract the requited part as ']], [[' >>> p = json.loads(\'\'\'{"sweep_enabled":true,"product":"XYZ","page":"XYZ Profile","list":{\\"id\\":205782,\\"name\\":\\"Robert Shriwas\\",\\"gender\\":\\"F\\",\\"practicing_since\\":null,\\"years\\":21,\\"specializations\\":[\\"Mentor\\"]},"form":{"q":"","city":"Delhi","locality":null},"cerebro":true}\'\'\')\n']], ['Extarct particulr part of json string using python regex'], 3, 0], [(37659598, 1), [['And you extract the requited part as '], ['Check this out I could manage to correct the json you provided.']], [[' >>> p["list"]\n{u\'name\': u\'Robert Shriwas\', u\'gender\': u\'F\', u\'specializations\': [u\'Mentor\'], u\'id\': 205782, u\'years\': 21, u\'practicing_since\': None}\n']], ['Extarct particulr part of json string using python regex'], 3, 0], [(37659598, 2), [['Check this out I could manage to correct the json you provided.'], ['-10000']], [[' >>> p = \'\'\'{"sweep_enabled":true,"product":"XYZ","page":"XYZ Profile","list":" {\\"id\\":205782,\\"name\\":\\"Robert Shriwas\\",\\"gender\\":\\"F\\",\\"practicing_since\\":null,\\"years\\":21,\\"specializations\\":[\\"Mentor\\"]}","form":{"q":"","city":"Delhi","locality":null},"cerebro":true}\'\'\'\n>>> q = re.sub(r\'(:)\\s*"\\s*(\\{[^\\}]+\\})\\s*"\',r\'\\1\\2\', p[1:-1])\n>>> q\n\'"sweep_enabled":true,"product":"XYZ","page":"XYZ Profile","list":{"id":205782,"name":"Robert Shriwas","gender":"F","practicing_since":null,"years":21,"specializations":["Mentor"]},"form":{"q":"","city":"Delhi","locality":null},"cerebro":true\'\n>>> r = p[0] + q + p[-1]\n>>> r\n\'{"sweep_enabled":true,"product":"XYZ","page":"XYZ Profile","list":{"id":205782,"name":"Robert Shriwas","gender":"F","practicing_since":null,"years":21,"specializations":["Mentor"]},"form":{"q":"","city":"Delhi","locality":null},"cerebro":true}\'\n>>> json.loads(r)\n{u\'product\': u\'XYZ\', u\'form\': {u\'q\': u\'\', u\'city\': u\'Delhi\', u\'locality\': None}, u\'sweep_enabled\': True, u\'list\': {u\'name\': u\'Robert Shriwas\', u\'gender\': u\'F\', u\'specializations\': [u\'Mentor\'], u\'id\': 205782, u\'years\': 21, u\'practicing_since\': None}, u\'cerebro\': True, u\'page\': u\'XYZ Profile\'}\n>>> s = json.loads(r)\n>>> s[\'list\']\n{u\'name\': u\'Robert Shriwas\', u\'gender\': u\'F\', u\'specializations\': [u\'Mentor\'], u\'id\': 205782, u\'years\': 21, u\'practicing_since\': None}\n>>> \n']], ['Extarct particulr part of json string using python regex'], 3, 1], [(37682284, 1), [['For example:'], ['gives:']], [[' field3d_mask_1 = np.zeros(field3d.shape, dtype=bool)\nfield3d_mask_2 = np.zeros(field3d.shape, dtype=bool)\n\nfor t in range(nt):\n    field3d_mask_1[t,:,:] = field2d > 0.3\n\nfield3d_mask_2[:,:,:] = field2d[np.newaxis,:,:] > 0.3\n\nprint((field3d_mask_1 == field3d_mask_2).all())\n']], ['Mask a 3d array with a 2d mask in numpy'], 2, 1], [(37685718, 0), [['The  text  argument (which is now called  string ) would not search inside the children elements texts of an element (why? - see the last note inside this  documentation paragraph ,  .string  would be effectively  None  for each of the presented  li  elements). What I would do is to locate the  b  element by text, then get all the  a   siblings :'], ['Or, you can  go up the tree  from  b  to  li  and then use  find_all()  to find all links inside  li :']], [[' b = soup.find("b", text=lambda text: text and "data I DO care about:" in text)\nlinks = [a["href"] for a in b.find_next_siblings("a", href=True)]\nprint(links)\n']], ['Finding specific links with Beautiful Soup'], 2, 1], [(37685718, 1), [['Or, you can  go up the tree  from  b  to  li  and then use  find_all()  to find all links inside  li :'], ['There are, of course, other ways to locate the desired  a  elements.']], [[' b = soup.find("b", text=lambda text: text and "data I DO care about:" in text)\nli = b.find_parent("li")\nlinks = [a["href"] for a in li.find_all("a", href=True)]\nprint(links)\n']], ['Finding specific links with Beautiful Soup'], 2, 1], [(37758227, 0), [['os.system() does not return the control of the subshell spawned by it, instead it returns only the exit code when the subshell is done executing the command. This can be verified by:'], ['Run it:']], [[' x = os.system("echo \'shankar\'")\nprint(x)\n']], ['Stop a command line command in script'], 5, 0], [(37758227, 1), [['Run it:'], ['Here proc  is the returned object which provides control over the spawned subprocess. You can retrieve information about the process or manipulate it with this object.']], [[" import subprocess \nproc = subprocess.Popen(['foo', 'bar', 'bar'], stdout=subprocess.PIPE, shell=True)\n"]], ['Stop a command line command in script'], 5, 0], [(37758227, 2), [['Here proc  is the returned object which provides control over the spawned subprocess. You can retrieve information about the process or manipulate it with this object.'], ['Stop it:']], [[' proc.pid # returns the id of process\n']], ['Stop a command line command in script'], 5, 0], [(37758227, 3), [['Stop it:'], ['Get output:']], [[' proc.terminate() # terminate the process.\n']], ['Stop a command line command in script'], 5, 0], [(37758227, 4), [['Get output:'], ['Note:  Popen.communicate()  returns output only when the subprocess has exited successfully or has been terminated or killed.']], [[' out, err = proc.communicate()\n']], ['Stop a command line command in script'], 5, 0], [(37760124, 0), [['Read the line, split the line, copy the array result into a set. If the size of the set is less than the size of the array, the file contains repeated elements'], ['To read the file word by word, try this']], [[" with open('filename', 'r') as f:\n    for line in f:\n        # Here is where you do what I said above\n"]], ['How to input a line word by word in Python?'], 4, 0], [(37760124, 1), [['To read the file word by word, try this'], ['Then you can do:']], [[' import itertools\n\ndef readWords(file_object):\n    word = ""\n    for ch in itertools.takewhile(lambda c: bool(c), itertools.imap(file_object.read, itertools.repeat(1))):\n        if ch.isspace():\n            if word: # In case of multiple spaces\n                yield word\n                word = ""\n            continue\n        word += ch\n    if word:\n        yield word # Handles last word before EOF\n']], ['How to input a line word by word in Python?'], 4, 0], [(37760124, 2), [['Then you can do:'], ['']], [[" with open('filename', 'r') as f:\n    for num in itertools.imap(int, readWords(f)):\n        # Store the numbers in a set, and use the set to check if the number already exists\n"]], ['How to input a line word by word in Python?'], 4, 0]]