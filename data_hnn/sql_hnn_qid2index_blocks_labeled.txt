[[(44780, 1), [['Then you can fire and forget:'], ['-10000']], [[' EXEC sp_grantastic\n']], ["What's the best way to implement a SQL script that will grant permissions to a database role on all the user tables in a database?"], 2, 0], [(79789, 0), [["Create a table with just time in it from midnight to midnight containing each minute of the day.  In the data warehouse world we would call this a time dimension.  Here's an example:"], ['an example of the data in the table would be']], [[' TIME_DIM\n -id\n -time_of_day\n -interval_15 \n -interval_30\n']], ['Elegant method for drawing hourly bar chart from time-interval data?'], 3, 0], [(79789, 1), [['an example of the data in the table would be'], ['Then all you have to do is join your table to the time dimension and then group by interval_15.  For example:']], [[' id   time_of_day    interval_15    interval_30\n1    00:00          00:00          00:00\n...\n30   00:23          00:15          00:00\n...\n100  05:44          05:30          05:30\n']], ['Elegant method for drawing hourly bar chart from time-interval data?'], 3, 0], [(128623, 1), [["Enabling the constraints again is a bit tricker - you  need to enable primary key constraints before you can reference them in a foreign key constraint.  This can be done using an ORDER BY on constraint_type.  'P' = primary key, 'R' = foreign key."], ['-10000']], [[' BEGIN\n  FOR c IN\n  (SELECT c.owner, c.table_name, c.constraint_name\n   FROM user_constraints c, user_tables t\n   WHERE c.table_name = t.table_name\n   AND c.status = \'DISABLED\'\n   ORDER BY c.constraint_type)\n  LOOP\n    dbms_utility.exec_ddl_statement(\'alter table "\' || c.owner || \'"."\' || c.table_name || \'" enable constraint \' || c.constraint_name);\n  END LOOP;\nEND;\n/\n']], ['Disable all table constraints in Oracle'], 2, 0], [(182130, 0), [['This can be done, but would be a lot more efficient if you stored the end date of each log.  With your model you have to do something like:'], ['With the additional column it woud be more like:']], [[" select l1.userid\nfrom status_log l1\nwhere l1.status='s'\nand l1.logcreated = (select max(l2.logcreated)\n                     from status_log l2\n                     where l2.userid = l1.userid\n                     and   l2.logcreated <= date '2008-02-15'\n                    );\n"]], ['SQL - state machine - reporting on historical data based on changeset'], 4, 1], [(182130, 2), [['This would appear in the table like this:'], ['Yes, my query would have to be re-written as']], [[' userid  from       to         status\nFRED    2008-01-01 2008-01-31 s\nFRED    2008-02-01 2008-02-07 c\nFRED    2008-02-08            a\n']], ['SQL - state machine - reporting on historical data based on changeset'], 4, 0], [(192220, 0), [['I cover Closure Table in my presentation  Models for Hierarchical Data with SQL and PHP  and in my book  SQL Antipatterns: Avoiding the Pitfalls of Database Programming .'], ['Store all paths in the Closure Table, where there is a direct ancestry from one node to another.  Include a row for each node to reference itself.  For example, using the data set you showed in your question:']], [[' CREATE TABLE ClosureTable (\n  ancestor_id   INT NOT NULL REFERENCES FlatTable(id),\n  descendant_id INT NOT NULL REFERENCES FlatTable(id),\n  PRIMARY KEY (ancestor_id, descendant_id)\n);\n']], ['What is the most efficient/elegant way to parse a flat table into a tree?'], 8, 0], [(192220, 1), [['Store all paths in the Closure Table, where there is a direct ancestry from one node to another.  Include a row for each node to reference itself.  For example, using the data set you showed in your question:'], ['Now you can get a tree starting at node 1 like this:']], [[' INSERT INTO ClosureTable (ancestor_id, descendant_id) VALUES\n  (1,1), (1,2), (1,4), (1,6),\n  (2,2), (2,4),\n  (3,3), (3,5),\n  (4,4),\n  (5,5),\n  (6,6);\n']], ['What is the most efficient/elegant way to parse a flat table into a tree?'], 8, 0], [(192220, 2), [['Now you can get a tree starting at node 1 like this:'], ['The output (in MySQL client) looks like the following:']], [[' SELECT f.* \nFROM FlatTable f \n  JOIN ClosureTable a ON (f.id = a.descendant_id)\nWHERE a.ancestor_id = 1;\n']], ['What is the most efficient/elegant way to parse a flat table into a tree?'], 8, 0], [(192220, 3), [['The output (in MySQL client) looks like the following:'], ['Re: comment from e-satis about immediate children (or immediate parent).  You can add a " path_length " column to the  ClosureTable  to make it easier to query specifically for an immediate child or parent (or any other distance).']], [[' +----+\n| id |\n+----+\n|  1 | \n|  2 | \n|  4 | \n|  6 | \n+----+\n']], ['What is the most efficient/elegant way to parse a flat table into a tree?'], 8, 0], [(192220, 4), [['Re: comment from e-satis about immediate children (or immediate parent).  You can add a " path_length " column to the  ClosureTable  to make it easier to query specifically for an immediate child or parent (or any other distance).'], ['Then you can add a term in your search for querying the immediate children of a given node.  These are descendants whose  path_length  is 1.']], [[' INSERT INTO ClosureTable (ancestor_id, descendant_id, path_length) VALUES\n  (1,1,0), (1,2,1), (1,4,2), (1,6,1),\n  (2,2,0), (2,4,1),\n  (3,3,0), (3,5,1),\n  (4,4,0),\n  (5,5,0),\n  (6,6,0);\n']], ['What is the most efficient/elegant way to parse a flat table into a tree?'], 8, 0], [(192220, 5), [['Then you can add a term in your search for querying the immediate children of a given node.  These are descendants whose  path_length  is 1.'], ['-10000']], [[' SELECT f.* \nFROM FlatTable f \n  JOIN ClosureTable a ON (f.id = a.descendant_id)\nWHERE a.ancestor_id = 1\n  AND path_length = 1;\n\n+----+\n| id |\n+----+\n|  2 | \n|  6 | \n+----+\n']], ['What is the most efficient/elegant way to parse a flat table into a tree?'], 8, 0], [(192220, 6), [['-10000'], ['-10000']], [[' SELECT f.name\nFROM FlatTable f \nJOIN ClosureTable a ON (f.id = a.descendant_id)\nWHERE a.ancestor_id = 1\nORDER BY f.name;\n']], ['What is the most efficient/elegant way to parse a flat table into a tree?'], 8, 0], [(192220, 7), [['-10000'], ['-10000']], [[' SELECT f.name, GROUP_CONCAT(b.ancestor_id order by b.path_length desc) AS breadcrumbs\nFROM FlatTable f \nJOIN ClosureTable a ON (f.id = a.descendant_id) \nJOIN ClosureTable b ON (b.descendant_id = a.descendant_id) \nWHERE a.ancestor_id = 1 \nGROUP BY a.descendant_id \nORDER BY f.name\n\n+------------+-------------+\n| name       | breadcrumbs |\n+------------+-------------+\n| Node 1     | 1           |\n| Node 1.1   | 1,2         |\n| Node 1.1.1 | 1,2,4       |\n| Node 1.2   | 1,6         |\n+------------+-------------+\n']], ['What is the most efficient/elegant way to parse a flat table into a tree?'], 8, 0], [(216007, 2), [['If you need more detail, run:'], ["Note:  The SQL Server account used needs the 'sysadmin' role (otherwise it will just show a single row and a count of 1 as the result)"]], [[" sp_who2 'Active'\n"]], ['How to determine total number of open/active connections in ms sql server 2005'], 3, 0], [(289649, 0), [['Assuming that the column headings "john", "lucy" etc are fixed, you can group by the address field and use if() functions combined with aggregate operators to get your results:'], ['eg.']], [[" select max(if(forename='john',surname,null)) as john,\n       max(if(forename='lucy',surname,null)) as lucy,\n       max(if(forename='jenny',surname,null)) as jenny,       \n       max(if(forename='steve',surname,null)) as steve,       \n       max(if(forename='richard',surname,null)) as richard,\n       address\nfrom tablename \ngroup by address;\n"]], ['Remapping/Concatenating in SQL'], 2, 1], [(313962, 0), [['So you could do something like'], ["What might be better however is to somehow calculate the date of 'last sunday at 00:00', and then the database would not have to run a function for each row, but I couldn't see an obvious way of doing that in MySQL. You could however easily generate this in php and do something like"]], [[' SELECT * FROM table WHERE YEARWEEK(purchased) = YEARWEEK(NOW());\n']], ['PHP/MySQL: Retrieving the last *full* weeks entries'], 2, 1], [(313962, 1), [["What might be better however is to somehow calculate the date of 'last sunday at 00:00', and then the database would not have to run a function for each row, but I couldn't see an obvious way of doing that in MySQL. You could however easily generate this in php and do something like"], ['-10000']], [[' $sunday = date((\'Y-m-d H:i:s\'), strtotime(\'last sunday 00:00\'));\n$sql = "SELECT * FROM table WHERE purchased >= \'$sunday\'";\n']], ['PHP/MySQL: Retrieving the last *full* weeks entries'], 2, 1], [(318528, 0), [['I also found out that '], ["will show you a lot of information about a table, including all triggers associated with it.  Using that, along with Ray's query can make it much easier to find the triggers.  Combined with this query from Ray's linked article:"]], [[' sp_depends <object_name> \n']], ['How do you identify the triggers associated with a table in a sybase database?'], 3, 0], [(318528, 1), [["will show you a lot of information about a table, including all triggers associated with it.  Using that, along with Ray's query can make it much easier to find the triggers.  Combined with this query from Ray's linked article:"], ['and you can see the definition of the trigger:']], [[' sp_helptext <trigger_name>\n']], ['How do you identify the triggers associated with a table in a sybase database?'], 3, 0], [(318528, 2), [['and you can see the definition of the trigger:'], ['will also show you all tables related to a trigger']], [[' sp_depends <trigger_name>\n']], ['How do you identify the triggers associated with a table in a sybase database?'], 3, 0], [(363084, 1), [['To produce a CSV file, you would do something like:'], ['To load the data back in from the file, use the  LOAD DATA INFILE  command with the same options you used to dump it out.  For the CSV format above, that would be']], [[' SELECT A,B,C\nINTO OUTFILE \'/tmp/result.txt\'\nFIELDS TERMINATED BY \',\' OPTIONALLY ENCLOSED BY \'"\'\nLINES TERMINATED BY \'\\n\'\nFROM X;\n']], ['MYSQL - How would I Export tables specifying only certain fields?'], 3, 1], [(363084, 2), [['To load the data back in from the file, use the  LOAD DATA INFILE  command with the same options you used to dump it out.  For the CSV format above, that would be'], ['-10000']], [[' LOAD DATA INFILE \'/tmp/result.txt\'\nINTO TABLE X\nFIELDS TERMINATED BY \',\' OPTIONALLY ENCLOSED BY \'"\'\nLINES TERMINATED BY \'\\n\';\n']], ['MYSQL - How would I Export tables specifying only certain fields?'], 3, 0], [(374079, 0), [['This is a set-based solution for the problem. The performance will probably suck, but it works :)'], ['Results:']], [[" CREATE TABLE #LogEntries (\n  ID INT IDENTITY,\n  LogEntry VARCHAR(100)\n)\n\nINSERT INTO #LogEntries VALUES ('beans')\nINSERT INTO #LogEntries VALUES ('beans')\nINSERT INTO #LogEntries VALUES ('beans')\nINSERT INTO #LogEntries VALUES ('cabbage')\nINSERT INTO #LogEntries VALUES ('cabbage')\nINSERT INTO #LogEntries VALUES ('carrots')\nINSERT INTO #LogEntries VALUES ('beans')\nINSERT INTO #LogEntries VALUES ('beans')\nINSERT INTO #LogEntries VALUES ('carrots')\n\nSELECT logentry, COUNT(*) FROM (\n    SELECT logentry, \n    ISNULL((SELECT MAX(id) FROM #logentries l2 WHERE l1.logentry<>l2.logentry AND l2.id < l1.id), 0) AS id\n    FROM #LogEntries l1\n) AS a\nGROUP BY logentry, id\n\n\nDROP TABLE #logentries \n"]], ['Group repeated rows in TSQL'], 2, 1], [(374079, 1), [['Results:'], ['The ISNULL() is required for the first set of beans. ']], [[' beans   3\ncabbage 2\ncarrots 1\nbeans   2\ncarrots 1\n']], ['Group repeated rows in TSQL'], 2, 0], [(379556, 0), [["In terms of getting the data out, you can use 'group by' and ' truncate ' to slice the data into 1 minute intervals. eg:  "], ['This will give you results like below (assuming there are 20 rows for alice between 8.00 and 8.01 and 40 rows between 8.01 and 8.02):']], [[" SELECT user_name, truncate(event_time, 'YYYYMMDD HH24MI'), count(*)\nFROM job_table\nWHERE event_time > TO_DATE( some start date time)\nAND user_name IN ( list of users to query )\nGROUP BY user_name, truncate(event_time, 'YYYYMMDD HH24MI') \n"]], ['Time slicing in Oracle/SQL'], 2, 1], [(379556, 1), [['This will give you results like below (assuming there are 20 rows for alice between 8.00 and 8.01 and 40 rows between 8.01 and 8.02):'], ['-10000']], [[' Alice  2008-12-16 08:00   20\nAlice  2008-12-16 08:01   40\n']], ['Time slicing in Oracle/SQL'], 2, 0], [(439138, 2), [['Test data I used is:'], ['edit:']], [[" create table t(account number, bookdate date, amount number);\n\ninsert into t(account, bookdate, amount) values (1, to_date('20080101', 'yyyymmdd'), 100);\n\ninsert into t(account, bookdate, amount) values (1, to_date('20080102', 'yyyymmdd'), 101);\n\ninsert into t(account, bookdate, amount) values (1, to_date('20080103', 'yyyymmdd'), -200);\n\ninsert into t(account, bookdate, amount) values (2, to_date('20080102', 'yyyymmdd'), 200);\n\ncommit;\n"]], ['Running total by grouped records in table'], 3, 0], [(501021, 0), [['With your datetimes stored this way, you simply use text comparisons such as '], ['or']], [[" SELECT * FROM tbl WHERE tbl.start = '2009-02-01 10:30:00'\n"]], ['Python + SQLite query to find entries that sit in a specified time slot'], 2, 1], [(501021, 1), [['or'], ['-10000']], [[" SELECT * FROM tbl WHERE '2009-02-01 10:30:00' BETWEEN tbl.start AND tbl.end;\n"]], ['Python + SQLite query to find entries that sit in a specified time slot'], 2, 1], [(521270, 0), [['I agreed with above, look into AND clauses'], ["However you shouldn't have to split the input sentences, you can use variable"]], [[' SELECT TITLE\nFROM MOVIES\nWHERE CONTAINS(TITLE,\'"hollywood*" AND "square*"\')\n']], ['Best way to implement a stored procedure with full text search'], 2, 1], [(521270, 1), [["However you shouldn't have to split the input sentences, you can use variable"], ['by the way\nsearch for the exact term (contains)\nsearch for any term in the phrase (freetext)']], [[' SELECT TITLE\nFROM MOVIES\nWHERE CONTAINS(TITLE,@parameter)\n']], ['Best way to implement a stored procedure with full text search'], 2, 1], [(539942, 0), [['-10000'], ['Or am I mistaken?']], [[" SELECT SUBSTRING(colDate,0,8) as 'date' \nFROM someTable\n"]], ['Updating multiple rows with a value calculated from another column'], 2, 1], [(539942, 1), [['Or am I mistaken?'], ['Would likely work too. Untested.']], [[' UPDATE someTable\nSET newDateField = SUBSTRING(colDate,0,8)\n']], ['Updating multiple rows with a value calculated from another column'], 2, 1], [(556509, 0), [['-10000'], ['No query can see the changes made by itself, or the following query:']], [[' UPDATE mytable, (\n  SELECT @loop := MAX(col1)\n  FROM\n    mytable\n  ) o\nSET col1 = (@loop := @loop + 1)\n']], ['SQL : update statement with dynamic column value assignment'], 2, 1], [(556509, 1), [['No query can see the changes made by itself, or the following query:'], ['would never end.']], [[' UPDATE mytable\nSET col1 = col2 + 1\nWHERE col1 > col2 \n']], ['SQL : update statement with dynamic column value assignment'], 2, 0], [(560694, 0), [['Assuming that you are using webforms, you need a textbox on your page:'], ['Assuming that you have a submit button:']], [[' <asp:TextBox ID="txtTags" runat="server" />\n']], ['adding a tags field to an asp.net web page'], 3, 0], [(560694, 1), [['Assuming that you have a submit button:'], ['You would have a SaveTags method that handles the click event:']], [[' <asp:Button ID="btnSubmit" onclick="SaveTags" runat="server" Text="submit" />\n']], ['adding a tags field to an asp.net web page'], 3, 0], [(560694, 2), [['You would have a SaveTags method that handles the click event:'], ['-10000']], [[' protected void SaveTags(object sender, EventArgs e)\n{\n    string[] tags = txtTags.Text.Split(\' \');\n\n    SqlConnection connection = new SqlConnection("Your connection string");\n    SqlCommand command = connection.CreateCommand("Insert Into Tags(tag) Values(@tag)");\n    foreach (string tag in tags)\n    {\n        command.Parameters.Clear();\n        command.Parameters.AddWithValue("@tag", tag);\n        command.ExecuteNonQuery();\n    }\n    connection.Close();\n}\n']], ['adding a tags field to an asp.net web page'], 3, 0], [(576071, 0), [['-10000'], ['More efficient way for  MySQL :']], [[' SELECT AVG(covered)\nFROM (\n  SELECT CASE WHEN COUNT(*) >= 2 THEN 1 ELSE 0 END AS covered\n  FROM app a\n  LEFT JOIN skill s ON (s.id_app = a.id AND s.lvl >= 2)\n  GROUP BY a.id\n)\n']], ['coverage percentage using a complex sql query...?'], 2, 1], [(576071, 1), [['More efficient way for  MySQL :'], ['This will stop counting as soon as it finds the second skilled  person  for each  app .']], [[' SELECT AVG\n       (\n         IFNULL\n         (\n           (\n           SELECT 1\n           FROM skill s\n           WHERE s.id_app = a.id\n           AND s.lvl >= 2\n           LIMIT 1, 1\n           ), 0\n         )\n       )\nFROM app a\n']], ['coverage percentage using a complex sql query...?'], 2, 1], [(603504, 0), [['There is no implicit convesion from  VARCHAR2  to  RAW . That means that this clause:'], ['will be impicitly converted into:']], [[' WHERE raw_column = :varchar_value\n']], ['How do you convert SYS_GUID() to varchar?'], 3, 0], [(603504, 1), [['will be impicitly converted into:'], ['Use:']], [[' WHERE RAWTOHEX(raw_column) = :varchar_value\n']], ['How do you convert SYS_GUID() to varchar?'], 3, 0], [(674776, 0), [['EDIT: Sorry, my first response was a bit rushed. Have now had a chance to look further. Due to the sub requester and the sub requester attribute both being duplicates you need to split them both up into a subquery. Also, your modified date could be different for both values. So i\'ve doubled that up. This is completely untested, and by no means the "optimum" solution. It\'s quite tricky to write the query without the actual database to check against. Hopefully it will explain what I meant though.'], ['SECOND EDIT: My last edit was that there were multiple SubRequesters as well as multiple Attribute, from your last comment you want to show all SubRequesters and the two relevent attributes? You can achieve this as follows.']], [[" SELECT\n    r.RequesterID,\n    p.FirstName + ' ' + p.LastName AS RequesterName,\n    sra1.ModifiedDate as UrgentModifiedDate,\n    sra1.AttributeValue as Urgent,\n    sra2.ModifiedDate as ClosedModifiedDate,\n    sra2.AttributeValue as Closed\nFROM\n    Personnel AS p\nINNER JOIN\n    Requester AS r \nON\n(\n    r.UserID = p.ContractorID\nOR\n    r.UserID = p.EmployeeID\n)\nLEFT OUTER JOIN\n(\n    SELECT\n        sr1.RequesterID,\n        sr1.ModifiedDate,\n        sa1.Attribute,\n        sa1.AttributeValue\n    FROM\n        SubRequester AS sr1\n    INNER JOIN\n        SubRequesterAttribute AS sa1\n    ON\n        sr1.SubRequesterID = sa1.SubRequesterID\n    AND\n        sa1.Attribute = 'Urgent'\n) sra1\nON\n    sra1.RequesterID = r.RequesterID\nLEFT OUTER JOIN\n(\n    SELECT\n        sr2.RequesterID,\n        sr2.ModifiedDate,\n        sa2.Attribute,\n        sa2.AttributeValue\n    FROM\n        SubRequester AS sr2\n    INNER JOIN\n        SubRequesterAttribute AS sa2\n    ON\n        sr2.SubRequesterID = sa2.SubRequesterID\n    AND\n        sa2.Attribute = 'Closed'\n) sra1\nON\n    sra2.RequesterID = r.RequesterID\n"]], ['Unified records for database query with Sql'], 2, 1], [(684106, 0), [['Find the first row where there does not exist a row with Id + 1'], ['To handle the special case where the lowest existing id is not 1, here is a ugly solution:']], [[' SELECT TOP 1 t1.Id+1 \nFROM table t1\nWHERE NOT EXISTS(SELECT * FROM table t2 WHERE t2.Id = t1.Id + 1)\nORDER BY t1.Id\n']], ['Find the smallest unused number in SQL Server'], 2, 1], [(684106, 1), [['To handle the special case where the lowest existing id is not 1, here is a ugly solution:'], ['-10000']], [[' SELECT TOP 1 * FROM (\n    SELECT t1.Id+1 AS Id\n    FROM table t1\n    WHERE NOT EXISTS(SELECT * FROM table t2 WHERE t2.Id = t1.Id + 1 )\n    UNION \n    SELECT 1 AS Id\n    WHERE NOT EXISTS (SELECT * FROM table t3 WHERE t3.Id = 1)) ot\nORDER BY 1\n']], ['Find the smallest unused number in SQL Server'], 2, 1], [(706664, 0), [['DDL:'], ['Query:']], [[' CREATE TABLE [dbo].[WorkOut](\n    [WorkOutID] [bigint] IDENTITY(1,1) NOT NULL,\n    [TimeSheetDate] [datetime] NOT NULL,\n    [DateOut] [datetime] NOT NULL,\n    [EmployeeID] [int] NOT NULL,\n    [IsMainWorkPlace] [bit] NOT NULL,\n    [DepartmentUID] [uniqueidentifier] NOT NULL,\n    [WorkPlaceUID] [uniqueidentifier] NULL,\n    [TeamUID] [uniqueidentifier] NULL,\n    [WorkShiftCD] [nvarchar](10) NULL,\n    [WorkHours] [real] NULL,\n    [AbsenceCode] [varchar](25) NULL,\n    [PaymentType] [char](2) NULL,\n    [CategoryID] [int] NULL,\n    [Year]  AS (datepart(year,[TimeSheetDate])),\n CONSTRAINT [PK_WorkOut] PRIMARY KEY CLUSTERED \n(\n    [WorkOutID] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]\n) ON [PRIMARY]\n\nALTER TABLE [dbo].[WorkOut] ADD  \nCONSTRAINT [DF__WorkOut__IsMainW__2C1E8537]  DEFAULT ((1)) FOR [IsMainWorkPlace]\n\nALTER TABLE [dbo].[WorkOut]  WITH CHECK ADD  CONSTRAINT [FK_WorkOut_Employee_EmployeeID] FOREIGN KEY([EmployeeID])\nREFERENCES [dbo].[Employee] ([EmployeeID])\n\nALTER TABLE [dbo].[WorkOut] CHECK CONSTRAINT [FK_WorkOut_Employee_EmployeeID]\n']], ['Generate SQL Create Scripts for existing tables with Query'], 3, 0], [(706664, 2), [['Output:'], ['Also check this article -']], [[' CREATE TABLE [dbo].[WorkOut]\n(\n      [WorkOutID] BIGINT NOT NULL IDENTITY(1,1)\n    , [TimeSheetDate] DATETIME NOT NULL\n    , [DateOut] DATETIME NOT NULL\n    , [EmployeeID] INT NOT NULL\n    , [IsMainWorkPlace] BIT NOT NULL DEFAULT((1))\n    , [DepartmentUID] UNIQUEIDENTIFIER NOT NULL\n    , [WorkPlaceUID] UNIQUEIDENTIFIER NULL\n    , [TeamUID] UNIQUEIDENTIFIER NULL\n    , [WorkShiftCD] NVARCHAR(10) COLLATE Cyrillic_General_CI_AS NULL\n    , [WorkHours] REAL NULL\n    , [AbsenceCode] VARCHAR(25) COLLATE Cyrillic_General_CI_AS NULL\n    , [PaymentType] CHAR(2) COLLATE Cyrillic_General_CI_AS NULL\n    , [CategoryID] INT NULL\n    , [Year] AS (datepart(year,[TimeSheetDate]))\n    , CONSTRAINT [PK_WorkOut] PRIMARY KEY ([WorkOutID] ASC)\n)\n\nALTER TABLE [dbo].[WorkOut] WITH CHECK ADD CONSTRAINT [FK_WorkOut_Employee_EmployeeID] FOREIGN KEY([EmployeeID]) REFERENCES [dbo].[Employee] ([EmployeeID])\nALTER TABLE [dbo].[WorkOut] CHECK CONSTRAINT [FK_WorkOut_Employee_EmployeeID]\n\nCREATE NONCLUSTERED INDEX [IX_WorkOut_WorkShiftCD_AbsenceCode] ON [dbo].[WorkOut] ([WorkShiftCD] ASC, [AbsenceCode] ASC)\nINCLUDE ([WorkOutID], [WorkHours])\n']], ['Generate SQL Create Scripts for existing tables with Query'], 3, 0], [(713960, 1), [['This runs fine on my SQL Server 2005, where MyTable.MyKey is an identity column.'], ['\n EDIT \nTHIS WORKS, with no errors...']], [[' -- Create empty temp table\nSELECT *\nINTO #TmpMikeMike\nFROM (SELECT\n      m1.*\n      FROM MyTable                 m1\n          LEFT OUTER JOIN MyTable  m2 ON m1.MyKey=m2.MyKey\n      WHERE 1=0\n ) dt\n\nINSERT INTO #TmpMike\nSELECT TOP 1 * FROM MyTable\n\nSELECT * from #TmpMike\n']], ['How to drop IDENTITY property of column in SQL Server 2005'], 3, 1], [(713960, 2), [['\n EDIT \nTHIS WORKS, with no errors...'], ['however, what is your real problem?   Why do you need to loop while inserting "*" into this temp table?  You may be able to shift strategy and come up with a much better algorithm overall.']], [[' -- Create empty temp table\nSELECT *\nINTO #Tmp_MyTable\nFROM (SELECT\n          m1.*\n          FROM MyTable                 m1\n              LEFT OUTER JOIN MyTable  m2 ON m1.KeyValue=m2.KeyValue\n          WHERE 1=0\n     ) dt\n...\nWHILE ...\nBEGIN\n    ...\n    INSERT INTO #Tmp_MyTable\n    SELECT TOP (@n) *\n    FROM MyTable\n    ...\n\nEND\n']], ['How to drop IDENTITY property of column in SQL Server 2005'], 3, 1], [(726582, 0), [["This will only really work if the pivoted columns form a unique identifier. So let's take Buggy's example; here is the original table:"], ['and we want to pivot it into a table that looks like this:']], [[' TaskID    Date    Hours\n']], ['Updates on PIVOTs in SQL Server 2008'], 5, 0], [(726582, 1), [['and we want to pivot it into a table that looks like this:'], ['In order to create the pivot, you would do something like this:']], [[' TaskID    11/15/1980    11/16/1980    11/17/1980 ... etc.\n']], ['Updates on PIVOTs in SQL Server 2008'], 5, 0], [(726582, 2), [['In order to create the pivot, you would do something like this:'], ['So then you have your pivoted table in  ##Pivoted . Now you perform an update to one of the hours fields:']], [[" DECLARE @FieldList NVARCHAR(MAX)\n\nSELECT\n    @FieldList =\n    CASE WHEN @FieldList <> '' THEN \n        @FieldList + ', [' + [Date] + ']' \n    ELSE \n        '[' + [Date] + ']' \n    END\nFROM\n    Tasks\n\n\n\nDECLARE @PivotSQL NVARCHAR(MAX)\nSET @PivotSQL = \n    '\n        SELECT \n            TaskID\n            , ' + @FieldList + '\n        INTO\n            ##Pivoted\n        FROM \n            (\n                SELECT * FROM Tasks\n            ) AS T\n        PIVOT\n            (\n                MAX(Hours) FOR T.[Date] IN (' + @FieldList + ') \n            ) AS PVT\n    '\n\nEXEC(@PivotSQL)\n"]], ['Updates on PIVOTs in SQL Server 2008'], 5, 0], [(726582, 3), [['So then you have your pivoted table in  ##Pivoted . Now you perform an update to one of the hours fields:'], ['Now  ##Pivoted  has an updated version of the hours for a task that took place on 11/16/1980 and we want to save that back to the original table, so we use an  UNPIVOT :']], [[' UPDATE\n    ##Pivoted\nSET\n    [11/16/1980 00:00:00] = 10\nWHERE\n    TaskID = 1234\n']], ['Updates on PIVOTs in SQL Server 2008'], 5, 0], [(726582, 4), [['Now  ##Pivoted  has an updated version of the hours for a task that took place on 11/16/1980 and we want to save that back to the original table, so we use an  UNPIVOT :'], ["You'll notice that I modified Buggy's example to remove aggregation by day-of-week. That's because there's no going back and updating if you perform any sort of aggregation. If I update the SUNHours field, how do I know which Sunday's hours I'm updating? This will only work if there is no aggregation. I hope this helps!"]], [[" DECLARE @UnPivotSQL NVarChar(MAX)\nSET @UnPivotSQL = \n    '\n        SELECT\n              TaskID\n            , [Date]\n            , [Hours]\n        INTO \n            ##UnPivoted\n        FROM\n            ##Pivoted\n        UNPIVOT\n        (\n            Value FOR [Date] IN (' + @FieldList + ')\n        ) AS UP\n\n    '\n\nEXEC(@UnPivotSQL)\n\nUPDATE\n    Tasks\nSET\n    [Hours] = UP.[Hours]\nFROM\n    Tasks T\nINNER JOIN\n    ##UnPivoted UP\nON\n    T.TaskID = UP.TaskID\n"]], ['Updates on PIVOTs in SQL Server 2008'], 5, 0], [(778909, 0), [['So, to save following the link, the query looks like this, where  #Numbers  is the table and  Num  is the column:'], ['for negative or positive values']], [["    SELECT RIGHT('000000000' + CONVERT(VARCHAR(8),Num), 8) FROM #Numbers\n"]], ["Most efficent method for adding leading 0's to an int in sql"], 2, 1], [(802027, 0), [['Definition: Limit is used to limit your MySQL query results to those that fall within a specified range. You can use it to show the first X number of results, or to show a range from X - Y results. It is phrased as Limit X, Y and included at the end of your query. X is the starting point (remember the first record is 0) and Y is the duration (how many records to display).\nAlso Known As: Range Results\nExamples:'], ['This will display the first 10 results from the database.']], [[' SELECT * FROM `your_table` LIMIT 0, 10 \n']], ['In SQL, how do you get the top N rows ordered by a certain column?'], 2, 1], [(802027, 1), [['This will display the first 10 results from the database.'], ['This will show records 6, 7, 8, 9, and 10']], [[' SELECT * FROM `your_table` LIMIT 5, 5 \n']], ['In SQL, how do you get the top N rows ordered by a certain column?'], 2, 1], [(852225, 0), [['First, get a list of parents:'], ['Then get a properly sorted list of children:']], [[' SELECT *\nFROM Persons\nWHERE id IN (SELECT parent FROM Persons)\nORDER BY (age, id)\n']], ['persons where the children are grouped for their parent'], 2, 0], [(852225, 1), [['Then get a properly sorted list of children:'], ["The two lists can then easily be merged on the  id / parent  since they are both sorted first by parent's  age ."]], [[' SELECT Child.*\nFROM Persons AS Child\n     JOIN Persons AS Parent ON (Parent.id = Child.parent)\nORDER BY (Parent.age, Parent.id, Child.age, Child.id)\n']], ['persons where the children are grouped for their parent'], 2, 0], [(895876, 0), [['-10000'], ['You may find it useful to add']], [[' select list_id, address_id, count(*) as count\nfrom LIST_MEMBERSHIPS\ngroup by 1, 2\norder by 3 desc\n']], ['How can I count the non-unique combinations of values in MySQL?'], 2, 1], [(895876, 1), [['You may find it useful to add'], ['-10000']], [[' having count > 1\n']], ['How can I count the non-unique combinations of values in MySQL?'], 2, 0], [(938232, 0), [["Here's an attempt at PIVOT:"], ["Given that it's just two columns, could try with a join:"]], [[' select *\nfrom YourTable\nPIVOT (sum(amount) FOR Method in (Cash,Check)) as Y\n']], ['SQL Pivot on subset'], 2, 1], [(938232, 1), [["Given that it's just two columns, could try with a join:"], ['-10000']], [[" select\n    type\n,   cash = a.amount\n,   check = b.amount\nfrom yourtable a\nfull join yourtable b on a.type = b.type\nwhere a.method = 'cash' or b.method = 'Check'\n"]], ['SQL Pivot on subset'], 2, 1], [(951401, 0), [["Yes, it's possible with CROSS APPLY (SQL 2005+):"], ['eg:']], [[" with testdata (CommaColumn, ValueColumn1, ValueColumn2) as (\n  select 'ABC,123', 1, 2 union all\n  select 'XYZ, 789', 2, 3\n  ) \nselect \n  b.items as SplitValue\n, a.ValueColumn1\n, a.ValueColumn2\nfrom testdata a\ncross apply dbo.Split(a.CommaColumn,',') b\n"]], ['SQL 2005 Split Comma Separated Column on Delimiter'], 2, 1], [(955927, 0), [['The  DBA_OBJECTS  view will list the procedures (as well as almost any other object):'], ['The  DBA_SOURCE  view will list the lines of source code for a procedure in question:']], [[" SELECT owner, object_name\nFROM dba_objects \nWHERE object_type = 'PROCEDURE'\n"]], ['What SQL would I need to use to list all the stored procedures on an Oracle database?'], 2, 0], [(955927, 1), [['The  DBA_SOURCE  view will list the lines of source code for a procedure in question:'], ['Note:  Depending on your privileges, you may not be able to query the  DBA_OBJECTS  and  DBA_SOURCE  views. In this case, you can use  ALL_OBJECTS  and  ALL_SOURCE  instead. The  DBA_  views contain  all  objects in the database, whereas the  ALL_  views contain only those objects that you may access.']], [[" SELECT line, text\nFROM dba_source\nWHERE owner = ?\n  AND name = ?\n  AND type = 'PROCEDURE'\nORDER BY line\n"]], ['What SQL would I need to use to list all the stored procedures on an Oracle database?'], 2, 0], [(970357, 0), [['To create a database dump from MySQL, you can run something like this --'], ['Now that we got that out of the way, you can log in to the MySQL database using:']], [[' mysqldump -h hostname -u username -p databasename > my_sql_dump.sql\n']], ['How can I change an URL inside a field in MySQL?'], 4, 0], [(970357, 1), [['Now that we got that out of the way, you can log in to the MySQL database using:'], ['And simply run this statement:']], [[' mysql -h hostname -u username -p databasename\n']], ['How can I change an URL inside a field in MySQL?'], 4, 0], [(970357, 2), [['And simply run this statement:'], ["If you make a mistake, you can often rerun the statement with the original and new texts inverted (if the new text -- in your case the new URL -- didn't already exist in the text before you did the replace.) Sometimes this is not possible depending on what the new text was (again, not likely in your case.) Anyway, you can always try recovering the sql dump --"]], [[' UPDATE `wp-posts` SET `post-content` = REPLACE(`post-content`, "http://oldurl.com", "http://newurl.com");\n']], ['How can I change an URL inside a field in MySQL?'], 4, 0], [(970357, 3), [["If you make a mistake, you can often rerun the statement with the original and new texts inverted (if the new text -- in your case the new URL -- didn't already exist in the text before you did the replace.) Sometimes this is not possible depending on what the new text was (again, not likely in your case.) Anyway, you can always try recovering the sql dump --"], ['And  voilà .']], [[' cat my_sql_dump.sql | mysql -h hostname -u username -p databasename\n']], ['How can I change an URL inside a field in MySQL?'], 4, 0], [(1019661, 1), [['lists the start day IDs:'], ['lists the end day IDs:']], [['  ID      EMPLOYEEID       PROJECTID           DAYID \n 1              64               2             168 \n 5              64               1             169 \n 9              64               2             182 \n\n\n\nselect *\n  from employee_schedule a                   \n where not exists( select *                         \n                     from employee_schedule b       \n                    where a.employeeid = b.employeei\n                      and a.projectid  = b.projectid\n                      and (a.dayid + 1) = b.dayid )\n']], ['Finding Start and End Dates from Date Numbers Table (Date Durations)'], 3, 0], [(1019661, 2), [['lists the end day IDs:'], ['-10000']], [['   ID      EMPLOYEEID       PROJECTID           DAYID \n  4              64               2             171 \n  8              64               1             172 \n 11              64               2             184 \n']], ['Finding Start and End Dates from Date Numbers Table (Date Durations)'], 3, 0], [(1069311, 1), [['The result (ready to use with XML parameter):'], ['-10000']], [[' <?xml version="1.0"?>\n<ArrayOfInt xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema">\n  <int>1</int>\n  <int>2</int>\n  <int>3</int>\n</ArrayOfInt>\n']], ['Passing an array of parameters to a stored procedure'], 4, 0], [(1069311, 2), [['-10000'], ['-10000']], [[' <ids>\n    <id>1</id>\n    <id>2</id>\n</ids>\n']], ['Passing an array of parameters to a stored procedure'], 4, 0], [(1070122, 0), [['Just do the order details condition in the usual way:'], ['Or use an expression as the data source']], [[" from o in orders\njoin od from orderdetails on o.id = od.orderid\n  into details\nwhere details.status == 'A'\nselect new { Order = o, Details = details}\n"]], ['How can I make a LINQ query with subqueries in the from statement?'], 3, 1], [(1070122, 1), [['Or use an expression as the data source'], ['Or even, use another comprehension expression as the source expression:']], [[" from o in orders\njoin od from orderdetails.Where(d => d.Status == 'A') on o.id = od.orderid\n  into details\nselect new { Order = o, Details = details}\n"]], ['How can I make a LINQ query with subqueries in the from statement?'], 3, 1], [(1070122, 2), [['Or even, use another comprehension expression as the source expression:'], ["(Setting you  DataContext 's  Log  property allows you to see the SQL so you can compare what SQL is actually generated.)"]], [[" from o in orders\njoin od from (from d in orderdetails\n              where d.Status == 'A'\n              select d)\n  on o.id = od.orderid\n  into details\nselect new { Order = o, Details = details}\n"]], ['How can I make a LINQ query with subqueries in the from statement?'], 3, 1], [(1074529, 0), [['Suggested using this syntax for placement of the <Query> node (this example is to retrieve the item with an ID of 1):'], ['So, I used this as my query:']], [[' <Query>\n  <SoapAction>http://schemas.microsoft.com/sharepoint/soap/GetListItems</SoapAction>\n  <Method Namespace="http://schemas.microsoft.com/sharepoint/soap/" Name="GetListItems">\n    <Parameters>\n      <Parameter Name="listName">\n        <DefaultValue>{CE7A4C2E-D03A-4AF3-BCA3-BA2A0ADCADC7}</DefaultValue>\n      </Parameter>\n      <Parameter Name="query" Type="xml">\n        <DefaultValue>\n          <Query>\n            <Where>\n              <Eq>\n                <FieldRef Name="ID"/>\n                <Value Type="Integer">1</Value>\n              </Eq>\n            </Where>\n          </Query>\n        </DefaultValue>\n      </Parameter>\n    </Parameters>\n  </Method>\n  <ElementPath IgnoreNamespaces="True">*</ElementPath>\n</Query>\n']], ['SOAP call with query on result (SSRS, Sharepoint)'], 4, 0], [(1074529, 1), [['So, I used this as my query:'], ['And then defined a parameter on the dataset named query, with the following value:']], [[' <Query>\n  <SoapAction>http://schemas.microsoft.com/sharepoint/soap/GetListItems</SoapAction>\n   <Method Namespace="http://schemas.microsoft.com/sharepoint/soap/" Name="GetListItems">\n      <Parameters>\n         <Parameter Name="listName">\n            <DefaultValue>{CE7A4C2E-D03A-4AF3-BCA3-BA2A0ADCADC7}</DefaultValue>\n         </Parameter>\n         <Parameter Name="query" Type="xml">\n        </Parameter>   \n      </Parameters>\n   </Method>\n   <ElementPath IgnoreNamespaces="True">*</ElementPath>\n</Query>\n']], ['SOAP call with query on result (SSRS, Sharepoint)'], 4, 0], [(1074529, 2), [['And then defined a parameter on the dataset named query, with the following value:'], ['I was also able to make my query dependent on a report parameter, by setting the query dataset parameter to the following expression:']], [[' <Query><Where><Eq><FieldRef Name="ID"/><Value Type="Integer">1</Value></Eq></Where></Query>\n']], ['SOAP call with query on result (SSRS, Sharepoint)'], 4, 0], [(1074529, 3), [['I was also able to make my query dependent on a report parameter, by setting the query dataset parameter to the following expression:'], ['-10000']], [[' ="<Query><Where><Eq><FieldRef Name=""ID""/><Value Type=""Integer"">" & \nParameters!TaskID.Value & \n"</Value></Eq></Where></Query>"\n']], ['SOAP call with query on result (SSRS, Sharepoint)'], 4, 0], [(1146012, 1), [['Not knowing the full schema of the tables, I would guess that the proper version of this query would look something like this:'], ['Looking one more time, I realize that your "fbDivision.DivisionName = ?" probably is reducing the number of rows in that table to one, and that there isn\'t a formal PK/FK relationship between those two tables.  In which case, you should dispense with the INNER JOIN nomenclature in the FROM clause and just list the two tables; I\'ve updated my example.']], [['   SELECT vw_fbScheduleFull.LocationName\n       , vw_fbScheduleFull.FieldName\n       , vw_fbScheduleFull.Description\n       , vw_fbScheduleFull.StartTime\n       , vw_fbScheduleFull.EndTime\n       , vw_fbScheduleFull.LowerDivision\n       , vw_fbScheduleFull.UpperDivision\n       , vw_fbScheduleFull.SeniorDivision\n    FROM vw_fbScheduleFull \n       , fbDivision\n   WHERE vw_fbScheduleFull.PracticeDate = ?\n     AND vw_fbScheduleFull.Locked IS NULL \n     AND fbDivision.DivisionName = ?\n     AND (vw_fbScheduleFull.LowerDivision = 1 OR fbDivision.LowerDivision <> 1)\n     AND (vw_fbScheduleFull.UpperDivision = 1 OR fbDivision.UpperDivision <> 1)\n     AND (vw_fbScheduleFull.SeniorDivision = 1 OR fbDivision.SeniorDivision <> 1)\nORDER BY vw_fbScheduleFull.LocationName\n       , vw_fbScheduleFull.FieldName\n       , vw_fbScheduleFull.StartTime \n;\n']], ['Join on multiple booleans'], 2, 1], [(1154702, 1), [['Or, you could transform your multiple query request into a two query request:'], ['-10000']], [[' DECLARE\n  @theDate datetime,\n  @theDate2 datetime\n\nSET @theDate = (SELECT Max(date) FROM news)\n  --trim the time off of @theDate\nSET @theDate = DateAdd(dd, DateDiff(dd, 0, @theDate), 0)\nSET @theDate2 = DateAdd(dd, 1, @theDate)\n\nSELECT *\nFROM news\nWHERE @theDate <= date AND date < @theDate2\nORDER BY date desc\n']], ['SQL Checking for NULL and incrementals'], 2, 1], [(1179355, 0), [['Minus operations use distinct sets. Try this instead:'], ['It produces:']], [[' select row_number() over (partition by name_id, val order by name_id, val), name_id, val \nfrom check_minus\nwhere val > 0\n  minus\nselect row_number() over (partition by name_id, val order by name_id, val), name_id, abs(val) \nfrom check_minus\nwhere val < 0\n']], ['Oracle Minus - From a list of values, how do I count ONLY non reversed values'], 2, 1], [(1179355, 1), [['It produces:'], ['-10000']], [[' RowNum Name_Id   Val\n1,     1,        20\n2,     1,        5\n2,     1,        15\n3,     1,        15\n']], ['Oracle Minus - From a list of values, how do I count ONLY non reversed values'], 2, 0], [(1197943, 0), [['Try creating a view called MASTER_MYVIEW first (you may need to deal with privileges there as well):'], ['Then create a public synonym for that new view:']], [[' create view master_myview as select ...;\n']], ['Creating public synonym at system level'], 2, 0], [(1197943, 1), [['Then create a public synonym for that new view:'], ['-10000']], [[' create or replace public synonym master_myview for <owner>.master_myview;\n']], ['Creating public synonym at system level'], 2, 0], [(1207740, 0), [['Replace the  Count  statements with'], ['To prune  ItemName s without any added dates, the query block had to be enclosed in a larger query, since checking against a calculated field cannot be done from inside a query.  The end result is this query:']], [[' Sum(Iif(DateDiff("d",DateAdded,Date())>=91,Iif(DateDiff("d",DateAdded,Date())<=180,\'1\',\'0\'),\'0\')) AS BTWN_91_180,\n']], ['Make a query Count() return 0 instead of empty'], 2, 1], [(1207740, 1), [['To prune  ItemName s without any added dates, the query block had to be enclosed in a larger query, since checking against a calculated field cannot be done from inside a query.  The end result is this query:'], ['-10000']], [[' SELECT *\nFROM \n     (\n     SELECT DISTINCT Source.ItemName AS InvestmentManager, \n     Sum(Iif(DateDiff("d",DateAdded,Date())>=20,Iif(DateDiff("d",DateAdded,Date())<=44,\'1\',\'0\'),\'0\')) AS BTWN_20_44,\n     Sum(Iif(DateDiff("d",DateAdded,Date())>=45,Iif(DateDiff("d",DateAdded,Date())<=60,\'1\',\'0\'),\'0\')) AS BTWN_45_60,\n     Sum(Iif(DateDiff("d",DateAdded,Date())>=61,Iif(DateDiff("d",DateAdded,Date())<=90,\'1\',\'0\'),\'0\')) AS BTWN_61_90,\n     Sum(Iif(DateDiff("d",DateAdded,Date())>=91,Iif(DateDiff("d",DateAdded,Date())<=180,\'1\',\'0\'),\'0\')) AS BTWN_91_180,\n     Sum(Iif(DateDiff("d",DateAdded,Date())>180,\'1\',\'0\')) AS GT_180,\n     Sum(Iif(DateDiff("d",DateAdded,Date())>=20,\'1\',\'0\')) AS Total\n     FROM Source\n     WHERE CompleteState=\'FAILED\'\n     GROUP BY ItemName\n     )\nWHERE Total > 0;\n']], ['Make a query Count() return 0 instead of empty'], 2, 1], [(1263780, 0), [["If it's one song after another, assuming a table named tblSongs with a 'sequence' & 'name' column.  You might want to try something like"], ['If song sequence X,Y is counted the same as Y,X then']], [[' select top N first.name, second.name, count(*)\nfrom tblSongs as first \n     inner join tblSongs as second\n         on second.sequence=first.sequence + 1\ngroup by first.name, second.name\norder by count(*) desc\n']], ['SQL - Find patterns of records'], 3, 1], [(1263780, 1), [['If song sequence X,Y is counted the same as Y,X then'], ['If you are looking for any pattern of 2 song sequences, then ']], [[' select top N first.name, second.name, count(*)\nfrom tblSongs as first \n     inner join tblSongs as second\n         on second.sequence=first.sequence + 1\n         or second.sequence=first.sequence - 1\ngroup by first.name, second.name\norder by count(*) desc\n']], ['SQL - Find patterns of records'], 3, 1], [(1263780, 2), [['If you are looking for any pattern of 2 song sequences, then '], ['Then do some statistical analysis on the spacing_count (which is beyond me).']], [[' select first.name, second.name, abs(second.sequence - first.sequence) as spacing_count\nfrom tblSongs as first \n     inner join tblSongs as second\n         on second.sequence=first.sequence + 1\n         or second.sequence=first.sequence - 1\n']], ['SQL - Find patterns of records'], 3, 1], [(1326701, 0), [['It\'s not trivial. First, you need another column "Flag" which is 0:'], ['You need to run these queries several times:']], [[' INSERT INTO Results (year, month, day, hour, duration, court, Flag)\nSELECT DATEPART (yy, b.StartDateTime),\n       DATEPART (mm, b.StartDateTime),\n       DATEPART (dd, b.StartDateTime),\n       DATEPART (hh, b.StartDateTime),\n       a.Duration,\n       a.Court,\n       0\nFROM Bookings b\nINNER JOIN Activities a\nON b.ActivityID = a.ID\n']], ['Single or multiple INSERTs based on values SELECTed'], 2, 0], [(1326701, 1), [['You need to run these queries several times:'], ["This will create an additional entry for each  duration > 1 . My guess is that you can't allocate a court for more than 8 hours, so you just need to run these three 8 times to fix all of them."]], [[' -- Copy all rows with duration > 1 and set the flag to 1\ninsert into results(year, month, day, hour, duration, court, Flag)\nselect year, month, day, hour+1, duration-1, court, 1\nfrom result\nwhere duration > 1\n;\n-- Set the duration of all copied rows to 1\nupdate result\nset duration = 1\nwhere flag = 0 and duration > 1\n;\n-- Prepare the copies for the next round\nupdate result\nset flag = 0\nwhere flag = 1\n']], ['Single or multiple INSERTs based on values SELECTed'], 2, 0], [(1341505, 0), [['The  DISTINCT  placed in a subquery should work:'], ['Once this is done, you would join this newly created table with the old table to associate the generated ids to the children tables:']], [[' SQL> INSERT INTO meeting\n  2     SELECT seq.nextval, meeting_desc, meeting_date\n  3       FROM (SELECT DISTINCT meeting_desc, meeting_date\n  4               FROM current_table);\n\n2 rows inserted\n']], ['Oracle: Normalizing data during migration'], 2, 0], [(1341505, 1), [['Once this is done, you would join this newly created table with the old table to associate the generated ids to the children tables:'], ['-10000']], [[' SQL>   INSERT INTO topic\n  2       SELECT m.id, topic_seq.NEXTVAL, ct.topic_desc\n  3         FROM current_table ct\n  4         JOIN meeting m ON (ct.meeting_desc = m.meeting_desc \n  5                            AND ct.meeting_date = m.meeting_date);\n\n5 rows inserted\n']], ['Oracle: Normalizing data during migration'], 2, 0], [(1344697, 1), [['Your stored procedure in this case will look something like:'], ["Here's a link on Stored Procedure basics:\n http://www.sql-server-performance.com/articles/dba/stored_procedures_basics_p1.aspx"]], [[' CREATE PROC [dbo].[IDCategory] \n    @IDCategory int\nAS \n    SELECT IDListing, IDCategory, Price, Seller, Image\n         FROM whateveryourtableisnamed\n         WHERE IDCategory = @IDCategory\n']], ['How can I make a stored procedure return a "dataset" using a parameter I pass?'], 2, 0], [(1362148, 0), [['-10000'], ['Using ADO.NET also works like a charm:']], [['  INSERT INTO dbo.TableWithOnlyIdentity DEFAULT VALUES\n']], ['How to insert into a table with just one IDENTITY column (SQL Express)'], 2, 1], [(1362148, 1), [['Using ADO.NET also works like a charm:'], ["Seems to be a limitation of VS - don't use VS for serious DB work :-)\nMarc"]], [[' using(SqlConnection _con = new SqlConnection("server=(local);\n                             database=test;integrated security=SSPI;"))\n{\n    using(SqlCommand _cmd = new SqlCommand\n            ("INSERT INTO dbo.TableWithOnlyIdentity DEFAULT VALUES", _con))\n    {\n        _con.Open();\n        _cmd.ExecuteNonQuery();\n        _con.Close();\n    }\n}   \n']], ['How to insert into a table with just one IDENTITY column (SQL Express)'], 2, 0], [(1410216, 0), [['Number 1 is easy, as Dr.Jokepu already showed you: '], ['Number 2 you can always do in the same query, adding the changes as you select:']], [[' INSERT INTO <table> (values) SELECT "values" FROM <anotherTable>;\n']], ['DB2 SQL add rows based on other rows'], 2, 0], [(1410216, 1), [['Number 2 you can always do in the same query, adding the changes as you select:'], ["(note the GETDATE() is a MS-SQL function, I don't remember the exact function for DB/2 at this moment)."]], [[" INSERT INTO MDSTD.MBANK ( MID, MAGN, MAAID, MTYPEOT, MAVAILS, MUSER, MTS)\nSELECT \n      MID \n     ,MAGN + 1\n     ,0 as MAAID\n     ,MTYPEOT\n     ,'A' as MAVAILS\n     ,MUSER\n     ,GETDATE() \nFROM mdstd.mbank \nWHERE MTYPEOT = '2' and MAVAILS = 'A'\n"]], ['DB2 SQL add rows based on other rows'], 2, 0], [(1421404, 1), [['-10000'], ['-10000']], [[' mysql> USE dbname;\nmysql> show triggers;\n']], ['Find out which tables were affected by Triggers'], 2, 1], [(1479831, 0), [['You must move the WHERE operator  above  the project list where RowNumber column is created. Use a derived table or a CTE:'], ['the equivalent CTE is:']], [[' SELECT * \n  FROM (\n   SELECT *, ROW_NUMBER() OVER (...) as RowNumber\n   FROM ...) As ...\n WHERE RowNumber = ...\n']], ['Using ranking-function derived column in where clause (SQL Server 2008)'], 2, 1], [(1479831, 1), [['the equivalent CTE is:'], ['-10000']], [[' WITH cte AS (\nSELECT *, ROW_NUMBER() OVER (...) as RowNumber\n       FROM ...)\nSELECT * FROM cte \nWHERE RowNumber = ...   \n']], ['Using ranking-function derived column in where clause (SQL Server 2008)'], 2, 1], [(1627604, 0), [["If you're working with Oracle/PLSQL:"], ['In SQL Server/T-SQL:']], [[" SELECT NumToDSInterval(enddate- startdate, 'MINUTE') FROM MyTable\n"]], ['SQL Query including time calculation'], 3, 1], [(1627604, 1), [['In SQL Server/T-SQL:'], ['In MySQL:']], [[' SELECT DateDiff(n, startdate, enddate) FROM MyTable\n']], ['SQL Query including time calculation'], 3, 1], [(1627604, 2), [['In MySQL:'], ["I'm sure there's one for SQLite and PostGre and any other flavor as well."]], [[' SELECT SubTime(enddate, startdate) FROM MyTable;\n']], ['SQL Query including time calculation'], 3, 1], [(1700110, 2), [['Thanks for all your help. The following is what worked for me:'], ['which gave me what I wanted:']], [[' select\n    m.date as p1,\n    m.grouping_field as p2,\n    sum(m.aggregating_field) as p3,\n    (select min(date) from daily\n        where month(date) = month(m.date)\n        and year(date) = year(m.date)) as p4,\n    (select max(date) from daily\n        where month(date) = month(m.date)\n        and year(date) = year(m.date)) as p5\nfrom\n    monthly m\ngroup by\n    m.date, m.grouping_field\n']], ['How do I select min/max dates from table 2 based on date in table 1 (without getting too much data from sums)'], 4, 1], [(1700110, 3), [['which gave me what I wanted:'], ['-10000']], [['     P1       P2    P3       P4         P5\n----------  ----  ----  ----------  ----------\n2007-10-01  BoxA  12.3  2007-10-16  2007-10-30\n2007-10-01  BoxB  13.6  2007-10-16  2007-10-30\n2007-10-01  BoxC   7.4  2007-10-16  2007-10-30\n2007-11-01  BoxA  20.3  2007-11-01  2007-11-30\n2007-11-01  BoxB  24.2  2007-11-01  2007-11-30\n2007-11-01  BoxC  21.7  2007-11-01  2007-11-30\n2007-12-01  BoxA   6.9  2007-12-01  2007-12-15\n2007-12-01  BoxB   6.4  2007-12-01  2007-12-15\n2007-12-01  BoxC   6.9  2007-12-01  2007-12-15\n']], ['How do I select min/max dates from table 2 based on date in table 1 (without getting too much data from sums)'], 4, 0], [(1712077, 0), [['The easiest way would be to drop the schema the objects are associated to:'], ['For the script you provided, you could instead run those queries without having to generate the intermediate script using the following anonymous procedure:']], [[' DROP USER [schema name] CASCADE\n']], ['Wipe data from Oracle DB'], 2, 1], [(1742507, 0), [['Yes, absolutely.  For example:'], ['Or perhaps you mean something more like this, which is also valid:']], [[' select cnt, count(*) from\n( select department_id, count(*) as cnt\n  from employees\n  group by department_id\n)\ngroup by cnt;\n']], ['AUTO-Parametrized multiple SELECT'], 2, 1], [(1742507, 1), [['Or perhaps you mean something more like this, which is also valid:'], ['-10000']], [[" select emp_name\nfrom employees\nwhere department_id in\n( select department_id\n  from departments\n  where location_id in\n  ( select location_id from locations\n    where country = 'US'\n  )\n);\n"]], ['AUTO-Parametrized multiple SELECT'], 2, 1], [(1747745, 0), [['One possibility would be to hold a computed column on table1 i.e.'], ["I don't know if DB2 supports computed (aka virtual) columns as such, but if not you can create a regular column and maintain it via a trigger.  The create the foreign key constraint:"]], [[' fieldx = (field1 || field2)\n']], ['How to put a constraint on two combined fields?'], 2, 0], [(1773534, 0), [["Let's say you have 2 Oracle stored functions like this:"], ['One of the functions returns a VARCHAR2 and the other returns ref cursor.  On VB side, you could do this:']], [["    FUNCTION my_func\n   (\n      p_parm1 VARCHAR2\n    , p_parm2 NUMBER\n   ) RETURN VARCHAR2\n   AS\n   BEGIN\n      RETURN p_parm1 || to_char(p_parm2);\n   END;\n\n   FUNCTION my_func2 RETURN SYS_REFCURSOR\n   AS\n      v_cursor SYS_REFCURSOR;\n   BEGIN\n      OPEN v_cursor FOR\n         SELECT 'hello there Sean' col1\n           FROM dual\n          UNION ALL\n         SELECT 'here is your answer' col1\n           FROM dual;      \n      RETURN v_cursor;          \n   END;\n"]], ['What is the right way to call an Oracle stored function from ado.net and get the result?'], 2, 0], [(1784283, 0), [['You can group on a constant which might be useful'], ['Edit: For datatype mismatch and multiple values and this allows you to group on both columns...']], [[" SELECT\n    SUM(Column0),\n    CASE @MyVar WHEN 'Column1' THEN Column1 ELSE '' END AS MyGrouping\nFROM\n    Table1\nGROUP BY\n    CASE @MyVar WHEN 'Column1' THEN Column1 ELSE '' END\n"]], ['SQL Server 2005/2008 Group By statement with parameters without using dynamic SQL?'], 2, 1], [(1784283, 1), [['Edit: For datatype mismatch and multiple values and this allows you to group on both columns...'], ['-10000']], [[" SELECT\n    SUM(Column0),\n    CASE @MyVar WHEN 'Column1' THEN Column1 ELSE NULL END AS Column1,\n    CASE @MyVar WHEN 'Column2' THEN Column2 ELSE NULL END AS Column2\nFROM\n    Table1\nGROUP BY\n    CASE @MyVar WHEN 'Column1' THEN Column1 ELSE NULL END,\n    CASE @MyVar WHEN 'Column2' THEN Column2 ELSE NULL END\n"]], ['SQL Server 2005/2008 Group By statement with parameters without using dynamic SQL?'], 2, 1], [(1785942, 0), [['There is quite a wealth of information in the SQL Server documentation on this, but the two statements to create the check constraints you ask for are:'], ['This allows you to have conditions like:']], [[' ALTER TABLE tablename ADD CONSTRAINT constraintName CHECK (colname between 1 and 5);\n\nALTER TABLE tablename ADD CONSTRAINT constraintName CHECK (colname in (1,2,4));\n']], ['How can I use check constraint in sql server 2005'], 2, 1], [(1785942, 1), [['This allows you to have conditions like:'], ['-10000']], [[' (colname >= 1 AND colname <= 5)\n']], ['How can I use check constraint in sql server 2005'], 2, 0], [(1809787, 0), [['As for your question about names before and after, I think you will have to parse the DDL to retrieve them, like that:'], ['The regular expressions could surely be written more clearly, but it works:']], [[" CREATE OR REPLACE TRIGGER MK_BEFORE_RENAME BEFORE RENAME ON SCHEMA \nDECLARE \n  sql_text ora_name_list_t;\n  v_stmt VARCHAR2(2000);\n  n PLS_INTEGER; \nBEGIN  \n  n := ora_sql_txt(sql_text);\n  FOR i IN 1..n LOOP\n   v_stmt := v_stmt || sql_text(i);\n  END LOOP;\n\n  Dbms_Output.Put_Line( 'Before: ' || regexp_replace( v_stmt, 'rename[[:space:]]+([a-z0-9_]+)[[:space:]]+to.*', '\\1', 1, 1, 'i' ) );\n  Dbms_Output.Put_Line( 'After: ' || regexp_replace( v_stmt, 'rename[[:space:]]+.*[[:space:]]+to[[:space:]]+([a-z0-9_]+)', '\\1', 1, 1, 'i' ) );\nEND;\n"]], ['Oracle: How do I determine the NEW name of an object in an "AFTER ALTER" trigger?'], 3, 1], [(1809787, 1), [['The regular expressions could surely be written more clearly, but it works:'], ['UPDATE  To accommodate your changed question:']], [[' RENAME \nmktestx\nTO                 mktesty;\n\nBefore: mktestx\nAfter: mktesty\n']], ['Oracle: How do I determine the NEW name of an object in an "AFTER ALTER" trigger?'], 3, 0], [(1809787, 2), [['UPDATE  To accommodate your changed question:'], ['-10000']], [[" CREATE OR REPLACE TRIGGER MK_AFTER_ALTER AFTER ALTER ON SCHEMA \nDECLARE \n  sql_text ora_name_list_t;\n  v_stmt VARCHAR2(2000);\n  n PLS_INTEGER; \nBEGIN  \n  n := ora_sql_txt(sql_text);\n  FOR i IN 1..n LOOP\n   v_stmt := v_stmt || sql_text(i);\n  END LOOP;\n\n  Dbms_Output.Put_Line( 'Before: ' || regexp_replace( v_stmt, 'alter[[:space:]]+table[[:space:]]+([a-z0-9_]+)[[:space:]]+rename[[:space:]]+to.*', '\\1', 1, 1, 'i' ) );\n  Dbms_Output.Put_Line( 'After: ' || regexp_replace( v_stmt, 'alter[[:space:]]+table[[:space:]]+.*to[[:space:]]+([a-z0-9_]+)', '\\1', 1, 1, 'i' ) );\nEND;\n"]], ['Oracle: How do I determine the NEW name of an object in an "AFTER ALTER" trigger?'], 3, 1], [(1822504, 0), [['How about:'], ['Perhaps more clearly:']], [[' SELECT TOP 1 IIF(EXISTS(\n       SELECT * FROM foo \n       WHERE <some condition>), 0, 1) As f1 \nFROM foo\n']], ['Determine existence of results in jet SQL?'], 2, 1], [(1822504, 1), [['Perhaps more clearly:'], ['-10000']], [[' SELECT TOP 1 IIF(EXISTS(\n       SELECT * FROM foo\n       WHERE <some condition>), 0, 1) As F1 \nFROM MSysObjects\n']], ['Determine existence of results in jet SQL?'], 2, 1], [(1830015, 0), [['This is for " tag1 AND (tag2 OR tag3) AND NOT tag4 OR tag5 ". I\'m sure you can figure out the rest.'], ['Edit: \nIf you want to avoid subqueries, you could do this:']], [[" SELECT items.* FROM items\n    LEFT JOIN (SELECT i1.item_id FROM tagged_items AS i1 INNER JOIN tags AS t1 ON i1.tag_id = t1.id AND t1.name = 'tag1') AS ti1 ON items.id = ti1.item_id\n    LEFT JOIN (SELECT i2.item_id FROM tagged_items AS i2 INNER JOIN tags AS t2 ON i2.tag_id = t2.id AND t2.name = 'tag2') AS ti2 ON items.id = ti2.item_id\n    LEFT JOIN (SELECT i3.item_id FROM tagged_items AS i3 INNER JOIN tags AS t3 ON i3.tag_id = t3.id AND t3.name = 'tag3') AS ti3 ON items.id = ti3.item_id\n    LEFT JOIN (SELECT i4.item_id FROM tagged_items AS i4 INNER JOIN tags AS t4 ON i4.tag_id = t4.id AND t4.name = 'tag4') AS ti4 ON items.id = ti4.item_id\n    LEFT JOIN (SELECT i5.item_id FROM tagged_items AS i5 INNER JOIN tags AS t5 ON i5.tag_id = t5.id AND t5.name = 'tag5') AS ti5 ON items.id = ti5.item_id\nWHERE ti1.item_id IS NOT NULL AND (ti2.item_id IS NOT NULL OR ti3.item_id IS NOT NULL) AND ti4.item_id IS NULL OR ti5.item_id IS NOT NULL;\n"]], ['Boolean expressions for a tagging system in SQL'], 2, 1], [(1830015, 1), [['Edit: \nIf you want to avoid subqueries, you could do this:'], ["I'm not sure why you'd want to do it though, as the additional left joins will likely result in a slower run."]], [[" SELECT items.* FROM items \n    LEFT JOIN tagged_items AS i1 ON items.id = i1.item_id LEFT JOIN tags AS t1 ON i1.tag_id = t1.id AND t1.name = 'tag1'\n    ...\nWHERE t1.item_id IS NOT NULL ...\n"]], ['Boolean expressions for a tagging system in SQL'], 2, 1], [(1853433, 0), [['To keep locks between multiple statements, they have to be wrapped in a transaction.  In your example:'], ['The update lock can be released before the insert is executed.  This would work reliably:']], [[' If (SELECT 1 FROM t3 with (updlock) where t3.a=-86)\n    INSERT INTO T3 SELECT -86,-86\n']], ['SQL Server locks - avoid insertion of duplicate entries'], 3, 0], [(1858559, 0), [['UPDATE:  My suggestion is the same even if you are running your script on a dedicated server! However, if you want to perform a full-text search of the word "literal" in BOOLEAN MODE like you have described, you can remove the  +  operator (because you are searching only one word) and construct the query as follow:'], ['So, to accomplish what you are trying to do, the fastest and easiest way is to follow the suggestion of Paul, using the  %  placeholder:']], [[" SELECT listOfColumsNames WHERE\nMATCH (colName) \nAGAINST ('literal*' IN BOOLEAN MODE);\n"]], ['Search literal within a word'], 2, 1], [(1858559, 1), [['So, to accomplish what you are trying to do, the fastest and easiest way is to follow the suggestion of Paul, using the  %  placeholder:'], ['-10000']], [[" SELECT listOfColumsNames \nWHERE colName LIKE '%literal%';\n"]], ['Search literal within a word'], 2, 1], [(1979522, 0), [['A simple JOIN would do the trick:'], ['In the orders/order_items example, orders is the master and order_items is the detail: each row in order_items belongs to, or is dependent on exactly one row in orders. The reverse is not true: one row in the  orders table can have zero or more related rows in the order_items table. The join condition ']], [[' SELECT     o.*\n,          i.*\nFROM       orders o\nINNER JOIN order_items i\nON         o.id = i.order_id\n']], ['How to fetch an object graph at once?'], 4, 1], [(1979522, 1), [['In the orders/order_items example, orders is the master and order_items is the detail: each row in order_items belongs to, or is dependent on exactly one row in orders. The reverse is not true: one row in the  orders table can have zero or more related rows in the order_items table. The join condition '], ['Now, suppose you have one master with two details, for example, customers as master and customer_orders as detail1 and customer_phone_numbers. Suppose you want to retrieve a particular customer along with all is orders and all its phone numbers. You might be tempted to write:']], [[' ON o.id = i.order_id \n']], ['How to fetch an object graph at once?'], 4, 0], [(1979522, 2), [['Now, suppose you have one master with two details, for example, customers as master and customer_orders as detail1 and customer_phone_numbers. Suppose you want to retrieve a particular customer along with all is orders and all its phone numbers. You might be tempted to write:'], ['This is valid SQL, and it will execute (asuming the tables and column names are in place)\nBut the problem is, is that it will give you a rubbish result. Assuming you have on customer with two orders (1,2) and two phone numbers (A, B) you get these records:']], [[' SELECT     c.*, o.*, p.*\nFROM       customers                c\nINNER JOIN customer_orders          o\nON         c.id                   = o.customer_id\nINNER JOIN customer_phone_numbers   p\nON         c.id                   = p.customer_id\n']], ['How to fetch an object graph at once?'], 4, 0], [(1979522, 3), [['This is valid SQL, and it will execute (asuming the tables and column names are in place)\nBut the problem is, is that it will give you a rubbish result. Assuming you have on customer with two orders (1,2) and two phone numbers (A, B) you get these records:'], ['This is rubbish, as it suggests there is some relationship between order 1 and phone numbers A and B and order 2 and phone numbers A and B. ']], [[' customer-data | order 1 | phone A\ncustomer-data | order 2 | phone A\ncustomer-data | order 1 | phone B\ncustomer-data | order 2 | phone B\n']], ['How to fetch an object graph at once?'], 4, 0], [(2044752, 1), [['Then, you can perform a query like:'], ['-10000']], [[' SELECT Animal FROM zoo_animals WHERE Zoo="Seattle Zoo"\n']], ['SQL mapping between multiple tables'], 2, 0], [(2045053, 0), [['-10000'], ['If the start and end dates come as strings, use  STR_TO_DATE  to convert from any given format:']], [[' SELECT timestamp\nFROM   tablename\nWHERE  timestamp >= userStartDate\n       AND timestamp < userEndDate + INTERVAL 1 DAY\n']], ['MYSQL - Retrieve Timestamps between dates'], 2, 1], [(2045053, 1), [['If the start and end dates come as strings, use  STR_TO_DATE  to convert from any given format:'], ['-10000']], [[" SELECT timestamp\nFROM   tablename\nWHERE  timestamp >= STR_TO_DATE('01/11/2010', '%m/%d/%Y')\n       AND timestamp < STR_TO_DATE('01/12/2010', '%m/%d/%Y') + INTERVAL 1 DAY\n"]], ['MYSQL - Retrieve Timestamps between dates'], 2, 1], [(2056938, 0), [['These queries both isolate the row with the highest  xfer_id  for each distinct  client_plt_id'], ['or, for mysql this may be better performing:']], [[' select xfer_id, client_plt_id, xfer_doc_no\nfrom   tab t1\nwhere  xfer_id = (\n       select max(xfer_id)\n       from   tab t2\n       where  t2.client_plt_id = t1.client_plt_id\n   )\n']], ['SQL isolate greatest values in a column'], 3, 1], [(2056938, 1), [['or, for mysql this may be better performing:'], ['If you simply want the one row with the highest  xfer_id , regardless of  client_plt_id , this is what you need:']], [[' select xfer_id, client_plt_id, xfer_doc_no\nfrom   tab t1\ninner join (\n       select max(xfer_id), client_plt_id\n       from   tab\n       group by client_plt_id\n       ) t2\non     t1.client_plt_id = t2.client_plt_id\nand    t1.xfer_id = t2.xfer_id\n']], ['SQL isolate greatest values in a column'], 3, 1], [(2056938, 2), [['If you simply want the one row with the highest  xfer_id , regardless of  client_plt_id , this is what you need:'], ['-10000']], [[' select xfer_id, client_plt_id, xfer_doc_no\nfrom   tab t1\nwhere  xfer_id = (select max(xfer_id) from tab)\n']], ['SQL isolate greatest values in a column'], 3, 1], [(2169720, 0), [['Use:'], ['-10000']], [[' WITH summary AS (\n    SELECT TRUNC(ls.started,\'HH\') AS dt,\n           ls.depot,\n           COUNT(*) AS num_depot\n      FROM logstats ls\n  GROUP BY TRUNC(ls.started,\'HH\'), ls.depot)\n  SELECT s.dt,\n         MAX(CASE WHEN s.depot = \'foo\' THEN s.num_depot ELSE 0 END) AS "count_of_foo",\n         MAX(CASE WHEN s.depot = \'bar\' THEN s.num_depot ELSE 0 END) AS "count_of_bar"\n    FROM summary s\nGROUP BY s.dt\nORDER BY s.dt\n']], ['Oracle: pivot (coalesce) some counts onto a single row?'], 3, 1], [(2169720, 1), [['-10000'], ['Pre Oracle9i would need the  CASE  statements changed to  DECODE , Oracle specific IF/ELSE logic.']], [['   SELECT s.dt,\n         MAX(CASE WHEN s.depot = \'foo\' THEN s.num_depot ELSE 0 END) AS "count_of_foo",\n         MAX(CASE WHEN s.depot = \'bar\' THEN s.num_depot ELSE 0 END) AS "count_of_bar"\n    FROM (SELECT TRUNC(ls.started,\'HH\') AS dt,\n                 ls.depot,\n                 COUNT(*) AS num_depot\n            FROM LOGSTATS ls\n        GROUP BY TRUNC(ls.started, \'HH\'), ls.depot) s\nGROUP BY s.dt\nORDER BY s.dt\n']], ['Oracle: pivot (coalesce) some counts onto a single row?'], 3, 1], [(2169720, 2), [['Pre Oracle9i would need the  CASE  statements changed to  DECODE , Oracle specific IF/ELSE logic.'], ['-10000']], [["   SELECT * \n    FROM (SELECT TRUNC(ls.started, 'HH') AS dt,\n                 ls.depot\n            FROM LOGSTATS ls\n        GROUP BY TRUNC(ls.started, 'HH'), ls.depot)\n   PIVOT (\n     COUNT(*) FOR depot\n   )\nORDER BY 1\n"]], ['Oracle: pivot (coalesce) some counts onto a single row?'], 3, 1], [(2183107, 1), [['You can make the queries to use the  SPATIAL  indexes:'], ['which will use the spatial index for searching and the relationship for fine filtering.']], [[" SELECT  *\nFROM    mytable m1\nJOIN    mytable m2\nON      MBRContains (m2.area, m1.area)\n        AND m2.parentId = m1.id\nWHERE   m1.name = 'London'\n"]], ['How to use foreign keys and a spatial index inside a MySQL table?'], 2, 0], [(2199315, 0), [['Try'], ["If this doesn't give sufficient precision, cast the inputs to  POWER  as floats:"]], [[' SELECT POWER(( 1.0 + 3.0 / 100.0 ), ( 1.0 / 365.0 ))\n']], ['How to get Microsoft SQL MATH POWER to show as decimal and not as INT (which it seems to do)?'], 2, 1], [(2199315, 1), [["If this doesn't give sufficient precision, cast the inputs to  POWER  as floats:"], ['-10000']], [[' SELECT POWER(( CAST(1.0 as float) + CAST(3.0 AS float) / 100.0 ), ( 1.0 / 365.0 ))\n']], ['How to get Microsoft SQL MATH POWER to show as decimal and not as INT (which it seems to do)?'], 2, 1], [(2289907, 0), [['Here you can use a trick that boolean expressions evaluate to either 0 or 1 in SQL:'], ['A more general (and more conventional) way is to use a CASE expression:']], [[' SELECT a2 + a8 + a7 * (a1 BETWEEN 0 AND 2) AS SUM\nFROM table_name\n']], ['Computing different sums depending on the value of one column'], 3, 1], [(2289907, 1), [['A more general (and more conventional) way is to use a CASE expression:'], ['You can also do something like this to include a CASE expression without repeating the common terms:']], [[' SELECT\n    CASE WHEN a1 BETWEEN 0 AND 2\n         THEN a2 + a7 + a8\n         ELSE a2 + a8\n    END AS SUM\nFROM table_name\n']], ['Computing different sums depending on the value of one column'], 3, 1], [(2289907, 2), [['You can also do something like this to include a CASE expression without repeating the common terms:'], ['-10000']], [[' SELECT\n    a2 + a8 + (CASE WHEN a1 BETWEEN 0 AND 2 THEN a7 ELSE 0 END) AS SUM\nFROM table_name\n']], ['Computing different sums depending on the value of one column'], 3, 1], [(2318539, 0), [['Wrap your unioned queries in another one as a derived table and you can use the top clause.'], ['-10000']], [[" SELECT TOP 100 * FROM (\n   SELECT * FROM table where field = 'entry'\n   UNION ALL\n   SELECT * FROM table where field = 'entry#'\n) sortedresults\n"]], ['Paging and custom-ordering a result'], 2, 0], [(2355791, 0), [['-10000'], ['-10000']], [['SQL 2000 Based solution DECLARE @Stack TABLE (\n  StackID INTEGER IDENTITY\n  , Category VARCHAR(20)\n  , RootID INTEGER\n  , ChildID INTEGER\n  , Visited BIT)\n\nINSERT INTO @Stack\nSELECT  [Category] = c.category_name\n        , [RootID] = c.category_id\n        , [ChildID] = c.category_id\n        , 0\nFROM    Categories c\n\nWHILE EXISTS (SELECT * FROM @Stack WHERE Visited = 0)\nBEGIN\n  DECLARE @StackID INTEGER\n  SELECT  @StackID = MAX(StackID) FROM    @Stack\n\n  INSERT INTO @Stack\n  SELECT  st.Category\n          , st.RootID\n          , c.category_id\n          , 0\n  FROM    @Stack st\n          INNER JOIN Categories c ON c.father_id = st.ChildID  \n  WHERE   Visited = 0\n\n  UPDATE  @Stack\n  SET     Visited = 1\n  WHERE   StackID <= @StackID\nEND\n\nSELECT  st.RootID\n        , st.Category\n        , COUNT(s.sales_id)\nFROM    @Stack st\n        INNER JOIN Sales s ON s.category_id = st.ChildID\nGROUP BY st.RootID, st.Category\nORDER BY st.RootID\n']], ['Help with generating a report from data in a parent-children model'], 2, 1], [(2355791, 1), [['-10000'], ['-10000']], [[' ;WITH QtyCTE AS (\n  SELECT  [Category] = c.category_name\n          , [RootID] = c.category_id\n          , [ChildID] = c.category_id\n  FROM    Categories c\n  UNION ALL \n  SELECT  cte.Category\n          , cte.RootID\n          , c.category_id\n  FROM    QtyCTE cte\n          INNER JOIN Categories c ON c.father_id = cte.ChildID\n)\nSELECT  cte.RootID\n        , cte.Category\n        , COUNT(s.sales_id)\nFROM    QtyCTE cte\n        INNER JOIN Sales s ON s.category_id = cte.ChildID\nGROUP BY cte.RootID, cte.Category\nORDER BY cte.RootID\n']], ['Help with generating a report from data in a parent-children model'], 2, 1], [(2386632, 0), [['For Ms Access you can try'], ['Example with table Data, which is the same...']], [[' SELECT  DISTINCT\n        *\nFROM Table1 tM\nWHERE NOT EXISTS(SELECT 1 FROM Table1 t WHERE tM.Source = t.Dest AND tM.Dest = t.Source AND tm.Source > t.Source)\n']], ['Fetch unique combinations of two field values'], 3, 1], [(2386632, 1), [['Example with table Data, which is the same...'], ['or ( Nice and Access Formatted... )']], [[' SELECT  DISTINCT\n        *\nFROM Data  tM\nWHERE NOT EXISTS(SELECT 1 FROM Data t WHERE tM.Source = t.Dest AND tM.Dest = t.Source AND tm.Source > t.Source)\n']], ['Fetch unique combinations of two field values'], 3, 1], [(2386632, 2), [['or ( Nice and Access Formatted... )'], ['-10000']], [[' SELECT DISTINCT *\nFROM Data AS tM\nWHERE (((Exists (SELECT 1 FROM Data t WHERE tM.Source = t.Dest AND tM.Dest = t.Source AND tm.Source > t.Source))=False));\n']], ['Fetch unique combinations of two field values'], 3, 1], [(2401396, 0), [['Given this data ...'], ['.. it is simply a matter of converting  the time elapsed since 01-JAN-1970  into seconds:']], [[" SQL> alter session set nls_date_format='dd-mon-yyyy hh24:mi:ss'\n  2  /\n\nSession altered.\n\nSQL> select * from t23\n  2  /\n\nMY_TIMESTAMP\n--------------------\n08-mar-2010 13:06:02\n08-mar-2010 13:06:08\n13-mar-1985 13:06:26\n\nSQL> \n"]], ['Oracle SQL - Column with unix timestamp, need dd-mm-yyyy timestamp'], 2, 0], [(2401396, 1), [['.. it is simply a matter of converting  the time elapsed since 01-JAN-1970  into seconds:'], ['-10000']], [[" SQL> select my_timestamp\n  2        , (my_timestamp - date '1970-01-01') * 86400 as unix_ts\n  3  from t23\n  4  /\n\nMY_TIMESTAMP            UNIX_TS\n-------------------- ----------\n08-mar-2010 13:06:02 1268053562\n08-mar-2010 13:06:08 1268053568\n13-mar-1985 13:06:26  479567186\n\nSQL>\n"]], ['Oracle SQL - Column with unix timestamp, need dd-mm-yyyy timestamp'], 2, 1], [(2406693, 0), [["I based that on this query (below) that I've tested on the Adventure Works sample cube from Miscrosoft:"], ["Based on your query I'm not sure why it is working without specifiying a hierarchy on your cube query (like [Time].[2010] instead of [Time].[Hierarchy Name].[2010]) but could you try this:"]], [[' SELECT {[Ship Date].[Fiscal Year].&[2002], [Ship Date].[Fiscal Year].&[2003]} ON 0,\n[Ship Date].[Month of Year].Members ON 1\nFROM [Adventure Works] WHERE [Measures].[Sales Amount]\n']], ['MDX Year on Year Sales by Months'], 2, 1], [(2411210, 0), [['-10000'], ['Output:']], [[' select p.*\nfrom (\n    select EMPID, DateWorked, Max(EffectiveDate) as MaxEffectiveDate\n    from Payroll\n    where EffectiveDate <= DateWorked\n    group by EMPID, DateWorked\n) pm\ninner join Payroll p on pm.EMPID = p.EMPID and pm.DateWorked = p.DateWorked and pm.MaxEffectiveDate = p.EffectiveDate\n']], ['Finding a sql query to get the latest associated date for each grouping'], 2, 1], [(2411210, 1), [['Output:'], ['-10000']], [[' EMPID       DateWorked              Hours       WageRate                                EffectiveDate\n----------- ----------------------- ----------- --------------------------------------- -----------------------\n1           2010-01-01 00:00:00.000 10          7.25                                    2009-06-10 00:00:00.000\n']], ['Finding a sql query to get the latest associated date for each grouping'], 2, 0], [(2461579, 0), [['Use temp tables & have the records dumped into it (from the dynamic query) & use the temp table to join with the static query that you have.'], ['And then']], [[" set @query = 'CREATE table #myTempTable AS\nselect\n    HumanResources.Employee.EmployeeID\n    ,HumanResources.Employee.LoginID\n    ,HumanResources.Employee.Title\n    ,HumanResources.EmployeeAddress.AddressID\nfrom\n    HumanResources.Employee\n    inner join HumanResources.EmployeeAddress\n    on HumanResources.Employee.EmployeeID = HumanResources.EmployeeAddress.EmployeeID\n;';\n\nEXEC (@query);\n"]], ['How to join dynamic sql statement in variable with normal statement'], 2, 0], [(2461579, 1), [['And then'], ['-10000']], [[' select\n    Employees.*\n    ,Addresses.City\nfrom\n    #myTempTable as Employees\n    inner join\n    (\n        select\n            Person.Address.AddressID\n            ,Person.Address.City\n        from\n            Person.Address\n    ) as Addresses\n    on Employees.AddressID = Addresses.AddressID\n']], ['How to join dynamic sql statement in variable with normal statement'], 2, 0], [(2466091, 0), [['For days use DATEDIFF and the modulo operation:'], ['For a period of 10 years, calculate the difference in the year modulo the period, and ensure that the month and day are the same:']], [[" SELECT * FROM dates\nWHERE `date` BETWEEN '1987-10-20' AND '1988-1-1'\nAND DATEDIFF(`date`, '1987-10-20') % 10 = 0\n"]], ['SQL to return dates that fall in period and range'], 2, 1], [(2466091, 1), [['For a period of 10 years, calculate the difference in the year modulo the period, and ensure that the month and day are the same:'], ["A period measured in months is not well-defined because months have different lengths. What is one month later than January 30th? You can get it working for some special cases such as 'first in the month'."]], [[" SELECT * FROM dates\nWHERE `date` BETWEEN '1980-10-20' AND '2000-10-20'\nAND MONTH(date) = 10 AND DAY(date) = 20 AND (YEAR(date) - 1980) % 10 = 0\n"]], ['SQL to return dates that fall in period and range'], 2, 1], [(2473843, 0), [['Use:'], ['Alternately, you can use  NOT EXISTS :']], [['    SELECT t.name\n     FROM TOOLS t\nLEFT JOIN INSTALLS i ON i.tool_id = t.id\n                    AND i.user_id = 99\n    WHERE i.id IS NULL\n']], ['MySQL: Select remaining rows'], 3, 1], [(2473843, 1), [['Alternately, you can use  NOT EXISTS :'], ['...or  NOT IN :']], [[' SELECT t.name\n  FROM TOOLS t\n WHERE NOT EXISTS(SELECT NULL \n                    FROM INSTALLS i\n                   WHERE i.tool_id = t.id\n                     AND i.user_id = 99)\n']], ['MySQL: Select remaining rows'], 3, 1], [(2473843, 2), [['...or  NOT IN :'], ['Of the three options, the  LEFT JOIN/IS NULL  is the most efficient on MySQL.   You can read more about it in this article .']], [[' SELECT t.name\n  FROM TOOLS t\n WHERE t.id NOT IN (SELECT i.tool_id\n                      FROM INSTALLS i\n                     WHERE i.user_id = 99)\n']], ['MySQL: Select remaining rows'], 3, 1], [(2507933, 0), [['I have found a way out of it.\nWe can use concatenation here,'], ['I did']], [[' select name,id,location from employee;\n']], ['Formatting the output of an SQL query'], 2, 0], [(2507933, 1), [['I did'], ['We get the output in a CSV format. It has just concatenated the output with commas (,).']], [[" select name||','||id||','||location from employee;\n"]], ['Formatting the output of an SQL query'], 2, 1], [(2524600, 0), [['You model with the test code becomes:'], ['which produces following output:']], [[' from sqlalchemy import create_engine, Column, Integer, DateTime, String, ForeignKey, Table\nfrom sqlalchemy.orm import relation, scoped_session, sessionmaker, eagerload\nfrom sqlalchemy.ext.declarative import declarative_base\n\nengine = create_engine(\'sqlite:///:memory:\', echo=True)\nsession = scoped_session(sessionmaker(bind=engine, autoflush=True))\nBase = declarative_base()\n\nt_subscription = Table(\'subscription\', Base.metadata,\n    Column(\'userId\', Integer, ForeignKey(\'user.id\')),\n    Column(\'channelId\', Integer, ForeignKey(\'channel.id\')),\n)\n\nclass Channel(Base):\n    __tablename__ = \'channel\'\n\n    id = Column(Integer, primary_key = True)\n    title = Column(String)\n    description = Column(String)\n    link = Column(String)\n    pubDate = Column(DateTime)\n\nclass User(Base):\n    __tablename__ = \'user\'\n\n    id = Column(Integer, primary_key = True)\n    username = Column(String)\n    password = Column(String)\n    sessionId = Column(String)\n\n    channels = relation("Channel", secondary=t_subscription)\n\n# NOTE: no need for this class\n# class Subscription(Base):\n    # ...\n\nBase.metadata.create_all(engine)\n\n\n# ######################\n# Add test data\nc1 = Channel()\nc1.title = \'channel-1\'\nc2 = Channel()\nc2.title = \'channel-2\'\nc3 = Channel()\nc3.title = \'channel-3\'\nc4 = Channel()\nc4.title = \'channel-4\'\nsession.add(c1)\nsession.add(c2)\nsession.add(c3)\nsession.add(c4)\nu1 = User()\nu1.username =\'user1\'\nsession.add(u1)\nu1.channels.append(c1)\nu1.channels.append(c3)\nu2 = User()\nu2.username =\'user2\'\nsession.add(u2)\nu2.channels.append(c2)\nsession.commit()\n\n\n# ######################\n# clean the session and test the code\nsession.expunge_all()\n\n# retrieve all (I assume those are not that many)\nchannels = session.query(Channel).all()\n\n# get subscription info for the user\n#q = session.query(User)\n# use eagerload(...) so that all \'subscription\' table data is loaded with the user itself, and not as a separate query\nq = session.query(User).options(eagerload(User.channels))\nfor u in q.all():\n    for c in channels:\n        print (c.id, c.title, (c in u.channels))\n']], ['How do I join three tables with SQLalchemy and keeping all of the columns in one of the tables?'], 3, 1], [(2524600, 1), [['which produces following output:'], ['But if you want to keep you model and just create an SA query that would give you the columns as you ask, following query should do the job:']], [[" (1, u'channel-1', True)\n(2, u'channel-2', False)\n(3, u'channel-3', True)\n(4, u'channel-4', False)\n(1, u'channel-1', False)\n(2, u'channel-2', True)\n(3, u'channel-3', False)\n(4, u'channel-4', False)\n"]], ['How do I join three tables with SQLalchemy and keeping all of the columns in one of the tables?'], 3, 0], [(2524600, 2), [['But if you want to keep you model and just create an SA query that would give you the columns as you ask, following query should do the job:'], ['The output is absolutely the same as in the option-1 above.']], [[' from sqlalchemy import and_\nfrom sqlalchemy.sql.expression import case\n#...\nq = (session.query(#User.username, \n                   Channel.id, Channel.title, \n                   case([(Subscription.channelId == None, False)], else_=True)\n                  ).outerjoin((Subscription, \n                                and_(Subscription.userId==User.id, \n                                     Subscription.channelId==Channel.id))\n                             )\n    )\n# optionally filter by user\nq = q.filter(User.id == uid()) # assuming uid() is the function that provides user.id\nq = q.filter(User.sessionId == id()) # assuming uid() is the function that provides user.sessionId\nres = q.all()\nfor r in res:\n    print r\n']], ['How do I join three tables with SQLalchemy and keeping all of the columns in one of the tables?'], 3, 1], [(2559110, 0), [["Here's an example from postgres, I hope the dialects are comparable in regards to recursive "], ["UPDATE:\nSorry, don't have ORA here, but according to this  article"]], [[' WITH RECURSIVE t(n) AS (\n    VALUES (1)\n  UNION ALL\n    SELECT n+1 FROM t WHERE n < 20\n)\nSELECT n FROM t;\n']], ['Is it possible to write a query which returns a date for every day between two specified days?'], 4, 1], [(2559110, 2), [['gives'], ['And indeed there are several  options .']], [[" SYS_CONNECT_BY_PATH(DUMMY,'/')\n--------------------------------\n/X\n/X/X\n/X/X/X\n"]], ['Is it possible to write a query which returns a date for every day between two specified days?'], 4, 0], [(2559110, 3), [['And indeed there are several  options .'], ["orafaq states that: 'It should be noted that in later versions of oracle, at least as far back as 10gR1, operations against dual are optimized such that they require no logical or physical I/O operations. This makes them quite fast.', so I would say this is not completely esoteric."]], [[" SELECT (CAST('01-JAN-2010' AS DATE) + (ROWNUM - 1)) n\nFROM   ( SELECT 1 just_a_column\n         FROM   dual\n         CONNECT BY LEVEL <= 20\n       )\n"]], ['Is it possible to write a query which returns a date for every day between two specified days?'], 4, 1], [(2563918, 0), [['If performance is an issue, you could use a MySQL variable:'], ['Alternatively, you could remove the  cumulative_sum  column and calculate it on each query:']], [[' set @csum := 0;\nupdate YourTable\nset cumulative_sum = (@csum := @csum + count)\norder by id;\n']], ['Create a Cumulative Sum Column in MySQL'], 2, 1], [(2563918, 1), [['Alternatively, you could remove the  cumulative_sum  column and calculate it on each query:'], ['This calculates the running sum in a running way :)']], [[' set @csum := 0;\nselect id, count, (@csum := @csum + count) as cumulative_sum\nfrom YourTable\norder by id;\n']], ['Create a Cumulative Sum Column in MySQL'], 2, 1], [(2588304, 0), [['Lots of same answers here. For some reason, though, all of them are joining the  Section  table which is (likely) not necessary.'], ['-10000']], [[' select\n  p.*\n\nfrom\n  Product    p,\n  Category   c\n\nwhere\n  p.category_id = c.id and\n  c.section_id = 123\n;\n']], ['SQL query multi table selection'], 4, 1], [(2588304, 1), [['-10000'], ['-10000']], [[' select\n  p.*\n\nfrom Product    p\n\njoin Category   c\n  on c.id = p.category_id\n and c.section_id = 123\n;\n']], ['SQL query multi table selection'], 4, 1], [(2588304, 2), [['-10000'], ["If doing this, you'll want to make sure  Section.name  is indexed"]], [[" select\n  p.*\n\nfrom Product    p\n\njoin Category   c\n  on c.id = p.category_id\n\njoin Section    s\n  on s.id = c.section_id\n and s.name = 'Books'\n;\n"]], ['SQL query multi table selection'], 4, 1], [(2588304, 3), [["If doing this, you'll want to make sure  Section.name  is indexed"], ['-10000']], [[' alter table Product add index name;\n']], ['SQL query multi table selection'], 4, 0], [(2640048, 0), [['For SQL Server, the  easiest  way would definitely be:'], ['If you want to use purely only INT\'s, you\'d have to construct something like this (at least you could do this in SQL Server - I\'m not familiar enough with Access to know if that\'ll work in the Access SQL "dialect"):']], [[' SELECT CAST(LEFT(CAST(YourInt AS VARCHAR(100)), 3) AS INT)\n']], ['SQL: how to get the left 3 numbers from an int'], 2, 1], [(2640048, 1), [['If you want to use purely only INT\'s, you\'d have to construct something like this (at least you could do this in SQL Server - I\'m not familiar enough with Access to know if that\'ll work in the Access SQL "dialect"):'], ["But that's always an approximation - what if you have a really really really large number..... it might just fall through the cracks.... "]], [[" DECLARE @MyInt INT = 1234567\n\nSELECT\n    CASE \n        WHEN @MyInt < 1000 THEN @MyInt\n        WHEN @MyInt > 10000000 THEN @MyInt / 100000\n        WHEN @MyInt > 1000000 THEN @MyInt / 10000\n        WHEN @MyInt > 100000 THEN @MyInt / 1000\n        WHEN @MyInt > 10000 THEN @MyInt / 100\n        WHEN @MyInt > 1000 THEN @MyInt / 10\n    END AS 'NewInt'\n"]], ['SQL: how to get the left 3 numbers from an int'], 2, 1], [(2651249, 0), [['Then you can left join on this and convert to dates based on number of days between min and max.'], ['will give you the required number of rows, which then you can use to']], [['  select @min_join_on := (select min(join_on) from user);\n select @no_rows := (select datediff(max(join_on), @min_join_on) from user)+1;\n']], ['wanted to get all dates in mysql result'], 4, 0], [(2651249, 1), [['will give you the required number of rows, which then you can use to'], ['So, if you can work with such fixed date ranges you can even substitute the table with the query, such as this']], [['  select adddate(@min_join_on, interval row day) from rows where row <= @no_rows;\n']], ['wanted to get all dates in mysql result'], 4, 0], [(2651249, 2), [['So, if you can work with such fixed date ranges you can even substitute the table with the query, such as this'], ['So at the end it is doable in a single query.']], [[' SELECT @row := @row + 1 as row FROM (select 0 union all select 1 union all select 3 union all select 4 union all select 5 union all select 6 union all select 6 union all select 7 union all select 8 union all select 9) t, (select 0 union all select 1 union all select 3 union all select 4 union all select 5 union all select 6 union all select 6 union all select 7 union all select 8 union all select 9) t2, (select 0 union all select 1 union all select 3 union all select 4 union all select 5 union all select 6 union all select 6 union all select 7 union all select 8 union all select 9) t3, (select 0 union all select 1 union all select 3 union all select 4 union all select 5 union all select 6 union all select 6 union all select 7 union all select 8 union all select 9) t4, (SELECT @row:=0) r\n']], ['wanted to get all dates in mysql result'], 4, 0], [(2651249, 3), [['So at the end it is doable in a single query.'], ['-10000']], [[" create table user(id INT NOT NULL AUTO_INCREMENT, name varchar(100), join_on date, PRIMARY KEY(id));\n\nmysql> select * from user;\n+----+-------+------------+\n| id | name  | join_on    |\n+----+-------+------------+\n|  1 | user1 | 2010-04-02 | \n|  2 | user2 | 2010-04-04 | \n|  3 | user3 | 2010-04-08 | \n|  4 | user4 | 2010-04-08 | \n+----+-------+------------+\n4 rows in set (0.00 sec)\n\ninsert into user values (null, 'user1', '2010-04-02'), (null, 'user2', '2010-04-04'), (null, 'user3', '2010-04-08'), (null, 'user4', '2010-04-08')\n\n\nSELECT date, count(id)\nFROM (\nSELECT adddate((select min(join_on) from user), row-1) as date \nFROM ( \nSELECT @row := @row + 1 as row FROM (select 0 union all select 1 union all select 3 union all select 4 union all select 5 union all select 6 union all select 6 union all select 7 union all select 8 union all select 9) t, (select 0 union all select 1 union all select 3 union all select 4 union all select 5 union all select 6 union all select 6 union all select 7 union all select 8 union all select 9) t2, (SELECT @row:=0) r ) n  \nWHERE n.row <= ( select datediff(max(join_on), min(join_on)) from user) + 1\n) dr LEFT JOIN user u ON dr.date = u.join_on\nGROUP BY dr.date\n\n+------------+-----------+\n| date       | count(id) |\n+------------+-----------+\n| 2010-04-02 |         1 | \n| 2010-04-03 |         0 | \n| 2010-04-04 |         1 | \n| 2010-04-05 |         0 | \n| 2010-04-06 |         0 | \n| 2010-04-07 |         0 | \n| 2010-04-08 |         2 | \n+------------+-----------+\n7 rows in set (0.00 sec)\n"]], ['wanted to get all dates in mysql result'], 4, 1], [(2695116, 0), [['-10000'], ['Some example tables:']], [[' /** XXX CODING HORROR... */\n']], ['Update multiple table column values using single query'], 4, 0], [(2695116, 1), [['Some example tables:'], ['... then create an updateable view']], [[" create table party (\n    party_id integer,\n    employee_id integer\n    );\n\ncreate table party_name (\n    party_id integer,\n    first_name varchar2(120 char),\n    last_name varchar2(120 char)\n    );\n\ninsert into party values (1,1000);   \ninsert into party values (2,2000);\ninsert into party values (3,3000);\n\ninsert into party_name values (1,'Kipper','Family');\ninsert into party_name values (2,'Biff','Family');\ninsert into party_name values (3,'Chip','Family');\n\ncommit;\n\nselect * from party_v;\n\nPARTY_ID    EMPLOYEE_ID    FIRST_NAME    LAST_NAME\n1            1000           Kipper        Family\n2            2000           Biff          Family\n3            3000           Chip          Family\n"]], ['Update multiple table column values using single query'], 4, 0], [(2695116, 2), [['... then create an updateable view'], ['You can now update the view directly...']], [[' create or replace view party_v\nas\nselect\n    p.party_id,\n    p.employee_id,\n    n.first_name,\n    n.last_name\nfrom\n    party p left join party_name n on p.party_id = n.party_id;\n\ncreate or replace trigger trg_party_update\ninstead of update on party_v \nfor each row\ndeclare\nbegin\n--\n    update party\n    set\n        party_id = :new.party_id,\n        employee_id = :new.employee_id\n    where\n        party_id = :old.party_id;\n--\n    update party_name\n    set\n        party_id = :new.party_id,\n        first_name = :new.first_name,\n        last_name = :new.last_name\n    where\n        party_id = :old.party_id;\n--\nend;\n/\n']], ['Update multiple table column values using single query'], 4, 0], [(2695116, 3), [['You can now update the view directly...'], ['-10000']], [[" update party_v\nset\n    employee_id = 42,\n    last_name = 'Oxford'\nwhere\n    party_id = 1;\n\nselect * from party_v;\n\nPARTY_ID    EMPLOYEE_ID    FIRST_NAME    LAST_NAME\n1            42             Kipper        Oxford\n2            2000           Biff          Family\n3            3000           Chip          Family\n"]], ['Update multiple table column values using single query'], 4, 0], [(2746331, 0), [['This:'], ['or this:']], [[' WITH    q AS\n        (\n        SELECT  *, ROW_NUMBER() OVER (PARTITION BY field2 ORDER BY field3 DESC) AS rn\n        FROM    table1\n        )\nSELECT  *\nFROM    q\nWHERE   rn = 1\n']], ['How to retrieve the rows (with maximum value in a field) having a another common field?'], 2, 1], [(2746331, 1), [['or this:'], ['Depending on the  field2  cardinality, the first or the second query can be more efficient.']], [[' SELECT  q.*\nFROM    (\n        SELECT  DISTINCT field2\n        FROM    table1\n        ) qo\nCROSS APPLY\n        (\n        SELECT  TOP 1 *\n        FROM    table1 t\n        WHERE   t.field2 = qo.field2\n        ORDER BY\n                t.field3 DESC\n        ) q\n']], ['How to retrieve the rows (with maximum value in a field) having a another common field?'], 2, 1], [(2769007, 0), [['You could create a user-defined function for this:'], ['and then use that to define your computed column:']], [[' CREATE FUNCTION dbo.GetValue(INT @ncode, INT @recid)\nRETURNS INT\nAS \n   SELECT @recid * nvalue \n   FROM c_const \n   WHERE code = @ncode\n']], ["formula for computed column based on different table's column"], 2, 0], [(2769007, 1), [['and then use that to define your computed column:'], ['-10000']], [[' ALTER TABLE dbo.YourTable\n   ADD NewColumnName AS dbo.GetValue(ncodeValue, recIdValue)\n']], ["formula for computed column based on different table's column"], 2, 0], [(2781315, 0), [['Dates are not strings, but either of the following will result in a date:'], ['(see the  documentation for CDate )']], [[" DATE [Table] SET `Birthdate` = CDate('1993-08-02 00:00:00.0') WHERE `ID` = 000\n"]], ['SQL Statement to update the date'], 2, 1], [(2781315, 1), [['(see the  documentation for CDate )'], ['-10000']], [[' DATE [Table] SET `Birthdate` = #08/02/1993# WHERE `ID` = 000\n']], ['SQL Statement to update the date'], 2, 1], [(2781419, 0), [['try this:'], ['For example:']], [[' CONVERT(DATETIME, CONVERT(NVARCHAR, YYYYMMDD))\n']], ['Optimal way to convert to date'], 3, 1], [(2781419, 1), [['For example:'], ['Results in:']], [[' SELECT CONVERT(DATETIME, CONVERT(NVARCHAR, 20100401))\n']], ['Optimal way to convert to date'], 3, 1], [(2781419, 2), [['Results in:'], ['-10000']], [[' 2010-04-01 00:00:00.000\n']], ['Optimal way to convert to date'], 3, 0], [(2788575, 0), [['-10000'], ['-10000']], [[' ALTER TABLE [wm].[TABLE_NAME]  WITH NOCHECK ADD  CONSTRAINT [FK_TABLE_NAME_PARENT_TABLE_NAME] FOREIGN KEY([FOREIGN_KEY])\nREFERENCES [wm].[PARENT_TABLE_NAME] ([PRIVATE_KEY])\nON DELETE CASCADE\nGO\n']], ['tsql script to add delete cascade to existing tables'], 2, 1], [(2788575, 1), [['-10000'], ['-10000']], [[' ALTER TABLE [wm].[Thumbs]  WITH NOCHECK ADD  CONSTRAINT [FK_Thumbs_Documents] FOREIGN KEY([DocID])\nREFERENCES [wm].[Documents] ([ID])\nON DELETE CASCADE\nGO\n']], ['tsql script to add delete cascade to existing tables'], 2, 1], [(2792388, 0), [['You could also temporarily remove the  IDENTITY  and try the folowing:'], ["Or, if you don't care about the order of the records, this"]], [[' ;WITH TBL AS\n(\n  SELECT *, ROW_NUMBER(ORDER BY ID) AS RN\n  FROM CURRENT_TABLE\n)\nUPDATE TBL\nSET ID = RN\n']], ['SQL Reset Identity ID in already populated table'], 2, 1], [(2792388, 1), [["Or, if you don't care about the order of the records, this"], ['-10000']], [[' DECLARE INT @id;\nSET @id = 0;\n\nUPDATE CURRENT_TABLE\nSET @id = ID = @id + 1;\n']], ['SQL Reset Identity ID in already populated table'], 2, 1], [(2884295, 0), [['Naively:'], ['or:']], [[" SELECT *\nFROM Entries\nWHERE Language = 'Swedish' \n\nUNION ALL\n\nSELECT *\nFROM Entries\nWHERE Language = 'English' \n    AND NOT EXISTS (\n        SELECT *\n        FROM Entries\n        WHERE Language = 'Swedish' \n    )\n"]], ['Help with constructing a conditional SQL statement'], 2, 1], [(2884295, 1), [['or:'], ['-10000']], [[" SELECT *\nFROM Entries\nWHERE Language = 'Swedish' \n    OR (Language = 'English' \n        AND NOT EXISTS (\n            SELECT *\n            FROM Entries\n            WHERE Language = 'Swedish' \n        )\n    )\n"]], ['Help with constructing a conditional SQL statement'], 2, 1], [(2900217, 0), [['Assuming birthday is stored as a DateTime'], ['This could also be written without the derived table like so:']], [[' Select Count(*)\nFrom    (\n        Select Id, Floor(DateDiff(d, BirthDate, GetDate()) / 365.25) As Age\n        From People\n        ) As EmpAges\nWhere EmpAges Between 20 And 40\n']], ['Getting age in years in a SQL query'], 3, 1], [(2900217, 1), [['This could also be written without the derived table like so:'], ['Yet another way would be to use DateAdd. As OMG Ponies and ck mentioned, this one would be the most efficient of the bunch as it would enable the use of an index on dateOfBirth if it existed.']], [[' Select Count(*)\nFrom People\nWhere Floor(DateDiff(d, BirthDate, GetDate()) / 365.25)  Between 20 And 40\n']], ['Getting age in years in a SQL query'], 3, 1], [(2900217, 2), [['Yet another way would be to use DateAdd. As OMG Ponies and ck mentioned, this one would be the most efficient of the bunch as it would enable the use of an index on dateOfBirth if it existed.'], ['-10000']], [[' Select Count(*)\nFrom People\nWhere DateOfBirth Between DateAdd(yy, -40, GetDate()) And DateAdd(yy, -20, GetDate())\n']], ['Getting age in years in a SQL query'], 3, 1], [(2913338, 3), [['Based on your edit, the actual query would be:'], ["(or  union  if you don't want duplicates where  a.name==b.name=='zoot'  and  a.somefield1==b.somefield1 )."]], [[" select name, somefield1 from tablea where name = 'zoot'\nunion all\nselect name, somefield1 from tableb where name = 'zoot'\n"]], ['In mySQL, Is it possible to SELECT from two tables and merge the columns?'], 4, 1], [(2919168, 1), [['The problem arises where your string contains literals, with the dreaded quotes ...'], ["So we have to escape the apostrophes, all of them, including the ones you haven't included in your posted string:"]], [[" SQL> select fmt_fname('TEST||to_char(sysdate, 'DDD')') from dual\n  2  /\nselect fmt_fname('TEST||to_char(sysdate, 'DDD')') from dual\n                                          *\nERROR at line 1:\nORA-00907: missing right parenthesis\n\n\nSQL>\n"]], ['Invoking a function call in a string in an Oracle Procedure'], 4, 0], [(2919168, 3), [["Just for the sake of fairness I feel I should point out that Tony's solution works just as well:"], ['In fact, by avoiding the SELECT on DUAL it is probably better.']], [[" SQL> create or replace function fmt_fname (p_dyn_string in varchar2)\n  2      return varchar2\n  3  is\n  4      return_value varchar2(128);\n  5  begin\n  6      execute immediate 'begin :result := ' || p_dyn_string || '; end;'\n  7          using out return_value;\n  8      return  return_value;\n  9  end;\n 10  /\n\nFunction created.\n\nSQL> select fmt_fname('''TEST''||to_char(sysdate, ''DDD'')') from dual\n  2  /\n\nFMT_FNAME('''TEST''||TO_CHAR(SYSDATE,''DDD'')')\n--------------------------------------------------------------------------------\nTEST147\n\nSQL>\n"]], ['Invoking a function call in a string in an Oracle Procedure'], 4, 1], [(2922856, 1), [['Note Null is YES, and  id  is not a primary key, nor does it auto_increment.'], ['Here is the alter command:']], [[' mysql> DESCRIBE test2;\n+-------+---------+------+-----+---------+-------+\n| Field | Type    | Null | Key | Default | Extra |\n+-------+---------+------+-----+---------+-------+\n| id    | int(11) | YES  |     | NULL    |       | \n+-------+---------+------+-----+---------+-------+\n1 row in set (0.00 sec)\n']], ['mysql: how to change column to be PK Auto_Increment'], 4, 0], [(2922856, 2), [['Here is the alter command:'], ['Now Null is NO, and  id  is a primary key with auto_increment.']], [[' mysql> ALTER TABLE test2 MODIFY COLUMN id INT NOT NULL auto_increment, ADD primary key (id);\n']], ['mysql: how to change column to be PK Auto_Increment'], 4, 1], [(2922856, 3), [['Now Null is NO, and  id  is a primary key with auto_increment.'], ['Primary keys are always unique.']], [[' mysql> describe test2;\ndescribe test2;\n+-------+---------+------+-----+---------+----------------+\n| Field | Type    | Null | Key | Default | Extra          |\n+-------+---------+------+-----+---------+----------------+\n| id    | int(11) | NO   | PRI | NULL    | auto_increment | \n+-------+---------+------+-----+---------+----------------+\n1 row in set (0.00 sec)\n']], ['mysql: how to change column to be PK Auto_Increment'], 4, 0], [(2930768, 0), [['Changing it to use the SS.SSS format works correctly:'], ["You haven't described what kind of data is contained in your  CREATED_AT  column. If it indeed a datetime, it will compare correctly against a string:"]], [[" sqlite> CREATE TABLE Foo (created_at TIMESTAMP);\nsqlite> INSERT INTO Foo VALUES('2010-05-28T15:36:56+0200');\nsqlite> SELECT * FROM Foo WHERE foo.created_at < '2010-05-28 16:20:55';\nsqlite> SELECT * FROM Foo WHERE DATETIME(foo.created_at) < '2010-05-28 16:20:55';\nsqlite> INSERT INTO Foo VALUES('2010-05-28T15:36:56.200');\nsqlite> SELECT * FROM Foo WHERE DATETIME(foo.created_at) < '2010-05-28 16:20:55';\n2010-05-28T15:36:56.200\n"]], ['How to compare sqlite TIMESTAMP values'], 3, 1], [(2945765, 1), [["UPDATE:  ah, okay, so you want to call this from .NET ! Well, in that case, just call it using the  .ExecuteReader()  method on your  SqlCommand  object - the stuff you're outputting using  OUTPUT...  will be returned to the .NET caller as a result set - you can loop through that:"], ['You should get back the resulting "$action" from that data reader.']], [[' using(SqlCommand cmd = new SqlCommand(mergeStmt, connection))\n{\n   connection.Open();\n\n   using(SqlDataReader rdr = cmd.ExecuteReader())\n   {\n      while(rdr.Read())\n      {\n         var outputAction = rdr.GetValue(0);\n      }\n\n      rdr.Close();\n   }\n   connection.Close();\n}\n']], ['Determining SQL MERGE statement result'], 2, 1], [(2978700, 0), [['drop table "AccountBalances"'], ['Resulted in:']], [[' CREATE TEMP TABLE "AccountBalances" (\n  "Id" INTEGER PRIMARY KEY, \n  "Balance" REAL);\n\nINSERT INTO "AccountBalances" values (1,0)\nINSERT INTO "AccountBalances" values (2,0);\nINSERT INTO "AccountBalances" values (3,0);\nINSERT INTO "AccountBalances" values (4,0);\nINSERT INTO "AccountBalances" values (5,0);\nINSERT INTO "AccountBalances" values (6,0);\n\nCREATE TRIGGER UpdateAccountBalance AFTER UPDATE ON AccountBalances\nBEGIN\n UPDATE AccountBalances \n    SET Balance = 1 + new.Balance \n  WHERE Id = new.Id + 1;\nEND;\n\nPRAGMA recursive_triggers = \'on\';\n\nUPDATE AccountBalances \n   SET Balance = 1 \n WHERE Id = 1\n\nselect * from "AccountBalances";\n']], ['Calculate running total in SQLite table using triggers'], 2, 1], [(2978700, 1), [['Resulted in:'], ['-10000']], [[' Id  Balance\n1   1\n2   2\n3   3\n4   4\n5   5\n6   6\n']], ['Calculate running total in SQLite table using triggers'], 2, 0], [(3005323, 0), [['Reading the comments you say that you are willing to add a auto increment or date field to know the proper position of each row. Once you add this I would recommend adding one more row to the In table called processed which is automatically set to false when the row is added to the table. Any rows that have been copied to OUT already have their processed filed set to true.'], ['Then to find the next item to move to OUT you can do']], [[' +----+\n| In |\n+-----------+-----------+-------+-----------+\n| AUtoId    | Supply_ID | Price | Processed |\n+-----------+-----------+-------+-----------+\n|     1     |     1     |  75   |     1     |\n|     2     |     1     |  75   |     1     |\n|     3     |     1     |  75   |     0     |\n|     4     |     2     |  80   |     0     |\n|     5     |     2     |  80   |     0     |\n+-----------+-----------+-------+---------- +\n']], ['How can I manage a FIFO-queue in an database with SQL?'], 2, 0], [(3005323, 1), [['Then to find the next item to move to OUT you can do'], ['Once the row is moved to OUT then you just UPDATE the processed field of that row to true.']], [[' SELECT TOP 1 Supply_ID, Price \nFROM In WHERE Processed = 0\nORDER BY [Your Auto Increment Field or Date]\n']], ['How can I manage a FIFO-queue in an database with SQL?'], 2, 0], [(3035105, 0), [['-10000'], ['Using self join']], [[" select e1.* from Employee e1, Employee e2  where \n           e2.name = 'a' and\n           e1.salary > e2.salary\n"]], ['Self join to a table'], 2, 1], [(3035105, 1), [['Using self join'], ['-10000']], [["  select e1.* from Employee e1 join Employee e2  on \n           e2.name = 'a' and\n           e1.salary > e2.salary\n"]], ['Self join to a table'], 2, 1], [(3053125, 0), [['Indentify the amount of free space in the database overall:'], ['Identify the amount of free log space: ']], [[' EXEC sp_spaceused\n']], ['Shrinking database'], 3, 0], [(3053125, 1), [['Identify the amount of free log space: '], ['Identify the amount of free space per data/log file:']], [[" DBCC SQLPERF('logspace')\n"]], ['Shrinking database'], 3, 0], [(3053125, 2), [['Identify the amount of free space per data/log file:'], ['-10000']], [[" SELECT \n    name AS 'File Name' , \n    physical_name AS 'Physical Name', \n    size/128 AS 'Total Size in MB',\n    size/128.0 - CAST(FILEPROPERTY(name, 'SpaceUsed') AS int)/128.0 AS 'Available Space In MB',\n    *\nFROM sys.database_files;\n"]], ['Shrinking database'], 3, 0], [(3084672, 0), [['You can;'], ['You can give the count column a name by aliasing it:']], [[' SELECT COUNT(DISTINCT userID) \nFROM Tbl\n']], ['TSQL Howto get count of unique users?'], 2, 1], [(3084672, 1), [['You can give the count column a name by aliasing it:'], ['-10000']], [[' SELECT COUNT(DISTINCT userID)  NumberOfDistinctUsers\nFROM Tbl\n']], ['TSQL Howto get count of unique users?'], 2, 1], [(3167775, 0), [['-10000'], ['Update: Added example of only using the highest SAT score']], [[" select \n    C.ACCOUNTNO,\n    C.CONTACT,\n    C.KEY1,\n    C.KEY4,  \n    HichschoolCS.State as HighSchool,  \n    TestSatCS.state as Test\n\n\nfrom \n    contact1 C\n    left join CONTSUPP HichschoolCS on C.accountno=HichschoolCS.accountno \n        and HichschoolCS.contact = 'High School'\n    left join CONTSUPP TestSatCS on C.accountno=TestSatCS.accountno \n        and TestSatCS.contact = 'Test/SAT'\nwhere \n    C.KEY1!='00PRSP' \n    AND (C.U_KEY2='2009 FALL' \n    OR C.U_KEY2='2010 SPRING' \n    OR C.U_KEY2='2010 J TERM' \n    OR C.U_KEY2='2010 SUMMER')\n"]], ['SQL - Grab Detail Rows as Columns in Join'], 2, 1], [(3167775, 1), [['Update: Added example of only using the highest SAT score'], ['-10000']], [[" select \n    C.ACCOUNTNO,\n    C.CONTACT,\n    C.KEY1,\n    C.KEY4,  \n    HichschoolCS.State as HighSchool,  \n    TestSatCS.state as Test\n\n\nfrom \n    contact1 C\n    left join CONTSUPP HichschoolCS on C.accountno=HichschoolCS.accountno \n        and HichschoolCS.contact = 'High School'\n    left join (SELECT MAX(state) state, \n        accountno\n        FROM\n            CONTSUPP TestSatCS \n        WHERE \n            contact = 'Test/SAT'\n        GROUP\n            accountno) TestSatCS\n    on C.accountno=TestSatCS.accountno \n\nwhere \n    C.KEY1!='00PRSP' \n    AND (C.U_KEY2='2009 FALL' \n    OR C.U_KEY2='2010 SPRING' \n    OR C.U_KEY2='2010 J TERM' \n    OR C.U_KEY2='2010 SUMMER')\n"]], ['SQL - Grab Detail Rows as Columns in Join'], 2, 1], [(3240290, 0), [['Using a JOIN, but risks duplicates:'], ['Using EXISTS, no duplicate risk:']], [[' SELECT t.*\n  FROM TABLE1 t\n  JOIN (SELECT Sequence FROM Table1 WHERE Hash=2783342) x ON x.sequence BETWEEN t.sequence \n                                                                            AND t.sequenceend\n']], ['How to find rows where a set of numbers is between two numbers?'], 2, 1], [(3240290, 1), [['Using EXISTS, no duplicate risk:'], ['-10000']], [[' SELECT t.*\n  FROM TABLE1 t\n WHERE EXISTS(SELECT NULL\n                FROM TABLE1 x\n               WHERE x.hash = 2783342\n                 AND x.sequence BETWEEN t.sequence \n                                    AND t.sequenceend)\n']], ['How to find rows where a set of numbers is between two numbers?'], 2, 1], [(3244796, 0), [['You just need a  WHERE  clause I think.'], ['Or you can do it in the XPath instead which I guess may be more efficient']], [["    INSERT INTO SN_IO ( [C1] ,[C2]  ,[C3] )\n   SELECT [C1] ,[C2] ,[C3]\n   FROM OPENXML (@currRecord, 'ios/io', 1)\n   WITH ([C1] [varchar](25)       'C1',\n         [C2] [varchar](25)       'C2',\n         [C3] [varchar](20)       'C3'  )    \n    WHERE  [C1]  IS NOT NULL  AND [C2]  IS NOT NULL AND [C3] IS NOT NULL  \n"]], ['Stored procedure - Passing a parameter as xml and reading the data'], 2, 1], [(3296390, 0), [["The query you're looking for is:"], ['Combined with  order by  you can choose which rows are the first (this leaves rows with the greatest last_update_date):']], [[' select distinct on (my_unique_1, my_unique_2) * from my_table;\n']], ['Enforcing uniqueness on PostgreSQL table column after non-unique values already inserted'], 4, 0], [(3296390, 1), [['Combined with  order by  you can choose which rows are the first (this leaves rows with the greatest last_update_date):'], ['Now you can select this into a new table:']], [['  select distinct on (my_unique_1, my_unique_2) * \n from my_table order by my_unique_1, my_unique_2, last_update_date desc;\n']], ['Enforcing uniqueness on PostgreSQL table column after non-unique values already inserted'], 4, 0], [(3296390, 2), [['Now you can select this into a new table:'], ['Or you can use it for delete, assuming  row_id  is a primary key:']], [['  create table my_new_table as\n select distinct on (my_unique_1, my_unique_2) * \n from my_table order by my_unique_1, my_unique_2, last_update_date desc;\n']], ['Enforcing uniqueness on PostgreSQL table column after non-unique values already inserted'], 4, 1], [(3296390, 3), [['Or you can use it for delete, assuming  row_id  is a primary key:'], ['-10000']], [['  delete from my_table where row_id not in (\n     select distinct on (my_unique_1, my_unique_2) row_id \n     from my_table order by my_unique_1, my_unique_2, last_update_date desc);\n']], ['Enforcing uniqueness on PostgreSQL table column after non-unique values already inserted'], 4, 1], [(3317750, 0), [['You can do one query to get the distinct types, and  LEFT JOIN  the same table, checking for type-inequality:'], ['Since you only want the average, you could replace the line']], [[' SELECT t1.type,\n       SUM(t2.some_value) / COUNT(t2.type)\nFROM ( SELECT DISTINCT type FROM temptable ) t1\nLEFT JOIN temptable t2 ON ( t1.type <> t2.type )\nGROUP BY t1.type\n']], ['Counting all other types but the current one'], 3, 1], [(3317750, 1), [['Since you only want the average, you could replace the line'], ['by']], [[' FROM ( SELECT DISTINCT type FROM temptable ) t1\n']], ['Counting all other types but the current one'], 3, 0], [(3317750, 2), [['by'], ['but the first solution might perform better, since the number of rows is reduced earlier.']], [[' FROM temptable t1\n']], ['Counting all other types but the current one'], 3, 0], [(3318852, 0), [['Here is an answer that eliminates the concatenation issue. I found out the non duplicates and eliminated them from the final answer.'], ['-10000']], [[" WITH MyTable AS\n(\n    SELECT 1 as ID, 'John' as FirstName, 'Doe' as LastName\n    UNION\n    SELECT 2 as ID, 'John' as FirstName, 'Doe' as LastName\n    UNION\n    SELECT 3 as ID, 'Tim' as FirstName, 'Doe' as LastName\n    UNION\n    SELECT 4 as ID, 'Jane' as FirstName, 'Doe' as LastName\n    UNION\n    SELECT 5 as ID, 'Jane' as FirstName, 'Doe' as LastName\n)\nSELECT Id, FirstName, LastName\nFROM MyTable SelectTable\nWHERE Id Not In\n(\n    SELECT Min (Id)\n    From MyTable SearchTable\n    GROUP BY FirstName, LastName\n    HAVING COUNT (*) = 1\n)\n"]], ['what is the quickest way to run a query to find where 2 fields are the same'], 3, 1], [(3318852, 1), [['-10000'], ['This will result in the following']], [[" WITH MyTable AS\n(\nSELECT 1 as ID, 'John' as FirstName, 'Doe' as LastName\nUNION\nSELECT 2 as ID, 'John' as FirstName, 'Doe' as LastName\nUNION\nSELECT 3 as ID, 'Time' as FirstName, 'Doe' as LastName\nUNION\nSELECT 4 as ID, 'Jane' as FirstName, 'Doe' as LastName\n)\nSELECT ID, FirstName, LastName\nFROM MyTable\nWHERE FirstName + LastName IN\n(\n    SELECT FirstName + LastName\n    FROM MyTable\n    GROUP BY FirstName + LastName\n    HAVING COUNT (*) > 1\n)\n"]], ['what is the quickest way to run a query to find where 2 fields are the same'], 3, 1], [(3318852, 2), [['This will result in the following'], ['-10000']], [[' ID          FirstName LastName\n----------- --------- --------\n1           John      Doe\n2           John      Doe\n']], ['what is the quickest way to run a query to find where 2 fields are the same'], 3, 0], [(3332230, 0), [["To my knowledge, MySQL doesn't support a table valued data type.  The use of the function you posted would be:"], ['...which would return:']], [[' SELECT simplecompare(yt.n, yt.m) AS eval\n    FROM YOUR_TABE yt\n']], ['I need to know how i can write IF statements and CASE break statements that use and execute queries, etc in MySQL?'], 2, 0], [(3332230, 1), [['...which would return:'], ['SQL is set based, which is different from typical programming (procedural or OO).']], [[' eval\n--------\n1 = 1\n2 < 3\netc.\n']], ['I need to know how i can write IF statements and CASE break statements that use and execute queries, etc in MySQL?'], 2, 0], [(3345268, 0), [['Try this - it will delete all duplicates from your table:'], ['Your duplicates should be gone now: output is:']], [[" ;WITH duplicates AS\n(\n    SELECT \n       ProductID, ProductName, Description, Category,\n       ROW_NUMBER() OVER (PARTITION BY ProductID, ProductName\n                          ORDER BY ProductID) 'RowNum'\n    FROM dbo.tblProduct\n)\nDELETE FROM duplicates\nWHERE RowNum > 1\nGO\n\nSELECT * FROM dbo.tblProduct\nGO\n"]], ['How to delete completely duplicate rows'], 2, 1], [(3345268, 1), [['Your duplicates should be gone now: output is:'], ['-10000']], [[' ProductID   ProductName   DESCRIPTION        Category\n   1          Cinthol         cosmetic soap      soap\n   1          Lux             cosmetic soap      soap\n   1          Crowning Glory  cosmetic soap      soap\n   2          Cinthol         nice soap          soap\n   3          Lux             nice soap          soap\n']], ['How to delete completely duplicate rows'], 2, 0], [(3361768, 0), [['In SQL Server 2008 you can use a multi-table update as follows:'], ['If the target table is currently empty then you should use an INSERT instead:']], [[' UPDATE tblindiantime \nSET tblindiantime.CountryName = contacts.BusinessCountry\nFROM tblindiantime \nJOIN contacts\nON -- join condition here\n']], ['Copy data from one column to other column (which is in a different table)'], 2, 1], [(3361768, 1), [['If the target table is currently empty then you should use an INSERT instead:'], ['-10000']], [[' INSERT INTO tblindiantime (CountryName)\nSELECT BusinessCountry FROM contacts\n']], ['Copy data from one column to other column (which is in a different table)'], 2, 1], [(3426560, 0), [['That can be done in a single statement:'], ['But this means that there will be duplicates if more than one record in TABLE_A relates to a TABLE_B record.  In that situation, use EXISTS rather than adding DISTINCT to the previous query:']], [[' SELECT b.*\n  FROM TABLE_B b\n  JOIN TABLE_A a ON a.id2 = b.id2\n WHERE a.id1 = @ID1\n']], ['SQL Server / 2 select in the same Stored procedure'], 3, 1], [(3426560, 1), [['But this means that there will be duplicates if more than one record in TABLE_A relates to a TABLE_B record.  In that situation, use EXISTS rather than adding DISTINCT to the previous query:'], ['The IN clause is equivalent, but EXISTS will be faster if there are duplicates:']], [[' SELECT b.*\n  FROM TABLE_B b\n WHERE EXISTS(SELECT NULL\n                FROM TABLE_A a\n               WHERE a.id2 = b.id2\n                 AND a.id1 = @ID1)\n']], ['SQL Server / 2 select in the same Stored procedure'], 3, 1], [(3426560, 2), [['The IN clause is equivalent, but EXISTS will be faster if there are duplicates:'], ['-10000']], [[' SELECT b.*\n  FROM TABLE_B b\n WHERE b.id2 IN (SELECT a.id2\n                   FROM TABLE_A a\n                  WHERE a.id1 = @ID1)\n']], ['SQL Server / 2 select in the same Stored procedure'], 3, 1], [(3440516, 0), [['This example passes in a table name and a column name:'], ['You need to realise that everything after EXECUTE IMMEDIATE must be a string that contains some valid SQL.  A good way to verify this is to set it up in a variable and print it to the screen:']], [[" CREATE PROCEDURE A\n  ( tab IN VARCHAR2\n  , col_name IN VARCHAR2\n  ) IS\nBEGIN\n   EXECUTE IMMEDIATE 'INSERT INTO ' || tab || '(' || col_name || ') VALUES(123)';\nEND A;\n"]], ['How do I use dynamic SQL to declare a column name derived from a table name?'], 3, 1], [(3440516, 2), [['EDIT : Since you want the column name to be a local variable that always has the same value, this could be done as:'], ['-10000']], [[" CREATE PROCEDURE A (tab IN VARCHAR2)\nIS\n   col_name VARCHAR2(30) := 'MYCOLUMN';\n   v_sql VARCHAR2(2000);\nBEGIN\n   v_sql := 'INSERT INTO ' || tab || '(' || col_name || ') VALUES(123)';\n   DBMS_OUTPUT.PUT_LINE('SQL='||v_sql);\n   EXECUTE IMMEDIATE v_sql;\nEND A;\n"]], ['How do I use dynamic SQL to declare a column name derived from a table name?'], 3, 1], [(3444082, 0), [['Assuming SQL Server 2005+, use:'], ['A risky approach would be:']], [[' SELECT x.id,\n       x.forename,\n       x.surname,\n       x.somedate\n  FROM (SELECT t.id,\n               t.forename,\n               t.surname,\n               t.somedate,\n               ROW_NUMBER() OVER (PARTITION BY t.forename, t.surname \n                                      ORDER BY t.somedate DESC, t.id DESC) AS rank\n          FROM TABLE t_ x\nWHERE x.rank = 1\n']], ['How to filter out similar rows (equal on certain columns) based on other column data'], 2, 1], [(3444082, 1), [['A risky approach would be:'], ['-10000']], [['   SELECT MAX(t.id) AS id,\n         t.forename,\n         t.surname,\n         MAX(t.somedate) AS somedate\n    FROM TABLE t\nGROUP BY t.forename, t.surname\n']], ['How to filter out similar rows (equal on certain columns) based on other column data'], 2, 1], [(3482194, 0), [['For the table:'], ['You could use the following query to insert user agents:']], [["   CREATE TABLE IF NOT EXISTS `user_agent_stats` (\n  `user_agent` varchar(255) collate utf8_bin NOT NULL,\n  `hits` int(21) NOT NULL default '1',\n  UNIQUE KEY `user_agent` (`user_agent`)\n) ENGINE=MyISAM DEFAULT CHARSET=utf8 COLLATE=utf8_bin;\n\n+------------+--------------+------+-----+---------+-------+\n| Field      | Type         | Null | Key | Default | Extra |\n+------------+--------------+------+-----+---------+-------+\n| user_agent | varchar(255) | NO   | PRI | NULL    |       | \n| hits       | int(21)      | NO   |     | NULL    |       | \n+------------+--------------+------+-----+---------+-------+\n"]], ['Ensuring uniqueness of additions to MySQL table using PHP'], 3, 0], [(3482194, 2), [['Executing the above query multiple times gives:'], ['-10000']], [[' +-------------------+------+\n| user_agent        | hits |\n+-------------------+------+\n| user agent string |    6 | \n+-------------------+------+\n']], ['Ensuring uniqueness of additions to MySQL table using PHP'], 3, 0], [(3502478, 1), [['This will return you one top user from each category:'], ['-10000']], [[' SELECT  u.*\nFROM    (\n        SELECT  DISTINCT category_id\n        FROM    users\n        ) uo\nJOIN    users u\nON      u.user_id = \n        (\n        SELECT  user_id\n        FROM    users ui\n        WHERE   ui.category_id = uo.category_id\n        ORDER BY\n                (\n                SELECT  COUNT(*)\n                FROM    votes v\n                WHERE   v.receiver_id = ui.user_id\n                ) DESC\n        LIMIT 1\n        )\n']], ['Top User SQL Query With Categories?'], 2, 1], [(3526673, 0), [['-10000'], ['Actually, if these are datetime values, then there is a better way:']], [[" Select Substring( MyTextColumn, 1, CharIndex( ' ', MyTextColumn ) - 1)\n"]], ['getting all chars before space in SQL SERVER'], 2, 1], [(3526673, 1), [['Actually, if these are datetime values, then there is a better way:'], ['-10000']], [[' Select Cast(DateDiff(d, 0, MyDateColumn) As datetime)\n']], ['getting all chars before space in SQL SERVER'], 2, 0], [(3550497, 0), [['For new databases, add the user in the model database. This is used as the template for all new databases.'], ['For existing databases, use sp_MSForEachDb']], [[" USE model\nCREATE USER ... FROM LOGIN...\nEXEC sp_addrolemember 'db_datareader', '...'\n"]], ['SQL Server - Give a Login Permission for Read Access to All Existing and Future Databases'], 2, 1], [(3550497, 1), [['For existing databases, use sp_MSForEachDb'], ['-10000']], [[" EXEC sp_MSForEachDb '\n USE ?\n CREATE USER ... FROM LOGIN...  \n EXEC sp_addrolemember ''db_datareader'', ''...''\n'\n"]], ['SQL Server - Give a Login Permission for Read Access to All Existing and Future Databases'], 2, 1], [(3579079, 0), [['Using a single table as in your first option is probably the simplest design. As you mentioned, many attributes that are subtype-specific will have to be given a  NULL  value on rows where these attributes do not apply. With this model, you would have one policies table, which would look something like this:'], ['You also cannot enforce  NOT NULL  on attributes of a subtype that should be mandatory. You would have to handle this in your application, which in general is not ideal.']], [[' +------+---------------------+----------+----------------+------------------+\n| id   | date_issued         | type     | vehicle_reg_no | property_address |\n+------+---------------------+----------+----------------+------------------+\n|    1 | 2010-08-20 12:00:00 | MOTOR    | 01-A-04004     | NULL             |\n|    2 | 2010-08-20 13:00:00 | MOTOR    | 02-B-01010     | NULL             |\n|    3 | 2010-08-20 14:00:00 | PROPERTY | NULL           | Oxford Street    |\n|    4 | 2010-08-20 15:00:00 | MOTOR    | 03-C-02020     | NULL             |\n+------+---------------------+----------+----------------+------------------+\n\n\\------ COMMON FIELDS -------/          \\----- SUBTYPE SPECIFIC FIELDS -----/\n']], ['How can you represent inheritance in a database?'], 4, 0], [(3579079, 1), [['You also cannot enforce  NOT NULL  on attributes of a subtype that should be mandatory. You would have to handle this in your application, which in general is not ideal.'], ['This is how you would have to query all the policies regardless of the type:']], [[' --// Table: policies_motor\n+------+---------------------+----------------+\n| id   | date_issued         | vehicle_reg_no |\n+------+---------------------+----------------+\n|    1 | 2010-08-20 12:00:00 | 01-A-04004     |\n|    2 | 2010-08-20 13:00:00 | 02-B-01010     |\n|    3 | 2010-08-20 15:00:00 | 03-C-02020     |\n+------+---------------------+----------------+\n\n--// Table: policies_property    \n+------+---------------------+------------------+\n| id   | date_issued         | property_address |\n+------+---------------------+------------------+\n|    1 | 2010-08-20 14:00:00 | Oxford Street    |   \n+------+---------------------+------------------+\n']], ['How can you represent inheritance in a database?'], 4, 0], [(3579079, 2), [['This is how you would have to query all the policies regardless of the type:'], ['Note how adding new subtypes would require the above query to be modified with an additional  UNION ALL  for each subtype. This can easily lead to bugs in your application if this operation is forgotten. ']], [[" SELECT     date_issued, other_common_fields, 'MOTOR' AS type\nFROM       policies_motor\nUNION ALL\nSELECT     date_issued, other_common_fields, 'PROPERTY' AS type\nFROM       policies_property;\n"]], ['How can you represent inheritance in a database?'], 4, 0], [(3579079, 3), [['Note how adding new subtypes would require the above query to be modified with an additional  UNION ALL  for each subtype. This can easily lead to bugs in your application if this operation is forgotten. '], ['This solution solves the problems identified in the other two designs:']], [[' CREATE TABLE policies (\n   policy_id          int,\n   date_issued        datetime,\n\n   -- // other common attributes ...\n);\n\nCREATE TABLE policy_motor (\n    policy_id         int,\n    vehicle_reg_no    varchar(20),\n\n   -- // other attributes specific to motor insurance ...\n\n   FOREIGN KEY (policy_id) REFERENCES policies (policy_id)\n);\n\nCREATE TABLE policy_property (\n    policy_id         int,\n    property_address  varchar(20),\n\n   -- // other attributes specific to property insurance ...\n\n   FOREIGN KEY (policy_id) REFERENCES policies (policy_id)\n);\n']], ['How can you represent inheritance in a database?'], 4, 0], [(3589286, 0), [['Two options - using LIMIT:'], ['Using MAX:']], [['   SELECT yt.numeric_column\n    FROM YOUR_TABLE yt\nORDER BY yt.numeric_column DESC\n   LIMIT 1\n']], ['Simple MySql - Get Largest Number in Table'], 2, 1], [(3589286, 1), [['Using MAX:'], ['-10000']], [[' SELECT MAX(yt.numeric_column)\n  FROM YOUR_TABLE yt\n']], ['Simple MySql - Get Largest Number in Table'], 2, 1], [(3609687, 0), [['Try this:'], ['To get the missing days is harder.']], [[' Select DateAdd(day, 0, DateDiff(day, 0, StartDate)) Date,\n    Name, Sum (Work) TotalWork\nFrom TableData\nGroup By Name, DateAdd(day, 0, DateDiff(day, 0, StartDate)) \n']], ['Iterating through dates in SQL'], 3, 1], [(3609687, 2), [['EDIT, I am revisiting this with a solution that uses a Common Table Expression (CTE). This does NOT require use of a dates table.'], ['-10000']], [['     Declare @SD DateTime, @ED DateTime\n    Declare @count integer = datediff(day, @SD, @ED)\n    With Ints(i) As\n      (Select 0 Union All\n    Select i + 1 From Ints\n    Where i < @count )  \n     Select DateAdd(day, 0, DateDiff(day, 0, td.StartDate)) Date,\n         td.Name, Sum (td.Work) TotalWork\n     From Ints i \n        Left Join TableData d\n           On DateDiff(day, @SD, d.StartDate) = i.i\n     Group By d.Name, DateAdd(day, 0, DateDiff(day, 0, d.StartDate)) \n']], ['Iterating through dates in SQL'], 3, 1], [(3623645, 0), [['-10000'], ['-10000']], [['Output testscript category_id name                 parent      lft         rgt         lftcalc     rgtcalc\n----------- -------------------- ----------- ----------- ----------- ----------- -----------\n1           ELECTRONICS          NULL        1           20          1           20\n2           TELEVISIONS          1           2           9           2           9\n3           TUBE                 2           3           4           3           4\n4           LCD                  2           5           6           5           6\n5           PLASMA               2           7           8           7           8\n6           PORTABLE ELECTRONICS 1           10          19          10          19\n7           MP3 PLAYERS          6           11          14          11          14\n8           FLASH                7           12          13          12          13\n9           CD PLAYERS           6           15          16          15          16\n10          2 WAY RADIOS         6           17          18          17          18\n']], ['How to repair a corrupted MPTT tree (nested set) in the database using SQL?'], 3, 0], [(3675616, 0), [['You could have a  where  clause that says there must be N working days between the start and the end day.  Unlike the  row_number()  variants, this should work in MS Access.  For example:'], ['This prints:']], [[" declare @Task table (taskid int, empid int, start date, days int)\ninsert @Task values (1, 1, '2010-01-01', 1)\ninsert @Task values (2, 1, '2010-01-01', 2)\ninsert @Task values (3, 1, '2010-01-01', 3)\n\ndeclare @WorkableDays table (empid int, day date)\ninsert @WorkableDays values (1, '2010-01-01')\ninsert @WorkableDays values (1, '2010-01-02')\ninsert @WorkableDays values (1, '2010-01-05')\n\nselect  t.taskid\n,       t.start\n,       endday.day as end\nfrom    @Task t\njoin    @WorkableDays endday\non      endday.empid = t.empid\nwhere   t.days = \n        (\n        select  COUNT(*)\n        from    @WorkableDays wd\n        where   wd.empId = t.empId\n                and wd.day between t.start and endday.day\n        )\n"]], ['Skipping rows in sql query (finding end date based on start date and worked days)'], 2, 1], [(3675616, 1), [['This prints:'], ['-10000']], [[' taskid   start       end\n1        2010-01-01  2010-01-01\n2        2010-01-01  2010-01-02\n3        2010-01-01  2010-01-05\n']], ['Skipping rows in sql query (finding end date based on start date and worked days)'], 2, 0], [(3702873, 0), [['Try this query.  The offsettime is the (Offset / 60 / 60)'], ['The results are']], [[' SELECT tzname.`Time_zone_id`,(`Offset`/60/60) AS `offsettime`,`Is_DST`,`Name`,`Transition_type_id`,`Abbreviation`\nFROM `time_zone_transition_type` AS `transition`, `time_zone_name` AS `tzname`\nWHERE transition.`Time_zone_id`=tzname.`Time_zone_id`\nORDER BY transition.`Offset` ASC;\n']], ['MySQL: How to select the UTC offset and DST for all timezones?'], 2, 1], [(3702873, 1), [['The results are'], ['-10000']], [[' 501 -12.00000000    0   0   PHOT    Pacific/Enderbury\n369 -12.00000000    0   0   GMT+12  Etc/GMT+12\n513 -12.00000000    0   1   KWAT    Pacific/Kwajalein\n483 -12.00000000    0   1   KWAT    Kwajalein\n518 -11.50000000    0   1   NUT Pacific/Niue\n496 -11.50000000    0   1   SAMT    Pacific/Apia\n528 -11.50000000    0   1   SAMT    Pacific/Samoa\n555 -11.50000000    0   1   SAMT    US/Samoa\n521 -11.50000000    0   1   SAMT    Pacific/Pago_Pago\n496 -11.44888889    0   0   LMT Pacific/Apia\n528 -11.38000000    0   0   LMT Pacific/Samoa\n555 -11.38000000    0   0   LMT US/Samoa\n521 -11.38000000    0   0   LMT Pacific/Pago_Pago\n518 -11.33333333    0   0   NUT Pacific/Niue\n544 -11.00000000    0   3   BST US/Aleutian\n163 -11.00000000    0   3   BST America/Nome\n518 -11.00000000    0   2   NUT Pacific/Niue\n496 -11.00000000    0   2   WST Pacific/Apia\n544 -11.00000000    0   0   NST US/Aleutian\n163 -11.00000000    0   0   NST America/Nome\n528 -11.00000000    0   4   SST Pacific/Samoa\n528 -11.00000000    0   3   BST Pacific/Samoa\n']], ['MySQL: How to select the UTC offset and DST for all timezones?'], 2, 0], [(3805664, 0), [['To get events for the next three non-sequential days, starting today, use:'], ['To get events for the next three sequential days, starting today, use the  DATE_ADD function :']], [[' SELECT x.*\n  FROM (SELECT ep.*,\n               CASE\n                 WHEN DATE(@dt) = DATE(x.dt) THEN @rownum\n                 ELSE @rownum := @rownum + 1\n               END AS rank,\n          FROM EVENT_POST ep\n          JOIN (SELECT @rowrum := 0, @dt := NULL) r\n         WHERE ep.startdate >= CURRENT_DATE\n      ORDER BY t.startdate, t.starttime) x\n WHERE x.rank <= 3\n']], ['Sort out the three first occurence of an attribute'], 2, 1], [(3805664, 1), [['To get events for the next three sequential days, starting today, use the  DATE_ADD function :'], ['-10000']], [[' SELECT ep.*\n  FROM EVENT_POST ep\n WHERE ep.startdate BETWEEN DATE(NOW)\n                        AND DATE_ADD(DATE(NOW), INTERVAL 3 DAY)\n']], ['Sort out the three first occurence of an attribute'], 2, 1], [(3819810, 1), [['EDIT2: \nOther variants of the core query can be'], ['The above query can be also written as']], [[' SELECT 1\nFROM \n(SELECT COUNT(DISTINCT column_name) AS distinct_values_by_pid\nFROM table_name\nGROUP BY PersonID) T\nHAVING MIN(distinct_values_by_pid) = MAX(distinct_values_by_pid)\n']], ['Normalizing a table: finding unique columns over series of rows (Oracle 10.x)'], 3, 1], [(3819810, 2), [['The above query can be also written as'], ["Which will test multiple columns at the same time returning true for columns that belong to 'Workers' and false for columns that should go into 'Persons'."]], [[' SELECT MIN(c1)=MAX(c1), MIN(c2)=MAX(c2), ...\nFROM \n(SELECT COUNT(DISTINCT column_name_1) AS c1, COUNT(DISTINCT column_name_2) AS c2, ...\nFROM table_name\nGROUP BY PersonID) T\n']], ['Normalizing a table: finding unique columns over series of rows (Oracle 10.x)'], 3, 1], [(3821642, 0), [['What about when there are three e-mails/names?\nWith shown data it should be easy to do'], ['You can also ']], [[" select replace(substring(substring_index(`Personnel`, ',', 1),length(substring_index(`Personnel`, ',', 1 - 1)) + 1), ',', '') personnel1,\n       replace(substring(substring_index(`Personnel`, ',', 2),length(substring_index(`Personnel`, ',', 2 - 1)) + 1), ',', '') personnel2,\nfrom `pubs_for_client`\n"]], ['Parse SQL file to separate columns'], 3, 1], [(3821642, 2), [['After which you can user'], ['You could also create your own function that will extract directly names and e-mails.']], [[" select strSplit(`Personnel`, ',', 1), strSplit(`Personnel`, ',', 2)\nfrom `pubs_for_client`\n"]], ['Parse SQL file to separate columns'], 3, 0], [(3827025, 0), [['-10000'], ['-10000']], [['For People SELECT p.*\n  FROM PEOPLE p\n  JOIN HOUSES h ON FIND_IN_SET(p.name, h.people)\n WHERE h.name = ?\n']], ['Matching delimited string to table rows'], 3, 1], [(3827025, 1), [['-10000'], ['-10000']], [['For Houses SELECT h.*\n  FROM HOUSES h\n  JOIN PEOPLE p ON FIND_IN_SET(h.name, p.houses)\n WHERE p.name = ?\n']], ['Matching delimited string to table rows'], 3, 1], [(3827025, 2), [['-10000'], ['-10000']], [[' CREATE TABLE people_houses (\n  house_id int,\n  person_id int,\n  PRIMARY KEY (house_id, person_id),\n  FOREIGN KEY (house_id) REFERENCES houses (id),\n  FOREIGN KEY (person_id) REFERENCES people (id)\n)\n']], ['Matching delimited string to table rows'], 3, 1], [(3886340, 0), [['Use  coalesce  to apply the default'], ['-10000']], [[" SELECT Listing.Title\n    , Listing.MLS\n    , Pictures.PictureTH\n    , coalesce(Pictures.Picture, 'default.jpg') as Picture\n    , Listing.ID  \nFROM Listing \nLEFT OUTER JOIN Pictures \n    ON Listing.ID = Pictures.ListingID \n"]], ['SQL Select Return Default Value If Null'], 2, 1], [(3886340, 1), [['-10000'], ['-10000']], [[" SELECT Listing.Title\n    , Listing.MLS\n    , Pictures.PictureTH\n    , coalesce(Pictures.Picture, 'default.jpg') as Picture\n    , Listing.ID  \nFROM Listing \nLEFT OUTER JOIN Pictures \n    ON Listing.ID = Pictures.ListingID \nWHERE Pictures.ID is null\nOR Pictures.ID = (SELECT MIN(ID) \n    FROM Pictures \n    WHERE (ListingID = Listing.ID))) \n"]], ['SQL Select Return Default Value If Null'], 2, 1], [(3891758, 0), [['This statement will return a list of columns based on the table name you put in:'], ["Not sure if I can avoid a loop here....you'll need to load the results from above into a cursor and then build a query from it.  Psuedo coded:"]], [[" select name from syscolumns\nwhere [id] = (select [id] from sysobjects where name = 'tablename')\n"]], ['How to update one table from another one without specifying column names?'], 2, 0], [(3891758, 1), [["Not sure if I can avoid a loop here....you'll need to load the results from above into a cursor and then build a query from it.  Psuedo coded:"], ['When the query is done being built in the loop, use exec sp_executesql @query.']], [[" set @query = 'update [1607348182] set '\nload cursor --(we will use @name to hold the column name)\nwhile stillrecordsincursor\nset @query = @query + @name + ' = tmp_[1607348182]. ' +@name + ','\nload next value from cursor\nloop!\n"]], ['How to update one table from another one without specifying column names?'], 2, 0], [(3895652, 0), [['using the  round  function you can try this'], ['the output will be']], [[' select round(4.584406, 1, 1)\n']], ['How to Truncate the Decimal Places without Rounding Up?'], 4, 1], [(3895652, 1), [['the output will be'], ['the key is the third parameter']], [[' 4.5\n']], ['How to Truncate the Decimal Places without Rounding Up?'], 4, 0], [(3895652, 3), [['-10000'], ['smallint, or int. When function is\n  omitted or has a value of 0 (default),\n  numeric_expression is rounded.  When a\n  value other than 0 is specified,\n  numeric_expression is truncated.']], [[' Is the type of operation to perform. function must be tinyint,\n']], ['How to Truncate the Decimal Places without Rounding Up?'], 4, 0], [(3900330, 0), [['-10000'], ['For your data set, this gives:']], [[" select min(id) from \n(\n  select id, senderID pID from table where receiverID = '1'\n  union\n  select id, receiverID pID from table where senderID = '1'\n) as fred\ngroup by pID;\n"]], ['MySQL get only rows with a unique value for a certain field'], 2, 1], [(3900330, 1), [['For your data set, this gives:'], ['-10000']], [[' +---------+\n| min(id) |\n+---------+\n|       0 |\n|       1 |\n+---------+\n']], ['MySQL get only rows with a unique value for a certain field'], 2, 0], [(3925043, 0), [["Any reason this isn't done as    "], ['I would use a subquery before resorting to @vars myself.  Something like this:']], [[' select prg.prefix_id, count(1) from tablename where... group by prg.prefix_id     \n']], ['Most optimized way to get column totals in SQL Server 2005+'], 2, 0], [(3925043, 1), [['I would use a subquery before resorting to @vars myself.  Something like this:'], ['-10000']], [['    select c1,c2,c1+c1 as total from \n   (SELECT \n   count(case when prg.prefix_id = 1 then iss.id end) as c1, \n   count(case when prg.prefix_id = 2 then iss.id end) as c2 \n   FROM dbo.TableName \n   WHERE ... ) a\n']], ['Most optimized way to get column totals in SQL Server 2005+'], 2, 1], [(3932947, 0), [['You can use  DATEADD :'], ['EDIT : if you need the number of days up to 6 months ago you can use  DATEDIFF :']], [[' select DATEADD(month, -6, @d)\n']], ['SQL Server 2005: how to subtract 6 month'], 2, 1], [(3932947, 1), [['EDIT : if you need the number of days up to 6 months ago you can use  DATEDIFF :'], ['-10000']], [[' select DATEDIFF(day, @d, DATEADD(month, -6, @d))\n']], ['SQL Server 2005: how to subtract 6 month'], 2, 1], [(3951413, 0), [['-10000'], ['Edit: \nIf you need to update multiple fields you can string them along—with commas in between—in that same  UPDATE  statement, e.g.:']], [[" UPDATE mytable \n   SET server_path = REPLACE(server_path,'/home/','/new_home/');\n"]], ['How can I find and replace in MySQL?'], 2, 1], [(3951413, 1), [['Edit: \nIf you need to update multiple fields you can string them along—with commas in between—in that same  UPDATE  statement, e.g.:'], ['-10000']], [[" UPDATE mytable \n   SET mycol1 = REPLACE(mycol1,'/home/','/new_home/'), \n       mycol2 = REPLACE(mycol2,'/home/','/new_home/');\n"]], ['How can I find and replace in MySQL?'], 2, 1], [(4017878, 0), [['You can do a JOIN in an UPDATE, essentially selecting from the parent table and UPDATEing the child table for all rows in a single UPDATE command.'], ['you can also INSERT based on a SELECT, so you would create one row from each row returned in the SELECT, like:']], [[' UPDATE c\n    SET Col1=p.Col1\n    FROM ParentTable           p\n        INNER JOIN ChildTable  c On p.ParentID=c.ParentID\n    WHERE ...\n']], ['php do something for every record in the database'], 2, 1], [(4017878, 1), [['you can also INSERT based on a SELECT, so you would create one row from each row returned in the SELECT, like:'], ['-10000']], [[" INSERT INTO ChildTable\n        (Col1, Col2, Col3, Col4)\n    SELECT\n        p.ColA, p.ColB, 'constant value', p.ColC-p.ColD\n        FROM ParentTable p\n        WHERE... \n"]], ['php do something for every record in the database'], 2, 1], [(4038960, 0), [['-10000'], ['If you only want to return results with records in OFFICE_TABLE you will want an inner join, e.g.:']], [[' SELECT `name`, `key`, ot.name AS OFFICE_NAME, `manager`, `id` \n  FROM `ASSOCIATION_TABLE` at\n       LEFT OUTER JOIN OFFICE_TABLE ot\n       ON ot.id = at.office\n WHERE `association`.`customer`=4;\n']], ['Basic MySQL Table Join?'], 2, 1], [(4038960, 1), [['If you only want to return results with records in OFFICE_TABLE you will want an inner join, e.g.:'], ['-10000']], [[' SELECT `name`, `key`, ot.name AS OFFICE_NAME, `manager`, `id` \n  FROM `ASSOCIATION_TABLE` at\n       INNER JOIN OFFICE_TABLE ot\n       ON ot.id = at.office\n WHERE `association`.`customer`=4;\n']], ['Basic MySQL Table Join?'], 2, 1], [(4062845, 0), [['e.g.'], ["To pull this off you'll probably need to have five columns, as follows:"]], [[' Ballmer employed-by Microsoft\nBallmer is-a Person\nMicrosoft is-a Organization\nMicrosoft run-by Ballmer\nSoftImage acquired-by Microsoft\nSoftImage is-a Organization\nJoel Spolsky is-a Person\nJoel Spolsky formerly-employed-by Microsoft\nSpolsky, Joel dreamed-up StackOverflow\nStackOverflow is-a Website\nSocrates is-a Person\nSocrates died-on (some date)\n']], ['How can I save semantic information in a MySQL table?'], 3, 0], [(4062845, 1), [["To pull this off you'll probably need to have five columns, as follows:"], ['The point of the canonical forms of your subject and object is to allow queries like this to work, even if your user puts in "Joel Spolsky" and "Spolsky, Joel" in two different places even if they mean the same person.']], [[' Full text subject  (whatever your user puts in)\nCanonical subject (what your user puts in, massaged into a standard form)\nRelation (is-a etc)\nFull text object\nCanonical object\n']], ['How can I save semantic information in a MySQL table?'], 3, 0], [(4062865, 0), [["You could alias  @@rowcount  to  '@id' , like:"], ['This prints:']], [[" declare @t table (name varchar(25))\n\ninsert @t (name) values ('jddjdjd')\n\nselect  @@rowcount as '@id'\n,       name\nfrom    @t\nfor xml path('row'), root('rows')\n"]], ['Adding a unique row count to a SQL 2008 "for xml path" statement?'], 2, 1], [(4062865, 1), [['This prints:'], ["However, I'm not sure it's clearly defined what  @@rowcount  means at the point where it gets turned into an attribute."]], [[' <rows>\n    <row id="1">\n        <name>jddjdjd</name>\n    </row>\n</rows>\n']], ['Adding a unique row count to a SQL 2008 "for xml path" statement?'], 2, 0], [(4212229, 1), [['you can insert it to file like'], ['-10000']], [[" INTO OUTFILE '/tmp/delete.sql';\n"]], ['Deleting dynamically managed tables in MySQL'], 3, 0], [(4225984, 0), [['To get the basic numbered-role data, we might start with'], ['BUT  this will give us, for each  org_nbr , a separate row for each  role_id  that has data! Which is not what we want - so we need to  GROUP BY org_nbr . But then we need to either  GROUP BY  or aggregate over every column in the  SELECT  list! The trick then is to come up with an aggregate function that will placate SQL Server  and  give us the results we want. In this case,  MIN  will do the job:']], [[' SELECT\n    org_nbr\n    , r1.assoc_id   role1_ID\n    , r1.last_name  role1_name\n    , r2.assoc_id   role2_ID\n    , r2.last_name  role2_name\n    , r3.assoc_id   role3_ID\n    , r3.last_name  role3_name\n    , r4.assoc_id   role4_ID\n    , r4.last_name  role4_name\n    , r5.assoc_id   role5_ID\n    , r5.last_name  role5_name\n    , r6.assoc_id   role6_ID\n    , r6.last_name  role6_name\nFROM\n    ASSOC_ROLE ar\n    LEFT JOIN ASSOCIATE r1 ON ar.role_id = 1 AND ar.assoc_id = r1.assoc_id\n    LEFT JOIN ASSOCIATE r2 ON ar.role_id = 2 AND ar.assoc_id = r2.assoc_id\n    LEFT JOIN ASSOCIATE r3 ON ar.role_id = 3 AND ar.assoc_id = r3.assoc_id\n    LEFT JOIN ASSOCIATE r4 ON ar.role_id = 4 AND ar.assoc_id = r4.assoc_id\n    LEFT JOIN ASSOCIATE r5 ON ar.role_id = 5 AND ar.assoc_id = r5.assoc_id\n    LEFT JOIN ASSOCIATE r6 ON ar.role_id = 6 AND ar.assoc_id = r6.assoc_id\n']], ['"Pivoting" non-aggregate data in SQL Server'], 3, 0], [(4225984, 1), [['BUT  this will give us, for each  org_nbr , a separate row for each  role_id  that has data! Which is not what we want - so we need to  GROUP BY org_nbr . But then we need to either  GROUP BY  or aggregate over every column in the  SELECT  list! The trick then is to come up with an aggregate function that will placate SQL Server  and  give us the results we want. In this case,  MIN  will do the job:'], ['Output:']], [[' SELECT\n    org_nbr\n    , MIN(r1.assoc_id)   role1_ID\n    , MIN(r1.last_name)  role1_name\n    , MIN(r2.assoc_id)   role2_ID\n    , MIN(r2.last_name)  role2_name\n    , MIN(r3.assoc_id)   role3_ID\n    , MIN(r3.last_name)  role3_name\n    , MIN(r4.assoc_id)   role4_ID\n    , MIN(r4.last_name)  role4_name\n    , MIN(r5.assoc_id)   role5_ID\n    , MIN(r5.last_name)  role5_name\n    , MIN(r6.assoc_id)   role6_ID\n    , MIN(r6.last_name)  role6_name\nFROM\n    ASSOC_ROLE ar\n    LEFT JOIN ASSOCIATE r1 ON ar.role_id = 1 AND ar.assoc_id = r1.assoc_id\n    LEFT JOIN ASSOCIATE r2 ON ar.role_id = 2 AND ar.assoc_id = r2.assoc_id\n    LEFT JOIN ASSOCIATE r3 ON ar.role_id = 3 AND ar.assoc_id = r3.assoc_id\n    LEFT JOIN ASSOCIATE r4 ON ar.role_id = 4 AND ar.assoc_id = r4.assoc_id\n    LEFT JOIN ASSOCIATE r5 ON ar.role_id = 5 AND ar.assoc_id = r5.assoc_id\n    LEFT JOIN ASSOCIATE r6 ON ar.role_id = 6 AND ar.assoc_id = r6.assoc_id\nGROUP BY\n    org_nbr\n']], ['"Pivoting" non-aggregate data in SQL Server'], 3, 1], [(4225984, 2), [['Output:'], ['Of course this will fall short should the maximum  role_id  increase...']], [[' org_nbr    role1_ID    role1_name role2_ID    role2_name role3_ID    role3_name role4_ID    role4_name role5_ID    role5_name role6_ID    role6_name\n---------- ----------- ---------- ----------- ---------- ----------- ---------- ----------- ---------- ----------- ---------- ----------- ----------\n1AA        1447        Cooper     NULL        NULL       1448        Collins    1448        Collins    1448        Collins    1449        Lynch\nWarning: Null value is eliminated by an aggregate or other SET operation.\n']], ['"Pivoting" non-aggregate data in SQL Server'], 3, 0], [(4226144, 0), [['-10000'], ['EDIT']], [[' delete \n  from projects \n where documentsFK = (\n                      select documentFK \n                        from documents \n                       where documentsFK > 125\n                     );\n\ndelete \n  from documents \n where documentsFK > 125;\n']], ['Delete row when a table has an FK relationship'], 2, 1], [(4226144, 1), [['EDIT'], ['-10000']], [[' delete \n  from projects \n where documentsFK in (\n                       select documentFK \n                         from documents \n                        where documentsFK > 125\n                      );\n\ndelete \n  from documents \n where documentsFK > 125;\n']], ['Delete row when a table has an FK relationship'], 2, 1], [(4257442, 0), [['In SQL Server 2008, use the  DATETIMEOFFSET  data type which is a DATETIME plus a timezone offset included.'], ['SQL Server 2008 also contains functions and SQL commands to convert  DATETIMEOFFSET  values from one timezone to another:']], [[" SELECT CAST('2010-11-23 16:35:29+09:00' AS datetimeoffset) \n"]], ['SQL Server How to persist and use a time across different time zones'], 3, 1], [(4257442, 1), [['SQL Server 2008 also contains functions and SQL commands to convert  DATETIMEOFFSET  values from one timezone to another:'], ['would result in:']], [[" SELECT \nSWITCHOFFSET(CAST('2010-11-23 16:35:29+09:00' AS datetimeoffset), '+01:00')\n"]], ['SQL Server How to persist and use a time across different time zones'], 3, 1], [(4257442, 2), [['would result in:'], ['Same time, different timezone (+1 hour from GMT)']], [[' 2010-11-23 08:35:29.0000000 +01:00\n']], ['SQL Server How to persist and use a time across different time zones'], 3, 0], [(4283031, 0), [['-10000'], ['A solution with JOINS. Will work only if you have past dates. ']], [["A. This answers 'where date is the closest date from now...': SELECT *\nFROM `categoriesSupports`\nWHERE `date` IN (\n    SELECT `date`\n    FROM `categoriesSupports`\n    ORDER BY `date` DESC\n    LIMIT 1\n)\n"]], ['how to get last date form DB table mysql'], 4, 1], [(4283031, 3), [['Replace  3  with any number if you want more or less days.'], ['This answers the latest version of the question.  ']], [['C. Same as A., but per support id SELECT a.*\nFROM `categoriesSupports` AS a\nLEFT JOIN `categoriesSupports` AS b\n    ON b.support_id = a.support_id AND b.date > a.date\nWHERE b.id IS NULL\n']], ['how to get last date form DB table mysql'], 4, 1], [(4301603, 0), [['-10000'], ['Ex:  ']], [[' SELECT DATENAME(month, <fieldname>) AS "Month Name" FROM <tablename>\n']], ['Month name in sql server 2008'], 2, 1], [(4301603, 1), [['Ex:  '], ['This value would return the  monthname  corresponding to the date value in the field  JoinDate  from the table  EMPLOYEE .']], [[' SELECT DATENAME(month, JoinDate) AS "Month Name" FROM EMPLOYEE\n']], ['Month name in sql server 2008'], 2, 1], [(4352912, 0), [["This works, don't know if it can be made any simpler"], ['EDIT: Found a sweeter alternative, if your ids never have negative numbers']], [[' SELECT ID1, ID2, ID3, ID4, ID5\nFROM IDS OUTT\nWHERE NOT EXISTS (SELECT 1\n                FROM IDS INN\n                WHERE OUTT.ID != INN.ID AND\n                      (ISNULL(OUTT.ID1, INN.ID1) = INN.ID1 OR (INN.ID1 IS NULL AND OUTT.ID1 IS NULL)) AND\n                      (ISNULL(OUTT.ID2, INN.ID2) = INN.ID2 OR (INN.ID2 IS NULL AND OUTT.ID2 IS NULL)) AND\n                      (ISNULL(OUTT.ID3, INN.ID3) = INN.ID3 OR (INN.ID3 IS NULL AND OUTT.ID3 IS NULL)) AND\n                      (ISNULL(OUTT.ID4, INN.ID4) = INN.ID4 OR (INN.ID4 IS NULL AND OUTT.ID4 IS NULL)) AND\n                      (ISNULL(OUTT.ID5, INN.ID5) = INN.ID5 OR (INN.ID5 IS NULL AND OUTT.ID5 IS NULL)))\n']], ['Select distinct not-null rows SQL server 2005'], 2, 1], [(4352912, 1), [['EDIT: Found a sweeter alternative, if your ids never have negative numbers'], ["EDIT2: There is one case where it won't work - in case two rows (with different ids) have exact same form. I am assuming that it is not there. If such a thing is present, then first create a view with a select distinct on the base table first, and then apply this query. "]], [[' SELECT ID1, ID2, ID3, ID4, ID5\nFROM IDS OUTT\nWHERE NOT EXISTS (SELECT 1\n                FROM IDS INN\n                WHERE OUTT.ID != INN.ID AND\n                      coalesce(OUTT.ID1, INN.ID1,-1) = isnull(INN.ID1,-1) AND\n                      coalesce(OUTT.ID2, INN.ID2,-1) = isnull(INN.ID2,-1) AND\n                      coalesce(OUTT.ID3, INN.ID3,-1) = isnull(INN.ID3,-1) AND\n                      coalesce(OUTT.ID4, INN.ID4,-1) = isnull(INN.ID4,-1) AND\n                      coalesce(OUTT.ID5, INN.ID5,-1) = isnull(INN.ID5,-1))  \n']], ['Select distinct not-null rows SQL server 2005'], 2, 1], [(4400347, 0), [['To get counts by ip and by day, the easiest way is to flatten the query:'], ['You can also do it by joining on IP:']], [[" SELECT 'day1' AS day, srcIP, count(*) AS count FROM Day1 GROUP BY srcIP\nUNION\nSELECT 'day2' AS day, srcIP, count(*) AS count FROM Day2 GROUP BY srcIP\nUNION\nSELECT 'day3' AS day, srcIP, count(*) AS count FROM Day3 GROUP BY srcIP\n"]], ['How to get a of count of items for multiple tables'], 2, 1], [(4400347, 1), [['You can also do it by joining on IP:'], ["But here you will be missing IPs that are not in Day1, unless you first do a SELECT DISTINCT srcIP from a UNION of all days, which is pretty expensive.  Basically this table structure doesn't lend itself too easily to this kind of aggregation."]], [[' SELECT srcIP, d1.count, d2.count, d3.count\nFROM (SELECT srcIP, count(*) AS count FROM Day1 GROUP BY srcIP) d1\nLEFT JOIN (SELECT srcIP, count(*) AS count FROM Day2 GROUP BY srcIP) d2 USING (srcIP)\nLEFT JOIN (SELECT srcIP, count(*) AS count FROM Day3 GROUP BY srcIP) d3 USING (srcIP)\n']], ['How to get a of count of items for multiple tables'], 2, 1], [(4429428, 0), [['http://download.oracle.com/docs/cd/B10500_01/appdev.920/a96590/adg09dyn.htm#24492'], ['Commence Example']], [[" CREATE OR REPLACE PROCEDURE dynaQuery(\n       TAB IN VARCHAR2, \n       sid in number ,\n       cur OUT NOCOPY sys_refcursor) IS\n query_str VARCHAR2(200);\nBEGIN\n    query_str := 'SELECT USERNAME FROM ' || tab\n      || ' WHERE sid= :id';\ndbms_output.put_line(query_str);\n    OPEN cur FOR query_str USING sid;\nEND ;\n/\n"]], ['Passing the tablename to the cursor'], 3, 1], [(4429428, 1), [['Commence Example'], ['Output:']], [[" create table test1(sid number, username varchar2(50));\ninsert into test1(sid, username) values(123,'abc');\ninsert into test1(sid, username) values(123,'ddd');\ninsert into test1(sid, username) values(222,'abc');\ncommit;\n/\n\n\n\n declare \n  cur  sys_refcursor ;\n  sid number ;\n  uName varchar2(50) ;\n  begin\n  sid := 123; \n  dynaQuery('test1',sid, cur);\n   LOOP\n     FETCH cur INTO uName;\n     DBMS_OUTPUT.put_line(uName);\n     EXIT WHEN cur%NOTFOUND;\n     -- process row here\n   END LOOP;\nCLOSE CUR;\n\n\n  end ;\n"]], ['Passing the tablename to the cursor'], 3, 0], [(4429428, 2), [['Output:'], ['EDIT: Added Close CUR that was rightly suggested by @JackPDouglas']], [[' SELECT USERNAME FROM test1 WHERE sid= :id\nabc\nddd\nabc\nddd\nddd\n']], ['Passing the tablename to the cursor'], 3, 0], [(4434581, 0), [['Try a self-join:'], ['Alternatively you can do it in SQL by wrapping the above query in another SELECT that uses EXISTS:']], [[' SELECT T1.id_group\nFROM jos_gj_users T1\nJOIN jos_gj_users T2\nON T1.id_group = T2.id_group\nWHERE T1.id_user = 20\nAND T2.id_user = 21\n']], ['SQL Query to check if student1 has a course with student 2'], 2, 1], [(4434581, 1), [['Alternatively you can do it in SQL by wrapping the above query in another SELECT that uses EXISTS:'], ['This query returns either 0 (false) or 1 (true).']], [[' SELECT CASE WHEN EXISTS\n(\n    SELECT T1.id_group\n    FROM jos_gj_users T1\n    JOIN jos_gj_users T2\n    ON T1.id_group = T2.id_group\n    WHERE T1.id_user = 20\n    AND T2.id_user = 21\n) THEN 1 ELSE 0 END AS result\n']], ['SQL Query to check if student1 has a course with student 2'], 2, 1], [(4441599, 0), [["Ok so I've done some playing around and based on the following sample data:"], ['You can execute the following Dynamic SQL.']], [[" Create Table TableA\n(\nIDCol int,\nSomeValue varchar(50)\n)\nCreate Table TableB\n(\nIDCol int,\nKEYCol int,\nValue varchar(50)\n)\n\nInsert into TableA\nValues (1, '123223')\nInsert Into TableA\nValues (2,'1232ff')\nInsert into TableA\nValues (3, '222222')\n\nInsert Into TableB\nValues( 23, 1, 435)\nInsert Into TableB\nValues( 24, 1, 436)\n\nInsert Into TableB\nValues( 25, 3, 45)\nInsert Into TableB\nValues( 26, 3, 46)\n\nInsert Into TableB\nValues( 27, 3, 435)\nInsert Into TableB\nValues( 28, 3, 437)\n"]], ['How do I join an unknown number of rows to another row?'], 2, 0], [(4441599, 1), [['You can execute the following Dynamic SQL.'], ['This gives you the following output:']], [[" declare @sql varchar(max)\ndeclare @pivot_list varchar(max)\ndeclare @pivot_select varchar(max)\n\nSelect \n        @pivot_list = Coalesce(@Pivot_List + ', ','') + '[' + Value +']',\n        @Pivot_select = Coalesce(@pivot_Select, ', ','') +'IsNull([' + Value +'],'''') as [' + Value + '],'\nFrom \n(\nSelect distinct Value From dbo.TableB \n)PivotCodes\n\nSet @Sql = '\n;With p as (\n\nSelect a.IdCol,\n        a.SomeValue,\n        b.Value\nFrom dbo.TableA a\nLeft Join dbo.TableB b on a.IdCol = b.KeyCol\n)\nSelect IdCol, SomeValue ' + Left(@pivot_select, Len(@Pivot_Select)-1) + '\nFrom p\nPivot ( Max(Value) for Value in (' + @pivot_list + '\n        )\n    )as pvt\n'\n\nexec (@sql)\n"]], ['How do I join an unknown number of rows to another row?'], 2, 1], [(4459902, 0), [['You could create a function like this:'], ['and then use it like this:']], [[" create function to_base_36 (n integer) return varchar2\nis\n  q integer;\n  r varchar2(100);\nbegin\n  q := n;\n  while q >= 36 loop\n     r := chr(mod(q,36)+case when mod(q,36) < 10 then 48 else 55 end) || r;\n     q := floor(q/36);\n  end loop;\n  r := chr(mod(q,36)+case when mod(q,36) < 10 then 48 else 55 end) || r;\n  return lpad(r,4,'0');\nend;\n"]], ['is it possible to have alphanumeric sequence generator in sql'], 3, 1], [(4459902, 1), [['and then use it like this:'], ['Or, without creating a function:']], [[' select rownum, to_base_36(rownum)\nfrom dual\nconnect by level < 36*36*36*36;\n']], ['is it possible to have alphanumeric sequence generator in sql'], 3, 0], [(4459902, 2), [['Or, without creating a function:'], ['-10000']], [[' with digits as\n( select n, chr(mod(n,36)+case when mod(n,36) < 10 then 48 else 55 end) d\n  from (Select rownum-1 as n from dual connect by level < 37)\n)\nselect d1.n*36*36*36 + d2.n*36*36 + d3.n*36 + d4.n, d1.d||d2.d||d3.d||d4.d\nfrom digits d1, digits d2, digits d3, digits d4\n']], ['is it possible to have alphanumeric sequence generator in sql'], 3, 1], [(4521020, 0), [['Now'], ['There will be an Interval table for looking up what each interval_id stands for.']], [[' Create table Availability (person_id int, interval_id int);\nCreate table Appointment (person_id int, interval_id int, appointment_desc text);\n']], ['Calculate open timeslots given availability and existing appointments - by day'], 3, 0], [(4521020, 1), [['There will be an Interval table for looking up what each interval_id stands for.'], ['Now you can find free intervals as']], [[' Create table Interval(interval_id int primary key, interval_start datetime, interval_end datetime)\n']], ['Calculate open timeslots given availability and existing appointments - by day'], 3, 0], [(4589157, 0), [['For a "complete" pull:'], ['For a single "profile" pull:']], [[' SELECT p.profileID, p.firstName, p.lastName, sc.cprAdultExp, sc.....\nFROM pro_Profile AS p\n   LEFT OUTER JOIN mod_StudentCertifications AS sc ON sc.profileID = p.profileID\nWHERE p.profileID NOT IN\n    (\n       SELECT profileID\n       FROM mod_userStatus\n    )\n;\n']], ['If and only if condition SQL -- SQL server 2008'], 2, 1], [(4589157, 1), [['For a single "profile" pull:'], ["EDIT: Looked at the execution plan of using a LEFT OUTER JOIN for mod_userStatus and checking it's primary key for null VS a NOT IN statement in a similar setup. The NOT IN statement is indeed less costly. "]], [[' SELECT p.profileID, p.firstName, p.lastName, sc.cprAdultExp, sc.....\nFROM pro_Profile AS p\n   LEFT OUTER JOIN mod_StudentCertifications AS sc ON sc.profileID = p.profileID\nWHERE p.profileID = ?\n    AND p.profileID NOT IN      \n    (\n       SELECT profileID\n       FROM mod_userStatus\n       WHERE profileID = ?\n    )\n;\n']], ['If and only if condition SQL -- SQL server 2008'], 2, 1], [(4598659, 1), [['Edit : Try this'], ['-10000']], [[' WITH  Years\n          AS (\n              SELECT DATEPART(year, GETDATE()) [Year]\n              UNION ALL\n              SELECT [Year]-1\n                FROM Years\n                WHERE [Year] > @YearToGet\n             )\n    SELECT DIVISION, DYYYY, SUM(APRICE) AS Sales, SUM(PARTY) AS PAX, SUM(NetAmount) AS NetSales, SUM(InsAmount) AS InsSales, SUM(CancelRevenue) AS CXSales, SUM(OtherAmount) AS OtherSales, SUM(CXVALUE) AS CXValue\n      FROM dbo.B101BookingsDetails \n      JOIN Years yr ON DYYYY = yr.[Year]\n      WHERE Booked <= CONVERT(int, DATEADD(year, DYYYY-YEAR(GETDATE()), DATEADD(day, DATEDIFF(day, 2, GETDATE()), 0)))\n      GROUP BY DYYYY, DIVISION\n      ORDER BY DIVISION, DYYYY\n    OPTION (MAXRECURSION 0);\n']], ['sql stored procedure loop'], 2, 1], [(4621932, 0), [['-10000'], ['I have PL/SQL code that wites it to the file system using a DIRECTORY:']], [[' DBMS_XMLDOM.WRITETOBUFFER  Writes the contents of the node to a buffer.\nDBMS_XMLDOM.WRITETOCLOB    Writes the contents of the node to a CLOB.\nDBMS_XMLDOM.WRITETOFILE    Writes the contents of the node to a file.\n']], ['Oracle: How do I display DBMS_XMLDOM.DOMDocument for debugging?'], 6, 1], [(4621932, 1), [['I have PL/SQL code that wites it to the file system using a DIRECTORY:'], ['I have created a function using dbms_xmldom.writetoclob']], [["    dbms_xmldom.writeToFile(dbms_xmldom.newDOMDocument( xmldoc)\n                                       ,'DATAPUMPDIR/myfile.xml') ;\n"]], ['Oracle: How do I display DBMS_XMLDOM.DOMDocument for debugging?'], 6, 1], [(4621932, 2), [['I have created a function using dbms_xmldom.writetoclob'], ['Query:']], [["    create or replace function xml2clob (xmldoc XMLType) return CLOB is\n     clobdoc CLOB := ' ';\n   begin\n     dbms_xmldom.writeToClob(dbms_xmldom.newDOMDocument( xmldoc)\n                                       ,clobdoc) ;\n     return clobdoc;\n   end;\n   /\n"]], ['Oracle: How do I display DBMS_XMLDOM.DOMDocument for debugging?'], 6, 1], [(4621932, 3), [['Query:'], ['Output:']], [[' SELECT xml2clob(Sys_Xmlagg(\n         Xmlelement(Name "dummy"\n                   ,dummy\n                   ),Xmlformat(\'dual\')))\n   FROM dual;\n']], ['Oracle: How do I display DBMS_XMLDOM.DOMDocument for debugging?'], 6, 0], [(4621932, 4), [['Output:'], ['You could try using a function like this:']], [[' <?xml version="1.0"?>\n<dual>\n  <dummy>X</dummy>\n</dual>\n']], ['Oracle: How do I display DBMS_XMLDOM.DOMDocument for debugging?'], 6, 0], [(4621932, 5), [['You could try using a function like this:'], ['-10000']], [["    create or replace function dom2clob (domdoc  DBMS_XMLDOM.DOMDocument) return CLOB is\n     clobdoc CLOB := ' ';\n   begin\n     dbms_xmldom.writeToClob(domdoc,clobdoc) ;\n     return clobdoc;\n   end;\n   /\n"]], ['Oracle: How do I display DBMS_XMLDOM.DOMDocument for debugging?'], 6, 1], [(4761507, 0), [['Create links representing every letter and number. Clicking these links will provide the users with the results from the database that begin with the selected character.'], ['This command will select the first 100 records from the desired character group:']], [[' SELECT title FROM table\nWHERE LEFT(title,1) = ?Char\nORDER BY title ASC;\n']], ['Matching first char in string to digit or non-standard character'], 4, 1], [(4761507, 1), [['This command will select the first 100 records from the desired character group:'], ['This command will select the second 100 records from the desired character group:']], [[' SELECT title FROM table\nWHERE LEFT(title,1) = ?Char\nORDER BY title ASC\nLIMIT 0, 100;\n']], ['Matching first char in string to digit or non-standard character'], 4, 1], [(4761507, 2), [['This command will select the second 100 records from the desired character group:'], ['Per your comments, if you want to combine characters 0-9  without  using regex, you will need to combine several  OR  statements:']], [[' SELECT title FROM table\nWHERE LEFT(title,1) = ?Char\nORDER BY title ASC\nLIMIT 100, 100;\n']], ['Matching first char in string to digit or non-standard character'], 4, 1], [(4773206, 0), [['Give this a try'], ['This can also be written']], [[' Update t\nSet t.yyyy = q.Name\nFrom TableToUpdate t\nJoin AddressTable q on q.Address = t.Address\n']], ['how to update using nested query in SQL'], 2, 1], [(4773206, 1), [['This can also be written'], ['Since the update table is accessible in the FROM/WHERE clauses, except it cannot be aliased.']], [[' Update TableToUpdate\nSet yyyy = q.Name\nFrom AddressTable q\nWHERE q.Address = TableToUpdate.Address\n']], ['how to update using nested query in SQL'], 2, 1], [(4787104, 0), [['If your Oracle version is recent enough, you can use SUM - OVER() to show the SUM (grouped) against every data row.'], ['Alternatively, you need to make an aggregate out of the  Site ,  Desk  columns']], [[' SELECT  \n    IMPORTID,Site,Desk,Region,RefObligor,\n    SUM(NOTIONAL) OVER(PARTITION BY IMPORTID, Region,RefObligor) AS SUM_NOTIONAL\nFrom \n    Positions\nWhere\n    ID = :importID\nOrder BY \n    IMPORTID,Region,Site,Desk,RefObligor\n']], ['How to Select and Order By columns not in Groupy By SQL statement - Oracle'], 2, 1], [(4787104, 1), [['Alternatively, you need to make an aggregate out of the  Site ,  Desk  columns'], ['-10000']], [[' SELECT  \n    IMPORTID,Region,Min(Site) Site, Min(Desk) Desk,RefObligor,SUM(NOTIONAL) AS SUM_NOTIONAL\nFrom \n    Positions\nWhere\n    ID = :importID\nGROUP BY \n    IMPORTID, Region,RefObligor\nOrder BY \n    IMPORTID, Region,Min(Site),Min(Desk),RefObligor\n']], ['How to Select and Order By columns not in Groupy By SQL statement - Oracle'], 2, 1], [(4821831, 0), [["First, start with a key generation table. It will contain 1 row for each company, containing your company identifier and an integer counter that we'll be bumping up each time an insert is performed."], ['Here you go:']], [[' create table dbo.CustomerNumberGenerator\n(\n  company     varchar(8) not null ,\n  curr_value  int        not null default(1) ,\n\n  constraint CustomerNumberGenerator_PK primary key clustered ( company ) ,\n\n)\n']], ['sql server: generate primary key based on counter and another column value'], 2, 0], [(4823208, 0), [['-10000'], ['The above query assumes that you can get']], [[' select a.id, b.id\nfrom people1 a\ninner join people1 b on a.id < b.id\nwhere not exists (\n    select *\n    from pairs1 c\n    where c.person_a_id = a.id\n      and c.person_b_id = b.id)\norder by a.id * rand()\nlimit 1;\n']], ['How do I select unique pairs of rows from a table at random?'], 4, 1], [(4823208, 1), [['The above query assumes that you can get'], ["and that the pairing  2 - 7  is valid since it doesn't exist, even if 2 is featured again.  If you only want a person to feature in  only one  pair ever, then"]], [[' 1 - 2\n2 - 7\n']], ['How do I select unique pairs of rows from a table at random?'], 4, 0], [(4823208, 2), [["and that the pairing  2 - 7  is valid since it doesn't exist, even if 2 is featured again.  If you only want a person to feature in  only one  pair ever, then"], ['If  multiple pairs  are to be generated in one single query,  AND  the destination table is still empty, you could use this single query.  Take note that  LIMIT 6  returns only 3 pairs.']], [[' select a.id, b.id\nfrom people1 a\ninner join people1 b on a.id < b.id\nwhere not exists (\n    select *\n    from pairs1 c\n    where c.person_a_id in (a.id, b.id))\n  and not exists (\n    select *\n    from pairs1 c\n    where c.person_b_id in (a.id, b.id))\norder by a.id * rand()\nlimit 1;\n']], ['How do I select unique pairs of rows from a table at random?'], 4, 1], [(4823208, 3), [['If  multiple pairs  are to be generated in one single query,  AND  the destination table is still empty, you could use this single query.  Take note that  LIMIT 6  returns only 3 pairs.'], ['-10000']], [[' select min(a) a, min(b) b\nfrom\n(\n    select\n      case when mod(@p,2) = 1 then id end a,\n      case when mod(@p,2) = 0 then id end b,\n      @p:=@p+1 grp\n    from (\n        select id\n        from (select @p:=1) p, people1\n        order by rand()\n        limit 6\n    ) x\n) y\ngroup by floor(grp/2)\n']], ['How do I select unique pairs of rows from a table at random?'], 4, 1], [(4841038, 1), [['Use this to create a table with >100K records, with roughly 1K rows matching the filter  i in (2,3)  and 1K rows matching  j in (2,3) :'], ['When doing:']], [[' drop table if exists t1;\ncreate table t1 (id int auto_increment primary key, i int, j int);\ncreate index ix_t1_on_i on t1(i);\ncreate index ix_t1_on_j on t1(j);\ninsert into t1 (i,j) values (2,2),(2,3),(4,5),(6,6),(2,6),(2,7),(3,2);\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i*2, j*2+i from t1;\ninsert into t1 (i,j) select i, j from t1;\ninsert into t1 (i,j) select i, j from t1;\ninsert into t1 (i,j) select 2, j from t1 where not j in (2,3) limit 1000;\ninsert into t1 (i,j) select i, 3 from t1 where not i in (2,3) limit 1000;\n']], ['Force MySQL to use two indexes on a Join'], 7, 0], [(4841038, 2), [['When doing:'], ['you get exactly 8 matches:']], [[' select t.* from t1 as t where t.i=2 and t.j=3 or t.i=3 and t.j=2\n']], ['Force MySQL to use two indexes on a Join'], 7, 0], [(4841038, 3), [['you get exactly 8 matches:'], ['Use  EXPLAIN  on the query above to get:']], [[' +-------+------+------+\n| id    | i    | j    |\n+-------+------+------+\n|     7 |    3 |    2 |\n| 28679 |    3 |    2 |\n| 57351 |    3 |    2 |\n| 86023 |    3 |    2 |\n|     2 |    2 |    3 |\n| 28674 |    2 |    3 |\n| 57346 |    2 |    3 |\n| 86018 |    2 |    3 |\n+-------+------+------+\n']], ['Force MySQL to use two indexes on a Join'], 7, 0], [(4841038, 4), [['Use  EXPLAIN  on the query above to get:'], ['To make it collect across two indexes, and then intersect them, use this:']], [[' id | select_type | table | type  | possible_keys         | key        | key_len | ref  | rows | Extra\n1  | SIMPLE      | t     | range | ix_t1_on_i,ix_t1_on_j | ix_t1_on_j | 5       | NULL | 1012 | Using where\n']], ['Force MySQL to use two indexes on a Join'], 7, 0], [(4841038, 6), [['Use that query with  explain  to get:'], ['This proves that the indexes are being used. But that may or may not be faster depending on many other factors.']], [[' id | select_type | table | type  | possible_keys | key        | key_len | ref  | rows | Extra\n1  | SIMPLE      | a     | range | ix_t1_on_i    | ix_t1_on_i | 5       | NULL | 1019 | Using where\n1  | SIMPLE      | b     | range | ix_t1_on_j    | ix_t1_on_j | 5       | NULL | 1012 | Using where; Using index\n']], ['Force MySQL to use two indexes on a Join'], 7, 0], [(4857837, 0), [['The literal interpretation would lead to'], ['And the next step to']], [[' select top 1000 from tbl order by columnname\n']], ['SQL query that can select n rows order by and then return m row'], 5, 0], [(4857837, 3), [['Unless you are after 2 different orderings'], ['or switching between asc/desc']], [[' SELECT TOP 100\nFROM (\n   select top 1000 from tbl\n   order by columnname) SQ\nORDER BY othercolumn\n']], ['SQL query that can select n rows order by and then return m row'], 5, 1], [(4857837, 4), [['or switching between asc/desc'], ['-10000']], [[' SELECT TOP 100\nFROM (\n   select top 1000 from tbl\n   order by columnname ASC) SQ\nORDER BY columnname DESC\n']], ['SQL query that can select n rows order by and then return m row'], 5, 1], [(4866013, 0), [['the count of the different  category_codes  used:'], ['count of the different  unique_codes  used:']], [[" category_codes_cnt = Item.objects.values('category_codes').distinct().count()\n"]], ['Merging rows when counting - Django/SQL'], 3, 1], [(4866013, 1), [['count of the different  unique_codes  used:'], ['count of the different  combination of category_code and unique_code  used:']], [[" unique_codes_cnt = Item.objects.values('unique_codes').distinct().count()\n"]], ['Merging rows when counting - Django/SQL'], 3, 1], [(4866013, 2), [['count of the different  combination of category_code and unique_code  used:'], ['-10000']], [[" codes_cnt = Item.objects.values('category_codes', 'unique_codes').distinct().count()\n"]], ['Merging rows when counting - Django/SQL'], 3, 1], [(4890793, 0), [['Hash column should be a  CHAR(32)  as that is the length of the hash:'], ['If you want to select from the table given user input:']], [[' CREATE TABLE `hashes` (\n    `id` INT NOT NULL AUTO_INCREMENT, \n    `hash` CHAR(32), \n    PRIMARY KEY (`id`)\n);\n\nmysql> describe hashes;\n+-------+----------+------+-----+---------+----------------+\n| Field | Type     | Null | Key | Default | Extra          |\n+-------+----------+------+-----+---------+----------------+\n| id    | int(11)  | NO   | PRI | NULL    | auto_increment |\n| hash  | char(32) | YES  |     | NULL    |                |\n+-------+----------+------+-----+---------+----------------+\n']], ['MySQL database for hashes'], 2, 1], [(4890793, 1), [['If you want to select from the table given user input:'], ['You can add a key on  hash  for better performance.']], [[" -- Insert sample data:\nmysql> INSERT INTO `hashes` VALUES (null, MD5('hello'));\nQuery OK, 1 row affected (0.00 sec)\n\n-- Test retrieval:\nmysql> SELECT * FROM `hashes` WHERE `hash` = MD5('hello');\n+----+----------------------------------+\n| id | hash                             |\n+----+----------------------------------+\n|  1 | 5d41402abc4b2a76b9719d911017c592 |\n+----+----------------------------------+\n1 row in set (0.00 sec)\n"]], ['MySQL database for hashes'], 2, 1], [(4914898, 0), [['If your formatting is EXACTLY'], ['Then use this WHERE clause']], [[' N1, N2 (e.g.) one comma and space between each N\n']], ['Selecting a record based on integer being in an array field'], 4, 0], [(4914898, 2), [['The addition of the prefix and suffix makes every number, anywhere in the list, consistently wrapped by comma-space and suffixed by comma.  Otherwise, you may get false positives with 53 appearing in part of another number.'], ['Then you can use']], [[' House\n+---------+----------------------+----------+\n| HouseID | HouseType | Description | Title |\n+---------+----------------------+----------+\n| 21      | B         | data        | data  |\n| 23      | B         | data        | data  |\n| 24      | B         | data        | data  |\n| 23      | B         | data        | data  |\n+---------+----------------------+----------+\n\nHouseArea\n+---------+-------\n| HouseID | AreaID\n+---------+-------\n| 21      | 17\n| 21      | 32\n| 21      | 53\n| 23      | 23\n| 23      | 73\n..etc\n']], ['Selecting a record based on integer being in an array field'], 4, 0], [(4914898, 3), [['Then you can use'], ['-10000']], [[' select * from house h\nwhere exists (\n    select *\n    from housearea a\n    where h.houseid=a.houseid and a.areaid=53)\n']], ['Selecting a record based on integer being in an array field'], 4, 0], [(4948269, 0), [['In SQL Server'], ['Or (more standard)']], [[" use master\n\nSELECT COLUMNPROPERTY( OBJECT_ID('dbo.spt_values'),'number','AllowsNull')\n"]], ['SQL : Test if a column has the "Not Null" property'], 2, 1], [(4948269, 1), [['Or (more standard)'], ['-10000']], [[" select IS_NULLABLE \nfrom INFORMATION_SCHEMA.COLUMNS \nwhere TABLE_SCHEMA='dbo' \n      AND TABLE_NAME='spt_values' \n      AND COLUMN_NAME='number'\n"]], ['SQL : Test if a column has the "Not Null" property'], 2, 1], [(4960337, 0), [['-10000'], ['The following query instead finds all cases where the LAST A purchase is 6 months or more before the FIRST D purchase.']], [[' select A.CustID, ElapsedDays = datediff(d, A.InvoiceDate, B.InvoiceDate)\nfrom Orders A\ninner join Orders B on B.CustID = A.CustID\n    and B.ProdID = 312\n    -- more than 6 months ago\n    and B.InvoiceDate > dateadd(m,6,A.InvoiceDate)\nwhere A.ProdID = 105\n']], ['How find Customers who Bought Product A and D > 6 months apart?'], 3, 1], [(4960337, 1), [['The following query instead finds all cases where the LAST A purchase is 6 months or more before the FIRST D purchase.'], ["And if for the same scenario above, you don't want to see this customer because the A (Jul) and D (Sep) purchases are not 6 months apart, you can exclude them from the first query using an  EXISTS  filter."]], [[' select A.CustID, ElapsedDays = datediff(d, A.InvoiceDate, B.InvoiceDate)\nfrom (\n    select CustID, Max(InvoiceDate) InvoiceDate\n    from Orders\n    where ProdID = 105\n    group by CustID) A\ninner join (\n    select CustID, Min(InvoiceDate) InvoiceDate\n    from Orders\n    where ProdID = 312\n    group by CustID) B on B.CustID = A.CustID\n    -- more than 6 months ago\n    and B.InvoiceDate > dateadd(m,6,A.InvoiceDate)\n']], ['How find Customers who Bought Product A and D > 6 months apart?'], 3, 1], [(4960337, 2), [["And if for the same scenario above, you don't want to see this customer because the A (Jul) and D (Sep) purchases are not 6 months apart, you can exclude them from the first query using an  EXISTS  filter."], ['-10000']], [[' select A.CustID, ElapsedDays = datediff(d, A.InvoiceDate, B.InvoiceDate)\nfrom Orders A\ninner join Orders B on B.CustID = A.CustID\n    and B.ProdID = 312\n    -- more than 6 months ago\n    and B.InvoiceDate > dateadd(m,6,A.InvoiceDate)\nwhere A.ProdID = 105\n  AND NOT EXISTS (\n    SELECT *\n    FROM Orders C\n    WHERE C.CustID=A.CustID\n    AND C.InvoiceDate > A.InvoiceDate\n    and C.InvoiceDate < B.InvoiceDate\n    and C.ProdID in (105,312))\n']], ['How find Customers who Bought Product A and D > 6 months apart?'], 3, 1], [(4971561, 0), [['Reverse your comparison!'], ['Good luck']], [[' SELECT * FROM reg WHERE tree=\'/20/1/1/1/1\' OR \'/20/1/1/1/1\' LIKE CONCAT(tree, "/%");\n']], ['traversing a tree upwards'], 2, 1], [(4971561, 1), [['Good luck'], ['-10000']], [[' mysql> create table temp_reg (tree varchar(255));\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> insert into temp_reg values (\'/20/1/1/1/1\'),(\'/30/1/1/1\'),(\'/20/1\');\nQuery OK, 3 rows affected (0.00 sec)\nRecords: 3  Duplicates: 0  Warnings: 0\n\nmysql> select * from temp_reg where \'/20/1/1/1/1\' LIKE CONCAT(tree, "%");\n+-------------+\n| tree        |\n+-------------+\n| /20/1/1/1/1 |\n| /20/1       |\n+-------------+\n2 rows in set (0.00 sec)\n']], ['traversing a tree upwards'], 2, 0], [(4986731, 0), [['Use the  FIND_IN_SET function :'], ['Or use a CASE statement:']], [[" SELECT e.* \n  FROM EMPLOYEE e \n WHERE e.code in (1,3,2,4) \nORDER BY FIND_IN_SET(e.code, '1,3,2,4')\n"]], ['How to select mysql rows in the order of IN clause'], 2, 1], [(4986731, 1), [['Or use a CASE statement:'], ['-10000']], [[' SELECT e.* \n  FROM EMPLOYEE e \n WHERE e.code in (1,3,2,4) \nORDER BY CASE e.code\n           WHEN 1 THEN 1 \n           WHEN 3 THEN 2\n           WHEN 2 THEN 3\n           WHEN 4 THEN 4\n         END\n']], ['How to select mysql rows in the order of IN clause'], 2, 1], [(5020149, 0), [['-10000'], ['example']], [[" select * from daily_meal where type = 'fruit' limit 1\nunion\nselect * from daily_meal where type = 'vegetable'\n"]], ['Limit SQL result by type (column value)'], 2, 1], [(5020149, 1), [['example'], ['-10000']], [[" mysql> desc daily_meal;\n+-------+--------------+------+-----+---------+-------+\n| Field | Type         | Null | Key | Default | Extra |\n+-------+--------------+------+-----+---------+-------+\n| name  | varchar(100) | YES  |     | NULL    |       |\n| type  | varchar(100) | YES  |     | NULL    |       |\n+-------+--------------+------+-----+---------+-------+\n2 rows in set (0.00 sec)\n\nmysql> select * from daily_meal;\n+----------+-----------+\n| name     | type      |\n+----------+-----------+\n| apple    | fruit     |\n| potato   | vegetable |\n| eggplant | vegetable |\n| cucumber | vegetable |\n| lemon    | fruit     |\n| orange   | fruit     |\n| carrot   | vegetable |\n+----------+-----------+\n7 rows in set (0.00 sec)\n\nmysql> select * from daily_meal where type = 'fruit' limit 1\n    -> union\n    -> select * from daily_meal where type = 'vegetable';\n+----------+-----------+\n| name     | type      |\n+----------+-----------+\n| apple    | fruit     |\n| potato   | vegetable |\n| eggplant | vegetable |\n| cucumber | vegetable |\n| carrot   | vegetable |\n+----------+-----------+\n5 rows in set (0.00 sec)\n"]], ['Limit SQL result by type (column value)'], 2, 1], [(5081080, 0), [['If I understand correctly you just need to define the "var" variable...'], ["Depending on exactly what you're doing, there may be a better approach that doesn't need the SELECT ... FROM DUAL:"]], [[' create or replace FUNCTION EXAMPLE (param IN VARCHAR2)\nRETURN NUMBER\nAS\n   var VARCHAR2(100);  -- This datatype may need modification\nBEGIN\n  select <string_handling>\n  into   var\n  from   dual;\n\n  return to_number(<some computation using var>);\nEND EXAMPLE ;\n']], ['Oracle Pl/SQl: custom function with intermediate results'], 2, 1], [(5081080, 1), [["Depending on exactly what you're doing, there may be a better approach that doesn't need the SELECT ... FROM DUAL:"], ['-10000']], [[' create or replace FUNCTION EXAMPLE (param IN VARCHAR2)\nRETURN NUMBER\nAS\n   var VARCHAR2(100);  -- This datatype may need modification\nBEGIN\n  var := <string_handling>;\n\n  return to_number(<some computation using var>);\nEND EXAMPLE ;\n']], ['Oracle Pl/SQl: custom function with intermediate results'], 2, 1], [(5087616, 1), [['With a working example, that would be'], ['resulting in']], [[" create table tq84_order_by (\n  txt   varchar2(10),\n  money number not null\n);\n\ninsert into tq84_order_by values ('aaa', 0);\ninsert into tq84_order_by values ('bbb', 2);\ninsert into tq84_order_by values ('ccc',-3);\ninsert into tq84_order_by values ('ddd', 4);\ninsert into tq84_order_by values ('eee', 1);\n\nselect * from tq84_order_by\norder by \ncase when money = 0 then 0\n                    else 1 \n                    end desc,\n                    money desc;\n"]], ['Dynamically get the maximum and minimum allowable value for a number column?'], 3, 1], [(5087616, 2), [['resulting in'], ['-10000']], [[' TXT             MONEY\n---------- ----------\nddd                 4\nbbb                 2\neee                 1\nccc                -3\naaa                 0    \n']], ['Dynamically get the maximum and minimum allowable value for a number column?'], 3, 0], [(5093557, 0), [["Let's say the table starts like this."], ["Let's also say that 75 is supposed to be 76. Assuming a sane user interface, the user can just change 75 to 76. A sane user interface would send this statement to the dbms."]], [[' order_accessories\nPK_refno  PK_acc\n1         73\n1         74\n1         75\n1         86\n1         92\n']], ['Updating intersection tables, alternative to delete->insert'], 3, 0], [(5111728, 0), [['ANSI compliant. Each specific DBMS may have a faster implementation'], ['Better written as a JOIN']], [[' select *\nfrom tbl\nwhere id in-- PARENTS of CHILDREN that match\n(   select parent_id from tbl\n    where values0 > 10 and has_children = 0)\nor id in   -- ONE CHILD ONLY\n(   select MIN(id) from tbl\n    where values0 > 10 and has_children = 0\n    group by parent_id)\nor id in   -- PARENTS\n(   select id from tbl\n    where values0 > 10 and has_children = 1)\n']], ['sql select puzzle: remove children when parent is filtered out'], 2, 1], [(5111728, 1), [['Better written as a JOIN'], ['-10000']], [[' select t.*\nfrom \n(   select parent_id as ID from tbl\n    where values0 > 10 and has_children = 0\n    UNION\n    select MIN(id) from tbl\n    where values0 > 10 and has_children = 0\n    group by parent_id\n    UNION\n    select id from tbl\n    where values0 > 10 and has_children = 1) X\njoin tbl t on X.ID = t.ID\n']], ['sql select puzzle: remove children when parent is filtered out'], 2, 1], [(5171809, 0), [["For 1, you'd do something like this:"], ["For 2, you'd do something like this:"]], [[" if @param = 'value'\n    select Col1, Col2 from Table1\nelse\n    select Col1, Col2 from Table2\n"]], ['Edit query based on parameters in SQL Reporting Services'], 2, 1], [(5171809, 1), [["For 2, you'd do something like this:"], ["WARNING:  Be very careful of option 2. If option 1 is feasible, then it is the safer option, as dynamically constructing SQL based upon user-supplied values is always a dangerous affair. While this particular example doesn't use the parameter directly in the SQL, it would be very easy to write something that did, and thus very easy to find a way to exploit it."]], [[" declare @sql nvarchar(4000)\n\nselect @sql = 'select Col1, Col2 from' + (case when @param = 'value' then 'Table1' else 'Table2' end)\n\nsp_executesql @sql\n"]], ['Edit query based on parameters in SQL Reporting Services'], 2, 1], [(5182723, 0), [['For your example:'], ['You can also use DIFFERENCE function (on same link as soundex) that will compare levels of similarity (4 being the most similar, 0 being the least).']], [[" select SOUNDEX('Dinosaurs'), SOUNDEX('Dinosores')\n"]], ['SQL - searching database with the LIKE operator'], 2, 1], [(5182723, 1), [['You can also use DIFFERENCE function (on same link as soundex) that will compare levels of similarity (4 being the most similar, 0 being the least).'], ['Edit:  ']], [[" SELECT DIFFERENCE('Dinosaurs', 'Dinosores'); --returns 4\n"]], ['SQL - searching database with the LIKE operator'], 2, 1], [(5282607, 0), [['You can add condition that tells "This Code must have a row with CT" sa do a sub-query:'], ['And to your first query add a filter to show only those records which have Code in previous subquery:']], [[" SELECT Code FROM transaction WHERE kind='CT' GROUP BY Code ;\n"]], ['How to Filter grouped query result set (SQL)'], 2, 0], [(5282607, 1), [['And to your first query add a filter to show only those records which have Code in previous subquery:'], ['This will get rid of record Code 2, because 2 will no be in results from first query']], [[" ... AND Code IN (SELECT Code FROM transaction WHERE kind='CT' GROUP BY Code ) ...\n"]], ['How to Filter grouped query result set (SQL)'], 2, 0], [(5290418, 0), [['Example calls'], ['Script']], [[' call insert_employee(\'f00\',32);\ncall insert_employee(\'bar\',64);\n\n$sql = sprintf("call insert_employee(\'%s\',%d)", $name, $age);\n']], ["How to insert a row's primary key in to another one of its columns?"], 2, 0], [(5290418, 1), [['Script'], ['-10000']], [[' drop table if exists employees;\ncreate table employees\n(\nid int unsigned not null auto_increment primary key,\nname varchar(32) not null,\nage tinyint unsigned not null default 0,\npid int unsigned not null default 0\n)\nengine=innodb;\n\ndrop procedure if exists insert_employee;\n\ndelimiter #\n\ncreate procedure insert_employee\n(\nin p_name varchar(32),\nin p_age tinyint unsigned\n)\nbegin\n\ndeclare v_id int unsigned default 0;\n\n  insert into employees(name, age) values (p_name, p_age);\n  set v_id = last_insert_id();\n  update employees set pid = v_id where id = v_id;\nend#\n\ndelimiter ;\n']], ["How to insert a row's primary key in to another one of its columns?"], 2, 1], [(5292145, 1), [["If your database doesn't support  TOP  or for performance reasons you would prefer to avoid the  ORDER BY  you could try something like:"], ['-10000']], [[' SELECT E.UserID\n    , E.EntryDate\n    , (SELECT S1.Detail\n       FROM Status AS S1\n       WHERE S1.UserID = E.UserID\n       AND S1.StatusDate = (SELECT MAX(S2.StatusDate)\n                            FROM Status AS S2\n                            WHERE S2.UserID = E.UserID\n                            AND S2.StatusDate <= E.EntryDate))\nFROM Entry AS E\n']], ['SQL query for maximum date'], 2, 1], [(5331808, 0), [['You can use  UNION ALL  to get rows from both tables:'], ['-10000']], [[" SELECT id, article, author, tag, date FROM table1 WHERE tag = '1'\nUNION ALL\nSELECT id, article, author, tag, date FROM table2 WHERE tag = '3'\nORDER BY date\n"]], ['How do I combine the results of two queries with ordering?'], 2, 1], [(5355585, 0), [['Try using  MAX  with a  GROUP BY .'], ['-10000']], [[' SELECT u.userName, MAX(c.carPrice)\nFROM users u\n    LEFT JOIN cars c ON u.id = c.belongsToUser\nWHERE u.id = 4;\nGROUP BY u.userName;\n']], ['how to sort order of LEFT JOIN in SQL query?'], 3, 1], [(5355585, 1), [['-10000'], ['Then if we want to find the maximum temperature by location, then we need to split the temperature records into groupings, where each record in a particular group has the same location. We then want to find the maximum temperature of each group. The query to do this would be as follows:']], [[' Location   Time    Temperature\n--------   ----    -----------\nLondon     12:00          10.0\nBristol    12:00          12.0\nGlasgow    12:00           5.0\nLondon     13:00          14.0\nBristol    13:00          13.0\nGlasgow    13:00           7.0\n...\n']], ['how to sort order of LEFT JOIN in SQL query?'], 3, 0], [(5355585, 2), [['Then if we want to find the maximum temperature by location, then we need to split the temperature records into groupings, where each record in a particular group has the same location. We then want to find the maximum temperature of each group. The query to do this would be as follows:'], ['-10000']], [[' SELECT Location, MAX(Temperature)\nFROM Temperatures\nGROUP BY Location;\n']], ['how to sort order of LEFT JOIN in SQL query?'], 3, 0], [(5380843, 0), [["For what you've asked, it sounds like you have a supertype-subtype relationship, which  is  a standard database design pattern. In this case, you have a single supertype table that represents the parent:"], ['Then you have one or more tables that define subtypes:']], [[' Location\n---------------\nLocationID (PK)\n...other common attributes\n']], ['Polymorphic ORM database pattern'], 4, 0], [(5380843, 1), [['Then you have one or more tables that define subtypes:'], ['Given this, a simple model would look like this:']], [[' Address\n-----------\nLocationID (PK, FK to Location)\n...address-specific attributes\n\nCountry\n-----------\nLocationID (PK, FK to Location)\n...country-specific attributes\n']], ['Polymorphic ORM database pattern'], 4, 0], [(5380843, 2), [['Given this, a simple model would look like this:'], ['Our two nullable fields are  City  and  Address . I am going to assume that having an  Address  without a  City  would be nonsense. In this case, we remove these two attributes from the  LocationPostal  table and create two more tables:']], [[" Location\n------------\nLocationID (PK)\nLocationType (non-nullable) ('C' for coordinate, 'P' for postal)\n\nLocationCoordinate\n------------------\nLocationID (PK; FK to Location)\nLatitude (non-nullable)\nLongitude (non-nullable)\n\nLocationPostal\n------------------\nLocationID (PK, FK to Location)\nCountry (non-nullable)\nCity (nullable)\nAddress (nullable)\n"]], ['Polymorphic ORM database pattern'], 4, 0], [(5380843, 3), [['Our two nullable fields are  City  and  Address . I am going to assume that having an  Address  without a  City  would be nonsense. In this case, we remove these two attributes from the  LocationPostal  table and create two more tables:'], ['-10000']], [[' LocationPostalCity\n------------------\nLocationID (PK; FK to LocationPostal)\nCity (non-nullable)\n\nLocationPostalCityAddress\n-------------------------\nLocationID (PK; FK to LocationPostalCity)\nAddress (non-nullable)\n']], ['Polymorphic ORM database pattern'], 4, 0], [(5393244, 0), [['Do the same thing as in the  answer you referenced , but change the XPath expression (second argument to XMLTYPE) from'], ['to e.g.']], [[" '//SOAProxyResult'\n"]], ['PLSQL read value from XML (Again)?'], 4, 0], [(5393244, 1), [['to e.g.'], ['or']], [[" '//t:ItemId/@Id'\n"]], ['PLSQL read value from XML (Again)?'], 4, 0], [(5393244, 2), [['or'], ['The third argument will need to declare the t namespace prefix:']], [[" '//t:ItemId/@ChangeKey'\n"]], ['PLSQL read value from XML (Again)?'], 4, 0], [(5393244, 3), [['The third argument will need to declare the t namespace prefix:'], ['and of course your input XML will need to declare that namespace prefix too.']], [[' \'xmlns:t="foobarbaz"\'\n']], ['PLSQL read value from XML (Again)?'], 4, 0], [(5410918, 0), [["This will return tomorrow's data"], ["This will return today's data"]], [[' WHERE ChangingDate > = dateadd(dd, datediff(dd, 0, getdate())+1, 0)\nand ChangingDate < dateadd(dd, datediff(dd, 0, getdate())+2, 0)\n']], ['composing a SQL query with a date offset'], 2, 1], [(5410918, 1), [["This will return today's data"], ['See also  How Does Between Work With Dates In SQL Server?']], [[' WHERE ChangingDate > = dateadd(dd, datediff(dd, 0, getdate())+0, 0)\nand ChangingDate < dateadd(dd, datediff(dd, 0, getdate())+1, 0)\n']], ['composing a SQL query with a date offset'], 2, 1], [(5455914, 0), [["This doesn't work?"], ['update trigger']], [[' CREATE TRIGGER trig_pano_raw BEFORE INSERT ON pano_raw\nFOR EACH ROW\nBEGIN\n    SET NEW.latlng = PointFromWKB( POINT( NEW.lat, NEW.lng ) );\nEND;\n']], ['TRIGGER based on spatial data'], 2, 0], [(5455914, 1), [['update trigger'], ['-10000']], [[' DELIMITER $$\nCREATE TRIGGER trig_Update_pano_raw BEFORE UPDATE ON pano_raw\nFOR EACH ROW\nBEGIN\n    IF ((NEW.lat != OLD.lat) OR (NEW.lng != OLD.lng))\n    THEN\n        SET NEW.latlng = PointFromWKB( POINT( NEW.lat, NEW.lng ) );\n    ELSEIF (NEW.latlng != OLD.latlng)\n    THEN\n        BEGIN\n            SET NEW.lat = X(NEW.latlng);\n            SET NEW.lng = Y(NEW.latlng);\n        END;\n    END IF;\nEND;$$\nDELIMITER ;\n']], ['TRIGGER based on spatial data'], 2, 1], [(5462205, 0), [['In  Oracle  and  PostgreSQL , it is calculated using a window function:'], ['In  MySQL , you can calculate it using session variables:']], [[' SELECT  id, val, SUM() OVER (ORDER BY id ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\nFROM    mytable\n']], ['MySQL SELECT function to sum current data'], 3, 1], [(5479975, 0), [["I won't comment on whether there is a better suited schema for doing this (it's quite possible), but for a schema having columns  name  and  item , the following query should work. (mysql syntax)"], ["Edit:  The idea behind collapsars answer seems to be much better than mine, so here's a bit shorter version of that with explanation."]], [[' SELECT k.name\nFROM (SELECT DISTINCT name FROM sets) AS k\nINNER JOIN sets i1 ON (k.name = i1.name AND i1.item = 1)\nINNER JOIN sets i2 ON (k.name = i2.name AND i2.item = 3)\nINNER JOIN sets i3 ON (k.name = i3.name AND i3.item = 5)\nLEFT JOIN sets ix ON (k.name = ix.name AND ix.item NOT IN (1, 3, 5))\nWHERE ix.name IS NULL;\n']], ['query for a set in a relational database'], 3, 1], [(5479975, 1), [["Edit:  The idea behind collapsars answer seems to be much better than mine, so here's a bit shorter version of that with explanation."], ['Edit:  It just dawned on me how to do this without the exclusion.']], [[' SELECT sets.name\nFROM sets\nLEFT JOIN (\n    SELECT DISTINCT name\n    FROM sets\n    WHERE item NOT IN (1, 3, 5)\n) s1\nON (sets.name = s1.name)\nWHERE s1.name IS NULL\nGROUP BY sets.name\nHAVING COUNT(sets.item) = 3;\n']], ['query for a set in a relational database'], 3, 1], [(5479975, 2), [['Edit:  It just dawned on me how to do this without the exclusion.'], ["The first subquery finds the total count of items in each set and the second one finds out the count of matching items in each set. When  matches.count  is 3, the set has all the items we're looking for, and if  totals.count  is also 3, the set doesn't have any extra items."]], [[' SELECT totals.name\nFROM (\n    SELECT name, COUNT(*) count\n    FROM sets\n    GROUP BY name\n) totals\nINNER JOIN (\n    SELECT name, COUNT(*) count\n    FROM sets\n    WHERE item IN (1, 3, 5)\n    GROUP BY name\n) matches\nON (totals.name = matches.name)\nWHERE totals.count = 3 AND matches.count = 3;\n']], ['query for a set in a relational database'], 3, 1], [(5501347, 0), [['you could use the built-in date (and  interval  -- thanks  Alex  for the link) calculation:'], ['for instance:']], [[" to_char(to_date(:x, 'hh24:mi') + INTERVAL :y MINUTE,'hh24:mi')\n"]], ['Increment Oracle time in varchar field by a certain amount?'], 2, 1], [(5501347, 1), [['for instance:'], ['-10000']], [[' SQL> WITH my_data AS (\n  2     SELECT \'12:15\' t FROM dual\n  3     UNION ALL SELECT \'10:30\' FROM dual\n  4  )\n  5  SELECT t, \n  6         to_char(to_date(t, \'hh24:mi\') + INTERVAL \'15\' MINUTE,\'hh24:mi\')"t+15"\n  7    FROM my_data;\n\nT     t+15\n----- -----\n12:15 12:30\n10:30 10:45\n']], ['Increment Oracle time in varchar field by a certain amount?'], 2, 1], [(5606689, 0), [['The result of the expression is  numeric (17,6) . To see this'], ['Returns']], [[" DECLARE @i  INT, @v SQL_VARIANT\n\nSET @i = 3\nSET @v = @i  / 9.0\n\nSELECT\n    CAST(SQL_VARIANT_PROPERTY(@v, 'BaseType') AS VARCHAR(30)) AS BaseType,\n    CAST(SQL_VARIANT_PROPERTY(@v, 'Precision') AS INT) AS Precision,\n    CAST(SQL_VARIANT_PROPERTY(@v, 'Scale') AS INT) AS Scale\n"]], ['SQL Server: Is there a way to check what is the resulting data type of implicit conversion?'], 5, 0], [(5606689, 1), [['Returns'], ['-10000']], [[' BaseType   Precision   Scale\n---------- ----------- -----------\nnumeric    17          6\n']], ['SQL Server: Is there a way to check what is the resulting data type of implicit conversion?'], 5, 0], [(5606689, 3), [['The rules that govern why  numeric(10,0) / numeric(2,1)  gives  numeric (17,6)   are covered here'], ['Substituting the relevant values in gives']], [[' Operation:        e1 / e2\nResult precision: p1 - s1 + s2 + max(6, s1 + p2 + 1)\nResult scale:     max(6, s1 + p2 + 1)\n']], ['SQL Server: Is there a way to check what is the resulting data type of implicit conversion?'], 5, 0], [(5606689, 4), [['Substituting the relevant values in gives'], ['-10000']], [[' 10 - 0 + 1 + max(6, 0 + 2 + 1)  = 17\nmax(6, 0 + 2 + 1)               =  6 \n']], ['SQL Server: Is there a way to check what is the resulting data type of implicit conversion?'], 5, 0], [(5719384, 0), [['This might be considered a hack (ok, it is a hack) but it works, and it gets the job done:'], ["Here's what the final report looks like (not exactly what I wanted but functionally equivalent, just not very pretty to look at:"]], [[" SELECT company\n   , product\n   , price\nFROM companyMaster\nORDER BY company,\n   , product,\n   , price\n\nUNION\n\nSELECT company + 'Total'\n   , ''\n   , SUM(price)\nFROM companyMaster\nGROUP BY company\n\nORDER BY company;\n"]], ['Insert line into a query result (sum)'], 2, 1], [(5719384, 1), [["Here's what the final report looks like (not exactly what I wanted but functionally equivalent, just not very pretty to look at:"], ['-10000']], [[' CompanyA    Product 7    14.99  \nCompanyA    Product 3    45.95\nCompanyA    Product 4    12.00\nCompanyA Total           72.94\nCompanyB    Product 3    45.95\nCompanyB Total           45.95\nCompanyC    Product 7    14.99\nCompanyC    Product 3    45.95\nCompanyC Total           60.94\n']], ['Insert line into a query result (sum)'], 2, 0], [(5760020, 0), [['I know this is a matter of style but in my opinion ansi style joins make this much clearer:'], ['In case you have multiple matching elements in a or b, this query will return duplicates. You can either add a DISTINCT or rewrite it as an EXISTS query:']], [[' SELECT c.*\nFROM c\nJOIN a ON a.model = c.model\nJOIN b on b.type = a.type\n']], ["ORACLE/SQL - Joining 3 tables that aren't all interconnected"], 3, 1], [(5760020, 1), [['In case you have multiple matching elements in a or b, this query will return duplicates. You can either add a DISTINCT or rewrite it as an EXISTS query:'], ['I think this should also give the same result, as long as there are no NULL values in model:']], [[' SELECT *\nFROM c\nWHERE EXISTS (SELECT 1\n              FROM a\n              JOIN b ON b.type = a.type\n              WHERE a.model = c.model)\n']], ["ORACLE/SQL - Joining 3 tables that aren't all interconnected"], 3, 1], [(5760020, 2), [['I think this should also give the same result, as long as there are no NULL values in model:'], ['-10000']], [[' SELECT *\nFROM c\nWHERE c.model IN (SELECT a.model\n                  FROM a\n                  JOIN b ON b.type = a.type)\n']], ["ORACLE/SQL - Joining 3 tables that aren't all interconnected"], 3, 1], [(5795541, 0), [['For alternative way to write your query, you could try a  not exists , like:'], ['Or an exclusive left join:']], [[' select  *\nfrom    clients c\nwhere   not exists\n        (\n        select  *\n        from    payments p\n        where   p.payments.client_id = clients.id\n                and payments.created_at > utc_timestamp() - interval 90 day\n        )\n']], ['sql query: no payments in last 90 days'], 2, 1], [(5795541, 1), [['Or an exclusive left join:'], ['If both are slow, add the  explain extended  output to your question, so we can see why.']], [[' select  *\nfrom    clients c\nleft join\n        payments p\non      p.payments.client_id = clients.id\n        and payments.created_at > utc_timestamp() - interval 90 day\nwhere   p.client_id is null\n']], ['sql query: no payments in last 90 days'], 2, 1], [(5803133, 0), [['-10000'], ['Lazy with no indexes']], [[" SELECT foo.id, 'R' AS type INTO bar FROM foo;\n"]], ['How to use SELECT INTO with static values included?'], 3, 1], [(5803133, 2), [["Nicer way (assuming you've created table  bar  already)"], ['-10000']], [[" INSERT INTO bar SELECT id, 'R' AS type FROM foo;\n"]], ['How to use SELECT INTO with static values included?'], 3, 0], [(5816567, 0), [['-10000'], ['For completeness, the ANSI SQL solution to this would be:']], [[' SELECT *\nFROM (\n   SELECT country, capitol, rownum as rn\n   FROM your_table\n   ORDER BY country\n) \nWHERE rn > 1\n']], ['select n rows in sql'], 2, 1], [(5816567, 1), [['For completeness, the ANSI SQL solution to this would be:'], ['That is a portable solution that works on almost all major DBMS']], [[' SELECT *\nFROM (\n   SELECT country, \n          capitol, \n          row_number() over (order by country) as rn\n   FROM your_table\n) \nWHERE rn > 1\n']], ['select n rows in sql'], 2, 1], [(5943678, 1), [['you have to'], ['so you can build the above query \nbut NO it will not work with identical names , GROUP_CONCAT will concat the values .']], [[' select distinct(name) from product_attribute\n']], ['MySQL - How to pivot NVP?'], 2, 0], [(5992308, 1), [['To try it out:'], ['-10000']], [[" SELECT MY_FUNC('aa') FROM SYSIBM.SYSDUMMY1;\n"]], ['How to create a function in DB2 that returns the value of a sequence?'], 2, 0], [(6031181, 0), [['-10000'], ['Result:']], [[" declare @T table (ItemId int, IntervalID int, StartDate datetime,   EndDate datetime)\n\ninsert into @T\nselect 1, 1,  NULL,        '2011-01-15' union all\nselect 2, 1, '2011-01-16', '2011-01-25' union all\nselect 3, 1, '2011-01-26',  NULL        union all\nselect 4, 2,  NULL,        '2011-01-17' union all\nselect 5, 2, '2011-01-16', '2011-01-25' union all\nselect 6, 2, '2011-01-26',  NULL\n\nselect T1.*\nfrom @T as T1\n  inner join @T as T2\n    on coalesce(T1.StartDate, '1753-01-01') < coalesce(T2.EndDate, '9999-12-31') and\n       coalesce(T1.EndDate, '9999-12-31') > coalesce(T2.StartDate, '1753-01-01') and\n       T1.IntervalID = T2.IntervalID and\n       T1.ItemId <> T2.ItemId\n"]], ['Find conflicted date intervals using SQL'], 2, 1], [(6031181, 1), [['Result:'], ['-10000']], [[' ItemId      IntervalID  StartDate               EndDate\n----------- ----------- ----------------------- -----------------------\n5           2           2011-01-16 00:00:00.000 2011-01-25 00:00:00.000\n4           2           NULL                    2011-01-17 00:00:00.000\n']], ['Find conflicted date intervals using SQL'], 2, 0], [(6057352, 0), [[''], ['..or if you have many rows per ssn and only want to find duplicate names)']], [[' SELECT\n   ssn\nFROM\n   Table t1\nGROUP BY\n   ssn\nHAVING COUNT(*) > 1\n']], ['Find duplicates in SQL'], 3, 0], [(6057352, 1), [['..or if you have many rows per ssn and only want to find duplicate names)'], ['Edit, oops, misunderstood']], [[' ...\nHAVING COUNT(DISTINCT name) > 1 \n']], ['Find duplicates in SQL'], 3, 0], [(6057352, 2), [['Edit, oops, misunderstood'], ['-10000']], [[' SELECT\n   ssn\nFROM\n   Table t1\nGROUP BY\n   ssn\nHAVING MIN(name) <> MAX(name)\n']], ['Find duplicates in SQL'], 3, 1], [(6070894, 0), [['Analytic functions could help:'], ['Gives:']], [[' select userid, map\n, case when prevend >= startday then prevend+1 else startday end newstart\n, endday\nfrom\n( select userid, map, startday, endday\n  , lag(endday) over (partition by userid order by startday) prevend\n  from mytable\n)\norder by userid, startday\n']], ['Detect overlapping ranges and correct then in oracle'], 2, 1], [(6070894, 1), [['Gives:'], ['-10000']], [[' USERID  MAP     NEWSTART        ENDDAY\n1       A       01/01/2011      01/05/2011\n1       B       01/06/2011      01/10/2011\n2       A       01/01/2011      01/07/2011\n2       B       01/08/2011      01/10/2011\n']], ['Detect overlapping ranges and correct then in oracle'], 2, 0], [(6093085, 0), [['Use a  Common Table Expression (CTE)  within your function will make it easy to replace the CTE with a base table later e.g. '], ['Alternatively, a derived table:']], [[" WITH YearCodes (year_code, year) AS\n     ( SELECT year_code, year\n         FROM ( VALUES ( 'Y', 2000 ), \n                       ( '1', 2001 ), \n                       ( '2', 2002 ) ) \n              AS YearCodes ( year_code, year ) )\nSELECT ...;\n"]], ['Mapping values without a table'], 2, 1], [(6093085, 1), [['Alternatively, a derived table:'], ['Perhaps that later base table could be a  calendar table .']], [[" SELECT *\n  FROM ( VALUES ( 'Y', 2000 ), \n                ( '1', 2001 ), \n                ( '2', 2002 ) ) \n       AS YearCodes ( year_code, year )\n       -- other stuff here;\n"]], ['Mapping values without a table'], 2, 1], [(6094039, 0), [['This should work (works for me)'], ['OR you use the  MERGE  statement. Something like this.']], [[" update table_a outer \nset sequence_column = (\n    select rnum from (\n\n           -- evaluate row_number() for all rows ordered by your columns\n           -- BEFORE updating those values into table_a\n           select id, row_number() over (order by column1, column2) rnum  \n           from table_a) inner \n\n    -- join on the primary key to be sure you'll only get one value\n    -- for rnum\n    where inner.id = outer.id);\n"]], ['Oracle: Updating a table column using ROWNUM in conjunction with ORDER BY clause'], 2, 1], [(6094039, 1), [['OR you use the  MERGE  statement. Something like this.'], ['-10000']], [[' merge into table_a u\nusing (\n  select id, row_number() over (order by column1, column2) rnum \n  from table_a\n) s\non (u.id = s.id)\nwhen matched then update set u.sequence_column = s.rnum\n']], ['Oracle: Updating a table column using ROWNUM in conjunction with ORDER BY clause'], 2, 1], [(6121779, 0), [["Here's how to achieve that:"], ['-10000']], [[' SELECT *\nFROM tb_values\nWHERE \n    ( SELECT COUNT(DISTINCT value)\n      FROM tb_value\n      WHERE isgoodvalue = true\n        AND value IN (value1, value2, value3)\n    ) = 3\n']], ['MYSQL subset operation'], 2, 0], [(6121779, 1), [['-10000'], ['-10000']], [[' SELECT *\nFROM project\n  JOIN \n    ( SELECT projectid\n      FROM projectTagMap\n      WHERE isgoodvalue = true\n        AND tag IN (tag1, tag2, tag3)\n      GROUP BY projectid\n      HAVING COUNT(*) = 3\n    ) AS ok\n    ON ok.projectid = project.id\n']], ['MYSQL subset operation'], 2, 1], [(6127338, 0), [["You're looking for a group by:"], ['Which can occasionally be written with a distinct on statement:']], [[' select *\nfrom table\ngroup by field1\n']], ['SQL/mysql - Select distinct/UNIQUE but return all columns?'], 3, 1], [(6127338, 1), [['Which can occasionally be written with a distinct on statement:'], ['On some platforms (e.g. PostgreSQL, Oracle, T-SQL) this can be done directly using window functions:']], [[' select distinct on field1 *\nfrom table\n']], ['SQL/mysql - Select distinct/UNIQUE but return all columns?'], 3, 1], [(6127338, 2), [['On some platforms (e.g. PostgreSQL, Oracle, T-SQL) this can be done directly using window functions:'], ["On others (MySQL, SQLite), you'll need to write subqueries that will make you join the entire table with itself ( example ), so not recommended."]], [[' select *\nfrom (\n   select *,\n          row_number() over (partition by field1 order by field2) as row_number\n   from table\n   ) as rows\nwhere row_number = 1\n']], ['SQL/mysql - Select distinct/UNIQUE but return all columns?'], 3, 1], [(6159814, 0), [['While outputting those content you can use  stripslashes  function.'], ['desc  is  mysql reserved word  and you must enclose  desc  in backticks ``']], [[" echo stripslashes($data['description']);\n"]], ['RSS to Database - How to Insert String with Any Character?'], 2, 0], [(6174355, 0), [['Setup sample data:'], ['Copy data:']], [[" -- @A and @B is the source tables\ndeclare @A as table\n(\n  id int,\n  FK_A_B int,\n  name varchar(10)\n)\n\ndeclare @B as table\n(\n  id int,\n  visible bit\n)  \n\n-- Sample data in @A and @B\ninsert into @B values (21, 1),(32, 0)\ninsert into @A values (1, 21, 'n1'),(5, 32, 'n2')\n\n\n-- @C and @D is the target tables with id as identity columns\ndeclare @C as table\n(\n  id int identity,\n  FK_C_D int not null,\n  name varchar(10)\n)\n\ndeclare @D as table\n(\n  id int identity,\n  visible bit\n)  \n\n-- Sample data already in @C and @D\ninsert into @D values (1),(0)\ninsert into @C values (1, 'x1'),(1, 'x2'),(2, 'x3')\n"]], ['How to copy tables avoiding cursors in SQL?'], 3, 0], [(6174355, 2), [['Result:'], ['You can test the code here:  http://data.stackexchange.com/stackoverflow/q/101643/using-merge-to-map-source-id-to-target-id']], [[' select *\nfrom @D as D\n  inner join @C as C\n    on D.id = C.FK_C_D\n\nid          visible id          FK_C_D      name\n----------- ------- ----------- ----------- ----------\n1           1       1           1           x1\n1           1       2           1           x2\n2           0       3           2           x3\n3           1       4           3           n1\n4           0       5           4           n2\n']], ['How to copy tables avoiding cursors in SQL?'], 3, 0], [(6226690, 0), [['You could use an indexed view, that SQL Server will automatically maintain:'], ['This just has two possible statuses, but could expand to more using a different data type. As I say, in this case, SQL Server will maintain the counts behind the scenes, so you can just query the view:']], [[' create table dbo.users (\n    ID int not null,\n    Activated bit not null\n)\ngo\ncreate view dbo.user_status_stats (Activated,user_count)\nwith schemabinding\nas\n    select Activated,COUNT_BIG(*) from dbo.users group by Activated\ngo\ncreate unique clustered index IX_user_status_stats on dbo.user_status_stats (Activated)\ngo\n']], ['Creating a variable on database to hold global stats'], 2, 1], [(6226690, 1), [['This just has two possible statuses, but could expand to more using a different data type. As I say, in this case, SQL Server will maintain the counts behind the scenes, so you can just query the view:'], ["and it won't have to query the underlying table. You need to use the  WITH (NOEXPAND)  hint on editions below (Enterprise/Developer)."]], [[' SELECT user_count from user_status_stats with (NOEXPAND) where Activated = 1\n']], ['Creating a variable on database to hold global stats'], 2, 0], [(6227934, 0), [['Not exactly beautiful, but:'], ['To illustrate:']], [[" CREATE OR REPLACE VIEW your_view AS\nSELECT tt.ID, SUBSTR(value, sp, ep-sp) split, other_col1, other_col2...\n  FROM (SELECT id, value\n             , INSTR(','||value, ',', 1, L) sp  -- 1st posn of substr at this level\n             , INSTR(value||',', ',', 1, L) ep  -- posn of delimiter at this level\n          FROM tt JOIN (SELECT LEVEL L FROM dual CONNECT BY LEVEL < 20) q -- 20 is max #substrings\n                    ON LENGTH(value)-LENGTH(REPLACE(value,','))+1 >= L \n) qq JOIN tt on qq.id = tt.id;\n"]], ['Create a view/temporary table from a column with CSV'], 2, 1], [(6227934, 1), [['To illustrate:'], ['-10000']], [["     SQL> CREATE TABLE tt (ID INTEGER, c VARCHAR2(20), othercol VARCHAR2(20));\n\n    Table created\n    SQL> INSERT INTO tt VALUES (1, 'a,b,c', 'val1');\n\n    1 row inserted\n    SQL> INSERT INTO tt VALUES (2, 'd,e,f,g', 'val2');\n\n    1 row inserted\n    SQL> INSERT INTO tt VALUES (3, 'a,f', 'val3');\n\n    1 row inserted\n    SQL> INSERT INTO tt VALUES (4,'aa,bbb,cccc', 'val4');\n\n    1 row inserted\n    SQL> CREATE OR REPLACE VIEW myview AS\n      2  SELECT tt.ID, SUBSTR(c, sp, ep-sp+1) splitval, othercol\n      3    FROM (SELECT ID\n      4               , INSTR(','||c,',',1,L) sp, INSTR(c||',',',',1,L)-1 ep\n      5            FROM tt JOIN (SELECT LEVEL L FROM dual CONNECT BY LEVEL < 20) q\n      6                      ON LENGTH(c)-LENGTH(REPLACE(c,','))+1 >= L\n      7  ) q JOIN tt ON q.id =tt.id;\n\n    View created\n    SQL> select * from myview order by 1,2;\n\n                                     ID SPLITVAL             OTHERCOL\n--------------------------------------- -------------------- --------------------\n                                      1 a                    val1\n                                      1 b                    val1\n                                      1 c                    val1\n                                      2 d                    val2\n                                      2 e                    val2\n                                      2 f                    val2\n                                      2 g                    val2\n                                      3 a                    val3\n                                      3 f                    val3\n                                      4 aa                   val4\n                                      4 bbb                  val4\n                                      4 cccc                 val4\n\n12 rows selected\n\nSQL> \n"]], ['Create a view/temporary table from a column with CSV'], 2, 0], [(6254626, 0), [['Why not get both sets of comments at once?'], ['Also you could consider:    ']], [[" SELECT\n   ...\nFROM\n   Products P\n   LEFT JOIN Comments C\n      ON P.ProductID LIKE C.SpecID + '%'\n      OR P.ProductID LIKE '%-' + C.SpecID\n"]], ['performing a sort of "reverse lookup" in sql server'], 3, 1], [(6254626, 1), [['Also you could consider:    '], ['Testing is in order to see if one performs better than the other. If you find the queries to be too slow, then trying adding some persisted calculated columns: in Products to specify whether the product ID has a dash in it or not, and in Comments add two columns, one with only product IDs and one with only suffices. Indexes on these columns could help.']], [[" SELECT\n   ...\nFROM\n   Products P\n   LEFT JOIN Comments C\n      ON (Len(C.SpecID) = 2 AND P.ProductID LIKE C.SpecID + '%')\n      OR (Len(C.SpecID) > 2 AND P.ProductID LIKE '%-' + C.SpecID)\n"]], ['performing a sort of "reverse lookup" in sql server'], 3, 1], [(6254626, 2), [['Testing is in order to see if one performs better than the other. If you find the queries to be too slow, then trying adding some persisted calculated columns: in Products to specify whether the product ID has a dash in it or not, and in Comments add two columns, one with only product IDs and one with only suffices. Indexes on these columns could help.'], ['-10000']], [[' ALTER TABLE Comments ADD ExactSpecID AS \n   (CASE WHEN Len(SpecID) > 2 THEN SpecID ELSE NULL END) PERSISTED\nALTER TABLE Comments ADD Suffix AS \n   (CASE WHEN Len(SpecID) = 2 THEN SpecID ELSE NULL END) PERSISTED\n']], ['performing a sort of "reverse lookup" in sql server'], 3, 0], [(6267954, 0), [['you can go with left outer join '], ['or with subselect']], [[' select \na.article_id, a.article_body, \nua.article_id as as been_read --will be not null for read articles\nfrom Articles a \nleft outer join Users_Articles ua \n    on (ua.article_id = a.article_id and ua.user_id = $current_user_id)\n']], ['SQL SELECT complex expression in column - additional boolean'], 2, 1], [(6267954, 1), [['or with subselect'], ['-10000']], [[' select \na.article_id, a.article_body, \n(select 1 from Users_Articles ua \n    where ua.article_id = a.article_id \n    and ua.user_id = $current_user_id) as been_read --will be not null for read articles\nfrom Articles a\n']], ['SQL SELECT complex expression in column - additional boolean'], 2, 1], [(6280565, 0), [["You could try the following. You have to create a redundant UNIQUE constraint on  (id, aId)  in Parent (SQL is pretty dumb isn't it?!)."], ['Possibly a much better solution would be to drop parentId from the Child table altogether, add  bId  instead and just reference the Parent table based on  (aId, bId) :']], [[' CREATE TABLE Child\n(parentId INTEGER NOT NULL,\n aId INTEGER NOT NULL UNIQUE,\nFOREIGN KEY (parentId,aId) REFERENCES Parent (id,aId),\ncreatedOn TIMESTAMP NOT NULL);\n']], ['Unique constraint over multiple tables'], 2, 1], [(6280565, 1), [['Possibly a much better solution would be to drop parentId from the Child table altogether, add  bId  instead and just reference the Parent table based on  (aId, bId) :'], ["Is there any reason why you can't do that?"]], [[' CREATE TABLE Child\n(aId INTEGER NOT NULL UNIQUE,\n bId INTEGER NOT NULL,\nFOREIGN KEY (aId,bId) REFERENCES Parent (aId,bId),\ncreatedOn TIMESTAMP NOT NULL);\n']], ['Unique constraint over multiple tables'], 2, 1], [(6295231, 1), [['EDIT 2:  Solved with the following query:'], ['-10000']], [[' SELECT friendly_name,\n(SELECT winner FROM title_history WHERE championship = c.id ORDER BY date_from DESC LIMIT 1) \nFROM championships AS c\nORDER BY name\n']], ['Ordering a MySQL query with LEFT JOIN'], 2, 1], [(6295650, 1), [['You can even use it to disallow overlaps as a table constraint:'], ['-10000']], [[' alter table events\nadd constraint overlap_excl\nexclude using gist(period(start_date, end_date) WITH &&);\n']], ['SQL query to search by day/month/year/day&month/day&year etc'], 3, 0], [(6333687, 0), [['-10000'], ['Intrinsic  int -conversion rounding :']], [[" SELECT\n   DateWithNoTimePortion = DateAdd(Day, DateDiff(Day, '19000101', DateCol), '19000101'),\n   VisitorCount = Count(*)\nFROM Log\nGROUP BY DateDiff(Day, 0, DateCol);\n"]], ['TSQL counting how many occurrences on each day'], 3, 1], [(6333687, 1), [['Intrinsic  int -conversion rounding :'], ['-10000']], [[" Convert(datetime, Convert(int, DateCol - '12:00:00.003'))\n"]], ['TSQL counting how many occurrences on each day'], 3, 0], [(6333687, 2), [['-10000'], ['-10000']], [[' Convert(date, DateCol)\n']], ['TSQL counting how many occurrences on each day'], 3, 0], [(6355613, 0), [['You can use  elements xsinil  with  for xml path .'], ['Result:']], [[" declare @T table (ID int identity, Name varchar(50))\n\ninsert into @T values ('Name1')\ninsert into @T values (null)\ninsert into @T values ('Name2')\n\nselect\n  ID,\n  Name\nfrom @T\nfor xml path('item'), root('root'), elements xsinil\n"]], ['Xml elements present in spite of null values'], 2, 1], [(6355613, 1), [['Result:'], ['-10000']], [[' <root xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n  <item>\n    <ID>1</ID>\n    <Name>Name1</Name>\n  </item>\n  <item>\n    <ID>2</ID>\n    <Name xsi:nil="true" />\n  </item>\n  <item>\n    <ID>3</ID>\n    <Name>Name2</Name>\n  </item>\n</root>\n']], ['Xml elements present in spite of null values'], 2, 0], [(6404158, 0), [['You can generate the necessary statements with a single query:'], ["Or if that returns  0 s and  1 s rather the statemenets, here's the version using  concat  instead:"]], [[" select 'RENAME TABLE ' || table_name ||  ' TO ' || substr(table_name, 5) ||';'\nfrom information_schema.tables\n"]], ['How to remove a prefix name from every table name in a mysql database'], 2, 1], [(6418214, 0), [['-- Setup:'], ['--Script:']], [[" declare @Device table(DeviceId int primary key, Parts varchar(1000))\ndeclare @Part table(PartId int identity(1,1) primary key, PartName varchar(100))\ndeclare @DevicePart table(DeviceId int, PartId int)\n\ninsert @Device\nvalues\n    (1, 'Part1, Part2, Part3'),\n    (2, 'Part2, Part3, Part4'),\n    (3, 'Part1')\n"]], ['Table Normalization (Parse comma separated fields into individual records)'], 3, 0], [(6418214, 2), [['-- Result:'], ['-10000']], [[' select *\nfrom @Part\n\nPartId      PartName\n----------- ---------\n1           Part1\n2           Part2\n3           Part3\n4           Part4\n\n\nselect *\nfrom @DevicePart\n\nDeviceId    PartId\n----------- -----------\n1           1\n1           2\n1           3\n2           2\n2           3\n2           4\n3           1   \n']], ['Table Normalization (Parse comma separated fields into individual records)'], 3, 0], [(6434996, 1), [['Then ordering is easy.'], ["There's no magic bullet for updating. "]], [[' SELECT name \nFROM user_sort_order\nWHERE user_id = ?\nORDER BY sort_order\n']], ['Manipulate the sort result considering the user preference - database'], 2, 0], [(6440318, 0), [['You can either try'], ['or change the trigger to specifically check for a different title name.']], [[' update mytable a set title = \n      (select title from mytable2 b \n        where b.id     = a.id and \n              b.title != a.title)\n']], ['Oracle : Automatic modification date on update'], 2, 1], [(6440318, 1), [['or change the trigger to specifically check for a different title name.'], ['-10000']], [[' create or replace\nTRIGGER schema.name_of_trigger\nBEFORE UPDATE ON schema.name_of_table\nFOR EACH ROW\nBEGIN\n--  Check for modification of title:\n    if :new.title != :old.title then\n       :new.modify_date := sysdate;\n    end if;\nEND;\n']], ['Oracle : Automatic modification date on update'], 2, 1], [(6468506, 0), [["Here's one alternate way to approach it, using PL/SQL, that will probably be more efficient in some cases but is clearly less readable."], ['Also note this potentially produces different results from your statement if there can be multiple rows with the same  process_date  value.  To make it handle duplicates requires a little more complexity:']], [[' DECLARE\n  CURSOR delete_cur IS\n    SELECT /*+ FIRST_ROWS(1) */\n      NULL\n    FROM daily_statistics\n    ORDER BY process_date DESC\n    FOR UPDATE;\n  trash  CHAR(1);\nBEGIN\n  OPEN delete_cur;\n  FETCH delete_cur INTO trash;\n  IF delete_cur%FOUND THEN\n    DELETE FROM daily_statistics WHERE CURRENT OF delete_cur;\n  END IF;\n  CLOSE delete_cur;\nEND;\n/\n']], ['Can I delete the most recent record without sub-select in Oracle?'], 2, 1], [(6468506, 1), [['Also note this potentially produces different results from your statement if there can be multiple rows with the same  process_date  value.  To make it handle duplicates requires a little more complexity:'], ['-10000']], [[' DECLARE\n  CURSOR delete_cur IS\n    SELECT /*+ FIRST_ROWS(1) */\n      process_date\n    FROM daily_statistics\n    ORDER BY process_date DESC\n    FOR UPDATE;\n  del_date  DATE;\n  next_date DATE;\nBEGIN\n  OPEN delete_cur;\n  FETCH delete_cur INTO del_date;\n  IF delete_cur%FOUND THEN\n    DELETE FROM daily_statistics WHERE CURRENT OF delete_cur;\n  END IF;\n  LOOP\n    FETCH delete_cur INTO next_date;\n    EXIT WHEN delete_cur%NOTFOUND OR next_date <> del_date;\n    DELETE FROM daily_statistics WHERE CURRENT OF delete_cur;\n  END LOOP;\n  CLOSE delete_cur;\nEND;\n/\n']], ['Can I delete the most recent record without sub-select in Oracle?'], 2, 1], [(6524697, 0), [['The following should work on MySQL or Oracle and some other databases:'], ['or (for Oracle, Postgre and others)']], [[" SELECT * FROM bdreminders\nWHERE firstname LIKE IFNULL( CONCAT(?,'%'), firstname)\nAND lastname LIKE IFNULL( CONCAT(?,'%'), lastname)\nAND baughtgift LIKE IFNULL( CONCAT(?,'%'), baughtgift)\nORDER BY firstname asc\n"]], ['using like operator in html5 database query'], 3, 1], [(6524697, 1), [['or (for Oracle, Postgre and others)'], ['or (for SQL server and others)']], [[" SELECT * FROM bdreminders\nWHERE firstname LIKE IFNULL( ? ||'%', firstname)\nAND lastname LIKE IFNULL( ? || '%', lastname)\nAND baughtgift LIKE IFNULL( ? || '%', baughtgift)\nORDER BY firstname asc\n"]], ['using like operator in html5 database query'], 3, 1], [(6524697, 2), [['or (for SQL server and others)'], ["I would try the last one first. If the above does not work and you get all bdreminders, the database does not concaternate NULL+string to NULL. In this case, I don't think you can use ISNULL as it will return the first non null value and thus, always return '%'."]], [[" SELECT * FROM bdreminders\nWHERE firstname LIKE IFNULL( ? +'%', firstname)\nAND lastname LIKE IFNULL( ? + '%', lastname)\nAND baughtgift LIKE IFNULL( ? + '%', baughtgift)\nORDER BY firstname asc\n"]], ['using like operator in html5 database query'], 3, 1], [(6536396, 0), [['It was hard to avoid those null values in the pivot.'], ['Output ']], [[" declare @t table (fruit varchar(10), colour varchar(10))\n\ninsert @t\nselect 'Apple',     'Red'   union all\nselect 'Orange',    'Red'   union all\nselect 'Berry',     'Green' union all\nselect 'PineApple', 'Green'\n\nselect * from (\nselect a.fruit, b.colour, case when c.fruit is null then 0 else 1 end found from \n(select distinct fruit, colour from @t) a\ncross join \n(select distinct colour from @t) b\nleft outer join \n(select distinct fruit, colour from @t) c\non a.fruit = c.fruit and b.colour = c.colour) d\nPIVOT\n(max(found)  \nFOR colour\nin([red],[green])  \n)AS p\norder by 3, 1   \n"]], ['How to convert two lists into adjacency matrix SQL Server T-SQL?'], 2, 1], [(6536396, 1), [['Output '], ['-10000']], [[' fruit      red         green\n---------- ----------- -----------\nApple      1           0\nOrange     1           0\nBerry      0           1\nPineApple  0           1\n']], ['How to convert two lists into adjacency matrix SQL Server T-SQL?'], 2, 0], [(6551214, 0), [['Query #1 here should tell you which times are the beginnings of chains by finding which times do not have any times below them but within 3 seconds:'], ['And then for each row, we can find the largest chain-starting timestamp that is less than our timestamp with Query #2:']], [[' SELECT DISTINCT Timestamp\nFROM Table a\nLEFT JOIN Table b\nON (b.Timestamp >= a.TimeStamp - INTERVAL 3 SECONDS\n    AND b.Timestamp < a.Timestamp)\nWHERE b.Timestamp IS NULL\n']], ['MySQL GROUP BY DateTime +/- 3 seconds'], 3, 0], [(6551214, 1), [['And then for each row, we can find the largest chain-starting timestamp that is less than our timestamp with Query #2:'], ['Once we have that, we can GROUP BY it as you wanted.']], [[' SELECT Table.id, MAX(StartOfChains.TimeStamp) AS ChainStartTime\nFROM Table\nJOIN ([query #1]) StartofChains\nON Table.Timestamp >= StartOfChains.TimeStamp\nGROUP BY Table.id\n']], ['MySQL GROUP BY DateTime +/- 3 seconds'], 3, 0], [(6551214, 2), [['Once we have that, we can GROUP BY it as you wanted.'], ["I'm not entirely sure this is distinct enough from Tom H's answer to be posted separately, but it sounded like you were having trouble with implementation, and I was thinking about it, so I thought I'd post again. Good luck!"]], [[' SELECT COUNT(*) --or whatever\nFROM Table\nJOIN ([query #2]) GroupingQuery\nON Table.id = GroupingQuery.id\nGROUP BY GroupingQuery.ChainStartTime\n']], ['MySQL GROUP BY DateTime +/- 3 seconds'], 3, 0], [(6591613, 1), [['Then your users table will reference the  height  and  weight  tables--and possibly many other dimension tables--astrological sign, marital status, etc.'], ['Then to do a search for users between 4 and 5 feet:']], [[' CREATE TABLE users (\n    uid         SERIAL PRIMARY KEY,\n    height      INT REFERENCES height(id),\n    weight      INT references weight(id),\n    sign        INT references sign(id),\n    ...\n);\n']], ["DB: saving user's height and weight"], 3, 0], [(6591613, 2), [['Then to do a search for users between 4 and 5 feet:'], ['Several advantages to this method:']], [[' SELECT *\nFROM users\nJOIN height ON users.height = height.id\nWHERE height.inches >= 48 AND height.inches <= 60;\n']], ["DB: saving user's height and weight"], 3, 0], [(6611453, 0), [['First some date arithmetic :'], ['OK, we got the bounds for the "last month" datetime range.\nNow we need some window function to get the first rows per gender :']], [[" SELECT now(), \n       date_trunc( 'month', now() ) - '1 MONTH'::INTERVAL, \n       date_trunc( 'month', now() );\n\n              now              |        ?column?        |       date_trunc       \n-------------------------------+------------------------+------------------------\n 2011-07-07 16:24:38.765559+02 | 2011-06-01 00:00:00+02 | 2011-07-01 00:00:00+02\n"]], ['PostgreSQL: trying to find miss and mister of the last month with highest rating'], 2, 0], [(6611453, 1), [['OK, we got the bounds for the "last month" datetime range.\nNow we need some window function to get the first rows per gender :'], ['Note this can give you several rows in case of ex-aequo.']], [[" SELECT * FROM (\n   SELECT *, rank( ) over (partition by gender order by score desc ) \n   FROM (\n      SELECT user_id, count(*) AS score FROM pref_rep \n      WHERE nice=true \n      AND last_rated >= date_trunc( 'month', now() ) - '1 MONTH'::INTERVAL\n      AND last_rated <  date_trunc( 'month', now() )\n      GROUP BY user_id) s1 \n   JOIN users USING (user_id)) s2 \nWHERE rank=1;\n"]], ['PostgreSQL: trying to find miss and mister of the last month with highest rating'], 2, 0], [(6616800, 0), [["Here's the mysql solution (with executable test code below):"], ["Here's the test code:"]], [[' INSERT INTO Table1 (col1, col2) VALUES ( val1, val2 );\nINSERT INTO Table2 (foreign_key_column) VALUES (LAST_INSERT_ID());\n']], ['SQL Insert into 2 tables, passing the new PK from one table as the FK in the other'], 2, 1], [(6621502, 0), [['-10000'], [' Now create an instead of Update trigger on tableA to warn about SNOs missing in tableA when trying to insert from front end app  ']], [[" \n\n    create  table TABLEA (\n     PartNo varchar(30),\n     SNo varchar(30),\n     PO varchar(10),\n     DO varchar(30))\n\n     insert into TABLEA \n     select '1AB1009', 'GR7764', 'ST', 'OND'\n     union\n    select '1AB1009','GR7765','ST','OND'\n\n    create  table TABLEB ( \n     SNo varchar(30)\n    )\n     insert into TABLEB\n     select 'GR7764'\n     union\n     select 'GR7765'\n\n     select * from TABLEA\n     select * from TABLEB\n     GO\n\n"]], ['how to a query to match the records in two different tables and if a match update with new values, no match prompt me to fill in the details?'], 4, 0], [(6621502, 1), [[' Now create an instead of Update trigger on tableA to warn about SNOs missing in tableA when trying to insert from front end app  '], [' Test if the trigger fires when the Sno are missing  ']], [[" \n\n    CREATE TRIGGER missingSNOs ON TABLEA\n    INSTEAD OF UPDATE\n    AS  \n\n        BEGIN\n            if EXISTS (SELECT 1\n                            FROM TABLEB B\n                            LEFT OUTER JOIN\n                            INSERTED I\n                            ON B.SNO = I.SNO\n                            WHERE I.SNO IS NULL\n                            )\n            begin\n                     SELECT B.SNO\n                            FROM TABLEB B\n                            LEFT OUTER JOIN\n                            INSERTED I\n                            ON B.SNO = I.SNO\n                            WHERE I.SNO IS NULL\n                RAISERROR('S.nos are missing in tableA which are present in tableB',16,1);\n                ROLLBACK;\n            end     \n        END\n    GO\n\n"]], ['how to a query to match the records in two different tables and if a match update with new values, no match prompt me to fill in the details?'], 4, 0], [(6621502, 2), [[' Test if the trigger fires when the Sno are missing  '], [' Finally clean up the code  ']], [[' \n\n-- Errors with message as the SNO is missing\nupdate TABLEA\nset PartNo = \'newPartNo\'\nwhere SNO = \'SnoNOTinB\'\n\n-- works no errors as both SNOS are present in tableB\nupdate TABLEA\nset PartNo = \'new one\'\nwhere SNO in (\'GR7764\', \'GR7765\')\n\n-- Also you dont have to join with tableB now and modify query as below\nUPDATE A\nset A.Mat_No =\'"+ Mat_No+"\',WO_No=\'"+WO_No+"\',\nCode = \'"+Code+"\',Desc = \'"+Desc+"\',\nCenter=\'"+Center+"\',\nDate=\'"+Date+"\',\nRemarks=\'"+Remarks+"\' \nFROM TableA A                   \nWHERE A.Status = \'IN\' \n\n']], ['how to a query to match the records in two different tables and if a match update with new values, no match prompt me to fill in the details?'], 4, 0], [(6621502, 3), [[' Finally clean up the code  '], ['-10000']], [[' \n\n    drop table TABLEA\n      drop table TABLEB\n\n']], ['how to a query to match the records in two different tables and if a match update with new values, no match prompt me to fill in the details?'], 4, 0], [(6673667, 0), [['Strictly speaking your query is correct, however what you\'re really looking for is "words starting with \'hyperlink\'" which means there will be a space character or it will be the start of the text field.'], ['Your other option would be to use full text search which would mean your query would look like this:']], [[" select          O_ObjectID, \n            rtrim(O_Name) as O_Name\nfrom            A_Object\nwhere           O_Name like @NamePrefix + '%' OR O_Name like '% ' + @NamePrefix + '%'\norder by        O_Name\n"]], ['Searching words in a database'], 2, 1], [(6673667, 1), [['Your other option would be to use full text search which would mean your query would look like this:'], ['and performance on this will be significantly faster as it will be indexed at a word level.']], [[' select          O_ObjectID, \n            rtrim(O_Name) as O_Name\nfrom            A_Object\nwhere           CONTAINS(O_Name, \'"\'+ @NamePrefix + \'*"\')\norder by        O_Name\n']], ['Searching words in a database'], 2, 1], [(6680228, 0), [['At least up to 10g, PUBLIC is not a real user. You cannot create objects in the "Public schema":'], ['If you run this query:']], [[' SQL> CREATE TABLE public.foobar (id integer);\n\nCREATE TABLE public.foobar (id integer)\n\nORA-00903: invalid table name\n\nSQL> CREATE TABLE system.foobar (id integer);\n\nTable created\n\nSQL> \n']], ['Managing Oracle Synonyms'], 2, 0], [(6688196, 0), [['The loop version:'], ['Statistics:']], [[" create function GetEntireLineage1 (@id int)\nreturns varchar(max)\nas\nbegin\n  declare @ret varchar(max)\n\n  select @ret = folder_name,\n         @id = parent_id\n  from Folder\n  where id = @id\n\n  while @@rowcount > 0\n  begin\n    select @ret = @ret + '-' + folder_name,\n           @id = parent_id\n    from Folder\n    where id = @id\n  end\n  return @ret\nend\n"]], ['What is the most efficient way to concatenate a string from all parent rows using T-SQL?'], 6, 1], [(6688196, 1), [['Statistics:'], ['The recursive CTE version:']], [['  SQL Server Execution Times:\n   CPU time = 125 ms,  elapsed time = 122 ms.\n']], ['What is the most efficient way to concatenate a string from all parent rows using T-SQL?'], 6, 0], [(6688196, 2), [['The recursive CTE version:'], ['Statistics:']], [[" create function GetEntireLineage2(@id int)\nreturns varchar(max)\nbegin\n  declare @ret varchar(max);\n\n  with cte(id, name) as\n  (\n    select f.parent_id,\n           cast(f.folder_name as varchar(max))\n    from Folder as f\n    where f.id = @id\n    union all\n    select f.parent_id,\n           c.name + '-' + f.folder_name\n    from Folder as f\n      inner join cte as c\n        on f.id = c.id\n  )\n  select @ret = name\n  from cte\n  where id is null\n  option (maxrecursion 0)\n\n  return @ret\nend\n"]], ['What is the most efficient way to concatenate a string from all parent rows using T-SQL?'], 6, 1], [(6688196, 3), [['Statistics:'], ["Recursive CTE with  for xml path('')  trick."]], [['  SQL Server Execution Times:\n   CPU time = 187 ms,  elapsed time = 183 ms.\n']], ['What is the most efficient way to concatenate a string from all parent rows using T-SQL?'], 6, 0], [(6688196, 4), [["Recursive CTE with  for xml path('')  trick."], ['Statistics:']], [[" create function [dbo].[GetEntireLineage4](@id int)\nreturns varchar(max)\nbegin\n  declare @ret varchar(max) = '';\n\n  with cte(id, lvl, name) as\n  (\n    select f.parent_id,\n           1,\n           f.folder_name\n    from Folder as f\n    where f.id = @id\n    union all\n    select f.parent_id,\n           lvl + 1,\n           f.folder_name\n    from Folder as f\n      inner join cte as c\n        on f.id = c.id\n  )\n  select @ret = (select '-'+name\n                 from cte\n                 order by lvl\n                 for xml path(''), type).value('.', 'varchar(max)')\n  option (maxrecursion 0)\n\n  return stuff(@ret, 1, 1, '')\nend\n"]], ['What is the most efficient way to concatenate a string from all parent rows using T-SQL?'], 6, 1], [(6688196, 5), [['Statistics:'], ['-10000']], [['  SQL Server Execution Times:\n   CPU time = 31 ms,  elapsed time = 37 ms.\n']], ['What is the most efficient way to concatenate a string from all parent rows using T-SQL?'], 6, 0], [(6691865, 0), [['Try this technique:'], ['In your Case:']], [[" declare @dt datetime\ndeclare @sql varchar(100)\nset @dt = getdate()\nset @sql = 'select 1 as [ ' + convert( varchar(25),@dt,120) + ']'  \nexec (@sql)\n"]], ['How do I name a column as a date value'], 2, 1], [(6691865, 1), [['In your Case:'], ['-10000']], [[" declare @dt datetime\ndeclare @sql varchar(100)\nset @dt = getdate()\nset @sql = 'select 0 as [ ' + convert( varchar(25),@dt,120) + ']'  \nexec (@sql)\n"]], ['How do I name a column as a date value'], 2, 1], [(6743541, 0), [['you can replace '], ['with']], [[" and table1.(value of table2.field) = 'Red'\n"]], ['Condition based on column in data'], 2, 0], [(6745525, 0), [['First get a little information about table:'], ['and just copy paste result into']], [[' select \'xmlelement("\'|| column_name||\'",new.\' || column_name || \'),\'  from all_tab_columns where lower(table_name) = \'my_table\';\n']], ['Oracle logging changes to XML'], 2, 0], [(6745525, 1), [['and just copy paste result into'], ['Ugly, but working.']], [[' select xmlelement("doc",\n\n--paste here\n\n) from dual;\n']], ['Oracle logging changes to XML'], 2, 0], [(6810923, 0), [['Another query that work for all languages is'], ["to_char(sysdate, 'D')  returns the following values for each day of week:"]], [[" select name, position, hiredate\n from table\nwhere to_char(sysdate, 'D') in (1, 2); -- 1 monday; 2 tuesday\n"]], ['Oracle SQL - How do i output data from a table based on the day of the week from a hiredate column?'], 2, 1], [(6810923, 1), [["to_char(sysdate, 'D')  returns the following values for each day of week:"], ['-10000']], [[' 1 monday\n2 tuesday\n3 wednesday\n4 thrusday\n5 friday\n6 saturday\n7 sunday\n']], ['Oracle SQL - How do i output data from a table based on the day of the week from a hiredate column?'], 2, 0], [(6811449, 0), [['The reason the counts can be null in the query you specify is because a left join will return nulls on unmatched records. So the subquery itself is not returning null counts (hence all the responses and confusion). You need to specify the IFNULL in the outer-most select, as follows:'], ["Run this set of queries and you'll see that the counts are always 2. You can change the way the NULL parent_ids are displayed (as NULL or 0), but the count itself will always return."]], [[" SELECT  qa.*, user_profiles.*, c.*, n.pid, ifnull(n.ans_count, 0) as ans_count\nFROM    qa\n        JOIN user_profiles\n          ON user_id = author_id\n        LEFT JOIN (SELECT cm_id,\n                          cm_author_id,\n                          id_fk,\n                          cm_text,\n                          cm_timestamp,\n                          first_name AS cm_first_name,\n                          last_name AS cm_last_name,\n                          facebook_id AS cm_fb_id,\n                          picture AS cm_picture\n                    FROM  cm\n                    JOIN  user_profiles\n                      ON  user_id = cm_author_id) AS c\n          ON id = c.id_fk\n        LEFT JOIN (SELECT   parent_id AS pid, COUNT(*) AS ans_count\n                     FROM   qa\n                    GROUP   BY parent_id) AS n\n          ON id = n.pid\nWHERE   id  LIKE '%'\nORDER   BY id DESC\n"]], ['Using IFNULL to set NULLs to zero'], 2, 1], [(6811449, 1), [["Run this set of queries and you'll see that the counts are always 2. You can change the way the NULL parent_ids are displayed (as NULL or 0), but the count itself will always return."], ['-10000']], [[' create temporary table if not exists SO_Test(\n    parent_id int null);\n\ninsert into SO_Test(parent_id)\nselect 2 union all select 4 union all select 6 union all select null union all select null union all select 45 union all select 2;\n\n\nSELECT IFNULL(parent_id, 0) AS pid, COUNT(*) AS ans_count\n   FROM SO_Test\n  GROUP BY IFNULL(parent_id, 0);\n\nSELECT parent_id AS pid, COUNT(*) AS ans_count\n   FROM SO_Test\n  GROUP BY parent_id;\n\ndrop table SO_Test;\n']], ['Using IFNULL to set NULLs to zero'], 2, 1], [(6814426, 0), [['you can write following query, if you are working in oracle -'], ['you can write as follow also..']], [[' delete from item_table where rowid not in\n(\n     select rowid from item_table \n     where (item,price1) in (select item,max(price1) from item_table group by item)\n        or (item,price2) in (select item,max(price2) from item_table group by item)\n)\n']], ['How to delete smaller records for each group?'], 2, 1], [(6814426, 1), [['you can write as follow also..'], ['-10000']], [[' delete from item_table where (item,date,shift,price1,price2 ) not in\n    (\n        select item,date,shift,price1,price2  from item_table \n        where (item,price1) in (select item,max(price1) from item_table group by item)\n           or (item,price2) in (select item,max(price2) from item_table group by item)\n    )\n']], ['How to delete smaller records for each group?'], 2, 1], [(6814563, 0), [['the code:'], ['will print: ']], [[' > db.mycoll.insert( {num:3, text:"smth", date: new Date(), childs:[1,2,3]})\n> var rec = db.mycoll.findOne();\n\n> for (key in rec) { \n    var val = rec[key];\n    print( key + "(" + typeof(val) + "): " + val ) }\n']], ['get attribute list from mongodb object'], 2, 1], [(6814563, 1), [['will print: '], ['(javascript array and date are just "object")']], [[' _id(object): 4e2d688cb2f2b62248c1c6bb\nnum(number): 3\ntext(string): smth\ndate(object): Mon Jul 25 2011 15:58:52 GMT+0300\nchilds(object): 1,2,3\n']], ['get attribute list from mongodb object'], 2, 0], [(6836478, 0), [['you can write your own function in the file  core/MY_Model.php  to do that:'], ['then make every model extend MY_Model']], [[" function queryThenUpdate($query,$update)\n{\n   $query = $this->db->query($query);\n   //use as you need $query\n   $this->db->update($update['table'],$update['data']);\n}\n"]], ['Codeigniter run query before a update'], 3, 0], [(6836478, 1), [['then make every model extend MY_Model'], ['and every time you need to update something:']], [[' class Your_Model extend MY_Model\n']], ['Codeigniter run query before a update'], 3, 0], [(6836478, 2), [['and every time you need to update something:'], ['-10000']], [[' $this->Your_Model->queryThenUpdate($query,$update)\n']], ['Codeigniter run query before a update'], 3, 0], [(6934563, 0), [['The T1 thread should do:'], ['When the server responds with ack, ']], [[' BEGIN;\nSELECT ID, VALUE FROM TAB WHERE SYNCHRONICED = 0;\nUPDATE TAB SET SYNCHRONICED = 1 WHERE SYNCHRONICED = 0;\nCOMMIT;\n']], ['Lock a database or table  in sqlite (Android)'], 2, 0], [(6934563, 1), [['When the server responds with ack, '], ['This will not affect any records updated or inserted since their  SYNCHRONICED  is 0.']], [[' UPDATE TAB SET SYNCHRONICED = 2 WHERE SYNCHRONICED = 1;\n']], ['Lock a database or table  in sqlite (Android)'], 2, 0], [(6937080, 1), [['After, AUTO_INCREMENT property can be removed -'], ['-10000']], [[' ALTER TABLE table_a\n  CHANGE COLUMN id id INT(11) NOT NULL;\n']], ['how to add primary key to table having duplicate values?'], 2, 0], [(6994843, 0), [['It probably needs tweaking to return the correct results but I hope you get the idea:'], ['A little note about  CASE...END . Your original code does not run because, unlike PHP or JavaScript, the SQL  CASE  is not a flow control structure that allows to choose which part of the code will run. Instead, it returns an expression. So you can do this:']], [[' SELECT ft1.task, COUNT(ft1.id) AS count\nFROM feed_tasks ft1\nLEFT JOIN pages p1 ON ft1.type=1 AND p1.id = ft1.reference_id\nLEFT JOIN urls u1 ON ft1.type=2 AND u1.id = ft1.reference_id\nWHERE COALESCE(p1.id, u1.id) IS NOT NULL\nAND ft1.account_id IS NOT NULL\nAND a1.user_id = :user_id\n']], ['MySQL query where JOIN depends on CASE'], 3, 1], [(6994843, 1), [['A little note about  CASE...END . Your original code does not run because, unlike PHP or JavaScript, the SQL  CASE  is not a flow control structure that allows to choose which part of the code will run. Instead, it returns an expression. So you can do this:'], ['... but not this:']], [[" SELECT CASE\n    WHEN foo<0 THEN 'Yes'\n    ELSE 'No'\nEND AS is_negative\nFROM bar\n"]], ['MySQL query where JOIN depends on CASE'], 3, 0], [(6994843, 2), [['... but not this:'], ['-10000']], [[" -- Invalid\nCASE \n    WHEN foo<0 THEN SELECT 'Yes' AS is_negative\n    ELSE SELECT 'No' AS is_negative\nEND\nFROM bar\n"]], ['MySQL query where JOIN depends on CASE'], 3, 0], [(7008452, 1), [['Result:'], ['Stored procedure with output parameter @startdate']], [[' (No column name)\n2011-08-10 00:00:00.000\n']], ['How do I select any value from SP?'], 4, 0], [(7008452, 3), [['Use like this'], ['-10000']], [[' declare @D datetime\nexec MySP @D out\nselect @D\n']], ['How do I select any value from SP?'], 4, 0], [(7112526, 0), [['One way to find such rows (or tuples) would be a query like:'], ["or follow @Ben's advice if the empty string is a problem.  Then you can do an  update :"]], [[' SELECT job_num, item_code, invoice_num\nFROM tablename\nWHERE job_num = 94834 AND item_code = "EFC-ASSOC-01" AND invoice_num = ""\n']], ['Checking the value of a field and updating it'], 3, 1], [(7112526, 1), [["or follow @Ben's advice if the empty string is a problem.  Then you can do an  update :"], ["However, the problem with this approach is that if you're not using the primary key to choose a row in the update statement, multiple rows could get updated (similarly, the select statement could return multiple rows).  So, you'll have to look at the database schema and determine the primary key column(s) of the table, and make sure that all of the primary key columns are used in the WHERE clause of the update.  If you just do"]], [[' UPDATE tablename SET invoice_num = ? WHERE job_num = .........\n']], ['Checking the value of a field and updating it'], 3, 0], [(7116576, 0), [["Anyway, here's my version of your test data.  I'm using names to make it easier to see what's going on:"], ["I'm going to use Oracle syntax to solve this, specifically the LAG analytic function:"]], [[" SQL> select s.name as student\n  2         , c.name as class\n  3         , q.season||' '||q.year as quarter\n  4         , q.q_id\n  5         , c.base_cost\n  6  from  enrolments e\n  7          join students s\n  8              on (s.s_id = e.s_id)\n  9          join classes c\n 10              on (c.c_id = e.c_id)\n 11          join quarters q\n 12              on (q.q_id = c.q_id)\n 13  order by s.s_id, q.q_id\n 14  /\n\nSTUDENT    CLASS                QUARTER               Q_ID  BASE_COST\n---------- -------------------- --------------- ---------- ----------\nSheldon    Introduction to SQL  Spring 2008            100        100\nSheldon    Advanced SQL         Spring 2009            104        150\nHoward     Introduction to SQL  Spring 2008            100        100\nHoward     Information Theory   Summer 2008            101         75\nRajesh     Information Theory   Summer 2008            101         75\nLeonard    Crypto Foundation    Autumn 2008            102        120\nLeonard    PHP for Dummies      Winter 2008            103         90\nLeonard    Advanced SQL         Spring 2009            104        150\n\n8 rows selected.\n\nSQL>\n"]], ['SQL find consecutive quarters'], 4, 0], [(7116576, 1), [["I'm going to use Oracle syntax to solve this, specifically the LAG analytic function:"], ['Now we can do some maths:']], [[" SQL> select s.name as student\n  2         , c.name as class\n  3         , q.season||' '||q.year as quarter\n  4         , q.q_id\n  5         , c.base_cost\n  6         , lag (q.q_id) over (partition by s.s_id order by q.q_id) prev_q_id\n  7  from  enrolments e\n  8          join students s\n  9              on (s.s_id = e.s_id)\n 10          join classes c\n 11              on (c.c_id = e.c_id)\n 12          join quarters q\n 13              on (q.q_id = c.q_id)\n 14  order by s.s_id, q.q_id\n 15  /\n\nSTUDENT    CLASS                QUARTER               Q_ID  BASE_COST  PREV_Q_ID\n---------- -------------------- --------------- ---------- ---------- ----------\nSheldon    Introduction to SQL  Spring 2008            100        100\nSheldon    Advanced SQL         Spring 2009            104        150        100\nHoward     Introduction to SQL  Spring 2008            100        100\nHoward     Information Theory   Summer 2008            101         75        100\nRajesh     Information Theory   Summer 2008            101         75\nLeonard    Crypto Foundation    Autumn 2008            102        120\nLeonard    PHP for Dummies      Winter 2008            103         90        102\nLeonard    Advanced SQL         Spring 2009            104        150        103\n\n8 rows selected.\n\nSQL>\n"]], ['SQL find consecutive quarters'], 4, 0], [(7116576, 3), [['(artifical break to obviate the need to scroll down to see the results)'], ["So, Howard and Leonard get discounts for their consecutive classes, and Sheldon and Raj don't."]], [[' STUDENT    CLASS                QUARTER      BASE_COST DISCOUNT_PCT ACTUAL_COST\n---------- -------------------- ----------- ---------- ------------ -----------\nSheldon    Introduction to SQL  Spring 2008        100            0         100\nSheldon    Advanced SQL         Spring 2009        150            0         150\nHoward     Introduction to SQL  Spring 2008        100            0         100\nHoward     Information Theory   Summer 2008         75           20          60\nRajesh     Information Theory   Summer 2008         75            0          75\nLeonard    Crypto Foundation    Autumn 2008        120            0         120\nLeonard    PHP for Dummies      Winter 2008         90           20          72\nLeonard    Advanced SQL         Spring 2009        150           20         120\n\n8 rows selected.\n\nSQL>\n']], ['SQL find consecutive quarters'], 4, 0], [(7246987, 0), [['I started by making a list of all tables, with filtering criteria and relational criteria.'], ['The next best way is to run the query with these options turned on:']], [[" articles\n\n  articles.expirydate > 'somedate'\n  articles.dateadded > 'somedate'\n  articles.status >= someint\n\n  articles.article_id <-> articles_to_geo.article_id\n  articles.article_id <-> articles_to_badges.article_id\n  articles.site_id <-> sites.id\n\narticles_to_geo\n\n  articles_to_geo.article_id <-> articles.article_id\n  articles_to_geo.whitelist_city_id <-> cities_whitelist.city_id\n\ncities_whitelist\n\n  cities_whitelist.published = someint\n\n  cities_whitelist.city_id <-> articles_to_geo.whitelist_city_id\n  cities_whiltelist.city_id <-> cities.city_id\n\ncities\n\n  cities.city_id <-> cities_whiltelist.city_id\n\narticles_to_badges\n\n  articles_to_badges.badge_id in (some ids)\n\n  articles_to_badges.article_id <-> articles.article_id\n  article_to_badges.badge_id <-> badges.id\n\nbadges\n\n  badges.id <-> article_to_badges.badge_id\n\nsites\n\n  sites.id <-> articles.site_id\n"]], ['How to properly index tables used in a query with multiple joins'], 5, 0], [(7246987, 1), [['The next best way is to run the query with these options turned on:'], ["One possible order is the order in the query.  This approach might be pretty bad because our Articles Filtering Criteria is based on 3 different ranges.  There could be thousands of articles that meet that criteria and it's hard to formulate an index to support those ranges."]], [[' SET STATISTICS IO ON\nSET STATISTICS TIME ON\n']], ['How to properly index tables used in a query with multiple joins'], 5, 0], [(7246987, 2), [["One possible order is the order in the query.  This approach might be pretty bad because our Articles Filtering Criteria is based on 3 different ranges.  There could be thousands of articles that meet that criteria and it's hard to formulate an index to support those ranges."], ['Another possible order is Cities first.  The Criteria for Cities is easily indexable and there might only be 1 row!  Finding the articles for a City and then filtering by date should read fewer rows than finding the articles for dates and then filtering down to the City.']], [[' Articles (Filter)\n  Articles_to_Geo (Relational by Article_Id)\n    Cities_WhiteList (Relational by City_Id) (Filter)\n    Cities (Relational by City_Id) (Filter)\n  Articles_to_Badges (Relational by Article_Id) (Filter)\n    Badges (Relational by Badge_Id)\n  Sites (Relational by Article_Id)\n']], ['How to properly index tables used in a query with multiple joins'], 5, 0], [(7246987, 3), [['Another possible order is Cities first.  The Criteria for Cities is easily indexable and there might only be 1 row!  Finding the articles for a City and then filtering by date should read fewer rows than finding the articles for dates and then filtering down to the City.'], ["A third approach could be Badges first.  This would be best if articles rarely accumulate Badges and there aren't many Badges."]], [[' Cities (Filter)\n  Cities_WhiteList (Relational by City_Id) (Filter)\n  Articles_to_Geo (Relational by City_Id)\n    Articles (Relational by Article_Id) (Filter)\n      Articles_to_Badges (Relational by Article_Id) (Filter)\n        Badges (Relational by Badge_Id)\n      Sites (Relational by Article_Id)\n']], ['How to properly index tables used in a query with multiple joins'], 5, 0], [(7246987, 4), [["A third approach could be Badges first.  This would be best if articles rarely accumulate Badges and there aren't many Badges."], ['-10000']], [[' Badges (Read the Whole Table)\n  Articles_to_Badges (Relational by Badge_Id) (Filter)\n    Articles (Relational by Article_Id) (Filter)\n      Articles_to_Geo (Relational by Article_Id)\n        Cities_WhiteList (Relational by City_Id) (Filter)\n        Cities (Relational by City_Id) (Filter)\n    Sites (Relational by Article_Id)\n']], ['How to properly index tables used in a query with multiple joins'], 5, 0], [(7260488, 0), [["Since you're using MySQL, I'll give you a MySQL-specific solution that's really easy:"], ['The better solution is to make the query not ambiguous.  For instance, if you want to fetch the gallery image that has the highest primary key value:']], [[' SELECT \n gallery.id, \n gallery.thumbnail_big, \n products.id, \n products.title, \n products.size, \n products.price, \n products.text_description, \n products.main_description \nFROM gallery\nINNER JOIN products \nON gallery.id=products.id\nGROUP BY products.id\n']], ['How can I get a single result from a related table in SQL?'], 2, 1], [(7260488, 1), [['The better solution is to make the query not ambiguous.  For instance, if you want to fetch the gallery image that has the highest primary key value:'], ["I have to assume you have another column  gallery.pkey  that is auto-increment, or otherwise serves to uniquely distinguish gallery images for a given product.  If you don't have such a column, you need to create one."]], [[' SELECT \n g1.id, \n g1.thumbnail_big, \n p.id, \n p.title, \n p.size, \n p.price, \n p.text_description, \n p.main_description \nFROM products p\nINNER JOIN gallery g1 ON p.id = g1.id\nLEFT OUTER JOIN gallery g2 ON p.id = g2.id AND g1.pkey < g2.pkey\nWHERE g2.id IS NULL\n']], ['How can I get a single result from a related table in SQL?'], 2, 1], [(7270243, 0), [['Country:'], ['Localized_Country:']], [[' Id  Code\n===============\n1   IT\n']], ['How to localize database table'], 3, 0], [(7270243, 1), [['Localized_Country:'], ['Which you then query like so:']], [[' CountryId  LanguageCode  LocalizedName\n=========================================\n1          IT            Italia\n1          EN            Italy\n']], ['How to localize database table'], 3, 0], [(7274514, 0), [['Yes, possible with full text search, and likely the best answer. For a straight T-SQL solution, you could use a split function and join, e.g. assuming a table of numbers called dbo.Numbers (you may need to decide on a different upper limit):'], ['And a splitting function that uses that table of numbers:']], [[' SET NOCOUNT ON;\nDECLARE @UpperLimit INT;\nSET @UpperLimit = 200000;\n\nWITH n AS\n(\n    SELECT\n        rn = ROW_NUMBER() OVER\n        (ORDER BY s1.[object_id])\n    FROM sys.objects AS s1\n    CROSS JOIN sys.objects AS s2\n    CROSS JOIN sys.objects AS s3\n)\nSELECT [Number] = rn - 1\nINTO dbo.Numbers\nFROM n\nWHERE rn <= @UpperLimit + 1;\n\nCREATE UNIQUE CLUSTERED INDEX n ON dbo.Numbers([Number]);\n']], ['SQL query to match keywords?'], 4, 0], [(7274514, 1), [['And a splitting function that uses that table of numbers:'], ['Then you can simply say:']], [[" CREATE FUNCTION dbo.SplitStrings\n(\n    @List NVARCHAR(MAX)\n)\nRETURNS TABLE\nAS\n    RETURN\n    (\n        SELECT DISTINCT\n            [Value] = LTRIM(RTRIM(\n                SUBSTRING(@List, [Number],\n                CHARINDEX(N',', @List + N',', [Number]) - [Number])))\n        FROM\n            dbo.Numbers\n        WHERE\n            Number <= LEN(@List)\n            AND SUBSTRING(N',' + @List, [Number], 1) = N','\n    );\nGO\n"]], ['SQL query to match keywords?'], 4, 0], [(7278905, 0), [['This should only do one pass over the table. You can use the analytic version of  count()  to get the frequency of each value independently:'], ['You can then use that as a CTE (or subquery factoring, I think in oracle terminology) and pull only the highest-frequency value from each column:']], [[' select firstname, count(*) over (partition by firstname) as c_fn,\n    lastname, count(*) over (partition by lastname) as c_ln,\n    favoriteanimal, count(*) over (partition by favoriteanimal) as c_fa,\n    favoritebook, count(*) over (partition by favoritebook) as c_fb\nfrom my_table;\n\nFIRSTN C_FN LASTNAME C_LN FAVORIT C_FA FAVORITEBOOK C_FB\n------ ---- -------- ---- ------- ---- ------------ ----\nBill      1 Ribbits     1 Lemur      2 Dhalgren        1\nFerris    1 Freemont    2 Possum     1 Ubik            2\nNancy     2 Freemont    2 Lemur      2 Housekeeping    1\nNancy     2 Drew        1 Penguin    1 Ubik            2\n']], ['Efficiently find top-N values from multiple columns independently in Oracle'], 2, 0], [(7278905, 1), [['You can then use that as a CTE (or subquery factoring, I think in oracle terminology) and pull only the highest-frequency value from each column:'], ["You're doing one pass over the CTE for each column, but that should still only hit the real table once (thanks to the  materialize  hint). And you may want to add to the  order by  clauses to tweak what do to if there are ties."]], [[' with tmp_tab as (\n    select /*+ MATERIALIZE */\n        firstname, count(*) over (partition by firstname) as c_fn,\n        lastname, count(*) over (partition by lastname) as c_ln,\n        favoriteanimal, count(*) over (partition by favoriteanimal) as c_fa,\n        favoritebook, count(*) over (partition by favoritebook) as c_fb\n    from my_table)\nselect (select firstname from (\n        select firstname,\n            row_number() over (partition by null order by c_fn desc) as r_fn\n            from tmp_tab\n        ) where r_fn = 1) as firstname,\n    (select lastname from (\n        select lastname,\n            row_number() over (partition by null order by c_ln desc) as r_ln\n        from tmp_tab\n        ) where r_ln = 1) as lastname,\n    (select favoriteanimal from (\n        select favoriteanimal,\n            row_number() over (partition by null order by c_fa desc) as r_fa\n        from tmp_tab\n        ) where r_fa = 1) as favoriteanimal,\n    (select favoritebook from (\n        select favoritebook,\n            row_number() over (partition by null order by c_fb desc) as r_fb\n        from tmp_tab\n        ) where r_fb = 1) as favoritebook\nfrom dual;\n\nFIRSTN LASTNAME FAVORIT FAVORITEBOOK\n------ -------- ------- ------------\nNancy  Freemont Lemur   Ubik\n']], ['Efficiently find top-N values from multiple columns independently in Oracle'], 2, 0], [(7315875, 0), [['According to your comment on the other answer,'], ['If you want to append this to the current value of FULL_ADDRESS, as I understand from the original question,']], [[" UPDATE Network_Plant_Items\n    SET FULL_ADDRESS = 'foobar' || COALESCE(BARCODE, MANUF_SERIAL_NUMBER)\n    WHERE BARCODE IS NOT NULL OR MANUF_SERIAL_NUMBER IS NOT NULL\n"]], ["SQL Query for an update of a column based on other column's data in a Table"], 2, 1], [(7315875, 1), [['If you want to append this to the current value of FULL_ADDRESS, as I understand from the original question,'], ["COALESCE()  returns the first non-NULL argument you pass to it. See Oracle's  manual page on it ."]], [[' UPDATE Network_Plant_Items\n    SET FULL_ADDRESS = FULL_ADDRESS || COALESCE(BARCODE, MANUF_SERIAL_NUMBER)\n    WHERE BARCODE IS NOT NULL OR MANUF_SERIAL_NUMBER IS NOT NULL\n']], ["SQL Query for an update of a column based on other column's data in a Table"], 2, 1], [(7322330, 0), [['This will work with most SQL DBMS, but shows the count value.'], ['This will work with some, but not necessarily all, DBMS; it orders by a column that is not shown in the result list:']], [[' SELECT ID, Owner_ID, Owner_Count\n  FROM AnonymousTable AS A\n  JOIN (SELECT Owner_ID, COUNT(*) AS Owner_Count\n          FROM AnonymousTable\n         GROUP BY Owner_ID\n       ) AS B ON B.Owner_ID = A.Owner_ID\n ORDER BY Owner_Count DESC, Owner_ID ASC, ID ASC;\n']], ['use count in sql'], 2, 1], [(7326337, 0), [['Following your edit...'], ['Returns']], [[" DECLARE @T TABLE\n(\nID INT,\nCategoryID CHAR(4),\nCode CHAR(4),\nStatus CHAR(4) NULL\n)\nINSERT INTO @T (ID,CategoryID, Code)\nSELECT 1,'A100',0012 UNION ALL SELECT 2,'A100',0012 UNION ALL\nSELECT 3,'A100',0055 UNION ALL SELECT 4,'A100',0012 UNION ALL\nSELECT 5,'B201',1116 UNION ALL SELECT 6,'B201',1116 UNION ALL\nSELECT 7,'B201',1121 UNION ALL SELECT 8,'B201',1024;\n\nWITH T AS\n(\nSELECT *, MIN(Code) OVER (PARTITION BY CategoryID ) AS MinCode\nfrom @T\n)\nUPDATE T\nSET Status = 'FAIL'\nWHERE Code <> MinCode\n\nSELECT *\nFROM @T\n"]], ['Updating a column based on values from other rows'], 2, 1], [(7326337, 1), [['Returns'], ['-10000']], [[' ID          CategoryID Code Status\n----------- ---------- ---- ------\n1           A100       12   NULL\n2           A100       12   NULL\n3           A100       55   FAIL\n4           A100       12   NULL\n5           B201       1116 FAIL\n6           B201       1116 FAIL\n7           B201       1121 FAIL\n8           B201       1024 NULL\n']], ['Updating a column based on values from other rows'], 2, 0], [(7364969, 0), [['Relevant indexes (should be the optimum - as long as we lack fore-knowledge which clubs will be queried):'], ['Total runtimes from EXPLAIN ANALYZE.']], [[' ALTER TABLE student ADD CONSTRAINT student_pkey PRIMARY KEY(stud_id );\nALTER TABLE student_club ADD CONSTRAINT sc_pkey PRIMARY KEY(stud_id, club_id);\nALTER TABLE club       ADD CONSTRAINT club_pkey PRIMARY KEY(club_id );\nCREATE INDEX sc_club_id_idx ON student_club (club_id);\n']], ['How to filter SQL results in a has-many-through relation'], 14, 0], [(7364969, 1), [['Total runtimes from EXPLAIN ANALYZE.'], ['-10000']], [['1) Martin 2: 44.594 ms SELECT s.stud_id, s.name\nFROM   student s\nJOIN   student_club sc USING (stud_id)\nWHERE  sc.club_id IN (30, 50)\nGROUP  BY 1,2\nHAVING COUNT(*) > 1;\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 2), [['-10000'], ['-10000']], [['2) Erwin 1: 33.217 ms SELECT s.stud_id, s.name\nFROM   student s\nJOIN   (\n   SELECT stud_id\n   FROM   student_club\n   WHERE  club_id IN (30, 50)\n   GROUP  BY 1\n   HAVING COUNT(*) > 1\n   ) sc USING (stud_id);\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 3), [['-10000'], ['-10000']], [['3) Martin 1: 31.735 ms SELECT s.stud_id, s.name\n   FROM   student s\n   WHERE  student_id IN (\n   SELECT student_id\n   FROM   student_club\n   WHERE  club_id = 30\n   INTERSECT\n   SELECT stud_id\n   FROM   student_club\n   WHERE  club_id = 50);\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 4), [['-10000'], ['-10000']], [['4) Derek: 2.287 ms SELECT s.stud_id,  s.name\nFROM   student s\nWHERE  s.stud_id IN (SELECT stud_id FROM student_club WHERE club_id = 30)\nAND    s.stud_id IN (SELECT stud_id FROM student_club WHERE club_id = 50);\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 5), [['-10000'], ['-10000']], [['5) Erwin 2: 2.181 ms SELECT s.stud_id,  s.name\nFROM   student s\nWHERE  EXISTS (SELECT * FROM student_club\n               WHERE  stud_id = s.stud_id AND club_id = 30)\nAND    EXISTS (SELECT * FROM student_club\n               WHERE  stud_id = s.stud_id AND club_id = 50);\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 6), [['-10000'], ['The last three perform pretty much the same. 4) and 5) result in the same query plan.']], [['6) Sean: 2.043 ms SELECT s.stud_id, s.name\nFROM   student s\nJOIN   student_club x ON s.stud_id = x.stud_id\nJOIN   student_club y ON s.stud_id = y.stud_id\nWHERE  x.club_id = 30\nAND    y.club_id = 50;\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 7), [['The last three perform pretty much the same. 4) and 5) result in the same query plan.'], ['-10000']], [['7) ypercube 1: 148.649 ms SELECT s.stud_id,  s.name\nFROM   student AS s\nWHERE  NOT EXISTS (\n   SELECT *\n   FROM   club AS c \n   WHERE  c.club_id IN (30, 50)\n   AND    NOT EXISTS (\n      SELECT *\n      FROM   student_club AS sc \n      WHERE  sc.stud_id = s.stud_id\n      AND    sc.club_id = c.club_id  \n      )\n   );\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 8), [['-10000'], ["As expected, those two perform almost the same. Query plan results in table scans, the planner doesn't find a way to use the indexes here."]], [['8) ypercube 2: 147.497 ms SELECT s.stud_id,  s.name\nFROM   student AS s\nWHERE  NOT EXISTS (\n   SELECT *\n   FROM  (\n      SELECT 30 AS club_id  \n      UNION  ALL\n      SELECT 50\n      ) AS c\n   WHERE NOT EXISTS (\n      SELECT *\n      FROM   student_club AS sc \n      WHERE  sc.stud_id = s.stud_id\n      AND    sc.club_id = c.club_id  \n      )\n   );\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 9), [["As expected, those two perform almost the same. Query plan results in table scans, the planner doesn't find a way to use the indexes here."], ["Fancy SQL, decent performance for a CTE. Very exotic query plan. \nAgain, would be interesting how 9.1 handles this. I am going to upgrade the db cluster used here to 9.1 soon. Maybe I'll rerun the whole shebang ..."]], [['9) wildplasser 1: 49.849 ms WITH RECURSIVE two AS (\n   SELECT 1::int AS level\n        , stud_id\n   FROM   student_club sc1\n   WHERE  sc1.club_id = 30\n   UNION\n   SELECT two.level + 1 AS level\n        , sc2.stud_id\n   FROM   student_club sc2\n   JOIN   two USING (stud_id)\n   WHERE  sc2.club_id = 50\n   AND    two.level = 1\n   )\nSELECT s.stud_id, s.student\nFROM   student s\nJOIN   two USING (studid)\nWHERE  two.level > 1;\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 10), [["Fancy SQL, decent performance for a CTE. Very exotic query plan. \nAgain, would be interesting how 9.1 handles this. I am going to upgrade the db cluster used here to 9.1 soon. Maybe I'll rerun the whole shebang ..."], ['CTE variant of query 2). Surprisingly, it can result in a slightly different query plan with the exact same data. I found a sequential scan on  student , where the subquery-variant used the index.']], [['10) wildplasser 2: 36.986 ms WITH sc AS (\n   SELECT stud_id\n   FROM   student_club\n   WHERE  club_id IN (30,50)\n   GROUP  BY stud_id\n   HAVING COUNT(*) > 1\n   )\nSELECT s.*\nFROM   student s\nJOIN   sc USING (stud_id);\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 11), [['CTE variant of query 2). Surprisingly, it can result in a slightly different query plan with the exact same data. I found a sequential scan on  student , where the subquery-variant used the index.'], ['-10000']], [[" SELECT s.stud_id, s.student\nFROM   student s\nJOIN   student_club sc USING (stud_id)\nWHERE  sc.club_id = 10                 -- member in 1st club ...\nAND    NOT EXISTS (\n   SELECT *\n   FROM  (SELECT 14 AS club_id) AS c  -- can't be excluded for missing the 2nd\n   WHERE  NOT EXISTS (\n      SELECT *\n      FROM   student_club AS d\n      WHERE  d.stud_id = sc.stud_id\n      AND    d.club_id = c.club_id\n      )\n   )\n"]], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 12), [['-10000'], ['-10000']], [[' SELECT s.*\nFROM   student s\nJOIN   student_club x USING (stud_id)\nWHERE  sc.club_id = 10                 -- member in 1st club ...\nAND    EXISTS (                        -- ... and membership in 2nd exists\n   SELECT *\n   FROM   student_club AS y\n   WHERE  y.stud_id = s.stud_id\n   AND    y.club_id = 14\n   )\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7364969, 13), [['-10000'], ['-10000']], [[' SELECT s.*\nFROM   student AS s\nWHERE  EXISTS (\n   SELECT *\n   FROM   student_club AS x\n   JOIN   student_club AS y USING (stud_id)\n   WHERE  x.stud_id = s.stud_id\n   AND    x.club_id = 14\n   AND    y.club_id = 10\n   )\n']], ['How to filter SQL results in a has-many-through relation'], 14, 1], [(7392374, 0), [['-10000'], ['-10000']], [['SQL Statement     ;WITH Alarm (C1, C1Alarm, C2, C2Alarm, C3, C3Alarm, C4, C4Alarm) AS (\n        SELECT  12.44, 0, 99.43, 0, 4.43, 1, 43.33, 0\n        UNION ALL SELECT 12.44, 1, 99.43, 0, 4.43, 1, 43.33, 0\n        UNION ALL SELECT 1, 0, 2, 1, 3, 1, 4, 1\n        UNION ALL SELECT 1, 1, 2, 1, 3, 1, 4, 1\n    )\n    , AddRowNumbers AS (\n        SELECT  rowNumber = ROW_NUMBER() OVER (ORDER BY C1)\n                , C1, C1Alarm\n                , C2, C2Alarm\n                , C3, C3Alarm\n                , C4, C4Alarm\n        FROM    Alarm   \n    )\n    , UnPivotColumns AS (\n        SELECT  rowNumber, value = C1 FROM AddRowNumbers WHERE C1Alarm = 0\n        UNION ALL SELECT rowNumber, C2 FROM AddRowNumbers WHERE C2Alarm = 0\n        UNION ALL SELECT rowNumber, C3 FROM AddRowNumbers WHERE C3Alarm = 0\n        UNION ALL SELECT rowNumber, C4 FROM AddRowNumbers WHERE C4Alarm = 0\n    )\n    SELECT  C1, C1Alarm\n            , C2, C2Alarm\n            , C3, C3Alarm\n            , C4, C4Alarm\n            , COALESCE(range1.range, range2.range)\n    FROM    AddRowNumbers rowNumber\n            LEFT OUTER JOIN (SELECT rowNumber, range = MAX(value) - MIN(value) FROM UnPivotColumns GROUP BY rowNumber HAVING COUNT(*) > 1) range1 ON range1.rowNumber = rowNumber.rowNumber\n            LEFT OUTER JOIN (SELECT rowNumber, range = AVG(value) FROM UnPivotColumns GROUP BY rowNumber HAVING COUNT(*) = 1) range2 ON range2.rowNumber = rowNumber.rowNumber  \n']], ['Calculate column in view based on other column values'], 2, 1], [(7432065, 1), [['The second way but may not be what you want, is to redo your sql query you will get same result (but not separated with the alias) like this:'], ['This query can be easily done with find like this']], [[" SELECT * FROM `videos` AS `U1` \nWHERE `U1`.`level_id` = '1' AND (`U1`.`submitted_date` > '2011-09-11' OR `U1`.`submitted_date` < '2011-09-11')\nORDER BY  submitted_date DESC\nLIMIT 0,10\n"]], ['How can I do sql union in cake php?'], 4, 1], [(7557231, 1), [['you can programmability include/exclude table by doing something like:'], ['-10000']], [[" EXEC sp_msforeachtable 'IF LEFT(''?'',9)=''[dbo].[xy'' BEGIN SELECT * FROM  ? END ELSE PRINT LEFT(''?'',9)'\n"]], ['Select * from n tables'], 2, 1], [(7558371, 0), [['You would need to modify your code to use dynamic SQL to refer to any object that is created at runtime.  You can probably use  EXECUTE IMMEDIATE , i.e.'], ['rather than']], [[" EXECUTE IMMEDIATE \n  'SELECT COUNT(*) FROM new_mv_name'\n  INTO l_cnt;\n"]], ['10g Package Construction - Restricting References'], 2, 1], [(7558371, 1), [['rather than'], ['That being said, however, I would be extremely dubious about a PL/SQL implementation that involved creating any new tables and materialized views at runtime.  That is almost always a mistake in Oracle.  Why do you need to create new objects at runtime?']], [[' SELECT COUNT(*)\n  INTO l_cnt\n  FROM new_mv_name;\n']], ['10g Package Construction - Restricting References'], 2, 0], [(7605630, 0), [['If you are using MSSql you can order by the newId() function to randomly get a row of data. You still need a service/page on the server side to run this code for you.'], ['for MySql this would suffice']], [[' select top 1 productName, sku\nfrom products\norder by newid()\n']], ["What's the best approach to dynamically display a single product from the database?"], 2, 1], [(7605630, 1), [['for MySql this would suffice'], ['-10000']], [[' SELECT productName, sku\nFROM products\nORDER BY Rand()\nLIMIT 1\n']], ["What's the best approach to dynamically display a single product from the database?"], 2, 1], [(7656057, 0), [['One row for each hour for a given date (SQL Server solution).'], ['-10000']], [[" select dateadd(hour, Number, '20110101')\nfrom master..spt_values\nwhere type = 'P' and\n      number between 0 and 23\n"]], ['How to make temporary table with row for each of last 24 hours?'], 2, 1], [(7656057, 1), [['-10000'], ['-10000']], [[" select dateadd(hour, datediff(hour, 0, getdate()) - number, 0)\nfrom master..spt_values\nwhere type = 'P' and\n      number between 0 and 23\n"]], ['How to make temporary table with row for each of last 24 hours?'], 2, 1], [(7676110, 0), [['It looks like all four column values are duplicated so you can do this - '], ['However if marital status can be different and you have some other column based on which to choose (for eg you want latest record based on a column create_date) you can do this']], [[' select distinct emp_name, emp_address, sex, marital_status\nfrom YourTable\n']], ['How to remove duplicates from table using SQL query'], 2, 1], [(7676110, 1), [['However if marital status can be different and you have some other column based on which to choose (for eg you want latest record based on a column create_date) you can do this'], ['-10000']], [[' select emp_name, emp_address, sex, marital_status\nfrom YourTable a\nwhere not exists (select 1 \n                   from YourTable b\n                  where b.emp_name = a.emp_name and\n                        b.emp_address = a.emp_address and\n                        b.sex = a.sex and\n                        b.create_date >= a.create_date)\n']], ['How to remove duplicates from table using SQL query'], 2, 1], [(7681122, 0), [['If your MAX(noteid) is 799, then try:'], ['Then when inserting a new record, for the NOTEID column, you would do:']], [[' CREATE SEQUENCE noteseq\n    START WITH 800\n    INCREMENT BY 1\n']], ['Oracle - Modify an existing table to auto-increment a column'], 2, 0], [(7681122, 1), [['Then when inserting a new record, for the NOTEID column, you would do:'], ['-10000']], [[' noteseq.nextval\n']], ['Oracle - Modify an existing table to auto-increment a column'], 2, 0], [(7745609, 0), [['All you need is a  GROUP BY  clause with the  MAX  aggregate function:'], ['-10000']], [[' SELECT id, MAX(rev)\nFROM YourTable\nGROUP BY id\n']], ['SQL select only rows with max value on a column'], 3, 0], [(7745609, 1), [['-10000'], ['-10000']], [[' SELECT a.id, a.rev, a.contents\nFROM YourTable a\nINNER JOIN (\n    SELECT id, MAX(rev) rev\n    FROM YourTable\n    GROUP BY id\n) b ON a.id = b.id AND a.rev = b.rev\n']], ['SQL select only rows with max value on a column'], 3, 1], [(7745609, 2), [['-10000'], ['-10000']], [[' SELECT a.*\nFROM YourTable a\nLEFT OUTER JOIN YourTable b\n    ON a.id = b.id AND a.rev < b.rev\nWHERE b.id IS NULL;\n']], ['SQL select only rows with max value on a column'], 3, 1], [(7748125, 0), [['Just join to the availability table twice'], ["or, if we're not into writing SQL like its 1985:"]], [[' SELECT rooms.* FROM rooms, availability as a1, availability as a2\nWHERE rooms.id = 123\nAND a1.room_id = rooms.id\nAND a2.room_id=  rooms.id\nAND a1.date_occupied + 1 = a2.date_occupied\n']], ['SQL find two consecutive days in a reservation system'], 2, 1], [(7748125, 1), [["or, if we're not into writing SQL like its 1985:"], ['-10000']], [[' SELECT rooms.* FROM rooms\nJOIN availability a1 on a1.room_id = rooms.id\nJoin availability a2 on a2.room_id = rooms.id AND a1.date_occupied + 1 = a2.date_occupied\nWHERE rooms.id = 123\n']], ['SQL find two consecutive days in a reservation system'], 2, 1], [(7763635, 0), [['-10000'], ['This will give you a list of playgroups that have at least one player sorted by the number of players. Of course, field name is made up  :)']], [[' SELECT PP.playgroup_id, COUNT(*) cnt\nFROM playgroup_players PP\nGROUP BY PP.playgroup_id\nORDER BY COUNT(*) DESC\n']], ['SQL Sort by popularity?'], 2, 1], [(7763635, 1), [['This will give you a list of playgroups that have at least one player sorted by the number of players. Of course, field name is made up  :)'], ["This should give you a list of ALL playgroups (even the ones with no players). I've tested this on Oracle and on some of my own data and it works"]], [[' SELECT G.playgroup_id, COUNT(PP.playgroup_id) cnt\nFROM playgroup G\n  LEFT OUTER JOIN playgroup_players PP ON (PP.playgroup_id=G.playgroup_id)\nGROUP BY G.playgroup_id\nORDER BY COUNT(*) DESC\n']], ['SQL Sort by popularity?'], 2, 1], [(7794875, 0), [['Proof of concept preparation:'], ['Query 1 - Node Levels:']], [[" declare @YourTable table (id int, parentid int, title varchar(20))\n\ninsert into @YourTable values\n(1,null, 'root'),\n(2,1,    'something'),\n(3,1,    'in the way'),\n(4,1,    'she moves'),\n(5,3,    ''),\n(6,null, 'I don''t know'),\n(7,6,    'Stick around');\n"]], ['Join a table to itself'], 2, 0], [(7794875, 1), [['Query 1 - Node Levels:'], ['-10000']], [[' with cte as (\n    select Id, ParentId, Title, 1 level \n    from @YourTable where ParentId is null\n\n    union all\n\n    select yt.Id, yt.ParentId, yt.Title, cte.level + 1\n    from @YourTable yt inner join cte on cte.Id = yt.ParentId\n)\nselect cte.*\nfrom cte \norder by level, id, Title\n']], ['Join a table to itself'], 2, 1], [(7830197, 1), [['Perhaps you could trim off leading and trailing commas left over like this:'], ["Thinking about this more, I'm more partial to just forcing the use of built-in  REPLACE()  and then cleaning out the extra comma where you may get two commas in a row.  This is looking for two commas side by side, as though there had been no spaces separating your original list items. If the items had been separated by commas and spaces, change  ',,'  to  ', ,'  in the outer  REPLACE()  call."]], [[" UPDATE children SET wishes = TRIM(BOTH ',' FROM REGEXP_REPLACE(wishes, '(,(\\s)?)?Surfboard', '')) WHERE caseNum='whatever';\n"]], ['Remove values in comma separated list from database'], 3, 1], [(7901416, 0), [['try creating a temp table in memory:'], ['then:']], [[' DECLARE @temp_receipts TABLE (\nAssociatedReceiptID int,\nsum_value int)\n']], ['Best way to update table with values calculated from same table'], 3, 0], [(7901416, 1), [['then:'], ['and then update the main table totals:']], [[' insert into @temp_receipts\nSELECT AssociatedReceiptID, sum(Value)\nFROM Receipt\nGROUP BY AssociatedReceiptID\n']], ['Best way to update table with values calculated from same table'], 3, 0], [(7901416, 2), [['and then update the main table totals:'], ['However, I would create a table called receipt_totals or something and use that instead. It makes no sense to have the total of each associated receipt in every single related row. if you are doing it for query convenience consider creating a view between receipts and receipt_totals ']], [[' UPDATE Receipt r\nSET Total = (SELECT sum_value\n             FROM @temp_receipts tt\n             WHERE r.AssociatedReceiptID = tt.AssociatedReceiptID)\n']], ['Best way to update table with values calculated from same table'], 3, 0], [(7905182, 0), [['You can do this, but its probably better just to update or delete the rows in the referencing table'], ['or with a slightly smaller hammer']], [[' ALTER TABLE InviteConfiguration NOCHECK CONSTRAINT ALL\n']], ['How do I turn off this error temporarily while I delete a record?'], 2, 1], [(7905182, 1), [['or with a slightly smaller hammer'], ['-10000']], [['  ALTER TABLE InviteConfiguration NOCHECK CONSTRAINT FK_InviteConfiguration_Invite\n']], ['How do I turn off this error temporarily while I delete a record?'], 2, 1], [(7991363, 0), [['2)  You can do the same using  mysqldump . This command should export CREATE DATABASE/CREATE TABLE queries:'], ['3)  You can pull information from mySQL schema tables. Most mySQL clients (phpMyAdmin, HeidiSQL etc) allow you to export result of queries as CSV. Some useful queries:']], [[' mysqldump -hlocalhost -uroot -proot --all-databases --no-data > create-database-and-tables.sql\n']], ['How to pull out schema of db from MySQL/phpMyAdmin?'], 2, 1], [(7991363, 1), [['3)  You can pull information from mySQL schema tables. Most mySQL clients (phpMyAdmin, HeidiSQL etc) allow you to export result of queries as CSV. Some useful queries:'], ['-10000']], [[" /*\n * DATABASE, TABLE, TYPE\n */\nSELECT TABLE_SCHEMA, TABLE_NAME, TABLE_TYPE\nFROM INFORMATION_SCHEMA.TABLES\nWHERE TABLE_SCHEMA NOT IN ('information_schema', 'performance_schema', 'mysql')\nORDER BY TABLE_SCHEMA, TABLE_NAME, TABLE_TYPE\n\n/*\n * DATABASE, TABLE, COLUMN, TYPE\n */\nSELECT TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, DATA_TYPE, IS_NULLABLE /* ETC */\nFROM INFORMATION_SCHEMA.COLUMNS\nWHERE TABLE_SCHEMA NOT IN ('information_schema', 'performance_schema', 'mysql')\nORDER BY TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION\n"]], ['How to pull out schema of db from MySQL/phpMyAdmin?'], 2, 1], [(7994408, 0), [['You cannot do this:'], ['You can however do this:']], [[' SELECT (Complex SubQuery) AS A, (Another Sub Query WHERE ID = A) FROM TABLE\n']], ['Use Alias in Select Query'], 3, 0], [(7994408, 1), [['You can however do this:'], ['Or']], [[' SELECT (Another Sub Query WHERE ID = A.somecolumn)\nFROM table\nJOIN SELECT (Complex SubQuery) AS A on (A.X = TABLE.Y)\n']], ['Use Alias in Select Query'], 3, 1], [(7994408, 2), [['Or'], ['The problem is that you cannot refer to aliases like this in the SELECT and WHERE clauses, because they will not have evaluated by the time the select or where part is executed. \nYou can also use a  having  clause, but having clauses do not use indexes and should be avoided if possible.  ']], [[' SELECT (Another Sub Query)\nFROM table\nWHERE table.afield IN (SELECT Complex SubQuery.otherfield)\n']], ['Use Alias in Select Query'], 3, 1], [(8001083, 2), [['Second update to meet newly discovered criteria.'], ['-10000']], [[" SELECT \n  y.*\nFROM\n  YourTable y,\n  (SELECT yb.id, yb.date FROM yb WHERE color = 'GREEN') ys\nWHERE\n  /* The colors 'before' green */\n  y.date < ys.date or\n  /* The colors on the same date as green, but with greater \n     or equal id to green. This includes green itself.\n     Note the parentheses here. */\n  (y.date = ys.date and y.id >= ys.id)\nORDER BY\n  y.date DESC\nLIMIT 4 OFFSET 0\n"]], ['SQL: ORDER BY `date` AND START WHERE`value`="something"?'], 3, 1], [(8014982, 0), [['If the table already exists:'], ['If you are creating the table yourself:']], [[' ALTER TABLE ADD CONSTRAINT CK_ExitDateReason\nCHECK (\n      (ExitDate IS NULL AND ExitReason IS NULL) \n   OR (ExitDate IS NOT NULL AND ExitReason IS NOT NULL) \n);\n']], ["Is there a way to make a column's nullability depend on another column's nullability?"], 2, 1], [(8015482, 0), [['You can use a recursive CTE to build a list of dates and then count the distinct dates.'], ['Result:']], [[" declare @T table\n(\n  startDate date,\n  endDate date\n);\n\ninsert into @T values\n('2011-01-01', '2011-01-05'),\n('2011-01-04', '2011-01-08'),\n('2011-01-11', '2011-01-15');\n\nwith C as\n(\n  select startDate,\n         endDate\n  from @T\n  union all\n  select dateadd(day, 1, startDate),\n         endDate\n  from C\n  where dateadd(day, 1, startDate) < endDate       \n)\nselect count(distinct startDate) as DayCount\nfrom C\noption (MAXRECURSION 0)\n"]], ['How to merge time intervals in SQL Server'], 3, 1], [(8015482, 1), [['Result:'], ['Or you can use a numbers table. Here I use master..spt_values:']], [[' DayCount\n-----------\n11\n']], ['How to merge time intervals in SQL Server'], 3, 0], [(8015482, 2), [['Or you can use a numbers table. Here I use master..spt_values:'], ['-10000']], [[" declare @MinStartDate date\nselect @MinStartDate = min(startDate)\nfrom @T\n\nselect count(distinct N.number)\nfrom @T as T\n  inner join master..spt_values as N\n    on dateadd(day, N.Number, @MinStartDate) between T.startDate and dateadd(day, -1, T.endDate)\nwhere N.type = 'P'    \n"]], ['How to merge time intervals in SQL Server'], 3, 1], [(8030624, 0), [['Join  Test  to itself thusly:'], ['Or use an intersection:']], [[' select t1.A, t1.B\nfrom Test t1\njoin Test t2 on t1.A = t2.B and t1.B = t2.A\n']], ['Checking if specific tuple exists in table'], 2, 1], [(8030624, 1), [['Or use an intersection:'], ['The self-join would probably be faster though.']], [[' select A, B from Test\nintersect\nselect B, A from Test\n']], ['Checking if specific tuple exists in table'], 2, 1], [(8044345, 0), [['For example, here a table:'], ['Here the special ordering:']], [[' mysql> select * from test;\n+----+-----------+\n| id | name      |\n+----+-----------+\n|  1 | London    |\n|  2 | Paris     |\n|  3 | Tokio     |\n|  4 | Rome      |\n|  5 | Amsterdam |\n+----+-----------+\n']], ['DBIx::Class : Resultset order_by based upon existence of a value in the list'], 3, 0], [(8046345, 0), [['-10000'], ['You could replace the  GROUP BY a, b, c  clause with a DISTINCT in front of  a  in the select-list of the first part of the UNION.  In most SQL DBMS, you must list all the non-aggregate columns from the select-list in the GROUP BY clause.  Using the MAX means that you have aggregates for  x  and  y  in the first half of the UNION and for  a ,  b  and  c  in the second half of the UNION.']], [['1st Alternative INSERT INTO x(a, b, c, x, y)\n    SELECT a, b, c, MAX(CAST(NULL AS INTEGER)) AS x, MAX(CAST(NULL AS INTEGER)) AS y\n      FROM pqr\n     WHERE p_a IS NULL\n     GROUP BY a, b, c\n    UNION\n    SELECT MAX(a) AS a, MAX(b) AS b, MAX(c) AS c, x, y\n      FROM pqr\n     WHERE p_a IS NOT NULL\n     GROUP BY x, y;\n']], ['Conditional GROUP BY and additional columns?'], 4, 1], [(8046345, 1), [['You could replace the  GROUP BY a, b, c  clause with a DISTINCT in front of  a  in the select-list of the first part of the UNION.  In most SQL DBMS, you must list all the non-aggregate columns from the select-list in the GROUP BY clause.  Using the MAX means that you have aggregates for  x  and  y  in the first half of the UNION and for  a ,  b  and  c  in the second half of the UNION.'], ['As discussed before, you need aggregates on the columns not in the GROUP BY list.']], [['2nd Alternative INSERT INTO x(a, b, c)\n    SELECT DISTINCT a, b, c\n      FROM pqr\n     WHERE p_a IS NULL;\nINSERT INTO x(a, b, c, x, y)\n    SELECT MAX(a) AS a, MAX(b) AS b, MAX(c) AS c, x, y\n      FROM pqr\n     WHERE p_a IS NOT NULL\n     GROUP BY x, y;\n']], ['Conditional GROUP BY and additional columns?'], 4, 1], [(8046386, 0), [['First, the setup:'], ['And now the query:']], [[" DECLARE @atable TABLE (\n  Id int IDENTITY,\n  UnitId int,\n  eventtime datetime,\n  ign bit\n);\nINSERT INTO @atable (UnitId, eventtime, ign)\nSELECT 356, '2011-05-04 10:41:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 10:42:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 10:43:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 10:45:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 10:47:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 10:48:00.000', 0 UNION ALL\nSELECT 356, '2011-05-04 11:14:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 11:14:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 11:15:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 11:15:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 11:15:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 11:16:00.000', 0 UNION ALL\nSELECT 356, '2011-05-04 11:16:00.000', 0 UNION ALL\nSELECT 356, '2011-05-04 11:16:00.000', 0 UNION ALL\nSELECT 356, '2011-05-04 14:49:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 14:50:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 14:50:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 14:51:00.000', 1 UNION ALL\nSELECT 356, '2011-05-04 14:52:00.000', 0 UNION ALL\nSELECT 356, '2011-05-04 14:52:00.000', 0 UNION ALL\nSELECT 356, '2011-05-04 20:52:00.000', 0;\n"]], ['sum of time based on flag from multiple rows SQL Server'], 6, 0], [(8046386, 1), [['And now the query:'], ['The  marked  common table expression (CTE) provides us with the additional criterion I was talking about at the beginning. The result set it produces looks like this:']], [[' WITH\nmarked AS (\n  SELECT\n    *,\n    Grp = ROW_NUMBER() OVER (PARTITION BY UnitId ORDER BY eventtime) -\n     ROW_NUMBER() OVER (PARTITION BY UnitId, ign ORDER BY eventtime)\n  FROM @atable\n),\nranked AS (\n  SELECT\n    *,\n    seqRank = DENSE_RANK() OVER (PARTITION BY UnitId, ign ORDER BY Grp),\n    eventRank = ROW_NUMBER() OVER (PARTITION BY UnitId, ign, Grp ORDER BY eventtime)\n  FROM marked\n),\nfinal AS (\n  SELECT\n    s.UnitId,\n    EventStart = s.eventtime,\n    EventEnd   = e.eventtime\n  FROM ranked s\n    INNER JOIN ranked e ON s.UnitId = e.UnitId AND s.seqRank = e.seqRank\n  WHERE s.ign = 1\n    AND e.ign = 0\n    AND s.eventRank = 1\n    AND e.eventRank = 1\n)\nSELECT *\nFROM final\nORDER BY\n  UnitId,\n  EventStart\n']], ['sum of time based on flag from multiple rows SQL Server'], 6, 1], [(8046386, 2), [['The  marked  common table expression (CTE) provides us with the additional criterion I was talking about at the beginning. The result set it produces looks like this:'], ['You can see for yourself how every sequence of events with identical  ign  can now be easily distinguished from the others by its own key of  (UnitId, ign, Grp) . So now we can rank every sequence as well as every event within a sequence, which is what the  ranked  CTE does. It produces the following result set:']], [[' Id  UnitId  eventtime                ign  Grp\n--  ------  -----------------------  ---  ---\n1   356     2011-05-04 10:41:00.000  1    0\n2   356     2011-05-04 10:42:00.000  1    0\n3   356     2011-05-04 10:43:00.000  1    0\n4   356     2011-05-04 10:45:00.000  1    0\n5   356     2011-05-04 10:47:00.000  1    0\n6   356     2011-05-04 10:48:00.000  0    5\n7   356     2011-05-04 11:14:00.000  1    1\n8   356     2011-05-04 11:14:00.000  1    1\n9   356     2011-05-04 11:15:00.000  1    1\n10  356     2011-05-04 11:15:00.000  1    1\n11  356     2011-05-04 11:15:00.000  1    1\n12  356     2011-05-04 11:16:00.000  0    10\n13  356     2011-05-04 11:16:00.000  0    10\n14  356     2011-05-04 11:16:00.000  0    10\n15  356     2011-05-04 14:49:00.000  1    4\n16  356     2011-05-04 14:50:00.000  1    4\n17  356     2011-05-04 14:50:00.000  1    4\n18  356     2011-05-04 14:51:00.000  1    4\n19  356     2011-05-04 14:52:00.000  0    14\n20  356     2011-05-04 14:52:00.000  0    14\n21  356     2011-05-04 20:52:00.000  0    14\n']], ['sum of time based on flag from multiple rows SQL Server'], 6, 0], [(8046386, 3), [['You can see for yourself how every sequence of events with identical  ign  can now be easily distinguished from the others by its own key of  (UnitId, ign, Grp) . So now we can rank every sequence as well as every event within a sequence, which is what the  ranked  CTE does. It produces the following result set:'], ["You can see that an  ign=1  sequence can now be matched with an  ign=0  sequence with the help of  seqRank . And picking only the earliest event from every sequence (filtering by  eventRank=1 ) we'll get start and end times of all the  ign=1  sequences. And so the result of the  final  CTE is:"]], [[' Id  UnitId  eventtime                ign  Grp  seqRank  eventRank\n--  ------  -----------------------  ---  ---  -------  ---------\n1   356     2011-05-04 10:41:00.000  1    0    1        1\n2   356     2011-05-04 10:42:00.000  1    0    1        2\n3   356     2011-05-04 10:43:00.000  1    0    1        3\n4   356     2011-05-04 10:45:00.000  1    0    1        4\n5   356     2011-05-04 10:47:00.000  1    0    1        5\n6   356     2011-05-04 10:48:00.000  0    5    1        1\n7   356     2011-05-04 11:14:00.000  1    1    2        1\n8   356     2011-05-04 11:14:00.000  1    1    2        2\n9   356     2011-05-04 11:15:00.000  1    1    2        3\n10  356     2011-05-04 11:15:00.000  1    1    2        4\n11  356     2011-05-04 11:15:00.000  1    1    2        5\n12  356     2011-05-04 11:16:00.000  0    10   2        1\n13  356     2011-05-04 11:16:00.000  0    10   2        2\n14  356     2011-05-04 11:16:00.000  0    10   2        3\n15  356     2011-05-04 14:49:00.000  1    4    3        1\n16  356     2011-05-04 14:50:00.000  1    4    3        2\n17  356     2011-05-04 14:50:00.000  1    4    3        3\n18  356     2011-05-04 14:51:00.000  1    4    3        4\n19  356     2011-05-04 14:52:00.000  0    14   3        1\n20  356     2011-05-04 14:52:00.000  0    14   3        2\n21  356     2011-05-04 20:52:00.000  0    14   3        3\n']], ['sum of time based on flag from multiple rows SQL Server'], 6, 0], [(8046386, 4), [["You can see that an  ign=1  sequence can now be matched with an  ign=0  sequence with the help of  seqRank . And picking only the earliest event from every sequence (filtering by  eventRank=1 ) we'll get start and end times of all the  ign=1  sequences. And so the result of the  final  CTE is:"], ["There's one possible case when this query will not work as it is. It's when the event list starts with an  ign=0  event instead of  ign=1 . If that is actually possible, you could simply add the following filter to the  ranked  CTE:"]], [[' UnitId  EventStart               EventEnd\n------  -----------------------  -----------------------\n356     2011-05-04 10:41:00.000  2011-05-04 10:48:00.000\n356     2011-05-04 11:14:00.000  2011-05-04 11:16:00.000\n356     2011-05-04 14:49:00.000  2011-05-04 14:52:00.000\n']], ['sum of time based on flag from multiple rows SQL Server'], 6, 0], [(8046386, 5), [["There's one possible case when this query will not work as it is. It's when the event list starts with an  ign=0  event instead of  ign=1 . If that is actually possible, you could simply add the following filter to the  ranked  CTE:"], ['It takes advantage of the fact that the first value of  Grp  will always be  0 . So, if  0  is assigned to events with  ign=0 , those events should be excluded.']], [[' WHERE NOT (ign = 0 AND Grp = 0)\n-- Alternatively: WHERE ign <> 0 OR Grp <> 0\n']], ['sum of time based on flag from multiple rows SQL Server'], 6, 0], [(8073455, 0), [['A quick way is to check the  create_time  or  update_time  when you execute this command:'], ['like the following example:']], [[' show table  status;\n']], ['How can I Determine Date of Import from MySQL?'], 2, 1], [(8073455, 1), [['like the following example:'], ['-10000']], [[' +--------------------+--------+---------+------------+------+----------------+-------------+------------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+----------------+---------+\n| Name               | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length  | Index_length | Data_free | Auto_increment | Create_time         | Update_time         | Check_time | Collation         | Checksum | Create_options | Comment |\n+--------------------+--------+---------+------------+------+----------------+-------------+------------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+----------------+---------+\n| a_table            | MyISAM |      10 | Dynamic    |    2 |             60 |         120 |  281474976710655 |         1024 |         0 |           NULL | 2011-09-08 18:26:38 | 2011-11-07 20:38:28 | NULL       | latin1_swedish_ci |     NULL |                |         |\n']], ['How can I Determine Date of Import from MySQL?'], 2, 0], [(8108295, 1), [["It's in PHP since I need it to be dynamic, but it would basically be the following if I needed, say, only 2 tags ( animals ,  pets )."], ['Am I on the right track?']], [[" SELECT * FROM nodes n JOIN tagged_nodes t ON t.nid=n.nid\nINNER JOIN tagged_nodes t1 ON t1.tid=t.tid WHERE t1.tid='animals'\nINNER JOIN tagged_nodes t2 ON t2.tid=t.tid WHERE t2.tid='pets'\n"]], ['Intersection of sets'], 2, 1], [(8110165, 1), [['If you are able to delete stores that do not have an associated school, the following query will remove the extra rows:'], ["If you only want to delete the Store's duplicate records, I would look at this query instead of the above:"]], [[' DELETE FROM st\nFROM Stores AS st\nLEFT JOIN Schools AS sch ON st.Store_ID = sch.Store_Id\nWHERE sch.Store_id IS NULL\n']], ['Removing duplicate foreign key rows in MySQL database'], 3, 0], [(8111247, 0), [['If you want to create the table automatically you can also use the following form:'], ['Note that you can create a view over the query to dynamically build the result set on demand.  The view can then be referenced from any HLL as a logical file:']], [[' CREATE TABLE new_table_name \nAS (SELECT * FROM <querytableA> \n    UNION SELECT * FROM <querytableB>) WITH DATA\n']], ['How to move a DB2 SQL result table into a physical file?'], 2, 1], [(8128360, 0), [["Okay, so after taking Wolf's suggestion, i went in and ran the following line of code"], ['After running this, i found that somehow there were duplicates of records in this table so, this was fixed by removing the duplicates and setting the table to have unique ids. This was done by using the following script on the DB:']], [['     select categorytype, count(*) \nfrom nptcategories \ngroup by categorytype \nhaving count(*) > 1;\n']], ['using multiple left outer joins pl/sql'], 2, 0], [(8128360, 1), [['After running this, i found that somehow there were duplicates of records in this table so, this was fixed by removing the duplicates and setting the table to have unique ids. This was done by using the following script on the DB:'], ['-10000']], [[' alter table nptcategories add constraint nptcatidunq unique(categoryid)\n']], ['using multiple left outer joins pl/sql'], 2, 0], [(8139699, 0), [['-10000'], ['OR']], [[' SELECT\n  *\nFROM\n  MyTable                                 AS data\nLEFT JOIN\n  (SELECT x, y, z FROM UpdateMyTable)     AS check\n    ON  data.x = check.x\n    AND data.y = check.y\n    AND data.z = check.z\nWHERE\n  x = @x\n  AND check.x IS NULL\n']], ["select records that don't have certain values in 2 columns"], 2, 1], [(8139699, 1), [['OR'], ['-10000']], [[' SELECT\n  *\nFROM\n  MyTable                                 AS data\nWHERE\n  x = @x\n  AND NOT EXISTS (\n                  SELECT\n                    *\n                  FROM\n                    UpdateMyTable        AS check\n                  WHERE\n                      data.x = check.x\n                  AND data.y = check.y\n                  AND data.z = check.z\n                 )\n']], ["select records that don't have certain values in 2 columns"], 2, 1], [(8143581, 0), [['Try this:'], ['Returns 1 or more digits from the start of the string. \nLeave out the anchor  ^  if you want the  first sequence of digits  in the string instead of the  sequence at the start . Example:']], [[" SELECT substring(address, '^\\\\d+') AS heading_number\nFROM   tbl\nWHERE  zip = 12345\nAND    address ILIKE '3%'\n"]], ['Extract first numeric part of field'], 3, 1], [(8153000, 0), [['Sample query'], ["based on some of the comments I've read here, here's a query for you"]], [[' SELECT count(*) FROM mytable\nWHERE abs(datediff(now(), event_date)) < 365*5\n']], ['Count Events/year in SQL'], 3, 1], [(8153000, 2), [['This is NOT very pretty but you can try this with pure mysql. You can also modify this to be a stored proc if necessary:'], ['temporary table will get dropped by itself after your connection is closed. If you add DROP TABLE after SELECT, you might not get your results back.']], [[' SET @y6 = year(now());\nSET @y5 = @y6-1;\nSET @y4 = @y5-1;\nSET @y3 = @y4-1;\nSET @y2 = @y3-1;\nSET @y1 = @y2-1;\n\nSET @y7 = @y6+1;\nSET @y8 = @y7+1;\nSET @y9 = @y8+1;\nSET @y10 = @y9+1;\nSET @y11 = @y10+1;\n\nCREATE TEMPORARY TABLE event_years (event_year int not null);\nINSERT INTO event_years SELECT @y1;\nINSERT INTO event_years SELECT @y2;\nINSERT INTO event_years SELECT @y3;\nINSERT INTO event_years SELECT @y4;\nINSERT INTO event_years SELECT @y5;\nINSERT INTO event_years SELECT @y6;\nINSERT INTO event_years SELECT @y7;\nINSERT INTO event_years SELECT @y8;\nINSERT INTO event_years SELECT @y9;\nINSERT INTO event_years SELECT @y10;\nINSERT INTO event_years SELECT @y11;\n\nSELECT ey.event_year , (SELECT count(event_date) from mytable where year(event_date) = ey.event_year)\nfrom event_years ey;\n']], ['Count Events/year in SQL'], 3, 1], [(8159093, 0), [["I'm still a little unclear on what you are asking, but it appears you can get your desired result set with the following query:"], ["I'm still confused after your last comment but give this a try"]], [[" SELECT distinct 'Junior' as Database, \n       xType, \n       displayLabel, \n       child_xType, \n       child_displayLabel\nFROM MyTable\nORDER BY displayLabel DESC, child_displayLabel ASC\n"]], ['How can you order like items in a nested set hierarchical structure?'], 2, 1], [(8159093, 1), [["I'm still confused after your last comment but give this a try"], ['-10000']], [[" SELECT 'Junior' as Database, \n       xType, \n       displayLabel, \n       child_xType, \n       child_displayLabel\nFROM MyTable\nGROUP BY xType, displayLabel, child_xType, child_displayLabel\nORDER BY min(lft1),  min(lft2)\n"]], ['How can you order like items in a nested set hierarchical structure?'], 2, 1], [(8216437, 0), [['A textbook candidate for the window function row_number():'], ['This also takes care of the situation where a set of dupes on  (worker_ID,type_ID)  shares the same  date . \nSee the simplified  demo on data.SE .']], [[' ;WITH x AS (\n    SELECT unique_ID\n          ,row_number() OVER (PARTITION BY worker_ID,type_ID ORDER BY date) AS rn\n    FROM   tbl\n    )\nDELETE FROM tbl\nFROM   x\nWHERE  tbl.unique_ID = x.unique_ID\nAND    x.rn > 1\n']], ['SQL: Remove duplicates'], 2, 1], [(8216437, 1), [['This also takes care of the situation where a set of dupes on  (worker_ID,type_ID)  shares the same  date . \nSee the simplified  demo on data.SE .'], ['-10000']], [[' ;WITH x AS (\n    SELECT unique_ID\n          ,row_number() OVER (PARTITION BY worker_ID,type_ID ORDER BY date) AS rn\n    FROM   tbl\n    )\nDELETE x\nWHERE  rn > 1\n']], ['SQL: Remove duplicates'], 2, 1], [(8223650, 0), [['you could use the like operator'], ['if you are worried about tags which are not php but have php in them like say phphp then you can use with comma']], [[" select * from articles where tag like '%php%'\n"]], ['How do I get all rows that contains a string in a field (SQL)?'], 2, 1], [(8223650, 1), [['if you are worried about tags which are not php but have php in them like say phphp then you can use with comma'], ['-10000']], [[" select * from articles where tag like '%php,%' or tag like '%,php%'\n"]], ['How do I get all rows that contains a string in a field (SQL)?'], 2, 1], [(8256892, 0), [['Cast it to  dtaetimeoffset  like'], ['you can then use  SWITCHOFFSET  to get into the specified timezone. For your example']], [[' select CAST(dt as datetimeoffset)  from test\n']], ['Converting normal datetime to a time zone in sql server 2008'], 2, 1], [(8256892, 1), [['you can then use  SWITCHOFFSET  to get into the specified timezone. For your example'], ['Results in  2011-11-24 23:26:30.0600000 +05:30']], [[" select switchoffset(CAST(dt as datetimeoffset),'+05:30')  from test \n"]], ['Converting normal datetime to a time zone in sql server 2008'], 2, 1], [(8276553, 0), [['You did not state your DBMS, but the following is an ANSI compliant SQL (should work on PosgreSQL, Oracle, DB2)'], ["Edit , the following should work on SQL Server (as that doesn't yet support  lead() ):"]], [[" SELECT *\nFROM (\n    SELECT listid, \n           itemid,\n           case \n              when lead(itemid) over (partition by listid order by itemid) is null then 'last'\n              else 'not_last'\n           end as last_flag\n    FROM items_tbl\n    WHERE listID = 'List_1'\n) t\nWHERE itemID = 'item_2'\n"]], ['Figure out the last item of a group of items in SQL'], 2, 1], [(8276553, 1), [["Edit , the following should work on SQL Server (as that doesn't yet support  lead() ):"], ['-10000']], [[" SELECT listid, \n       itemid,\n       case \n         when rn = list_count the 'last'\n         else 'not_last'\n       end\nFROM (\n    SELECT listid, \n           itemid,\n           row_number() over (partition by listid order by itemid) as rn,\n           count(*) over (partition by listid) as list_count\n    FROM items_tbl\n    WHERE listID = 'List_1'\n) t\nWHERE itemID = 'item_2'\n"]], ['Figure out the last item of a group of items in SQL'], 2, 1], [(8293350, 0), [['You should try this:'], ['If you need to get all questions (even the ones not having options) you could use']], [[' SELECT que.*, opt.* FROM questions que\nINNER JOIN options opt ON que.queid = opt.queid\nWHERE que.queid = 1\n']], ['SQL query to join columns in result'], 2, 1], [(8293350, 1), [['If you need to get all questions (even the ones not having options) you could use'], ['LEFT JOIN  always loads questions and, if they have options, their options too; if not you get NULL for options columns.']], [[' SELECT que.*, opt.* FROM questions que\nLEFT JOIN options opt ON que.queid = opt.queid\nWHERE que.queid = 1\n']], ['SQL query to join columns in result'], 2, 1], [(8306044, 0), [['You can try something like this:'], ['Sample output:']], [[" select\n    Date,\n    (select sum(events)\n     from tablename d2\n     where abs(datediff(DAY, d1.Date, d2.Date)) <= 2) as EventCount\nfrom\n    tablename d1\nwhere\n    Date between '11/03/2011' and '11/07/2011'\n"]], ['SQL - Summing events by date (5 days at a time)'], 2, 1], [(8306044, 1), [['Sample output:'], ['-10000']], [[' Date        EventCount\n11/03/2011  12\n11/04/2011  9  ** Note that the correct value for w02 is 9, not 7\n11/05/2011  14\n11/06/2011  10\n11/07/2011  14\n']], ['SQL - Summing events by date (5 days at a time)'], 2, 0], [(8315026, 0), [['You could use a  CASE  statement'], ['However, it may be more efficient and easier to read to just do an  OR']], [[" SELECT id\n  FROM table\n WHERE age = (CASE WHEN variable = 'aaa' \n                   THEN 21\n                   WHEN variable = 'bbb'\n                   THEN 99\n                   ELSE null\n                END)\n"]], ['select with condition oracle'], 2, 1], [(8315026, 1), [['However, it may be more efficient and easier to read to just do an  OR'], ['-10000']], [[" SELECT id\n  FROM table\n WHERE (variable = 'aaa' AND age = 21)\n    OR (variable = 'bbb' AND age = 99)\n"]], ['select with condition oracle'], 2, 1], [(8327616, 0), [['You can use the  CONCAT()  function:'], ['or even better, the standard  || (double pipe)  operator:']], [[" SELECT * \nFROM MATERIALS \nWHERE longname LIKE CONCAT(shortname, '%')\n"]], ["Dynamic 'LIKE' Statement in SQL (Oracle)"], 2, 1], [(8327616, 1), [['or even better, the standard  || (double pipe)  operator:'], ['-10000']], [[" SELECT * \nFROM MATERIALS \nWHERE longname LIKE (shortname || '%')\n"]], ["Dynamic 'LIKE' Statement in SQL (Oracle)"], 2, 1], [(8337138, 0), [['Sample data (may vary):'], ["Select statement, it returns 0 if the day is 'weekend' or not exists in  calendar  table. Please keep in mind that  MAXRECURSION  is a value between 0 and 32,767."]], [[" select * into #totals from (\nselect '1001' as person, 114.00  as total, 199905 as month union\nselect '1001', 120.00, 199906 union\nselect '1001', 120.00, 199907 union\nselect '1001', 120.00, 199908  \n\n) t\n\nselect * into #calendar from (\nselect cast('19990501' as datetime) as tran_date, 'WEEKEND' as day_type union\nselect '19990502', 'WEEKEND' union\nselect '19990503', 'WORKING_DAY' union\nselect '19990504', 'WORKING_DAY' union\nselect '19990505', 'WORKING_DAY' union\nselect '19990601', 'WEEKEND' union\nselect '19990602', 'WORKING_DAY' union\nselect '19990603', 'WORKING_DAY' union\nselect '19990604', 'WORKING_DAY' union\nselect '19990605', 'WORKING_DAY' union\nselect '19990606', 'WORKING_DAY' union\nselect '19990701', 'WORKING_DAY' union\nselect '19990702', 'WEEKEND' union\nselect '19990703', 'WEEKEND' union\nselect '19990704', 'WORKING_DAY' union\nselect '19990801', 'WORKING_DAY' union\nselect '19990802', 'WORKING_DAY' union\nselect '19990803', 'WEEKEND' union\nselect '19990804', 'WEEKEND' union\nselect '19990805', 'WORKING_DAY' union\nselect '19990901', 'WORKING_DAY'\n) t\n"]], ['SQL to get an daily average from month total'], 2, 0], [(8337138, 1), [["Select statement, it returns 0 if the day is 'weekend' or not exists in  calendar  table. Please keep in mind that  MAXRECURSION  is a value between 0 and 32,767."], ['-10000']], [[" ;with dates as ( \n    select cast('19990501' as datetime) as tran_date \n    union all \n    select dateadd(dd, 1, tran_date) \n    from dates where dateadd(dd, 1, tran_date) <= cast('20010101' as datetime) \n) \nselect t.person , d.tran_date, (case when wd.tran_date is not null then t.total / w_days else 0 end) as day_avg \nfrom dates d \nleft join #totals t on  \n    datepart(yy, d.tran_date) * 100 + datepart(mm, d.tran_date) = t.month \nleft join ( \n        select datepart(yy, tran_date) * 100 + datepart(mm, tran_date) as month, count(*) as w_days \n        from #calendar \n        where day_type = 'WORKING_DAY' \n        group by datepart(yy, tran_date) * 100 + datepart(mm, tran_date) \n) c on t.month = c.month  \nleft join #calendar wd on d.tran_date = wd.tran_date and wd.day_type = 'WORKING_DAY' \nwhere t.person is not null\noption(maxrecursion 20000) \n"]], ['SQL to get an daily average from month total'], 2, 1], [(8350660, 1), [["I'll assume you actually want the count for each group in the projection."], ['-10000']], [[' from p in CRM.tProducts\n    join oi in CRM.tOrderItems on p.prodID equals oi.prodID\n    join o in CRM.tOrders on oi.orderID equals o.orderID\nwhere o.status > 1 && p.active == true\ngroup p by p.Name into nameGroup\norderby nameGroup.Count()\nselect new { Name = nameGroup.Key, Count = nameGroup.Count() };\n']], ['LINQ OrderBy Count of Records in a Joined Table'], 2, 1], [(8384688, 0), [['Try this (for MySQL)'], ['and this for MS-SQL']], [[" UPDATE your_table\nSET col1 = CONCAT_WS('.', col1, col2)\n"]], ['Concat two table columns and update one with result'], 2, 1], [(8384688, 1), [['and this for MS-SQL'], ['-10000']], [[' UPDATE your_table\nSET col1 =col1 || "." || col2\n']], ['Concat two table columns and update one with result'], 2, 1], [(8423506, 0), [['Quite simple'], ['Then']], [[" CREATE PROCEDURE [logging]    \n   @PROCID int,,\n   @MESSAGE VARCHAR(MAX)\n-- allows resolution of @PROCID in some circumstances\n-- eg nested calls, no direct permission on inner proc\nWITH EXECUTE AS OWNER\nAS\nBEGIN\n    -- you are using schemas, right?\n    PRINT OBJECT_SCHEMA_NAME(@PROCID) + '.' + OBJECT_NAME(@PROCID);\n    PRINT @MESSAGE\nEND;\nGO\n"]], ['T-SQL Dynamically execute stored procedure'], 2, 0], [(8423506, 1), [['Then'], ['MSDN on  OBJECT_SCHEMA_NAME  and  @@PROCID']], [[" execute logging @@PROCID, N'log_message';\n"]], ['T-SQL Dynamically execute stored procedure'], 2, 0], [(8451219, 1), [['And to import:'], ['-10000']], [[' impdp user2/pass2@db2 directory=dp_out remap_schema=user1:user2 dumpfile=user1.dmp logfile=user2.log\n']], ['How do I copy or import Oracle schemas between two different databases on different servers?'], 2, 1], [(8451558, 0), [['It sounds like you just need a simple  REPLACE'], ["You'd need to turn that into an  UPDATE  statement against your table"]], [[" SQL> with x as (\n  2    select '123E4.00' str from dual\n  3    union all\n  4    select '123K5.00' from dual\n  5    union all\n  6    select '123K123' from dual\n  7  )\n  8  select replace( str, '.' )\n  9    from x;\n\nREPLACE(\n--------\n123E400\n123K500\n123K123\n"]], ['Remove a decimal from many fields'], 2, 0], [(8524475, 0), [['-10000'], ['The result:']], [[" SET search_path='tmp';\n\nDROP TABLE items CASCADE;\nCREATE TABLE items\n    ( item_id INTEGER NOT NULL PRIMARY KEY\n    , item VARCHAR\n    , save_date date NOT NULL\n    );\nINSERT INTO items(item_id,item,save_date) VALUES\n ( 1, 'car', '2011-12-01' )\n,( 2, 'wheel', '2011-12-10' )\n,( 3, 'screen', '2011-12-11' )\n,( 4, 'table', '2011-12-15' )\n    ;\n\nDROP TABLE periods CASCADE;\nCREATE TABLE periods\n    ( period_id INTEGER NOT NULL PRIMARY KEY\n    , period_name VARCHAR\n    , start_date date NOT NULL\n    );\nINSERT INTO periods(period_id,period_name,start_date) VALUES\n ( 1, 'period1', '2011-12-05' )\n,( 2, 'period2', '2011-12-09' )\n,( 3, 'period3', '2011-12-12' )\n    ;\n-- self-join to find the next interval\nWITH pe AS (\n    SELECT p0.period_id,p0.period_name,p0.start_date\n        , p1.start_date AS end_date\n    FROM periods p0\n    -- must be a left join; because the most recent interval is still open\n    -- (has no successor)\n    LEFT JOIN periods p1 ON p1.start_date > p0.start_date\n    WHERE NOT EXISTS (\n        SELECT * FROM periods px\n        WHERE px.start_date > p0.start_date\n        AND px.start_date < p1.start_date\n        )\n    )\nSELECT it.item_id\n    , it.item\n    , it.save_date\n    , pe.period_id\n    , pe.period_name\n    , pe.start_date\n    , pe.end_date\nFROM items it\nLEFT JOIN pe\n       ON it.save_date >= pe.start_date\n      AND ( it.save_date < pe.end_date OR pe.end_date IS NULL)\n    ;\n"]], ['Join tables by suitable period'], 2, 1], [(8524475, 1), [['The result:'], ['-10000']], [['  item_id |  item  | save_date  | period_id | period_name | start_date |  end_date\n---------+--------+------------+-----------+-------------+------------+------------\n       1 | car    | 2011-12-01 |           |             |            |\n       2 | wheel  | 2011-12-10 |         2 | period2     | 2011-12-09 | 2011-12-12\n       3 | screen | 2011-12-11 |         2 | period2     | 2011-12-09 | 2011-12-12\n       4 | table  | 2011-12-15 |         3 | period3     | 2011-12-12 |\n(4 rows)\n']], ['Join tables by suitable period'], 2, 0], [(8527731, 1), [['Or, if you need the results for each REF, instead of a specific REF, you can try this:'], ['-10000']], [[' SELECT mt.REF, mt.UserName, mt.TransDate\nFROM \n    dbo.MyTable mt JOIN (\n        SELECT\n            REF,\n            MIN(TransDate) AS MinTransDate\n        FROM dbo.MyTable\n        WHERE Status = 1\n        GROUP BY REF\n    ) MinResult mr ON mr.REF = mt.REF AND mr.MinTransDate = mt.TransDate\n']], ['sql subquery group by'], 2, 1], [(8546198, 0), [['You can use a case statement in your join condition, something like this:'], ['However, depending on your indexes, it may be quicker to use a union, eg.']], [[' SELECT * FROM games g\n    JOIN accounts a \n      ON a.id = case g.userid1 when ? then g.userid2 else g.userid1 end\nWHERE \n    g.userid1 = ? OR g.userid2 = ?\n']], ['Selecting using two column names, using the other one if one is known of each record'], 3, 1], [(8546198, 1), [['However, depending on your indexes, it may be quicker to use a union, eg.'], ['An alternative query using  OR ,']], [['   SELECT * FROM games g\n      JOIN accounts a ON a.id = case g.userid2\n  WHERE g.userid1 = ?\nUNION ALL\n  SELECT * FROM games g\n      JOIN accounts a ON a.id = case g.userid1\n  WHERE g.userid2 = ?\n']], ['Selecting using two column names, using the other one if one is known of each record'], 3, 1], [(8546198, 2), [['An alternative query using  OR ,'], ['-10000']], [[' SELECT * FROM games g, accounts a \nWHERE \n      (g.userid1 = ? AND g.userid2 = a.id) \n   OR (g.userid2 = ? AND g.userid1 = a.id)\n']], ['Selecting using two column names, using the other one if one is known of each record'], 3, 1], [(8578252, 0), [['Try something like this.'], ['Or something like this where @normaldate is the search date.']], [["  select CAST(replace(convert(varchar, getdate(), 101), '/', '') AS DECIMAL)\n"]], ['change sql parameter to date decimal'], 2, 1], [(8578252, 1), [['Or something like this where @normaldate is the search date.'], ['-10000']], [[" SELECT decimaldate FROM TABLE1 WHERE decimaldate = CAST(replace(convert(varchar, @normaldate, 101), '/', '') AS DECIMAL)\n"]], ['change sql parameter to date decimal'], 2, 1], [(8610517, 0), [['The parameterization of the  DBMS_XMLGEN  call seems to be the goal. This is accomplished by using a little PL/SQL.  The Oracle Docs for the DBMS_XMLGEN package  describe a few operations which should help. First, create a context from a SYS_REFCURSOR using this form:'], ['Then, use the context in another form of  GetXML :']], [[' DBMS_XMLGEN.NEWCONTEXT (\n  queryString  IN SYS_REFCURSOR)\nRETURN ctxHandle;\n']], ['Trying to replace dbms_xmlgen.xmlget with sys_xmlagg'], 3, 0], [(8610517, 1), [['Then, use the context in another form of  GetXML :'], ['Roughly, your code would look something like this:']], [[' DBMS_XMLGEN.GETXML (\n   ctx          IN ctxHandle, \n   tmpclob      IN OUT NCOPY CLOB,\n   dtdOrSchema  IN number := NONE)\nRETURN BOOLEAN;\n']], ['Trying to replace dbms_xmlgen.xmlget with sys_xmlagg'], 3, 0], [(8629046, 0), [['Unless you explain in more detail how those values from  Value1  and  Value2  columns belong together, and only if that "matching" is really deterministic, then you could do something like this:'], ['Something like:']], [[" DECLARE @temp TABLE (ID INT, Value1 VARCHAR(20), Value2 VARCHAR(20))\n\nINSERT INTO @temp\n        (ID, Value1, Value2)\nVALUES\n        (1, 'Rajan', NULL),\n        (3, 'Vijayan', NULL),\n        (1, NULL, 'Ravi'),\n        (3, NULL, 'sudeep'),\n        (2, 'kumar', NULL),\n        (2, NULL, 'venkat')\n\nSELECT DISTINCT\n   ID, \n   (SELECT Value1 FROM @temp t2 WHERE t2.ID = t.ID AND Value1 IS NOT NULL) AS 'Value1',\n   (SELECT Value2 FROM @temp t2 WHERE t2.ID = t.ID AND Value2 IS NOT NULL) AS 'Value2'\nFROM\n   @temp t\n"]], ['How to avoid the null values'], 3, 1], [(8629046, 1), [['Something like:'], ['would give you a reproducible output of:']], [[" DECLARE @temp TABLE (ID INT, Value1 VARCHAR(20), Value2 VARCHAR(20))\n\nINSERT INTO @temp\n        (ID, Value1, Value2)\nVALUES\n        (1, 'Rajan', NULL),\n        (1, 'Vijayan', NULL),\n        (1, NULL, 'Ravi'),\n        (1, NULL, 'sudeep'),\n        (2, 'kumar', NULL),\n        (2, NULL, 'venkat')\n\n;WITH Value1CTE AS\n(\n    SELECT ID, Value1,\n       ROW_NUMBER() OVER (PARTITION BY ID ORDER BY Value1) AS 'RowNum'\n    FROM @temp\n    WHERE Value1 IS NOT NULL\n),\nValue2CTE AS\n(\n    SELECT ID, Value2,\n       ROW_NUMBER() OVER (PARTITION BY ID ORDER BY Value2) AS 'RowNum'\n    FROM @temp\n    WHERE Value2 IS NOT NULL\n)\nSELECT \n   v1.ID, \n    v1.Value1, v2.Value2\nFROM\n   Value1CTE v1\nINNER JOIN \n    Value2CTE v2 ON v1.ID = v2.ID AND v1.RowNum = v2.RowNum\n"]], ['How to avoid the null values'], 3, 1], [(8629046, 2), [['would give you a reproducible output of:'], ["This is under the assumption that given two entries with the  SAME  ID, you want to sort ( ORDER BY ) the actual values (e.g.  Rajan  before  Vijayan  and  Ravi  before  sudeep  --> there you'd join  Rajan  and  Ravi  together, as well as  Vijayan  and  sudeep )."]], [[' ID  Value1  Value2\n1   Rajan   Ravi\n1   Vijayan sudeep\n2   kumar   venkat\n']], ['How to avoid the null values'], 3, 0], [(8636956, 0), [['Try this to compare the first 8 characters only:'], ['The cast implicitly trims trailing characters.  ddid  only has 8 characters to begin with. No need to process it, too. This achieves the same:']], [[' SELECT r.domainid, r.dombegin, r.domend, d.ddid \nFROM   domainregion r\nJOIN   dyndomrun d ON r.domainid::varchar(8) = d.ddid \nORDER  BY r.domainid, d.ddid, r.dombegin, r.domend;\n']], ['How to join two tables with one of them not having a primary key and not the same character length'], 3, 1], [(8645254, 0), [['The simplest way is to compare a COUNT per ID with the number of elements in your list:'], ["Edit, with question update. In MySQL, it's easier to use a separate table for search terms"]], [[" SELECT\n   ID\nFROM\n   MyTable\nWHERE\n   NAME IN ('A', 'B', 'C')\nGROUP BY\n   ID\nHAVING\n   COUNT(*) = 3;\n"]], ['Find rows with same ID and have a particular set of names'], 3, 1], [(8647675, 0), [['then when we looked for speed'], ['and now our database is only responsible for storing and retrieving data']], [[' we made them into CLR functions\nhttp://msdn.microsoft.com/en-US/library/a8s4s5dz(v=VS.90).aspx\n']], ['List category/subcategory tree and display its sub-categories in the same row'], 2, 0], [(8647675, 1), [['and now our database is only responsible for storing and retrieving data'], ['-10000']], [[' this sort of thing will be in our data layer in the application\n']], ['List category/subcategory tree and display its sub-categories in the same row'], 2, 0], [(8669703, 0), [['This may be oversimplifying the problem, but if you have control over the sp, just use in rather than =:'], ['If this is not an option, just push the results of both sproc calls into a temp table:']], [[' CREATE PROCEDURE [dbo].[MyStored]\nAS\n   SELECT blahblahblah WHERE StoredState IN (0,1) LotsOfJoinsFollow;\nRETURN 0\n']], ['How do I combine result sets from two stored procedure calls?'], 2, 1], [(8669703, 1), [['If this is not an option, just push the results of both sproc calls into a temp table:'], ['-10000']], [[' /*Create a table with the same columns that the sproc returns*/\nCREATE TABLE #tempblahblah(blahblahblah NVARCHAR(50))\n\nINSERT #tempblahblah ( blahblahblah )\n EXEC MyStored 0\n\nINSERT #tempblahblah ( blahblahblah )\n EXEC MyStored 1\n\nSELECT * FROM #tempblahblah']], ['How do I combine result sets from two stored procedure calls?'], 2, 1], [(8684054, 0), [['You need some modulo operations and  DATEDIFF .'], ['Gives output ']], [[" declare @periodStart datetime\ndeclare @periodEnd datetime\n\nset @periodStart = CAST('2011-12-03' as datetime)\nset @periodEnd = CAST('2011-12-16' as datetime)\n\ndeclare @anyDate datetime\nset @anyDate = CAST('2011-12-30' as datetime)\n\ndeclare @periodLength int\nset @periodLength = DATEDIFF(day, @periodStart, @periodEnd) + 1\n\n\ndeclare @daysFromFirstPeriod int\nset @daysFromFirstPeriod = DATEDIFF(day, @periodStart, @anyDate)\ndeclare @daysIntoPeriod int\nset @daysIntoPeriod = @daysFromFirstPeriod % @periodLength\n\nselect @periodLength as periodLength, @daysFromFirstPeriod as daysFromFirstPeriod, @daysIntoPeriod as daysIntoPeriod\nselect DATEADD(day, -@daysIntoPeriod, @anyDate) as currentPeriodStart, DATEADD(day, @periodLength -@daysIntoPeriod, @anyDate) as currentPeriodEnd\n"]], ['T-SQL how to get date range for 2 week pay period'], 3, 1], [(8684054, 1), [['Gives output '], ['and']], [[' periodLength    daysFromFirstPeriod daysIntoPeriod\n14              27                  13\n']], ['T-SQL how to get date range for 2 week pay period'], 3, 0], [(8684054, 2), [['and'], ['-10000']], [[' currentPeriodStart        currentPeriodEnd\n2011-12-17 00:00:00.000   2011-12-31 00:00:00.000\n']], ['T-SQL how to get date range for 2 week pay period'], 3, 0], [(8711054, 0), [['Here is an example:'], ['-10000']], [[" declare @test varchar(5)\nselect @test = '12,'\n\nselect substring(@test, 1, len(@test)-1)\n"]], ['Trying to get rid of comma at end of a column'], 2, 1], [(8711054, 1), [['-10000'], ['-10000']], [[" UPDATE [Database].[schema].[Table]\nSET    substring([Columnx], 1, len([Columnx])-1)\nWHERE  [Columnx] like '%,'\nAND  len([Columnx]) > 0\n"]], ['Trying to get rid of comma at end of a column'], 2, 1], [(8718458, 0), [['You can always use the  GROUP BY /  HAVING  query in an IN clause.  This works and is relatively straightforward but it may not be particularly efficient if the number of duplicate rows is relatively large.'], ['It would generally be more efficient to use analytic functions in order to avoid hitting the table a second time.  ']], [[' SELECT *\n  FROM table1\n WHERE (name, type_id) IN (SELECT name, type_id\n                             FROM table1\n                            GROUP BY name, type_id\n                           HAVING COUNT(*) > 1)\n']], ['view all data for duplicate rows in oracle'], 3, 1], [(8718458, 1), [['It would generally be more efficient to use analytic functions in order to avoid hitting the table a second time.  '], ['Depending on what you are planning to do with the data and how many duplicates of a particular row there might be, you also might want to join  table1  to itself to get the data in a single row']], [[' SELECT *\n  FROM (SELECT id, \n               name,\n               type_id,\n               code,\n               lat,\n               long,\n               count(*) over (partition by name, type_id) cnt\n          FROM table1)\n WHERE cnt > 1\n']], ['view all data for duplicate rows in oracle'], 3, 1], [(8718458, 2), [['Depending on what you are planning to do with the data and how many duplicates of a particular row there might be, you also might want to join  table1  to itself to get the data in a single row'], ['-10000']], [[' SELECT a.name,\n       a.type_id,\n       a.id,\n       b.id,\n       a.code,\n       b.code,\n       a.lat,\n       b.lat,\n       a.long,\n       b.long\n  FROM table1 a\n       JOIN table1 b ON (a.name = b.name AND\n                         a.type_id = b.type_id AND\n                         a.rowid > b.rowid)\n']], ['view all data for duplicate rows in oracle'], 3, 1], [(8806028, 0), [['You can always just do the sums again, like so:'], ['Or, faster, you can wrap it up in a subquery, like this:']], [[" SELECT \n    shop_id,\n    sum(CASE WHEN product = 'Fiesta' THEN units END) as Fiesta,\n    sum(CASE WHEN product = 'Focus' THEN units END) as Focus,\n    sum(CASE WHEN product = 'Puma' THEN units END) as Puma,\n    sum(CASE WHEN product = 'Fiesta' THEN units END) / sum(CASE WHEN product = 'Focus' THEN units END) as Ratio\nFROM sales\nGROUP BY shop_id\n"]], ['How to do calculations with crosstab/pivot via case in sqlite?'], 2, 1], [(8806028, 1), [['Or, faster, you can wrap it up in a subquery, like this:'], ['-10000']], [[" select\n    shop_id,\n    Fiesta,\n    Focus,\n    Puma,\n    Fiesta/Focus as Ratio\nfrom\n    (\n    SELECT \n        shop_id,\n        sum(CASE WHEN product = 'Fiesta' THEN units END) as Fiesta,\n        sum(CASE WHEN product = 'Focus' THEN units END) as Focus,\n        sum(CASE WHEN product = 'Puma' THEN units END) as Puma\n    FROM sales\n    GROUP BY shop_id\n    ) x\n"]], ['How to do calculations with crosstab/pivot via case in sqlite?'], 2, 1], [(8847175, 0), [['You could make it easier for yourself by adding an extra column, containing the sum of the amounts with a lower ID.'], ['You can then select based on that new column:']], [[' "ID" "oamount" "mamount"\n\'1\'  \'1500\'    \'0\'\n\'2\'  \'2000\'    \'1500\'\n\'3\'  \'2000\'    \'3500\'\n\'4\'  \'1000\'    \'5500\'\n']], ['how to select from table untill the total is a specific number?'], 2, 0], [(8928978, 2), [['Example:'], ['-10000']], [[" CREATE TABLE petnames(name VARCHAR(40));\nINSERT INTO petnames VALUES\n  ('barfy'),('max'),('whiskers'),('champ'),('big-D'),('Big D'),('Sally');\n\nSELECT name FROM petnames WHERE 'bigD' SOUNDS LIKE name;\n+-------+\n| name  |\n+-------+\n| big-D |\n| Big D |\n+-------+\n"]], ['How can I use the LIKE operator on a list of strings to compare?'], 3, 1], [(8939857, 0), [['Turns out, it can be even simpler. :)'], ['Or, if you actually want the data type  date  instead of  timestamp with time zone :']], [[" SELECT generate_series(\n          date_trunc('year', min(created_at))\n        , now()\n        , interval '1 month') AS month;\nFROM   users;\n"]], ['Generating a series from a predefined date (PG)'], 2, 1], [(9015870, 0), [['+row position'], ['-10000']], [[" SELECT car_id, url, signup, CONCAT(pos1, '/', @p1) position FROM (\n  SELECT\n    c.*,\n    @p1:=@p1+1 pos1,\n    @p2:=IF(car_id = 3 AND @p2 IS NULL, @p1, @p2)\n  FROM\n    cars c,\n    (SELECT @p1:=0, @p2:=NULL) t\n  ORDER BY\n    signup\n) t\nWHERE\n  pos1 BETWEEN @p2 - 1 AND @p2 + 1\n"]], ['Find position of given PK and next and previous row as one result row'], 2, 1], [(9015870, 1), [['-10000'], ['-10000']], [[' SELECT\n  @p2 pos,\n  MAX(IF(pos1 > @p2, car_id, NULL)) nextid,\n  MAX(IF(pos1 > @p2, url, NULL)) nexturl,\n  MAX(IF(pos1 < @p2, car_id, NULL)) previd,\n  MAX(IF(pos1 < @p2, url, NULL)) prevurl\nFROM (\n  SELECT\n    c.*,\n    @p1:=@p1+1 pos1,\n    @p2:=IF(car_id = 3 AND @p2 IS NULL, @p1, @p2)\n  FROM\n    cars c,\n    (SELECT @p1:=0, @p2:=NULL) t\n  ORDER BY\n    signup\n) t\nWHERE\n  pos1 BETWEEN @p2 - 1 AND @p2 + 1\n']], ['Find position of given PK and next and previous row as one result row'], 2, 1], [(9056169, 0), [["If you're looking for the first range that contains at least a part of the block, try a condition like:"], ['In SQL:']], [[' vala <= colb and cola <= valb\n']], ['Ranges on multiple columns'], 2, 0], [(9056169, 1), [['In SQL:'], ['-10000']], [[' select  *\nfrom    example\nwhere   vala <= colb and cola <= valb\norder by\n        cola -- Lowest network range\nlimit   1\n']], ['Ranges on multiple columns'], 2, 1], [(9127317, 0), [['Use  isnull , if  UPDATE_DATE  is null it uses  CREATION_DATE  to order rows.'], ["coalesce  is an alternative and it's going to work in most RDBMS (afaik)."]], [[' select * \nfrom table\norder by isnull(UPDATE_DATE, CREATION_DATE) asc\n']], ['How to order by a column (which match a criteria) in SQL?'], 2, 1], [(9127317, 1), [["coalesce  is an alternative and it's going to work in most RDBMS (afaik)."], ['-10000']], [[' select * \nfrom table\norder by coalesce(UPDATE_DATE, CREATION_DATE) asc\n']], ['How to order by a column (which match a criteria) in SQL?'], 2, 1], [(9153901, 0), [["You don't even need a subquery:"], ['If there are more than one results with same Max count, then you need a subquery:']], [[' SELECT COUNT(bc.taken) AS mn\n     , b.title\nFROM books_clients AS bc\n  JOIN books b \n    ON b.book_id = bc.book_id\nGROUP BY b.title\nORDER BY mn DESC\nLIMIT 1\n']], ['Select max value within other select statement and display also a relevant field from the nested select'], 2, 1], [(9153901, 1), [['If there are more than one results with same Max count, then you need a subquery:'], ['-10000']], [[' SELECT allb.mn\n     , allb.title\nFROM \n    ( SELECT COUNT(bc.taken) AS mn\n      FROM books_clients AS bc\n        JOIN books b \n          ON b.book_id = bc.book_id\n      GROUP BY b.title\n      ORDER BY mn DESC\n      LIMIT 1\n    ) AS maxb\n  JOIN\n    ( SELECT COUNT(bc.taken) AS mn\n           , b.title\n      FROM books_clients AS bc\n        JOIN books b \n          ON b.book_id = bc.book_id\n      GROUP BY b.title\n    ) AS allb\n    ON allb.mn = maxb.man\n']], ['Select max value within other select statement and display also a relevant field from the nested select'], 2, 1], [(9172621, 0), [['Given date like this:'], ['You can get the per-game rankings with this:']], [['  id | player_id | game_id | points \n----+-----------+---------+--------\n  1 |         1 |       1 |      0\n  2 |         1 |       2 |      1\n  3 |         1 |       3 |      5\n  4 |         2 |       1 |      1\n  5 |         2 |       2 |      0\n  6 |         2 |       3 |      0\n  7 |         3 |       1 |      2\n  8 |         3 |       2 |      3\n  9 |         3 |       3 |      1\n']], ['Enumerate in postgresql'], 3, 0], [(9172621, 1), [['You can get the per-game rankings with this:'], ['That will give you output like this:']], [[' select game_id, player_id, points,\n       rank() over (partition by game_id order by points desc)\nfrom players\n']], ['Enumerate in postgresql'], 3, 1], [(9172621, 2), [['That will give you output like this:'], ['-10000']], [['  game_id | player_id | points | rank \n---------+-----------+--------+------\n       1 |         3 |      2 |    1\n       1 |         2 |      1 |    2\n       1 |         1 |      0 |    3\n       2 |         3 |      3 |    1\n       2 |         1 |      1 |    2\n       2 |         2 |      0 |    3\n       3 |         1 |      5 |    1\n       3 |         3 |      1 |    2\n       3 |         2 |      0 |    3\n']], ['Enumerate in postgresql'], 3, 0], [(9197597, 0), [['Correlated-Sub-Query:'], ['Sub-Query:']], [[" SELECT\n  count(browser), browser\nFROM\n  access\nWHERE\n      date = (SELECT MIN(date) FROM access AS lookup WHERE ip = access.ip)\n  AND date > '2011-11-1'\n  AND date < '2011-12-1' \nGROUP BY\n  browser\n"]], ['How to determine first instance of multiple items in a table'], 2, 1], [(9197597, 1), [['Sub-Query:'], ['Either way, be sue to have an index on  (ip, date)']], [[" SELECT\n  count(access.browser), access.browser\nFROM\n  (SELECT ip, MIN(date) AS date FROM access GROUP BY ip) AS lookup\nINNER JOIN\n  access\n    ON  access.ip   = lookup.ip\n    AND access.date = lookup.date\nWHERE\n      lookup.date > '2011-11-1'\n  AND lookup.date < '2011-12-1' \nGROUP BY\n  access.browser\n"]], ['How to determine first instance of multiple items in a table'], 2, 1], [(9206962, 0), [['There are several options - just 2 as examples:'], ['OR']], [[' SELECT nums.number FROM nums \nLEFT OUTER JOIN even ON even.number = nums.number \nWHERE even.number IS NULL\n']], ['Oracle SQL - Using joins to find values in one table, and not another'], 2, 1], [(9206962, 1), [['OR'], ['-10000']], [[' SELECT nums.number FROM nums\nMINUS\nSELECT even.number FROM even\n']], ['Oracle SQL - Using joins to find values in one table, and not another'], 2, 1], [(9218949, 0), [['You can use this query to produce results below:'], ["This does not get everything into a single row like you wanted (you'd need a pivot for that, and I don't think sqlite has it), but it lets you see what is going on. Here is what you'd get from this query:"]], [[' select p1.name, p2.name, t.name\nfrom places p1\njoin placestags pt1 on p1.id=pt1.placeid\njoin placestags pt2 on pt1.tagid=pt2.tagid and pt2.placeid <> p1.id\njoin places p2 on pt2.placeid=p2.id\njoin tags t on t.id=pt1.tagid\norder by p1.id, t.id\n']], ['Query places that have common tags in database'], 3, 1], [(9218949, 1), [["This does not get everything into a single row like you wanted (you'd need a pivot for that, and I don't think sqlite has it), but it lets you see what is going on. Here is what you'd get from this query:"], ['If you are looking to shorten the query time, try reducing the number of joins, and remove the symmetric duplicates, like this:']], [[' Place1      |   Place2       | Shared_Tag\n------------|----------------|-----------\nMcDonalds       Burger King     Burgers\nMcDonalds       Burger King     Fries\nBurger King     McDonalds       Burgers\nBurger King     McDonalds       Fries\n']], ['Query places that have common tags in database'], 3, 0], [(9218949, 2), [['If you are looking to shorten the query time, try reducing the number of joins, and remove the symmetric duplicates, like this:'], ['-10000']], [[' select pt1.placeid, pt2.placeid, pt1.tagid\nfrom placestags pt1\njoin placestags pt2 on pt1.tagid=pt2.tagid and pt2.placeid > pt1.placeid\norder by pt1.placeid, pt1.tagid\n']], ['Query places that have common tags in database'], 3, 1], [(9237650, 0), [['e.g., Using IIf'], ['e.g., Using SWITCH']], [[' SELECT Slot.Day\nFROM Slot\nGROUP BY Slot.Day\nORDER BY IIf(Slot.Day = "Monday", 1,\n         IIf(Slot.Day = "Tuesday", 2,\n         IIf(Slot.Day = "Wednesday", 3,\n         IIf(Slot.Day = "Thursday", 4,\n         IIf(Slot.Day = "Friday", 5)))));\n']], ['Sort Days of the Week in SQL'], 2, 1], [(9237650, 1), [['e.g., Using SWITCH'], ['-10000']], [[" SELECT Slot.Day\nFROM Slot\nGROUP BY Slot.Day\nORDER BY SWITCH(Slot.Day = 'Monday', 1,\n                Slot.Day = 'Tuesday', 2,\n                Slot.Day = 'Wednesday', 3,\n                Slot.Day = 'Thursday', 4,\n                Slot.Day = 'Friday', 5);\n"]], ['Sort Days of the Week in SQL'], 2, 1], [(9288893, 0), [['The simple set'], ['can be sorted']], [[' 5    10\n7    null\nnull 8\n']], ['SQL: ORDER BY based on two columns of interlaced values'], 3, 0], [(9288893, 1), [['can be sorted'], ['and ']], [[' null 8\n5    10\n7    null\n']], ['SQL: ORDER BY based on two columns of interlaced values'], 3, 0], [(9288893, 2), [['and '], ['depending on where you start sorting.']], [[' 5    10\n7    null\nnull 8\n']], ['SQL: ORDER BY based on two columns of interlaced values'], 3, 0], [(9301321, 1), [['Edit:\nBased on your comment you should be able to do something this like:'], ['If you want to be sure you always get 3 results:']], [[' SELECT * \nFROM list_cards \nWHERE card_id IN (1, 2) AND qty > 0\n\nUNION\n\nSELECT * \nFROM list_cards \nWHERE qty > 0\n']], ['sql to find certain ids and fillins'], 3, 1], [(9355066, 0), [['If you want no ads in  either  table, then the sort of query you are after is:'], ['To select ids from other tables:']], [[' SELECT id\nFROM members\nWHERE id NOT IN ( any id from any other table )\n']], ['A MySQL query addressing three tables: How many from A are not in B or C?'], 4, 0], [(9355066, 1), [['To select ids from other tables:'], ['Hence:']], [[' SELECT id\nFROM <othertable>\n']], ['A MySQL query addressing three tables: How many from A are not in B or C?'], 4, 0], [(9355066, 2), [['Hence:'], ['If you wanted to avoid a sub-query (a possible performance increase, depending..) you could use some LEFT JOINs:']], [[' SELECT id\nFROM members\nWHERE id NOT IN (SELECT id FROM dog_shareoffered)\n AND  id NOT IN (SELECT id FROM dog_sharewanted)\n']], ['A MySQL query addressing three tables: How many from A are not in B or C?'], 4, 1], [(9355066, 3), [['If you wanted to avoid a sub-query (a possible performance increase, depending..) you could use some LEFT JOINs:'], ['Why this works:']], [[' SELECT members.id\nFROM members\nLEFT JOIN dog_shareoffered\n ON dog_shareoffered.id = members.id\nLEFT JOIN dog_sharewanted\n ON dog_sharewanted.id = members.id\nWHERE dog_shareoffered.id IS NULL\n  AND dog_sharewanted.id IS NULL\n']], ['A MySQL query addressing three tables: How many from A are not in B or C?'], 4, 1], [(9356686, 0), [['Try'], ['or']], [[' select a.* from Article a\ninner join ArticleTag at\n  on at.idArticle = a.idArticle\nwhere at.idTag in (select idTag from ArticleTag where idArticle =5)\n']], ['mysql query for related articles'], 2, 1], [(9356686, 1), [['or'], ['-10000']], [[' select a.* from Article a\ninner join ArticleTag at on at.idArticle= a.idArticle\ninner join ArticleTag at2 on at2.idTag = a.idTag and at2.IdArticle! = at.idArticle\nwhere at2.idArticle = 5\n']], ['mysql query for related articles'], 2, 1], [(9394879, 0), [['Long-winded option'], ["Working from the innermost query to the outermost.  This query selects the basic fees and calculates the total_costs for this row.  This total_costs formula will need adjustment as I'm not 100% clear on what you were looking for there.  Will refer to this as  [SQ1]"]], [[" (\n    SELECT\n        financesTallied.date,\n        financesTallied.rate,\n        financesTallied.supply_fee,\n        financesTallied.demand_fee,\n        financesTallied.charged_fee,\n        financesTallied.total_costs,\n        financesTallied.net_return\n\n    FROM (\n\n        SELECT\n            financeWithNetReturn.*,\n            @supplyFee := @supplyFee + financeWithNetReturn.supply_fee,\n            @demandFee := @demandFee + financeWithNetReturn.demand_fee,\n            @charedFee := @charedFee + financeWithNetReturn.charged_fee\n        FROM \n        ( // Calculate net return based off total costs\n            SELECT \n                financeData.*,\n                financeData.supply_fee - financeData.total_costs AS net_return\n            FROM \n            ( // Select the data\n                SELECT\n                    date, \n                    rate, \n                    supply_fee, \n                    demand_fee, \n                    charged_fee,\n                    (supply_fee+demand_fee+charged_fee)/rate AS total_costs // need clarification on others/rate\n                FROM financies\n                WHERE date BETWEEN '2010-01-10' AND '2011-01-01'\n                ORDER BY date ASC\n            ) AS financeData\n        ) AS financeWithNetReturn,\n        (\n            SELECT\n                @supplyFee := 0\n                @demandFee := 0\n                @charedFee := 0\n        ) AS variableInit\n    ) AS financesTallied\n) UNION (\n    SELECT\n        '*Total*',\n        NULL,\n        @supplyFee,\n        @demandFee,\n        @chargedFee,\n        NULL,\n        NULL\n)\n"]], ['Sum totals for columns'], 7, 1], [(9394879, 1), [["Working from the innermost query to the outermost.  This query selects the basic fees and calculates the total_costs for this row.  This total_costs formula will need adjustment as I'm not 100% clear on what you were looking for there.  Will refer to this as  [SQ1]"], ["Next level up I'm just reusing the calculated total_costs column with the supply_fee column to add in a net_return column. This concludes the basic data you need per-row, will refer to this as  [SQL2]"]], [["             SELECT\n                date, \n                rate, \n                supply_fee, \n                demand_fee, \n                charged_fee,\n                (supply_fee+demand_fee+charged_fee)/rate AS total_costs // need clarification on others/rate\n            FROM financies\n            WHERE date BETWEEN '2010-01-10' AND '2011-01-01'\n            ORDER BY date ASC\n"]], ['Sum totals for columns'], 7, 0], [(9394879, 2), [["Next level up I'm just reusing the calculated total_costs column with the supply_fee column to add in a net_return column. This concludes the basic data you need per-row, will refer to this as  [SQL2]"], ["At this level it's time to start tallying up the values, so need to initialise the variables required with 0 values ( [SQL3] )"]], [['         SELECT \n            financeData.*,\n            financeData.supply_fee - financeData.total_costs AS net_return\n        FROM \n        ([SQ1]) AS financeData\n']], ['Sum totals for columns'], 7, 0], [(9394879, 3), [["At this level it's time to start tallying up the values, so need to initialise the variables required with 0 values ( [SQL3] )"], ["Next level up, I'm using the calculated rows to calculate the totals ( [SQL4] )"]], [['         SELECT\n            @supplyFee := 0\n            @demandFee := 0\n            @charedFee := 0 \n']], ['Sum totals for columns'], 7, 0], [(9394879, 4), [["Next level up, I'm using the calculated rows to calculate the totals ( [SQL4] )"], ['Now finally at the top level, just need to output the desired columns without the calculated columns ( [SQL5] )']], [['     SELECT\n        financeWithNetReturn.*,\n        @supplyFee := @supplyFee + financeWithNetReturn.supply_fee,\n        @demandFee := @demandFee + financeWithNetReturn.demand_fee,\n        @charedFee := @charedFee + financeWithNetReturn.charged_fee\n    FROM \n    ([SQL2]) AS financeWithNetReturn,\n    ([SQL3]) AS variableInit\n']], ['Sum totals for columns'], 7, 0], [(9394879, 5), [['Now finally at the top level, just need to output the desired columns without the calculated columns ( [SQL5] )'], ['And then output it UNIONED with a totals row']], [[' SELECT\n    financesTallied.date,\n    financesTallied.rate,\n    financesTallied.supply_fee,\n    financesTallied.demand_fee,\n    financesTallied.charged_fee,\n    financesTallied.total_costs,\n    financesTallied.net_return\n\nFROM ([SQL4]) AS financesTallied\n']], ['Sum totals for columns'], 7, 0], [(9394879, 6), [['And then output it UNIONED with a totals row'], ['-10000']], [[" ([SQL5]) UNION (\n    SELECT\n        '*Total*',\n        NULL,\n        @supplyFee,\n        @demandFee,\n        @chargedFee,\n        NULL,\n        NULL\n)\n"]], ['Sum totals for columns'], 7, 0], [(9403894, 1), [['-10000'], ['-10000']], [[" SELECT\n  cl.id, cl.lead_id, cl.client_name, \n  po.id, po.carrier,\n  pa.downpayment_time, pa.status, pa.policy_id\nFROM\n  pdp_client_info AS cl\n  JOIN pdp_policy_info AS po ON (cl.id = po.id)\n  JOIN pdp_payment AS pa ON (po.id = pa.policy_id)\nWHERE\n  (pa.downpayment_date = '$current_date')\n  AND (pa.status IN ('pending', 'failed', 'application', 'submitted', 'canceled'))\nORDER BY\n  FIND_IN_SET(pa.status, 'pending,failed,application,submitted,canceled')\n"]], ['Sort by a particular value'], 2, 1], [(9414038, 0), [["There's no need to get data about employees if all you want is sales per region. Your subquery is therefore redundant..."], ['There are two strategies to avoid this. One is to assign the sale to just one region; in the comments, you say there\'s no data on which to make that decision, so you could do it on the "lowest regionID) - something like:']], [[' select\n      r.RegionDescription, \n      sum(OD.Quantity*OD.UnitPrice)\nfrom\n   Region R\n   inner join Territories T\n       on R.RegionID=T.RegionID\n   inner join EmployeeTerritories ET\n       on T.TerritoryID=ET.TerritoryID\n   inner join  Employees E\n       on ET.EmployeeID=E.EmployeeID\n   inner join Orders O\n       on E.EmployeeID=o.EmployeeID\n   inner join [Order Details] OD\n                on o.OrderID=OD.OrderID\n  Group by r.RegionDescription\n']], ['Join between two master and one detail Table'], 2, 0], [(9414038, 1), [['There are two strategies to avoid this. One is to assign the sale to just one region; in the comments, you say there\'s no data on which to make that decision, so you could do it on the "lowest regionID) - something like:'], ["(again, no access to DB, so can't test - but this should filter out duplicates)."]], [[' select\n      r.RegionDescription, \n      sum(OD.Quantity*OD.UnitPrice)\nfrom\n   Region R\n   inner join Territories T\n       on R.RegionID=T.RegionID\n   inner join EmployeeTerritories ET\n       on T.TerritoryID=ET.TerritoryID\n   inner join  Employees E\n       on ET.EmployeeID=E.EmployeeID\n   inner join Orders O\n       on E.EmployeeID=o.EmployeeID\n   inner join [Order Details] OD\n                on o.OrderID=OD.OrderID\n  Group by r.RegionDescription\n  having et.TerritoryID = min(territoryID)\n']], ['Join between two master and one detail Table'], 2, 1], [(9419615, 0), [['I do a first reasearch with the first criterium\xa0:'], ['I get the result in a PHP array. Then, a second one, with the second criterium\xa0:']], [[' where Topics.PK_TOPICS=8\n']], ['SQL query on many-to-many with redundant constraint'], 3, 0], [(9419615, 1), [['I get the result in a PHP array. Then, a second one, with the second criterium\xa0:'], ['I get the results in another, temporary PHP array.\nAnd then I use PHP array_intersect()\xa0:']], [[' where Topics.PK_TOPICS=15\n']], ['SQL query on many-to-many with redundant constraint'], 3, 0], [(9419615, 2), [['I get the results in another, temporary PHP array.\nAnd then I use PHP array_intersect()\xa0:'], ['to find only the results that are matching both criteriums. Obviously, I can reuse $results to intersect as many time as I want. So, no limits to search criteriums. ']], [[' $results = array_intersect($results, $temp_results);\n']], ['SQL query on many-to-many with redundant constraint'], 3, 0], [(9429371, 0), [['To achieve what you  actually want , you need to apply a date function to the created_at column:'], ["To restrict the query to entries created in the current month, you add a  WHERE -clause to the query to only select entries that satisfy that condition. Here's an example:"]], [[' SELECT COUNT(1) AS entries, DATE(created_at) as date\nFROM wp_frm_items\nWHERE user_id =1\nGROUP BY DATE(created_at)\nLIMIT 0 , 30\n']], ['Sql Query to count same date entries'], 3, 1], [(9429371, 1), [["To restrict the query to entries created in the current month, you add a  WHERE -clause to the query to only select entries that satisfy that condition. Here's an example:"], ['Edit : The query to group by month can be created in a number of different ways. Here is an example:']], [[" SELECT COUNT(1) AS entries, DATE(created_at) as date \nFROM  wp_frm_items\nWHERE user_id = 1 \n  AND created_at >= DATE_FORMAT(CURDATE(),'%Y-%m-01') \nGROUP BY DATE(created_at)\n"]], ['Sql Query to count same date entries'], 3, 1], [(9429371, 2), [['Edit : The query to group by month can be created in a number of different ways. Here is an example:'], ['-10000']], [[" SELECT COUNT(1) AS entries, DATE_FORMAT(created_at,'%Y-%c') as month\nFROM wp_frm_items\nWHERE user_id =1\nGROUP BY DATE_FORMAT(created_at,'%Y-%c')\n"]], ['Sql Query to count same date entries'], 3, 1], [(9432630, 0), [['In case you need to do this as a set and not one row at a time. Given the following split function:'], ['Then with the following table and sample data, and string variable, you can get all of the results this way:']], [[" USE tempdb;\nGO\nCREATE FUNCTION dbo.SplitStrings(@List NVARCHAR(MAX))\nRETURNS TABLE\nAS\n   RETURN ( SELECT Item FROM\n       ( SELECT Item = x.i.value('(./text())[1]', 'nvarchar(max)')\n         FROM ( SELECT [XML] = CONVERT(XML, '<i>'\n         + REPLACE(@List,',', '</i><i>') + '</i>').query('.')\n           ) AS a CROSS APPLY [XML].nodes('i') AS x(i) ) AS y\n       WHERE Item IS NOT NULL\n   );\nGO\n"]], ['String concatenation in SQL server'], 5, 0], [(9432630, 1), [['Then with the following table and sample data, and string variable, you can get all of the results this way:'], ['Results:']], [[" DECLARE @foo TABLE(ID INT IDENTITY(1,1), col NVARCHAR(MAX));\n\nINSERT @foo(col) SELECT N'c,d,e,f,g';\nINSERT @foo(col) SELECT N'c,e,b';\nINSERT @foo(col) SELECT N'd,e,f,x,a,e';\n\nDECLARE @string NVARCHAR(MAX) = N'a,b,c,d';\n\n;WITH x AS\n(\n    SELECT f.ID, c.Item FROM @foo AS f\n    CROSS APPLY dbo.SplitStrings(f.col) AS c\n), y AS\n(\n    SELECT ID, Item FROM x\n    UNION\n    SELECT x.ID, s.Item\n        FROM dbo.SplitStrings(@string) AS s\n        CROSS JOIN x\n)\nSELECT DISTINCT ID, Items = STUFF((SELECT ',' + Item \n    FROM y AS y2 WHERE y2.ID = y.ID \n    FOR XML PATH(''), TYPE).value('.[1]', 'nvarchar(max)'), 1, 1, N'')\nFROM y;\n"]], ['String concatenation in SQL server'], 5, 0], [(9432630, 2), [['Results:'], ["Adding a potential solution for SQL Server 2008 that is a bit more convoluted but gets things done with one less loop (using a massive table scan and replace instead). I don't think this is any better than the solution above, and it is certainly less maintainable, but it is an option to test out should you find you are able to upgrade to 2008 or better (and also for any 2008+ users who come across this question)."]], [[' ID   Items\n--   ----------\n 1   a,b,c,d,e,f,g\n 2   a,b,c,d,e\n 3   a,b,c,d,e,f,x\n']], ['String concatenation in SQL server'], 5, 0], [(9432630, 3), [["Adding a potential solution for SQL Server 2008 that is a bit more convoluted but gets things done with one less loop (using a massive table scan and replace instead). I don't think this is any better than the solution above, and it is certainly less maintainable, but it is an option to test out should you find you are able to upgrade to 2008 or better (and also for any 2008+ users who come across this question)."], ['The code:']], [[" SET NOCOUNT ON;\n\n-- let's pretend this is our static table:\n\nCREATE TABLE #x\n(\n    ID INT IDENTITY(1,1),\n    col NVARCHAR(MAX)\n);\n\nINSERT #x(col) VALUES(N'c,d,e,f,g'), (N'c,e,b'), (N'd,e,f,x,a,e');\n\n-- and here is our parameter:\n\nDECLARE @string NVARCHAR(MAX) = N'a,b,c,d';\n"]], ['String concatenation in SQL server'], 5, 0], [(9459554, 0), [["I think this is the query you're looking for:"], ["I see you've updated tableA data. The query results in this, given the previous data:"]], [[' select b.*, c.filenumber from b\njoin (\n  select id, max(count) as count from a\n  group by id\n) as NewA on b.id = NewA.id\njoin c on NewA.count = c.count\n']], ['Get the max value of a column from set of rows'], 2, 1], [(9475177, 0), [['Here is a solution based on nested subqueries.  First, I added a few rows to catch a few more cases.  Transaction 10, for example, should not be cancelled by transaction 12, because transaction 11 comes in between.'], ['First, create a query to grab, for each transaction, "the date of the most recent transaction before that one in the same account":']], [[' > select * from transactions order by date_time;\n+----+---------+------+---------------------+--------+\n| id | account | type | date_time           | amount |\n+----+---------+------+---------------------+--------+\n|  1 |       1 | R    | 2012-01-01 10:01:00 |   1000 |\n|  2 |       3 | R    | 2012-01-02 12:53:10 |   1500 |\n|  3 |       3 | A    | 2012-01-03 13:10:01 |  -1500 |\n|  4 |       2 | R    | 2012-01-03 17:56:00 |   2000 |\n|  5 |       1 | R    | 2012-01-04 12:30:01 |   1000 |\n|  6 |       2 | A    | 2012-01-04 13:23:01 |  -2000 |\n|  7 |       3 | R    | 2012-01-04 15:13:10 |   3000 |\n|  8 |       3 | R    | 2012-01-05 12:12:00 |   1250 |\n|  9 |       3 | A    | 2012-01-06 17:24:01 |  -1250 |\n| 10 |       3 | R    | 2012-01-07 00:00:00 |   1250 |\n| 11 |       3 | R    | 2012-01-07 05:00:00 |   4000 |\n| 12 |       3 | A    | 2012-01-08 00:00:00 |  -1250 |\n| 14 |       2 | R    | 2012-01-09 00:00:00 |   2000 |\n| 13 |       3 | A    | 2012-01-10 00:00:00 |  -1500 |\n| 15 |       2 | A    | 2012-01-11 04:00:00 |  -2000 |\n| 16 |       2 | R    | 2012-01-12 00:00:00 |   5000 |\n+----+---------+------+---------------------+--------+\n16 rows in set (0.00 sec)\n']], ['SQL: Select transactions where rows are not of criteria inside the same table'], 4, 0], [(9475177, 1), [['First, create a query to grab, for each transaction, "the date of the most recent transaction before that one in the same account":'], ["Use that as a subquery to get each transaction and its predecessor on the same row.  Use some filtering to pull out the transactions we're interested in - namely, 'A' transactions whose predecessors are 'R' transactions that they exactly cancel out -"]], [[' SELECT t2.*,\n       MAX(t1.date_time) AS prev_date\nFROM transactions t1\nJOIN transactions t2\nON (t1.account = t2.account\n   AND t2.date_time > t1.date_time)\nGROUP BY t2.account,t2.date_time\nORDER BY t2.date_time;\n\n+----+---------+------+---------------------+--------+---------------------+\n| id | account | type | date_time           | amount | prev_date           |\n+----+---------+------+---------------------+--------+---------------------+\n|  3 |       3 | A    | 2012-01-03 13:10:01 |  -1500 | 2012-01-02 12:53:10 |\n|  5 |       1 | R    | 2012-01-04 12:30:01 |   1000 | 2012-01-01 10:01:00 |\n|  6 |       2 | A    | 2012-01-04 13:23:01 |  -2000 | 2012-01-03 17:56:00 |\n|  7 |       3 | R    | 2012-01-04 15:13:10 |   3000 | 2012-01-03 13:10:01 |\n|  8 |       3 | R    | 2012-01-05 12:12:00 |   1250 | 2012-01-04 15:13:10 |\n|  9 |       3 | A    | 2012-01-06 17:24:01 |  -1250 | 2012-01-05 12:12:00 |\n| 10 |       3 | R    | 2012-01-07 00:00:00 |   1250 | 2012-01-06 17:24:01 |\n| 11 |       3 | R    | 2012-01-07 05:00:00 |   4000 | 2012-01-07 00:00:00 |\n| 12 |       3 | A    | 2012-01-08 00:00:00 |  -1250 | 2012-01-07 05:00:00 |\n| 14 |       2 | R    | 2012-01-09 00:00:00 |   2000 | 2012-01-04 13:23:01 |\n| 13 |       3 | A    | 2012-01-10 00:00:00 |  -1500 | 2012-01-08 00:00:00 |\n| 15 |       2 | A    | 2012-01-11 04:00:00 |  -2000 | 2012-01-09 00:00:00 |\n| 16 |       2 | R    | 2012-01-12 00:00:00 |   5000 | 2012-01-11 04:00:00 |\n+----+---------+------+---------------------+--------+---------------------+\n13 rows in set (0.00 sec)\n']], ['SQL: Select transactions where rows are not of criteria inside the same table'], 4, 0], [(9475177, 2), [["Use that as a subquery to get each transaction and its predecessor on the same row.  Use some filtering to pull out the transactions we're interested in - namely, 'A' transactions whose predecessors are 'R' transactions that they exactly cancel out -"], ["From the result above it's apparent we're almost there - we've identified the unwanted transactions.  Using  LEFT JOIN  we can filter these out of the whole transaction set:"]], [[" SELECT\n  t3.*,transactions.*\nFROM\n  transactions\n  JOIN\n  (SELECT t2.*,\n          MAX(t1.date_time) AS prev_date\n   FROM transactions t1\n   JOIN transactions t2\n   ON (t1.account = t2.account\n      AND t2.date_time > t1.date_time)\n   GROUP BY t2.account,t2.date_time) t3\n  ON t3.account = transactions.account\n     AND t3.prev_date = transactions.date_time\n     AND t3.type='A'\n     AND transactions.type='R'\n     AND t3.amount + transactions.amount = 0\n  ORDER BY t3.date_time;\n\n\n+----+---------+------+---------------------+--------+---------------------+----+---------+------+---------------------+--------+\n| id | account | type | date_time           | amount | prev_date           | id | account | type | date_time           | amount |\n+----+---------+------+---------------------+--------+---------------------+----+---------+------+---------------------+--------+\n|  3 |       3 | A    | 2012-01-03 13:10:01 |  -1500 | 2012-01-02 12:53:10 |  2 |       3 | R    | 2012-01-02 12:53:10 |   1500 |\n|  6 |       2 | A    | 2012-01-04 13:23:01 |  -2000 | 2012-01-03 17:56:00 |  4 |       2 | R    | 2012-01-03 17:56:00 |   2000 |\n|  9 |       3 | A    | 2012-01-06 17:24:01 |  -1250 | 2012-01-05 12:12:00 |  8 |       3 | R    | 2012-01-05 12:12:00 |   1250 |\n| 15 |       2 | A    | 2012-01-11 04:00:00 |  -2000 | 2012-01-09 00:00:00 | 14 |       2 | R    | 2012-01-09 00:00:00 |   2000 |\n+----+---------+------+---------------------+--------+---------------------+----+---------+------+---------------------+--------+\n4 rows in set (0.00 sec)\n"]], ['SQL: Select transactions where rows are not of criteria inside the same table'], 4, 0], [(9475177, 3), [["From the result above it's apparent we're almost there - we've identified the unwanted transactions.  Using  LEFT JOIN  we can filter these out of the whole transaction set:"], ['-10000']], [[" SELECT\n  transactions.*\nFROM\n  transactions\nLEFT JOIN\n  (SELECT\n     transactions.id\n   FROM\n     transactions\n     JOIN\n     (SELECT t2.*,\n             MAX(t1.date_time) AS prev_date\n      FROM transactions t1\n      JOIN transactions t2\n      ON (t1.account = t2.account\n         AND t2.date_time > t1.date_time)\n      GROUP BY t2.account,t2.date_time) t3\n     ON t3.account = transactions.account\n        AND t3.prev_date = transactions.date_time\n        AND t3.type='A'\n        AND transactions.type='R'\n        AND t3.amount + transactions.amount = 0) t4\n  USING(id)\n  WHERE t4.id IS NULL\n    AND transactions.type = 'R'\n  ORDER BY transactions.date_time;\n\n+----+---------+------+---------------------+--------+\n| id | account | type | date_time           | amount |\n+----+---------+------+---------------------+--------+\n|  1 |       1 | R    | 2012-01-01 10:01:00 |   1000 |\n|  5 |       1 | R    | 2012-01-04 12:30:01 |   1000 |\n|  7 |       3 | R    | 2012-01-04 15:13:10 |   3000 |\n| 10 |       3 | R    | 2012-01-07 00:00:00 |   1250 |\n| 11 |       3 | R    | 2012-01-07 05:00:00 |   4000 |\n| 16 |       2 | R    | 2012-01-12 00:00:00 |   5000 |\n+----+---------+------+---------------------+--------+\n"]], ['SQL: Select transactions where rows are not of criteria inside the same table'], 4, 0], [(9518900, 0), [['If there is something equivalent to a CROSS APPLY, then you can do the following. (EDIT: I noticed the requirement for schools to be able to have multiple teams. This solution would only work with one team per school. You will need a recursive CTE and ROW_NUMBER as far as I can tell, otherwise---which are not available in SQLite to my knowledge)'], ['EDIT:\nHowever, this is the temp table solution as was requested. You need the inner while since you could have multiple teams within the school (something I had disregarded before and makes the CROSS APPLY solution not work without a recursive CTE and ROW_NUMBER, which has been edited to acknowledge)']], [[' SELECT  TeamTable.*\nFROM    Table\nCROSS APPLY\n    (\n        SELECT  TOP 4 *\n        FROM Table AS InnerTable\n        WHERE   InnerTable.school = Table.School\n        ORDER BY InnerTable.Pos\n    ) AS TeamTable\n']], ['how to find teams with sql command'], 2, 1], [(9518900, 1), [['EDIT:\nHowever, this is the temp table solution as was requested. You need the inner while since you could have multiple teams within the school (something I had disregarded before and makes the CROSS APPLY solution not work without a recursive CTE and ROW_NUMBER, which has been edited to acknowledge)'], ['-10000']], [[' CREATE TABLE #SchoolList \n    (Id INT IDENTITY(1,1), School VARCHAR(50))\n\nINSERT INTO #SchoolList\nSELECT DISTINCT School\nFROM TeamTable\n\nCREATE TABLE #TeamList\n    (TeamNumber INT IDENTITY(1,1), Pos INT, Name VARCHAR(50),\n        School VARCHAR(50))\n\nDECLARE @CurrentSchool VARCHAR(50), @CurrentSchoolPos INT\nDECLARE @CurrentSchoolLookupId INT\nSET @CurrentSchoolId = 1\nWHILE EXISTS (SELECT 1 FROM #SchoolList WHERE Id > @CurrentSchoolLookupId)\nBEGIN\n    SELECT @CurrentSchool = School FROM #SchoolList\n        WHERE Id = @CurrentSchoolLookupId\n    SET @CurrentSchoolPos = SELECT TOP 1 Pos FROM TeamTable \n                            WHERE School = @CurrentSchool \n                            ORDER BY POS\n    WHILE ISNULL(@CurrentSchoolPos, 0) > 0\n    BEGIN\n        INSERT INTO #TeamList\n        SELECT Pos, Name, School \n        FROM TeamTable \n        WHERE School = @CurrentSchool AND Pos = @CurrentSchoolPos\n\n        SET @CurrentSchoolPos = SELECT TOP 1 Pos FROM TeamTable \n                                WHERE School = @CurrentSchool \n                                    AND Pos > @CurrentSchoolPos ORDER BY POS\n    END\n    SET @CurrentSchoolLookupId = @CurrentSchoolLookupId + 1\nEND\n\nSELECT * FROM #TeamList\n']], ['how to find teams with sql command'], 2, 1], [(9535224, 1), [['Like:'], ['Edit #2:']], [['  DOSQL "INSERT INTO Leads (DateTimeField) VALUES (Convert(datetime, cbdate1 + \' \' + cbtime1))"\n']], ['Concatenate Two Values On Insert - SQL'], 2, 1], [(9548686, 0), [['first join things up.'], ['then filter down to the posts you want']], [[' select q.question_id, q.title\nfrom question q, post p\nwhere q.question_id = p.question_id\n']], ['query inside of query'], 3, 0], [(9548686, 1), [['then filter down to the posts you want'], ['then count up']], [[" select q.question_id, q.title\nfrom question q, post p\nwhere q.question_id = p.question_id\nand p.post like '%SEARCHTERM%'\n"]], ['query inside of query'], 3, 0], [(9548686, 2), [['then count up'], ['-10000']], [[" select q.question_id, q.title, count( post_id )\nfrom question q, post p\nwhere q.question_id = p.question_id\nand p.post like '%SEARCHTERM%'\ngroup by q.question_id, q.title\n"]], ['query inside of query'], 3, 0], [(9573470, 0), [['You can use either a subquery ( SQLize ):'], ['or a multi-table update ( SQLize ):']], [[' UPDATE Table1\nSET Val2 = ( SELECT Val1 FROM Table2 WHERE Table1.ID = Table2.ID )\nWHERE Val2 IS NULL\n']], ['MySQL Selecting from One table into Another Based on ID'], 3, 1], [(9573470, 1), [['or a multi-table update ( SQLize ):'], ['or the same with an explicit  JOIN  ( SQLize ):']], [[' UPDATE Table1, Table2\nSET Table1.Val2 = Table2.Val1\nWHERE Table1.ID = Table2.ID AND Table1.Val2 IS NULL\n']], ['MySQL Selecting from One table into Another Based on ID'], 3, 1], [(9573470, 2), [['or the same with an explicit  JOIN  ( SQLize ):'], ["(I assume you only want to update the rows in  Table1  for which  Val2  is NULL.  If you'd rather overwrite the values for all rows with matching  ID s in  Table2 , just remove the  WHERE Table1.Val2 IS NULL  condition.)"]], [[' UPDATE Table1 JOIN Table2 ON Table1.ID = Table2.ID\nSET Table1.Val2 = Table2.Val1\nWHERE Table1.Val2 IS NULL\n']], ['MySQL Selecting from One table into Another Based on ID'], 3, 1], [(9581458, 0), [['Consider this query:'], ['Alternative query using  Fowler :']], [[' SELECT *\nFROM Hire AS H1, Hire AS H2\nWHERE H1.carId = H2.carId\nAND H1.hireId < H2.hireId \nAND \n   CASE \n   WHEN H1.onHireDate > H2.onHireDate THEN H1.onHireDate \n   ELSE H2.onHireDate END\n   <\n   CASE \n   WHEN H1.offHireDate > H2.offHireDate THEN H2.offHireDate \n   ELSE H1.offHireDate END\n']], ['How can I prevent date overlaps in SQL?'], 2, 1], [(9581458, 1), [['Alternative query using  Fowler :'], ['-10000']], [[' SELECT *\n  FROM Hire AS H1, Hire AS H2\n WHERE H1.carId = H2.carId\n       AND H1.hireId < H2.hireId \n       AND H1.onHireDate < H2.offHireDate \n       AND H2.onHireDate < H1.offHireDate;\n']], ['How can I prevent date overlaps in SQL?'], 2, 1], [(9623187, 0), [['Step 0 : Window Time Range -- The sample data does not include 3 minutes of data, so I used a variable to hold the desired number of seconds for the window time range. For the actual data, you could use 180 seconds.'], ["Step 1 : First Time -- Although the  first_time  isn't important, it is still necessary to make sure we don't include incomplete time periods. It will be used later to exclude data before the first complete time period has elapsed."]], [[' DECLARE @seconds int\nSET @seconds = 10\n']], ['Best way to replicate Oracles range windowing function in SQL Server'], 5, 0], [(9623187, 1), [["Step 1 : First Time -- Although the  first_time  isn't important, it is still necessary to make sure we don't include incomplete time periods. It will be used later to exclude data before the first complete time period has elapsed."], ["Step 2 : Time Windows -- The Oracle query uses  partition by case_id, channel_index order by start_time range numtodsinterval(3, 'minute') preceeding  to find the minimum and maximum  dms_value  as well as the  first_time  in the subquery. Since SQL Server does not have the  range  functionality, you need to use a subquery to define the 3 minute windows. The Oracle query uses  range ... preceeding , so the SQL Server range will use  DATEADD  with a negative value:"]], [[' -- Query to return the first_time, last_time, and range_time\n-- range_time is first complete time period using the time range\nSELECT  case_id \n    ,   channel_index \n    ,   MIN(start_time) AS first_time\n    ,   DATEADD(ss, @seconds, MIN(start_time)) AS range_time\n    ,   MAX(start_time) AS last_time\nFROM    #continuous_data \nGROUP BY case_id, channel_index\nORDER BY case_id, channel_index\n\n-- Results from the sample data\ncase_id     channel_index first_time              range_time              last_time\n----------- ------------- ----------------------- ----------------------- -----------------------\n2081        50            2011-05-18 09:36:39.000 2011-05-18 09:36:49.000 2011-05-18 09:37:08.000\n2081        51            2011-05-18 09:36:34.000 2011-05-18 09:36:44.000 2011-05-18 09:37:04.000\n']], ['Best way to replicate Oracles range windowing function in SQL Server'], 5, 0], [(9623187, 2), [["Step 2 : Time Windows -- The Oracle query uses  partition by case_id, channel_index order by start_time range numtodsinterval(3, 'minute') preceeding  to find the minimum and maximum  dms_value  as well as the  first_time  in the subquery. Since SQL Server does not have the  range  functionality, you need to use a subquery to define the 3 minute windows. The Oracle query uses  range ... preceeding , so the SQL Server range will use  DATEADD  with a negative value:"], ['Step 3 : MIN/MAX for Time Windows -- Next you need to find the minimum and maximum values for each window. This is where the majority of the calculation is performed and needs the most debugging to get the expected results.']], [[' -- Windowing for each time range. Window is the negative time\n-- range from each start_time row\nSELECT  case_id \n    ,   channel_index \n    ,   DATEADD(ss, -@seconds, start_time) AS window_start\n    ,   start_time                         AS window_end\nFROM    #continuous_data \nORDER BY case_id, channel_index, start_time\n']], ['Best way to replicate Oracles range windowing function in SQL Server'], 5, 0], [(9623187, 3), [['Step 3 : MIN/MAX for Time Windows -- Next you need to find the minimum and maximum values for each window. This is where the majority of the calculation is performed and needs the most debugging to get the expected results.'], ['Step 4 : Finally, you can put it all together to return the lowest MAX value and highest MIN value for each time window:']], [[' -- Find the maximum and minimum values for each window range\n-- I included the start_time min/max/diff for debugging\nSELECT  su.case_id \n    ,   su.channel_index \n    ,   win.window_end \n    ,   MAX(dms_value) AS dms_max\n    ,   MIN(dms_value) AS dms_min\n    ,   MIN(su.start_time) AS time_min\n    ,   MAX(su.start_time) AS time_max\n    ,   DATEDIFF(ss, MIN(su.start_time), MAX(su.start_time)) AS time_diff\nFROM    #continuous_data AS su\n   JOIN (\n        -- Windowing for each time range. Window is the negative time\n        -- range from each start_time row\n        SELECT  case_id \n            ,   channel_index \n            ,   DATEADD(ss, -@seconds, start_time) AS window_start\n            ,   start_time                         AS window_end\n        FROM    #continuous_data \n    ) AS win\n        ON (    su.case_id       = win.case_id\n            AND su.channel_index = win.channel_index)\n   JOIN (\n        -- Find the first_time and add the time range\n        SELECT  case_id \n            ,   channel_index \n            ,   MIN(start_time)                        AS first_time\n            ,   DATEADD(ss, @seconds, MIN(start_time)) AS range_time\n        FROM    #continuous_data \n        GROUP BY case_id, channel_index\n    ) AS fir\n        ON (    su.case_id       = fir.case_id\n            AND su.channel_index = fir.channel_index)\nWHERE   su.start_time BETWEEN win.window_start AND win.window_end\n    AND win.window_end >= fir.range_time\nGROUP BY su.case_id, su.channel_index, win.window_end\nORDER BY su.case_id, su.channel_index, win.window_end\n\n-- Results from sample data:\ncase_id     channel_index window_end              dms_max                dms_min                time_min                time_max                time_diff\n----------- ------------- ----------------------- ---------------------- ---------------------- ----------------------- ----------------------- -----------\n2081        50            2011-05-18 09:36:49.000 104.5625               94.8125                2011-05-18 09:36:39.000 2011-05-18 09:36:49.000 10\n2081        50            2011-05-18 09:36:50.000 105.8125               95.4375                2011-05-18 09:36:40.000 2011-05-18 09:36:50.000 10\n2081        50            2011-05-18 09:36:52.000 107.125                98.0625                2011-05-18 09:36:42.000 2011-05-18 09:36:52.000 10\n2081        50            2011-05-18 09:36:53.000 108.4375               99.3125                2011-05-18 09:36:44.000 2011-05-18 09:36:53.000 9\n2081        50            2011-05-18 09:36:54.000 109.75                 99.3125                2011-05-18 09:36:44.000 2011-05-18 09:36:54.000 10\n2081        50            2011-05-18 09:36:55.000 111.0625               100.625                2011-05-18 09:36:45.000 2011-05-18 09:36:55.000 10\n2081        50            2011-05-18 09:36:57.000 112.3125               103.25                 2011-05-18 09:36:48.000 2011-05-18 09:36:57.000 9\n2081        50            2011-05-18 09:36:58.000 113.625                103.25                 2011-05-18 09:36:48.000 2011-05-18 09:36:58.000 10\n2081        50            2011-05-18 09:36:59.000 114.9375               104.5625               2011-05-18 09:36:49.000 2011-05-18 09:36:59.000 10\n2081        50            2011-05-18 09:37:01.000 116.25                 107.125                2011-05-18 09:36:52.000 2011-05-18 09:37:01.000 9\n2081        50            2011-05-18 09:37:02.000 117.5                  107.125                2011-05-18 09:36:52.000 2011-05-18 09:37:02.000 10\n2081        50            2011-05-18 09:37:03.000 118.8125               108.4375               2011-05-18 09:36:53.000 2011-05-18 09:37:03.000 10\n2081        50            2011-05-18 09:37:05.000 120.125                111.0625               2011-05-18 09:36:55.000 2011-05-18 09:37:05.000 10\n2081        50            2011-05-18 09:37:06.000 121.4375               112.3125               2011-05-18 09:36:57.000 2011-05-18 09:37:06.000 9\n2081        50            2011-05-18 09:37:07.000 122.75                 112.3125               2011-05-18 09:36:57.000 2011-05-18 09:37:07.000 10\n2081        50            2011-05-18 09:37:08.000 124.0625               113.625                2011-05-18 09:36:58.000 2011-05-18 09:37:08.000 10\n2081        51            2011-05-18 09:36:46.000 98                     96                     2011-05-18 09:36:40.000 2011-05-18 09:36:46.000 6\n2081        51            2011-05-18 09:36:52.000 98                     92                     2011-05-18 09:36:46.000 2011-05-18 09:36:52.000 6\n2081        51            2011-05-18 09:36:58.000 92                     86                     2011-05-18 09:36:52.000 2011-05-18 09:36:58.000 6\n2081        51            2011-05-18 09:37:04.000 86                     80                     2011-05-18 09:36:58.000 2011-05-18 09:37:04.000 6\n']], ['Best way to replicate Oracles range windowing function in SQL Server'], 5, 0], [(9630004, 0), [["That said, if you're  really sure , you can set the auto increment value to any value using;"], ["That is, if you want AUTOINCREMENT on the next insert on table 'TableA' to generate 5, you do;"]], [[' UPDATE sqlite_sequence set seq=<next sequence no -1> where name=<table name>;\n']], ['How to decrease the Auto increment _id in android SQLite?'], 2, 1], [(9630859, 0), [['You have to store the value in an arraylist and which is retrieved from database and set the value to the edit text as '], ['After the data is retrieved, you have to check the condition whether  editText.getText().toString()  length is greater then zero you should not allow them to edit the text in  editText  by using following']], [[' // myarraylist is the arraylist which contains \n// the data retrieved from database\neditText.setText(myarraylist.get(0)); \n']], ['fetching data from database and set it on edittext'], 2, 0], [(9630859, 1), [['After the data is retrieved, you have to check the condition whether  editText.getText().toString()  length is greater then zero you should not allow them to edit the text in  editText  by using following'], ['-10000']], [['   editText.setFocusable(false);\n']], ['fetching data from database and set it on edittext'], 2, 0], [(9655852, 0), [['So, what I understand it would be useful for you (and minimal, of course) would be this:'], ['You can get this with the following query (based on your table schea, I assume  name  has those values  P B ):']], [[' 36.00   T T     xxx@gmail.com\n6.00    R T     yyy@gmail.com\n46.00   P B     zzz@msn.com  \n10.00   y a     aaa@aol.com\n']], ['sum of customer transactions'], 2, 0], [(9655852, 1), [['You can get this with the following query (based on your table schea, I assume  name  has those values  P B ):'], ["Let me know if this is what you're (actually) looking for."]], [[" select sum(`Purchase Price`) as total_sum, name, email from purchases\nwhere `Purchase Date` between '2012-01-01' and '2012-01-31'\ngroup by email, name\norder by email\n"]], ['sum of customer transactions'], 2, 1], [(9704624, 0), [['APEX provides a utility to split the values out of a shuttle item like this:'], ['So for your requirement you could do:']], [[' declare\n    tab apex_application_global.vc_arr2;\nbegin\n    tab := apex_util.string_to_table (:p1_multiple_item);\n    ...\nend;\n']], ['Oracle APEX - Saving Shuttle Item selections to a new table'], 2, 0], [(9704624, 1), [['So for your requirement you could do:'], ['(NB I have not dealt with whether the row already exists, but you get the idea.)']], [[" declare\n    tab apex_application_global.vc_arr2;\nbegin\n    tab := apex_util.string_to_table (:p1_multiple_item);\n    for i in 1..tab.count loop\n        insert into order_parts_table (order_number, part_number, order_status)\n        values (:p1_order_number, tab(i), 'ACTIVE');\n    end loop;\nend;\n"]], ['Oracle APEX - Saving Shuttle Item selections to a new table'], 2, 1], [(9755681, 1), [["Since you're on 10g, however, the simplest option is probably to reverse the string and subtract the position that is found from the length of the string"], ['Both approaches should work in 11g']], [[" length(str) - regexp_instr(reverse(str),'[[:digit:]]') + 1\n"]], ['Use regexp_instr to get the last number in a string'], 3, 1], [(9760884, 1), [['output'], ["The N before the string value tells SQL Server to treat it as unicode, notice that you get a question mark back when you don't use N?"]], [[' ----\n文\n\n(1 row(s) affected)\n\n\n----\n?\n\n(1 row(s) affected)\n']], ['Hebrew and other languages in sql'], 2, 0], [(9764030, 0), [["So, here's my attempt (which did return the expected results for all the sample data provided in the original post):"], ["Afterwards, it only remains for us to group by key values and sum the obtained amounts. Here's the output:"]], [[" WITH data (id, str) AS (\n             SELECT 1, '$15 / 1GB 24m + Intern 120MB' ----------> 1.12 GB\n  UNION ALL  SELECT 2, '$19.95 / 500MB + $49.95 / 9GB Blackberry' -----> 9.5GB\n  UNION ALL  SELECT 3, '$174.95 Blackberry 24GB + $10 / 1GB Datapack' ----> 25GB\n  UNION ALL  SELECT 4, '$79 / 6GB' --> 6GB\n  UNION ALL  SELECT 5, Null --> Null\n  UNION ALL  SELECT 6, '$20 Plan' --> 0GB\n  UNION ALL  SELECT 7, '460MB' --> 0.46GB\n),\nunified AS (\n  SELECT\n    id,\n    oldstr = str,\n    str = REPLACE(str, 'GB', '000MB')\n  FROM data\n),\nsplit AS (\n  SELECT\n    id,\n    ofs    = 0,\n    endpos = CHARINDEX('MB', str),\n    length = ISNULL(CHARINDEX(' ', REVERSE(SUBSTRING(str, 1, NULLIF(CHARINDEX('MB', str), 0) - 1)) + ' ') - 1, 0),\n    str    = SUBSTRING(str, NULLIF(CHARINDEX('MB', str), 0) + 2, 999999)\n  FROM unified\n  UNION ALL\n  SELECT\n    id,\n    ofs    = NULLIF(endpos, 0) + 1,\n    endpos = CHARINDEX('MB', str),\n    length = ISNULL(CHARINDEX(' ', REVERSE(SUBSTRING(str, 1, NULLIF(CHARINDEX('MB', str), 0) - 1)) + ' ') - 1, 0),\n    str    = SUBSTRING(str, NULLIF(CHARINDEX('MB', str), 0) + 2, 999999)\n  FROM split\n  WHERE length > 0\n),\nextracted AS (\n  SELECT\n    d.id,\n    str = d.oldstr,\n    mb = CAST(SUBSTRING(d.str, s.ofs + s.endpos - s.length, s.length) AS int)\n  FROM unified d\n  INNER JOIN split s ON d.id = s.id\n)\nSELECT\n  id,\n  str,\n  gb = RTRIM(CAST(SUM(mb) AS float) / 1000) + 'GB'\nFROM extracted\nGROUP BY id, str\nORDER BY id\n"]], ['SQL Server 2008 Prior String Extract'], 2, 1], [(9764030, 1), [["Afterwards, it only remains for us to group by key values and sum the obtained amounts. Here's the output:"], ['-10000']], [[' id  str                                           gb\n--  --------------------------------------------  ------\n1   $15 / 1GB 24m + Intern 120MB                  1.12GB\n2   $19.95 / 500MB + $49.95 / 9GB Blackberry      9.5GB\n3   $174.95 Blackberry 24GB + $10 / 1GB Datapack  25GB\n4   $79 / 6GB                                     6GB\n5   NULL                                          NULL\n6   $20 Plan                                      0GB\n7   460MB                                         0.46GB\n']], ['SQL Server 2008 Prior String Extract'], 2, 0], [(9777457, 0), [['First, you would have three tables something like this:'], ['So, to see what kind of menus each restaurant offers, your query goes like this:']], [[" restaurants\n---------------\nid    name\n1     Moe's\n2     Steak & Shrimp House\n3     McDonald's\n\nrestaurant_menus\n----------------\nrestaurant_id    menu_type\n1                1\n1                3\n2                4\n3                1\n3                3\n3                4\n\nmenu_types\n---------------\nid    type\n1     Breakfast\n2     Brunch\n3     Lunch\n4     Dinner\n"]], ['DB schema, many-many or bool values in table'], 3, 0], [(9777457, 2), [['This would produce:'], ['-10000']], [[" name                  type       \n--------------------  -----------\nMcDonald's            Lunch      \nMcDonald's            Breakfast  \nMcDonald's            Dinner     \nMoe's                 Breakfast  \nMoe's                 Lunch      \nSteak & Shrimp House  Dinner     \n"]], ['DB schema, many-many or bool values in table'], 3, 0], [(9789395, 0), [['Escape (double escape) the plus sign:'], ["Moreover, there're no need to make a group with  (info)"]], [[" E'^(info)\\\\+[A-Za-z0-9._%-]+@[A-Za-z0-9.-]+[.][A-Za-z]+'\n  here __^^\n"]], ['Ignore emails that match a regexp in Postgres'], 2, 1], [(9789395, 1), [["Moreover, there're no need to make a group with  (info)"], ['-10000']], [[" E'^info\\\\+[A-Za-z0-9._%-]+@[A-Za-z0-9.-]+[.][A-Za-z]+'\n"]], ['Ignore emails that match a regexp in Postgres'], 2, 1], [(9807875, 0), [['-10000'], ['To do it without the regexp functions (for older Oracle versions), it depends a bit on how much you want to validate the format of the strings.']], [[" with prefix_list as (\n  select regexp_substr( str1, '^[A-Z]*' ) prefix from t1 where str2 = 'NAME1'\n)\nselect t1.str1 from t1 join prefix_list\n        on t1.str1 = prefix_list.prefix\n           or regexp_like( t1.str1, prefix_list.prefix||'_[0-9]' )\n"]], ['SQL: Feeding SELECT output to LIKE'], 2, 1], [(9807875, 1), [['To do it without the regexp functions (for older Oracle versions), it depends a bit on how much you want to validate the format of the strings.'], ['-10000']], [[" select t1.str1\n  from (\n  select case when instr( str1, '_' ) > 0\n                then substr( str1, 1, instr( str1, '_' ) - 1 )\n              else str1\n         end prefix\n    from t1 where str2 = 'NAME1'\n) prefix_list,\n  t1\nwhere t1.str1 = prefix\n   or t2.str1 like prefix || '\\__' escape '\\'\n"]], ['SQL: Feeding SELECT output to LIKE'], 2, 1], [(9861297, 0), [['Update the  Order  table:'], ['Then, update the  Customer  table:']], [[' UPDATE o\nSET o.person_id = cc.max_person_id\nFROM\n    [Order] AS o\n  JOIN\n    Customer AS c\n        ON c.person_id = o.person_id\n  JOIN\n    ( SELECT customer_id\n           , MAX(person_id) AS max_person_id\n      FROM Customer\n      GROUP BY customer_id\n    ) AS cc\n        ON cc.customer_id = c.customer_id ;\n']], ['Fixing duplicate customers in SQL'], 2, 0], [(9861297, 1), [['Then, update the  Customer  table:'], ['-10000']], [[' UPDATE c\nSET c.person_id = cc.max_person_id\nFROM\n    Customer AS c\n  JOIN\n    ( SELECT customer_id\n           , MAX(person_id) AS max_person_id\n      FROM Customer\n      GROUP BY customer_id\n    ) AS cc\n        ON cc.customer_id = c.customer_id ;\n']], ['Fixing duplicate customers in SQL'], 2, 0], [(9919278, 0), [['Ed Northridge\'s answer will work, and I have upvoted it, but just in case multiple replacements are required I am adding another option using his sample data. If, for example one of the companies was called "The PC Company LTD" This would duplicate rows in the output with one being "The PC LTD" and the other "The PC Company". To resolve this there are 2 option depending on your desired outcome. The first is to only replace the "Bad Strings" when they occur at the end of the name. '], ['The other option is replace All occurances of the Bad Strings recursively:']], [[" SELECT  c.ID, RTRIM(x.Name) [Name]\nFROM    @companies c\n        OUTER APPLY \n        (   SELECT  REPLACE(c.name, item, '') AS [Name]\n            FROM    @badStrings\n                    -- WHERE CLAUSE ADDED HERE\n            WHERE   CHARINDEX(item, c.Name) = 1 + LEN(c.Name) - LEN(Item)\n        ) x\nWHERE   c.name != '' \nAND     x.[Name] != c.Name\n"]], ['SQL multiple replace'], 2, 1], [(9919278, 1), [['The other option is replace All occurances of the Bad Strings recursively:'], ['This would yield "The PC" from "The PC Company".']], [[" ;WITH CTE AS\n(   SELECT  c.ID, c.Name [OriginalName], RTRIM(x.Name) [Name], 1 [Level]\n    FROM    @companies c\n            OUTER APPLY \n            (   SELECT  REPLACE(c.name, item, '') AS [Name]\n                FROM    @badStrings\n                WHERE   CHARINDEX(item, c.Name) = 1 + LEN(c.Name) - LEN(Item)\n            ) x\n    WHERE   c.name != '' \n    AND     RTRIM(x.Name) != c.Name\n    UNION ALL\n    SELECT  c.ID, OriginalName, RTRIM(x.Name) [Name], Level + 1 [Level]\n    FROM    CTE c\n            OUTER APPLY \n            (   SELECT  REPLACE(c.name, item, '') AS [Name]\n                FROM    @badStrings\n                WHERE   CHARINDEX(item, c.Name) = 1 + LEN(c.Name) - LEN(Item)\n            ) x\n    WHERE   c.name != '' \n    AND     x.[Name] != c.Name  \n)\n\nSELECT  DISTINCT ID, Name, OriginalName\nFROM    (   SELECT  *, MAX(Level) OVER(PARTITION BY ID) [MaxLevel]\n            FROM    CTE\n        ) c\nWHERE   Level = maxLevel\n"]], ['SQL multiple replace'], 2, 1], [(10011337, 0), [["Okay, this isn't the prettiest of code, but it does enforce the constraint, I think. The trick is to create an indexed view with two unique indexes defined on it:"], ['Now we insert some initial data:']], [[' create table dbo.ABC (\n    Col1 int not null,\n    Col2 int not null\n)\ngo\ncreate view dbo.ABC_Col1_Col2_dep\nwith schemabinding\nas\n    select Col1,Col2,COUNT_BIG(*) as Cnt\n    from\n        dbo.ABC\n    group by\n        Col1,Col2\ngo\ncreate unique clustered index IX_Col1_UniqueCol2 on dbo.ABC_Col1_Col2_dep (Col1)\ngo\ncreate unique nonclustered index IX_Col2_UniqueCol1 on dbo.ABC_Col1_Col2_dep (Col2)\ngo\n']], ['How to design a database table to enforce non-duplicate Unique Key records'], 5, 1], [(10011337, 1), [['Now we insert some initial data:'], ['We can add another row with exactly the same values for  Col1  and  Col2 :']], [[' insert into dbo.ABC (Col1,Col2)\nselect 1,3 union all\nselect 2,19 union all\nselect 3,12\n']], ['How to design a database table to enforce non-duplicate Unique Key records'], 5, 0], [(10011337, 2), [['We can add another row with exactly the same values for  Col1  and  Col2 :'], ['But if we pick a value for  Col2  that has been used for another  Col1 , or vice versa, we get errors:']], [[' insert into dbo.ABC (Col1,Col2)\nselect 1,3\n']], ['How to design a database table to enforce non-duplicate Unique Key records'], 5, 0], [(10011337, 3), [['But if we pick a value for  Col2  that has been used for another  Col1 , or vice versa, we get errors:'], ['-10000']], [[' insert into dbo.ABC (Col1,Col2)\nselect 2,3\ngo\ninsert into dbo.ABC (Col1,Col2)\nselect 1,5\n']], ['How to design a database table to enforce non-duplicate Unique Key records'], 5, 0], [(10011337, 4), [['-10000'], ["will only have one row for a particular  Col1  value, and only one row with a particular  Col2  value, provided that the constraint you're seeking to enforce has not been broken - but as soon as a non-matching row is inserted into the base table, this query returns multiple rows."]], [['     select Col1,Col2,COUNT_BIG(*) as Cnt\n    from\n        dbo.ABC\n    group by\n        Col1,Col2\n']], ['How to design a database table to enforce non-duplicate Unique Key records'], 5, 0], [(10019557, 0), [['Cast StateID to a compatible type, e.g.'], ['or']], [[" WHERE URL LIKE '%' + CONVERT(varchar(50), StateID) + '%'\n"]], ['Join SQL Server tables on a like statement'], 2, 1], [(10019557, 1), [['or'], ['if URL is nvarchar(...)']], [[" WHERE URL LIKE N'%' + CONVERT(nvarchar(50), StateID) + N'%'\n"]], ['Join SQL Server tables on a like statement'], 2, 1], [(10025996, 0), [['In any case you want a left join between the discounts table and the periods table. This will give you the period data to do the  begin = today  where clause, and null if there is no period. Thus the SQL to select the data would be'], ['in rails you should be able to achieve this as follows:']], [[' SELECT [columns]\nFROM discounts_table\nLEFT JOIN periods_table ON periods_table.discount_id = discounts_table.id\nWHERE (periods_table.begin = [today]) OR (periods_table.begin IS NULL AND discounts_table.created_at BETWEEN [yesterday] AND [today])\n']], ['Selecting different condition based on presence of association?'], 2, 1], [(10025996, 1), [['in rails you should be able to achieve this as follows:'], ['Unfortunately you need the use SQL statements rather than letting rails create it for you as:']], [[' Discount\n  .joins("LEFT JOIN periods_table ON periods_table.discount_id = discounts_table.id")\n  .where("(periods_table.begin = ?) OR (periods_table.begin IS NULL AND discounts_table.created_at BETWEEN ? AND ?)", today, today, 1.day.ago.to_date)\n']], ['Selecting different condition based on presence of association?'], 2, 0], [(10035769, 0), [["Since you're on SQL Server  2008 , you can use the new  TIME  datatype:"], ["If your backend isn't 2008 yet :-) then you'd need something like:"]], [[" SELECT * FROM MyTable\nWHERE CAST(SyncDate AS TIME) BETWEEN '14:00' and '14:30'\n"]], ['Query to Select Between Two Times of Day'], 2, 1], [(10035769, 1), [["If your backend isn't 2008 yet :-) then you'd need something like:"], ['to check for 14:00-14:30 hours.']], [[' SELECT * FROM MyTable\nWHERE DATEPART(HOUR, SyncDate) = 14 AND DATEPART(MINUTE, SyncDate) BETWEEN 0 AND 30\n']], ['Query to Select Between Two Times of Day'], 2, 1], [(10109770, 0), [['This should do it for you:'], ['EDIT or you can put the  WHERE  clause inside the first  select']], [[" create table #temp \n(\n    id int, \n    parentid int,\n    data varchar(1)\n)\ninsert #temp (id, parentid, data) values (1, -1, 'a')\ninsert #temp (id, parentid, data) values (2,1, 'b')\ninsert #temp (id, parentid, data) values  (3,2, 'c')\ninsert #temp (id, parentid, data) values  (4,3, 'd')\ninsert #temp (id, parentid, data) values  (5,3, 'f')\n\n; with cte as (\n    select  id, parentid, data, id as topparent\n    from    #temp\n    union all\n    select  child.id, child.parentid, child.data, parent.topparent\n    from    #temp child\n    join    cte parent\n    on      parent.id = child.parentid\n\n)\nselect  id, parentid, data\nfrom    cte\nwhere topparent = 2\n\ndrop table #temp\n"]], ['get all child from an parent id'], 3, 1], [(10109770, 1), [['EDIT or you can put the  WHERE  clause inside the first  select'], ['Results:']], [[" create table #temp \n(\n    id int, \n    parentid int,\n    data varchar(1)\n)\ninsert #temp (id, parentid, data) values (1, -1, 'a')\ninsert #temp (id, parentid, data) values (2,1, 'b')\ninsert #temp (id, parentid, data) values  (3,2, 'c')\ninsert #temp (id, parentid, data) values  (4,3, 'd')\ninsert #temp (id, parentid, data) values  (5,3, 'f')\n\n; with cte as (\n    select  id, parentid, data, id as topparent\n    from    #temp\n    WHERE id = 2\n    union all\n    select  child.id, child.parentid, child.data, parent.topparent\n    from    #temp child\n    join    cte parent\n    on      parent.id = child.parentid\n\n)\nselect  id, parentid, data\nfrom    cte\n\ndrop table #temp\n"]], ['get all child from an parent id'], 3, 1], [(10109770, 2), [['Results:'], ['-10000']], [[' id  parentid      data\n2   1              b\n3   2              c\n4   3              d\n5   3              f\n']], ['get all child from an parent id'], 3, 0], [(10121680, 0), [['Another approach would be -'], ['One of the benefits of using this query is that it is easy to modify to include more facility_ids. If you want to find all housing_ids that have facility_ids 1, 3, 4 & 7 you just do -']], [[' SELECT housing_id\nFROM mytable\nWHERE facility_id IN (4,7)\nGROUP BY housing_id\nHAVING COUNT(DISTINCT facility_id) = 2\n']], ['SQL query over multiple rows'], 6, 1], [(10121680, 1), [['One of the benefits of using this query is that it is easy to modify to include more facility_ids. If you want to find all housing_ids that have facility_ids 1, 3, 4 & 7 you just do -'], ['Here are the indices used for running all these tests -']], [[' SELECT housing_id\nFROM mytable\nWHERE facility_id IN (1,3,4,7)\nGROUP BY housing_id\nHAVING COUNT(DISTINCT facility_id) = 4\n']], ['SQL query over multiple rows'], 6, 1], [(10121680, 2), [['Here are the indices used for running all these tests -'], ['First query tested is the dependant subquery -']], [[' SHOW INDEXES FROM mytable;\n+---------+------------+---------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+\n| Table   | Non_unique | Key_name            | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type |\n+---------+------------+---------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+\n| mytable |          0 | UQ_housing_facility |            1 | housing_id  | A         |      500537 |     NULL | NULL   |      | BTREE      |\n| mytable |          0 | UQ_housing_facility |            2 | facility_id | A         |      500537 |     NULL | NULL   |      | BTREE      |\n| mytable |          0 | UQ_facility_housing |            1 | facility_id | A         |          12 |     NULL | NULL   |      | BTREE      |\n| mytable |          0 | UQ_facility_housing |            2 | housing_id  | A         |      500537 |     NULL | NULL   |      | BTREE      |\n| mytable |          1 | IX_housing          |            1 | housing_id  | A         |      500537 |     NULL | NULL   |      | BTREE      |\n| mytable |          1 | IX_facility         |            1 | facility_id | A         |          12 |     NULL | NULL   |      | BTREE      |\n+---------+------------+---------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+\n']], ['SQL query over multiple rows'], 6, 0], [(10121680, 3), [['First query tested is the dependant subquery -'], ['Next is my version using the GROUP BY ... HAVING COUNT ...']], [[' SELECT SQL_NO_CACHE DISTINCT housing_id\nFROM mytable\nWHERE housing_id IN (SELECT housing_id FROM mytable WHERE facility_id=4)\nAND housing_id IN (SELECT housing_id FROM mytable WHERE facility_id=7);\n\n17321 rows in set (9.15 sec)\n\n+----+--------------------+---------+-----------------+----------------------------------------------------------------+---------------------+---------+------------+--------+---------------------------------------+\n| id | select_type        | table   | type            | possible_keys                                                  | key                 | key_len | ref        | rows   | Extra                                 |\n+----+--------------------+---------+-----------------+----------------------------------------------------------------+---------------------+---------+------------+--------+---------------------------------------+\n|  1 | PRIMARY            | mytable | range           | NULL                                                           | IX_housing          | 4       | NULL       | 500538 | Using where; Using index for group-by |\n|  3 | DEPENDENT SUBQUERY | mytable | unique_subquery | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | func,const |      1 | Using index; Using where              |\n|  2 | DEPENDENT SUBQUERY | mytable | unique_subquery | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | func,const |      1 | Using index; Using where              |\n+----+--------------------+---------+-----------------+----------------------------------------------------------------+---------------------+---------+------------+--------+---------------------------------------+\n\nSELECT SQL_NO_CACHE DISTINCT housing_id\nFROM mytable\nWHERE housing_id IN (SELECT housing_id FROM mytable WHERE facility_id=1)\nAND housing_id IN (SELECT housing_id FROM mytable WHERE facility_id=3)\nAND housing_id IN (SELECT housing_id FROM mytable WHERE facility_id=4)\nAND housing_id IN (SELECT housing_id FROM mytable WHERE facility_id=7);\n\n567 rows in set (9.30 sec)\n\n+----+--------------------+---------+-----------------+----------------------------------------------------------------+---------------------+---------+------------+--------+---------------------------------------+\n| id | select_type        | table   | type            | possible_keys                                                  | key                 | key_len | ref        | rows   | Extra                                 |\n+----+--------------------+---------+-----------------+----------------------------------------------------------------+---------------------+---------+------------+--------+---------------------------------------+\n|  1 | PRIMARY            | mytable | range           | NULL                                                           | IX_housing          | 4       | NULL       | 500538 | Using where; Using index for group-by |\n|  5 | DEPENDENT SUBQUERY | mytable | unique_subquery | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | func,const |      1 | Using index; Using where              |\n|  4 | DEPENDENT SUBQUERY | mytable | unique_subquery | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | func,const |      1 | Using index; Using where              |\n|  3 | DEPENDENT SUBQUERY | mytable | unique_subquery | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | func,const |      1 | Using index; Using where              |\n|  2 | DEPENDENT SUBQUERY | mytable | unique_subquery | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | func,const |      1 | Using index; Using where              |\n+----+--------------------+---------+-----------------+----------------------------------------------------------------+---------------------+---------+------------+--------+---------------------------------------+\n']], ['SQL query over multiple rows'], 6, 0], [(10121680, 4), [['Next is my version using the GROUP BY ... HAVING COUNT ...'], ['And last but not least the self join -']], [[' SELECT SQL_NO_CACHE housing_id\nFROM mytable\nWHERE facility_id IN (4,7)\nGROUP BY housing_id\nHAVING COUNT(DISTINCT facility_id) = 2;\n\n17321 rows in set (0.79 sec)\n\n+----+-------------+---------+-------+---------------------------------+-------------+---------+------+--------+------------------------------------------+\n| id | select_type | table   | type  | possible_keys                   | key         | key_len | ref  | rows   | Extra                                    |\n+----+-------------+---------+-------+---------------------------------+-------------+---------+------+--------+------------------------------------------+\n|  1 | SIMPLE      | mytable | range | UQ_facility_housing,IX_facility | IX_facility | 4       | NULL | 198646 | Using where; Using index; Using filesort |\n+----+-------------+---------+-------+---------------------------------+-------------+---------+------+--------+------------------------------------------+\n\nSELECT SQL_NO_CACHE housing_id\nFROM mytable\nWHERE facility_id IN (1,3,4,7)\nGROUP BY housing_id\nHAVING COUNT(DISTINCT facility_id) = 4;\n\n567 rows in set (1.25 sec)\n\n+----+-------------+---------+-------+---------------------------------+-------------+---------+------+--------+------------------------------------------+\n| id | select_type | table   | type  | possible_keys                   | key         | key_len | ref  | rows   | Extra                                    |\n+----+-------------+---------+-------+---------------------------------+-------------+---------+------+--------+------------------------------------------+\n|  1 | SIMPLE      | mytable | range | UQ_facility_housing,IX_facility | IX_facility | 4       | NULL | 407160 | Using where; Using index; Using filesort |\n+----+-------------+---------+-------+---------------------------------+-------------+---------+------+--------+------------------------------------------+\n']], ['SQL query over multiple rows'], 6, 0], [(10121680, 5), [['And last but not least the self join -'], ['-10000']], [[' SELECT SQL_NO_CACHE a.housing_id\nFROM mytable a\nINNER JOIN mytable b\n    ON a.housing_id = b.housing_id\nWHERE a.facility_id = 4 AND b.facility_id = 7;\n\n17321 rows in set (1.37 sec)\n\n+----+-------------+-------+--------+----------------------------------------------------------------+---------------------+---------+-------------------------+-------+-------------+\n| id | select_type | table | type   | possible_keys                                                  | key                 | key_len | ref                     | rows  | Extra       |\n+----+-------------+-------+--------+----------------------------------------------------------------+---------------------+---------+-------------------------+-------+-------------+\n|  1 | SIMPLE      | b     | ref    | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | IX_facility         | 4       | const                   | 94598 | Using index |\n|  1 | SIMPLE      | a     | eq_ref | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | test.b.housing_id,const |     1 | Using index |\n+----+-------------+-------+--------+----------------------------------------------------------------+---------------------+---------+-------------------------+-------+-------------+\n\nSELECT SQL_NO_CACHE a.housing_id\nFROM mytable a\nINNER JOIN mytable b\n    ON a.housing_id = b.housing_id\nINNER JOIN mytable c\n    ON a.housing_id = c.housing_id\nINNER JOIN mytable d\n    ON a.housing_id = d.housing_id\nWHERE a.facility_id = 1\nAND b.facility_id = 3\nAND c.facility_id = 4\nAND d.facility_id = 7;\n\n567 rows in set (1.64 sec)\n\n+----+-------------+-------+--------+----------------------------------------------------------------+---------------------+---------+-------------------------+-------+--------------------------+\n| id | select_type | table | type   | possible_keys                                                  | key                 | key_len | ref                     | rows  | Extra                    |\n+----+-------------+-------+--------+----------------------------------------------------------------+---------------------+---------+-------------------------+-------+--------------------------+\n|  1 | SIMPLE      | b     | ref    | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | IX_facility         | 4       | const                   | 93782 | Using index              |\n|  1 | SIMPLE      | d     | eq_ref | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | test.b.housing_id,const |     1 | Using index              |\n|  1 | SIMPLE      | c     | eq_ref | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | test.b.housing_id,const |     1 | Using index              |\n|  1 | SIMPLE      | a     | eq_ref | UQ_housing_facility,UQ_facility_housing,IX_housing,IX_facility | UQ_housing_facility | 8       | test.d.housing_id,const |     1 | Using where; Using index |\n+----+-------------+-------+--------+----------------------------------------------------------------+---------------------+---------+-------------------------+-------+--------------------------+\n']], ['SQL query over multiple rows'], 6, 0], [(10139181, 0), [['-10000'], ['Just a side note: \nIf you have a more advanced SQL server that supports windowing functions, like SQL Server 2008 you can instead write']], [[' SELECT a.custID, MAX(a.product), MAX(a.price)\nFROM orders AS a \nWHERE a.price = (select MAX(b.price) from orders b where a.custID=b.custID)\nGROUP by a.custID\n']], ['Extract maximum value with object name in Access using SQL - handle identical values'], 2, 1], [(10164354, 0), [['I recommend against using  either of these methods you described.  Instead, create a single  highlight  table with 3 columns:'], ['Values then look like:']], [[' CREATE TABLE highlight \n(\n  article_id INT NOT NULL,\n  language VARCHAR(),\n  highlight_text VARCHAR() CHARACTER SET utf8,\n  PRIMARY KEY (article_id, language),\n  FOREIGN KEY (article_id) REFERENCES articles (article_id)\n)\n']], ['Designing a table with a column need to stored in four different languages'], 2, 1], [(10164354, 1), [['Values then look like:'], ['-10000']], [[' 2  en  The English text for article 2\n2  dr  The French text for article 2\n2  de  The German text for article 2\n3  en  The English text for article 3\n3  dr  The French text for article 3\n3  de  The German text for article 3\n3  sw  Oh wait, article 3 also needed Swahili text!\n']], ['Designing a table with a column need to stored in four different languages'], 2, 0], [(10182533, 1), [['Then get rid of all the cursor and looping nonsense and do this:'], ['-10000']], [[' INSERT dbo.mrhierlookup\n(\n  heiraui,\n  aui\n)\nSELECT s.Item, m.aui\n  FROM dbo.mrhier3 AS m\n  CROSS APPLY dbo.SplitStrings(m.ptr) AS s\nGROUP BY s.Item, m.aui;\n']], ['Efficient query to split a delimited column into a separate table'], 2, 0], [(10189129, 0), [['This is a simple one, LIMIT the subquery'], ['An alternative (and my preferred) would be the following, where the subquery gets the data, and the outer query simply reorders it before spitting it back out.']], [[' SELECT ci.*\nFROM `calendar_item` AS `ci` \nWHERE (ci.id IN (\n    SELECT id FROM calendar_item \n    WHERE (end_time < FROM_UNIXTIME(1334667600))\n    ORDER BY end_time DESC\n    LIMIT 10\n))\nGROUP BY `ci`.`id` \nORDER BY `ci`.`end_time` ASC\nLIMIT 10\n']], ['Retrieving the previous 10 results from a table that are nearest to a certain date and maintaining ascending sorting order'], 2, 1], [(10189129, 1), [['An alternative (and my preferred) would be the following, where the subquery gets the data, and the outer query simply reorders it before spitting it back out.'], ['-10000']], [[' SELECT i.*\nFROM (\n    SELECT ci.*\n    FROM calendar_item AS ci\n    WHERE ci.end_time < FROM_UNIXTIME(1334667600)\n    ORDER BY ci.end_time DESC\n    LIMIT 10\n) AS i\nORDER BY i.`end_time` ASC\n']], ['Retrieving the previous 10 results from a table that are nearest to a certain date and maintaining ascending sorting order'], 2, 1], [(10196144, 0), [['It seems like you just want something like this:'], ['Tbl_Answer']], [[' SELECT C_NAME, AnswerNum\nFROM\n(\nSELECT C.C_NAME, "1" AS AnswerNum, T.USER_ID\nFROM COUNTRY C \n    JOIN TBL_ANSWERS T \n        ON  T.ANSWER1_ID = C.C_ID \nUNION ALL\nSELECT C.C_NAME, "2" AS AnswerNum, T.USER_ID\nFROM COUNTRY C \n    JOIN TBL_ANSWERS T \n        ON  T.ANSWER2_ID = C.C_ID \n...\nUNION ALL\nSELECT C.C_NAME, "8" AS AnswerNum, T.USER_ID\nFROM COUNTRY C \n    JOIN TBL_ANSWERS T \n        ON  T.ANSWER8_ID = C.C_ID \n) AS AnswersJoined\nWHERE USER_ID = \'4\' \n']], ['SQL include duplicates in an SELECT statement'], 4, 1], [(10196144, 1), [['Tbl_Answer'], ['Tbl_Question']], [['  Question_Id|User_Id|Response_Id\n']], ['SQL include duplicates in an SELECT statement'], 4, 0], [(10196144, 2), [['Tbl_Question'], ['This would allow you to just run a simple  BETWEEN . Something like this:']], [['  Id|QuestionNumber\n']], ['SQL include duplicates in an SELECT statement'], 4, 0], [(10199927, 0), [['So avi becomes three rows in a letters table:'], ['http://data.stackexchange.com/stackoverflow/query/67103/http-stackoverflow-com-questions-10199927-find-chars-in-any-order-in-sql-server']], [[' a\nv\ni\n']], ['Find chars in any order in Sql Server'], 2, 0], [(10199927, 1), [['http://data.stackexchange.com/stackoverflow/query/67103/http-stackoverflow-com-questions-10199927-find-chars-in-any-order-in-sql-server'], ['-10000']], [[" DECLARE @t AS TABLE (search varchar(100));\nINSERT INTO @t VALUES ('avi');\n\nDECLARE @words AS TABLE (word varchar(100));\nINSERT INTO @words VALUES ('avion'), ('iva'), ('name');\nwith cte as\n(\n  select substring(search, 1, 1) as letter,\n         stuff(search, 1, 1, '') as search,\n         1 as RowID\n  from @t\n  union all\n  select substring(search, 1, 1) as letter,\n         stuff(search, 1, 1, '') as search,\n         RowID + 1 as RowID\n  from cte\n  where len(search) > 0\n)\n,letters AS (\n  SELECT DISTINCT letter FROM cte\n)\nSELECT words.word\nFROM letters\nINNER JOIN @words AS words\n    ON CHARINDEX(letter, word) > 0\nGROUP BY words.word\nHAVING COUNT(*) = (SELECT COUNT(*) FROM letters)\n"]], ['Find chars in any order in Sql Server'], 2, 1], [(10209706, 0), [['You can use the mod operator,  %  to  ORDER BY'], ['You can get further rotations by adding to Id, ie']], [[' DECLARE @maxId AS INT\nSELECT @maxId = MAX(Id) FROM MyTable\n\nSELECT id FROM MyTable\nORDER BY Id % @maxId \n']], ['Elegant way to create a circular permutation with MySQL'], 3, 1], [(10209706, 1), [['You can get further rotations by adding to Id, ie'], ['get you']], [[' ORDER BY (Id + 1) % @maxId\n']], ['Elegant way to create a circular permutation with MySQL'], 3, 0], [(10209706, 2), [['get you'], ['Working SQL Fiddle (which I just found out exists)\n http://sqlfiddle.com/#!3/a7f15/5']], [[' 3\n4\n1\n2\n']], ['Elegant way to create a circular permutation with MySQL'], 3, 0], [(10240035, 0), [['Give this a try:'], ['Or we can make it even simpler if you were using MySQL:']], [[" select name,\n    count(case when grade in ('A', 'B', 'C') then 1 end) totalPass,\n    count(case when grade = 'A' then 1 end) totalA,\n    count(case when grade = 'B' then 1 end) totalB,\n    count(case when grade = 'C' then 1 end) totalC\nfrom t\ngroup by name\n"]], ['SQL and Counting'], 2, 1], [(10240035, 1), [['Or we can make it even simpler if you were using MySQL:'], ['Here is the  fiddle .']], [[" select name,\n    sum(grade in ('A', 'B', 'C')) totalPass,\n    sum(grade = 'A') totalA,\n    sum(grade = 'B') totalB,\n    sum(grade = 'C') totalC\nfrom t\ngroup by name\n"]], ['SQL and Counting'], 2, 1], [(10277115, 0), [['Using ROW_NUMBER'], ['Using MAX']], [[' SELECT *\nFROM   (\n         SELECT ID, voting_ID, username, timestamp, XMLBallot\n                , rn = ROW_NUMBER() OVER (PARTITION BY voting_ID, username ORDER BY timestamp DESC)\n         FROM   Ballots\n       ) bt \nWHERE  rn = 1\n']], ['Select newest record group by username in SQL Server 2008'], 2, 1], [(10277115, 1), [['Using MAX'], ['-10000']], [[' SELECT bt.ID, bt.voting_ID, bt.username, bt.timestamp, bt.XMLBallot\nFROM   Ballots bt\n       INNER JOIN (\n          SELECT username, voting_ID, timestamp = MAX(timestamp)\n          FROM   Ballots\n          GROUP BY\n                 username, voting_ID\n        ) btm ON btm.username = bt.Username\n                 AND btm.voting_ID = bt.voting_ID\n                 AND btm.timestamp = bt.timestamp\n']], ['Select newest record group by username in SQL Server 2008'], 2, 1], [(10296422, 0), [["I'd be tempted to create a separate table,  RunInformation , with a primary key column,  Id , and a  RunDate  column:"], ['You could then replace the  dateRan  column from your table with a reference to the  RunInformation  table. This will allow you to store additional information about the run in future, if the needs arises.']], [[' Id -- RunDate\n']], ['How to assign an id to a group SQL Server'], 2, 0], [(10296422, 1), [['You could then replace the  dateRan  column from your table with a reference to the  RunInformation  table. This will allow you to store additional information about the run in future, if the needs arises.'], ['-10000']], [[' Id -- Name -- AttributeIMeasure -- RunInformationId\n']], ['How to assign an id to a group SQL Server'], 2, 0], [(10310499, 1), [['Then I guess you could'], ['Basicly just skip getting the STATUS column from T1. Then there can be no conflict.']], [[' SELECT T1.name, T1.address, T1.phone, T2.title, T2.description \nFROM (  SELECT CID, name, address, phone\n        FROM T1) AS T1\nLEFT JOIN T2\nON T1.CID=T2.ID\nWHERE STATUS = 1\n']], ['How to avoid "Ambiguous field in query" without adding Table Name or Table Alias in where clause'], 2, 1], [(10330898, 0), [['Maybe something like this:'], ['If you want the other years and still sum them. Then you can do this:']], [[" SELECT \n    item_name, \n    SUM(CASE WHEN YEAR( DATE )=2011 THEN item_sold_qty ELSE 0 END) AS '2011',\n    SUM(CASE WHEN YEAR( DATE )=2012 THEN item_sold_qty ELSE 0 END) AS '2012'\nFROM \n    item\nJOIN sales ON item.id = sales.item_number\nGROUP BY\n    item_name\nORDER BY \n    item_name\n"]], ['sql query to set year as column name'], 2, 1], [(10330898, 1), [['If you want the other years and still sum them. Then you can do this:'], ['EDIT2']], [[" SELECT \n    item_name, \n    SUM(CASE WHEN YEAR( DATE )=2011 THEN item_sold_qty ELSE 0 END) AS '2011',\n    SUM(CASE WHEN YEAR( DATE )=2012 THEN item_sold_qty ELSE 0 END) AS '2012',\n    SUM(CASE WHEN NOT YEAR( DATE ) IN (2011,2012) THEN item_sold_qty ELSE 0 END) AS 'AllOtherYears'\nFROM \n    item\nJOIN sales ON item.id = sales.item_number\nGROUP BY\n    item_name\nORDER BY \n    item_name\n"]], ['sql query to set year as column name'], 2, 1], [(10338000, 0), [["I think you're on the right track with views, but since each call will need to pass the user ID, it sounds like what you really need are table-valued functions.  I'm most familiar with Microsoft SQL, where it would look something like this:"], ['Note that the TVF literally returns a table, to which you would join to see which projects are available.  The TVF definition might look something like this:']], [[' SELECT P.*\nFROM Projects AS P\n     INNER JOIN dbo.AuthProjects(@UserID) AS AP ON P.ProjectID = AP.ProjectID\n']], ['how to do content based authorization?'], 2, 0], [(10338000, 1), [['Note that the TVF literally returns a table, to which you would join to see which projects are available.  The TVF definition might look something like this:'], ['-10000']], [[' CREATE FUNCTION dbo.AuthProjects(@UserID INT)\n    RETURNS @Results TABLE (ProjectID INT NOT NULL, WriteAccess BIT NOT NULL)\nAS BEGIN\n    INSERT INTO @Results (ProjectID, WriteAccess)\n        SELECT\n            ProjectID, WriteAccess\n        FROM\n            Authorizations\n        WHERE\n            UserID = @UserID\n\n    -- Additional logic for more ways a project may be authorized\n\n    RETURN\nEND\n']], ['how to do content based authorization?'], 2, 0], [(10389260, 0), [['try something like this:'], ['OUTPUT:']], [[" DECLARE @YourTable table (A int, b varchar(10))\nINSERT @YourTable VALUES (0, 'hello') --OP's data\nINSERT @YourTable VALUES (0, 'test')\nINSERT @YourTable VALUES (0, 'hi')\nINSERT @YourTable VALUES (1, 'blah1')\nINSERT @YourTable VALUES (1, 'blah2')\nINSERT @YourTable VALUES (1, 'blah3')\nINSERT @YourTable VALUES (1, 'blah4')\nINSERT @YourTable VALUES (1, 'blah5')\nINSERT @YourTable VALUES (1, 'blah6')\n\n;WITH NumberedRows AS\n(   SELECT \n        A,B,ROW_NUMBER() OVER (PARTITION BY A ORDER BY A,B) AS RowNumber\n        FROM @YourTable\n)\n, GroupCounts AS\n(   SELECT\n        A,MAX(RowNumber) AS MaxA\n        FROM NumberedRows\n        GROUP BY A\n)\nSELECT\n    n.a,n.b\n    FROM NumberedRows           n\n        INNER JOIN GroupCounts  c ON n.A=c.A\n    WHERE n.RowNUmber<=(c.MaxA+1)*0.3\n"]], ['Select 30% of each column value'], 6, 1], [(10389260, 1), [['OUTPUT:'], ['EDIT  based on the great idea in the comment from Andriy M']], [[' a           b\n----------- ----------\n0           hello\n1           blah1\n1           blah2\n\n(3 row(s) affected)\n']], ['Select 30% of each column value'], 6, 0], [(10389260, 2), [['EDIT  based on the great idea in the comment from Andriy M'], ['OUTPUT:']], [[' ;WITH NumberedRows AS\n(   SELECT \n        A,B,ROW_NUMBER() OVER (PARTITION BY A ORDER BY A,B) AS RowNumber\n            ,COUNT(*) OVER (PARTITION BY A) AS TotalOf\n        FROM @YourTable\n)\nSELECT\n    n.a,n.b\n    FROM NumberedRows            n\n    WHERE n.RowNumber<=(n.TotalOf+1)*0.3\n    ORDER BY A\n']], ['Select 30% of each column value'], 6, 1], [(10389260, 3), [['OUTPUT:'], ['EDIT  here are "random" rows, using Andriy M idea:']], [[' a           b\n----------- ----------\n0           hello\n1           blah1\n1           blah2\n\n(3 row(s) affected)\n']], ['Select 30% of each column value'], 6, 0], [(10389260, 4), [['EDIT  here are "random" rows, using Andriy M idea:'], ['OUTPUT:']], [[" DECLARE @YourTable table (A int, b varchar(10))\nINSERT @YourTable VALUES (0, 'hello') --OP's data\nINSERT @YourTable VALUES (0, 'test')\nINSERT @YourTable VALUES (0, 'hi')\nINSERT @YourTable VALUES (1, 'blah1')\nINSERT @YourTable VALUES (1, 'blah2')\nINSERT @YourTable VALUES (1, 'blah3')\nINSERT @YourTable VALUES (1, 'blah4')\nINSERT @YourTable VALUES (1, 'blah5')\nINSERT @YourTable VALUES (1, 'blah6')\n\n;WITH NumberedRows AS\n(   SELECT \n        A,B,ROW_NUMBER() OVER (PARTITION BY A ORDER BY newid()) AS RowNumber\n        FROM @YourTable\n)\n, GroupCounts AS (SELECT A,COUNT(A) AS MaxA FROM NumberedRows GROUP BY A)\nSELECT\n    n.A,n.B\n    FROM NumberedRows           n\n        INNER JOIN GroupCounts  c ON n.A=c.A\n    WHERE n.RowNUmber<=(c.MaxA+1)*0.3\n    ORDER BY n.A\n"]], ['Select 30% of each column value'], 6, 1], [(10389260, 5), [['OUTPUT:'], ['-10000']], [[' a           b\n----------- ----------\n0           hi\n1           blah3\n1           blah6\n\n(3 row(s) affected)\n']], ['Select 30% of each column value'], 6, 0], [(10423479, 0), [['try this:'], ['hope this helps.']], [[' SELECT  a.Event_ID, \n        a.Competitor_ID,\n        a.Place,\n        COALESCE(b.money, 0) as `Money`\nFROM    entry a left join prize b\n            on  (a.event_id = b.event_ID) AND\n                (a.place = b.Place)\n']], ['MySQL Retrieving data from two tables using inner join syntax'], 2, 1], [(10423479, 1), [['hope this helps.'], ['-10000']], [[" EVENT_ID    COMPETITOR_ID   PLACE   MONEY\n101           101            1      120\n101           102            2       60\n101           201            3       30\n101           301            4        0   -- << this is what you're looking for\n102           201            2        5\n103           201            3       40\n"]], ['MySQL Retrieving data from two tables using inner join syntax'], 2, 0], [(10477017, 0), [['Ignoring, for the moment, the question of what to do if the same value appears in the  same  table, the simplest query would be:'], ['Or, we could do it in the  UNION  style from your question.']], [[' SELECT * from Table1 T1 full outer join Table2\nON T1.IDCodeField = T2.IDCodeField\nWHERE T1.IDCodeField is null or T2.IDCodeField is null\n']], ['SQL Compare with one column, but returns all columns if matched'], 3, 1], [(10477017, 1), [['Or, we could do it in the  UNION  style from your question.'], ['Both of the above queries  will  return rows if the same  IDCodeField  value is duplicated only within a single table. If you wish to exclude this possibility, you might try finding the unique values first:']], [[' SELECT * from Table1 where IDCodeField not in (select IDCodeField from Table2)\nUNION ALL\nSELECT * from Table2 where IDCodeField not in (select IDCOdeField from Table1)\n']], ['SQL Compare with one column, but returns all columns if matched'], 3, 1], [(10532323, 0), [['Try this:'], ['Output:']], [[' select *, CurrentLocation\nfrom tbl x\n\nouter apply\n(\n  select top 1 location as CurrentLocation\n  from tbl\n  where [user] = x.[user]\n    and id <= x.id\n  order by id\n\n) y\n\norder by id\n']], ['Replicate recent location'], 2, 1], [(10532323, 1), [['Output:'], ['Live test:  http://www.sqlfiddle.com/#!3/83a6a/7']], [[' ID      USER    DATE            LOCATION    CURRENTLOCATION\n1       Tom     2012-03-06      US          US\n2       Tom     2012-02-04      UK          US\n3       Tom     2012-01-06      Uk          US\n4       Bob     2012-03-06      UK          UK\n5       Bob     2012-02-04      UK          UK\n6       Bob     2012-01-06      AUS         UK\n7       Dev     2012-03-06      US          US\n8       Dev     2012-02-04      AUS         US\n9       Nic     2012-01-06      US          US\n']], ['Replicate recent location'], 2, 0], [(10659824, 0), [["If you want to simultaneously count the number of rows with multiple specific criteria in a data set, you can use the pattern  COUNT(CASE WHEN criteria THEN 1 END) .  Here's an example that counts the number of rows for  stats = 2 , and for  stats = 3 :"], ['Results:']], [[' SELECT\n  count(case when stats = 2 then 1 end) as ok,\n  count(case when stats = 3 then 1 end) as not_ok\nfrom\n  Table1\n']], ['Mysql Count Distinct results'], 2, 1], [(10659824, 1), [['Results:'], ['Demo:  http://www.sqlfiddle.com/#!2/82414/1']], [[' OK | NOT_OK\n-----------\n2  | 1\n']], ['Mysql Count Distinct results'], 2, 0], [(10666965, 0), [['This is the answer:'], ['First, you need to get a set where for each products with lowest priority, which is from this query:']], [[' select a.id, a.name, a.category, a.price, b.filename as file_name \nfrom products a left join (\n    select i.p_id, i.filename from (select id, min(priority) as min_p \n    from images group by p_id) q \n    left join images i on q.id = i.id\n) b on a.id = b.p_id \nwhere a.category in (1, 2, 3);\n']], ['Joining two MySQL tables, but with additional conditions?'], 7, 1], [(10666965, 1), [['First, you need to get a set where for each products with lowest priority, which is from this query:'], ['The result will be:']], [[' select id, min(priority) as min_p from images group by p_id;\n']], ['Joining two MySQL tables, but with additional conditions?'], 7, 0], [(10666965, 2), [['The result will be:'], ["The next step will be to get an outer join, in this case I'd choose (arbitrarily according to my preference), the left join:"]], [[' +----+----------+\n| id | lowest_p |\n+----+----------+\n|  1 |        0 |\n|  2 |        2 |\n|  3 |        2 |\n|  4 |        1 |\n+----+----------+\n4 rows in set (0.00 sec)\n']], ['Joining two MySQL tables, but with additional conditions?'], 7, 0], [(10666965, 3), [["The next step will be to get an outer join, in this case I'd choose (arbitrarily according to my preference), the left join:"], ['This query produce what you want in short:']], [[' select i.p_id, i.filename from (select id, min(priority) as min_p \nfrom images group by p_id) q left join images i on q.id = i.id;\n']], ['Joining two MySQL tables, but with additional conditions?'], 7, 0], [(10666965, 4), [['This query produce what you want in short:'], ['Now you just need to decorate this, again using left join:']], [[' +------+----------+\n| p_id | filename |\n+------+----------+\n|    1 | image1   |\n|    2 | image3   |\n|    3 | image4   |\n|    4 | image7   |\n+------+----------+\n4 rows in set (0.00 sec)\n']], ['Joining two MySQL tables, but with additional conditions?'], 7, 0], [(10666965, 5), [['Now you just need to decorate this, again using left join:'], ["And you'll get what you want:"]], [[' select a.id, a.name, a.category, a.price, b.filename as file_name \nfrom products a left join (\n    select i.p_id, i.filename from (select id, min(priority) as min_p \n    from images group by p_id) q \n    left join images i on q.id = i.id\n) b on a.id = b.p_id \nwhere a.category in (1, 2, 3);\n']], ['Joining two MySQL tables, but with additional conditions?'], 7, 1], [(10666965, 6), [["And you'll get what you want:"], ['You can also put the products in the right hand side of the left join, depending on what you expected when there is product without images available. The query above will display the view as above, with the file_name field as "null".']], [[' +------+-------+----------+-------+-----------+\n| id   | name  | category | price | file_name |\n+------+-------+----------+-------+-----------+\n|    1 | item1 |        1 |  0.99 | image1    |\n|    2 | item2 |        2 |  1.99 | image3    |\n|    3 | item3 |        3 |  2.95 | image4    |\n+------+-------+----------+-------+-----------+\n3 rows in set (0.00 sec)\n']], ['Joining two MySQL tables, but with additional conditions?'], 7, 0], [(10670090, 0), [['You can use:'], ['Or for MySQL:']], [[' SELECT TOP 1 ID, MIN(SQRT(POW((100-x),2)) + POW((150-y),2)) AS distance FROM cabstands GROUP BY ID ORDER BY distance ASC\n']], ['SQL Query With Calculated MIN, Requesting Other Column Returns All Rows'], 2, 1], [(10670090, 1), [['Or for MySQL:'], ['-10000']], [[' SELECT ID, MIN(SQRT(POW((100-x),2)) + POW((150-y),2)) AS distance FROM cabstands GROUP BY ID ORDER BY distance ASC LIMIT 1\n']], ['SQL Query With Calculated MIN, Requesting Other Column Returns All Rows'], 2, 1], [(10694376, 0), [['Try this:'], ['Or this:']], [[' CREATE TABLE teamPlayer\n(\nplayerID INT NOT NULL, \nteamID INT NOT NULL,\nPRIMARY KEY(playerID, teamID)\n);\n\nalter table teamPlayer\nadd constraint \n    fk_teamPlayer__Player foreign key(playerID) references Player(personID);\n\nalter table teamPlayer\nadd constraint \n    fk_teamPlayer__Team foreign key(teamID) references Team(teamID);\n']], ['SQL how to handle a many to many relationship'], 3, 1], [(10694376, 1), [['Or this:'], ["If you don't need to name your foreign keys explicitly, you can use this:"]], [[' CREATE TABLE teamPlayer\n(\nplayerID INT NOT NULL, \nteamID INT NOT NULL,\nPRIMARY KEY(playerID, teamID),\n\nconstraint fk_teamPlayer__Player\nforeign key(playerID) references Player(personID),\n\nconstraint fk_teamPlayer__Team \nforeign key(teamID) references Team(teamID)\n\n);\n']], ['SQL how to handle a many to many relationship'], 3, 1], [(10694376, 2), [["If you don't need to name your foreign keys explicitly, you can use this:"], ['-10000']], [[' CREATE TABLE teamPlayer\n(\nplayerID INT NOT NULL references Player(personID), \nteamID INT NOT NULL references Team(teamID),\nPRIMARY KEY(playerID, teamID)\n);\n']], ['SQL how to handle a many to many relationship'], 3, 1], [(10777996, 0), [["You can use Common Table Expressions (CTEs) to solve this problem.  CTEs can be used for recursion, as Andrei pointed out (see the excellent reference that Andrei included in his post).  Let's say you have a table as follows:"], ["and let's insert the following data into the table:"]], [[' create table Person\n(\n   PersonId int primary key,\n   Name varchar(25),\n   ManagerId int foreign Key references Person(PersonId)\n)\n']], ['SQL query when a table has a link to itself'], 4, 0], [(10777996, 1), [["and let's insert the following data into the table:"], ["then we want a query that will return everyone who directly or indirectly reports to Bob, which would be Steve, Tim and John.  We don't want to return James and Bob, since they report to no one, or Joe, since he reports to James.  This can be done with a CTE query as follows:"]], [[" insert into Person (PersonId, Name, ManagerId) values \n    (1,'Bob', null),\n    (2, 'Steve',1),\n    (3, 'Tim', 2)\n    (4, 'John', 3),\n    (5, 'James', null),\n    (6, 'Joe', 5)\n"]], ['SQL query when a table has a link to itself'], 4, 0], [(10777996, 3), [['This query returns the correct results:'], ['Edit:  This answer is valid assuming the OP is using SQL Server 2005 or higher.  I do not know if this syntax is valid in MySQL or Oracle.']], [[' PersonId    Name                      ManagerId\n----------- ------------------------- -----------\n2           Steve                     1\n3           Tim                       2\n4           John                      3\n']], ['SQL query when a table has a link to itself'], 4, 0], [(10787043, 0), [['-10000'], ['Result:']], [[" SET search_path= 'tmp';\n\nDROP TABLE dogcat CASCADE;\nCREATE TABLE dogcat\n        ( id serial NOT NULL\n        , zname    varchar\n        , foo    INTEGER\n        , bar    INTEGER\n        , house_id INTEGER NOT NULL\n        , PRIMARY KEY (zname,house_id)\n        );\nINSERT INTO dogcat(zname,foo,bar,house_id) VALUES\n  ('Cat',12,4,1)\n ,('Cat',9,4,2)\n ,('Dog',8,23,1)\n ,('Bird',9,54,1)\n ,('Bird',78,2,2)\n ,('Bird',29,32,3)\n        ;\n-- Carthesian product of the {name,house_id} domains\nWITH cart AS (\n        WITH beast AS (\n                SELECT distinct zname AS zname\n                FROM dogcat\n                )\n        , house AS (\n                SELECT distinct house_id AS house_id\n                FROM dogcat\n                )\n        SELECT beast.zname AS zname\n        ,house.house_id AS house_id\n        FROM beast , house\n        )\nINSERT INTO dogcat(zname,house_id, foo,bar)\nSELECT ca.zname, ca.house_id\n        ,fb.foo, fb.bar\nFROM cart ca\n     -- find the animal with the lowes id\nJOIN dogcat fb ON fb.zname = ca.zname AND NOT EXISTS\n        ( SELECT * FROM dogcat nx\n        WHERE nx.zname = fb.zname\n        AND nx.id < fb.id\n        )\nWHERE NOT EXISTS (\n        SELECT * FROM dogcat dc\n        WHERE dc.zname = ca.zname\n        AND dc.house_id = ca.house_id\n        )\n        ;\n\nSELECT * FROM dogcat;\n"]], ["Returning a row if and only if a sibling row doesn't exist"], 2, 1], [(10787043, 1), [['Result:'], ['-10000']], [[' SET\nDROP TABLE\nNOTICE:  CREATE TABLE will create implicit sequence "dogcat_id_seq" for serial column "dogcat.id"\nNOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "dogcat_pkey" for table "dogcat"\nCREATE TABLE\nINSERT 0 6\nINSERT 0 3\n id | zname | foo | bar | house_id \n----+-------+-----+-----+----------\n  1 | Cat   |  12 |   4 |        1\n  2 | Cat   |   9 |   4 |        2\n  3 | Dog   |   8 |  23 |        1\n  4 | Bird  |   9 |  54 |        1\n  5 | Bird  |  78 |   2 |        2\n  6 | Bird  |  29 |  32 |        3\n  7 | Cat   |  12 |   4 |        3\n  8 | Dog   |   8 |  23 |        2\n  9 | Dog   |   8 |  23 |        3\n(9 rows)\n']], ["Returning a row if and only if a sibling row doesn't exist"], 2, 0], [(10797333, 0), [['There are a couple of different approaches you could take to get data into your array.  The first would be a simple loop, as in the following:'], ['Another, as suggested by @Rene, would be to use BULK COLLECT, as follows:']], [[' DECLARE\n  TYPE NUMBER_ARRAY IS VARRAY(100) OF NUMBER;\n\n  arrNums  NUMBER_ARRAY;\n  i NUMBER := 1;\nBEGIN\n  arrNums := NUMBER_ARRAY();\n\n  FOR aRow IN (SELECT NUMBER_FIELD\n                 FROM A_TABLE\n                 WHERE ROWNUM <= 100)\n  LOOP\n    arrNums.EXTEND;\n    arrNums(i) := aRow.SEQUENCE_NO;\n    i := i + 1;\n  END LOOP;\nend;\n']], ['How to Specify Array variable in plsql'], 2, 1], [(10797333, 1), [['Another, as suggested by @Rene, would be to use BULK COLLECT, as follows:'], ['Share and enjoy.']], [[' DECLARE\n  TYPE NUMBER_ARRAY IS VARRAY(100) OF NUMBER;\n\n  arrNums  NUMBER_ARRAY;\nBEGIN\n  arrNums := NUMBER_ARRAY();\n  arrNums.EXTEND(100);\n\n  SELECT NUMBER_FIELD\n    BULK COLLECT INTO arrNums\n    FROM A_TABLE\n    WHERE ROWNUM <= 100;\nend;\n']], ['How to Specify Array variable in plsql'], 2, 1], [(10813098, 0), [['You do it the same way you will do normally -'], ['If you need query where any one remark matches -']], [[' SELECT ABC.*, XYZ.* FROM XYZ, ABC\nWHERE \nXYZ.KOD_TYPE=ABC.REMARK1\nAND XYZ.KOD_TYPE=ABC.REMARK2\nAND XYZ.KOD_TYPE=ABC.REMARK3\nAND XYZ.KOD_TYPE=ABC.REMARK4\nAND XYZ.KOD_TYPE=ABC.REMARK5\n']], ['JOIN multiple fields to one field'], 2, 1], [(10813098, 1), [['If you need query where any one remark matches -'], ['-10000']], [[' SELECT ABC.*, XYZ.* FROM XYZ, ABC\nWHERE \nXYZ.KOD_TYPE=ABC.REMARK1\nOR XYZ.KOD_TYPE=ABC.REMARK2\nOR XYZ.KOD_TYPE=ABC.REMARK3\nOR XYZ.KOD_TYPE=ABC.REMARK4\nOR XYZ.KOD_TYPE=ABC.REMARK5\n']], ['JOIN multiple fields to one field'], 2, 1], [(10860452, 0), [['For example, consider the following table'], ["Now let's  find out which columns belong to  indextest_uq :"]], [[' CREATE TABLE indextest (a INT, b INT);\nALTER TABLE indextest ADD CONSTRAINT indextest_pk PRIMARY KEY (a);\nALTER TABLE indextest ADD CONSTRAINT indextest_uq UNIQUE (a, b);                                                                           \n']], ['How to discover the columns for a given index or key in MonetDB'], 3, 0], [(10860452, 2), [['The result of this query looks like this:'], ['Obviously, more information from the  columns  and  tables  tables could be included by extending the  SELECT  part of the query.']], [[' +----------+-----------+------------+-------------+-------------+\n| index_id | column_id | table_name | column_name | column_type |\n+==========+===========+============+=============+=============+\n|     6446 |      6438 | indextest  | a           | int         |\n|     6446 |      6439 | indextest  | b           | int         |\n+----------+-----------+------------+-------------+-------------+\n']], ['How to discover the columns for a given index or key in MonetDB'], 3, 0], [(10918093, 0), [['You need to use this Postgres function'], ['Your situation involves the select statement having the following:']], [[" overlay(string placing string from int [for int]) \nex: overlay('Txxxxas' placing 'hom' from 2 for 4)\n"]], ['Changing part of a string on some values in postgres database'], 2, 1], [(10919401, 0), [['The usual trick is to set a separate parameter for selecting everything:'], ['If you are willing to switch to using  named JDBC parameters , you could rewrite with one parameter, and use  null  to mean "select everything":']], [[' SELECT book FROM com WHERE genre=? OR 1=?\n']], ['Select all data in sql with where condition?'], 2, 1], [(10919401, 1), [['If you are willing to switch to using  named JDBC parameters , you could rewrite with one parameter, and use  null  to mean "select everything":'], ['-10000']], [[' SELECT book FROM com WHERE genre=:genre_param OR :genre_param is null\n']], ['Select all data in sql with where condition?'], 2, 1], [(10979035, 1), [['and alter your table'], ['-10000']], [[' ALTER TABLE <yourTable> \nADD CONSTRAINT Ck_UniqueDefaultForUser \nCHECK (dbo.CheckDefaultUnicity(UserId) <2)\n']], ['Single default value in a table'], 2, 0], [(10993189, 0), [['Just remove the  .*  at the end of your expression it is responsible for matching the additional stuff.'], ['To ensure that there is a non digit after the 4 digits at the end you can use an alternation']], [[" SELECT 1 FROM DUAL WHERE \n  REGEXP_LIKE('555-5555x123', '^[0-9]{3,4}[^[:digit:]][0-9]{4}$')\n"]], ['Oracle Regex expression to match exactly non digit then digits again'], 2, 1], [(10993189, 1), [['To ensure that there is a non digit after the 4 digits at the end you can use an alternation'], ['Now, after your 4 digits there must be either the end of the row OR a non digit ( [^0-9]  is a negated character class), then anything (but newlines) till the end of the row.']], [[" SELECT 1 FROM DUAL WHERE \n  REGEXP_LIKE('555-5555x123', '^[0-9]{3,4}[^[:digit:]][0-9]{4}($|[^0-9].*$)')\n"]], ['Oracle Regex expression to match exactly non digit then digits again'], 2, 1], [(10993546, 0), [['(1) Add a new column:'], ['(2) Update the new column']], [[' ALTER TABLE yourtable \nADD COLUMN `new_date` DATE NULL AFTER `views`; \n']], ['Changing the column Type in SQL'], 5, 0], [(10993546, 1), [['(2) Update the new column'], ['If your data looks like this:  mmmm dd, yyyy, hh:mm  (p.e.  May 17, 2012, 8:36 pm ) , you can update like this:']], [[' UPDATE yourtable SET new_date = old_date;\n']], ['Changing the column Type in SQL'], 5, 0], [(10993546, 2), [['If your data looks like this:  mmmm dd, yyyy, hh:mm  (p.e.  May 17, 2012, 8:36 pm ) , you can update like this:'], ['(3) Delete the old column']], [[' UPDATE yourtable\nSET new_date = STR_TO_DATE(old_date, "%M %e, %Y");\n']], ['Changing the column Type in SQL'], 5, 0], [(10993546, 3), [['(3) Delete the old column'], ['(4) Rename the new column']], [[' ALTER TABLE yourtable \nDROP COLUMN `old_date`; \n']], ['Changing the column Type in SQL'], 5, 0], [(10993546, 4), [['(4) Rename the new column'], ['Done!']], [[' ALTER TABLE yourtable \nCHANGE `new_date` `old_date` DATE NULL; \n']], ['Changing the column Type in SQL'], 5, 0], [(10999396, 0), [['You can either have the newly inserted ID being output to the SSMS console like this:'], ['Or if you need to capture the newly inserted  ID  inside T-SQL (e.g. for later further processing), you need to create a table variable:']], [[" INSERT INTO MyTable(Name, Address, PhoneNo)\nOUTPUT INSERTED.ID\nVALUES ('Yatrix', '1234 Address Stuff', '1112223333')\n"]], ["How do I use an INSERT statement's OUTPUT clause to get the identity value?"], 2, 1], [(10999396, 1), [['Or if you need to capture the newly inserted  ID  inside T-SQL (e.g. for later further processing), you need to create a table variable:'], ['This way, you can put multiple values into  @OutputTbl  and do further processing on those. You could also use a "regular" temporary table ( #temp ) or even a "real" persistent table as your "output target" here.']], [[" DECLARE @OutputTbl TABLE (ID INT)\n\nINSERT INTO MyTable(Name, Address, PhoneNo)\nOUTPUT INSERTED.ID INTO @OutputTbl(ID)\nVALUES ('Yatrix', '1234 Address Stuff', '1112223333')\n"]], ["How do I use an INSERT statement's OUTPUT clause to get the identity value?"], 2, 1], [(11019847, 0), [['I would call this a data dependency. Not all data dependencies can be modeled directly or conveniently with relational decomposition. This one can be handled pretty easily with a check constraint:'], ['Another solution might be to use two tables:']], [[' CREATE TABLE Students (\n  id SERIAL PRIMARY KEY, -- for example, something else in reality\n  grade INTEGER NOT NULL,\n  honors BOOLEAN,\n  CONSTRAINT ensure_honors_grade \n    CHECK((honors IS NULL AND grade < 7) OR \n          (honors IS NOT NULL AND grade >= 7))\n);\n']], ['Database design pattern where one attribute only applies if another attribute has certain value(s)'], 2, 1], [(11019847, 1), [['Another solution might be to use two tables:'], ["This alternative design is more explicit about the relationship between the grade and whether or not there is an honors flag, and leaves room for further differentiation of students in grades 7-8 (though the table name should be improved). If you only have the one property, the honors boolean, then this is probably overkill. As @BrankoDimitrijevic mentions, this doesn't enforce the existence of a row in  Honors  just because the grade is 7 or 8, and you're also paying for an index you wouldn't otherwise need. So there are tradeoffs; these are certainly not the  only  two designs possible; Branko also suggests using triggers."]], [[' CREATE TABLE Students (\n  id SERIAL PRIMARY KEY,\n  grade INTEGER NOT NULL,\n  CONSTRAINT id_grade_unique UNIQUE (id, grade) -- needed for FK constraint below\n);\n\nCREATE TABLE Honors (\n  student_id INTEGER NOT NULL,\n  grade INTEGER NOT NULL,\n  honors BOOLEAN NOT NULL,\n  CONSTRAINT student_fk FOREIGN KEY (student_id, grade) REFERENCES Students(id, grade),\n  CONSTRAINT valid_grade CHECK(grade >= 7)\n);\n']], ['Database design pattern where one attribute only applies if another attribute has certain value(s)'], 2, 1], [(11033340, 0), [['Easy:'], ['or if you just want one row:']], [[" SELECT \n   Val1,\n   Val2,\n   Val3,\n   (Val1 + Val2 + Val3) as 'Total'\nFROM Emp\n"]], ['How to find sum of multiple columns in a table in SQL Server 2005?'], 2, 1], [(11033340, 1), [['or if you just want one row:'], ['-10000']], [[" SELECT \n   SUM(Val1) as 'Val1',\n   SUM(Val2) as 'Val2',\n   SUM(Val3) as 'Val3',\n   (SUM(Val1) + SUM(Val2) + SUM(Val3)) as 'Total'\nFROM Emp\n"]], ['How to find sum of multiple columns in a table in SQL Server 2005?'], 2, 1], [(11097839, 0), [["The only way I can think to get this effect is, if you're on 11g, to add the cast value as a virtual column on the table, and (if it's still needed) create the view against that:"], ['-10000']], [[' ALTER TABLE "MyTable" ADD "MyBDColumn" AS\n    (CAST("MyColumn" AS BINARY_DOUBLE)) NOT NULL;\n\nCREATE OR REPLACE VIEW "MyView" AS\nSELECT\n    "MyBDColumn" AS "MyColumn"\nFROM "MyTable";\n\ndesc "MyView"\n\n Name                                      Null?    Type\n ----------------------------------------- -------- ----------------------------\n MyColumn                                  NOT NULL BINARY_DOUBLE\n']], ['How to create a not null column in a view'], 3, 1], [(11097839, 1), [['-10000'], ['And  desc "MyView"  still gives:']], [[' CREATE TABLE "MyTable" \n(\n  "MyColumn" NUMBER NOT NULL,\n  "MyBDColumn" BINARY_DOUBLE NOT NULL\n);\n\nCREATE TRIGGER "MyTrigger" before update or insert on "MyTable"\nFOR EACH ROW\nBEGIN\n    :new."MyBDColumn" := :new."MyColumn";\nEND;\n/\n\nCREATE VIEW "MyView" AS\nSELECT\n    "MyBDColumn" AS "MyColumn"\nFROM "MyTable";\n\nINSERT INTO "MyTable" ("MyColumn") values (2);\n\nSELECT * FROM "MyView";\n\n  MyColumn\n----------\n  2.0E+000\n']], ['How to create a not null column in a view'], 3, 1], [(11097839, 2), [['And  desc "MyView"  still gives:'], ['As Leigh mentioned (also on dba.se), if you did want to insert/update the view you could use an  instead of  trigger, with the VC or fake version.']], [['  Name                                      Null?    Type\n ----------------------------------------- -------- ----------------------------\n MyColumn                                  NOT NULL BINARY_DOUBLE\n']], ['How to create a not null column in a view'], 3, 0], [(11104819, 0), [['Assuming the edge table has been created with something like:'], ['How about something like (assuming no self-arcs and for every link from a->b there is also a link from b->a):']], [[' CREATE TABLE edges( node1 INTEGER, node2 INTEGER, weight REAL );\n']], ['sql query: create a table by merging rows from an exisiting table as follows:'], 3, 0], [(11114638, 0), [['You can use'], ['This works in two steps :']], [[' select substring_index(substring(mycol, instr(mycol, "=")+1), " ", 1)\n']], ['How to cut a part of a string in MySQL?'], 3, 1], [(11114638, 1), [['This works in two steps :'], ['and ']], [[' substring(mycol, instr(mycol, "=")+1)\n']], ['How to cut a part of a string in MySQL?'], 3, 0], [(11114638, 2), [['and '], ['get the first element of the virtual array you\'d got from a split by " ", and so returns the first token of xxx.']], [[' substring_index( xxx , " ", 1)\n']], ['How to cut a part of a string in MySQL?'], 3, 0], [(11116129, 0), [["If the datatype of  name  column is  varchar  then don't need to use  rtrim  function the right side spaces will be automatically trim. use only  LTRIM  only."], ['Run this see the how it trims the right spaces automatically.']], [[' update tablename\nset    name = ltrim(name)\nwhere  <condition>;\n']], ['Alter All Column Values using TRIM in SQL'], 2, 1], [(11117622, 0), [['-10000'], ['The pure sql (not the double negation  NOT EXISTS , NOT IN() :']], [[" DROP SCHEMA tmp CASCADE;\nCREATE SCHEMA tmp;\n\nSET search_path='tmp';\n\n\nCREATE TABLE instrument\n        ( id INTEGER NOT NULL PRIMARY KEY\n        , zname varchar\n        );\nINSERT INTO instrument(id, zname) VALUES\n(1, 'instrument_1'), (2, 'instrument_2')\n, (3, 'instrument_3'), (4, 'instrument_4');\n\nCREATE TABLE piece\n        ( id INTEGER NOT NULL PRIMARY KEY\n        , zname varchar\n        );\nINSERT INTO piece(id, zname) VALUES\n(1, 'piece_1'), (2, 'piece_2'), (3, 'piece_3'), (4, 'piece_4');\n\nCREATE TABLE has_part\n        ( piece_id INTEGER NOT NULL\n        , instrument_id INTEGER NOT NULL\n        , PRIMARY KEY (piece_id,instrument_id)\n        );\n\nINSERT INTO has_part(piece_id,instrument_id) VALUES\n(1,1), (1,2), (1,3)\n, (2,1), (2,2), (2,3), (2,4)\n, (3,1), (3,3), (3,4)\n, (4,2)\n        ;\n"]], ['Select all subsets in a many-to-many relation'], 2, 1], [(11117622, 1), [['The pure sql (not the double negation  NOT EXISTS , NOT IN() :'], ['-10000']], [[' SELECT zname\nFROM piece pp\nWHERE NOT EXISTS (\n        SELECT * FROM has_part nx\n        WHERE nx.piece_id = pp.id\n        AND nx.instrument_id NOT IN (1,2,3)\n        )\n        ;\n']], ['Select all subsets in a many-to-many relation'], 2, 1], [(11119197, 0), [["Sample data (if I've got the answer wrong, maybe you can adopt this, add it to your question, and add more samples and expected outputs):"], ['And the query:']], [[' create table #Sessions (\n    --We\'ll treat this as a semi-open interval - the session was "live" at SessionStart, and "dead" at SessionEnd\n    SessionStart datetime2 not null,\n    SessionEnd datetime2 null\n)\ninsert into #Sessions (SessionStart,SessionEnd) values\n(\'20120101\',\'20120105\'),\n(\'20120103\',\'20120109\'),\n(\'20120107\',\'20120108\')\n']], ['sql server table peak time'], 5, 0], [(11119197, 2), [['Which, with  my  sample data gives:'], ['-10000']], [[' SessionStart           Cnt         SessionEnd             rnk\n---------------------- ----------- ---------------------- --------------------\n2012-01-03 00:00:00.00 2           2012-01-05 00:00:00.00 1\n2012-01-07 00:00:00.00 2           2012-01-08 00:00:00.00 1\n']], ['sql server table peak time'], 5, 0], [(11119197, 4), [["This time, I'm outputting  all  of the time periods, together with the number of simultaneous users at the time (order from highest to lowest):"], ['-10000']], [[' StartTime              EndTime                Cnt\n---------------------- ---------------------- -----------\n2012-01-03 00:00:00.00 2012-01-05 00:00:00.00 2\n2012-01-07 00:00:00.00 2012-01-08 00:00:00.00 2\n2012-01-01 00:00:00.00 2012-01-03 00:00:00.00 1\n2012-01-05 00:00:00.00 2012-01-07 00:00:00.00 1\n2012-01-08 00:00:00.00 2012-01-09 00:00:00.00 1\n']], ['sql server table peak time'], 5, 0], [(11135522, 0), [['Assuming that the latest exchange rate is the one with the highest id you can use:'], ['But I strongly suggest another pattern I love. I explained it in  another answer  this morning: ']], [[' SELECT *\nFROM rates r\nWHERE r.id IN (\n    SELECT MAX(r1.id)\n    FROM rates r1\n    GROUP BY r1.currency_code\n) T;\n']], ['The best way to select the latest rates for several currency codes from the DB'], 2, 1], [(11135522, 1), [['But I strongly suggest another pattern I love. I explained it in  another answer  this morning: '], ['-10000']], [[' SELECT\n  c.*,\n  r1.*\nFROM currency c\nINNER JOIN rates r1 ON c.code = r1.currency_code\nLEFT JOIN rates r2 ON r1.currency_code = r2.currency_code AND r2.id > r1.id\nWHERE r2.id IS NULL;\n']], ['The best way to select the latest rates for several currency codes from the DB'], 2, 1], [(11168749, 1), [['EDIT: As provided by the op in the comments, the current year needs to be taken rather than hardcoding it. The updated query is'], ['-10000']], [[" SELECT L || '/01/' || TO_CHAR (SYSDATE, 'YYYY') DATESS FROM \n(SELECT LEVEL L FROM DUAL CONNECT BY LEVEL < 13)\n"]], ['How To Find First Date of All MOnths In A Year'], 2, 1], [(11215684, 0), [['To find rows that  contain   x  you can use  LIKE :'], ['To find rows that  do not contain   x  you can use  NOT LIKE :']], [[" SELECT * FROM yourtable WHERE col LIKE '%x%'\n"]], ['Find all but allowed characters in column'], 4, 0], [(11215684, 1), [['To find rows that  do not contain   x  you can use  NOT LIKE :'], ["So your query should use  NOT LIKE  because you want rows that  don't contain  something:"]], [[" SELECT * FROM yourtable WHERE col NOT LIKE '%x%'\n"]], ['Find all but allowed characters in column'], 4, 1], [(11215684, 2), [["So your query should use  NOT LIKE  because you want rows that  don't contain  something:"], ['-10000']], [[" SELECT NID FROM NOTES WHERE NOTE NOT LIKE '%[0-9a-zA-Z#.;:/^\\(\\)\\@\\ \\  \\\\\\-]%'\n"]], ['Find all but allowed characters in column'], 4, 1], [(11215684, 3), [['-10000'], ['-10000']], [[' 0-9 a-z A-z . : ; ^ & @ \\ / ( ) #\n']], ['Find all but allowed characters in column'], 4, 0], [(11227924, 0), [['Static Version, is where you hard-code the values to the transformed:'], ['Dynamic Version, the values are generated at run-time:']], [[" ;with hd (id, name, parentid, category)\nas\n(\n  select id, name, parentid, 1 as category\n  from yourtable\n  where parentid is null\n  union all\n  select t1.id, t1.name, t1.parentid, hd.category +1\n  from yourtable t1\n  inner join hd\n    on t1.parentid = hd.id\n),\nunpiv as\n(\n  select value, 'cat_'+cast(category as varchar(5))+'_'+ col col_name\n  from\n  (\n    select cast(id as varchar(17)) id, name, parentid, category\n    from hd\n  ) src\n  unpivot\n  (\n    value for col in (id, name)\n  ) un\n)\nselect [cat_1_id], [cat_1_name],\n                   [cat_2_id], [cat_2_name],\n                   [cat_3_id], [cat_3_name]\nfrom unpiv\npivot\n(\n  max(value)\n  for col_name in ([cat_1_id], [cat_1_name],\n                   [cat_2_id], [cat_2_name],\n                   [cat_3_id], [cat_3_name])\n) piv\n"]], ['PIVOT on hierarchical data'], 3, 1], [(11227924, 1), [['Dynamic Version, the values are generated at run-time:'], ['The Results are the same for both:']], [[" ;with hd (id, name, parentid, category)\nas\n(\n  select id, name, parentid, 1 as category\n  from yourtable\n  where parentid is null\n  union all\n  select t1.id, t1.name, t1.parentid, hd.category +1\n  from yourtable t1\n  inner join hd\n    on t1.parentid = hd.id\n)\nselect category categoryNumber\ninto #temp\nfrom hd\n\nDECLARE @cols AS NVARCHAR(MAX),\n    @query  AS NVARCHAR(MAX)\n\nselect @cols = STUFF((SELECT distinct ',' + quotename('cat_'+cast(CATEGORYNUMBER as varchar(10))+'_'+col) \n                  from #temp\n                  cross apply (select 'id' col\n                               union all \n                               select 'name' col) src\n            FOR XML PATH(''), TYPE\n            ).value('.', 'NVARCHAR(MAX)') \n        ,1,1,'')\n\nset @query = ';with hd (id, name, parentid, category)\n              as\n              (\n                select id, name, parentid, 1 as category\n                from yourtable\n                where parentid is null\n                union all\n                select t1.id, t1.name, t1.parentid, hd.category +1\n                from yourtable t1\n                inner join hd\n                  on t1.parentid = hd.id\n              ),\n              unpiv as\n              (\n                select value, ''cat_''+cast(category as varchar(5))+''_''+ col col_name\n                from\n                (\n                  select cast(id as varchar(17)) id, name, parentid, category                 \n                  from hd\n                ) src\n                unpivot\n                (\n                  value for col in (id, name)\n                ) un\n              )\n              select '+@cols+'\n              from unpiv\n              pivot\n              (\n                max(value)\n                for col_name in ('+@cols+')\n               ) piv'\n\nexecute(@query)\n\ndrop table #temp\n"]], ['PIVOT on hierarchical data'], 3, 1], [(11227924, 2), [['The Results are the same for both:'], ['-10000']], [[' | CAT_1_ID | CAT_1_NAME | CAT_2_ID |        CAT_2_NAME | CAT_3_ID | CAT_3_NAME |\n--------------------------------------------------------------------------------\n|        1 | Decorating |        2 | Paint and Brushes |        5 |    Rollers |\n']], ['PIVOT on hierarchical data'], 3, 0], [(11260900, 0), [['If you need only emailAddress it is quite simple:'], ['If you want to choose both distinct emailAddress and ANY customerName related to it then you must somehow tell SQL how to choose the customerName. The easiest way is to select i.e. MIN(customerName), then all other (usually those that are later in alphabet but it actually depends on collation) are discarded. Query would be:']], [[' select distinct emailAddress from <YourTableNameHere>\n']], ['Making a query that only shows unique records'], 2, 1], [(11260900, 1), [['If you want to choose both distinct emailAddress and ANY customerName related to it then you must somehow tell SQL how to choose the customerName. The easiest way is to select i.e. MIN(customerName), then all other (usually those that are later in alphabet but it actually depends on collation) are discarded. Query would be:'], ['-10000']], [[' select emailAddress, min(customerName) as pickedCustomerName\nfrom <YourTableNameHere>\ngroup by emailAddress\n']], ['Making a query that only shows unique records'], 2, 1], [(11282433, 0), [['One possibility is NOT IN. There is no such thing as a minus query in MS Access.'], ['For a purely sql solution, you need, say:']], [[' select h.* from hello h\nWHERE uniqueid NOT IN\n(select uniqueid from hello1 h1)\n']], ['Minus Query in MsAccess'], 2, 1], [(11282433, 1), [['For a purely sql solution, you need, say:'], ['However, it is easier using VBA.']], [[' SELECT t.* FROM Table t\nLEFT JOIN NewTable n\nON t.ID = n.ID\nWHERE t.Field1 & "" <> n.Field1 & ""\n   OR t.Field2 & "" <> n.Field2 & ""\n']], ['Minus Query in MsAccess'], 2, 1], [(11292524, 2), [['Ah I take that back, it is just a problem with NULLs - other posts suggest ISNULL or COALESCE to eliminate the nulls, you could use a placeholder value like -1 which could work e.g.'], ['You need to ensure this will work though as if you have a value in column2/3 then column_1 will no longer = -1. It might be worth doing a case to see if they are all NULL in which case replacing the 1st null with -1']], [[' SELECT bankid, AVG(CASE WHEN value = -1 THEN NULL ELSE value END) AS Average \nFROM ( \n    SELECT bankid,  \n    isnull(AVG(column_1), -1) as column_1 ,\n    AVG(Column_2) as column_2 ,\n    Avg(column_3) as column_3 \n    FROM data     \n    group by bankid\n) as pvt \nUNPIVOT (Value FOR o in (column_1, column_2, column_3)) as u\nGROUP BY bankid \n']], ['How can get null column after UNPIVOT?'], 3, 1], [(11307344, 0), [["There's a transaction section in the output of:"], ["Which looks like (that's from my local MySQL currently not running any queries):"]], [[' SHOW ENGINE INNODB STATUS\\G\n']], ['How to check verify that SQL query was ran in transaction?'], 2, 1], [(11307344, 1), [["Which looks like (that's from my local MySQL currently not running any queries):"], ["I don't know if you can actively monitor this information, so that you can see it exactly in the moment of you 3 insert operations. You can probably use that last bullet of yours (using slow queries) here..."]], [[" TRANSACTIONS\n------------\nTrx id counter 900\nPurge done for trx's n:o < 0 undo n:o < 0\nHistory list length 0\nLIST OF TRANSACTIONS FOR EACH SESSION:\n---TRANSACTION 0, not started\nMySQL thread id 47, OS thread handle 0x7fc8b85d3700, query id 120 localhost root\nSHOW ENGINE INNODB STATUS\n"]], ['How to check verify that SQL query was ran in transaction?'], 2, 0], [(11308438, 0), [['http://sqlfiddle.com/#!2/a4ed8/1'], ['http://sqlfiddle.com/#!2/f4f9a/1']], [[" CREATE TABLE IF NOT EXISTS person (\n   id  INT NOT NULL AUTO_INCREMENT,\n   PRIMARY KEY ( id )\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 AUTO_INCREMENT=1;\n\nCREATE TRIGGER insert_kangaroo_id BEFORE INSERT ON person FOR EACH ROW BEGIN\n  DECLARE newid INT;\n\n  SET newid = (SELECT AUTO_INCREMENT\n               FROM information_schema.TABLES\n               WHERE TABLE_SCHEMA = DATABASE()\n               AND TABLE_NAME = 'person'\n              );\n\n  IF NEW.id AND NEW.id >= newid THEN\n    SET newid = NEW.id;\n  END IF;\n\n  SET NEW.id = 5 * CEILING( newid / 5 );\nEND;\n"]], ['MYSQL auto_increment_increment'], 2, 1], [(11308438, 1), [['http://sqlfiddle.com/#!2/f4f9a/1'], ['-10000']], [[' CREATE TABLE IF NOT EXISTS person (\n   secretid  INT NOT NULL AUTO_INCREMENT,\n   id        INT NOT NULL,\n   PRIMARY KEY ( secretid )\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 AUTO_INCREMENT=1;\n\nCREATE TRIGGER update_kangaroo_id BEFORE UPDATE ON person FOR EACH ROW BEGIN\n  SET NEW.id = NEW.secretid * 5;\nEND;\n\nCREATE TRIGGER insert_kangaroo_id BEFORE INSERT ON person FOR EACH ROW BEGIN\n  SET NEW.id = NEW.secretid * 5; -- NEW.secretid is empty = unusuable!\nEND;\n']], ['MYSQL auto_increment_increment'], 2, 0], [(11329936, 0), [['Your subquery has no where clause and thus counts all records, but you can do it without subquery'], ['You might want to get results for parents having no children as well. In that case you can use an outer join']], [[' SELECT\n    "Criterion = 1" AS CritDesc,\n    SUM(IIf(Criterion = 1, 1, 0)) AS NumCrit,\n    COUNT(*) AS TotalNum,\n    SUM(IIf(Criterion = 1, 1, 0)) / COUNT(*) AS Percentage,\n    ParentNumber AS Parent\nFROM\n    tblChild\nGROUP BY\n    ParentNumber;\n']], ['Calculate Percentages In Query - Access SQL'], 2, 1], [(11329936, 1), [['You might want to get results for parents having no children as well. In that case you can use an outer join'], ['Note that I get the total number of children with  Count(C.Number)  as  Count(*)  would count records with no children as well and yield  1  in that case. In the percentage calculation, however, I divide by  Count(*)  in order to avoid a division by zero. The result will still be correct in that case, since the sum of records with  Criterion = 1  will be zero.']], [[' SELECT\n    "Criterion = 1" AS CritDesc,\n    SUM(IIf(C.Criterion = 1, 1, 0)) AS NumCrit,\n    COUNT(C.Number) AS TotalNumOfChildren,\n    SUM(IIf(C.Criterion = 1, 1, 0)) / COUNT(*) AS Percentage,\n    P.Number AS Parent\nFROM\n    tblChild AS C\n    LEFT JOIN tblParent AS P\n        ON C.ParentNumber = P.Number  \nGROUP BY\n    P.Number;\n']], ['Calculate Percentages In Query - Access SQL'], 2, 1], [(11350686, 0), [['-10000'], ['The  DISTINCT  should not be necessary, if you have defined multi-column primary or unique keys on the columns.']], [['Linked by <code>(tag_id, mark_id)</code> SELECT DISTINCT i.*\nFROM   tags_users  tu  \nJOIN   marks_users mu USING (user_id)\nJOIN   items       i  USING (tag_id, mark_id)\nWHERE  tu.user_id = 5;\n']], ['Combine results of joins on two tables'], 5, 1], [(11350686, 1), [['The  DISTINCT  should not be necessary, if you have defined multi-column primary or unique keys on the columns.'], ['Assumes that entries in  items  itself are UNIQUE on  (tag_id, mark_id) .']], [[' SELECT i.*\nFROM   items i  \nWHERE  EXISTS (\n    SELECT 1\n    FROM   tags_users  tu\n    WHERE  tu.tag_id = i.tag_id\n    AND    tu.user_id = 5\n    )\nOR     EXISTS (\n    SELECT 1\n    FROM   marks_users mu \n    WHERE  mu.mark_id = i.mark_id\n    AND    mu.user_id = 5\n    );\n']], ['Combine results of joins on two tables'], 5, 1], [(11350686, 2), [['Assumes that entries in  items  itself are UNIQUE on  (tag_id, mark_id) .'], ['Total runtime:  38229.860 ms']], [["Gordon's query SELECT DISTINCT i.*\nFROM   items i\nLEFT   JOIN tags_users tu on i.tag_id = tu.tag_id\nLEFT   JOIN marks_users mu on i.mark_id = mu.mark_id\nWHERE  5 IN (tu.user_id, mu.user_id);\n"]], ['Combine results of joins on two tables'], 5, 1], [(11350686, 3), [['Total runtime:  38229.860 ms'], ['Total runtime:  110.450 ms']], [[' SELECT DISTINCT i.*\nFROM   items i\nLEFT   JOIN tags_users tu on i.tag_id = tu.tag_id AND tu.user_id = 5\nLEFT   JOIN marks_users mu on i.mark_id = mu.mark_id AND mu.user_id = 5\nWHERE  tu.user_id = 5 OR mu.user_id = 5;\n']], ['Combine results of joins on two tables'], 5, 1], [(11350686, 4), [['Total runtime:  110.450 ms'], ['Total runtime:  178.901 ms']], [[' SELECT i.*\nFROM   items i \nJOIN   tags_users  tu ON i.tag_id = tu.tag_id AND tu.user_id = 5\nUNION\nSELECT i.*\nFROM   items i \nJOIN   marks_users mu ON i.mark_id = mu.mark_id AND mu.user_id = 5;\n']], ['Combine results of joins on two tables'], 5, 1], [(11363669, 0), [['You can do it in one whooping statement: '], ['I used a first subquery to list all intervals:']], [[" SQL> WITH timeline AS\n  2          (SELECT mydate startdate,\n  3                  lead(mydate) OVER (ORDER BY mydate) - 1 enddate\n  4             FROM (SELECT startdate mydate FROM interval_test\n  5                   UNION\n  6                   SELECT enddate FROM interval_test)\n  7            WHERE mydate IS NOT NULL)\n  8  SELECT startdate,\n  9         enddate,\n 10         max(substr(sys_connect_by_path(item, ','), 2)) items\n 11    FROM (SELECT t.startdate,\n 12                 t.enddate,\n 13                 item,\n 14                 row_number() OVER (PARTITION BY t.startdate, t.enddate\n 15                                    ORDER BY i.item) rn\n 16            FROM    timeline t\n 17                 JOIN\n 18                    interval_test i\n 19                 ON nvl(i.enddate, DATE '9999-12-31') - 1 >= t.startdate\n 20                AND i.startdate <= nvl(t.enddate, DATE '9999-12-31'))\n 21  START WITH rn = 1\n 22  CONNECT BY rn = PRIOR rn + 1\n 23         AND startdate = PRIOR startdate\n 24  GROUP BY startdate, enddate\n 25  ORDER BY startdate;\n\nSTARTDATE  ENDDATE    ITEMS\n---------- ---------- --------------------\n2012-01-01 2012-01-31 AAA\n2012-02-01 2012-02-29 AAA,BBB\n2012-03-01            AAA\n"]], ['Oracle timeline report from overlapping intervals'], 3, 1], [(11363669, 1), [['I used a first subquery to list all intervals:'], ['joined to the following query that lists all items on one row given two dates:']], [[' SQL> SELECT mydate startdate,\n  2                  lead(mydate) OVER (ORDER BY mydate) - 1 enddate\n  3             FROM (SELECT startdate mydate FROM interval_test\n  4                   UNION\n  5                   SELECT enddate FROM interval_test)\n  6            WHERE mydate IS NOT NULL;\n\nSTARTDATE  ENDDATE\n---------- ----------\n2012-01-01 2012-01-31\n2012-02-01 2012-02-29\n2012-03-01\n']], ['Oracle timeline report from overlapping intervals'], 3, 0], [(11363669, 2), [['joined to the following query that lists all items on one row given two dates:'], ['-10000']], [[" SELECT max(substr(sys_connect_by_path(item, ','), 2)) items\n  FROM (SELECT item, row_number() OVER (ORDER BY item) rn\n          FROM interval_test\n         WHERE nvl(enddate, DATE '9999-12-31') >= :startdate\n           AND startdate <= :enddate)\nCONNECT BY rn = PRIOR rn + 1\nSTART WITH rn = 1;\n"]], ['Oracle timeline report from overlapping intervals'], 3, 0], [(11396151, 1), [['Once registered, you should be able to call the function in your queries:'], ['-10000']], [[' def a = SaturnStvterm.findAll("from SaturnStvterm as s where id > TT_STUDENT.STU_GENERAL.F_Get_Current_term()")\n']], ['From within a grails HQL, how would I use a (non-aggregate) Oracle function?'], 2, 0], [(11404664, 0), [["The problem is that you're not correlating your subquery with your outer query. It helps to use different aliases for all tables involved, and the join to  Members  inside the subquery seems unnecessary:"], ['Result:']], [[" create table Members (ID int not null,Attend_Freq int not null,Last_Attend_Date datetime not null)\ninsert into Members (ID,Attend_Freq,Last_Attend_Date) values\n(123,4,'19000101')\n\ncreate table Attendance (ID int not null,Member_ID int not null,Last_Attend_Date datetime not null)\ninsert into Attendance (ID,Member_ID,Last_Attend_Date) values\n(987,123,'20120605'),\n(888,123,'20120604'),\n(567,123,'20120603'),\n(456,234,'20120630'),\n(1909,292,'20120705')\n\nupdate M\nset\n    Last_Attend_Date =\n        (select MAX(Last_Attend_Date)\n            from Attendance A2\n        where A2.Member_ID = M.ID) --M is a reference to the outer table here\nfrom\n    Members M\n        inner join\n    Attendance A\n        on\n            M.ID = A.Member_ID\nwhere\n    m.Attend_Freq < 5 and\n    A.Last_Attend_Date < DATEADD(day,-14,CURRENT_TIMESTAMP)\n\nselect * from Members\n"]], ['SQL Update most recent in table instead of most recent on selected record'], 2, 1], [(11404664, 1), [['Result:'], ['-10000']], [[' ID          Attend_Freq Last_Attend_Date\n----------- ----------- ----------------\n123         4           2012-06-05\n']], ['SQL Update most recent in table instead of most recent on selected record'], 2, 0], [(11419308, 0), [['The format is:'], ["The values you'll need are:"]], [[' CreateParameter( name, type, direction, size, value )\n']], ['how to pass javascript array to oracle store procedure by ado parameter object'], 3, 0], [(11419308, 1), [["The values you'll need are:"], ["And you'll call it like:"]], [[' adVarChar = 200\nAdArray = 0x2000\nadParamInput = 1\n']], ['how to pass javascript array to oracle store procedure by ado parameter object'], 3, 0], [(11419308, 2), [["And you'll call it like:"], ['-10000']], [[" var param = cmd.CreateParameter( 'par', adVarChar + AdArray, adParamInput, 255, userArray )\n"]], ['how to pass javascript array to oracle store procedure by ado parameter object'], 3, 0], [(11419793, 0), [['You have to use  EXECUTE  for dynamic SQL. Also, a  DO  statement cannot take parameters. Create a plpgsql function:'], ['Call:']], [[" CREATE OR REPLACE FUNCTION f_revoke_all_from_role(_role text)\n  RETURNS void AS\n$BODY$\nBEGIN\n\nIF EXISTS (SELECT 1 FROM pg_roles WHERE rolname = _role) THEN\n    EXECUTE 'REVOKE ALL PRIVILEGES ON TABLE x FROM ' || quote_ident(_role);\nEND IF;\n\nEND;\n$BODY$ LANGUAGE plpgsql;\n"]], ['Detect role in Postgresql dynamically'], 2, 1], [(11419793, 1), [['Call:'], ['-10000']], [[" SELECT f_revoke_all_from_role('superman');\n"]], ['Detect role in Postgresql dynamically'], 2, 0], [(11426911, 0), [["I think that you might use worksupdates as 'ruling table' and attach the rest there:"], ['Or pivoting the tables around and having works rule, maybe better:']], [[' SELECT works.id, title, version, date, pages, uploaded, uri\n    FROM workupdates\n    JOIN info ON info.id=workupdates.info\n    JOIN works ON workupdates.work = works.id\n    WHERE workupdates.date =\n        (SELECT MAX(date) FROM workupdates WHERE work = works.id)\n;\n']], ['Convert sub-subquery with a order+limit 1 to left join'], 2, 1], [(11426911, 1), [['Or pivoting the tables around and having works rule, maybe better:'], ["It ought to be possible to save an iteration when joining worksupdates and works, but it's not coming to me at the moment (and it might be I'm dreaming things up) :-("]], [[' SELECT works.id, title, version, date, pages, uploaded, uri\n    FROM works\n    JOIN workupdates ON (workupdates.work = works.id\n          AND workupdates.date =\n              (SELECT MAX(date) FROM workupdates WHERE work = works.id))\n    JOIN info ON info.id=workupdates.info\n;\n']], ['Convert sub-subquery with a order+limit 1 to left join'], 2, 1], [(11436797, 0), [['You can, pretty much as Michael and Gordon did, just tack an empty row on with  union all , but you need to have it before the  order by :'], ["But this relies on  null  being sorted after any real values, which may not always be the case (not sure, but might be affected by NLS parameters), and it isn't known if the real  eventkey  can ever be  null  anyway. So it's probably safer to introduce a dummy column in both parts of the query and use that for the ordering, but exclude it from the results by nesting the query:"]], [[" ...\nand to_date(to_char(t.enddatetime, 'DD-MON-YYYY')) <=\n    to_date('?DATE2::?','MM/DD/YYYY')\nunion all\nselect null, null, null, null, null, null, null, null\nfrom dual\norder by eventid, starttime, actionsequence;\n"]], ['Insert blank row to result after ORDER BY'], 4, 1], [(11436797, 2), [["The date handling is odd though, particularly the  to_date(to_char(...))  parts. It looks like you're just trying to lose the time portion, in which case you can use  trunk  instead:"], ["But applying any function to the date column prevents any index on it being used, so it's better to leave that alone and get the variable part in the right state for comparison:"]], [[" where trunc(t.startdatetime) >= to_date('?DATE1::?','MM/DD/YYYY')\nand trunc(t.enddatetime) <= to_date('?DATE2::?','MM/DD/YYYY')\n"]], ['Insert blank row to result after ORDER BY'], 4, 0], [(11436797, 3), [["But applying any function to the date column prevents any index on it being used, so it's better to leave that alone and get the variable part in the right state for comparison:"], ['The  + 1  adds a day, so id  DATE2  was  07/12/2012 , the filter is  < 2012-07-13 00:00:00 , which is the same as  <= 2012-07-12 23:59:59 .']], [[" where t.startdatetime >= to_date('?DATE1::?','MM/DD/YYYY')\nand t.enddatetime < to_date('?DATE2::?','MM/DD/YYYY') + 1\n"]], ['Insert blank row to result after ORDER BY'], 4, 0], [(11441696, 1), [['The problem that you have is that the populations in the different months may be different, so the joins will lose rows.  A good way to handle this is with a driving table:'], ['You can do all this in one SQL statement.  There are repetitive parts (such as the column names in the select).  Consider using Excel to generate these.']], [[' select . . .\nfrom (select companyname, employee, id from tjan union\n      select companyname, employee, id from tfeb union\n      . . .\n     ) driving left outer join\n     tjan\n     on tjan.companyname = driving.companyname and\n        tjan.employee = driving.employee and\n        tjan.id = driving.id left outer join\n     tfeb\n     on tfeb.companyname = driving.companyname and\n        tfeb.employee = driving.employee and\n        tfeb.id = driving.id left outer join\n    . . .\n']], ['Merging matching data side by side from different tables'], 2, 1], [(11445551, 0), [["I'm not sure what the performance of this will be like, but it's a more set-based approach than your current one:"], ['Result:']], [[" declare @T table (CategoryID int not null,Time datetime2 not null,IsSampled bit not null,Value decimal(10,5) not null)\ninsert into @T (CategoryID,Time,IsSampled,Value) values\n(1,'2012-07-01T00:00:00.000',0,65.36347),\n(1,'2012-07-01T00:00:11.000',0,80.16729),\n(1,'2012-07-01T00:00:14.000',0,29.19716),\n(1,'2012-07-01T00:00:25.000',0,7.05847),\n(1,'2012-07-01T00:00:36.000',0,98.08257),\n(1,'2012-07-01T00:00:57.000',0,75.35524),\n(1,'2012-07-01T00:00:59.000',0,35.35524)\n\n;with BinnedValues as (\n    select CategoryID,Time,IsSampled,Value,DATEADD(minute,DATEDIFF(minute,0,Time),0) as TimeBin\n    from @T\n), MinMax as (\n    select CategoryID,Time,IsSampled,Value,TimeBin,\n        ROW_NUMBER() OVER (PARTITION BY CategoryID, TimeBin ORDER BY Value) as MinPos,\n        ROW_NUMBER() OVER (PARTITION BY CategoryID, TimeBin ORDER BY Value desc) as MaxPos,\n        ROW_NUMBER() OVER (PARTITION BY CategoryID, TimeBin ORDER BY Time) as Earliest\n    from\n        BinnedValues\n)\nupdate MinMax set IsSampled = 1 where MinPos=1 or MaxPos=1 or Earliest=1\n\nselect * from @T\n"]], ['How can I update extreme columns within range fast?'], 2, 1], [(11445551, 1), [['Result:'], ['It could possibly be sped up if the  TimeBin  column could be added as a computed column to the table and added to appropriate indexes.']], [[' CategoryID  Time                   IsSampled Value\n----------- ---------------------- --------- ---------------------------------------\n1           2012-07-01 00:00:00.00 1         65.36347\n1           2012-07-01 00:00:11.00 0         80.16729\n1           2012-07-01 00:00:14.00 0         29.19716\n1           2012-07-01 00:00:25.00 1         7.05847\n1           2012-07-01 00:00:36.00 1         98.08257\n1           2012-07-01 00:00:57.00 0         75.35524\n1           2012-07-01 00:00:59.00 0         35.35524\n']], ['How can I update extreme columns within range fast?'], 2, 0], [(11456664, 0), [["Haven't tried it, but I think this should work"], ['You can think of that as ']], [['  select NoOfChanges, count (*) from\n ( \n     select suba.id, count(*) as NoOfChanges from \n      ( select id, service_type from table_name\n       group by 1,2) as  suba\n       group by 1 \n       having count (*) > 1 \n    )\n subtableb\n group by NoOfChanges \n']], ['Counting in sql and subas'], 2, 1], [(11456664, 1), [['You can think of that as '], ["but subtableb isn't a real table, but the results from your previous query"]], [[' select NoOfChanges, count (*) from subtableb\ngroup by NoOfChanges  \n']], ['Counting in sql and subas'], 2, 1], [(11463090, 0), [['You can use this solution:'], ["You can use  GROUP_CONCAT()  to get a CSV of the  imageid 's for each  postid :"]], [[' SELECT b.filename\nFROM posts a\nINNER JOIN images b ON FIND_IN_SET(b.imageid, a.gallery) > 0\nWHERE a.postid = 3\n']], ['Single MySQL field with comma separated values'], 2, 1], [(11468551, 0), [['Below is the script to the solution i came up with:'], ['The above will give the folowing results:']], [[" DECLARE @start_date datetime = CONVERT(DATETIME,'2012-02-06 23:59:01.000',20);\nDECLARE @end_date datetime = CONVERT(DATETIME,'2012-12-08 23:59:17.000',20);\nDECLARE @org datetime  ;\nDECLARE @end datetime  ;\nDECLARE @datetable TABLE (h_start datetime, h_end datetime,h_sesc int);\n\nWHILE (dateadd(second, -1, dateadd(hour, datediff(hour, 0, @start_date)+1, 0))) < @end_date\nBEGIN\nSET @org = null;\nSET @org = @start_date;\nSET @end = (dateadd(second, -1, dateadd(hour, datediff(hour, 0, @org)+1, 0)));\nINSERT INTO @datetable (h_start, h_end,h_sesc)\nVALUES(dateadd(second, 0,@org), @end,DATEDIFF(second, @org,@end));\n\nSET @start_date = dateadd(second, 1,@end);\n\nEND;\n\n\nINSERT INTO @datetable (h_start, h_end,h_sesc)\nVALUES(dateadd(second, 0,@start_date), @end_date,DATEDIFF(second, dateadd(second, 0,@start_date),@end_date));\n\nSELECT * FROM @datetable;\n"]], ['Getting hours interval between date range'], 3, 1], [(11468551, 1), [['The above will give the folowing results:'], ['..\n..']], [[' h_start                 h_end                   h_sesc\n2012-02-06 23:59:01.000 2012-02-06 23:59:59.000 58\n2012-02-07 00:00:00.000 2012-02-07 00:59:59.000 3599\n2012-02-07 01:00:00.000 2012-02-07 01:59:59.000 3599\n2012-02-07 02:00:00.000 2012-02-07 02:59:59.000 3599\n2012-02-07 03:00:00.000 2012-02-07 03:59:59.000 3599\n2012-02-07 04:00:00.000 2012-02-07 04:59:59.000 3599\n2012-02-07 05:00:00.000 2012-02-07 05:59:59.000 3599\n']], ['Getting hours interval between date range'], 3, 0], [(11468551, 2), [['..\n..'], ['Hope someone will find it useful.']], [[' 2012-12-08 18:00:00.000 2012-12-08 18:59:59.000 3599\n2012-12-08 19:00:00.000 2012-12-08 19:59:59.000 3599\n2012-12-08 20:00:00.000 2012-12-08 20:59:59.000 3599\n2012-12-08 21:00:00.000 2012-12-08 21:59:59.000 3599\n2012-12-08 22:00:00.000 2012-12-08 22:59:59.000 3599\n2012-12-08 23:00:00.000 2012-12-08 23:59:17.000 3557\n']], ['Getting hours interval between date range'], 3, 0], [(11480527, 0), [['If you are interested in returning only one row, the easiest way to do this would be:'], ['NOTE: I specify the bare  theDate  column in the conditions in the WHERE clause, rather than wrapping that in any function... by specifying the bare column and a bounded range, we enable MySQL to make use of an index range scan operation. There are other possible ways to include this condition in the WHERE clause, for example...']], [[" SELECT t.*\n  FROM table_name t\n WHERE t.name = '$username'\n   AND t.theDate >= CAST(DATE_FORMAT(NOW(),'%Y-%m-01') AS DATE)\n   AND t.theDate < DATE_ADD(DATE_FORMAT(NOW(),'%Y-%m-01'), INTERVAL 1 MONTH)\n ORDER BY s.name DESC, s.theDate DESC\n LIMIT 1\n"]], ['MySQL - Select the least day of the current month/year, not necessarily the first day of the month'], 4, 1], [(11480527, 1), [['NOTE: I specify the bare  theDate  column in the conditions in the WHERE clause, rather than wrapping that in any function... by specifying the bare column and a bounded range, we enable MySQL to make use of an index range scan operation. There are other possible ways to include this condition in the WHERE clause, for example...'], ['If you are intending to get all the rows for the "least" date in a month for a given user (your question doesn\'t seem to indicate that you need only one row), here\'s one way get that result:']], [[" DATE_FORMAT(t.theDate,'%Y-%m') = DATE_FORMAT(NOW(),'%Y-%m')\n"]], ['MySQL - Select the least day of the current month/year, not necessarily the first day of the month'], 4, 0], [(11480527, 2), [['If you are intending to get all the rows for the "least" date in a month for a given user (your question doesn\'t seem to indicate that you need only one row), here\'s one way get that result:'], ['NOTE: We\'re assuming here that \'theDate\' is datatype DATE (with no time component).  If it\'s a DATETIME or a TIMESTAMP, there\'s a potential for a time component, and that query may not return all rows for a given "date" value, if the time components are different for the rows with the same "date". (e.g. \'2012-07-13 17:30\' and \'2012-07-13 19:55\' are different datetime values.) If we want to return both of those rows (because both are a date of "July 13"), we need to do a range scan instead of an equality test.']], [[" SELECT t.* \n  FROM table_name t\n  JOIN ( SELECT s.name\n              , s.theDate\n           FROM table_name s \n          WHERE s.name = '$username'\n            AND s.theDate >= CAST(DATE_FORMAT(NOW(),'%Y-%m-01') AS DATE)\n            AND s.theDate < DATE_ADD(DATE_FORMAT(NOW(),'%Y-%m-01'), INTERVAL 1 MONTH)\n          ORDER BY s.name DESC, s.theDate DESC\n          LIMIT 1\n       ) r\n    ON r.name = t.name\n   AND r.theDate = t.theDate \n"]], ['MySQL - Select the least day of the current month/year, not necessarily the first day of the month'], 4, 1], [(11480527, 3), [['NOTE: We\'re assuming here that \'theDate\' is datatype DATE (with no time component).  If it\'s a DATETIME or a TIMESTAMP, there\'s a potential for a time component, and that query may not return all rows for a given "date" value, if the time components are different for the rows with the same "date". (e.g. \'2012-07-13 17:30\' and \'2012-07-13 19:55\' are different datetime values.) If we want to return both of those rows (because both are a date of "July 13"), we need to do a range scan instead of an equality test.'], ['Note those last two lines... we\'re looking for any rows with a  theDate  value that is greater than or equal to the "least" value found for the current month AND that is ALSO less than midnight of the following day.']], [[" SELECT t.* \n  FROM table_name t\n  JOIN ( SELECT s.name\n              , s.theDate\n           FROM table_name s \n          WHERE s.name = '$username'\n            AND s.theDate >= CAST(DATE_FORMAT(NOW(),'%Y-%m-01') AS DATE)\n            AND s.theDate < DATE_ADD(DATE_FORMAT(NOW(),'%Y-%m-01'), INTERVAL 1 MONTH)\n          ORDER BY s.name DESC, s.theDate DESC\n          LIMIT 1\n       ) r\n    ON t.name = r.name \n   AND t.theDate >= r.theDate\n   AND t.theDate < DATE_FORMAT(DATE_ADD(r.theDate,INTERVAL 1 DAY),'%Y-%m-%d')\n"]], ['MySQL - Select the least day of the current month/year, not necessarily the first day of the month'], 4, 1], [(11495713, 0), [["And as I had stated in my  answer  to your previous question, you're better off making the comparison on the bare datetime column so that the query remains sargable(i.e. able to utilize indexes):"], ['This assumes the  crm_date_time_column  will never contain times which are in the future (e.g. tomorrow, next month, etc.), but if it can, you would just add:']], [[' SELECT     a.value\nFROM       table_c a\nINNER JOIN table_a b ON a.table_c_id = b.id\nWHERE      a.table_c_id IN (9,17,25) AND\n           b.crm_date_time_column >= UNIX_TIMESTAMP(CURDATE())\nGROUP BY   a.value \n']], ['Return results of query based on todays date in SQL (MySQL) Part 2'], 2, 1], [(11495713, 1), [['This assumes the  crm_date_time_column  will never contain times which are in the future (e.g. tomorrow, next month, etc.), but if it can, you would just add:'], ['as another condition in the  WHERE  clause.']], [[' AND b.crm_date_time_column < UNIX_TIMESTAMP(CURDATE() + INTERVAL 1 DAY)\n']], ['Return results of query based on todays date in SQL (MySQL) Part 2'], 2, 0], [(11510950, 0), [['You could also try using EXCEPT (similar to MINUS in Oracle):'], ['Or, more relevant to your example:']], [[' (SELECT 1\nUNION\nSELECT 2\nUNION \nSELECT 3\nUNION\nSELECT 4\nUNION\nSELECT 5\nUNION\nSELECT 6)\nEXCEPT\n(SELECT 2\n UNION\n SELECT 3\n UNION\n SELECT 4)\n']], ['Which values are missing in SQL from a list?'], 2, 1], [(11510950, 1), [['Or, more relevant to your example:'], ['where Field contains 2, 4, and 5.']], [[' (SELECT 1\nUNION\nSELECT 2\nUNION \nSELECT 3\nUNION\nSELECT 4\nUNION\nSELECT 5\nUNION\nSELECT 6)\nEXCEPT\n(SELECT Field FROM Table)        \n']], ['Which values are missing in SQL from a list?'], 2, 1], [(11568694, 0), [['thanks to @hackattack, who found this ?  answered already elsewhere .'], ["BUT, ALAS - that didn't work. \nThe MySQL 5 reference shows it slightly different syntax:"]], [[" BEGIN\nINSERT INTO users (username, password) \n  VALUES('test', 'test')\nINSERT INTO profiles (userid, bio, homepage) \n  VALUES(LAST_INSERT_ID(),'Hello world!', 'http://www.stackoverflow.com');\nCOMMIT;\n"]], ['SQL relational insert to 2 tables in single query without resorting to mysql_insert_id()'], 2, 0], [(11568694, 1), [["BUT, ALAS - that didn't work. \nThe MySQL 5 reference shows it slightly different syntax:"], ['And, lo/behold - that works!']], [[" INSERT INTO `table2` (`description`) \n  VALUES('sdfsdf');# 1 row affected.\nINSERT INTO `table1`(`table1_id`,`title`) \n  VALUES(LAST_INSERT_ID(),'hello world');\n"]], ['SQL relational insert to 2 tables in single query without resorting to mysql_insert_id()'], 2, 1], [(11696995, 0), [["There's no need for the Date(...) as far as i can tell. This example seems to work"], ['The between statement can cause issues with range boundaries for dates as']], [[" DECLARE @TheDate Date = '2012-07-01';\n\nSELECT 'hello' WHERE (@TheDate BETWEEN '2012-04-01' AND '2012-06-30')\n--None returned\nSET @TheDate = '2012-05-01'\n\nSELECT 'hello' WHERE (@TheDate BETWEEN '2012-04-01' AND '2012-06-30')\n--selects hello\n"]], ['SQL: retrieve records between dates in all databases'], 5, 1], [(11696995, 1), [['The between statement can cause issues with range boundaries for dates as'], ['is really interpreted as']], [[" BETWEEN '01/01/2009' AND '01/31/2009'\n"]], ['SQL: retrieve records between dates in all databases'], 5, 0], [(11696995, 2), [['is really interpreted as'], ['so will miss anything that occurred during the day of Jan 31st. In this case, you will have to use:']], [[" BETWEEN '01/01/2009 00:00:00' AND '01/31/2009 00:00:00'\n"]], ['SQL: retrieve records between dates in all databases'], 5, 0], [(11696995, 3), [['so will miss anything that occurred during the day of Jan 31st. In this case, you will have to use:'], ['or']], [[" myDate >= '01/01/2009 00:00:00' AND myDate < '02/01/2009 00:00:00'  --CORRECT!\n"]], ['SQL: retrieve records between dates in all databases'], 5, 0], [(11696995, 4), [['or'], ['UPDATE: It is entirely possible to have records created within that last second of the day, with a datetime as late as 01/01/2009 23:59:59.997!!']], [[" BETWEEN '01/01/2009 00:00:00' AND '01/31/2009 23:59:59' --WRONG! (see update!)\n"]], ['SQL: retrieve records between dates in all databases'], 5, 0], [(11753269, 0), [['-10000'], ['Your  NLS_CHARACTERSET  should be set to  AL32UTF8 . So try']], [["  SQL> create table mytbl (data_col varchar2(200));\n Table created\n SQL> insert into mytbl values('在职'); \n 1 row inserted.\n SQL> commit;\n Commit complete.\n SQL> select * from mytbl where data_col like '%在职%';\n DATA_COL                                                                                                                                                                                               \n -----------\n 在职 \n\n SQL> SELECT * FROM nls_database_parameters where parameter='NLS_CHARACTERSET';\n PARAMETER                      VALUE                                  \n ------------------------------ ----------------------------------------\n NLS_CHARACTERSET               AL32UTF8   \n"]], ['string comparing query with chinese chars - Oracle Database'], 3, 0], [(11753269, 1), [['Your  NLS_CHARACTERSET  should be set to  AL32UTF8 . So try'], ['Also make sure that parameter  NLS_NCHAR_CHARACTERSET  is set to  UTF8 .']], [["  SQL> ALTER SESSION SET NLS_CHARACTERSET = 'AL32UTF8';\n"]], ['string comparing query with chinese chars - Oracle Database'], 3, 0], [(11753269, 2), [['Also make sure that parameter  NLS_NCHAR_CHARACTERSET  is set to  UTF8 .'], ['-10000']], [["  SQL> ALTER SESSION SET NLS_NCHAR_CHARACTERSET = 'UTF8';\n"]], ['string comparing query with chinese chars - Oracle Database'], 3, 0], [(11762700, 0), [["SQL Server does not track the order of inserted rows, so there is no reliable way to get that information given your current table structure. Even if  employee_id  is an  IDENTITY  column, it is not 100% foolproof to rely on that for order of insertion (since you can fill gaps and even create duplicate ID values using  SET IDENTITY_INSERT ON ). If  employee_id  is an  IDENTITY  column  and  you are sure that rows aren't manually inserted out of order, you should be able to use this variation of your query to select the data in sequence, newest first:"], ["You can make a change to your table to track this information for new rows, but you won't be able to derive it for your existing data (they will all me marked as inserted at the time you make this change)."]], [[' SELECT \n   ROW_NUMBER() OVER (ORDER BY EMPLOYEE_ID DESC) AS ID, \n   EMPLOYEE_ID,\n   EMPLOYEE_NAME \nFROM dbo.CSBCA1_5_FPCIC_2012_EES207201222743\nORDER BY ID;\n']], ['How do I get row id of a row in sql server'], 2, 1], [(11762700, 1), [["You can make a change to your table to track this information for new rows, but you won't be able to derive it for your existing data (they will all me marked as inserted at the time you make this change)."], ['Note that this may break existing code that just does  INSERT INTO dbo.whatever SELECT/VALUES()  - e.g. you may have to revisit your code and define a proper, explicit column list.']], [[' ALTER TABLE dbo.CSBCA1_5_FPCIC_2012_EES207201222743 \n-- wow, who named this?\n  ADD CreatedDate DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP;\n']], ['How do I get row id of a row in sql server'], 2, 0], [(11769527, 0), [['This query will return all of the rows in the attached table that are not in the local version of the table'], ['And this will do the converse, returning all rows in the local table that are not matched in the remote table.']], [[' SELECT * FROM attachedTable \nWHERE col1 NOT IN( SELECT lt.col1 FROM localTable as lt)\n']], ['vb.net comparing two databases then insert or delete'], 2, 1], [(11769527, 1), [['And this will do the converse, returning all rows in the local table that are not matched in the remote table.'], ['-10000']], [[' SELECT * FROM localTable \nWHERE col1 NOT IN( SELECT rt.col1 FROM attachedTable As rt)\n']], ['vb.net comparing two databases then insert or delete'], 2, 1], [(11783678, 0), [['This query produces the DML statement to find  all rows  in all tables, where a column has a foreign-key constraint  referencing another table  but hold a  NULL  value in that column:'], ['Produces a query like this:']], [[" WITH x AS (\n SELECT c.conrelid::regclass    AS tbl\n      , c.confrelid::regclass   AS ftbl\n      , quote_ident(k.attname)  AS fk\n      , quote_ident(pf.attname) AS pk\n FROM   pg_constraint c\n JOIN   pg_attribute  k ON (k.attrelid, k.attnum) = (c.conrelid, c.conkey[1])\n JOIN   pg_attribute  f ON (f.attrelid, f.attnum) = (c.confrelid, c.confkey[1])\n LEFT   JOIN pg_constraint p  ON p.conrelid = c.conrelid AND p.contype = 'p'\n LEFT   JOIN pg_attribute  pf ON (pf.attrelid, pf.attnum)\n                               = (p.conrelid, p.conkey[1])\n WHERE  c.contype   = 'f'\n AND    c.confrelid = 'fk_tbl'::regclass  -- references to this tbl\n AND    f.attname   = 'fk_tbl_id'         -- and only to this column\n)\nSELECT string_agg(format(\n'SELECT %L AS tbl\n     , %L AS pk\n     , %s::text AS pk_val\n     , %L AS fk\n     , %L AS ftbl\nFROM   %1$s WHERE %4$s IS NULL'\n                  , tbl\n                  , COALESCE(pk 'NONE')\n                  , COALESCE(pk 'NULL')\n                  , fk\n                  , ftbl), '\nUNION ALL\n') || ';'\nFROM   x;\n"]], ['How can I find tables which reference a particular row via a foreign key?'], 5, 1], [(11783678, 2), [['Produces output like this:'], ['-10000']], [['     tbl    |     pk       | pk_val |    fk        |  ftbl\n-----------+--------------+--------+--------------+--------\n some_tbl  | some_tbl_id  | 49     | fk_tbl_id    | fk_tbl\n some_tbl  | some_tbl_id  | 58     | fk_tbl_id    | fk_tbl\n other_tbl | other_tbl_id | 66     | some_name_id | fk_tbl\n other_tbl | other_tbl_id | 67     | some_name_id | fk_tbl\n']], ['How can I find tables which reference a particular row via a foreign key?'], 5, 0], [(11783678, 3), [['-10000'], ['-10000']], [[" AND    c.confrelid = 'fk_tbl'::regclass\nAND    f.attname = 'fk_tbl_id' -- and only this column\n"]], ['How can I find tables which reference a particular row via a foreign key?'], 5, 0], [(11783678, 4), [['-10000'], ['Finds all such rows in the entire database (commented out the restriction to one table). Tested with Postgres 9.1.4 and works for me.']], [[" WITH x AS (\n SELECT c.confrelid::regclass   AS ftbl\n       ,quote_ident(f.attname)  AS fk\n       ,quote_ident(pf.attname) AS pk\n       ,string_agg(c.conrelid::regclass::text, ', ') AS referencing_tbls\n FROM   pg_constraint c\n JOIN   pg_attribute  f ON (f.attrelid, f.attnum) = (c.confrelid, c.confkey[1])\n LEFT   JOIN pg_constraint p  ON p.conrelid = c.confrelid AND p.contype = 'p'\n LEFT   JOIN pg_attribute  pf ON (pf.attrelid, pf.attnum)\n                               = (p.conrelid, p.conkey[1])\n WHERE  c.contype = 'f'\n -- AND    c.confrelid = 'fk_tbl'::regclass  -- only referring this tbl\n GROUP  BY 1, 2, 3\n)\nSELECT string_agg(format(\n'SELECT %L AS ftbl\n     , %L AS pk\n     , %s::text AS pk_val\n     , %L AS fk\n     , %L AS referencing_tbls\nFROM   %1$s WHERE %4$s IS NULL'\n                  , ftbl\n                  , COALESCE(pk, 'NONE')\n                  , COALESCE(pk, 'NULL')\n                  , fk\n                  , referencing_tbls), '\nUNION ALL\n') || ';'\nFROM   x;\n"]], ['How can I find tables which reference a particular row via a foreign key?'], 5, 1], [(11793666, 0), [['-10000'], ['Edited: Between clause is  inclusive  (both dates are included in the result) so if you maybe want to exclude one of the dates in the variable columns better use:']], [[' SELECT myColumn\n  FROM myTable\n WHERE Date BETWEEN @StartDate AND @EndDate\n']], ['Retrieving records from a table within two date variables'], 2, 1], [(11793666, 1), [['Edited: Between clause is  inclusive  (both dates are included in the result) so if you maybe want to exclude one of the dates in the variable columns better use:'], ['-10000']], [[' SELECT myColumn\n  FROM myTable\n WHERE Date >= @StartDate\n   AND Date <= @EndDate\n']], ['Retrieving records from a table within two date variables'], 2, 1], [(11814210, 0), [['Try this : '], ['Create a Month table to store the value from 1 to 12 .Instead of master..spt_values you can also use  sys.all_objects']], [[" Declare @Sample table \n(Buy datetime ,Qty int)\n\nInsert into @Sample values\n( '01-01-2012' ,1),\n('01-01-2012',1 ),\n('01-02-2012',1 ),\n('01-03-2012',1 ),\n('01-05-2012',1 ),\n('01-07-2012',1 ),\n('01-12-2012',1 )\n\n;with cte as \n(\n  select top 12 row_number() over(order by t1.number) as N\n  from   master..spt_values t1 \n   cross join master..spt_values t2\n )\nselect t.N as month,\nisnull(datepart(year,y.buy),'2012') as Year,\nsum(isnull(y.qty,0)) as Quantity\nfrom cte t\nleft join @Sample y\non month(convert(varchar(20),buy,103)) = t.N\ngroup by y.buy,t.N\n"]], ['SQL Query Group By Mount And Year'], 3, 1], [(11814210, 1), [['Create a Month table to store the value from 1 to 12 .Instead of master..spt_values you can also use  sys.all_objects'], ['or use a recursive cte to generate the month table']], [['   select row_number() over (order by object_id) as months\n  from sys.all_objects  \n']], ['SQL Query Group By Mount And Year'], 3, 0], [(11814210, 2), [['or use a recursive cte to generate the month table'], ['and then use Left join to compare the value from the month table with your table and use  isnull  function to handle the null values.']], [[' ;with cte(N) as \n(\nSelect 1 \nunion all\nSelect 1+N from cte where N<12\n)\nSelect * from cte\n']], ['SQL Query Group By Mount And Year'], 3, 0], [(11822599, 1), [['But of course you can do this in SQL directly.'], ['-10000']], [[' where LAST_MODIFIED > to_date(<your_date_string_to_compare>,<your_date_format>)\n']], ['How to compare oracle date and lotusscript date?'], 2, 1], [(11833448, 0), [['If you have your query in a view, you might use this:'], ['(I know it looks ugly.)']], [[' where\n    Invoice_Date between\n    (\n        case\n            when datepart(dd, getdate()) = 1 then dateadd(mm, -1, getdate())\n            else dateadd(dd, -15, getdate())\n        end\n    )\n    and\n    (\n        case\n            when datepart(dd, getdate()) = 1 then dateadd(dd, -1, getdate())\n            else dateadd(dd, -1, getdate())\n        end\n    )\n']], ['How to query 2 different date ranges depending on the day it is run'], 2, 1], [(11833448, 1), [['(I know it looks ugly.)'], ['-10000']], [[' where\n    Invoice_Date between\n    (\n        case\n            when datepart(dd, dateadd(dd, datediff(dd, 0, getdate()), 0)) = 1 then dateadd(mm, -1, dateadd(dd, datediff(dd, 0, getdate()), 0))\n            else dateadd(dd, -15, dateadd(dd, datediff(dd, 0, getdate()), 0))\n        end\n    )\n    and\n    (\n        case\n            when datepart(dd, dateadd(dd, datediff(dd, 0, getdate()), 0)) = 1 then dateadd(dd, -1, dateadd(dd, datediff(dd, 0, getdate()), 0))\n            else dateadd(dd, -1, dateadd(dd, datediff(dd, 0, getdate()), 0))\n        end\n    )\n']], ['How to query 2 different date ranges depending on the day it is run'], 2, 1], [(11844855, 0), [['Below are three queries that will do the task:'], ['or']], [[" SELECT\n  c.*\nFROM\n  client c \nWHERE\n  NOT EXISTS(SELECT * FROM notes n WHERE n.client_id = c.client_id \n    AND n.note = 'do not send')\n"]], ['linked tables in firebird, discard records that have a specific value in a one to many linked table'], 3, 1], [(11844855, 1), [['or'], ['or']], [[" SELECT\n  c.*, n.client_id\nFROM\n  client.c LEFT JOIN\n    (SELECT client_id FROM notes WHERE note = 'do not send') n\n  ON c.client_id = n.client_id\nWHERE\n  n.client_id IS NULL\n"]], ['linked tables in firebird, discard records that have a specific value in a one to many linked table'], 3, 1], [(11844855, 2), [['or'], ['-10000']], [[" SELECT\n  c.*\nFROM\n  client c \nWHERE\n  NOT c.client_id IN (SELECT client_id FROM notes n \n    WHERE n.note = 'do not send')\n"]], ['linked tables in firebird, discard records that have a specific value in a one to many linked table'], 3, 1], [(11847584, 0), [['Static Pivot:'], ['Dynamic Pivot:']], [[' SELECT *\nFROM\n(\n    SELECT col1, col2\n    FROM yourTable\n) x\nPIVOT\n(\n   min(col2)\n   for col1 in ([A], [B], [C])\n)p\n']], ['Transposing Rows in to colums in SQL Server 2005'], 3, 1], [(11847584, 1), [['Dynamic Pivot:'], ['If you do not want to use the  PIVOT  function, then you can perform a similar type of query with  CASE  statements:']], [[" DECLARE @cols AS NVARCHAR(MAX),\n    @query  AS NVARCHAR(MAX)\n\nselect @cols = STUFF((SELECT distinct ',' + QUOTENAME(col1) \n                    from t1\n            FOR XML PATH(''), TYPE\n            ).value('.', 'NVARCHAR(MAX)') \n        ,1,1,'')\n\nset @query = 'SELECT ' + @cols + ' from \n             (\n                select col1, col2\n                from t1\n            ) x\n            pivot \n            (\n                min(col2)\n                for col1 in (' + @cols + ')\n            ) p '\n\nexecute(@query)\n"]], ['Transposing Rows in to colums in SQL Server 2005'], 3, 1], [(11847584, 2), [['If you do not want to use the  PIVOT  function, then you can perform a similar type of query with  CASE  statements:'], ['See  SQL Fiddle with Demo']], [[" select \n  SUM(CASE WHEN col1 = 'A' THEN col2 END) as A,\n  SUM(CASE WHEN col1 = 'B' THEN col2 END) as B,\n  SUM(CASE WHEN col1 = 'C' THEN col2 END) as C\nFROM t1\n"]], ['Transposing Rows in to colums in SQL Server 2005'], 3, 1], [(11852951, 0), [['The following uses correlated subqueries to get the numbers you want.  The idea is to count the number of cumulative starts and cumulative ends, up to each time:'], ['This query will have duplicates when there are multiple starts and ends at the same time.  In this case, you would need to determine how to treat this case.  But, the idea is the same.  The outer select would be:']], [[' with alltimes as\n    (select t.*\n     from ((select part_start_time as thetime, 1 as IsStart, 0 as IsEnd\n            from t\n           ) union all\n           (select part_end_time, 0 as isStart, 1 as IsEnd\n            from t\n           )\n          ) t\n     )\nselect t.*,\n       (cumstarts - cumends) as numactive\nfrom (select alltimes.thetime,\n             (select sum(isStart)\n              from allStarts as where as.part_start_time <= alltimes.thetime\n             ) as cumStarts,\n             (select sum(isEnd)\n              from allStarts as where as.part_end_time <= alltimes.thetime\n             ) as cumEnds\n      from alltimes\n     ) t\n']], ['SQL - Determine count of records active at time'], 4, 1], [(11852951, 1), [['This query will have duplicates when there are multiple starts and ends at the same time.  In this case, you would need to determine how to treat this case.  But, the idea is the same.  The outer select would be:'], ['and you need a group by clause:']], [[' select t.thetime, max(cumstarts - cumends) as numactives\n']], ['SQL - Determine count of records active at time'], 4, 0], [(11852951, 2), [['and you need a group by clause:'], ['The "max" gives the starts precedence (meaning with the same time stampt, the starts are treated as happening first, so you get the maximum actives at that time).  "Min" would give the ends precedence.  And, if you use average, remember to convert to floating point:']], [[' group by t.thetime\n']], ['SQL - Determine count of records active at time'], 4, 0], [(11852951, 3), [['The "max" gives the starts precedence (meaning with the same time stampt, the starts are treated as happening first, so you get the maximum actives at that time).  "Min" would give the ends precedence.  And, if you use average, remember to convert to floating point:'], ['-10000']], [[' select t.thetime, avg(cumstarts*1.0 - cumends) as avgnumactives\n']], ['SQL - Determine count of records active at time'], 4, 0], [(11900470, 0), [['For adding or subtracting an amount of time expressed as a literal you can use INTERVAL.'], ['As well there are now standard ways to express date and time literals and avoid the use of various database specific conversion functions. ']], [[" SELECT TO_TIMESTAMP('10/08/2012','DD/MM/YYYY')\n     - INTERVAL '0.001' SECOND \nFROM dual;\n"]], ['Oracle: subtract millisecond from a datetime'], 4, 1], [(11900470, 1), [['As well there are now standard ways to express date and time literals and avoid the use of various database specific conversion functions. '], ['For your original question the time part of a day is stored in fractional days. So one second is:']], [[" SELECT TIMESTAMP '2012-10-08 00:00:00' \n   - INTERVAL '0.001' SECOND DATA\nFROM dual;\n"]], ['Oracle: subtract millisecond from a datetime'], 4, 1], [(11900470, 2), [['For your original question the time part of a day is stored in fractional days. So one second is:'], ['Divide by 1000 to get milliseconds. ']], [[' 1 / (hours in day * minutes in hour * seconds in a minute)\n']], ['Oracle: subtract millisecond from a datetime'], 4, 0], [(11900470, 3), [['Divide by 1000 to get milliseconds. '], ['-10000']], [[' 1 / (24 * 60 * 60 * 1000)\n']], ['Oracle: subtract millisecond from a datetime'], 4, 0], [(11912188, 0), [["Here's an example of an aggregate that returns lowest-ranked non- NULL  string:"], ['CREATE TABLE TopNonNullRank (\n    Id     INT            NOT NULL,\n    UserId NVARCHAR (32)  NOT NULL,\n    Value1 NVARCHAR (128) NULL,\n    Value2 NVARCHAR (128) NULL,\n    Value3 NVARCHAR (128) NULL,\n    Value4 NVARCHAR (128) NULL,\n    PRIMARY KEY CLUSTERED (Id ASC)\n);']], [[' using System;\nusing System.Data;\nusing System.Data.SqlClient;\nusing System.Data.SqlTypes;\nusing System.IO;\nusing Microsoft.SqlServer.Server;\n\n[Serializable]\n[SqlUserDefinedAggregate(Format.UserDefined, MaxByteSize = -1, IsNullIfEmpty = true)]\npublic struct LowestRankString : IBinarySerialize\n{\n    public int currentRank;\n    public SqlString currentValue;\n\n    public void Init()\n    {\n        currentRank = int.MaxValue;\n        currentValue = SqlString.Null;\n    }\n\n    public void Accumulate(int Rank, SqlString Value)\n    {\n        if (!Value.IsNull)\n        {\n            if (Rank <= currentRank)\n            {\n                currentRank = Rank;\n                currentValue = Value;\n            }\n        }\n    }\n\n    public void Merge(LowestRankString Group)\n    {\n        Accumulate(Group.currentRank, Group.currentValue);\n    }\n\n    public SqlString Terminate()\n    {\n        return currentValue;\n    }\n\n    public void Read(BinaryReader r)\n    {\n        currentRank = r.ReadInt32();\n        bool hasValue = r.ReadBoolean();\n        if (hasValue)\n        {\n            currentValue = new SqlString(r.ReadString());\n        }\n        else\n        {\n            currentValue = SqlString.Null;\n        }\n    }\n\n    public void Write(BinaryWriter w)\n    {\n        w.Write(currentRank);\n\n        bool hasValue = !currentValue.IsNull;\n        w.Write(hasValue);\n        if (hasValue)\n        {\n            w.Write(currentValue.Value);\n        }\n    }\n}\n']], ['Smart SQL Merge - n rows, coalesce'], 4, 0], [(11912188, 1), [['CREATE TABLE TopNonNullRank (\n    Id     INT            NOT NULL,\n    UserId NVARCHAR (32)  NOT NULL,\n    Value1 NVARCHAR (128) NULL,\n    Value2 NVARCHAR (128) NULL,\n    Value3 NVARCHAR (128) NULL,\n    Value4 NVARCHAR (128) NULL,\n    PRIMARY KEY CLUSTERED (Id ASC)\n);'], ['The following simple query returns top non- NULL  value for each column. ']], [[" INSERT INTO TopNonNullRank (Id, UserId, Value1, Value2, Value3, Value4) VALUES \n    (1, N'Ada', NULL, N'Top value 2 for A', N'Top value 3 for A', NULL),\n    (2, N'Ada', N'Top value 1 for A', NULL, N'Other value 3', N'Top value 4 for A'),\n    (3, N'Ada', N'Other value 1 for A', N'Other value 2 for A', N'Other value 3 for A', NULL),\n    (4, N'Bob', N'Top value 1 for B', NULL, NULL, NULL),\n    (5, N'Bob', NULL, NULL, NULL, N'Top value 4 for B'),\n    (6, N'Bob', N'Other value 1 for B', N'Top value 2 for B', NULL, N'Other value 4');\n"]], ['Smart SQL Merge - n rows, coalesce'], 4, 0], [(11912188, 2), [['The following simple query returns top non- NULL  value for each column. '], ['The only thing left is merging the results back to the original table. The simplest way would be something like this:']], [[' SELECT \n    UserId,\n    dbo.LowestRankString(Id, Value1) AS TopValue1,\n    dbo.LowestRankString(Id, Value2) AS TopValue2,\n    dbo.LowestRankString(Id, Value3) AS TopValue3,\n    dbo.LowestRankString(Id, Value4) AS TopValue4\nFROM TopNonNullRank\nGROUP BY UserId\n']], ['Smart SQL Merge - n rows, coalesce'], 4, 0], [(11912188, 3), [['The only thing left is merging the results back to the original table. The simplest way would be something like this:'], ['Note that this update still leaves you with duplicate rows, and you would need to get rid of them.']], [[' WITH TopValuesPerUser AS\n(\n    SELECT \n        UserId,\n        dbo.LowestRankString(Id, Value1) AS TopValue1,\n        dbo.LowestRankString(Id, Value2) AS TopValue2,\n        dbo.LowestRankString(Id, Value3) AS TopValue3,\n        dbo.LowestRankString(Id, Value4) AS TopValue4\n    FROM TopNonNullRank\n    GROUP BY UserId\n)\nUPDATE TopNonNullRank\nSET\n    Value1 = TopValue1,\n    Value2 = TopValue2,\n    Value3 = TopValue3,\n    Value4 = TopValue4\nFROM TopNonNullRank AS OriginalTable\nLEFT JOIN TopValuesPerUser ON TopValuesPerUser.UserId = OriginalTable.UserId;\n']], ['Smart SQL Merge - n rows, coalesce'], 4, 0], [(11960289, 0), [['You can wrap a query in another query:'], ['The idea is that you use the query with a  Rank  table, like so:']], [[' SELECT TechID, Rank FROM Rank,\n(SELECT x.TechID, Count(*) AS cnt, tblEmployeeData.LName, \n    tblEmployeeData.Pernr, tblEmployeeData.Occurrences, tblEmployeeData.Standing\nFROM tblEmployeeData\nINNER JOIN tblOccurrence AS x ON tblEmployeeData.TechID = x.TechID\nWHERE (((x.OccurrenceDate) Between DateAdd("m",-6,Date()) And Date())\n  AND ((Exists     \n    (SELECT * FROM tblOccurrence AS y  WHERE y.TechID = x.TechID AND DATEADD \n    ("d", -1, x.[OccurrenceDate]) = y.[OccurrenceDate]))=False))\nGROUP BY x.TechID, tblEmployeeData.LName, tblEmployeeData.Pernr) a\nWHERE a.Cnt BETWEEN Rank.Low And rank.High\n']], ['Access SQL update based on count results and conditional update'], 3, 1], [(11960289, 1), [['The idea is that you use the query with a  Rank  table, like so:'], ['This runs for me in a rough mock-up']], [[' Low High    Rank\n0   3       Good\n4   5       Verbal Warning\n6   7       Written Warning\n8   8       Final Written Warning\n9   99      Termination\n']], ['Access SQL update based on count results and conditional update'], 3, 0], [(11960289, 2), [['This runs for me in a rough mock-up'], ['-10000']], [[' SELECT a.TechID, tblRank.Rank FROM tblRank, (SELECT x.TechID, Count(*) AS cnt, tblEmployeeData.LName, \n    tblEmployeeData.Pernr, tblEmployeeData.Occurrences, tblEmployeeData.Standing\nFROM tblEmployeeData\nINNER JOIN tblOccurrence AS x ON tblEmployeeData.TechID = x.TechID\nWHERE (((x.OccurrenceDate) Between DateAdd("m",-6,Date()) And Date()) AND ((Exists     \n    (SELECT * FROM tblOccurrence AS y  WHERE y.TechID = x.TechID AND DATEADD \n    ("d", -1, x.[OccurrenceDate]) = y.[OccurrenceDate]))=False))\nGROUP BY x.TechID, tblEmployeeData.LName, tblEmployeeData.Pernr, tblEmployeeData.Occurrences, tblEmployeeData.Standing) a\nWHERE a.Cnt BETWEEN tblRank.Low And tblrank.High\n']], ['Access SQL update based on count results and conditional update'], 3, 1], [(11969118, 0), [['Instead of using  UNION ALL , try joining your tables together:'], ['This will give you the results on a single row.  If you really want the results as seperate rows, you could perhaps select the table name along with the *_name field:']], [[' SELECT A.A_name, B.B_name, C.C_name\nFROM TableA A\n    INNER JOIN TableB B ON A.companyId = B.companyId\n    INNER JOIN TableC C ON A.companyId = C.companyId\nWHERE A.companyId = 1\n']], ['SQLite: How to get certain field from multiple tables?'], 2, 1], [(11969118, 1), [['This will give you the results on a single row.  If you really want the results as seperate rows, you could perhaps select the table name along with the *_name field:'], ['-10000']], [[" SELECT 'TableA' AS TableName, A_name FROM TableA WHERE companyId = 1 UNION ALL\nSELECT 'TableB', B_name FROM TableB WHERE companyId = 1 UNION ALL\nSELECT 'TableC', C_name FROM TableC WHERE companyId = 1\n"]], ['SQLite: How to get certain field from multiple tables?'], 2, 1], [(12013073, 0), [['To get a  datetime :'], ['And to get a number representing the time:']], [[' SELECT GetDate() - DateDiff(day, 0, GetDate());\n-- returns the time with zero as the datetime part (1900-01-01).\n']], ['Extract time from datetime efficiently (as decimal or datetime)'], 3, 1], [(12013073, 1), [['And to get a number representing the time:'], ['If you really want a string, then:']], [[' SELECT DateDiff(millisecond, DateDiff(day, 0, GetDate()), GetDate());\n-- time since midnight in milliseconds, use as you wish\n']], ['Extract time from datetime efficiently (as decimal or datetime)'], 3, 1], [(12013073, 2), [['If you really want a string, then:'], ['-10000']], [[" SELECT Convert(varchar(8), GetDate(), 108); -- 'hh:mm:ss'\nSELECT Convert(varchar(12), GetDate(), 114); -- 'hh:mm:ss.nnn' where nnn is milliseconds\n"]], ['Extract time from datetime efficiently (as decimal or datetime)'], 3, 1], [(12050795, 1), [["If publisher's name is unique you can add the column to group by like this"], ['-10000']], [[' select j.publisher_id,p.publisher_name, count(j.publisher_id)\nFROM a1_journal j \n  inner join a1_publisher p ON  j.publisher_id=p.publisher_id \nGROUP BY j.publisher_id, p.publisher_name\nHAVING count(j.publisher_id) >=3\nORDER BY count(j.publisher_id) DESC\n']], ['How to remove null values from a count function'], 3, 1], [(12050795, 2), [['-10000'], ['-10000']], [[' SELECT aj.publisher_id, aj.numberOfJournals, ap.publisher_name\nFROM a1_publisher ap \nINNER JOIN (\n    SELECT j.publisher_id, count(j.publisher_id) numberOfJournals\n    FROM a1_journal j \n       inner join a1_publisher p ON  j.publisher_id=p.publisher_id \n    GROUP BY j.publisher_id\n    HAVING count(j.publisher_id) >=3  ) aj \nON ap.publisher_id = ap.publisher_id\nORDER BY count(j.publisher_id) DESC\n']], ['How to remove null values from a count function'], 3, 1], [(12063841, 0), [['Use  ISNULL()  or  COALESCE() , or  CASE'], ['OR']], [[' SELECT    ISNULL(ColumnA, ColumnB) AS [YourColumn]\nFROM      FOO\n']], ['Display value from column B if column A is NULL'], 3, 1], [(12063841, 1), [['OR'], ['OR']], [[' SELECT    COALESCE(ColumnA, ColumnB) AS [YourColumn]\nFROM      FOO\n']], ['Display value from column B if column A is NULL'], 3, 1], [(12063841, 2), [['OR'], ['-10000']], [[' SELECT    CASE WHEN ColumnA IS NULL THEN\n              ColumnB\n          ELSE\n              ColumnA\n          END AS [YourColumn]\nFROM      FOO\n']], ['Display value from column B if column A is NULL'], 3, 1], [(12085307, 0), [['Use  to_char :'], ["Here's a function that produces a  text  formatted value:"]], [[" regress=# SELECT to_char( (9999999 ||' seconds')::interval, 'HH24:MM:SS' );\n  to_char   \n------------\n 2777:00:39\n(1 row)\n"]], ['sec_to_time() function in PostgreSQL?'], 5, 1], [(12085307, 1), [["Here's a function that produces a  text  formatted value:"], ['eg:']], [[" CREATE OR REPLACE FUNCTION sec_to_time(bigint) RETURNS text AS $$\nSELECT to_char( ($1|| ' seconds')::interval, 'HH24:MI:SS');\n$$ LANGUAGE 'SQL' IMMUTABLE;\n"]], ['sec_to_time() function in PostgreSQL?'], 5, 1], [(12085307, 2), [['eg:'], ["If you'd prefer an  INTERVAL  result, use:"]], [[' regress=# SELECT sec_to_time(9999999);\n sec_to_time \n-------------\n 2777:00:39\n(1 row)\n']], ['sec_to_time() function in PostgreSQL?'], 5, 0], [(12085307, 4), [['... which will produce results like:'], ["Don't cast an  INTERVAL  to  TIME  though; it'll discard the days part. Use  to_char(theinterval, 'HH24:MI:SS)  to convert it to  text  without truncation instead."]], [[' SELECT sec_to_time(9999999);\n       sec_to_time       \n-------------------------\n 3 mons 25 days 17:46:39\n(1 row)\n']], ['sec_to_time() function in PostgreSQL?'], 5, 0], [(12088243, 0), [['See my script below which includes a function to simply obtain the status of a URL. When I run this script I get the following output:'], ["If you want the actual content behind a URL, try  oHttp.ResponseText . Here's the  WinHTTP reference  if you are interested in other capabilities as well."]], [[' http://www.google.com => 200 [OK]\nhttp://www.google.com/does_not_exist => 404 [Not Found]\nhttp://does_not_exist.google.com => -2147012889\n    [The server name or address could not be resolved]\n']], ['ActiveX calling URL page'], 2, 0], [(12088243, 1), [["If you want the actual content behind a URL, try  oHttp.ResponseText . Here's the  WinHTTP reference  if you are interested in other capabilities as well."], ['-10000']], [[' Option Explicit\n\nDim aUrlList\naUrlList = Array( _\n    "http://www.google.com", _\n    "http://www.google.com/does_not_exist", _\n    "http://does_not_exist.google.com" _\n)\n\nDim i\nFor i = 0 To UBound(aUrlList)\n    WScript.Echo aUrlList(i) & " => " & GetUrlStatus(aUrlList(i))\nNext\n\nFunction GetUrlStatus(sUrl)\n    Dim oHttp : Set oHttp = CreateObject("WinHttp.WinHttpRequest.5.1")\n\n    On Error Resume Next\n\n    With oHttp\n        .Open "GET", SUrl, False\n        .Send\n    End With\n\n    If Err Then\n        GetUrlStatus = Err.Number & " [" & Err.Description & "]"\n    Else\n        GetUrlStatus = oHttp.Status & " [" & oHttp.StatusText & "]"\n    End If\n\n    Set oHttp = Nothing\nEnd Function\n']], ['ActiveX calling URL page'], 2, 1], [(12133106, 0), [['This should work,'], ['also if you want to get all people having common friends try this']], [[' Select f1.FRIEND_ID,f1.FRIEND_NAME from \nFRIENDS f1,FRIENDS f2 where f1.FRIEND_ID =f2.FRIEND_ID and \nf1.id=1 and f2.id=2\n']], ['MySQL - How do I compare two columns for repeated values?'], 2, 1], [(12133106, 1), [['also if you want to get all people having common friends try this'], ['this will return two people having same friends per row:  http://sqlfiddle.com/#!2/c9f36/2/0']], [[" Select f1.FRIEND_ID,f1.FRIEND_NAME,f1.id 'first person',f2.id as 'second person' from \nFRIENDS f1,FRIENDS f2 where f1.FRIEND_ID =f2.FRIEND_ID and \nf1.id<>f2.id and f1.id<f2.id\n"]], ['MySQL - How do I compare two columns for repeated values?'], 2, 1], [(12151979, 0), [['Example you have record like this'], ['and ']], [[' Orders Table\n------------------------------------\nOrderID     |     attachedCompanyIDs\n------------------------------------\n   1                     1,2,3               -- comma separated values\n   2                     2,4     \n']], ['Have an array in a SQL field. How to display it systematically?'], 4, 0], [(12151979, 1), [['and '], ['Using the function']], [[' Company Table\n--------------------------------------\nCompanyID      |        name\n--------------------------------------\n    1                 Company 1\n    2                 Another Company\n    3                 StackOverflow\n    4                 Nothing\n']], ['Have an array in a SQL field. How to display it systematically?'], 4, 0], [(12151979, 2), [['Using the function'], ['will result']], [[' SELECT name \nFROM orders, company\nWHERE orderID = 1 AND FIND_IN_SET(companyID, attachedCompanyIDs)\n']], ['Have an array in a SQL field. How to display it systematically?'], 4, 1], [(12151979, 3), [['will result'], ['-10000']], [[' name\n---------------\nCompany 1\nAnother Company\nStackOverflow\n']], ['Have an array in a SQL field. How to display it systematically?'], 4, 0], [(12160776, 0), [["I think you're looking for something like this, though your example calculations may be off a little:"], ['This gives us the following output:']], [[' SELECT\n    COLA,\n    COLB,\n    ROUND(\n        -- Divide the running total...\n        (SELECT CAST(SUM(COLB) AS FLOAT) FROM #MyTempTable WHERE COLA <= a.COLA) /\n        -- ...by the full total\n        (SELECT CAST(SUM(COLB) AS FLOAT) FROM #MyTempTable),\n        2\n    ) AS COLC\nFROM #MyTempTable AS a\nORDER BY COLA\n']], ['SQL cumulative % Total'], 2, 1], [(12160776, 1), [['This gives us the following output:'], ['The reason that your results are 0 (or 1) is because you are dividing ints by ints, thus giving you an int (see  Datatype precedence ).']], [[' COLA    COLB    COLC\nName1   218     0.35\nName2   157     0.6\nName3   134     0.81\nName4   121     1\n']], ['SQL cumulative % Total'], 2, 0], [(12175474, 0), [['-10000'], ['Using If statement in MySQL :']], [[' UPDATE A SET act=now() WHERE id=1 AND act_reset <> 0\n']], ['simple flow control with mysql'], 2, 1], [(12175474, 1), [['Using If statement in MySQL :'], ['-10000']], [[' IF act_reset <> 0 THEN \n  UPDATE A SET act=now() WHERE id=1 \nEND IF; \n']], ['simple flow control with mysql'], 2, 1], [(12221037, 0), [['Static Version:'], ['Dynamic Version,  this will get the list of columns to  unpivot  and then to  pivot  at run-time:']], [[' select *\nfrom\n(\n  select fk, col + cast(rownumber as varchar(1)) new_col,\n    val\n  from \n  (\n    select fk, rownumber, value, cast(type as varchar(10)) type,\n      status\n    from yourtable\n  ) x\n  unpivot\n  (\n    val\n    for col in (value, type, status)\n  ) u\n) x1\npivot\n(\n  max(val)\n  for new_col in\n    ([value1], [type1], [status1], \n     [value2], [type2], [status2],\n    [value3], [type3])\n) p\n']], ['How can I query row data as columns?'], 2, 1], [(12221037, 1), [['Dynamic Version,  this will get the list of columns to  unpivot  and then to  pivot  at run-time:'], ['see  SQL Fiddle with Demo']], [[" DECLARE @colsUnpivot AS NVARCHAR(MAX),\n    @query  AS NVARCHAR(MAX),\n    @colsPivot as  NVARCHAR(MAX)\n\nselect @colsUnpivot = stuff((select ','+quotename(C.name)\n         from sys.columns as C\n         where C.object_id = object_id('yourtable') and\n               C.name not in ('fk', 'rownumber')\n         for xml path('')), 1, 1, '')\n\nselect @colsPivot = STUFF((SELECT  ',' \n                      + quotename(c.name \n                         + cast(t.rownumber as varchar(10)))\n                    from yourtable t\n                     cross apply \n                      sys.columns as C\n                   where C.object_id = object_id('yourtable') and\n                         C.name not in ('fk', 'rownumber')\n                   group by c.name, t.rownumber\n                   order by t.rownumber\n            FOR XML PATH(''), TYPE\n            ).value('.', 'NVARCHAR(MAX)') \n        ,1,1,'')\n\n\nset @query \n  = 'select *\n      from\n      (\n        select fk, col + cast(rownumber as varchar(10)) new_col,\n          val\n        from \n        (\n          select fk, rownumber, value, cast(type as varchar(10)) type,\n            status\n          from yourtable\n        ) x\n        unpivot\n        (\n          val\n          for col in ('+ @colsunpivot +')\n        ) u\n      ) x1\n      pivot\n      (\n        max(val)\n        for new_col in\n          ('+ @colspivot +')\n      ) p'\n\nexec(@query)\n"]], ['How can I query row data as columns?'], 2, 1], [(12248899, 0), [['Here, try this one,'], ['-10000']], [[" SELECT  a.dept_id, \n        NewTable.NameValues\nFROM    (\n          SELECT DISTINCT dept_ID\n          FROM tableA\n        ) a \n        LEFT JOIN\n        (\n          SELECT  dept_id,\n                STUFF((\n                  SELECT  ', ' + [Name] \n                  FROM    tableA\n                  WHERE   ( dept_id = Results.dept_id )\n                  FOR XML PATH('')), 1, 1, '') AS NameValues\n          FROM    tableA Results\n          GROUP BY dept_id\n        ) NewTable\n        on a.dept_id = NewTable.dept_id\nGO\n"]], ['How can i concatenate and make a group of text in sql server?'], 2, 1], [(12248899, 1), [['-10000'], ['-10000']], [[" SELECT  a.dept_id, \n        SUBSTRING(d.nameList,1, LEN(d.nameList) - 1) ConcatenateNames\nFROM \n        (\n            SELECT DISTINCT dept_id\n            FROM   tableA\n        ) a\n        CROSS APPLY\n        (\n            SELECT name + ', ' \n            FROM tableA AS B \n            WHERE A.dept_id = B.dept_id \n            FOR XML PATH('')\n        ) D (nameList)\nGO\n"]], ['How can i concatenate and make a group of text in sql server?'], 2, 1], [(12250195, 0), [['For the first one would be:'], ['For the second one:']], [[' UPDATE Stackoverflow\nSet StateId = 1\nwhere GeneralId = 1000;\n']], ['How can I update more than one record in MS SQL?'], 3, 0], [(12250195, 1), [['For the second one:'], ['For both of them:']], [[' UPDATE Stackoverflow\nSet StateId = 1\nwhere GeneralId = 1001;\n']], ['How can I update more than one record in MS SQL?'], 3, 0], [(12250195, 2), [['For both of them:'], ['-10000']], [[' UPDATE Stackoverflow\nSet StateId = 1\nwhere GeneralId IN (1000,1001);\n']], ['How can I update more than one record in MS SQL?'], 3, 1], [(12251993, 1), [['and restore it in a new SQLite database:'], ['-10000']], [[' gunzip -c foo.dump.gz | sqlite3 foo.new.db\n']], ['Dumping sqlite3 database for use in Titanium'], 2, 0], [(12265411, 0), [['The standard SQL way is to use like:'], ['That is in a query statement.  You can also do this in TSQL:']], [[" where @stringVar like '%thisstring%'\n"]], ['How can I tell if a VARCHAR variable contains a substring?'], 2, 1], [(12265411, 1), [['That is in a query statement.  You can also do this in TSQL:'], ['-10000']], [[" if @stringVar like '%thisstring%'\n"]], ['How can I tell if a VARCHAR variable contains a substring?'], 2, 1], [(12335438, 0), [['For the time zone you can:'], ['or the equivalent:']], [[' SHOW timezone;\n']], ['Server timezone offset value'], 6, 0], [(12335438, 1), [['or the equivalent:'], ['Frustratingly, there appears to be no built-in function to report the time offset from UTC the client is using in hours and minutes, which seems kind of insane to me. You can get the offset by comparing the current time in UTC to the current time locally:']], [[" SELECT current_setting('TIMEZONE');\n"]], ['Server timezone offset value'], 6, 0], [(12335438, 4), [["That'll match the desired result except that it doesn't produce a leading zero, so  -05:00  is just  -5:00 . Annoyingly it seems to be impossible to get  to_char  to produce a leading zero for hours, leaving me with the following ugly manual formatting:"], ["If you don't need the leading zero you can instead use:"]], [[" CREATE OR REPLACE FUNCTION oracle_style_tz() RETURNS text AS $$\nSELECT to_char(extract(timezone_hour FROM current_timestamp),'FM00')||':'||\n       to_char(extract(timezone_minute FROM current_timestamp),'FM00');\n$$ LANGUAGE 'SQL' STABLE;\n"]], ['Server timezone offset value'], 6, 0], [(12366390, 0), [['( supports most RDBMS )'], ['If you are using  MSSQL 2008+']], [[' SELECT  a.*\nFROM    tbProduct a\n        INNER JOIN\n        (\n            SELECT Category, MAX(Price) maxPrice\n            FROM tbProduct\n            GROUP BY Category\n        ) b ON a.category = b.category AND\n                a.price = b.maxPrice\n']], ['How to select product that have the maximum price of each category?'], 3, 1], [(12366390, 1), [['If you are using  MSSQL 2008+'], ['or']], [[' WITH allProducts AS\n(\nSELECT  ProductId,ProductName,Category,Price,\n        ROW_NUMBER() OVER (PARTITION BY CATEGORY ORDER BY Price DESC) ROW_NUM\nFROM tbProduct\n)\nSELECT ProductId,ProductName,Category,Price\nFROM allProducts\nWHERE ROW_NUM = 1\n']], ['How to select product that have the maximum price of each category?'], 3, 1], [(12366390, 2), [['or'], ['-10000']], [[' SELECT ProductId,ProductName,Category,Price\nFROM    \n(\nSELECT  ProductId,ProductName,Category,Price,\n        ROW_NUMBER() OVER (PARTITION BY CATEGORY ORDER BY Price DESC) ROW_NUM\nFROM tbProduct\n) allProducts\nWHERE ROW_NUM = 1\n']], ['How to select product that have the maximum price of each category?'], 3, 1], [(12386646, 0), [['Edit:'], ['Or if you need a complex logic, you can write an other SP, which can heve a return value:']], [[' DECLARE @ResultOfTheFirstQuery nvarchar(max)\n\nSELECT @ResultOfTheFirstQuery = (Select Top(1)RequiredQuery \n                                 as ReqQry from EPMaster)\n\nexec sp_executeSql @ResultOfTheFirstQuery\n']], ['Execute a result in  SQL Server using a stored procedure'], 2, 1], [(12386646, 1), [['Or if you need a complex logic, you can write an other SP, which can heve a return value:'], ['Here is an already  well answered question  how to get the paramater return. You can use  RETURN  or  OUTPUT  parameter.']], [[' DECLARE @ResultOfTheFirstQuery nvarchar(max)\n\nSELECT @ResultOfTheFirstQuery = FirstStoredprocedure @params\n\nexec sp_executeSql @ResultOfTheFirstQuery\n']], ['Execute a result in  SQL Server using a stored procedure'], 2, 1], [(12407247, 0), [['Only by being slightly silly:'], ['You might also want to consider retrieving both result sets in one go, rather than doing two calls:']], [[" CREATE PROCEDURE [dbo].[TopVRM]\n@orderby varchar(255)\nAS\nSELECT Peroid1.Pareto FROM dbo.Peroid1\nGROUP by Pareto\nORDER by CASE WHEN @orderby='ASC' THEN Pareto END,\n         CASE WHEN @orderby='DESC' THEN Pareto END DESC\n"]], ['SQL stored procedure passing parameter into "order by"'], 2, 1], [(12419421, 0), [['--To get all the columns from locatie table'], ['--To get all the columns from persooninfo table']], [[' select l.* from   locatie l\njoin   persooninfo p\non     l.id=p.id_p\n']], ['[FIXED]From 2 mySQL databases, to one'], 3, 0], [(12419421, 1), [['--To get all the columns from persooninfo table'], ['----To get all the columns from persooninfo and locatie  table']], [[' select l.* from   locatie l\njoin   persooninfo p\non     l.id=p.id_p\n']], ['[FIXED]From 2 mySQL databases, to one'], 3, 0], [(12419421, 2), [['----To get all the columns from persooninfo and locatie  table'], ['-10000']], [[' select * from   locatie l\njoin   persooninfo p\non     l.id=p.id_p\n']], ['[FIXED]From 2 mySQL databases, to one'], 3, 1], [(12419854, 1), [['then run that script.  You might want to add'], ['to specify an exact list of tables for extra piece of mind.']], [[" AND table_name IN ('MY_TAB1','MY_TAB2')\n"]], ['Dropping the same column name from mutiple tables in Oracle'], 2, 0], [(12456897, 0), [['I think this is enough:    '], ['or if you want to have the conditions separated, so you can build more complex queries easier:']], [[" SELECT candidate_id \nFROM actions_log AS a\nWHERE job_id = 1858 \n  AND ( action = 'a'  \n     OR action = 'b' \n    AND EXISTS \n        ( SELECT candidate_id \n          FROM actions_log \n          WHERE job_id = a.job_id\n            AND action = 'c'\n        )\n      ) ;\n"]], ['MySQL: same field value in multiple UNION'], 2, 1], [(12456897, 1), [['or if you want to have the conditions separated, so you can build more complex queries easier:'], ['-10000']], [["     SELECT candidate_id \n    FROM actions_log AS a\n    WHERE job_id = 1858 \n      AND action = 'a'  \nUNION DISTINCT\n    SELECT b.candidate_id \n    FROM actions_log AS b\n      JOIN actions_log AS c\n        ON  c.candidate_id = b.candidate_id\n        AND c.job_id = b.job_id\n    WHERE b.job_id = 1858 \n      AND b.action = 'b'\n      AND c.action = 'c' ;\n"]], ['MySQL: same field value in multiple UNION'], 2, 1], [(12463628, 0), [['Final Query'], ['First, inner select, this applies a mock  row_number  to all of the records in your table (See  SQL Fiddle with Demo ):']], [[' select data, group_row_number, overall_row_num\nfrom\n(\n  select data,\n        @num := if(@data = `data`, @num + 1, 1) as group_row_number,\n        @data := `data` as dummy, overall_row_num\n  from\n  (\n    select data, @rn:=@rn+1 overall_row_num\n    from yourtable, (SELECT @rn:=0) r\n  ) x\n  order by data, overall_row_num\n) x\norder by overall_row_num\n']], ['MySQL - Get a counter for each duplicate value'], 4, 1], [(12463628, 1), [['First, inner select, this applies a mock  row_number  to all of the records in your table (See  SQL Fiddle with Demo ):'], ["Second part of the query, compares each row in your table to the next one to see if it has the same value, if it doesn't then start the  group_row_number  over (see  SQL Fiddle with Demo ):"]], [[' select data, @rn:=@rn+1 overall_row_num\nfrom yourtable, (SELECT @rn:=0) r\n']], ['MySQL - Get a counter for each duplicate value'], 4, 0], [(12463628, 2), [["Second part of the query, compares each row in your table to the next one to see if it has the same value, if it doesn't then start the  group_row_number  over (see  SQL Fiddle with Demo ):"], ['The last select, returns the values you want and places them back in the order you requested:']], [[' select data,\n      @num := if(@data = `data`, @num + 1, 1) as group_row_number,\n      @data := `data` as dummy, overall_row_num\nfrom\n(\n  select data, @rn:=@rn+1 overall_row_num\n  from yourtable, (SELECT @rn:=0) r\n) x\norder by data, overall_row_num\n']], ['MySQL - Get a counter for each duplicate value'], 4, 0], [(12463628, 3), [['The last select, returns the values you want and places them back in the order you requested:'], ['-10000']], [[' select data, group_row_number, overall_row_num\nfrom\n(\n  select data,\n        @num := if(@data = `data`, @num + 1, 1) as group_row_number,\n        @data := `data` as dummy, overall_row_num\n  from\n  (\n    select data, @rn:=@rn+1 overall_row_num\n    from yourtable, (SELECT @rn:=0) r\n  ) x\n  order by data, overall_row_num\n) x\norder by overall_row_num\n']], ['MySQL - Get a counter for each duplicate value'], 4, 0], [(12498046, 0), [['See  SQL Fiddle'], ['gets']], [[' SELECT T.*\nFROM T\nWHERE NOT EXISTS (\n  SELECT * \n  FROM T AS _T\n  WHERE _T.conversation_id = T.conversation_id\n  AND (\n    _T.date_created > T.date_created\n    OR\n    _T.date_created = T.date_created AND _T.id > T.id) \n)\nORDER BY T.date_created DESC\n']], ['SQL - get latest records from table where field is unique'], 2, 1], [(12498046, 1), [['gets'], ['-10000']], [[' ID      STATUS  CONVERSATION_ID   MESSAGE_ID    DATE_CREATED\n3         2         2                95         May, 05 2012 \n2         2         1                87         March, 03 2012 \n']], ['SQL - get latest records from table where field is unique'], 2, 0], [(12527563, 0), [['Another solution is preparing a lookup table containing sums you need (but there obviously needs to be some grouping ID, I call it  MASTER_ID ), like that:'], ['Also create an index on that table on column  MASTER_ID . Later, you can modify your query like that:']], [[' CREATE TABLE comm_lkp AS\nSELECT MASTER_ID, SUM(commentsCount) as cnt\nFROM mycontents\nGROUP BY MASTER_ID\n']], ['it is possible to "group by" without losing the original rows?'], 2, 0], [(12527563, 1), [['Also create an index on that table on column  MASTER_ID . Later, you can modify your query like that:'], ["It also shouldn't touch your performance as long as lookup table will be relatively small."]], [[' SELECT\n    ...,\n    commentsCount,\n    cnt as commentsSum\nFROM\n    mycontents as a\n        JOIN comm_lkp as b ON (a.MASTER_ID=b.MASTER_ID)\nWHERE\n    name LIKE "%mysql%"\n']], ['it is possible to "group by" without losing the original rows?'], 2, 0], [(12530027, 0), [['You could change the default filegroup before the  select into , and reset it after:'], ['This prints:']], [[" select 41 as i into newtable1\nalter database test modify filegroup [secondary] default\nselect 41 as i into newtable2\nalter database test modify filegroup [primary] default\n\nselect  t.name as TableName\n,       f.name as Filegroup\nfrom    sys.tables t\njoin    sys.indexes i\non      t.object_id = i.object_id\njoin    sys.filegroups f\non      f.data_space_id = i.data_space_id\nwhere   t.name like 'newtable%'\n"]], ['Duplicate table and move it to different filegroup'], 2, 1], [(12530027, 1), [['This prints:'], ['-10000']], [[' TableName   Filegroup\nnewtable1   PRIMARY\nnewtable2   SECONDARY\n']], ['Duplicate table and move it to different filegroup'], 2, 0], [(12544051, 1), [['EDIT: \nAfter seeing your comment about not having a need for a high performing single query to solve this problem (which I\'m not sure is even possible), and since it seems to be more of a "one-off" process that you will be calling, I wrote up the following code using a cursor and one temporary table to solve your problem of assignments:'], ['The basic idea is, that it iterates over the employees, in random order, and assigns to each one a random Place that meets the criteria of different home and current posting, as well as controlling the amount that get assigned to each place for each Designation to ensure that the locations are not "over-assigned" for each role.']], [[" select *, null NewPlaceID into #Employee from Employee\n\ndeclare @empNo int\nDECLARE emp_cursor CURSOR FOR  \nSELECT EmpNo from Employee order by newid()\n\nOPEN emp_cursor   \nFETCH NEXT FROM emp_cursor INTO @empNo\n\nWHILE @@FETCH_STATUS = 0   \nBEGIN\n    update #Employee \n    set NewPlaceID = \n        (\n        select top 1 p.PlaceID from Place p \n        where \n            p.PlaceName != #Employee.Home AND \n            p.PlaceName != #Employee.CurrentPosting AND\n            (\n                CASE #Employee.Designation \n                WHEN 'Manager' THEN p.Manager\n                WHEN 'PO' THEN p.PO\n                WHEN 'Clerk' THEN p.Clerk\n                END\n            ) > (select count(*) from #Employee e2 where e2.NewPlaceID = p.PlaceID AND e2.Designation = #Employee.Designation)\n        order by newid()\n        ) \n    where #Employee.EmpNo = @empNo\n    FETCH NEXT FROM emp_cursor INTO @empNo   \nEND\n\nCLOSE emp_cursor\nDEALLOCATE emp_cursor\n\nselect e.*, p.PlaceName as RandomPosting from Employee e\ninner join #Employee e2 on (e.EmpNo = e2.EmpNo)\ninner join Place p on (e2.NewPlaceID = p.PlaceID)\n\ndrop table #Employee\n"]], ['Randomly assign work location and each location should not exceed the number of designated employees'], 2, 1], [(12579635, 0), [['try this:'], ['EDIT : This is based on the first comment for this answer']], [[" INSERT NewDB.center_has_b (center_id, b_id)\n select 'N', oldb_id from OldDB.oldb WHERE centerN = 1\n"]], ['MySQL: Migrating data into a many to many relationship from an OldDB plain table'], 2, 0], [(12579635, 1), [['EDIT : This is based on the first comment for this answer'], ['-10000']], [[" insert into center_has_b (center_id,b_id)\nselect c.enter_id ,old.b_id\nfrom centers c\ncross join old.b\nwhere Allcenters = 'Y'\n"]], ['MySQL: Migrating data into a many to many relationship from an OldDB plain table'], 2, 1], [(12590682, 1), [['Then to query, you would use something like this:'], ['-10000']], [[' select *\nfrom users u\nleft join users_events ue\n    on u.id = ue.u_id\nleft join events e\n    on ue.e_id = e.id;\n']], ['MySQL database design: User and event table'], 2, 0], [(12593776, 1), [['According to your updates:'], ['SQLFiddle']], [[" select *\n  from order_information oi\n   left join mass_decode md \n     on oi.color_cd = md.cd\nwhere md.key = 'COLOR_CD' or md.key is null;\n"]], ['Oracle SQL: Joining another table with one missing tuple'], 2, 1], [(12698945, 0), [['You can use a subquery:'], ['or you can use  CTE  using  row_number() :']], [[' select t1.asset_no,\n  t1.sub,\n  t1.add_dtm\nfrom table1 t1\ninner join\n(\n  select max(add_dtm) mxdate, asset_no\n  from table1\n  group by asset_no\n) t2\n  on t1.add_dtm = t2.mxdate\n  and t1.asset_no = t2.asset_no\n']], ['sql oracle duplicates'], 3, 1], [(12698945, 1), [['or you can use  CTE  using  row_number() :'], ['Or without CTE using  row_number() :']], [[' with cte as\n(\n  select asset_no,\n    sub,\n    add_dtm,\n    row_number() over(partition by asset_no \n                      order by add_dtm desc) rn\n  from table1\n) \nselect *\nfrom cte\nwhere rn = 1\n']], ['sql oracle duplicates'], 3, 1], [(12698945, 2), [['Or without CTE using  row_number() :'], ['-10000']], [[' select *\nfrom \n(\n  select asset_no,\n    sub,\n    add_dtm,\n    row_number() over(partition by asset_no \n                      order by add_dtm desc) rn\n  from table1\n) x\nwhere rn = 1\n']], ['sql oracle duplicates'], 3, 1], [(12712480, 0), [['To find a value that contains non-printable characters such as carriage return or vertical tab or end of line you can use  regexp_like  function. In your case to display rows where a string value of a particular column contains carriage return at the end the similar query can be used.  '], ['Trim  function, by default, deletes leading and trailing spaces and it will not delete  carriage return  or  end of line  characters. Lets carry out a simple test:']], [[" select *\n  from your_table_name\n where regexp_like(trim(string_column), '[[:space:]]$')\n"]], ['SQL query to test if string value contains carriage return'], 2, 1], [(12712480, 1), [['Trim  function, by default, deletes leading and trailing spaces and it will not delete  carriage return  or  end of line  characters. Lets carry out a simple test:'], ['-10000']], [[" SQL> create table Test_Table(\n  2    id number,\n  3    col1 varchar2(101)\n  4  );\n\nTable created\n\nSQL> insert into Test_Table (id, col1)\n  2    values(1, 'Simple string');\n\n1 row inserted\n\nSQL> commit;\n\nCommit complete\n\nSQL> insert into Test_Table (id, col1)\n  2    values(1, 'Simple string with carriage return at the end' || chr(13));\n\n1 row inserted\n\nSQL> commit;\n\nCommit complete\n\nSQL> insert into Test_Table (id, col1)\n  2    values(1, '   Simple string with carriage return at the end leading and trailing spaces' || chr(13)||'   ');\n\n1 row inserted\n\nSQL> commit;\n\nCommit complete\n\nSQL> insert into Test_Table (id, col1)\n  2    values(1, '  Simple string leading and trailing spaces  ');\n\n1 row inserted\n\nSQL> commit;\n\nCommit complete\n\nSQL> select *\n  2    from test_table;\n\n        ID COL1\n--------------------------------------------------------------------------------\n         1 Simple string\n         1 Simple string with carriage return at the end\n         1    Simple string with carriage return at the end leading and trailing spaces\n         1   Simple string leading and trailing spaces\n\nSQL> \nSQL> select *\n  2    from test_table\n  3   where regexp_like(trim(col1), '[[:space:]]$')\n  4  ;\n\n        ID COL1\n----------------------------------------------------------------------------------\n         1 Simple string with carriage return at the end\n         1    Simple string with carriage return at the end leading and trailing spaces\n\nSQL> \n"]], ['SQL query to test if string value contains carriage return'], 2, 0], [(12713468, 1), [['Some DBs will allow you to build up a table "in-place", instead of having to create a separate table.  E.g. in PostgreSQL (any version):'], ['More modern versions of PostgreSQL (and perhaps other DBs) will let you use the slightly nicer  VALUES  syntax to do the same thing.']], [[" SELECT *\nFROM (\n    SELECT 'foo'\n    UNION ALL SELECT 'bar'\n    UNION ALL SELECT 'baz'    -- etc.\n) inplace_allowed\nWHERE inplace_allowed.val NOT IN (\n    SELECT maintable.val\n)\n"]], ['Can SQL determine which values from a set of possible column values do not exist?'], 2, 1], [(12730070, 0), [['You are trying to  PIVOT  the data but MySQL does not have a  PIVOT  function. Also to make this easier, you will want to partition the data based on the  degerAdi  value to apply a rownumber.  If you have a known number of columns, then you can use:'], ['If you have an unknown number of columns then you will want to use prepared statements:']], [[" select rn,\n  max(case when DEGERADI = 'asd' then DEGER end) asd,\n  max(case when DEGERADI = 'rty' then DEGER end) rty,\n  max(case when DEGERADI = 'hhh' then DEGER end) hhh,\n  max(case when DEGERADI = 'hjh' then DEGER end) hjh,\n  max(case when DEGERADI = 'ffgu' then DEGER end) ffgu,\n  max(case when DEGERADI = 'qwe' then DEGER end) qwe\nfrom\n(\n  select id, degerAdi, deger,\n   @num := if(@degerAdi = `degerAdi`, @num + 1, 1) as rn,\n   @degerAdi := `degerAdi` as dummy\n  from table1\n) x\ngroup by rn;\n"]], ['I need a way to use column values as column names in MySQL'], 2, 1], [(12730070, 1), [['If you have an unknown number of columns then you will want to use prepared statements:'], ['See  SQL Fiddle with demo']], [[" SET @sql = NULL;\nSELECT\n  GROUP_CONCAT(DISTINCT\n    CONCAT(\n      'max(case when degerAdi = ''',\n      degerAdi,\n      ''' then deger end) AS ',\n      degerAdi\n    )\n  ) INTO @sql\nFROM Table1;\n\nSET @sql \n  = CONCAT('SELECT rn, ', @sql, ' \n           from\n           (\n             select id, degerAdi, deger,\n              @num := if(@degerAdi = `degerAdi`, @num + 1, 1) as rn,\n              @degerAdi := `degerAdi` as dummy\n             from table1\n           ) x\n           group by rn');\n\nPREPARE stmt FROM @sql;\nEXECUTE stmt;\nDEALLOCATE PREPARE stmt;\n"]], ['I need a way to use column values as column names in MySQL'], 2, 1], [(12773500, 0), [['As mentioned the SQL appears fine.  I ran a quick test here with the following:'], ['This gives the below result set:']], [[' create table #temp\n(num int)\n\ninsert #temp\nselect 1 union all\nselect 1 union all\nselect 1 union all\nselect 2 union all\nselect 3 \n\nselect Num, COUNT(num) as Occurances from #temp group by num\n\ndrop table #temp\n']], ['SQLite count ocurrences in row'], 2, 1], [(12773500, 1), [['This gives the below result set:'], ['Compare the above to your whole code, including the table creation etc.']], [[' Num Occurances\n1       3\n2       1\n3       1\n']], ['SQLite count ocurrences in row'], 2, 0], [(12783579, 0), [["To demonstrate, if I create a dummy table with just a CLOB column, and populate it with a value that has the carriage return/linefeed you're looking for:"], ['I get:']], [[" create table t42(text clob);\n\ninsert into t42 values ('Hello Mr. X' || CHR(13) || CHR(10)\n    || CHR(13) || CHR(10)\n    || 'Text from Mailboddy' || CHR(13) || CHR(10)\n    || CHR(13) || CHR(10)\n    || 'Greetins' || CHR(13) || CHR(10)\n    || 'Mr. Y');\n\nselect * from t42;\n"]], ['Read file with multiple empty lines from ORACLE DB with BASH'], 6, 0], [(12783579, 1), [['I get:'], ['Using your procedure (very slightly modified so it will run):']], [[' TEXT\n--------------------------------------------------------------------------------\nHello Mr. X\n\nText from Mailboddy\n\nGreetins\nMr. Y\n']], ['Read file with multiple empty lines from ORACLE DB with BASH'], 6, 0], [(12783579, 3), [['file  contains:'], ['If I only change one line in your code, to:']], [[' Hello Mr. X\nText from Mailboddy\nGreetins\nMr. Y\n']], ['Read file with multiple empty lines from ORACLE DB with BASH'], 6, 0], [(12783579, 4), [['If I only change one line in your code, to:'], ['then  file  now contains:']], [[' SET SERVEROUTPUT ON FORMAT WRAPPED;\n']], ['Read file with multiple empty lines from ORACLE DB with BASH'], 6, 0], [(12783579, 5), [['then  file  now contains:'], ['-10000']], [[' Hello Mr. X\n\nText from Mailboddy\n\nGreetins\nMr. Y\n']], ['Read file with multiple empty lines from ORACLE DB with BASH'], 6, 0], [(12815194, 0), [['Try to use  union all'], ['but if you wont to add header, and if  DOCID   is  int  type, you have to use  union all  and  cast  as below']], [[' SELECT null as PROFILETITLE, null as DOCID \nUNION ALL\nSELECT PROFILETITLE, DOCID \nFROM PROFILES\nWHERE COMPANYCODE=? \nORDER BY PROFILETITLE\n']], ['Selecting an additional empty row that does not exist'], 2, 1], [(12815194, 1), [['but if you wont to add header, and if  DOCID   is  int  type, you have to use  union all  and  cast  as below'], ['-10000']], [[" SELECT 'PROFILETITLE' as PROFILETITLE, 'DOCID' as DOCID \nUNION ALL\nSELECT PROFILETITLE, CAST ( DOCID AS varchar(30) )\nFROM PROFILES\nWHERE COMPANYCODE=? \nORDER BY PROFILETITLE\n"]], ['Selecting an additional empty row that does not exist'], 2, 1], [(12818621, 0), [['Assuming your starting table is named  plop'], ['That returns:']], [[' SELECT\n  plop.id,\n  CASE\n    WHEN plop.type = 1 THEN (SELECT array_agg(plop.entry * plop.size * val.x) FROM (VALUES (0.5), (0.3), (0.2)) val (x))::int4[]\n    WHEN plop.type = 2 THEN (SELECT array_agg(3 * plop.entry * x/x ) FROM generate_series(1, plop.size / 3) x)::int4[]\n    ELSE ARRAY[plop.entry * plop.size]::int4[]\n  END AS prize_pool\nFROM plop\n;\n']], ['Postgresql. Create array inside select query'], 2, 1], [(12818621, 1), [['That returns:'], ['Because  entry x size / ( size / 3 ) = 3 x entry']], [[' ┌────┬──────────────────┐                                                                                                                                                                                       \n│ id │    prize_pool    │                                                                                                                                                                                       \n├────┼──────────────────┤                                                                                                                                                                                       \n│  1 │ {100}            │                                                                                                                                                                                       \n│  2 │ {200}            │                                                                                                                                                                                       \n│  3 │ {150,90,60}      │                                                                                                                                                                                       \n│  4 │ {90,90,90,90,90} │                                                                                                                                                                                       \n└────┴──────────────────┘\n']], ['Postgresql. Create array inside select query'], 2, 0], [(12823575, 0), [['If you can accept CSV instead of tabulated results, you could simply group the table twice:'], ['Otherwise, you can join the above subquery to itself:']], [[' SELECT GROUP_CONCAT(User) FROM (\n  SELECT   User, GROUP_CONCAT(DISTINCT `Show` ORDER BY `Show` SEPARATOR 0x1e) AS s\n  FROM     Shows\n  GROUP BY User\n) t GROUP BY s\n']], ['How do I find pairs that share the one property (column) through multiple tuples (rows)?'], 2, 1], [(12823575, 1), [['Otherwise, you can join the above subquery to itself:'], ['See them on  sqlfiddle .']], [[' SELECT DISTINCT LEAST(t.User, u.User) AS User1,\n             GREATEST(t.User, u.User) AS User2\nFROM (\n  SELECT   User, GROUP_CONCAT(DISTINCT `Show` ORDER BY `Show` SEPARATOR 0x1e) AS s\n  FROM     Shows\n  GROUP BY User\n) t JOIN (\n  SELECT   User, GROUP_CONCAT(DISTINCT `Show` ORDER BY `Show` SEPARATOR 0x1e) AS s\n  FROM     Shows\n  GROUP BY User\n) u USING (s)\nWHERE t.User <> u.User\n']], ['How do I find pairs that share the one property (column) through multiple tuples (rows)?'], 2, 1], [(12839031, 0), [['This example works for me'], ['solution with  varchar(15)']], [[" declare @val float\ndeclare @val2 float\nselect @val = 17.666655942234 \nselect @val2 = 17.66\nselect substring(convert(varchar(30),@val), 1, patindex('%.%',convert(varchar(30),@val)))+reverse(convert(varchar(30),convert(int,reverse(substring(convert(varchar(30),@val), patindex('%.%',convert(varchar(30),@val))+1,6))))) as Val,\n       substring(convert(varchar(30),@val2), 1, patindex('%.%',convert(varchar(30),@val2)))+reverse(convert(varchar(30),convert(int,reverse(substring(convert(varchar(30),@val2), patindex('%.%',convert(varchar(30),@val2))+1,6))))) as Val2\n"]], ['Sybase convert float to string'], 2, 1], [(12839031, 1), [['solution with  varchar(15)'], ['-10000']], [[" declare @val numeric(10,5)\ndeclare @val2 numeric(10,5)\nselect @val = convert(numeric(10,5),17.666655942234)\nselect @val2 = convert(numeric(10,5),17.66)\nselect convert(varchar(15),substring(convert(varchar(15),@val), 1, patindex('%.%',convert(varchar(15),@val)))+reverse(convert(varchar(15),convert(int,reverse(substring(convert(varchar(15),@val), patindex('%.%',convert(varchar(15),@val))+1,6)))))) as Val,\n       convert(varchar(15),substring(convert(varchar(15),@val2), 1, patindex('%.%',convert(varchar(15),@val2)))+reverse(convert(varchar(15),convert(int,reverse(substring(convert(varchar(15),@val2), patindex('%.%',convert(varchar(15),@val2))+1,6)))))) as Val2\n"]], ['Sybase convert float to string'], 2, 1], [(12849213, 0), [['Assuming that  Date  is stored as you show on the expected result this should work:'], ['Otherwise id  Date  is of type  DATE ,  DATETIME  or  TIMESTAMP  you could do something like this:']], [[' SELECT\n   SUM(Amount) AS "Profit/Loss",\n   Date\nFROM your_table\nGROUP BY(Date)\n']], ['MySQL query to return total Profit/Loss for a list of dates'], 3, 1], [(12849213, 1), [['Otherwise id  Date  is of type  DATE ,  DATETIME  or  TIMESTAMP  you could do something like this:'], ['to achieve the comulative SUM  here  is a good hint:']], [[' SELECT\n   SUM(Amount) AS "Profit/Loss",\n   DATE_FORMAT(Date, \'%d-%m-%y\') AS Date\nFROM your_table\nGROUP BY(DATE_FORMAT(Date, \'%d-%m-%y\'))\n']], ['MySQL query to return total Profit/Loss for a list of dates'], 3, 1], [(12849213, 2), [['to achieve the comulative SUM  here  is a good hint:'], ['essentialy you store the current sum into a variable (@csum) and for each row of the grouped transactions you increase it by the daily balance']], [[" SET @csum := 0;\nSELECT\n   (@csum := @csum + x.ProfitLoss) as ProfitLoss,\n   x.Date\nFROM\n(\n   SELECT\n      SUM(Amount) AS ProfitLoss,\n      DATE_FORMAT(Date, '%d-%m-%y') AS Date\n   FROM your_table\n   GROUP BY(DATE_FORMAT(Date, '%d-%m-%y'))\n) x\norder by x.Date;\n"]], ['MySQL query to return total Profit/Loss for a list of dates'], 3, 1], [(12870094, 0), [['So, the  COUNT  function does not count  NULL  so use  COUNT(*)  instead of  COUNT(y) .'], ['Or you can also use  COUNT(x)  like this one.']], [[' SELECT y, COUNT(*) AS COUNT\nFROM mytable\nGROUP BY y\n']], ['How can I group by on a field which has NULL values?'], 2, 1], [(12875040, 1), [['Building on that, you want to take that list of tags and find other parent_ids that share them.'], ['That will give you a count of how many tags those other parent_ids share.']], [['  SELECT parent_id, count(*)\n FROM tags t2\n WHERE EXISTS (\n     SELECT t1.id\n     FROM tags t1\n     WHERE t1.parent_id = ?\n     AND t1.id = t2.id\n )\n GROUP BY parent_id\n']], ['Find similar objects that share the most tags'], 2, 1], [(12879550, 0), [["You're basically just missing a status comparison since you want one row per status;"], ['or rewritten as a  JOIN ;']], [[" SELECT *\nFROM WF_Approval sr1\nWHERE NOT EXISTS (\n    SELECT *\n    FROM  WF_Approval sr2 \n    WHERE sr1.DocumentID = sr2.DocumentID AND \n          sr1.Status = sr2.Status AND                  # <-- new line\n          sr1.StepNumber < sr2.StepNumber\n) AND MasterStepID = 'Approval1'\n"]], ['How to select row with max value when duplicate rows exist in SQL Server'], 2, 1], [(12879550, 1), [['or rewritten as a  JOIN ;'], ['SQLfiddle with both versions of the query here .']], [[" SELECT *\nFROM WF_Approval sr1\nLEFT JOIN WF_Approval sr2\n  ON sr1.DocumentID = sr2.DocumentID \n AND sr1.Status = sr2.Status\n AND sr1.StepNumber < sr2.StepNumber\nWHERE sr2.DocumentID IS NULL\n  AND sr1.MasterStepID = 'Approval1';\n"]], ['How to select row with max value when duplicate rows exist in SQL Server'], 2, 1], [(12899727, 0), [['-10000'], ['to get all records from table  A  that are not in table  B . Or']], [[' select X\nfrom A\nLEFT OUTER JOIN B on A.x = B.X\nWHERE B.X IS NULL\n']], ['SQL - Check if all the columns in one table also exist in another'], 2, 1], [(12899727, 1), [['to get all records from table  A  that are not in table  B . Or'], ['to get all records from table  B  that are not in table  A .']], [[' select X\nfrom B\nLEFT OUTER JOIN A on A.x = B.X\nWHERE A.X IS NULL\n']], ['SQL - Check if all the columns in one table also exist in another'], 2, 1], [(12951673, 0), [['You might think you could declare your own PL/SQL (sub)type and use that in the statement:'], ['As a nasty hack, you could do something like:']], [[' declare\n    subtype my_type is t1.v%type;\nbegin\n    insert into t1 select cast(v as my_type) from t2;\nend;\n/\n']], ['Oracle Cast using %TYPE attribute'], 3, 0], [(12989520, 0), [['Try this one,'], ['-10000']], [[" update tab \nset mytext = concat('text none, ', Replace(mytext, 'text none',''));\n"]], ['Update text of column'], 2, 1], [(12989520, 1), [['-10000'], ['-10000']], [[" update tab \nset mytext = Replace(mytext, 'text none','text none, ');\n"]], ['Update text of column'], 2, 1], [(13003656, 0), [['Use a  HAVING  clause to filter an aggregated column.'], ['wrap the results in a subquery']], [[' SELECT   id, count(oID) \nFROM     MyTable \nGROUP BY oID \nHAVING   count(oID) = 1\n']], ['SQL GROUP BY and a condition on COUNT'], 2, 1], [(13003656, 1), [['wrap the results in a subquery'], ['-10000']], [[' SELECT a.*\nFROM tableName a INNER JOIN\n    (\n        SELECT   id \n        FROM     MyTable \n        GROUP BY id  \n        HAVING   count(oID) = 1\n    ) b ON a.ID = b.ID\n']], ['SQL GROUP BY and a condition on COUNT'], 2, 1], [(13024512, 0), [['If you want to show  all  regions, and within each region to count the number with populations greater than 10 million, then probably this is easiest:'], ['From your comments to @Yograj Gupta question - if you want regions where  all  countries have populations > 10000000, then you can either modify the above:']], [[' SELECT region, SUM(CASE WHEN population > 10000000 THEN 1 ELSE 0 END) as BigCountries\nFROM bbc\nGROUP BY region\n']], ['How to return requested results?'], 3, 1], [(13024512, 1), [['From your comments to @Yograj Gupta question - if you want regions where  all  countries have populations > 10000000, then you can either modify the above:'], ['Or just exploit a simpler property:']], [[' SELECT region, COUNT(*) as Cnt,SUM(CASE WHEN population > 10000000 THEN 1 ELSE 0 END) as BigCountries\nFROM bbc\nGROUP BY region\nHAVING COUNT(*) = SUM(CASE WHEN population > 10000000 THEN 1 ELSE 0 END)\n']], ['How to return requested results?'], 3, 1], [(13024512, 2), [['Or just exploit a simpler property:'], ['where the minimum population for any country in the region is > 10000000, then all countries must have a population > 10000000']], [[' SELECT region, COUNT(*) as Cnt,MIN(population) as LowestPop\nFROM bbc\nGROUP BY region\nHAVING MIN(population) > 10000000\n']], ['How to return requested results?'], 3, 1], [(13054785, 0), [['Okay the query should look like this, to update items 1,2,3,4:'], ['It can however be done using  Linq :']], [['  UPDATE Items\n SET bitIsTab = 1\n WHERE ReqID IN (1,2,3,4);\n']], ['How to update selective rows in a table in sql server?'], 6, 1], [(13054785, 3), [['To execute the stored procedure:'], ['Could also be done in a more reusable way, with the  bitIsTab  as a parameter:']], [["  EXEC sp_setTabItems '1,2,3,4'\n"]], ['How to update selective rows in a table in sql server?'], 6, 0], [(13054785, 4), [['Could also be done in a more reusable way, with the  bitIsTab  as a parameter:'], ['And executed this way:']], [[" CREATE PROCEDURE sp_setTabItems\n    @isTab bit,\n    @ids varchar(500) AS\n UPDATE Items\n SET bitIsTab = @isTab \n WHERE charindex(',' + ReqID + ',', ',' + @ids + ',') > 0;\n"]], ['How to update selective rows in a table in sql server?'], 6, 1], [(13054785, 5), [['And executed this way:'], ["I updated the stored procedure solution, since comparing a  INT  with a  VARCHAR  won't work  with the  EXEC ."]], [[" EXEC sp_setTabItems '1,2,3,4',1\n"]], ['How to update selective rows in a table in sql server?'], 6, 0], [(13055295, 0), [['You can try this'], ['SQL FIDDLE EXAMPLE']], [[' select\n    td.DocID, td.FullName, td.DocContRole,\n    row_number() over (partition by td.DocID, td.DocContRole order by td.FullName) as NumRole\nfrom dbo.#TempDoc_DocContRoles as td\n']], ['Increment value in SQL SELECT statement'], 2, 1], [(13068001, 0), [['This query will sequentially take the values from the  temp  table and update the code in the example table in round robin fashion, repeating the values from  temp  when required.'], ['If the ids are not sequential in either table, then you can  row_number()  them first, e.g.']], [[' update e\nset code = t.code\nfrom example e\njoin temp t on t.id = (e.id -1) % (select count(*) from temp) + 1\n']], ['update each row with different values in temp table'], 2, 1], [(13068001, 1), [['If the ids are not sequential in either table, then you can  row_number()  them first, e.g.'], ['The same technique (mod, row-number) can be used in other RDBMS, but the syntax will differ a little.']], [[' update e\nset code = t.code\nfrom (select *,rn=row_number() over (order by id) from example) e\njoin (select *,rn=row_number() over (order by id) from temp) t\n  on t.rn = (e.rn -1) % (select count(*) from temp) + 1\n']], ['update each row with different values in temp table'], 2, 1], [(13069202, 0), [['I think you should be able to do:'], ['If only part of the regexp comes from the placeholder, use string concatenation:']], [[' select id_name from name_table where regexp_like(name, ?);\n']], ['Regexp_like with placeholders perl'], 2, 1], [(13080106, 1), [['otherwise, if you have multiple number of cache, you can use  Prepared Statement'], ['-10000']], [[" SET @sql = NULL;\nSELECT\n  GROUP_CONCAT(DISTINCT\n    CONCAT(\n      'SUM(CASE WHEN cached =  ''',\n      cached,\n      ''' then 1 ELSE 0 end) AS ',\n      CONCAT('cached_',cached)\n    )\n  ) INTO @sql\nFROM requests;\n\nSET @sql = CONCAT('SELECT DATE(datetime) as datetime, ', @sql, ' \n                   FROM requests \n                   GROUP BY DAY(datetime)');\n\nPREPARE stmt FROM @sql;\nEXECUTE stmt;\nDEALLOCATE PREPARE stmt;\n"]], ['How to combine these queries that group by the same field?'], 2, 1], [(13096793, 0), [['-10000'], ["MySQL doesn't support FULL JOIN, so specifically for MySQL, you can use"]], [['     SELECT COALESCE(o.date, p.date) date, Sales, Purchases\n      FROM (SELECT date, SUM(amount) Sales FROM CustomerOrder GROUP BY date) o\n FULL JOIN (SELECT date, SUM(amount) Purchases FROM PurchaseOrder GROUP BY date) p\n        ON o.date = p.date\n  ORDER BY date\n']], ['SQL query to get total amount from 2 table and sort by date'], 2, 1], [(13096793, 1), [["MySQL doesn't support FULL JOIN, so specifically for MySQL, you can use"], ['-10000']], [['     SELECT o.date, Sales, Purchases\n      FROM (SELECT date, SUM(amount) Sales FROM CustomerOrder GROUP BY date) o\n LEFT JOIN (SELECT date, SUM(amount) Purchases FROM PurchaseOrder GROUP BY date) p\n        ON o.date = p.date\n UNION ALL\n    SELECT date, NULL, SUM(amount) Purchases\n      FROM PurchaseOrder p2\n     WHERE NOT EXISTS (SELECT *\n                       FROM CustomerOrder o2\n                       WHERE o2.date = p2.date)\n  GROUP BY date\n  ORDER BY date\n']], ['SQL query to get total amount from 2 table and sort by date'], 2, 1], [(13103114, 0), [["It's easy to do this without  PIVOT  keyword, just by grouping"], ['you can also do this with  PIVOT  keyword']], [[" select\n    P.ProfileID,\n    min(case when PD.PropertyName = 'FirstName' then P.PropertyValue else null end) as FirstName,\n    min(case when PD.PropertyName = 'LastName' then P.PropertyValue else null end) as LastName,\n    min(case when PD.PropertyName = 'Salary' then P.PropertyValue else null end) as Salary\nfrom Profiles as P\n    left outer join PropertyDefinitions as PD on PD.PropertyDefinitionID = P.PropertyDefinitionID\ngroup by P.ProfileID\n"]], ['T:SQL: select values from rows as columns'], 2, 1], [(13103114, 1), [['you can also do this with  PIVOT  keyword'], ['UPDATE : For dynamic number of properties - take a look at  Increment value in SQL SELECT statement']], [[' select\n    *\nfrom\n(\n    select P.ProfileID, P.PropertyValue, PD.PropertyName\n    from Profiles as P\n        left outer join PropertyDefinitions as PD on PD.PropertyDefinitionID = P.PropertyDefinitionID\n) as P\n    pivot\n    (\n        min(P.PropertyValue)\n        for P.PropertyName in ([FirstName], [LastName], [Salary])\n    ) as PIV\n']], ['T:SQL: select values from rows as columns'], 2, 1], [(13110356, 0), [['Partitioning in postgresql works great for big logs. First create the parent table:'], ['Now create the partitions. In this case one for each month, 900 k rows, would be good:']], [[' create table  game_history_log (\n    gameid integer,\n    views integer,\n    plays integer,\n    likes integer,\n    log_date date\n);\n']], ['Best way to store huge log data'], 4, 0], [(13110356, 1), [['Now create the partitions. In this case one for each month, 900 k rows, would be good:'], ['Notice the check constraints in each partition. If you try to insert in the wrong partition:']], [[" create table game_history_log_201210 (\n    check (log_date between '2012-10-01' and '2012-10-31')\n) inherits (game_history_log);\n\ncreate table game_history_log_201211 (\n    check (log_date between '2012-11-01' and '2012-11-30')\n) inherits (game_history_log);\n"]], ['Best way to store huge log data'], 4, 0], [(13110356, 2), [['Notice the check constraints in each partition. If you try to insert in the wrong partition:'], ['One of the advantages of partitioning is that it will only search in the correct partition reducing drastically and consistently the search size regardless of how many years of data there is. Here the explain for the search for a certain date:']], [[' insert into game_history_log_201210 (\n    gameid, views, plays, likes, log_date\n) values (1, 2, 3, 4, \'2012-09-30\');\nERROR:  new row for relation "game_history_log_201210" violates check constraint "game_history_log_201210_log_date_check"\nDETAIL:  Failing row contains (1, 2, 3, 4, 2012-09-30).\n']], ['Best way to store huge log data'], 4, 0], [(13110356, 3), [['One of the advantages of partitioning is that it will only search in the correct partition reducing drastically and consistently the search size regardless of how many years of data there is. Here the explain for the search for a certain date:'], ['Notice that apart from the parent table it only scanned the correct partition. Obviously you can have indexes on the partitions to avoid a sequential scan.']], [[" explain\nselect *\nfrom game_history_log\nwhere log_date = date '2012-10-02';\n                                              QUERY PLAN                                              \n------------------------------------------------------------------------------------------------------\n Result  (cost=0.00..30.38 rows=9 width=20)\n   ->  Append  (cost=0.00..30.38 rows=9 width=20)\n         ->  Seq Scan on game_history_log  (cost=0.00..0.00 rows=1 width=20)\n               Filter: (log_date = '2012-10-02'::date)\n         ->  Seq Scan on game_history_log_201210 game_history_log  (cost=0.00..30.38 rows=8 width=20)\n               Filter: (log_date = '2012-10-02'::date)\n"]], ['Best way to store huge log data'], 4, 0], [(13128635, 1), [['For the sake of completeness this is how I would do it with a  LEFT JOIN :'], ['-10000']], [[" SELECT  *\nFROM    Users u\n        LEFT JOIN Banned b\n            ON b.UserID = u.UserID\nWHERE   u.IsActive = 1\nAND     u.Status <> 'disabled'\nAND     b.UserID IS NULL        -- EXCLUDE ROWS WITH A MATCH IN `BANNED`\n"]], ['Using a left join and checking if the row existed along with another check in where clause'], 2, 1], [(13144230, 0), [['You can create Views for things like this.'], ['Then you may run them:']], [[' create view vResult1 as\nselect your(\n         complicated(\n           query(\n             here()\n           )\n         )\n       );\n\ncreate view vResult2 as\nselect another(\n         complicated(\n           query(\n             here()\n           )\n         )\n       );\n']], ['Divisioning of results of two select SQL-statements'], 2, 0], [(13144230, 1), [['Then you may run them:'], ['If you need parameters for your complicated queries - you may use  stored procedures . ']], [[' select vResult1/vResult2;\n']], ['Divisioning of results of two select SQL-statements'], 2, 0], [(13159227, 0), [['The basic syntax will be:'], ['Hard-coded static version will be something similar to this:']], [[" select user,\n    sum(case when wrapupcode = 'Service' then 1 else 0 end) Service,\n    sum(case when wrapupcode = 'Sales' then 1 else 0 end) Sales,\n    sum(case when wrapupcode = 'Meeting' then 1 else 0 end) Meeting,\n    sum(case when wrapupcode = 'Other' then 1 else 0 end) Other,\n    count(timediff) timediff\nfrom\n(       \n    <yourquery>\n) src\ngroup by user\n"]], ['SQL Dynamic Columns'], 3, 1], [(13159227, 1), [['Hard-coded static version will be something similar to this:'], ['If you need a dynamic version, then you can use prepared statements:']], [[" select user,\n    sum(case when wrapupcode = 'Service' then 1 else 0 end) Service,\n    sum(case when wrapupcode = 'Sales' then 1 else 0 end) Sales,\n    sum(case when wrapupcode = 'Meeting' then 1 else 0 end) Meeting,\n    sum(case when wrapupcode = 'Other' then 1 else 0 end) Other,\n    count(timediff) timediff\nfrom\n(       \n    select u.loginid as user,\n        b.name wrapupcode,\n        time(age.`instime`) as initialtime,\n        age.`ENDOFWRAPUPTIME` AS endofwrapup,\n        count(timediff(age.`ENDOFWRAPUPTIME`,   time(age.`instime`))) as timediff\n    from agentcallinformation age\n    left join `axpuser` u\n        on age.userid = u.pkey\n    left join `breakcode` b\n        on age.wrapupcode = b.pkey\n        and age.wrapupcode <> ''\n    WHERE age.endofwrapuptime IS NOT null \n) src\ngroup by user\n"]], ['SQL Dynamic Columns'], 3, 1], [(13159227, 2), [['If you need a dynamic version, then you can use prepared statements:'], ['-10000']], [[" SET @sql = NULL;\nSELECT\n  GROUP_CONCAT(DISTINCT\n    CONCAT(\n      'sum(case when wrapupcode = ''',\n      name,\n      ''' then 1 else 0 end) AS ',\n      name\n    )\n  ) INTO @sql\nFROM breakcode;\n\nSET @sql = CONCAT('SELECT user, ', @sql, ' \n                    , count(timediff) timediff\n                  from\n                  (     \n                    select u.loginid as user,\n                        b.name wrapupcode,\n                        time(age.`instime`) as initialtime,\n                        age.`ENDOFWRAPUPTIME` AS endofwrapup,\n                        count(timediff(age.`ENDOFWRAPUPTIME`,   time(age.`instime`))) as timediff\n                    from agentcallinformation age\n                    left join `axpuser` u\n                        on age.userid = u.pkey\n                    left join `breakcode` b\n                        on age.wrapupcode = b.pkey\n                        and age.wrapupcode <> ''\n                    WHERE age.endofwrapuptime IS NOT null \n                ) src\n                GROUP BY user');\n\nPREPARE stmt FROM @sql;\nEXECUTE stmt;\nDEALLOCATE PREPARE stmt;\n"]], ['SQL Dynamic Columns'], 3, 1], [(13173833, 0), [['This should do it:'], ['With your revised data structure this should work:']], [[" SELECT  ID,\n        StudentID,\n        Mon,\n        MAX(CASE WHEN Type LIKE 'Obtained%' THEN Value END) AS Obtained,\n        MAX(CASE WHEN Type LIKE 'Benefit%' THEN Value END) AS Benefit,\n        MAX(CASE WHEN Type LIKE 'Max%' THEN Value END) AS `Max`,\n        CASE WHEN RIGHT(Type, 2) = 'II' THEN 'II' ELSE 'I' END AS Type\nFROM    T\nGROUP BY ID, StudentID, Mon, CASE WHEN RIGHT(Type, 2) = 'II' THEN 'II' ELSE 'I' END\nORDER BY ID, StudentID, Mon, Type\n"]], ['How to have many column from just one column?'], 2, 1], [(13173833, 1), [['With your revised data structure this should work:'], ['EXAMPLE ON SQL FIDDLE']], [[" SELECT  ID,\n        StudentID,\n        Mon,\n        COALESCE(MAX(CASE WHEN Type IN (1, 7) THEN Value END), 0) AS Obtained,\n        COALESCE(MAX(CASE WHEN Type IN (2, 8) THEN Value END), 0) AS Benefit,\n        COALESCE(MAX(CASE WHEN Type IN (4, 10) THEN Value END), 0) AS `Max`,\n        CASE WHEN Type IN (7, 8, 10) THEN 'II' WHEN Type IN (1, 2, 4) THEN 'I' END AS Type\nFROM    T\nWHERE   Type IN (1, 2, 4, 7, 8, 10)\nGROUP BY ID, StudentID, Mon, CASE WHEN Type IN (7, 8, 10) THEN 'II' WHEN Type IN (1, 2, 4) THEN 'I' END\nORDER BY ID, StudentID, Mon, Type\n"]], ['How to have many column from just one column?'], 2, 1], [(13183568, 0), [["I'd think it would be better to store each month's forecast in its own row in a table that looks like this "], ['Maybe have a salary history table, that trigger populates when employee data changes/payroll runs']], [[' month   forecast\n-----   --------\n    1      30000\n    2      31000\n    3      28000\n   ...       ...\n    60     52000\n']], ['Database schema design for financial forecasting'], 2, 0], [(13183568, 1), [['Maybe have a salary history table, that trigger populates when employee data changes/payroll runs'], ['Then again, you can do SUM or other aggregate function to get to the reported data.']], [[' employeeId    month   Salary\n----------    -----   ------\n         1        1     4000\n         2        1     3000\n         3        1     5000\n         1        2     4100\n         2        2     3100\n         3        2     4800\n       ...      ...      ...\n']], ['Database schema design for financial forecasting'], 2, 0], [(13230133, 0), [['I believe Oracle is  case sensitive by default ?  If so, then this should work:'], ['If this works then you can simply update them with']], [[' SELECT *\nFROM table_name\nWHERE LOWER(email) <> email\n']], ['Selecting all uppercased-value rows of a table in SQL Navigator'], 2, 1], [(13234818, 0), [['It appears that you can:'], ['What surprises me is that PostgreSQL proper (which does not have this  CREATE EXTERNAL TABLE  feature)  always  accepts ISO-style  YYYY-MM-DD  and  YYYYMMDD  dates, irrespective of  DATESTYLE . Observe:']], [[" SET DATESTYLE = 'YMD';\n"]], ['Formatting External tables in Greenplum (PostgreSQL)'], 4, 0], [(13234818, 1), [['What surprises me is that PostgreSQL proper (which does not have this  CREATE EXTERNAL TABLE  feature)  always  accepts ISO-style  YYYY-MM-DD  and  YYYYMMDD  dates, irrespective of  DATESTYLE . Observe:'], ["Here's how it works with a PostgreSQL  file_fdw   SQL/MED  foreign data wrapper :"]], [[" regress=> SELECT '20121229'::date, '2012-12-29'::date, current_setting('DateStyle');\n    date    |    date    | current_setting \n------------+------------+-----------------\n 2012-12-29 | 2012-12-29 | ISO, MDY\n(1 row)\n\nregress=> SET DateStyle = 'DMY';\nSET\nregress=> SELECT '20121229'::date, '2012-12-29'::date, current_setting('DateStyle');\n    date    |    date    | current_setting \n------------+------------+-----------------\n 2012-12-29 | 2012-12-29 | ISO, DMY\n(1 row)\n"]], ['Formatting External tables in Greenplum (PostgreSQL)'], 4, 0], [(13234818, 3), [['The CSV file contents are:'], ['so you can see that Pg will always accept ISO dates for CSV, irrespective of datestyle.']], [[' 20121229,2012-12-29\n']], ['Formatting External tables in Greenplum (PostgreSQL)'], 4, 0], [(13237623, 0), [['If both tables are truly the same schema:'], ["Otherwise, you'll have to specify the column names (the column list for  newTable  is optional if you are specifying a value for all columns and selecting columns in the same order as  newTable 's schema):"]], [[' INSERT INTO newTable\nSELECT * FROM oldTable\n']], ['Copy data into another table'], 2, 1], [(13237623, 1), [["Otherwise, you'll have to specify the column names (the column list for  newTable  is optional if you are specifying a value for all columns and selecting columns in the same order as  newTable 's schema):"], ['-10000']], [[' INSERT INTO newTable (col1, col2, col3)\nSELECT column1, column2, column3\nFROM oldTable\n']], ['Copy data into another table'], 2, 1], [(13241518, 0), [['Try This:'], ['.']], [[" --setup\ncreate table #fa00100 (assetId int, assetindex int, acquisitionCost int, dateAcquired date)\ncreate table #fa00200 (assetIndex int, moDepreciateRate int, fullyDeprFlag nchar(1), fullyDeprFlagBit bit)\n\ninsert #fa00100 \n      select 1, 1, 100, '2012-01-09'\nunion select 2, 2, 500, '2012-05-09'\ninsert #fa00200\n      select 1, 10, 'N', 0\nunion select 2, 15, 'Y', 1\n"]], ['sql query including month columns?'], 3, 0], [(13241518, 2), [['.'], ['-10000']], [['     --remove temp tables from setup\ndrop table #fa00100\ndrop table #fa00200\n']], ['sql query including month columns?'], 3, 0], [(13249903, 0), [['Sounds like you want this:'], ['Or you can use the following:']], [[' select model_id\nfrom yourtable\nwhere property in (1, 3)\ngroup by model_id\nhaving count(*) > 1;\n']], ['MySQL select multiple rows by referencing to one data field'], 2, 1], [(13249903, 1), [['Or you can use the following:'], ['See  SQL Fiddle with Demo']], [[' select model_id\nfrom yourtable t1\nwhere property = 1\n  and exists (select model_id\n              from yourtable t2\n              where t1.model_id = t2.model_id\n                and property = 3)\n']], ['MySQL select multiple rows by referencing to one data field'], 2, 1], [(13277973, 0), [['Something like SUM feature will work. Might be a little slow. '], ['Edit: If you want the last 30 days something like this query should work. It worked on my test table. ']], [[' SELECT SUM(requestType) FROM Requests WHERE `userEmail` = `userEmail` and `date` BETWEEN `first-date YYYY-MM-DD` AND `second-date YYYY-MM-DD`;  \n']], ['SQL average number of requests per user over time period'], 2, 1], [(13277973, 1), [['Edit: If you want the last 30 days something like this query should work. It worked on my test table. '], ['-10000']], [['  SELECT SUM(requestType) FROM Requests WHERE `userEmail` = `userEmail` and `date`BETWEEN curdate() - INTERVAL 30 DAY AND curdate();\n']], ['SQL average number of requests per user over time period'], 2, 1], [(13281693, 1), [['If you need to truly compare the numbers at the end, you will need to parse them out and cast them:'], ['-10000']], [[" SET @policy1 = 'XXXX-00099';\nSET @policy2 = 'XXXX-000598';\nSELECT @policy1, @policy2, \n   CONVERT(SUBSTRING(@policy2, INSTR(@policy2, '-')+1), UNSIGNED) >\n   CONVERT(SUBSTRING(@policy2, INSTR(@policy2, '-')+1), UNSIGNED) AS comparison;\n=========================================\n> 'XXXX-00099', 'XXXX-000598', 0\n"]], ['Comparing number in formatted string in MySQL?'], 2, 1], [(13308281, 0), [['-10000'], ['-10000']], [[' SELECT name, GROUP_CONCAT(number)\nFROM objects\nWHERE number IN (2,3)\nGROUP BY name\nHAVING COUNT(*) = 2\n']], ['MySQL GROUP BY "and filter"'], 2, 1], [(13308281, 1), [['-10000'], ['-10000']], [[' SELECT  a.name, GROUP_CONCAT(A.number)\nFROM    objects a\n        INNER JOIN\n        (\n          SELECT name\n          FROM objects\n          WHERE number IN (2,3)\n          GROUP BY name\n          HAVING COUNT(*) = 2\n        ) b ON a.Name = b.Name\nGROUP BY a.name\n']], ['MySQL GROUP BY "and filter"'], 2, 1], [(13345583, 0), [['you data says that the others apart from pear+orange expire today, so assuming you want to exclude expiring today and include those expiring WITHIN 2 months time:'], ['or a more index friendly way of putting it (removing the functions on the column side):']], [[' SQL> select food, manufacturedate, add_months(manufacturedate,12) expiry_date from product where add_months(manufacturedate, 12) <= add_months(trunc(sysdate), 2) and add_months(manufacturedate, 12) > trunc(sysdate);\n\nFOOD        MANUFACTU EXPIRY_DA\n--------------- --------- ---------\norange      12-JAN-12 12-JAN-13\npear        12-JAN-12 12-JAN-13\n']], ['oracle - how to list out the products that are going to expire in 2months time?'], 2, 1], [(13345583, 1), [['or a more index friendly way of putting it (removing the functions on the column side):'], ['-10000']], [[' SQL> select food, manufacturedate, add_months(manufacturedate,12) expiry_date from product where manufacturedate <= add_months(trunc(sysdate), -10) and manufacturedate > add_months(trunc(sysdate), -12);\n\nFOOD        MANUFACTU EXPIRY_DA\n--------------- --------- ---------\norange      12-JAN-12 12-JAN-13\npear        12-JAN-12 12-JAN-13\n']], ['oracle - how to list out the products that are going to expire in 2months time?'], 2, 1], [(13377997, 0), [['Customer may or may not have the email (Additional) in  emails  table.\nAlso, Customer have more than one additional emails entry in  emails  table. Like below'], ['In that case, Use the below query to get it done,']], [[' List<Customer> customers = new List<Customer> \n{ \n    new Customer { ClientId = 1, Email = "client1@domain.com", Credits = 2 },\n    new Customer { ClientId = 2, Email = "client2@domain.com", Credits = 1 },\n    new Customer { ClientId = 3, Email = "client3@domain.com", Credits = 1 },\n};\n\nList<Emails> emails = new List<Emails> \n{ \n    new Emails { ClientId = 1, Email = "client1-2@domain.com" },\n    new Emails { ClientId = 1, Email = "client1-3@domain.com" },\n    new Emails { ClientId = 2, Email = "client2-1@domain.com" },\n};\n']], ['Join and Union with Entity Framework'], 2, 0], [(13377997, 1), [['In that case, Use the below query to get it done,'], ['I hope it helps you.']], [[' var result = from c in customers\n             let _emails = emails.Where(e => c.ClientId == e.ClientId).Select(t => t.Email)\n             where c.Email == "client3@domain.com" || _emails.Contains("client3@domain.com")\n             select new\n             {\n                 Allowed = c.Credits > 0,\n                 MainEmail = c.Email\n             };\n']], ['Join and Union with Entity Framework'], 2, 1], [(13406949, 0), [['Do it on the client side.  Having said that, this example should show you the way.'], ['The key is in the last expression']], [[" with p(price1, multiplier) as (select 1234.5, 10)\nselect '$' + replace(cast((CAST(p.Price1 AS decimal(10,2)) * cast(isnull(p.Multiplier,1) as decimal(10,2))) as varchar), '.0000', ''),\n       '$' + parsename(convert(varchar,cast(p.price1*isnull(p.Multiplier,1) as money),1),2)\nfrom p\n"]], ['Formatting a number as a monetary value including separators'], 2, 1], [(13410246, 0), [['-10000'], ['-10000']], [['1. use join(...) - I would opt for this one in your case qry = session.query(Sample).join(Cell).filter(Cell.name == "a_string")\n\n>> SELECT sample.id AS sample_id, sample.factor_id AS sample_factor_id\n>> FROM sample JOIN cell ON cell.id = sample.factor_id\n>> WHERE cell.name = :name_1\n']], ['syntax to query another table using relationship in ORM?'], 2, 1], [(13410246, 1), [['-10000'], ['-10000']], [['2. use any/has(...) - this will use a sub-query qry = session.query(Sample).filter(Sample.cell.has(Cell.name == "a_string"))\n\n>> SELECT sample.id AS sample_id, sample.factor_id AS sample_factor_id\n>> FROM sample\n>> WHERE EXISTS (SELECT 1\n>> FROM cell\n>> WHERE cell.id = sample.factor_id AND cell.name = :name_1)\n']], ['syntax to query another table using relationship in ORM?'], 2, 1], [(13419701, 0), [['I assumed a TrainRoutes table with one row for each of R1, R2 etc. You could replace this with select distinct RouteID from Stops if required.'], ["You can also do this without the TrainRoute table like so, but you're now cross joining two larger tables:"]], [[' Select\n    r1.RouteID Route1,\n    r2.RouteID Route2\nFrom\n    -- cross to compare each route with each route\n    dbo.TrainRoutes r1\n        Cross Join\n    dbo.TrainRoutes r2\n        Inner Join\n    dbo.Stops s1\n        On r1.RouteID = s1.RouteID\n        Inner Join\n    dbo.Stops s2\n        On r2.RouteID = s2.RouteID\nWhere\n    r1.RouteID < r2.RouteID -- no point in comparing R1 with R2 and R2 with R1\nGroup By\n    r1.RouteID,\n    r2.RouteID\nHaving\n     -- check each route has the same number of stations\n    count(Distinct s1.stationID) = count(Distinct s2.stationID) And\n    -- check each route has the same stops\n    Sum(Case When s1.StationID = s2.StationID Then 1 Else 0 End) = count(Distinct s1.StationID) And\n    -- check each route has different halts\n    sum(Case When s1.StationID = s2.StationID And s1.Halts = s2.Halts Then 1 Else 0 End) != count(Distinct s1.StationID)\n']], ['Compare two sets of an SQL "GROUP BY" result'], 2, 1], [(13419701, 1), [["You can also do this without the TrainRoute table like so, but you're now cross joining two larger tables:"], ['http://sqlfiddle.com/#!6/76978/8']], [[' Select\n    s1.RouteID Route1,\n    s2.RouteID Route2\nFrom\n    dbo.Stops s1\n        Cross Join\n    dbo.Stops s2\nWhere\n    s1.RouteID < s2.RouteID\nGroup By\n    s1.RouteID,\n    s2.RouteID\nHaving\n    count(Distinct s1.stationID) = count(Distinct s2.stationID) And\n    Sum(Case When s1.StationID = s2.StationID Then 1 Else 0 End) = count(Distinct s1.StationID) And\n    sum(Case When s1.StationID = s2.StationID And s1.Halts = s2.Halts Then 1 Else 0 End) != count(Distinct s1.StationID)\n']], ['Compare two sets of an SQL "GROUP BY" result'], 2, 1], [(13427389, 0), [['Since a recipe can use multiple ingredients and you are looking for recipes that use one or more of the ingredients specified, you should use the  DISTINCT  keyword to prevent duplicate results where a recipe is using more than one ingredient from the list specified. Also, you can use  IN  clause to filter on multiple ingredient IDs.'], ['Alternatively, if you are looking for recipes that are using all the ingredients specified in the list, then you can group the results by recipe name and check if the count of records is same as the number of ingredients in your list.']], [[' select DISTINCT r.name\nfrom \n    recipes r\n    inner join ingredient_index i\n    on i.recipe_id = r.recipe_id\nwhere i.ingredient_id IN (7, 5);\n']], ['Recipe Database, search by ingredient'], 2, 1], [(13427389, 1), [['Alternatively, if you are looking for recipes that are using all the ingredients specified in the list, then you can group the results by recipe name and check if the count of records is same as the number of ingredients in your list.'], ["This is assuming that there won't be duplicate records with same (recipe_id, ingredient_id) tuple (better ensured with a UNIQUE constraint)."]], [[' select r.name\nfrom \n    recipes r\n    inner join ingredient_index i\n    on i.recipe_id = r.recipe_id\nwhere i.ingredient_id IN (7, 5)\nGROUP BY r.name\nHAVING COUNT(*) = 2\n']], ['Recipe Database, search by ingredient'], 2, 1], [(13452415, 0), [['You can use  INSERT INTO .. SELECT  instead of cursors and while loops like so:'], ['Update:  Try this: ']], [[" INSERT INTO Member(ContaId)\nSELECT TOP 1000 c.ContaId\nFROM FastGroupe fg\nINNER JOIN FastParticipant fp \n    ON fg.FastGroupeId = fp.FastGroupeId\nINNER JOIN Participant p\n    ON fp.ParticipantId = p.ParticipantId\nINNER JOIN Contact c\n    ON p.ContaId = c.ContaId\nWHERE FastGroupeName like '%Group%'\n"]], ['SQL Server 2008 insert into table using loop'], 2, 1], [(13471159, 0), [['You can use  FOR XML PATH :'], ['Result:']], [[" SELECT Ticket, \n  STUFF((SELECT distinct ' - ' + cast(UpdatedBy as varchar(20)) + ' ' + comment\n              from yourtable t2\n              where t1.Ticket = t2.Ticket\n            FOR XML PATH(''), TYPE\n\n            ).value('.', 'NVARCHAR(MAX)') \n        ,1,2,'') comments\nfrom yourtable t1\ngroup by ticket\n"]], ['Combine multiple rows of table in single row in SQL'], 2, 1], [(13471159, 1), [['Result:'], ['-10000']], [[' | TICKET |                                       COMMENTS |\n-----------------------------------------------------------\n|    100 |  23 Text 1 - 24 Text 2 - 25 Text 3 - 26 Text 4 |\n']], ['Combine multiple rows of table in single row in SQL'], 2, 0], [(13474207, 0), [['MySQL :'], ['or']], [[' SELECT NAME, SURNAME FROM MY_TABLE WHERE NAME = IFNULL(?,NAME);\n']], ['sql query if parameter is null select all'], 4, 1], [(13474207, 1), [['or'], ['ORACLE :']], [[' SELECT NAME, SURNAME FROM MY_TABLE WHERE NAME = COALESCE(?,NAME);\n']], ['sql query if parameter is null select all'], 4, 1], [(13474207, 2), [['ORACLE :'], ['SQL Server  /  SYBASE :']], [[' SELECT NAME, SURNAME FROM MY_TABLE WHERE NAME = NVL(?,NAME);\n']], ['sql query if parameter is null select all'], 4, 1], [(13474207, 3), [['SQL Server  /  SYBASE :'], ['-10000']], [[' SELECT NAME, SURNAME FROM MY_TABLE WHERE NAME = ISNULL(?,NAME);\n']], ['sql query if parameter is null select all'], 4, 1], [(13523272, 0), [['MS SQL Server 2008 Schema Setup :'], ['Query 1 :']], [[" create table YourTable\n(\n  ParentID int,\n  ChildName varchar(10)\n);\n\ninsert into YourTable values\n(1, 'Max'),\n(1, 'Jessie'),\n(2, 'Steven'),\n(2, 'Lucy'),\n(2, 'Jake'),\n(3, 'Mark');\n"]], ['SQL Server Group Concat with Different characters'], 3, 0], [(13523272, 1), [['Query 1 :'], ['Results :']], [[" with T as \n(\n  select ParentID,\n         ChildName,\n         row_number() over(partition by ParentID order by ChildName) as rn,\n         count(*) over(partition by ParentID) as cc\n  from YourTable\n)\nselect T1.ParentID,\n       (\n         select case\n                  when T2.rn = 1 and T2.cc > 1 then ' and '\n                  else ', ' \n                end + T2.ChildName\n         from T as T2\n         where T1.ParentID = T2.ParentID\n         order by T2.rn desc\n         for xml path(''), type\n       ).value('substring(text()[1], 3)', 'varchar(max)') as ChildNames\nfrom T as T1\ngroup by T1.ParentID\n"]], ['SQL Server Group Concat with Different characters'], 3, 1], [(13523272, 2), [['Results :'], ['-10000']], [[' | PARENTID |            CHILDNAMES |\n------------------------------------\n|        1 |        Max and Jessie |\n|        2 | Steven, Lucy and Jake |\n|        3 |                  Mark |\n']], ['SQL Server Group Concat with Different characters'], 3, 0], [(13537347, 0), [['-10000'], ["in case if col1 wasn't an increment it would go somewhat like"]], [[" SELECT * FROM table WHERE col2='CDE' ORDER BY col1 DESC LIMIT 1\n"]], ['Get row where column2 is X and column1 is max of column1'], 2, 1], [(13537347, 1), [["in case if col1 wasn't an increment it would go somewhat like"], ['-10000']], [[" SELECT *,MAX(col1) AS max_col1 FROM table WHERE col2='CDE' GROUP BY col2 LIMIT 1\n"]], ['Get row where column2 is X and column1 is max of column1'], 2, 1], [(13545617, 0), [['I assume you use mysql database.'], ['-10000']], [[' CREATE TABLE A\n(\n    id INT NOT NULL PRIMARY KEY,\n    b_id INT NOT NULL,\n    c_id INT NOT NULL,\n    FOREIGN KEY (b_id) REFERENCES B (id),\n    FOREIGN KEY (c_id) REFERENCES C (id)\n) TYPE = INNODB;\n']], ['Reference from one table to another entire table and specified row'], 2, 1], [(13545617, 1), [['-10000'], ['-10000']], [['Update for using postgresql: CREATE TABLE "A"\n(\n   id integer NOT NULL, \n   b_id integer NOT NULL, \n   c_id integer NOT NULL, \n   CONSTRAINT id PRIMARY KEY (id), \n   CONSTRAINT b_id FOREIGN KEY (b_id) REFERENCES "B" (id) \n      ON UPDATE NO ACTION ON DELETE NO ACTION, --with no action restriction\n   CONSTRAINT c_id FOREIGN KEY (c_id) REFERENCES "C" (id) \n      ON UPDATE CASCADE ON DELETE CASCADE  --with cascade restriction\n) \nWITH (\n  OIDS = FALSE\n)\n;\nALTER TABLE "C" OWNER TO postgres;\n']], ['Reference from one table to another entire table and specified row'], 2, 1], [(13584250, 0), [['SQLFIDDLEEXAMPLE'], ['Result:']], [[" SELECT \nID, LISTAGG(TELNO, ', ') \nWITHIN GROUP (ORDER BY TELNO) \nAS TEL_LIST\nFROM   tbl\nGROUP BY ID;\n"]], ['SQL using listagg() and group by non duplicated values'], 2, 1], [(13584250, 1), [['Result:'], ['-10000']], [[' | ID |                             TEL_LIST |\n---------------------------------------------\n|  1 |               0123456789, 0207983498 |\n|  2 | 0124339848, 02387694364, 09348374834 |\n']], ['SQL using listagg() and group by non duplicated values'], 2, 0], [(13595333, 0), [['Use Oracle export to export a whole table to a file, copy the file to serverB and import.'], ['For groups of records, write a query to build a pipe-delimited (or whatever delimiter suits your data) file with  rows you need to move.  Copy that file to serverB.  Write a control file for sqlldr and use sqlldr to load the rows into the table.  sqlldr is part of the oracle installation.']], [[' http://www.orafaq.com/wiki/Import_Export_FAQ\n']], ['How copy data from one database to another on different server?'], 5, 0], [(13595333, 1), [['For groups of records, write a query to build a pipe-delimited (or whatever delimiter suits your data) file with  rows you need to move.  Copy that file to serverB.  Write a control file for sqlldr and use sqlldr to load the rows into the table.  sqlldr is part of the oracle installation.'], ['If you have db listeners up on each server and tnsnames knows about both, you can directly:']], [[' http://www.thegeekstuff.com/2012/06/oracle-sqlldr/\n']], ['How copy data from one database to another on different server?'], 5, 0], [(13595333, 2), [['If you have db listeners up on each server and tnsnames knows about both, you can directly:'], ['Look at the remote table section:']], [[' insert into mytable@remote \nselect * from mytable\n  where somecolumn=somevalue;\n']], ['How copy data from one database to another on different server?'], 5, 1], [(13595333, 3), [['Look at the remote table section:'], ['If this is going to be an ongoing thing, create a db link from instance@serverA to instance@serverB.\nYou can then do anything you have permissions for with data on one instance or the other or both.']], [[' http://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_9014.htm\n']], ['How copy data from one database to another on different server?'], 5, 0], [(13595333, 4), [['If this is going to be an ongoing thing, create a db link from instance@serverA to instance@serverB.\nYou can then do anything you have permissions for with data on one instance or the other or both.'], ['-10000']], [[' http://psoug.org/definition/CREATE_DATABASE_LINK.htm\n']], ['How copy data from one database to another on different server?'], 5, 0], [(13618078, 1), [['However, since you only seem to be interested in columns from table  u  to begin with, this alternative query would be more elegant:'], ['This alternative has the additional advantage, that you always get  one  row from  u , even if there are multiple rows in  u_org  or  login .']], [[' SELECT u.uid, u.fname, u.lname\nFROM   u\nWHERE (u.uid IS NULL OR EXISTS (\n   SELECT 1\n   FROM   u_org o\n   WHERE  o.uid = u.uid\n   AND    o.orgid = 2\n   ))\nAND NOT EXISTS (\n   SELECT 1\n   FROM   login l\n   WHERE  l.uid = u.uid\n   AND    l.access = 4\n   );\n']], ['Query where foreign key column can be NULL'], 2, 1], [(13632163, 0), [['Runnable example here:  http://sqlfiddle.com/#!3/894e9/4'], ['This version defaults any language:']], [[" if object_id('[FloorName]') is not null drop table [FloorName]\nif object_id('[BuildingName]') is not null drop table [BuildingName]\nif object_id('[Floor]') is not null drop table [Floor]\nif object_id('[Building]') is not null drop table [Building]\nif object_id('[Language]') is not null drop table [Language]\n\ncreate table [Language]\n(\n    Id bigint not null identity(1,1) primary key clustered\n    , code nvarchar(5)\n)\ncreate table [Building]\n(\n    Id bigint not null identity(1,1) primary key clustered\n    , something nvarchar(64)\n)\ncreate table [Floor]\n(\n    Id bigint not null identity(1,1) primary key clustered\n    , BuildingId bigint foreign key references [Building](Id)\n    , something nvarchar(64)\n)\ncreate table [BuildingName]\n(\n    Id bigint not null identity(1,1) primary key clustered\n    , BuildingId bigint foreign key references [Building](Id)\n    , LanguageId bigint foreign key references [Language](Id)\n    , name nvarchar(64)\n)\ncreate table [FloorName]\n(\n    Id bigint not null identity(1,1) primary key clustered\n    , FloorId bigint foreign key references [Floor](Id)\n    , LanguageId bigint foreign key references [Language](Id)\n    , name nvarchar(64)\n)\n\ninsert [Language]\n      select 'en-us'\nunion select 'en-gb'\nunion select 'fr'\n\ninsert [Building]\n      select 'B1'\nunion select 'B2'\n\ninsert [Floor]\n      select 1, 'F1.1'\nunion select 1, 'F1.2'\nunion select 1, 'F1.3'\nunion select 1, 'F1.4'\nunion select 1, 'F1.5'\nunion select 2, 'F2.1'\nunion select 2, 'F2.2'\nunion select 2, 'F2.3'\nunion select 2, 'F2.4'\nunion select 2, 'F2.5'\n\ninsert BuildingName\nselect b.Id\n, l.id\n, 'BuildingName :: ' + b.something + ' ' + l.code\nfrom [Building] b\ncross join [Language] l\nwhere l.code in ('en-us', 'fr')\n\ninsert FloorName\nselect f.Id\n, l.Id\n, 'FloorName :: ' + f.something + ' ' + l.code\nfrom [Floor] f\ncross join [Language] l\nwhere f.something in ( 'F1.1', 'F1.2', 'F2.1')\nand l.code in ('en-us', 'fr')\n\ninsert FloorName\nselect  f.Id\n, l.Id\n, 'FloorName :: ' + f.something + ' ' + l.code\nfrom [Floor] f\ncross join [Language] l\nwhere f.something not in ( 'F1.1', 'F1.2', 'F2.1')\nand l.code in ('en-us')\n\n\ndeclare @defaultLanguageId bigint\nselect @defaultLanguageId = id from [Language] where code = 'en-us' --default language is US English\n\nselect b.Id\n, b.something\n, bn.name\n, isnull(bfn.name, bfnDefault.name)\n, bl.code BuildingLanguage\nfrom [Building] b\ninner join [BuildingName] bn\n    on bn.BuildingId = b.Id\ninner join [Language] bl\n    on bl.Id = bn.LanguageId\ninner join [Floor] bf\n    on bf.BuildingId = b.Id\nleft outer join [FloorName] bfn\n    on bfn.FloorId = bf.Id\n    and bfn.LanguageId = bl.Id\nleft outer join [Language] bfl\n    on bfl.Id = bfn.LanguageId\nleft outer join [FloorName] bfnDefault\n    on bfnDefault.FloorId = bf.Id\n    and bfnDefault.LanguageId = @defaultLanguageId\n"]], ['Create a view with alternate/default values for missing relationships'], 2, 1], [(13632163, 1), [['This version defaults any language:'], ['-10000']], [[' select b.Id\n, b.something\n, bn.name\n, isnull(bfn.name, (select top 1 name from [FloorName] x where x.FloorId=bf.Id))\n, bl.code BuildingLanguage\nfrom [Building] b\ninner join [BuildingName] bn\n    on bn.BuildingId = b.Id\ninner join [Language] bl\n    on bl.Id = bn.LanguageId\ninner join [Floor] bf\n    on bf.BuildingId = b.Id\nleft outer join [FloorName] bfn\n    on bfn.FloorId = bf.Id\n    and bfn.LanguageId = bl.Id\nleft outer join [Language] bfl\n    on bfl.Id = bfn.LanguageId\n']], ['Create a view with alternate/default values for missing relationships'], 2, 1], [(13678718, 0), [["6 answers and 5 of them don't work (for SQL Server)... "], ['Specifically for your question, since you KNOW that the data with 4-characters is a number, then you can do a direct lexicographical (text) comparison (yes it works):']], [[' SELECT *\n  FROM foo\n WHERE CASE WHEN LEN(bar) = 4 THEN\n       CASE WHEN CONVERT(Int,bar) >= 5000 THEN 1 ELSE 0 END\n       END = 1;\n']], ['Execute a WHERE clause before another one'], 2, 1], [(13678718, 1), [['Specifically for your question, since you KNOW that the data with 4-characters is a number, then you can do a direct lexicographical (text) comparison (yes it works):'], ['-10000']], [[" SELECT *\n  FROM foo\n WHERE LEN(bar) = 4 AND bar > '5000';\n"]], ['Execute a WHERE clause before another one'], 2, 1], [(13717630, 0), [['Try something like this:'], ['For your example the query will look like:']], [[" SELECT 'A'\nFROM tableA\nWHERE current_setting(setting_name) = 'setting A'\nUNION ALL\nSELECT 'B'\nFROM tableB\nWHERE current_setting(setting_name) = 'setting B'\n"]], ['Choose view select statement dynamically by session variable in PostgreSQL'], 2, 1], [(13717630, 1), [['For your example the query will look like:'], ['UPD Checked: postgres executes only one of the queries.  EXPLAIN ANALYZE  shows that the second query was planned but marked as  (never executes) .']], [[" SELECT 'A'\nFROM tableA\nWHERE myVar = 1\nUNION ALL\nSELECT 'B'\nFROM tableB\nWHERE myVar != 1\n"]], ['Choose view select statement dynamically by session variable in PostgreSQL'], 2, 1], [(13730484, 0), [['You would use  FOR XML PATH  for this:'], ['Result:']], [[" select p.name,\n  Stuff((SELECT ', ' + s.skillName \n         FROM skilllink l\n         left join skill s\n           on l.skillid = s.id \n         where p.id = l.personid\n         FOR XML PATH('')),1,1,'') Skills\nfrom person p\n"]], ['SELECT multiple rows from single column into single row'], 2, 1], [(13730484, 1), [['Result:'], ['-10000']], [[' | NAME |            SKILLS |\n----------------------------\n| Bill | Telepathy, Karate |\n|  Bob |            (null) |\n|  Jim |         Carpentry |\n']], ['SELECT multiple rows from single column into single row'], 2, 0], [(13758033, 0), [['I guess you need this?'], ["If as you've described in the comment  mastertable.carcolor  (and others) contains a comma separated list of  Id 's in  varchar  then it should be:"]], [[' select * from mastertable\nleft join carcolortable on mastertable.carcolor=carcolortable.id\nleft join varianttable on mastertable.variant=varianttable.id\nleft join accessoriestable on mastertable.accessories=accessoriestable.id\n']], ['how to join multiple select statement together'], 2, 1], [(13758033, 1), [["If as you've described in the comment  mastertable.carcolor  (and others) contains a comma separated list of  Id 's in  varchar  then it should be:"], ['-10000']], [[" select * from mastertable\nleft join carcolortable on \n        ( ','+mastertable.carcolor+',' \n          LIKE \n          '%,'+CAST(carcolortable.id as varchar(100))+',%'\n         )\nleft join varianttable on \n        ( ','+mastertable.variant+',' \n          LIKE \n          '%,'+CAST(varianttable.id as varchar(100))+',%'\n         )\n\nleft join accessoriestable on \n        ( ','+mastertable.accessories+',' \n          LIKE \n          '%,'+CAST(accessoriestable.id as varchar(100))+',%'\n         )\n"]], ['how to join multiple select statement together'], 2, 1], [(13771275, 0), [['For a list of players  without duplicates  an  EXISTS  semi-join is probably best:'], ['This is probably faster (duplicates are probably not possible):']], [[' SELECT playerFirstName, playerLastName\nFROM   player AS p \nWHERE EXISTS (\n   SELECT 1\n   FROM   player2Statistic AS ps \n   WHERE  ps.playerID = p.playerID\n   AND    ps.StatisticID = 1\n   AND    ps.p2sStatistic > 65\n   )\nAND EXISTS (\n   SELECT 1\n   FROM   player2Statistic AS ps \n   WHERE  ps.playerID = p.playerID\n   AND    ps.StatisticID = 3\n   AND    ps.p2sStatistic > 295\n   );\n']], ['Query different IDs with different values?'], 2, 1], [(13771275, 1), [['This is probably faster (duplicates are probably not possible):'], ['If your top-secret brand of RDBMS does not support the SQL-standard  (USING (playerID) , substitute:  ON ps1.playerID = p.playerID  to the same effect.']], [[' SELECT p.playerFirstName, p.playerLastName\nFROM   player           AS p \nJOIN   player2Statistic AS ps1 USING (playerID)\nJOIN   player2Statistic AS ps3 USING (playerID)\nAND    ps1.StatisticID = 1\nAND    ps1.p2sStatistic > 65\nAND    ps3.StatisticID = 3\nAND    ps3.p2sStatistic > 295;\n']], ['Query different IDs with different values?'], 2, 1], [(13789442, 0), [['To list all the jobs that started within a specified date:'], ['To list all the steps for a specified job on a specified date with their status:']], [[' declare @date date = getdate()\n\nSELECT\n    J.job_id,\n    J.name\nFROM msdb.dbo.sysjobs AS J \nINNER JOIN msdb.dbo.sysjobhistory AS H ON H.job_id = J.job_id\nWHERE run_date = CONVERT(VARCHAR(8), GETDATE(), 112)\nGROUP BY J.job_id, J.name\n']], ['List all the jobs that have been executed within a specified date?'], 2, 1], [(13789442, 1), [['To list all the steps for a specified job on a specified date with their status:'], ['More information  here .']], [[" declare @date date = getdate()\ndeclare @job_name varchar(50) = 'test'\n\nSELECT\n    H.run_date,\n    H.run_time,\n    H.step_id,\n    H.step_name,\n    H.run_status\nFROM msdb.dbo.sysjobs AS J\nINNER JOIN msdb.dbo.sysjobhistory AS H ON H.job_id = J.job_id\nWHERE \n    run_date = CONVERT(VARCHAR(8), GETDATE(), 112)\n    AND J.name = @job_name\n"]], ['List all the jobs that have been executed within a specified date?'], 2, 1], [(13791170, 0), [['Try this'], ['or']], [[' SELECT\n    whatever\nFROM\n    A\n    INNER JOIN B\n        ON A.A_ID = B.A_ID\nWHERE\n    B.C_ID IN (4, 5)\n']], ['How do I join tables where a column has exactly all values that I want?'], 5, 1], [(13791170, 1), [['or'], ['-10000']], [[' SELECT\n    whatever\nFROM\n    A\n    INNER JOIN B\n        ON A.A_ID = B.A_ID\nWHERE\n    B.C_ID = 4 OR B.C_ID = 5\n']], ['How do I join tables where a column has exactly all values that I want?'], 5, 1], [(13791170, 2), [['-10000'], ['The sub-select groups by  A_ID  and counts the records. The HAVING clause works like the WHERE clause but is executed after grouping. So the inner select returns only  A_ID s corresponding to (4, 5)-pairs of  C_ID . The whole query always returns an even number of records like']], [[' SELECT\n    whatever\nFROM\n    A\n    INNER JOIN B\n        ON A.A_ID = B.A_ID\nWHERE\n    A.A_ID IN (SELECT A_ID\n               FROM B\n               WHERE C_ID IN (4, 5)\n               GROUP BY A_ID\n               HAVING COUNT(*) = 2) AND\n    B.C_ID IN (4, 5)\n']], ['How do I join tables where a column has exactly all values that I want?'], 5, 1], [(13791170, 3), [['The sub-select groups by  A_ID  and counts the records. The HAVING clause works like the WHERE clause but is executed after grouping. So the inner select returns only  A_ID s corresponding to (4, 5)-pairs of  C_ID . The whole query always returns an even number of records like'], ['Thanks, with your help I came up with this:']], [[' SELECT B.*\nFROM A INNER JOIN B ON A.A_ID = B.A_ID\nWHERE B.C_ID IN (4, 5) AND\n      A.A_ID IN (SELECT A_ID\n                 FROM B\n                 GROUP BY A_ID\n                 HAVING MIN(C_ID)=4 AND MAX(C_ID)=5 AND COUNT(*)=2)\n']], ['How do I join tables where a column has exactly all values that I want?'], 5, 1], [(13791170, 4), [['Thanks, with your help I came up with this:'], ['-10000']], [[' SELECT\n    *\nFROM\n    A a\n    INNER JOIN B\n        ON a.A_ID = B.A_ID\nWHERE\n    (SELECT COUNT(*) FROM B b WHERE b.A_ID = a.A_ID and C_ID IN (4, 5)) =\n (SELECT COUNT(*) FROM A aa INNER JOIN B b ON aa.A_ID = b.A_ID WHERE b.A_ID = a.A_ID)\n']], ['How do I join tables where a column has exactly all values that I want?'], 5, 1], [(13832037, 0), [['-10000'], ['-10000']], [[" SELECT  *\nFROM    History\nWHERE   DATE_FORMAT(CURDATE(), '%M') = `month` AND\n        DAY(CURDATE()) = `day_num`\n"]], ['MySQL: Select values based on current month and day'], 2, 1], [(13832037, 1), [['-10000'], ['-10000']], [[' SELECT  *\nFROM    History\nWHERE   MONTHNAME(CURDATE()) = `month` AND\n        DAY(CURDATE()) = `day_num`\n']], ['MySQL: Select values based on current month and day'], 2, 1], [(13840468, 0), [['You can use the  UNPIVOT  function to do this, the version below concatenates the column name and value together, but you can always display them as separate columns:'], ['The above works great if you have a known number of columns, but if you have 800 columns that you want to transform, you might want to use dynamic sql to perform this:']], [[" select col+':'+cast(value as varchar(10)) col\nfrom test\nunpivot\n(\n  value\n  for col in (A, B, C, D)\n) unpiv\n"]], ['SQL query for fetching a single record in format "column heading: column value"'], 9, 0], [(13840468, 1), [['The above works great if you have a known number of columns, but if you have 800 columns that you want to transform, you might want to use dynamic sql to perform this:'], ['The first piece get the list of columns that you want to unpivot dynamically:']], [[" DECLARE @colsUnpivot AS NVARCHAR(MAX),\n    @query  AS NVARCHAR(MAX)\n\nselect @colsUnpivot = stuff((select ','+quotename(C.name)\n         from sys.columns as C\n         where C.object_id = object_id('test')\n         for xml path('')), 1, 1, '')\n\nset @query \n  = 'select col+'':''+cast(value as varchar(10)) col\n     from test\n     unpivot\n     (\n       value\n       for col in ('+ @colsunpivot +')\n     ) u'\n\nexec(@query)\n"]], ['SQL query for fetching a single record in format "column heading: column value"'], 9, 0], [(13840468, 2), [['The first piece get the list of columns that you want to unpivot dynamically:'], ['The second piece gets the same list of columns but wraps each column in a  cast  as a  varchar :']], [[" select @colsUnpivot = stuff((select ','+quotename(C.name)\n             from sys.columns as C\n             where C.object_id = object_id('test')\n             for xml path('')), 1, 1, '')\n"]], ['SQL query for fetching a single record in format "column heading: column value"'], 9, 0], [(13840468, 3), [['The second piece gets the same list of columns but wraps each column in a  cast  as a  varchar :'], ['Then your final query will be:']], [[" select @colsUnpivotCast = stuff((select ', cast('+quotename(C.name)+' as varchar(50)) as '+quotename(C.name)\n         from sys.columns as C\n         where C.object_id = object_id('test')\n         for xml path('')), 1, 1, '')\n"]], ['SQL query for fetching a single record in format "column heading: column value"'], 9, 0], [(13840468, 4), [['Then your final query will be:'], ['The  UNPIVOT  function is performing the same process as a  UNION ALL  which would look like this:']], [[" DECLARE @colsUnpivot AS NVARCHAR(MAX),\n    @colsUnpivotCast AS NVARCHAR(MAX),\n    @query  AS NVARCHAR(MAX)\n\n\nselect @colsUnpivot = stuff((select ','+quotename(C.name)\n         from sys.columns as C\n         where C.object_id = object_id('test')\n         for xml path('')), 1, 1, '')\n\nselect @colsUnpivotCast = stuff((select ', cast('+quotename(C.name)+' as varchar(50)) as '+quotename(C.name)\n         from sys.columns as C\n         where C.object_id = object_id('test')\n         for xml path('')), 1, 1, '')\n\n\nset @query \n  = 'select col+'':''+value col\n     from\n    (\n      select '+@colsUnpivotCast+'\n      from test\n    ) src\n     unpivot\n     (\n       value\n       for col in ('+ @colsunpivot +')\n     ) u'\n\n\nexec(@query)\n"]], ['SQL query for fetching a single record in format "column heading: column value"'], 9, 0], [(13840468, 5), [['The  UNPIVOT  function is performing the same process as a  UNION ALL  which would look like this:'], ['The result of all of the queries is the same:']], [[" select col+':'+value as col\nfrom\n(\n  select A value, 'A' col\n  from test\n  union all\n  select cast(B as varchar(10)) value, 'B' col\n  from test\n  union all\n  select cast(C as varchar(10)) value, 'C' col\n  from test\n  union all\n  select cast(D as varchar(10)) value, 'D' col\n  from test\n) src\n"]], ['SQL query for fetching a single record in format "column heading: column value"'], 9, 0], [(13840468, 6), [['The result of all of the queries is the same:'], ['Edit #2:  using  UNPIVOT  strips out any of the null columns which could cause some data to drop. If that is the case, then you will want to wrap the columns with  IsNull()  to replace the  null  values:']], [[' |    COL |\n----------\n|    A:1 |\n| B:2.00 |\n|    C:3 |\n|    D:4 |\n']], ['SQL query for fetching a single record in format "column heading: column value"'], 9, 0], [(13840468, 7), [['Edit #2:  using  UNPIVOT  strips out any of the null columns which could cause some data to drop. If that is the case, then you will want to wrap the columns with  IsNull()  to replace the  null  values:'], ['Replacing the null values, will give a result like this:']], [[" DECLARE @colsUnpivot AS NVARCHAR(MAX),\n    @colsUnpivotCast AS NVARCHAR(MAX),\n    @query  AS NVARCHAR(MAX)\n\n\nselect @colsUnpivot = stuff((select ','+quotename(C.name)\n         from sys.columns as C\n         where C.object_id = object_id('test')\n         for xml path('')), 1, 1, '')\n\nselect @colsUnpivotCast = stuff((select ', IsNull(cast('+quotename(C.name)+' as varchar(50)), '''') as '+quotename(C.name)\n         from sys.columns as C\n         where C.object_id = object_id('test')\n         for xml path('')), 1, 1, '')\n\n\nset @query \n  = 'select col+'':''+value col\n     from\n    (\n      select '+@colsUnpivotCast+'\n      from test\n    ) src\n     unpivot\n     (\n       value\n       for col in ('+ @colsunpivot +')\n     ) u'\n\n\nexec(@query)\n"]], ['SQL query for fetching a single record in format "column heading: column value"'], 9, 1], [(13840468, 8), [['Replacing the null values, will give a result like this:'], ['-10000']], [[' |    COL |\n----------\n|    A:1 |\n| B:2.00 |\n|     C: |\n|    D:4 |\n']], ['SQL query for fetching a single record in format "column heading: column value"'], 9, 0], [(13862099, 1), [['The resulting query will look like this:'], ['-10000']], [[" SELECT `e`.*, IF(at_visibility.value_id > 0, at_visibility.value, at_visibility_default.value) AS `visibility`\nFROM `catalog_product_entity` AS `e`\nINNER JOIN `catalog_product_entity_int` AS `at_visibility_default`\n    ON (`at_visibility_default`.`entity_id` = `e`.`entity_id`)\n    AND (`at_visibility_default`.`attribute_id` = '526')\n    AND `at_visibility_default`.`store_id` = 0\nLEFT JOIN `catalog_product_entity_int` AS `at_visibility` ON (`at_visibility`.`entity_id` = `e`.`entity_id`)\n    AND (`at_visibility`.`attribute_id` = '526')\n    AND (`at_visibility`.`store_id` = 1)\nWHERE (IF(at_visibility.value_id > 0, at_visibility.value, at_visibility_default.value) = '1')\n"]], ['Magento SQL query: Get all simple products that are "not visible individually"'], 2, 1], [(13901809, 0), [["As far as I know, you can't do this, you can't  UPDATE  and  DELETE  in one single query. However, you can do this as two  UPDATE  and  DELETE  queries like so:"], ['Note that:  You have to put these two queries in one  TRANSACTION .']], [[" UPDATE Table1 t1\nINNER JOIN\n(\n  SELECT val1, GROUP_CONCAT(val2 SEPARATOR ',') Val2\n  FROM Table1\n  GROUP BY val1\n) t2 ON t1.val1 = t2.val1\nSET t1.val2 = t2.val2;\n\nDELETE t\nFROM table1 t\nWHERE id NOT IN\n(\n  SELECT ID\n  FROM\n  (\n    SELECT MIN(ID) id, val1\n    FROM table1\n    GROUP BY val1\n   ) sub\n );\n"]], ['Sql how to remove duplicate records with merging values?'], 2, 1], [(13901809, 1), [['Note that:  You have to put these two queries in one  TRANSACTION .'], ['-10000']], [[' | ID |  VAL1 |    VAL2 |\n------------------------\n|  1 |  john | sam,joe |\n|  2 | larry |     tom |\n']], ['Sql how to remove duplicate records with merging values?'], 2, 0], [(13967474, 0), [['Try this: '], ['As per your request using  SUM  function']], [[' SELECT orderid, COUNT(orderid) no_of_iteraction\nFROM tblTemp \nGROUP BY orderid\n']], ['count no of instance of tuple with same value in some attribute'], 3, 1], [(13967474, 1), [['As per your request using  SUM  function'], ['OR']], [[' SELECT orderid, SUM(1) no_of_iteraction\nFROM tblTemp \nGROUP BY orderid\n']], ['count no of instance of tuple with same value in some attribute'], 3, 1], [(13967474, 2), [['OR'], ['-10000']], [[' SELECT orderid, SUM(cnt)\nFROM (SELECT orderid, 1 cnt FROM tblTemp ORDER BY orderid) AS A \nGROUP BY orderid\n']], ['count no of instance of tuple with same value in some attribute'], 3, 1], [(14056134, 1), [['The following query will not query work, but it gives the idea of moving the thread to the subquery:'], ['The reason it will not work is because the  from  clause will return no rows rather than 1 row with a NULL value.  So, to get what you want, you can use:']], [[" INSERT INTO search_email(meta, subject, body, sender, tos, ccs, folder, threadid)\n    SELECT 'meta1', 'subject1', 'body1', 'sender1', 'tos1', 'ccs1', 'folder1',\n            coalesce(t.threadID,\n                     <generate new thread id here>\n                    )\n    from (SELECT search_email.threadID\n          FROM search_email \n          WHERE search_email.subject MATCH '%query%' AND \n                ((search_email.sender = '%sender%' AND search_email.tos = '%receiver%') OR\n                 (search_email.sender = '%receiver%' AND search_email.tos = '%sender%')\n                )\n          LIMIT 1\n         ) t\n"]], ['reusing result of SELECT statement within a CASE statement sqllite'], 3, 0], [(14091654, 0), [['-10000'], ['You can do with  TRIGGER  also,']], [[' UPDATE logs_month SET status =\'1\'\nWHERE DATE_FORMAT(month,"%m/%y") = \'11/12\';\nCOMMIT;\nINSERT INTO some_table (columns) values (select columns\nfrom logs_month where DATE_FORMAT(month,"%m/%y") = \'11/12\';\n']], ['How to query insert on updated rows?'], 2, 1], [(14091654, 1), [['You can do with  TRIGGER  also,'], ['You can do like this']], [[' DELIMITER $$\nCREATE TRIGGER `logs_m` \nAFTER UPDATE ON `logs_month`\nFOR EACH ROW \nBEGIN\n    IF NEW.status=1 THEN\n    INSERT INTO some_table (field) values (NEW.field);\n    END IF;\nEND$$\n\nDELIMITER ;\n']], ['How to query insert on updated rows?'], 2, 1], [(14124763, 0), [['One way would be'], ['or with join']], [[' SELECT DISTINCT CustomerId FROM Attributes a \nWHERE NOT EXISTS (\n    SELECT * FROM Attributes forbidden \n    WHERE forbidden.CustomerId = a.CustomerId AND forbidden.Class = _forbiddenClassValue_ AND forbidden.Code = _forbiddenCodeValue_\n)\n']], ['How to write a Sql query to find distinct values that have never met the following "Where Not(a=x and b=x)"'], 2, 1], [(14124763, 1), [['or with join'], ["Yet another way is to use EXCEPT, as per ypercube's answer"]], [[' SELECT DISTINCT a.CustomerId FROM Attributes a\nLEFT JOIN (\n    SELECT CustomerId FROM Attributes\n    WHERE Class = _forbiddenClassValue_ AND Code = _forbiddenCodeValue_\n) havingForbiddenPair ON a.CustomerId = havingForbiddenPair.CustomerId\nWHERE havingForbiddenPair.CustomerId IS NULL\n']], ['How to write a Sql query to find distinct values that have never met the following "Where Not(a=x and b=x)"'], 2, 1], [(14159629, 0), [['You did not specify what RDBMS you are using but this will work in all versions:'], ['If you are using a database with the  PIVOT  function, then your query will be like this:']], [[" select blog,\n  id,\n  max(case when attribute = 'pid' then value end) postid,\n  max(case when attribute = 'date' then value end) date,\n  max(case when attribute = 'title' then value end) title\nfrom yourtable\ngroup by blog, id\n"]], ['sql table pivot'], 3, 1], [(14159629, 2), [['The result for both will be:'], ['-10000']], [[' | BLOG | ID | POSTID | DATE | TITLE |\n-------------------------------------\n|    p |  1 |   abc1 | abc2 |  abc3 |\n|    p |  2 |   abc1 | abc2 |  abc3 |\n|    p |  3 |   abc1 | abc2 |  abc3 |\n']], ['sql table pivot'], 3, 0], [(14168940, 0), [['First, drop the current constraint without a cascading delete.'], ['Then, re-add the constraint with the ON DELETE CASCADES:']], [[' ALTER TABLE Session_Completed\nDROP PRIMARY KEY pk_SessionId\n']], ['How to delete rows in other database tables'], 2, 0], [(14206236, 0), [['-10000'], ['-10000']], [[" SELECT LocationX, LocationY, City, Type, COUNT(*) CountOfLocation  \nFROM   tableName\nWHERE  DateTimeStamp BETWEEN '2013-08-01 8:49:00' AND '2013-08-01 8:59:59'\nGROUP  BY LocationX, LocationY, City, Type\n"]], ['I have a table where i need to group and count 2 columns within a certain date range'], 2, 1], [(14206236, 1), [['-10000'], ['-10000']], [[' SELECT LocationX, LocationY, City, Type, COUNT(*) AS CountOfLocation  \nFROM   tableName\nWHERE  DateTimeStamp BETWEEN #2013-08-01 08:49:00# AND #2013-08-01 08:59:59#\nGROUP  BY LocationX, LocationY, City, Type\n']], ['I have a table where i need to group and count 2 columns within a certain date range'], 2, 1], [(14211346, 0), [['You may also want to account for carriage returns and tabs. These three (Line feeds, carriage returns and tabs) are the usual culprits and can be removed with the following :'], ['If you encounter any more "white space" characters that can\'t be removed with the above then try one or all of the below:']], [[" LTRIM(RTRIM(REPLACE(REPLACE(REPLACE(ProductAlternateKey, CHAR(10), ''), CHAR(13), ''), CHAR(9), '')))\n"]], ['How to remove white space characters from a string in SQL Server'], 4, 1], [(14211346, 1), [['If you encounter any more "white space" characters that can\'t be removed with the above then try one or all of the below:'], ['This list of potential white space characters could be used to create a function such as :']], [[" --NULL\nReplace([YourString],CHAR(0),'');\n--Horizontal Tab\nReplace([YourString],CHAR(9),'');\n--Line Feed\nReplace([YourString],CHAR(10),'');\n--Vertical Tab\nReplace([YourString],CHAR(11),'');\n--Form Feed\nReplace([YourString],CHAR(12),'');\n--Carriage Return\nReplace([YourString],CHAR(13),'');\n--Column Break\nReplace([YourString],CHAR(14),'');\n--Non-breaking space\nReplace([YourString],CHAR(160),'');\n"]], ['How to remove white space characters from a string in SQL Server'], 4, 1], [(14211346, 2), [['This list of potential white space characters could be used to create a function such as :'], ['Which you could then use as follows:']], [[" Create Function [dbo].[CleanAndTrimString] \n(@MyString as varchar(Max))\nReturns varchar(Max)\nAs\nBegin\n    --NULL\n    Set @MyString = Replace(@MyString,CHAR(0),'');\n    --Horizontal Tab\n    Set @MyString = Replace(@MyString,CHAR(9),'');\n    --Line Feed\n    Set @MyString = Replace(@MyString,CHAR(10),'');\n    --Vertical Tab\n    Set @MyString = Replace(@MyString,CHAR(11),'');\n    --Form Feed\n    Set @MyString = Replace(@MyString,CHAR(12),'');\n    --Carriage Return\n    Set @MyString = Replace(@MyString,CHAR(13),'');\n    --Column Break\n    Set @MyString = Replace(@MyString,CHAR(14),'');\n    --Non-breaking space\n    Set @MyString = Replace(@MyString,CHAR(160),'');\n\n    Set @MyString = LTRIM(RTRIM(@MyString));\n    Return @MyString\nEnd\nGo\n"]], ['How to remove white space characters from a string in SQL Server'], 4, 1], [(14211346, 3), [['Which you could then use as follows:'], ['-10000']], [[' Select \n    dbo.CleanAndTrimString(ProductAlternateKey) As ProductAlternateKey\nfrom DimProducts\n']], ['How to remove white space characters from a string in SQL Server'], 4, 0], [(14253673, 0), [['An example that works for mysql follows, for MS SQL you would use CHARINDEX instead of INSTR and substring instead of substr. '], ['Results.']], [[" select employeesWithCountries.*\n, countries.sort \nfrom (\n    select empId, empLotusNotes, substr( empLotusNotes, afterStartOfDelimiter ) country from (\n        select empId\n        , empLotusNotes\n        , INSTR( empLotusNotes, '/' ) + 1 as afterStartOfDelimiter \n        from EmployeesLotusNotes\n    ) employees\n) employeesWithCountries\ninner join (\n    SELECT 'Japan' as country, 1 as sort\n    union\n    SELECT 'China' as country, 2 as sort\n    union\n    SELECT 'India' as country, 3 as sort\n    union\n    SELECT 'USA' as country, 4 as sort\n) countries\non employeesWithCountries.country = countries.country\norder by countries.sort, employeesWithCountries.empLotusNotes\n"]], ['Applying Where clause for Order by in SQL'], 2, 1], [(14253673, 1), [['Results.'], ['-10000']], [[' 30003    Kyo Jun/Japan   Japan    1\n40004    Jee Lee/China   China    2\n10001    Amit B/India    India    3\n20002    Bharat C/India  India    3\n50005    Xavier K/USA    USA      4\n']], ['Applying Where clause for Order by in SQL'], 2, 0], [(14285554, 1), [['Then you would just:'], ['Option 2 : \nMake a database procedure to do the above functionality and call that instead. ']], [[" $productKey = $this->_helper->model('ProductKeys')->getKeyAndMarkUsed();\n"]], ['Zend Database Table getrow'], 2, 0], [(14286714, 0), [['Try something like:'], ['The whole query with same style counts and simplified  CASE WHEN ... :']], [[" SELECT\n  DATE(created_at) AS date,\n  SUM(CASE WHEN state = 'complete' THEN 1 ELSE 0 END) AS complete,\n  SUM(CASE WHEN state = 'paid' THEN 1 ELSE 0 END) AS paid,\n  COUNT(DISTINCT CASE WHEN state IN('new','paying','completing') THEN user_id ELSE NULL END) AS in_progress,\n  COUNT(DISTINCT CASE WHEN state IN('payment_failed','completion_failed') THEN user_id ELSE NULL END) AS failed\nFROM orders\nWHERE created_at BETWEEN ? AND ?\nGROUP BY DATE(created_at);\n"]], ['SQL sum of column value, unique per user per day'], 2, 1], [(14286714, 1), [['The whole query with same style counts and simplified  CASE WHEN ... :'], ['-10000']], [[" SELECT\n  DATE(created_at) AS date,\n  COUNT(CASE WHEN state = 'complete' THEN 1 END) AS complete,\n  COUNT(CASE WHEN state = 'paid' THEN 1 END) AS paid,\n  COUNT(DISTINCT CASE WHEN state IN('new','paying','completing') THEN user_id END) AS in_progress,\n  COUNT(DISTINCT CASE WHEN state IN('payment_failed','completion_failed') THEN user_id END) AS failed\nFROM orders\nWHERE created_at BETWEEN ? AND ?\nGROUP BY DATE(created_at);\n"]], ['SQL sum of column value, unique per user per day'], 2, 1], [(14296002, 0), [['First - get the  max(maxattached)  for every customer and month:'], ['Next - for every customer rank all his values:']], [[" SELECT id,\n       max(maxattached) as max_att         \nFROM myTable \nWHERE weekending >= now() - interval '1 year' \nGROUP BY id, date_trunc('month',weekending);\n"]], ['Need to find Average of top 3 records grouped by ID in SQL'], 5, 0], [(14296002, 1), [['Next - for every customer rank all his values:'], ['Next - get the top 3 for every customer:']], [[' SELECT id,\n       max_att,\n       row_number() OVER (PARTITION BY id ORDER BY max_att DESC) as max_att_rank\nFROM <previous select here>;\n']], ['Need to find Average of top 3 records grouped by ID in SQL'], 5, 0], [(14296002, 2), [['Next - get the top 3 for every customer:'], ['Next - get the  avg  of the values for every customer:']], [[' SELECT id,\n       max_att\nFROM <previous select here>\nWHERE max_att_rank <= 3;\n']], ['Need to find Average of top 3 records grouped by ID in SQL'], 5, 0], [(14296002, 3), [['Next - get the  avg  of the values for every customer:'], ['UPDATE2: Here is the query, that will work on 8.1 :']], [[' SELECT id,\n       avg(max_att) as avg_att\nFROM <previous select here>\nGROUP BY id;\n']], ['Need to find Average of top 3 records grouped by ID in SQL'], 5, 0], [(14296002, 4), [['UPDATE2: Here is the query, that will work on 8.1 :'], ['The idea - to take your initial query and run it for every customer ( customer_table  - table with all unique  id  for customers).']], [[" SELECT customer_id,\n       (SELECT round(avg(max_att),0)\n        FROM (SELECT max(maxattached) as max_att         \n              FROM table1\n              WHERE weekending >= now() - interval '2 year' \n                AND id = ct.customer_id\n              GROUP BY date_trunc('month',weekending)\n              ORDER BY max_att DESC\n              LIMIT 3) sub \n        ) as avg_att\nFROM customer_table ct;\n"]], ['Need to find Average of top 3 records grouped by ID in SQL'], 5, 1], [(14313834, 0), [['First, since  COUNT()  only counts non-null values, your  query  can be simplified:'], ['For  that  you would use:']], [[' SELECT count(DISTINCT names) AS unique_names\n      ,count(names) AS names_not_null\nFROM   table;\n']], ['Apply the same aggregate to every column in a table'], 2, 0], [(14313834, 1), [['For  that  you would use:'], ['Since  count(*)  count  all  rows and  count(names)  only rows with non-null  names . \n Removed inferior alternative after hint by @Andriy.']], [[' count(*) - count(names) AS names_null\n']], ['Apply the same aggregate to every column in a table'], 2, 0], [(14345171, 0), [['So for example when selecting data from a linked server you would generally use the following syntax to get the data:'], ['If you created a synonym for Linkedserver.database.schema.table as DBTable1 the syntax would be: ']], [[' SELECT *\nFROM Linkedserver.database.schema.table\n']], ['How to get data from two databases in two servers with one SELECT statement?'], 2, 0], [(14345171, 1), [['If you created a synonym for Linkedserver.database.schema.table as DBTable1 the syntax would be: '], ['It saves a bit on typing plus if your linked server ever changed you would not need to go do changes all over your code. Like I said this can really be of benefit if you use linked servers in a lot of code.']], [[' SELECT *\nFROM DBTable1\n']], ['How to get data from two databases in two servers with one SELECT statement?'], 2, 0], [(14355527, 0), [['Suggested design:-'], ["Under this structure, solving your specific problem, finding questions that haven't been answered yet, becomes trivial."]], [[' create table `user-questions`\n(\n   user_id int,\n   question_id int,\n   answered datetime\n)\n']], ['Get row, if ID is not in Array/comma-seperated-list'], 2, 0], [(14355527, 1), [["Under this structure, solving your specific problem, finding questions that haven't been answered yet, becomes trivial."], ["I don't play day to day with MySQL, so please feel free to correct any typos, SO'ers.  The approach is sound, though."]], [[" -- Find a question that hasn't been answered by user id 22.\nSELECT\n  q.* \nFROM \n  `questions`\nLEFT OUTER JOIN `user-questions` uq\nON q.question_id = uq.question_id\n-- Just a sample user ID\nAND uq.user_id = 22\nWHERE\n  uq.question_id IS NULL\n"]], ['Get row, if ID is not in Array/comma-seperated-list'], 2, 1], [(14366759, 0), [['-10000'], ['-10000']], [[" SELECT o.* \nFROM dbo.Orders o\nWHERE EXISTS ( SELECT *   FROM dbo.Transactions t1 \n               WHERE t1.OrderId = o.OrderId   AND t1.Code = 'TX33'\n             )\n  AND EXISTS ( SELECT *   FROM dbo.Transactions t2 \n               WHERE t2.OrderId = o.OrderId   AND t2.Code = 'TX34'\n             )\n  AND\n    (     EXISTS ( SELECT *   FROM dbo.Transactions t1 \n                   WHERE t1.OrderId = o.OrderId   AND t1.Code = 'TX35'\n                 )\n      AND EXISTS ( SELECT *   FROM dbo.Transactions t2 \n                   WHERE t2.OrderId = o.OrderId   AND t2.Code = 'TX36'\n\n    OR  EXISTS ( SELECT *   FROM dbo.Transactions t \n                 WHERE t.OrderId = o.OrderId    AND t.Code = 'TX37'\n               )\n\n    OR    EXISTS ( SELECT *   FROM dbo.Transactions t1 \n                   WHERE t1.OrderId = o.OrderId   AND t1.Code = 'TX38'\n                 )\n      AND EXISTS ( SELECT *   FROM dbo.Transactions t2 \n                   WHERE t2.OrderId = o.OrderId   AND t2.Code = 'TX39'\n                 )\n    ) ;\n"]], ['How do you perform a join to a table with "OR" conditions?'], 2, 1], [(14366759, 1), [['-10000'], ['-10000']], [[" SELECT o.* \nFROM dbo.Orders o\n  JOIN\n    ( SELECT OrderId\n      FROM dbo.Transactions\n      WHERE Code IN ('TX33', 'TX34', 'TX35', 'TX36', 'TX37', 'TX38', 'TX39')\n      GROUP BY OrderId\n      HAVING COUNT(DISTINCT CASE WHEN Code = 'TX33' THEN Code END) = 1\n         AND COUNT(DISTINCT CASE WHEN Code = 'TX34' THEN Code END) = 1\n         AND ( COUNT(DISTINCT \n                     CASE WHEN Code IN ('TX35', 'TX36') THEN Code END) = 2\n            OR COUNT(DISTINCT CASE WHEN Code = 'TX37' THEN Code END) = 1\n            OR COUNT(DISTINCT \n                     CASE WHEN Code IN ('TX38', 'TX39') THEN Code END) = 2\n             ) \n    ) t\n    ON t.OrderId = o.OrderId ;\n"]], ['How do you perform a join to a table with "OR" conditions?'], 2, 1], [(14372302, 0), [['You should use  UNION .  Try this (untested):'], ["Well I just realized you don't have a SourceId or TitleId in your Table3.  Not going to be able to get that information, but you could still do:"]], [[' SELECT t.title_name, s.source_name, t1.text_content, t1.added_date   \nFROM Table1 t1\nJOIN Title T \n   ON t1.TitleId = T.TitleId\nJOIN Source S \n   ON t1.SourceId = S.SourceId\nUNION\nSELECT t.title_name, s.source_name, t2.description, t2.added_date   \nFROM Table2 t2\nJOIN Title T \n   ON t2.TitleId = T.TitleId\nJOIN Source S \n   ON t2.SourceId = S.SourceId\nUNION\nSELECT t.title_name, s.source_name, t3.description, t3.added_date   \nFROM Table3 t3\nJOIN Title T \n   ON t3.TitleId = T.TitleId\nJOIN Source S \n   ON t3.SourceId = S.SourceId\n']], ['Sql query to get result from 3 tables'], 2, 1], [(14372302, 1), [["Well I just realized you don't have a SourceId or TitleId in your Table3.  Not going to be able to get that information, but you could still do:"], ['-10000']], [[" SELECT DISTINCT Title_Name, Source_Name, Text_Content, Added_Date\nFROM \n(\n   SELECT t.title_name, s.source_name, t1.text_content, t1.added_date   \n   FROM Table1 t1\n   JOIN Title T \n     ON t1.TitleId = T.TitleId\n   JOIN Source S \n     ON t1.SourceId = S.SourceId\n   UNION\n   SELECT t.title_name, s.source_name, t2.description, t2.added_date   \n   FROM Table2 t2\n   JOIN Title T \n     ON t2.TitleId = T.TitleId\n   JOIN Source S \n     ON t2.SourceId = S.SourceId\n   UNION\n   SELECT t3.title, 'Unknown', t3.description, t3.added_date   \n   FROM Table3 t3\n) t\nORDER BY added_date\n"]], ['Sql query to get result from 3 tables'], 2, 1], [(14374677, 0), [['you can use  inline IF  statement. eg'], ['UPDATE 1']], [[" UPDATE articles\nSET publishedDate = IF(published = 1, 'new date HERE', publishedDate)\n-- WHERE condition here\n"]], ['Update a field just another one has some condition'], 2, 1], [(14374677, 1), [['UPDATE 1'], ['-10000']], [[' -- assumes 0 = false, 1 = true\nSET @status := 1;\nSET @newDate := CURDATE();\n\nUPDATE articles\nSET publishedDate = IF(1 = @status, @newDate, publishedDate),\n    published = @status\n-- WHERE condition here\n']], ['Update a field just another one has some condition'], 2, 1], [(14385741, 0), [['-10000'], ["To address @Habo's point, you could also do:"]], [[' SELECT columns FROM dbo.table2\nWHERE \n    CONVERT(DATE, given_schedule) \n    = CONVERT(DATE, DATEADD(DAY, -3, CURRENT_TIMESTAMP))\nAND \n    DATEPART(HOUR, given_schedule) \n    = DATEPART(HOUR, CURRENT_TIMESTAMP);\n']], ['Retrieve rows from a certain day but only in a certain hour'], 2, 1], [(14385741, 1), [["To address @Habo's point, you could also do:"], ['This is, of course, most useful if there is actually an index with  given_schedule  as the leading column.']], [[' DECLARE @s SMALLDATETIME = CURRENT_TIMESTAMP;\n\nSET @s = DATEADD(DAY, -3, DATEADD(MINUTE, -DATEPART(MINUTE, @s), @s));\n\nSELECT columns FROM dbo.table2\n  WHERE given_schedule >= @s\n  AND given_schedule < DATEADD(HOUR, 1, @s);\n']], ['Retrieve rows from a certain day but only in a certain hour'], 2, 1], [(14400023, 0), [['(1) You can generate a table using syntax, such as:'], ['Actually, I would be inclined to drop the requirement of one row per student and instead have one row per student/bad character.  Here is an approach:']], [[" select chr(13) as badchar from dual union all\nselect '!' . . .\n"]], ['Display columns that contain a carriage return'], 2, 0], [(14400023, 1), [['Actually, I would be inclined to drop the requirement of one row per student and instead have one row per student/bad character.  Here is an approach:'], ['It leaves an extra comma at the end of the column names.  This can be removed by making this a subquery and doing string manipulations at the next level.']], [[" select a.id,\n       a.addr_1, a.addr_2, a.addr_3, a.addr_4, a.addr_5, a.addr_6, a.addr_7,\n       ((case when INSTR(a.addr_1, b.badChar) > 0 then 'addr_1,' else '' end) ||\n        (case when INSTR(a.addr_2, b.badChar) > 0 then 'addr_2,' else '' end) ||\n        (case when INSTR(a.addr_3, b.badChar) > 0 then 'addr_3,' else '' end) ||\n        (case when INSTR(a.addr_4, b.badChar) > 0 then 'addr_4,' else '' end) ||\n        (case when INSTR(a.addr_5, b.badChar) > 0 then 'addr_5,' else '' end) ||\n        (case when INSTR(a.addr_6, b.badChar) > 0 then 'addr_6,' else '' end) ||\n        (case when INSTR(a.addr_7, b.badChar) > 0 then 'addr_7,' else '' end)\n       ) as addrs,\n       b.badChar\nfrom a cross join\n     (select chr(13) as badChar from dual) as b\nWHERE INSTR(a.addr_1, b.badChar) > 0 OR\n      INSTR(a.addr_2, b.badChar) > 0 OR\n      INSTR(a.addr_3, b.badChar) > 0 OR\n      INSTR(a.addr_4, b.badChar) > 0 OR\n      INSTR(a.addr_5, b.badChar) > 0 OR\n      INSTR(a.addr_6, b.badChar) > 0 OR\n      INSTR(a.addr_7, b.badChar) > 0;\n"]], ['Display columns that contain a carriage return'], 2, 0], [(14416241, 0), [["you can use XMLTABLE. as your XML document seems to be a fragment in the row, i've wrapped this in a  <root>  element."], ['example output for group1:']], [[' select grp, substr(name, \n              instr(name, \'/\', -1) + 1,\n              instr(name, \'@\') - instr(name, \'/\', -1) - 1\n             ) name\n  from mytab m, \n       xmltable(xmlnamespaces(\'DAV:\' as "D"), \n                \'/root/D:href\' passing xmltype(\'<root>\'||usr||\'</root>\')\n                columns\n                name varchar2(200) path \'./text()\');\n']], ['ORACLE Parsing XML string into separate records'], 2, 1], [(14442822, 0), [['Use a  PARAMETERS  clause as the first line of your SQL to inform the db engine the form control contains a Date/Time value.'], ['Then use the parameter with  DateAdd()  in your WHERE clause:']], [[' PARAMETERS Forms!Frm_Start![Date] DateTime;\n']], ['Using a date field from a form in an access query'], 3, 0], [(14446303, 0), [['Try using   NOT EXISTS  instead of  COUNT = 0 . This should perform much better.'], ['I believe using  LEFT JOIN/IS NULL  is more efficient in MySQL than using  NOT EXISTS , so this will perform better than the above (although perhaps not significantly):']], [[' SELECT  COUNT(*)\nFROM    log AS log_main\nWHERE   log_main.status=1 \nAND     NOT EXISTS\n        (   SELECT 1\n            FROM   log AS log_inner\n            WHERE   log_inner.fingerprint_id=log_main.fingerprint_id\n            AND     log_inner.status = 0\n            AND     log_inner.date < log_main.date \n            AND     log_inner.date >= (log_main.date - INTERVAL 35 SECOND)\n        );\n']], ['Find records that have related records in the past'], 3, 1], [(14446303, 1), [['I believe using  LEFT JOIN/IS NULL  is more efficient in MySQL than using  NOT EXISTS , so this will perform better than the above (although perhaps not significantly):'], ['To get records with 1 or 2 attempts etc I would still use a JOIN, but like so:']], [[' SELECT  COUNT(*)\nFROM    log AS log_main\n        LEFT JOIN log AS log_inner\n            ON log_inner.fingerprint_id=log_main.fingerprint_id\n            AND log_inner.status = 0\n            AND log_inner.date < log_main.date \n            AND log_inner.date >= (log_main.date - INTERVAL 35 SECOND)\nWHERE   log_main.status = 1 \nAND     Log_inner.fingerprint_id IS NULL;\n']], ['Find records that have related records in the past'], 3, 1], [(14446303, 2), [['To get records with 1 or 2 attempts etc I would still use a JOIN, but like so:'], ['-10000']], [[' SELECT  COUNT(*)\nFROM    (   SELECT  log_Main.id\n            FROM    log AS log_main\n                    INNER JOIN log AS log_inner\n                        ON log_inner.fingerprint_id=log_main.fingerprint_id\n                        AND log_inner.status = 0\n                        AND log_inner.date < log_main.date \n                        AND log_inner.date >= (log_main.date - INTERVAL 35 SECOND)\n            WHERE   log_main.status = 1 \n            AND     Log_inner.fingerprint_id IS NULL\n            GROUP BY log_Main.id\n            HAVING COUNT(log_Inner.id) = 1\n        ) d\n']], ['Find records that have related records in the past'], 3, 1], [(14469652, 1), [['ie your base query:'], ['the partition splits our calculations per ID(unique row):']], [[' select rownum id, name, start_date,\n\xa0 \xa0 \xa0 \xa0end_date, trunc(end_date)-trunc(start_date) date_range\n\xa0 from table1\n']], ['How to generate rows for date range by key'], 7, 0], [(14469652, 2), [['the partition splits our calculations per ID(unique row):'], ['the measures:']], [[' 6 \xa0model partition by(id as key)\n']], ['How to generate rows for date range by key'], 7, 0], [(14469652, 3), [['the measures:'], ['the rules define HOW we are going to populate our columns:']], [[' 8 \xa0 \xa0 \xa0 \xa0measures(name, start_date, cast(null as date) the_date, date_range)\n']], ['How to generate rows for date range by key'], 7, 0], [(14469652, 4), [['the rules define HOW we are going to populate our columns:'], ['so with\xa0']], [[' 9 \xa0 \xa0 \xa0 \xa0rules (the_date [for f from 0 to date_range[0] increment 1] \xa0= start_date[0] + cv(f),\n10 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 name[any] = name[0]);\n']], ['How to generate rows for date range by key'], 7, 0], [(14469652, 5), [['so with\xa0'], ["p.s. \nfor connect by you'd need to do something like this:"]], [[' the_date [for f from 0 to date_range[0] increment 1]\n']], ['How to generate rows for date range by key'], 7, 0], [(14469652, 6), [["p.s. \nfor connect by you'd need to do something like this:"], ['i.e. isolate the connect by to a subquery, then filter out the rows where individual_day > end_date.']], [[" select \n    A.EMPLOYEE_NAME,\n    A.START_DATE+(b.r-1) AS INDIVIDUAL_DAY,\n    TO_CHAR(A.START_DATE,'MM/DD/YYYY') START_DATE,\n    TO_CHAR(A.END_DATE,'MM/DD/YYYY') END_DATE\nFROM table1 A\n     cross join (select rownum r\n                   from (select max(end_date-start_date) d from table1)\n                  connect by level-1 <= d) b\n where A.START_DATE+(b.r-1) <= A.END_DATE\n order by 1, 2;\n"]], ['How to generate rows for date range by key'], 7, 0], [(14479213, 0), [["Try this (Assuming  'HE'  has a space on either side);"], ['Another way is;']], [[" select name, count\nfrom yourTable where charindex(' he ',name)=0\nunion\nselect 'HE' name, sum(count) as count\nfrom yourTable where charindex(' he ',name)>0\n"]], ['Join 2 rows in same table sql query'], 2, 1], [(14479213, 1), [['Another way is;'], ['-10000']], [[" select A.name, sum(A.count) as count\nfrom (\n    select case charindex(' he ',name) \n           when 0 then name else 'HE' end name, count\n    from yourTable\n) A\ngroup by A.name\norder by A.name\n"]], ['Join 2 rows in same table sql query'], 2, 1], [(14482625, 1), [['ie:'], ['-10000']], [[' SQL> select * from dual;\n\nD\n-\nX\n\nSQL> col DUMMY format a5\nSQL> select * from dual;\n\nDUMMY\n-----\nX\n']], ['Display full column name instead of shortened'], 2, 1], [(14501440, 0), [['This will remove leading and trailing spaces'], ['some versions of SQL Support']], [[' Update tablename set fieldName = ltrim(rtrim(fieldName));\n']], ['How to delete leading empty space in a SQL Database Table using MS SQL Server Managment Studio'], 3, 1], [(14501440, 1), [['some versions of SQL Support'], ['If you just want to remove leading']], [[' Update tablename set fieldName = trim(fieldName);\n']], ['How to delete leading empty space in a SQL Database Table using MS SQL Server Managment Studio'], 3, 1], [(14501440, 2), [['If you just want to remove leading'], ['-10000']], [[' update tablename set fieldName = LTRIM(fieldName);\n']], ['How to delete leading empty space in a SQL Database Table using MS SQL Server Managment Studio'], 3, 1], [(14513314, 0), [['(1) Using a statement block'], ['(2) Calling stored procedures.']], [[" IF \n(SELECT COUNT(*) FROM Production.Product WHERE Name LIKE 'Touring-3000%' ) > 5\nBEGIN\n   PRINT 'There are 5 Touring-3000 bikes.'\nEND\nELSE \nBEGIN\n   PRINT 'There are Less than 5 Touring-3000 bikes.'\nEND ;\n"]], ['if statement using a query in sql'], 2, 1], [(14513314, 1), [['(2) Calling stored procedures.'], ['More Examples:']], [[" DECLARE @compareprice money, @cost money \nEXECUTE Production.uspGetList '%Bikes%', 700, \n    @compareprice OUT, \n    @cost OUTPUT\nIF @cost <= @compareprice \nBEGIN\n    PRINT 'These products can be purchased for less than \n    $'+RTRIM(CAST(@compareprice AS varchar(20)))+'.'\nEND\nELSE\n    PRINT 'The prices for all products in this category exceed \n    $'+ RTRIM(CAST(@compareprice AS varchar(20)))+'.'\n"]], ['if statement using a query in sql'], 2, 1], [(14537280, 0), [['Something like this:'], ['As requested in the comment, here is a trigger to update only movies that have reviews greater than 2 in LateRating:']], [[' CREATE trigger update_LateRating_title INSTEAD OF UPDATE OF title ON LateRating\nBEGIN\n  UPDATE Movie SET title = new.title WHERE movie.mID = old.mID;\nEND;\n']], ['SQL instead-of trigger'], 2, 1], [(14537280, 1), [['As requested in the comment, here is a trigger to update only movies that have reviews greater than 2 in LateRating:'], ['(There are different ways to interpret this later request. Should title updates be allowed for the  movie  which has more than 2 stars somewhere or only for the  record  actually having more than 2 stars? My code is for the former choice).']], [[' CREATE trigger update_LateRating_title INSTEAD OF \nUPDATE OF title ON LateRating\nBEGIN\n  UPDATE Movie SET title = new.title \n  WHERE movie.mID = old.mID \n  AND movie.mID IN (SELECT mID FROM LateRating WHERE stars > 2);\nEND;\n']], ['SQL instead-of trigger'], 2, 1], [(14540736, 0), [['Try something like this:'], ['Here is the updated query -- both should work just fine though, this is just easier to read:']], [[' SELECT t1.state, \n   t1.lname, \n   t1.fname, \n   t1.network as t1Network, \n   t2.network as t2Network\nFROM table1 t1 \n   INNER JOIN table2 t2 \n      ON t1.fname=t2.fname \n      AND t1.lname=t2.lname \n      AND t1.state=t2.state\n      AND t1.network=t2.network\nUNION \nSELECT t1.state, \n   t1.lname, \n   t1.fname, \n   t1.network as t1Network, \n   t2.network as t2Network\nFROM table1 t1 \n   LEFT JOIN table2 t2 \n      ON t1.fname=t2.fname \n      AND t1.lname=t2.lname \n      AND t1.state=t2.state\n      AND t1.network=t2.network\nWHERE t2.network IS NULL\nUNION \nSELECT t2.state, \n   t2.lname, \n   t2.fname, \n   t1.network as t1Network, \n   t2.network as t2Network\nFROM table2 t2 \n   LEFT JOIN table1 t1\n      ON t1.fname=t2.fname \n      AND t1.lname=t2.lname \n      AND t1.state=t2.state\n      AND t1.network=t2.network\nWHERE t1.network IS NULL\n']], ['sql avoid cartesian product'], 2, 1], [(14540736, 1), [['Here is the updated query -- both should work just fine though, this is just easier to read:'], ['And the  updated fiddle .']], [[' SELECT t1.state, \n   t1.lname, \n   t1.fname, \n   t1.network as t1Network, \n   t2.network as t2Network\nFROM table1 t1 \n   LEFT JOIN table2 t2 \n      ON t1.fname=t2.fname \n      AND t1.lname=t2.lname \n      AND t1.state=t2.state\n      AND t1.network=t2.network\nUNION \nSELECT t2.state, \n   t2.lname, \n   t2.fname, \n   t1.network as t1Network, \n   t2.network as t2Network\nFROM table2 t2 \n   LEFT JOIN table1 t1\n      ON t1.fname=t2.fname \n      AND t1.lname=t2.lname \n      AND t1.state=t2.state\n      AND t1.network=t2.network\nWHERE t1.network IS NULL\n']], ['sql avoid cartesian product'], 2, 1], [(14540917, 0), [["I'm a little confused by your question, but it sounds like you're trying to make your Company_X_Sales table have 3 rows instead of 1, just with varying quantities?  If so, something like this should work:"], ['To get those rows into the table, you have a few options, but something like this should work:']], [[' SELECT S.PO_Number, C.InterCO_PO_no, C.Sales_Order_No, C.Part_No, S.Qty\nFROM Company_X_Sales C\n   JOIN CPC_Sales S ON C.InterCO_PO_no = S.InterCO_SO_No\n']], ['How can I create multiple rows from a single row (sql server 2008)'], 2, 1], [(14540917, 1), [['To get those rows into the table, you have a few options, but something like this should work:'], ['Good luck.']], [[' --Flag the rows for deletion\nUPDATE Company_X_Sales SET Qty = -1 -- Or some arbitrary value that does not exist in the table\n\n--Insert new correct rows\nINSERT INTO Company_X_Sales \nSELECT C.InterCO_PO_no, C.Sales_Order_No, C.Part_No, S.Qty\nFROM Company_X_Sales C\n   JOIN CPC_Sales S ON C.InterCO_PO_no = S.InterCO_SO_No\n\n--Cleanup flagged rows for deletion\nDELETE FROM Company_X_Sales  WHERE Qty = -1\n']], ['How can I create multiple rows from a single row (sql server 2008)'], 2, 1], [(14565788, 0), [['I would use this:'], ['This will group by the first of every month, so ']], [[" SELECT  Closing_Date = DATEADD(MONTH, DATEDIFF(MONTH, 0, Closing_Date), 0), \n        Category,  \n        COUNT(Status) TotalCount \nFROM    MyTable\nWHERE   Closing_Date >= '2012-02-01' \nAND     Closing_Date <= '2012-12-31'\nAND     Defect_Status1 IS NOT NULL\nGROUP BY DATEADD(MONTH, DATEDIFF(MONTH, 0, Closing_Date), 0), Category;\n"]], ['How to group by month from Date field using sql'], 3, 1], [(14565788, 1), [['This will group by the first of every month, so '], ['Alternatively you could use something like this:']], [[" `DATEADD(MONTH, DATEDIFF(MONTH, 0, '20130128'), 0)` \n"]], ['How to group by month from Date field using sql'], 3, 0], [(14565788, 2), [['Alternatively you could use something like this:'], ['It really depends what your desired output is. (Closing Year is not necessary in your example, but if the date range crosses a year boundary it may be).']], [[" SELECT  Closing_Year = DATEPART(YEAR, Closing_Date),\n        Closing_Month = DATEPART(MONTH, Closing_Date),\n        Category,  \n        COUNT(Status) TotalCount \nFROM    MyTable\nWHERE   Closing_Date >= '2012-02-01' \nAND     Closing_Date <= '2012-12-31'\nAND     Defect_Status1 IS NOT NULL\nGROUP BY DATEPART(YEAR, Closing_Date), DATEPART(MONTH, Closing_Date), Category;\n"]], ['How to group by month from Date field using sql'], 3, 1], [(14610658, 0), [['You can do this in one step. A tested example may be found here:  http://sqlfiddle.com/#!2/05760/12'], ['-10000']], [[' SELECT \n  COUNT(*) / \n  COUNT(DISTINCT cast(`date` as date)) avg_posts_per_day\nFROM \n  posts\n']], ['Average or calculate average'], 2, 1], [(14610658, 1), [['-10000'], ['-10000']], [[' SELECT \n  AVG(posts_per_day) AS AVG_POSTS_PER_DAY\nFROM (    \n  SELECT \n    CAST(`date` as date), \n    COUNT(*) posts_per_day\n  FROM posts  \n  GROUP BY \n    CAST(`date` as date)\n) ppd\n']], ['Average or calculate average'], 2, 1], [(14636287, 0), [['-10000'], ['Result:']], [[' declare @XMLData xml = \'\n<Upload xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema">\n  <DeviceID>0008E02B66DD_</DeviceID>\n  <DeviceType>03.20</DeviceType>\n  <FarmID>2</FarmID>\n  <UploadDate>0001-01-01T00:00:00</UploadDate>\n  <Sessions>\n    <SessionID>99</SessionID>\n    <RecordedDate>2012-02-03T13:00:00+13:00</RecordedDate>\n    <Readings />\n  </Sessions>\n</Upload>\';\n\nselect T.N.value(\'substring((RecordedDate/text())[1], 1, 19)\', \'datetime\'),\n       T.N.value(\'(RecordedDate/text())[1]\', \'datetime\'),\n       T.N.value(\'(RecordedDate/text())[1]\', \'datetimeoffset\')\nfrom @XMLData.nodes(\'/Upload/Sessions\') as T(N);\n']], ['Convert local datetime from xml to datetime in sql'], 2, 1], [(14636287, 1), [['Result:'], ['-10000']], [[' 2012-02-03 13:00:00.000 \n2012-02-03 00:00:00.000 \n2012-02-03 13:00:00.0000000 +13:00\n']], ['Convert local datetime from xml to datetime in sql'], 2, 0], [(14636901, 0), [['Here is an example:'], ['As @Erwin Brandstetter correctly points out, using  rank()  will produce the correct results and allow for sorting on additional fields (in this case, appraisal).  ']], [[' SELECT\n    p.*\n    ,h.address\n    ,h.appraisal\nFROM (SELECT *, row_number() over() rn FROM people) p\nLEFT JOIN homes h\n    ON h.person_id = p.person_id\nORDER BY p.rn, h.appraisal;\n']], ['PostgreSQL ORDER BY with VIEWs'], 2, 1], [(14636901, 1), [['As @Erwin Brandstetter correctly points out, using  rank()  will produce the correct results and allow for sorting on additional fields (in this case, appraisal).  '], ['Think about it this way, using row_number(), it will always sort by that field only, regardless of any other sorting parameters.  By using rank() where ties are the same, other fields can easily be search upon.  ']], [[' SELECT\n    p.*\n    ,h.address\n    ,h.appraisal\nFROM (SELECT *, rank() over() rn FROM people) p\nLEFT JOIN homes h\n    ON h.person_id = p.person_id\nORDER BY p.rn, h.appraisal;\n']], ['PostgreSQL ORDER BY with VIEWs'], 2, 1], [(14672688, 0), [["I'll prefer to use  CASE  here."], ['or']], [[' UPDATE TAble1\nSET Result = CASE value\n                WHEN 1 THEN x\n                WHEN 2 THEN y\n                ....\n                ELSE z\n            END\n']], ['How to Update a MYSQL Column Based On Varying Conditions'], 2, 1], [(14672688, 1), [['or'], ['-10000']], [[' UPDATE TAble1\nSET Result = CASE \n                WHEN value = 1 THEN x\n                WHEN value = 2 THEN y\n                ....\n                ELSE z\n            END\n']], ['How to Update a MYSQL Column Based On Varying Conditions'], 2, 1], [(14675304, 0), [['The following does what you want:'], ["If for some reason you don't have an id, you can take your chances with the following query:"]], [[' select top 4 *\nfrom (select top 5 *\n      from Article a\n      order by id desc\n     ) a\norder by id asc\n']], ['How to get (One Before Last) row in SQL Server 2005'], 3, 1], [(14675304, 1), [["If for some reason you don't have an id, you can take your chances with the following query:"], ['By the way, you can use the same idea with a real column:']], [[' select a.*\nfrom (select a.*, row_number() over (order by (select NULL)) as seqnum,\n             count(*) over () as totcnt\n      from Article a\n     ) a\nwhere seqnum between totcnt - 5 and totcnt - 1\n']], ['How to get (One Before Last) row in SQL Server 2005'], 3, 1], [(14675304, 2), [['By the way, you can use the same idea with a real column:'], ['-10000']], [[' select a.*\nfrom (select a.*, row_number() over (order by id) as seqnum,\n             count(*) over () as totcnt\n      from Article a\n     ) a\nwhere seqnum between totcnt - 5 and totcnt - 1\n']], ['How to get (One Before Last) row in SQL Server 2005'], 3, 1], [(14699703, 0), [['You could concat as string aggregation using the format for your  Table1 , '], ['You could get the result as:']], [[" SELECT col1,\n     col2,\n     col3,\n     listagg(col4, ',') within GROUP(\nORDER BY col4) AS col4\nFROM agg_test\nGROUP BY col1,\n     col2,\n     col3;\n"]], ['Loop through all rows and concat unique values in SQL table'], 2, 1], [(14699703, 1), [['You could get the result as:'], ['-10000']], [[' col1    col2    col3    col4\n______________________________________    \nval1    val2    val3    val4,val5,val6\nvalx    valy    valz    val4,val5\n']], ['Loop through all rows and concat unique values in SQL table'], 2, 0], [(14705215, 2), [['You can use small variation of this query to get rank of single user, but avoid issue of the same ranking ambiguity:'], ['-10000']], [[" SELECT *\nFROM (\n    SELECT\n        @rank:=@rank+1 AS rank,\n        name,\n        poin\n    FROM user,\n        (SELECT @rank:=0) r\n    ORDER BY poin DESC\n) x\nWHERE name = 'user1'\n"]], ['How to find rows in SQL / MySQL with ORDER BY'], 3, 1], [(14730469, 0), [['MS SQL Server 2008 Schema Setup :'], ['Query 1 :']], [[" create table tblFile\n(\n  FileName varchar(10),\n  FileLocation varchar(30)\n)\n\ninsert into tblFile values\n('file1',                  '\\\\server1\\folder1\\file1'),\n('file1',                  '\\\\server2\\folder1\\file1'),\n('file2',                  '\\\\server1\\folder1\\file2'),\n('file2',                  '\\\\server2\\folder1\\file2')\n"]], ['Row data to column'], 3, 0], [(14730469, 1), [['Query 1 :'], ['Results :']], [[" select T1.FileName,\n       (\n       select ', '+T2.FileLocation\n       from tblFile as T2\n       where T1.FileName = T2.FileName\n       for xml path(''), type\n       ).value('substring(text()[1], 3)', 'varchar(max)') as FileLocations\nfrom tblFile as T1\ngroup by T1.FileName\n"]], ['Row data to column'], 3, 1], [(14730469, 2), [['Results :'], ['-10000']], [[' | FILENAME |                                    FILELOCATIONS |\n---------------------------------------------------------------\n|    file1 | \\\\server1\\folder1\\file1, \\\\server2\\folder1\\file1 |\n|    file2 | \\\\server1\\folder1\\file2, \\\\server2\\folder1\\file2 |\n']], ['Row data to column'], 3, 0], [(14732938, 0), [['You can use an aggregate function and a  CASE  to  pivot  the data:'], ['Or you can use the  PIVOT  function:']], [[" select\n  name,\n  max(case when date = '2013-04-01' then city end) [City 04/01/2013],\n  max(case when date = '2013-05-01' then city end) [City 05/01/2013]\nfrom yourtable\ngroup by name\n"]], ['Pivot on a single table'], 5, 1], [(14732938, 1), [['Or you can use the  PIVOT  function:'], ['This can even be done by joining on your table multiple times:']], [[' select name, [2013-04-01] as [City 04/01/2013], [2013-05-01] as [City 05/01/2013]\nfrom\n(\n  select name, city, date\n  from yourtable\n) src\npivot\n(\n  max(city)\n  for date in ([2013-04-01], [2013-05-01])\n) piv\n']], ['Pivot on a single table'], 5, 1], [(14732938, 2), [['This can even be done by joining on your table multiple times:'], ['The above queries will work great if you have known dates that you want to transform into columns. But if you have an unknown number of columns, then you will want to use dynamic sql:']], [[" select d1.name,\n  d1.city [City 04/01/2013], \n  d2.city [City 05/01/2013]\nfrom yourtable d1\nleft join yourtable d2\n  on d1.name = d2.name\n  and d2.date = '2013-05-01'\nwhere d1.date = '2013-04-01'\n"]], ['Pivot on a single table'], 5, 1], [(14732938, 3), [['The above queries will work great if you have known dates that you want to transform into columns. But if you have an unknown number of columns, then you will want to use dynamic sql:'], ['All of them give the result:']], [[" DECLARE @cols AS NVARCHAR(MAX),\n    @colNames AS NVARCHAR(MAX),\n    @query  AS NVARCHAR(MAX)\n\nselect @cols = STUFF((SELECT distinct ',' + QUOTENAME(convert(char(10), date, 120)) \n                    from yourtable\n            FOR XML PATH(''), TYPE\n            ).value('.', 'NVARCHAR(MAX)') \n        ,1,1,'')\n\nselect @colNames = STUFF((SELECT distinct ',' + QUOTENAME(convert(char(10), date, 120)) +' as '+ QUOTENAME('City '+convert(char(10), date, 120))\n                    from yourtable\n            FOR XML PATH(''), TYPE\n            ).value('.', 'NVARCHAR(MAX)') \n        ,1,1,'')\n\nset @query = 'SELECT name, ' + @colNames + ' from \n             (\n                select name, \n                  city, \n                  convert(char(10), date, 120) date\n                from yourtable\n            ) x\n            pivot \n            (\n                max(city)\n                for date in (' + @cols + ')\n            ) p '\n\nexecute(@query)\n"]], ['Pivot on a single table'], 5, 1], [(14732938, 4), [['All of them give the result:'], ['-10000']], [[' |   NAME | CITY 04/01/2013 | CITY 05/01/2013 |\n----------------------------------------------\n|   Paul |           Milan |          Berlin |\n| Charls |            Rome |        El Cairo |\n|    Jim |           Tokyo |           Milan |\n| Justin |   San Francisco |           Paris |\n|   Bill |          London |          Madrid |\n']], ['Pivot on a single table'], 5, 0], [(14746540, 1), [['This assumes you have a convenient Table of Elements in your database:'], ['-10000']], [[" CREATE TABLE elements\n(\n    atomic_number   INTEGER NOT NULL PRIMARY KEY CONSTRAINT c1_elements\n                    CHECK (atomic_number > 0 AND atomic_number < 120),\n    symbol          CHAR(3) NOT NULL UNIQUE CONSTRAINT c2_elements,\n    name            CHAR(20) NOT NULL UNIQUE CONSTRAINT c3_elements,\n    atomic_weight   DECIMAL(8, 4) NOT NULL,\n    period          SMALLINT NOT NULL\n                    CHECK (period BETWEEN 1 AND 7),\n    group           CHAR(2) NOT NULL\n                    -- 'L' for Lanthanoids, 'A' for Actinoids\n                    CHECK (group IN ('1', '2', 'L', 'A', '3', '4', '5', '6',\n                                     '7', '8', '9', '10', '11', '12', '13',\n                                     '14', '15', '16', '17', '18')),\n    stable          CHAR(1) DEFAULT 'Y' NOT NULL\n                    CHECK (stable IN ('Y', 'N'))\n);\n\nINSERT INTO elements VALUES(  1, 'H',   'Hydrogen',        1.0079, 1, '1',  'Y');\nINSERT INTO elements VALUES(  2, 'He',  'Helium',          4.0026, 1, '18', 'Y');\nINSERT INTO elements VALUES(  3, 'Li',  'Lithium',         6.9410, 2, '1',  'Y');\nINSERT INTO elements VALUES(  4, 'Be',  'Beryllium',       9.0122, 2, '2',  'Y');\nINSERT INTO elements VALUES(  5, 'B',   'Boron',          10.8110, 2, '13', 'Y');\nINSERT INTO elements VALUES(  6, 'C',   'Carbon',         12.0110, 2, '14', 'Y');\nINSERT INTO elements VALUES(  7, 'N',   'Nitrogen',       14.0070, 2, '15', 'Y');\nINSERT INTO elements VALUES(  8, 'O',   'Oxygen',         15.9990, 2, '16', 'Y');\nINSERT INTO elements VALUES(  9, 'F',   'Fluorine',       18.9980, 2, '17', 'Y');\nINSERT INTO elements VALUES( 10, 'Ne',  'Neon',           20.1800, 2, '18', 'Y');\nINSERT INTO elements VALUES( 11, 'Na',  'Sodium',         22.9900, 3, '1',  'Y');\nINSERT INTO elements VALUES( 12, 'Mg',  'Magnesium',      24.3050, 3, '2',  'Y');\nINSERT INTO elements VALUES( 13, 'Al',  'Aluminium',      26.9820, 3, '13', 'Y');\nINSERT INTO elements VALUES( 14, 'Si',  'Silicon',        28.0860, 3, '14', 'Y');\nINSERT INTO elements VALUES( 15, 'P',   'Phosphorus',     30.9740, 3, '15', 'Y');\nINSERT INTO elements VALUES( 16, 'S',   'Sulphur',        32.0650, 3, '16', 'Y');\nINSERT INTO elements VALUES( 17, 'Cl',  'Chlorine',       35.4530, 3, '17', 'Y');\nINSERT INTO elements VALUES( 18, 'Ar',  'Argon',          39.9480, 3, '18', 'Y');\n"]], ['How to select from table where the table name is a local variable(informix)'], 2, 0], [(14790098, 0), [['-10000'], ['If not then maybe:']], [[" Select  SEC_TO_TIME(SUM(TIME_TO_SEC(timediff(timeOut, timeIn)))) AS totalhours\nFROM volHours \nWHERE username = 'skolcz'\n"]], ['MySQL - SUM of a group of time differences'], 2, 1], [(14790098, 1), [['If not then maybe:'], ['-10000']], [[" Select  SEC_TO_TIME(SELECT SUM(TIME_TO_SEC(timediff(timeOut, timeIn))) \nFROM volHours \nWHERE username = 'skolcz') as totalhours\n"]], ['MySQL - SUM of a group of time differences'], 2, 1], [(14792677, 0), [["Simple.  Don't use  VALUES()  (you're already doing it to refer to the existing value of  check_status ):"], ['Or use it to set the new content rather than repeating yourself:']], [[" INSERT INTO some_table ('description', 'comment', 'some_unique_key')\nVALUES ('some description', 'some comment', 32)\nON DUPLICATE KEY UPDATE\ndescription = IF(check_status = 1, description, 'some description')\ncomment = IF(check_status = 1, comment, 'some comment')\n"]], ['MySQL upsert with extra check'], 2, 1], [(14792677, 1), [['Or use it to set the new content rather than repeating yourself:'], ['-10000']], [[" INSERT INTO some_table ('description', 'comment', 'some_unique_key')\nVALUES ('some description', 'some comment', 32)\nON DUPLICATE KEY UPDATE\ndescription = IF(check_status = 1, description, VALUES(description))\ncomment = IF(check_status = 1, comment, VALUES(comment))\n"]], ['MySQL upsert with extra check'], 2, 1], [(14830410, 0), [['It seems like the following query is what you need. Notice that the filter for  memberid = 200  has been moved to the join condition:'], ['This query gives the result:']], [[' select s.section_id,\n  s.title,\n  s.description,\n  m.status\nfrom Sections s\nleft join SectionMembers sm\n  on s.section_id = sm.section_id\n  and sm.memberid = 200\nleft join MemberStatus m\n  on sm.status_code = m.status_code\nwhere s.section_ownerid = 100;\n']], ['Multiple Table Joins with WHERE clause'], 2, 1], [(14830410, 1), [['This query gives the result:'], ['-10000']], [[' | SECTION_ID |  TITLE | DESCRIPTION |         STATUS |\n------------------------------------------------------\n|          1 | title1 |       desc1 |  PendingMember |\n|          2 | title2 |       desc2 | MemberRejected |\n|          3 | title3 |       desc3 | MemberRejected |\n|          4 | title4 |       desc4 |   ActiveMember |\n|          5 | title5 |       desc5 |         (null) |\n|          6 | title6 |       desc6 |         (null) |\n']], ['Multiple Table Joins with WHERE clause'], 2, 0], [(14838374, 0), [['Assuming the above is true then you can use table valued parameters. The first step would be to create your parameter:'], ['Then you can create a procedure to get your filtered results']], [[' CREATE TYPE dbo.TableFilter AS TABLE \n(   Name        VARCHAR(50), \n    LowerValue  INT, \n    UpperValue  INT\n);\n']], ['TSQL dynamic filters on one column'], 3, 0], [(14838374, 1), [['Then you can create a procedure to get your filtered results'], ['Then you can call your procedure using something like:']], [[' CREATE PROCEDURE dbo.CustomTableFilter @Filter dbo.TableFilter READONLY\nAS\n    SELECT  T.*\n    FROM    T\n    WHERE   EXISTS\n            (   SELECT  1\n                FROM    @Filter f\n                WHERE   T.Name = f.Name\n                AND     T.Value >= f.LowerValue \n                AND     T.Value <= f.UpperValue\n            )\n']], ['TSQL dynamic filters on one column'], 3, 0], [(14838374, 2), [['Then you can call your procedure using something like:'], ['Example on SQL Fiddle']], [[" DECLARE @Filter dbo.TableFilter;\nINSERT @Filter VALUES ('X', 1, 5), ('Y', 10, 25);\n\nEXECUTE dbo.CustomTableFilter @Filter;\n"]], ['TSQL dynamic filters on one column'], 3, 0], [(14841239, 0), [["If I understand you correctly, you're working with columns that contain multiple, delimited values (like the PICK database) :"], ['Typically, in a normalized database, one would have:']], [[' `For multiple parts, this character | is added and the structure is repeated.`\n']], ['sql normalize a table'], 2, 0], [(14841239, 1), [['Typically, in a normalized database, one would have:'], ['There could be zero, one, or multiple UNIT_SERVICES associated with a UNIT.\nThere could be zero, one, or multiple SERVICE_PARTS associated with a SERVICE.']], [[' UNIT  (something that might need service or repair)\nUnitId  PK\nUnitDescription\n\nPARTS  (repair / replacement parts)\nPartId PK\nPartDescription\n\nUNIT_SERVICES  (instances of repair visits/ service)\nServiceID   int primary key\nUnitId      foreign key references UNIT\nServiceDate\nTechnicianID\netc\n\n\nSERVICE_PART   (part used in the service)\nID          primary key\nServiceID   foreign key references SERVICE\nPartID      foreign key references PART\nQuantity\n']], ['sql normalize a table'], 2, 0], [(14849316, 1), [['For modified requirements:'], ["To work around what appears to be a 9i bug (probably fixed in 9.2.0.3 or 9.2.0.6 according to MOS, but depends exectly which bug you're hitting):"]], [[' with t as (\n    select id, dt, lead(dt) over (partition by id order by dt) as next_dt\n    from t42\n    where id in (4, 5)\n)\nselect t4.id as id4, t4.dt as date4, t5.id as id5, min(t5.dt) as date5\nfrom t t4\njoin t t5 on t5.dt > t4.dt and (t4.next_dt is null or t5.dt <= t4.next_dt)\nwhere t4.id = 4\nand t5.id = 5\ngroup by t4.id, t4.dt, t5.id\norder by t4.dt;\n\n       ID4 DATE4                        ID5 DATE5               \n---------- --------------------- ---------- ---------------------\n         4 16.03.2012 17:49:28            5 10.05.2012 09:38:56   \n         4 12.06.2012 08:47:52            5 02.08.2012 11:27:43   \n         4 03.08.2012 13:24:54            5 03.08.2012 14:14:07   \n']], ['How to fetch consecutive pairs of records in Oracle'], 3, 1], [(14849316, 2), [["To work around what appears to be a 9i bug (probably fixed in 9.2.0.3 or 9.2.0.6 according to MOS, but depends exectly which bug you're hitting):"], ["I don't have an old enough version to test this against unfortunately. You don't have to use the  t5  subselect, you could just join your main table straight to  t4 , but I think this is a little clearer."]], [[' select t4.id as id4, t4.dt as date4, t5.id as id5, min(t5.dt) as date5\nfrom (\n    select id, dt, lead(dt) over (partition by id order by dt) as next_dt\n    from t42\n    where id = 4\n) t4\njoin (select id, dt\n    from t42\n    where id = 5\n) t5 on t5.dt > t4.dt and (t4.next_dt is null or t5.dt <= t4.next_dt)\ngroup by t4.id, t4.dt, t5.id\norder by t4.dt;\n']], ['How to fetch consecutive pairs of records in Oracle'], 3, 1], [(14856663, 1), [['Or a LINQ query'], ['then you can do:']], [['     int rowIndex = -1;\n\n    DataGridViewRow row = dgv.Rows\n        .Cast<DataGridViewRow>()\n        .Where(r => r.Cells["SystemId"].Value.ToString().Equals(searchValue))\n        .First();\n\n    rowIndex = row.Index;\n']], ['Datagrid textbox search C#'], 3, 1], [(14856663, 2), [['then you can do:'], ['-10000']], [['  dataGridView1.Rows[rowIndex].Selected = true;\n']], ['Datagrid textbox search C#'], 3, 0], [(14860852, 1), [['You then use the view as you would use any table'], ['-10000']], [[' SELECT data, speeding\nFROM ViewName\n']], ['Set column to automatically pull data from referenced table'], 2, 0], [(14866797, 0), [['you can use  CASE  on this,'], ['-10000']], [[" SELECT  SUM(arc_baseEventCount) 'total event count', \n        SUM(CASE WHEN arc_name = 'Connector Raw Event Statistics' THEN arc_baseEventCount ELSE NULL END) 'Connector Raw Event Statistics'\nFROM    Events\n"]], ['cartesian product - SUM two columns in the same table'], 2, 1], [(14866797, 1), [['-10000'], ['-10000']], [[" SELECT  SUM(arc_baseEventCount) 'total event count', \n        SUM(CASE WHEN arc_name = 'Connector Raw Event Statistics' THEN arc_baseEventCount ELSE NULL END) 'total_1',\n        SUM(CASE WHEN name = 'Connector Raw Event Statistics' THEN arc_deviceCustomNumber3 ELSE NULL END) 'total_2'\nFROM    Events\n"]], ['cartesian product - SUM two columns in the same table'], 2, 1], [(14903899, 0), [['You can use the following:'], ['Or you can use:']], [[" select t1.col1,\n  t1.col2, \n  t1.col3,\n  left(t2.col4, len(t2.col4)-1) col4\nfrom table1 t1\ncross apply\n(\n  select cast(t2.Col4 as varchar(10)) + ', '\n  from Table2 t2\n  where t1.col1 = t2.col1\n  FOR XML PATH('')\n) t2 (col4)\n"]], ['sub query with comma delimited output in one column'], 2, 1], [(14903899, 1), [['Or you can use:'], ['See  SQL Fiddle with Demo']], [[" select t1.col1,\n  t1.col2, \n  t1.col3,\n  STUFF(\n         (SELECT ', ' + cast(t2.Col4 as varchar(10))\n          FROM Table2 t2\n          where t1.col1 = t2.col1\n          FOR XML PATH (''))\n          , 1, 1, '')  AS col4\nfrom table1 t1\n"]], ['sub query with comma delimited output in one column'], 2, 1], [(14930630, 0), [["You are missing the  FROM  clause, and the string literals must be in  ''  instead of double quotes. If the  age  is of data type numeric, remove the quotes around it, if not use  '' . Something like:"], ['This should give you the row:']], [[" Select person1.*\nFROM person1\nwhere person1.age    = 42 \n  and person1.job    = 'bng' \n  and person1.gender = 'f';\n"]], ['How to select attributes in a relational database where I have to check multiple attributes?'], 2, 1], [(14930630, 1), [['This should give you the row:'], ['-10000']], [[' | PERSON1 | AGE | JOB | GENDER |\n--------------------------------\n|      p2 |  42 | bng |      f |\n']], ['How to select attributes in a relational database where I have to check multiple attributes?'], 2, 0], [(14952911, 0), [['Say, you have a table:\n'], ['Now, to achieve your case you can do the following:\n']], [[' CREATE TABLE tab (\n  id  integer PRIMARY KEY,\n  a1  integer\n);\n']], ['Postgres: How to create reference cell?'], 2, 0], [(14952911, 1), [['Now, to achieve your case you can do the following:\n'], ["As you can see, I'm using existing columns in the formula and assign the result a new alias  a2 ."]], [[' SELECT id,\n       a1,\n       a1+1 AS a2\n  FROM tab;\n']], ['Postgres: How to create reference cell?'], 2, 1], [(14961787, 0), [['This should work:'], ['And it produces these results:']], [[' SELECT O.OrderId, C.ChargeId\nFROM Orders O\n  JOIN Charges C ON O.CustomerId = C.CustomerId AND\n    (C.ProductId = O.ProductId OR C.ProductId = 0)\nORDER BY O.OrderId, C.ChargeId\n']], ['SQL Server 2005: Insert one to many (1 Order-Many Charges) results into @table'], 2, 1], [(14961787, 1), [['And it produces these results:'], ['-10000']], [[' ORDERID   CHARGEID\n1         1\n1         2\n2         3\n2         4\n3         5\n4         1\n']], ['SQL Server 2005: Insert one to many (1 Order-Many Charges) results into @table'], 2, 0], [(14964462, 0), [['That can be done with the case expression:'], ['For nullable Boolean bit more is needed:']], [[' UPDATE FOO a \nSET a.bar = \n  CASE a.bar \n    WHEN TRUE THEN FALSE\n    ELSE TRUE END\nWHERE a.id in :ids\n']], ['JPA Query for toggling a boolean in a UPDATE'], 2, 1], [(14964462, 1), [['For nullable Boolean bit more is needed:'], ['-10000']], [[' UPDATE FOO a \nSET a.bar = \n  CASE a.bar \n    WHEN TRUE THEN FALSE\n    WHEN FALSE THEN TRUE\n    ELSE a.bar END\nWHERE a.id in :ids\n']], ['JPA Query for toggling a boolean in a UPDATE'], 2, 1], [(14965566, 0), [['Making some assumptions about your data as in comments, particularly about how to match and pick a substitute  name  value; and with some dummy data that I think matches yours:'], ['This gets your result:']], [[" create table tablea(out_num number,\n    equip_name varchar2(5),\n    event_type varchar2(10),\n    comments varchar2(10),\n    timestamp date, feed_id number);\n\ncreate table tableb(id number, name varchar2(10));\n\nalter session set nls_date_format = 'MM/DD/YYYY HH24:MI';\n\ninsert into tablea values (12345, null, 'abcd', null, to_date('02/11/2013 11:12'), 1);\ninsert into tablea values (12345, null, 'abcd', null, to_date('02/11/2013 11:11'), 1);\ninsert into tablea values (12345, null, 'abcd', null, to_date('02/11/2013 11:06'), 1);\ninsert into tablea values (12345, null, 'abcd', null, to_date('02/11/2013 11:06'), 1);\ninsert into tablea values (12345, null, 'SUB', null, to_date('02/11/2013 11:11'), 2);\ninsert into tablea values (12345, null, 'SUB', null, to_date('02/11/2013 11:12'), 2);\ninsert into tablea values (12345, null, 'XYZ', null, to_date('02/11/2013 11:13'), 3);\ninsert into tablea values (12345, null, 'XYZ', null, to_date('02/11/2013 11:13'), 3);\ninsert into tablea values (12345, null, 'XYZ', null, to_date('02/11/2013 11:13'), 3);\ninsert into tablea values (12345, null, 'XYZ', null, to_date('02/11/2013 11:13'), 3);\ninsert into tablea values (12345, null, 'XYZ', null, to_date('02/11/2013 11:13'), 3);\ninsert into tablea values (12345, null, 'XYZ', null, to_date('02/11/2013 11:03'), 3);\ninsert into tablea values (12345, null, 'CAUSE', 'APPLE', to_date('02/11/2013 11:13'), 4);\ninsert into tablea values (12345, null, 'CAUSE', 'APPLE', to_date('02/11/2013 11:13'), 4);\ninsert into tablea values (12345, null, 'CAUSE', 'APPLE', to_date('02/11/2013 11:13'), 4);\ninsert into tablea values (12345, null, 'STATUS', 'BOOKS', to_date('02/11/2013 11:13'), 5);\ninsert into tablea values (12345, null, 'STATUS', 'BOOKS', to_date('02/11/2013 11:13'), 5);\ninsert into tablea values (12345, null, 'STATUS', 'BOOKS', to_date('02/11/2013 11:03'), 5);\n\ninsert into tableb values(3, 'LION');\n"]], ['How to copy in field if query returns it blank?'], 4, 0], [(14965566, 1), [['This gets your result:'], ['If I add some more data for a different  out_num :']], [[" select * from (\n    select a.out_num,\n        a.timestamp,\n        a.equip_name,\n        a.event_type,\n        a.comments,\n        coalesce(b.name,\n            first_value(b.name)\n                over (partition by a.out_num\n                    order by b.name nulls last)) as name\n    from tablea a\n    left outer join tableb b on a.feed_id = b.id\n    where a.out_num = '12345'\n    and a.event_type in ('CAUSE', 'STATUS', 'XYZ')\n)\nwhere event_type in ('CAUSE', 'STATUS');\n\n   OUT_NUM TIMESTAMP          EQUIP_NAME EVENT_TYPE COMMENTS   NAME     \n---------- ------------------ ---------- ---------- ---------- ----------\n     12345 02/11/2013 11:03              STATUS     BOOKS      LION       \n     12345 02/11/2013 11:13              STATUS     BOOKS      LION       \n     12345 02/11/2013 11:13              STATUS     BOOKS      LION       \n     12345 02/11/2013 11:13              CAUSE      APPLE      LION       \n     12345 02/11/2013 11:13              CAUSE      APPLE      LION       \n     12345 02/11/2013 11:13              CAUSE      APPLE      LION       \n"]], ['How to copy in field if query returns it blank?'], 4, 1], [(14965566, 2), [['If I add some more data for a different  out_num :'], ["...then this - which just has the filter dropped, and I've left out the  coalesce  this time - gives the same answer for  12345 , and this for  12346 :"]], [[" insert into tablea values (12346, null, 'abcd', null, to_date('02/11/2013 11:11'), 1);\ninsert into tablea values (12346, null, 'SUB', null, to_date('02/11/2013 11:12'), 2);\ninsert into tablea values (12346, null, 'XYZ', null, to_date('02/11/2013 11:13'), 6);\ninsert into tablea values (12346, null, 'CAUSE', 'APPLE', to_date('02/11/2013 11:14'), 4);\ninsert into tablea values (12346, null, 'STATUS', 'BOOKS', to_date('02/11/2013 11:15'), 5);\n\ninsert into tableb values(1, 'TIGER');\n"]], ['How to copy in field if query returns it blank?'], 4, 0], [(14965566, 3), [["...then this - which just has the filter dropped, and I've left out the  coalesce  this time - gives the same answer for  12345 , and this for  12346 :"], ['... where  TIGER  is linked to  abcd , not  XYZ .']], [[" select * from (\n    select a.out_num,\n        a.timestamp,\n        a.equip_name,\n        a.event_type,\n        a.comments,\n        first_value(b.name)\n            over (partition by a.out_num\n                order by b.name nulls last) as name\n    from tablea a\n    left outer join tableb b on a.feed_id = b.id\n)\nwhere out_num = '12346'\nand event_type in ('CAUSE', 'STATUS');\n\n   OUT_NUM TIMESTAMP          EQUIP_NAME EVENT_TYPE COMMENTS   NAME     \n---------- ------------------ ---------- ---------- ---------- ----------\n     12346 02/11/2013 11:14              CAUSE      APPLE      TIGER      \n     12346 02/11/2013 11:15              STATUS     BOOKS      TIGER      \n"]], ['How to copy in field if query returns it blank?'], 4, 1], [(15002034, 0), [['In MySQL you will want to use the  GROUP_CONCAT()  function which will concatenate the multiple rows into a single row.  Since this is an aggregate function, you will also use a  GROUP BY  clause on the query:'], ['The result is:']], [[' select p.id,\n  p.name,\n  group_concat(c.id order by c.id) ChildrenIds,\n  group_concat(c.name order by c.id) ChildrenNames\nfrom parent p\nleft join children c\n  on p.id = c.parent_id\ngroup by p.id, p.name\n']], ['SQL to group more than one records of a joined table?'], 2, 1], [(15002034, 1), [['The result is:'], ['-10000']], [[' | ID |     NAME | CHILDRENIDS |                    CHILDRENNAMES |\n------------------------------------------------------------------\n|  1 | Parent 1 |         1,2 |            Child P1 1,Child P1 2 |\n|  2 | Parent 2 |       3,4,5 | Child P2 1,Child P2 2,Child P2 3 |\n']], ['SQL to group more than one records of a joined table?'], 2, 0], [(15034144, 0), [['You can do this by using  row_number()  to create a fake join column:'], ['Actually, in Oracle, you can also just use  rownum :']], [[' select coalesce(a.id, b.id) as id, a.colors, b.states\nfrom (select a.*, row_number() over (order by id) as seqnum\n      from a\n     ) a full outer join\n     (select b.*, row_number() over (order by id) as seqnum\n      from b\n     ) b\n     on b.seqnum = a.seqnum\n']], ['Is it possible to join two tables of multiple rows by only the first ID in each table?'], 2, 1], [(15034144, 1), [['Actually, in Oracle, you can also just use  rownum :'], ['-10000']], [[' select coalesce(a.id, b.id) as id, a.colors, b.states\nfrom (select a.*, rownum as seqnum\n      from a\n     ) a full outer join\n     (select b.*, rownum as seqnum\n      from b\n     ) b\n     on b.seqnum = a.seqnum\n']], ['Is it possible to join two tables of multiple rows by only the first ID in each table?'], 2, 1], [(15066914, 1), [['and it gives me:'], ['and I need:']], [[' USERNAME                  NAME            SURNAME  \n------------------------- --------------- ---------------\nexisting_user              Hello           All\n\n1 row selected.\n']], ['SQL return Information by not existing rows'], 3, 0], [(15066914, 2), [['and I need:'], ['The Problem: the user not_existing_user is not existing in the DataBase, \nbut the query has to show him anyway from the code\nwith the Info - User not in the DB. \nFor 500 Users I can not check everyone separate :/']], [[' USERNAME                  NAME            SURNAME  \n------------------------- --------------- ---------------\nexisting_user             Hello           All\nnot_existing_user     Not Exists      Not Exists\n\n2 row selected.\n']], ['SQL return Information by not existing rows'], 3, 0], [(15100101, 0), [['An inefficient approach, but one that is relatively easy to follow, would be something like'], ["You can then call that in a SQL statement (I would think that you'd want at least a third column with the column name)"]], [[" SQL> ed\nWrote file afiedt.buf\n\n  1  create or replace type emp_unpivot_type\n  2  as object (\n  3    empno number,\n  4    col   varchar2(4000)\n  5* );\nSQL> /\n\nType created.\n\nSQL> create or replace type emp_unpivot_tbl\n  2  as table of emp_unpivot_type;\n  3  /\n\nType created.\n\nSQL> ed\nWrote file afiedt.buf\n\n  1  create or replace function unpivot_emp\n  2  ( p_empno in number )\n  3    return emp_unpivot_tbl\n  4    pipelined\n  5  is\n  6    l_val varchar2(4000);\n  7  begin\n  8    for cols in (select column_name from user_tab_columns where table_name = 'EMP')\n  9    loop\n 10      execute immediate 'select ' || cols.column_name || ' from emp where empno = :empno'\n 11         into l_val\n 12       using p_empno;\n 13      pipe row( emp_unpivot_type( p_empno, l_val ));\n 14    end loop;\n 15    return;\n 16* end;\nSQL> /\n\nFunction created.\n"]], ['UNPIVOT on an indeterminate number of columns'], 2, 1], [(15100101, 1), [["You can then call that in a SQL statement (I would think that you'd want at least a third column with the column name)"], ["A more efficient approach would be to adapt Tom Kyte's  show_table pipelined table function ."]], [[' SQL> ed\nWrote file afiedt.buf\n\n  1  select *\n  2*   from table( unpivot_emp( 7934 ))\nSQL> /\n\n     EMPNO COL\n---------- ----------------------------------------\n      7934 7934\n      7934 MILLER\n      7934 CLERK\n      7934 7782\n      7934 23-JAN-82\n      7934 1301\n      7934\n      7934 10\n\n8 rows selected.\n']], ['UNPIVOT on an indeterminate number of columns'], 2, 0], [(15108987, 0), [['This is really easy with  union .  Try this:'], ['By the way, if you have duplicates, you might want this instead:']], [[' (select t.* from t where t.col <= YOURNAME\n order by t.col desc\n limit 6\n)\nunion all\n(select t.* from t where t.col > YOURNAME\n order by t.col\n limit 5\n)\norder by t.col\n']], ['Mysql get a number of before and afer rows'], 2, 1], [(15108987, 1), [['By the way, if you have duplicates, you might want this instead:'], ['-10000']], [[' (select t.* from t where t.col = YOURNAME)\nunion all\n(select t.* from t where t.col < YOURNAME\n order by t.col desc\n limit 5\n)\nunion all\n(select t.* from t where t.col > YOURNAME\n order by t.col\n limit 5\n)\norder by t.col\n']], ['Mysql get a number of before and afer rows'], 2, 1], [(15117826, 0), [['Users:'], ['White_Rules']], [[' User_ID |   Source_ID\n--------+--------------\n  1     |      1  \n']], ['selecting multiple counts when tables not directly co-relate'], 7, 0], [(15117826, 1), [['White_Rules'], ['Black_Rules']], [[' Victim_ID | Rule_ID\n----------+-------------\n   1      |    1\n   1      |    2\n']], ['selecting multiple counts when tables not directly co-relate'], 7, 0], [(15117826, 2), [['Black_Rules'], ['If you run']], [[' Victim_ID | Rule_ID\n----------+-------------\n   1      |    3\n   1      |    4\n']], ['selecting multiple counts when tables not directly co-relate'], 7, 0], [(15117826, 3), [['If you run'], ['You will get all combinations of  White_Rules.Rule_ID  and  Black_Rules.Rule_ID :']], [[' SELECT  Users.User_ID, \n        Users.Source_ID, \n        White_Rules.Rule_ID AS WhiteRuleID, \n        Black_Rules.Rule_ID AS BlackRuleID\nFROM    Users\n        LEFT JOIN White_Rules\n            ON White_Rules.Victim_ID = Users.User_ID\n        LEFT JOIN Black_Rules\n            ON Black_Rules.Victim_ID = Users.User_ID\n']], ['selecting multiple counts when tables not directly co-relate'], 7, 0], [(15117826, 4), [['You will get all combinations of  White_Rules.Rule_ID  and  Black_Rules.Rule_ID :'], ['You should get the required results if you change your query to this:']], [[' User_ID | Source_ID | WhiteRuleID | BlackRuleID\n--------+-----------+-------------+-------------\n  1     |    1      |      1      |      3\n  1     |    1      |      2      |      4\n  1     |    1      |      1      |      3\n  1     |    1      |      2      |      4\n']], ['selecting multiple counts when tables not directly co-relate'], 7, 0], [(15117826, 5), [['You should get the required results if you change your query to this:'], ['An alternative would be:']], [[" SELECT  Users.Source_ID,\n        SUM(COALESCE(w.TotalWhite, 0)) AS TotalWhite,\n        SUM(COALESCE(b.TotalBlack, 0)) AS TotalBlack,\n        SUM(COALESCE(g.TotalGeneral, 0)) AS TotalGeneral\nFROM    Users\n        LEFT JOIN\n        (   SELECT  Victim_ID, COUNT(*) AS TotalWhite\n            FROM    White_Rules\n            GROUP BY Victim_ID\n        ) w\n            ON w.Victim_ID = Users.User_ID\n        LEFT JOIN\n        (   SELECT  Victim_ID, COUNT(*) AS TotalBlack\n            FROM    Black_Rules\n            GROUP BY Victim_ID\n        ) b\n            ON b.Victim_ID = Users.User_ID\n        LEFT JOIN\n        (   SELECT  Victim_ID, COUNT(*) AS TotalGeneral\n            FROM    General_Rules\n            GROUP BY Victim_ID\n        ) g\n            ON g.Victim_ID = Users.User_ID\nWHERE   Deleted = 'f'\nAND     Source IS NOT NULL\nGROUP BY Users.Source_ID\n"]], ['selecting multiple counts when tables not directly co-relate'], 7, 1], [(15117826, 6), [['An alternative would be:'], ['Example on SQL Fiddle']], [[" SELECT  Users.Source_ID,\n        COUNT(Rules.TotalWhite) AS TotalWhite,\n        COUNT(Rules.TotalBlack) AS TotalBlack,\n        COUNT(Rules.TotalGeneral) AS TotalGeneral\nFROM    Users\n        LEFT JOIN\n        (   SELECT  Victim_ID, 1 AS TotalWhite, NULL AS TotalBlack, NULL AS TotalGeneral\n            FROM    White_Rules\n            UNION ALL\n            SELECT  Victim_ID, NULL AS TotalWhite, 1 AS TotalBlack, NULL AS TotalGeneral\n            FROM    Black_Rules\n            UNION ALL\n            SELECT  Victim_ID, NULL AS TotalWhite, NULL AS TotalBlack, 1 AS TotalGeneral\n            FROM    General_Rules\n        ) Rules\n            ON Rules.Victim_ID = Users.User_ID\nWHERE   Deleted = 'f'\nAND     Source IS NOT NULL\nGROUP BY Users.Source_ID\n"]], ['selecting multiple counts when tables not directly co-relate'], 7, 1], [(15122065, 0), [['For that, you need to look at all the numbers.  The best way is using  group by  and  having :'], ['If you want to be sure that all 5 codes are selected, then use this condition:']], [[" select personid\nfrom person\ngroup by personid\nhaving sum(case when code not in ('1', '2', '3', '4', '5') then 1 else 0 end) = 0\n"]], ['SQL query for displaying specific data'], 2, 1], [(15150057, 0), [['The easiest way to do this is with a correlated subquery:'], ['To get the current date, use  isnull() :']], [[' select t.*,\n       (select top 1 dateadd(day, -1, startDate )\n        from tbl_temp t2\n        where t2.aid = t.aid and\n              t2.uid = t.uid and\n              t2.startdate > t.startdate\n       ) as endDate\nfrom tbl_temp t\n']], ['Adding a Date column based on the next row date value'], 2, 1], [(15150057, 1), [['To get the current date, use  isnull() :'], ["Normally, I would recommend  coalesce()  over  isnull() .  However, there is a bug in some versions of SQL Server where it evaluates the first argument twice.  Normally, this doesn't make a difference, but with a subquery it does."]], [[' select t.*,\n       isnull((select top 1 dateadd(day, -1, startDate )\n               from tbl_temp t2\n               where t2.aid = t.aid and\n                     t2.uid = t.uid and\n                     t2.startdate > t.startdate\n               ), getdate()\n              ) as endDate\nfrom tbl_temp t\n']], ['Adding a Date column based on the next row date value'], 2, 1], [(15187839, 0), [['-10000'], ['and if you want them in one column']], [[" SELECT\n  MIN(email) AS address1\n  IF(MAX(email)==MIN(email),NULL,MAX(email)) AS address2\nFROM emaillist\nGROUP BY substring_index(email, '@', -1);\n"]], ['MYSQL How do I Select all emails from a table but limit number of emails with the same domain'], 2, 1], [(15187839, 1), [['and if you want them in one column'], ['-10000']], [[" SELECT MIN(email) AS address1\nFROM emaillist\nGROUP BY substring_index(email, '@', -1)\nUNION\nSELECT MAX(email) AS address1\nFROM emaillist\nGROUP BY substring_index(email, '@', -1)\n"]], ['MYSQL How do I Select all emails from a table but limit number of emails with the same domain'], 2, 1], [(15203058, 0), [['I\'m not particullarly proud of this solution because it is not very clear, but at least it\'s fast and simple. If all of the items have  "done" = 1  then the sum will be equal to the count SUM = COUNT'], ['And if you add a having clause you get the items that are "done". ']], [[' SELECT query_id, SUM(done) AS doneSum, COUNT(done) AS doneCnt \nFROM tbl \nGROUP BY query_id\n']], ['Group the rows that are having the same value in specific field in MySQL'], 2, 1], [(15203058, 1), [['And if you add a having clause you get the items that are "done". '], ['I\'ll let you format the solution properly, you can do a DIFERENCE to get the "not done" items or doneSum <> doneCnt.']], [[' HAVING doneSum = doneCnt\n']], ['Group the rows that are having the same value in specific field in MySQL'], 2, 0], [(15208232, 0), [['Assuming there are no additional columns besides the 3 pairs listed, this can be done with a simple  WHERE  clause that tests for a non- NULL  start date in each column along with a corresponding  NULL  end.  If any of the three conditions is met, the  Company  will be returned.'], ["If your empty fields are actually empty strings  ''  instead of  NULL , substitute the empty string as in:"]], [[' SELECT DISTINCT Company\nFROM Table1\nWHERE\n  (Start1 IS NOT NULL AND End1 IS NULL)\n  OR (Start2 IS NOT NULL AND End2 IS NULL)\n  OR (Start3 IS NOT NULL AND End3 IS NULL)\n']], ['How to see if a field entry has a corresponding entry in another field?'], 2, 1], [(15208232, 1), [["If your empty fields are actually empty strings  ''  instead of  NULL , substitute the empty string as in:"], ["Note, the  DISTINCT  isn't needed if the  Company  column is a unique or primary key."]], [[" (Start1 <> '' AND End1 = '')\n"]], ['How to see if a field entry has a corresponding entry in another field?'], 2, 0], [(15237740, 0), [['just add having clause'], ['but if you only what the  ID']], [[' SELECT userId, COUNT(DISTINCT webpageId) AS count \nFROM visits \nGROUP BY userId\nHAVING COUNT(DISTINCT webpageId) > 1\n']], ['select users have more than one distinct records in mysql'], 2, 1], [(15237740, 1), [['but if you only what the  ID'], ['-10000']], [[' SELECT userId\nFROM visits \nGROUP BY userId\nHAVING COUNT(DISTINCT webpageId) > 1\n']], ['select users have more than one distinct records in mysql'], 2, 1], [(15243399, 0), [['Try this'], ['For the sample Oracle HR database it returns']], [[" SELECT 'Existing Tables: ' || wm_concat(table_name) tablenames \n  FROM user_tables;\n"]], ['Select all table names from Oracle DB'], 3, 1], [(15243399, 1), [['For the sample Oracle HR database it returns'], ['UPDATE:  Example with  LISTAGG()']], [[' TABLENAMES\n------------------------------------------------------------------------------------\nExisting Tables: REGIONS,LOCATIONS,DEPARTMENTS,JOBS,EMPLOYEES,JOB_HISTORY,COUNTRIES\n']], ['Select all table names from Oracle DB'], 3, 0], [(15243399, 2), [['UPDATE:  Example with  LISTAGG()'], ['-10000']], [[" SELECT 'Existing Tables: ' || LISTAGG(table_name, ',') \n        WITHIN GROUP (ORDER BY table_name) tablenames \n  FROM user_tables;\n"]], ['Select all table names from Oracle DB'], 3, 1], [(15264563, 0), [['You could get it like this:'], ['Note that in case if you had more than one signin/signout per day for an employee and you wanted to get his first  SignIn  and last  SignOut  for a day, you would have to change the query:']], [[" SELECT  l1.EmpID\n        , l1.LoginTime [SignIn]\n        , l2.LoginTime [SignOut]\nFROM    Login l1\nLEFT JOIN   \n        Login l2 ON \n        l2.EmpID = l1.EmpID\nAND     CAST(l2.LoginTime AS DATE) = CAST(l1.LoginTime AS DATE)\nAND     l2.status = 'SignOut'\nWHERE   l1.status = 'SignIn'\n"]], ['Aggregate on Datetime Column for Pivot'], 3, 1], [(15264563, 1), [['Note that in case if you had more than one signin/signout per day for an employee and you wanted to get his first  SignIn  and last  SignOut  for a day, you would have to change the query:'], ['And here is another query that also works for multiple signin/signouts of a user during the same day. This will list all of his signin/signouts in a day:']], [[" SELECT  l1.EmpID\n        , MIN(l1.LoginTime) [SignIn]\n        , MAX(l2.LoginTime) [SignOut]\nFROM    Login l1\nLEFT JOIN   \n        Login l2 ON \n        l2.EmpID = l1.EmpID\nAND     CAST(l2.LoginTime AS DATE) = CAST(l1.LoginTime AS DATE)\nAND     l2.status = 'SignOut'\nWHERE   l1.status = 'SignIn'\nGROUP BY\n        l1.EmpID, CAST(l1.LoginTime AS DATE)\n"]], ['Aggregate on Datetime Column for Pivot'], 3, 1], [(15264563, 2), [['And here is another query that also works for multiple signin/signouts of a user during the same day. This will list all of his signin/signouts in a day:'], ['Here is  SQL Fiddle  for last two queries that handle multiple signin/signout scenarios of a user in a single day, for that purpose I added user with  EmpID  102 to sample data.']], [[" ;WITH cte1 AS\n(\n    SELECT  *\n            , ROW_NUMBER() OVER \n                (PARTITION BY EmpID, CAST(LoginTime AS DATE) ORDER BY LoginTime) \n                AS num\n    FROM    Login\n)\n\nSELECT  l1.EmpID\n        , l1.LoginTime [SignIn]\n        , l2.LoginTime [SignOut]\nFROM    cte1 l1\nLEFT JOIN   \n        cte1 l2 ON \n        l2.EmpID = l1.EmpID\nAND     CAST(l2.LoginTime AS DATE) = CAST(l1.LoginTime AS DATE)\nAND     l2.num = l1.num + 1\nWHERE   l1.status = 'SignIn'\n"]], ['Aggregate on Datetime Column for Pivot'], 3, 1], [(15302356, 0), [["Accomplishing this in XSLT is not quite as straightforward as it would be in SQL, but assuming you assembled the two input files into a single document ahead of time (which I would recommend if it's not problematic for you):"], ['This XSLT can be used to join the data together:']], [[' <Xml>\n    <Classes>\n        <Class Name="BIOLOGY101" ClassId="11"/>\n        <Class Name="PHYSICS101" ClassId="13"/>\n        <Class Name="CALCULUS101" ClassId="17"/>\n        <Class Name="BIOLOGY101" ClassId="19"/>\n    </Classes>\n    <Students>\n        <Student Name="Bob Johnson" ClassId="11"/>\n        <Student Name="Bob Johnson" ClassId="17"/>\n        <Student Name="Bob Johnson" ClassId="19"/>\n        <Student Name="Joe Jackson" ClassId="11"/>\n        <Student Name="Joe Jackson" ClassId="13"/>\n        <Student Name="Joe Jackson" ClassId="17"/>\n        <Student Name="Rick Robertson" ClassId="13"/>\n        <Student Name="Rick Robertson" ClassId="17"/>\n        <Student Name="Rick Robertson" ClassId="19"/>\n    </Students>\n</Xml>\n']], ['How can I use XSLT to combine two XML docs, similar to a SQL JOIN'], 5, 0], [(15302356, 2), [['When this is run on the input XML above, it produces:'], ['And if you can change your XML a little to indicate the outer and inner group, and which attribute to match on, like this:']], [[' <Xml>\n  <Classes>\n    <Class Name="BIOLOGY101" ClassId="11">\n      <Student Name="Bob Johnson" />\n      <Student Name="Joe Jackson" />\n    </Class>\n    <Class Name="PHYSICS101" ClassId="13">\n      <Student Name="Joe Jackson" />\n      <Student Name="Rick Robertson" />\n    </Class>\n    <Class Name="CALCULUS101" ClassId="17">\n      <Student Name="Bob Johnson" />\n      <Student Name="Joe Jackson" />\n      <Student Name="Rick Robertson" />\n    </Class>\n    <Class Name="BIOLOGY101" ClassId="19">\n      <Student Name="Bob Johnson" />\n      <Student Name="Rick Robertson" />\n    </Class>\n  </Classes>\n</Xml>\n']], ['How can I use XSLT to combine two XML docs, similar to a SQL JOIN'], 5, 0], [(15302356, 3), [['And if you can change your XML a little to indicate the outer and inner group, and which attribute to match on, like this:'], ['Then you could use this more generic XSLT which, while less efficient, should work for any input similar to the above:']], [[' <Xml>\n  <Classes outer="true" matchAttribute="ClassId">\n     ....\n  </Classes>\n  <Students inner="true">\n     ....\n  </Students>\n</Xml>\n']], ['How can I use XSLT to combine two XML docs, similar to a SQL JOIN'], 5, 0], [(15357576, 0), [['You can simply do this:'], ['this will give you:']], [[" SELECT DISTINCT SONO,  ElectricalStatus\nFROM tablename\nWHERE  ElectricalStatus = 'Required';\n"]], ['select where.... electrical status is required in ms sql 2005'], 2, 1], [(15357576, 1), [['this will give you:'], ['-10000']], [[' | SONO | ELECTRICALSTATUS |\n---------------------------\n|    1 |         Required |\n|    2 |         Required |\n']], ['select where.... electrical status is required in ms sql 2005'], 2, 0], [(15359303, 0), [['-10000'], ['-10000']], [[' delete from tblA where\n  (col1, col2, ...) not in (queryB);\n\ninsert into tblA \n  (queryB) minus (select * from tblA);\n']], ['Change table contents to match a query without deleting all rows'], 2, 1], [(15359303, 1), [['-10000'], ['-10000']], [[' create table diff as\n   select \n      ta.rowid ta_rid, \n      tb.*\n   from tblA ta \n      full join (queryB) tb \n         on ta.col1 = tb.col1 \n         and ta.col2 = tb.col2 \n         and ta.col3 = tb.col3 \n   where \n      ta.rowid is null or tb.col1 is null; \n\ndelete from tblA ta \n  where ta.rowid in (select d.ta_rid from diff d where d.ta_rid is not null);\ninsert into tblA ta \n  select d.col1, d.col2, d.col3 from diff d where d.ta_rid is null;      \n']], ['Change table contents to match a query without deleting all rows'], 2, 1], [(15376335, 0), [['-10000'], ['-10000']], [[' SELECT   Product_ID, Date, Colour, Size, Material\nFROM\n        (\n            SELECT  Product_ID, Date, Attribute, Value\n            FROM    Table1\n        ) org\n        PIVOT\n        (\n            MAX(Value)\n            FOR Attribute IN (Colour, Size, Material)\n        ) pivotHeader\n']], ['Pivoting two colums leaving other columns in a table unchanged'], 3, 1], [(15376335, 1), [['-10000'], ['The other way of doing this is by using  MAX()  and  CASE']], [[' ╔════════════╦══════╦════════╦════════╦══════════╗\n║ PRODUCT_ID ║ DATE ║ COLOUR ║  SIZE  ║ MATERIAL ║\n╠════════════╬══════╬════════╬════════╬══════════╣\n║   10025135 ║ 2009 ║ Red    ║ 20 cm  ║ Steel    ║\n║   10025135 ║ 2010 ║ Green  ║ (null) ║ Alloy    ║\n║   10025136 ║ 2009 ║ Black  ║ 30cm   ║ (null)   ║\n╚════════════╩══════╩════════╩════════╩══════════╝\n']], ['Pivoting two colums leaving other columns in a table unchanged'], 3, 0], [(15376335, 2), [['The other way of doing this is by using  MAX()  and  CASE'], ['-10000']], [[" SELECT  Product_ID, DATE,\n        MAX(CASE WHEN Attribute = 'Colour' THEN Value END ) Colour,\n        MAX(CASE WHEN Attribute = 'Size' THEN Value END ) Size,\n        MAX(CASE WHEN Attribute = 'Material' THEN Value END ) Material\nFROM    Table1\nGROUP   BY Product_ID, DATE\n"]], ['Pivoting two colums leaving other columns in a table unchanged'], 3, 1], [(15387808, 0), [['You could use two sub-queries:'], ['Or']], [[' SELECT  a.*\n      , (SELECT Count(b.id) FROM inquiries I1 WHERE I1.dealer_id = a.id) as counttotal\n      , (SELECT SUM(b.cost) FROM inquiries I2 WHERE I2.dealer_id = a.id) as turnover\nFROM dealers a\nORDER BY name ASC\n']], ['MySQL Join two tables count and sum from second table'], 2, 1], [(15387808, 1), [['Or'], ['-10000']], [[' SELECT  a.*\n     , COALESCE(T.counttotal, 0) as counttotal   -- use coalesce or equiv. to turn NULLs to 0\n     , COALESCE(T.turnover, 0) as turnover       -- use coalesce or equiv. to turn NULLs to 0\n FROM dealers a\n LEFT OUTER JOIN (SELECT a.id, Count(b.id) as counttotal, SUM(b.cost) as turnover\n               FROM dealers a1 \n               INNER JOIN inquiries b ON a1.id = b.dealer_id\n              GROUP BY a.id) T\n         ON a.id = T.id\nORDER BY a.name\n']], ['MySQL Join two tables count and sum from second table'], 2, 1], [(15400897, 0), [['Try this -'], ['Tested code --']], [[' UPDATE TABLE set fieldname =  DATE_ADD( fieldname, INTERVAL 3 YEAR ) \n']], ['How to change date in database'], 2, 1], [(15400897, 1), [['Tested code --'], ['-10000']], [[" UPDATE date \nSET `varchardate`= DATE_FORMAT(DATE_ADD(  str_to_date(`varchardate`, '%d %M %Y'), INTERVAL 3 YEAR ) , '%d %M %Y')\n"]], ['How to change date in database'], 2, 1], [(15414398, 1), [['If you need the query to be flexible, then you will convert this to use dynamic SQL:'], ['The result of both is:']], [[" DECLARE @cols AS NVARCHAR(MAX),\n    @query  AS NVARCHAR(MAX)\n\nselect @cols = STUFF((SELECT ',' + QUOTENAME(subsection +'_'+sectioncode+'_Cost') \n                    from SectionNames\n                    group by subsection, sectioncode, sectionid\n                    order by sectionid\n            FOR XML PATH(''), TYPE\n            ).value('.', 'NVARCHAR(MAX)') \n        ,1,1,'')\n\nset @query = 'SELECT employeeid,' + @cols + ' \n              from \n             (\n                select e.employeeid,\n                  s.subsection +''_''+s.sectioncode+''_Cost'' Section,\n                  e.cost\n                from employee e\n                inner join sectionnames s\n                  on e.sectionid = s.sectionid\n            ) x\n            pivot \n            (\n                max(cost)\n                for section in (' + @cols + ')\n            ) p '\n\nexecute(@query)\n"]], ['Merge two or more columns dynamically based on table columns?'], 3, 1], [(15414398, 2), [['The result of both is:'], ['-10000']], [[' | EMPLOYEEID | INDIVIDUAL_XYZ_COST | FAMILY_XYZ_COST | FRIENDS_CYD_COST | LEVEL1_PCPO_COST | LEVEL2_PCPO_COST | LEVEL3_PCPO_COST |\n----------------------------------------------------------------------------------------------------------------------------------\n|          1 |                $200 |            $300 |              $40 |              $10 |         No Level |         No Level |\n']], ['Merge two or more columns dynamically based on table columns?'], 3, 0], [(15420689, 0), [["For encrypted values you can't. Even if you created the  tsvector  client-side, the tsvector would contain a form of the encrypted text so it wouldn't be acceptable for most applications. Observe:"], ['Sure, given the encrypted value:']], [[" regress=> SELECT to_tsvector('my secret password is CandyStrip3r');\n               to_tsvector                \n------------------------------------------\n 'candystrip3r':5 'password':3 'secret':2\n(1 row)\n"]], ['How do you do a PostgreSQL fulltext search on encoded or encrypted data?'], 4, 0], [(15420689, 1), [['Sure, given the encrypted value:'], ["you  can  (but shouldn't) do something like this:"]], [[" CREATE EXTENSION pgcrypto;\n\nregress=> SELECT encrypt( convert_to('my s3kritPassw1rd','utf-8'), '\\xdeadbeef', 'aes');\n                              encrypt                               \n--------------------------------------------------------------------\n \\x10441717bfc843677d2b76ac357a55ac5566ffe737105332552f98c2338480ff\n(1 row)\n"]], ['How do you do a PostgreSQL fulltext search on encoded or encrypted data?'], 4, 0], [(15428168, 0), [['Use  SELECT ... INTO :'], ["If you don't need to copy the data, only to create a new empty table with the same column structure, add a  WHERE  clause with a falsy expression:"]], [[' SELECT *\nINTO ABC_1\nFROM ABC;\n']], ['SQL Server - Create a copy of a database table and place it in the same database?'], 2, 1], [(15428168, 1), [["If you don't need to copy the data, only to create a new empty table with the same column structure, add a  WHERE  clause with a falsy expression:"], ['-10000']], [[' SELECT *\nINTO ABC_1\nFROM ABC\nWHERE 1 <> 1;\n']], ['SQL Server - Create a copy of a database table and place it in the same database?'], 2, 1], [(15436509, 0), [['-10000'], ['-10000']], [[' UPDATE data a\n       INNER JOIN data b\n          ON a.originalid = b.id\nSET a.data = b.data\n']], ['SQL: Copy some field values to another record inside the same table'], 2, 1], [(15436509, 1), [['-10000'], ['-10000']], [[' ╔════╦════════════╦════════════╗\n║ ID ║ ORIGINALID ║   STRING   ║\n╠════╬════════════╬════════════╣\n║  1 ║ (null)     ║ original 1 ║\n║  2 ║ (null)     ║ original 2 ║\n║  3 ║ 1          ║ original 1 ║\n║  4 ║ 2          ║ original 2 ║\n║  5 ║ 2          ║ original 2 ║\n╚════╩════════════╩════════════╝\n']], ['SQL: Copy some field values to another record inside the same table'], 2, 0], [(15445216, 0), [['Oracle has a  last_day()  function:'], ['Results:']], [[" SELECT LAST_DAY(to_date('04/04/1924','MM/DD/YYYY')) from dual;\n\nSELECT LAST_DAY(ADD_MONTHS(to_date('04/04/1924','MM/DD/YYYY'), -1)) from dual;\n\nSELECT LAST_DAY(ADD_MONTHS(to_date('04/04/1924','MM/DD/YYYY'), -2)) from dual;\n"]], ['How to get last day of a month from a given date?'], 2, 1], [(15445216, 1), [['Results:'], ['Use  Add_Months()  on your date to get the appropriate month, and then apply  last_day() .']], [[' April, 30 1924 00:00:00+0000\n\nMarch, 31 1924 00:00:00+0000\n\nFebruary, 29 1924 00:00:00+0000\n']], ['How to get last day of a month from a given date?'], 2, 0], [(15448705, 0), [['just add  TOP  to limit the number of results'], ['-10000']], [[" select TOP 1 COUNT(*) as 'Number of times a product is sold at same quantity' \nfrom  Sales.SalesOrderDetail \ngroup by  OrderQty, ProductID \norder by  COUNT(*) desc\n"]], ['Maximum of the count of the grouped elements'], 2, 1], [(15448705, 1), [['-10000'], ['-10000']], [[' WITH results \nAS\n(\n  select COUNT(*) as [Number of times a product is sold at same quantity],\n         DENSE_RANK() OVER (ORDER BY COUNT(*) DESC) rank_no \n  from   Sales.SalesOrderDetail \n  group   by OrderQty, ProductID \n)\nSELECT [Number of times a product is sold at same quantity]\nFROM   results\nWHERE  rank_no = 2\n']], ['Maximum of the count of the grouped elements'], 2, 1], [(15512015, 0), [['-10000'], ['Join  cte  to itself, but remove duplicates on  dob  from the second instance. Thereby everybody gets exactly one  UPDATE . If more than one person share the same  dop ,  the same one  is selected as younger sibling for all persons on the next  dob . I do this with:']], [['Query 1 WITH cte AS (\n   SELECT *, dense_rank() OVER (ORDER BY dob) AS drk\n   FROM   person\n    )\nUPDATE person p\nSET    younger_sibling_name = y.name\n      ,younger_sibling_dob  = y.dob\nFROM   cte x\nJOIN   (SELECT DISTINCT ON (drk) * FROM cte) y ON y.drk = x.drk + 1\nWHERE  x.pid = p.pid;\n']], ['Update PostgreSQL table with values from self'], 3, 1], [(15512015, 1), [['Join  cte  to itself, but remove duplicates on  dob  from the second instance. Thereby everybody gets exactly one  UPDATE . If more than one person share the same  dop ,  the same one  is selected as younger sibling for all persons on the next  dob . I do this with:'], ['Indices on  dob  and  pid  make this fast.']], [[' (SELECT DISTINCT ON (rnk) * FROM cte)\n']], ['Update PostgreSQL table with values from self'], 3, 0], [(15512015, 2), [['Indices on  dob  and  pid  make this fast.'], ['-> SQLfiddle']], [['Query 2 WITH cte AS (\n   SELECT dob, min(name) AS name\n         ,row_number() OVER (ORDER BY dob) rn\n   FROM   person p\n   GROUP  BY dob\n   )\nUPDATE person p\nSET    younger_sibling_name = y.name\n      ,younger_sibling_dob  = y.dob\nFROM   cte x\nJOIN   cte y ON y.rn = x.rn + 1\nWHERE  x.dob = p.dob;\n']], ['Update PostgreSQL table with values from self'], 3, 1], [(15532084, 0), [['You can do this by : '], ['then update all rows by : ']], [['     ALTER TABLE table_one\n    ADD COLUMN test_column VARCHAR(100) NULL;\n\n    GO;\n']], ['How do I add a calculated column in sql workbench / j'], 2, 0], [(15532084, 1), [['then update all rows by : '], ['-10000']], [[' UPDATE table_one\nSET test_column = (CASE WHEN LEFT(name,3) = "Ads" THEN "ok" ELSE "no" END) \n']], ['How do I add a calculated column in sql workbench / j'], 2, 0], [(15541196, 0), [['Use  LEFT JOIN  instead:'], ['-10000']], [[" SELECT \n  m.medianame,\n  IFNULL(COUNT(ad.id), 0) AS Total \nFROM a_mediatype as m\nLEFT JOIN a_advertise   AS a   ON a.mediaTypeId    = m.mediaId\nLEFT JOIN a_ad_display  AS ad  ON ad.advId         = a.advId\nLEFT JOIN organization_ AS o   ON a.organizationId = o.organizationId\nLEFT JOIN organization_ AS p   ON o.organizationId = p.organizationId \n                              AND p.organizationId = '37423'  \n                              AND o.treePath       LIKE CONCAT( p.treePath, '%')\nGROUP BY m.medianame;\n"]], ['how to fetch all data from one table in mysql?'], 2, 1], [(15541196, 1), [['-10000'], ['-10000']], [[' | MEDIANAME | TOTAL |\n---------------------\n| animation |    13 |\n|     image |     2 |\n|     video |     0 |\n']], ['how to fetch all data from one table in mysql?'], 2, 0], [(15543977, 0), [['Try this:'], ['This will give you something like this:']], [[" DECLARE @startDate DATETIME\nDECLARE @currentDate DATETIME\nDECLARE @numberOfWeeks INT\n\nDECLARE @dates TABLE(\n    StartDate DateTime,\n    EndDate DateTime \n)\n\nSET @startDate = GETDATE()--'2012-01-01' -- Put whatever you want here\nSET @numberOfWeeks = 8 -- Choose number of weeks here\nSET @currentDate = @startDate\n\nwhile @currentDate < dateadd(week, @numberOfWeeks, @startDate)\nbegin\n    INSERT INTO @Dates(StartDate, EndDate) VALUES (@currentDate, dateadd(day, 6, @currentDate))\n    set @currentDate = dateadd(day, 7, @currentDate);\nend\n\nSELECT * FROM @dates\n"]], ['MS SQL Server 2008 :Getting start date and end date of the week to next 8 weeks'], 3, 1], [(15543977, 1), [['This will give you something like this:'], ["Or you could tweak the final select if you don't want the time component, like this:"]], [[' StartDate           EndDate \n21/03/2013 11:22:46 27/03/2013 11:22:46 \n28/03/2013 11:22:46 03/04/2013 11:22:46 \n04/04/2013 11:22:46 10/04/2013 11:22:46 \n11/04/2013 11:22:46 17/04/2013 11:22:46 \n18/04/2013 11:22:46 24/04/2013 11:22:46 \n25/04/2013 11:22:46 01/05/2013 11:22:46 \n02/05/2013 11:22:46 08/05/2013 11:22:46 \n09/05/2013 11:22:46 15/05/2013 11:22:46 \n']], ['MS SQL Server 2008 :Getting start date and end date of the week to next 8 weeks'], 3, 0], [(15543977, 2), [["Or you could tweak the final select if you don't want the time component, like this:"], ['-10000']], [[' SELECT CONVERT(VARCHAR, StartDate, 103), CONVERT(VARCHAR, EndDate, 103) FROM @dates\n']], ['MS SQL Server 2008 :Getting start date and end date of the week to next 8 weeks'], 3, 0], [(15559090, 1), [['Or, if the target table already exists:'], ["I would advise not to use  date  as column name. It's a  reserved word  in every SQL standard and a function and data type name in PostgreSQL."]], [[' INSERT INTO transactions_combined (<list names of target column here!>)\nSELECT ...\n']], ['Combine two tables into a new one so that select rows from the other one are ignored'], 2, 0], [(15616278, 0), [['With the help of Steoleary i have managed a solution'], ['As a result, i now get the accurate time. ']], [[" DECLARE @SecondsToConvert int\nSET @SecondsToConvert = (SELECT (SUM(DATEDIFF(hour,InviteTime,EndTime) * 3600) + SUM(DATEDIFF(minute,InviteTime,EndTime) * 60) + SUM(DATEDIFF(second,InviteTime,EndTime) * 1)) AS [Seconds] \n FROM [LcsCDR].[dbo].[SessionDetailsView]\nWHERE FromUri LIKE '%robert%'\nAND (CAST([InviteTime] AS date)) BETWEEN '2012-12-27' AND '2013-01-28'\nAND MediaTypes = '16'\nGROUP BY FromUri)\n\n-- Declare variables\n DECLARE @Hours int\n DECLARE @Minutes int\n DECLARE @Seconds int\n\n-- Set the calculations for hour, minute and second\nSET @Hours = @SecondsToConvert/3600\nSET @Minutes = (@SecondsToConvert % 3600) / 60\nSET @Seconds = @SecondsToConvert % 60\n\nSELECT COUNT(*) AS 'Aantal gesprekken'\n,FromUri AS 'Medewerker'\n,@Hours AS 'Uren' ,@Minutes AS 'Minuten' , @Seconds AS 'Seconden'\n FROM [LcsCDR].[dbo].[SessionDetailsView]\nWHERE FromUri LIKE '%robert%'\nAND (CAST([InviteTime] AS date)) BETWEEN '2012-12-27' AND '2013-01-28'\nAND MediaTypes = '16'\nGROUP BY FromUri\n"]], ['SQL convert Seconds to Minutes to Hours'], 2, 1], [(15616278, 1), [['As a result, i now get the accurate time. '], ['28 hours, 19 minutes and 56 seconds, just like it should be :)']], [[' 302 robert  28  19  56\n']], ['SQL convert Seconds to Minutes to Hours'], 2, 0], [(15616638, 0), [['Basically, you can filter the result from the product of the two tables via  a.Name < b.Name'], ['-10000']], [[' SELECT  a.Name Name1, b.Name Name2\nFROM    TableName a, TableName b\nWHERE   a.Name < b.Name\nORDER   BY Name1, Name2\n']], ['How to remove duplicate rows from a join query in mysql'], 2, 1], [(15616638, 1), [['-10000'], ['-10000']], [[' ╔═══════╦═════════╗\n║ NAME1 ║  NAME2  ║\n╠═══════╬═════════╣\n║ Amit  ║ Bhagi   ║\n║ Amit  ║ Chinmoy ║\n║ Bhagi ║ Chinmoy ║\n╚═══════╩═════════╝\n']], ['How to remove duplicate rows from a join query in mysql'], 2, 0], [(15621609, 0), [["Unfortunately, there are some limitations with  CASE  expressions that make it cumbersome to do what you want. For example, all of the branches in a  CASE  expression must return the same type, or be implicitly convertible to the same type. I wouldn't try that with strings and dates. You also can't use  CASE  to specify sort direction."], ['An arguably easier solution (especially if this gets more complex) is to use dynamic SQL. To thwart SQL injection you can test the values:']], [[" SELECT column_list_please\nFROM dbo.Product -- dbo prefix please\nORDER BY \n  CASE WHEN @sortDir = 'asc' AND @sortOrder = 'name' THEN name END,\n  CASE WHEN @sortDir = 'asc' AND @sortOrder = 'created_date' THEN created_date END,\n  CASE WHEN @sortDir = 'desc' AND @sortOrder = 'name' THEN name END DESC,\n  CASE WHEN @sortDir = 'desc' AND @sortOrder = 'created_date' THEN created_date END DESC;\n"]], ['T-SQL Conditional Order By'], 2, 1], [(15621609, 1), [['An arguably easier solution (especially if this gets more complex) is to use dynamic SQL. To thwart SQL injection you can test the values:'], ['Another plus for dynamic SQL, in spite of all the fear-mongering that is spread about it: you can get the best plan for each sort variation, instead of one single plan that will optimize to whatever sort variation you happened to use first. It also performed best universally in a recent performance comparison I ran:']], [[" IF @sortDir NOT IN ('asc', 'desc')\n  OR @sortOrder NOT IN ('name', 'created_date')\nBEGIN\n  RAISERROR('Invalid params', 11, 1);\n  RETURN;\nEND\n\nDECLARE @sql NVARCHAR(MAX) = N'SELECT column_list_please\n  FROM dbo.Product ORDER BY ' + @sortOrder + ' ' + @sortDir;\n\nEXEC sp_executesql @sql;\n"]], ['T-SQL Conditional Order By'], 2, 1], [(15622474, 0), [['Unfortunately with your table structure of  points  you will have to  unpivot  the data.  An  unpivot  takes the data from the multiple columns into rows. Once the data is in the rows, it will be much easier to join,  filter the data and total the points for each account. The code to unpivot the data will be similar to this:'], ['See  SQL Fiddle with Demo . The query gives a result similar to this:']], [[" select account,\n  cast(cast(year as varchar(4))+'-'+replace(month_col, 'M', '')+'-01' as date) full_date,\n  pts\nfrom points\nunpivot\n(\n  pts\n  for month_col in ([M01], [M02], [M03], [M04], [M05], [M06], [M07], [M08], [M09], [M10], [M11], [M12])\n) unpiv\n"]], ['SQL Rolling Total up to a certain date'], 3, 0], [(15622474, 1), [['See  SQL Fiddle with Demo . The query gives a result similar to this:'], ['Once the data is in this format, you can join the  Customers  table to get the total points for each  account , so the code will be similar to the following:']], [[' | ACCOUNT |  FULL_DATE | PTS |\n------------------------------\n|     123 | 2011-01-01 |  10 |\n|     123 | 2011-02-01 |   0 |\n|     123 | 2011-03-01 |   0 |\n|     123 | 2011-04-01 |   0 |\n|     123 | 2011-05-01 |  10 |\n']], ['SQL Rolling Total up to a certain date'], 3, 0], [(15627299, 0), [['This problem is commonly known as  Relational Division .'], ['-10000']], [[" SELECT  a.Name\nFROM    [user] a\n        INNER JOIN UserInGroup b\n            ON a.ID = b.UserID\n        INNER JOIN [Group] c\n            ON b.groupID = c.TypeId\nWHERE   c.Name IN ('Directors','London')\nGROUP   BY a.Name\nHAVING  COUNT(*) = 2\n"]], ["Using 'AND' in a many-to-many relationship"], 3, 1], [(15627299, 1), [['-10000'], ['-10000']], [[" SELECT  a.Name\nFROM    [user] a\n        INNER JOIN UserInGroup b\n            ON a.ID = b.UserID\n        INNER JOIN [Group] c\n            ON b.groupID = c.TypeId\nWHERE   c.Name IN ('Directors','London')\nGROUP   BY a.Name\nHAVING  COUNT(DISTINCT c.Name) = 2\n"]], ["Using 'AND' in a many-to-many relationship"], 3, 1], [(15627299, 2), [['-10000'], ['-10000']], [[' ╔══════╗\n║ NAME ║\n╠══════╣\n║ Bob  ║\n╚══════╝\n']], ["Using 'AND' in a many-to-many relationship"], 3, 0], [(15650876, 0), [['Your attributes are attached to pages. So, you can search for pages that have certain attributes, by checking if those Attributes exist for a page. Finding the pages would look like this:'], ['If you want to find the Links, then you can join this to PAGE_LINK (and even to LINK, if you like).']], [[" Select Page.ID\nFrom Page\nwhere EXISTS\n (Select * \n  From Attributes\n  Where Page_Id = Page.ID\n    and (     (Name = 'Season' and Value = 'Autumn')\n          or  (Name = 'Flavour' and Value = 'Savory')\n          ... etc. ...\n        )\n"]], ['Searching Across Multiple Tables'], 2, 1], [(15650876, 1), [['If you want to find the Links, then you can join this to PAGE_LINK (and even to LINK, if you like).'], ['-10000']], [[" Select Page.ID\nFrom Page\n Join Page_Link PL on PL.Page_ID = Page.ID\n Join Link on Link.ID = PL.Link_ID\nwhere EXISTS\n (Select * \n  From Attributes\n  Where Page_Id = Page.ID\n    and (     (Name = 'Season' and Value = 'Autumn')\n          or  (Name = 'Flavour' and Value = 'Savory')\n          ... etc. ...\n        )\n"]], ['Searching Across Multiple Tables'], 2, 1], [(15706765, 0), [['-10000'], ['If a primary key  already exists  then you want to do this:']], [[' ALTER TABLE space ADD PRIMARY KEY(Postal, Number, Houseletter);\n']], ['How can I make three columns my primary key'], 4, 1], [(15706765, 1), [['If a primary key  already exists  then you want to do this:'], ['if you got duplicate PKs, you can try this:']], [[' ALTER TABLE space DROP PRIMARY KEY, ADD PRIMARY KEY(Postal, Number, Houseletter);\n']], ['How can I make three columns my primary key'], 4, 1], [(15706765, 2), [['if you got duplicate PKs, you can try this:'], ['Second question, your query should look like this :']], [[' ALTER IGNORE TABLE space ADD UNIQUE INDEX idx_name (Postal, Number, Houseletter );\n']], ['How can I make three columns my primary key'], 4, 1], [(15706765, 3), [['Second question, your query should look like this :'], ['-10000']], [[' SELECT postal, number, houseletter, furniturevalue, livingspace\nFROM space INNER JOIN furniture\nON ( space.postal = furniture.postal\nAND     space.number = furniture.number\nAND     space.houseletter = furniture.houseletter)\n']], ['How can I make three columns my primary key'], 4, 0], [(15720109, 0), [['Since  MySQL  do not support  Window Function  like any RDBMS has, you can still simulate what  DENSE_RANK()  can do by using  user define variables , eg'], ['-10000']], [[' SELECT  a.ID, a.TotalScore, b.Rank\nFROM    TableName a\n        INNER JOIN\n        (\n            SELECT  TotalScore, @rn := @rn + 1 Rank\n            FROM\n                    (\n                        SELECT  DISTINCT TotalScore\n                        FROM    TableName\n                    ) a, (SELECT @rn := 0) b\n            ORDER   BY TotalScore DESC\n        ) b ON  a.TotalScore = b.TotalScore\nWHERE   Rank <= 3\n']], ['beginner - obtain the top 3 in sql (taking same total score into account)'], 2, 1], [(15720109, 1), [['-10000'], ['-10000']], [[' ╔════╦════════════╦══════╗\n║ ID ║ TOTALSCORE ║ RANK ║\n╠════╬════════════╬══════╣\n║  7 ║         20 ║    1 ║\n║  4 ║         20 ║    1 ║\n║  6 ║         18 ║    2 ║\n║  9 ║         18 ║    2 ║\n║  1 ║         16 ║    3 ║\n╚════╩════════════╩══════╝\n']], ['beginner - obtain the top 3 in sql (taking same total score into account)'], 2, 0], [(15736503, 0), [['Code and Test Cases:'], ['Simple Performance Test:']], [[" --Function to convert a string to a date, or return null if the format is wrong.\ncreate or replace function validate_date(p_string in string) return date is\nbegin\n    return to_date(p_string, 'MONTH DD, YYYY');\nexception when others then\n    begin\n        return to_date(p_string, 'MM/DD/YYYY');\n    exception when others then\n        begin\n            return to_date(p_string, 'DD-MON-RR');\n        exception when others then\n            return null;\n        end;\n    end;\nend;\n/\n\n--Test individual values\nselect validate_date('JULY 31, 2009') from dual;\n2009-07-31\nselect validate_date('7/31/2009') from dual;\n2009-07-31\nselect validate_date('31-JUL-09') from dual;\n2009-07-31\nselect validate_date('2009-07-31') from dual;\n<null>\n"]], ['Oracle using REGEXP to validate a date field'], 2, 1], [(15736503, 1), [['Simple Performance Test:'], ['-10000']], [[' --Create table to hold test data\ncreate table test1(a_date varchar2(1000)) nologging;\n\n--Insert 10 million rows\nbegin\n    for i in 1 .. 100 loop\n        insert /*+ append */ into test1\n        select to_char(sysdate+level, \'MM/DD/YYYY\') from dual connect by level <= 100000;\n\n        commit;\n    end loop;\nend;\n/\n\n--"Warm up" the database, run this a few times, see how long a count takes.\n--Best case time to count: 2.3 seconds\nselect count(*) from test1;\n\n\n--How long does it take to convert all those strings?\n--6 minutes... ouch\nselect count(*)\nfrom test1\nwhere validate_date(a_date) is not null;\n']], ['Oracle using REGEXP to validate a date field'], 2, 0], [(15742348, 0), [['Following should be your query -'], ['then query can be -']], [[" Select * from employee where projectname = (select projectname from employee where LastName = 'Jones');\n"]], ['devide operation in sql'], 2, 1], [(15742348, 1), [['then query can be -'], ['Thanks']], [[" Select * from employee where projectname in (select projectname from employee where LastName = 'Jones');\n"]], ['devide operation in sql'], 2, 1], [(15743183, 0), [['You need to use  GROUP BY  clause because  GROUP_CONCAT()  is an aggregate function.'], ['-10000']], [[' SELECT  Title, GROUP_CONCAT(FEAT) FeatList\nFROM    Prop_Feat\nGROUP   BY Title\n']], ["How to fetch Distinct Title from the GROUP_CONCAT as Left Join without repeating other tables' data?"], 2, 1], [(15743183, 1), [['-10000'], ['-10000']], [[' ╔════════════╦═══════════════════╗\n║   TITLE    ║     FEATLIST      ║\n╠════════════╬═══════════════════╣\n║ Appliances ║ Gas Range,Fridge  ║\n║ Interior   ║ Hardwood Flooring ║\n╚════════════╩═══════════════════╝\n']], ["How to fetch Distinct Title from the GROUP_CONCAT as Left Join without repeating other tables' data?"], 2, 0], [(15758509, 0), [['Query 1 :'], ['Results :']], [[" SELECT\n   a.user,\n   SUM(IF(a.parent_id = 0, 1, 0)) as 'NewPosts',\n   SUM(IF(a.parent_id > 0, 1,0))  as 'Responses',\n   COUNT(a.parent_id)             as 'TotalPosts',\n   SUM(IF(a.user = b.user, 1, 0)) as 'SelfResponses'\nFROM \n  Table1 a\nLEFT JOIN\n  Table1 b\nON \n  a.parent_id = b.id\nGROUP BY \n  a.user\n"]], ['Count references to own ID in MySQL with Grouping'], 2, 1], [(15758509, 1), [['Results :'], ['-10000']], [[' |   USER | NEWPOSTS | RESPONSES | TOTALPOSTS | SELFRESPONSES |\n--------------------------------------------------------------\n|  Henry |        1 |         2 |          3 |             1 |\n| Joseph |        1 |         0 |          1 |             0 |\n']], ['Count references to own ID in MySQL with Grouping'], 2, 0], [(15808243, 0), [['In SQLServer2005+ use option with  OUTER APPLY  operator'], ['OR option with  CTE  and  ROW_NUMBER()  ranking function']], [[' SELECT *\nFROM master t1 OUTER APPLY (\n                            SELECT TOP 1 t2.Col1, t2.Col2 ...\n                            FROM child t2\n                            WHERE t1.Id = t2.Id\n                            ORDER BY t2.CreatedDate DESC\n                            ) o\n']], ['How to Select master table data and select referance table top one data sql query'], 2, 1], [(15808243, 1), [['OR option with  CTE  and  ROW_NUMBER()  ranking function'], ['-10000']], [[' ;WITH cte AS\n (                            \n  SELECT *, \n         ROW_NUMBER() OVER(PARTITION BY t1.Id ORDER BY t2.CreatedDate DESC) AS rn\n  FROM master t1 JOIN child t2 ON t1.Id = t2.Id\n  )\n  SELECT *\n  FROM cte\n  WHERE rn = 1\n']], ['How to Select master table data and select referance table top one data sql query'], 2, 1], [(15834569, 1), [['Since you have 3 million items, it might pay to raise the setting for  temp_buffer  ( for this session only ):'], ['Or however much you can afford and is enough to hold the temp table in RAM, which is much faster. Note: must be done  first  in the session - before any temp objects are created.']], [[' SET temp_buffers = 1000MB;\n']], ['How to bulk insert only new rows in PostreSQL'], 3, 0], [(15834569, 2), [['Or however much you can afford and is enough to hold the temp table in RAM, which is much faster. Note: must be done  first  in the session - before any temp objects are created.'], ['In the same session! A temporary table is dropped automatically at the end of the session.']], [[' SELECT tbl.tbl_id, tbl.title\nFROM   tbl\nJOIN   tmp USING (title)\n']], ['How to bulk insert only new rows in PostreSQL'], 3, 0], [(15836482, 0), [['SQLFIDDLEExample'], ['Result:']], [[' UPDATE Table1\nSET car_name = (SELECT t1.car_name\n                FROM (SELECT * FROM Table1) t1\n                WHERE t1.id < Table1.id\n                AND t1.car_name is not null\n                ORDER BY t1.id DESC\n                LIMIT 1)\nWHERE car_name is null\n']], ['Query to replace null values from the table'], 2, 1], [(15836482, 1), [['Result:'], ['-10000']], [[' | ID | CAR_NAME | MODEL | YEAR |\n--------------------------------\n|  1 |        a |   abc | 2000 |\n|  2 |        b |   xyx | 2001 |\n|  3 |        b |   asd | 2003 |\n|  4 |        c |   qwe | 2004 |\n|  5 |        c |   xds | 2005 |\n|  6 |        d |   asd | 2006 |\n']], ['Query to replace null values from the table'], 2, 0], [(15872394, 0), [['Let be table B:'], ['Let be table C']], [[' id\n----\n1\n2\n3\n']], ['Using multiple joins (e.g left join)'], 6, 0], [(15872394, 1), [['Let be table C'], ['Table B']], [[' id     name\n------------\n1      John\n2      Mary\n2      Anne\n3      Stef\n']], ['Using multiple joins (e.g left join)'], 6, 0], [(15872394, 2), [['Table B'], ['table C']], [[' id\n----\n1\n2\n2\n3\n4\n']], ['Using multiple joins (e.g left join)'], 6, 0], [(15872394, 3), [['table C'], ['Every id from b is matched with ids from c, then first id=2 will be matched twice and second id=2 will be matched twice so the result of']], [[' id     name\n------------\n1      John\n2      Mary\n2      Anne\n3      Stef\n']], ['Using multiple joins (e.g left join)'], 6, 0], [(15872394, 5), [['will be'], ['The id=4 is not matched but appears in the result because is a left join.']], [[' id     name\n------------\n1      John\n2      Mary\n2      Mary\n2      Anne\n2      Anne\n3      Stef\n4      (null)\n']], ['Using multiple joins (e.g left join)'], 6, 0], [(15948208, 0), [['I think to get exactly what you want in one query is not easily possible. But I came to something that is nearly your desired result:'], ['This gives me the following result:']], [[" SELECT TIME(air), title, GROUP_CONCAT(DAYOFWEEK(air)) \nFROM programs WHERE title = 'Factor' \nGROUP BY TIME(air)\n"]], ['Group dates by their day of week'], 2, 1], [(15948208, 1), [['This gives me the following result:'], ['With this result you can easily utilize php to get your desired result. Results like "monday, wednesday, friday-saturday" are possible with this too.']], [[' TIME(air)   title   GROUP_CONCAT(DAYOFWEEK(air))\n-------------------------------------------------\n14:00:00    Factor  3\n17:00:00    Factor  2,3,4\n']], ['Group dates by their day of week'], 2, 0], [(15964439, 0), [['First, set up the tables:'], ['Now declare what would be the  TVP  passed into the stored procedure (note that this script and the next need to be run together in this simulation):']], [[' create table Requests (RId int IDENTITY(1,1) not null primary key,RequestName varchar(10) not null)\ncreate table Services (SId int IDENTITY(1,1) not null primary key,ServiceName varchar(10) not null)\ncreate table Mappings (MId int IDENTITY(1,1) not null,RId int not null references Requests,SId int not null references Services)\n']], ["Efficient way to insert multiple rows and assigning each one's Id to another table's column"], 5, 0], [(15964439, 1), [['Now declare what would be the  TVP  passed into the stored procedure (note that this script and the next need to be run together in this simulation):'], ["And then, inside the SP, you'd have code like the following:"]], [[" declare @NewValues table (\n    RequestName varchar(10) not null,\n    ServiceName varchar(10) not null\n)\ninsert into @NewValues (RequestName,ServiceName) values\n('R1','S1'),\n('R1','S2'),\n('R1','S3'),\n('R2','S4'),\n('R2','S5'),\n('R3','S6')\n"]], ["Efficient way to insert multiple rows and assigning each one's Id to another table's column"], 5, 0], [(15964439, 3), [['And to check the result:'], ['produces:']], [[' select * from Mappings\n']], ["Efficient way to insert multiple rows and assigning each one's Id to another table's column"], 5, 0], [(15964439, 4), [['produces:'], ['Which is similar to what you have in your question.']], [[' MId         RId         SId\n----------- ----------- -----------\n1           1           1\n2           1           2\n3           1           3\n4           2           4\n5           2           5\n6           3           6\n']], ["Efficient way to insert multiple rows and assigning each one's Id to another table's column"], 5, 0], [(16036991, 0), [['Using the original formula:'], ['or by using subquery:']], [[' select sum([some calculation]) as x,\n       sum([some other calculation]) as y,\n       sum([some calculation]) / sum([some other calculation]) as z\nfrom    tableName\n']], ['Reference something in the select clause SQL'], 2, 1], [(16036991, 1), [['or by using subquery:'], ['-10000']], [[' SELECT  x,\n        y,\n        x/y z\nFROM \n(\n   select sum([some calculation]) as x,\n          sum([some other calculation]) as y\n   from   tableName\n) s\n']], ['Reference something in the select clause SQL'], 2, 1], [(16053215, 0), [['If I understand you right, then try something like this:'], ['-10000']], [[' select * \nfrom(\n  select sent_by, row_number() over (order by sent_by desc, id asc) row_num\n  from MY_TEST) t\nwhere row_num = 2 -- or 3 ... n\n']], ['find second (or nth) latest value in oracle'], 2, 1], [(16053215, 1), [['-10000'], ['Here is a sqlfiddle demo']], [[' select * \nfrom(\n  select sent_by, \n         rank() over (order by max(id) desc)  rk\n   from MY_TEST\n  group by sent_by) t\nwhere rk = 2 -- or 3 .. n\n']], ['find second (or nth) latest value in oracle'], 2, 1], [(16053425, 0), [['If I understand your question correctly, maybe you need something like this:'], ['Or maybe this:']], [[" SELECT 'col_a' col\nFROM yourtable\nWHERE col_a\nUNION\nSELECT 'col_b'\nFROM yourtable\nWHERE col_b\nUNION\nSELECT 'col_c'\nFROM yourtable\nWHERE col_c\n...\n"]], ['Select column names that match a criteria (MySQL)'], 4, 1], [(16053425, 1), [['Or maybe this:'], ['that will return rows in this format:']], [[" SELECT\n  id,\n  CONCAT_WS(', ',\n    CASE WHEN col_a THEN 'col_a' END,\n    CASE WHEN col_b THEN 'col_b' END,\n    CASE WHEN col_c THEN 'col_c' END) cols\nFROM\n  yourtable\n"]], ['Select column names that match a criteria (MySQL)'], 4, 1], [(16053425, 2), [['that will return rows in this format:'], ['Please see fiddle  here . And if you need to do it dynamically, you could use this prepared statement:']], [[' | ID | COLS                |\n----------------------------\n|  1 | col_a, col_c        |\n|  2 | col_a, col_b, col_c |\n|  3 |                     |\n|  4 | col_c               |\n...\n']], ['Select column names that match a criteria (MySQL)'], 4, 0], [(16053425, 3), [['Please see fiddle  here . And if you need to do it dynamically, you could use this prepared statement:'], ['Fiddle  here .']], [[" SELECT\n  CONCAT(\n    'SELECT id, CONCAT_WS(\\', \\',',\n  GROUP_CONCAT(\n    CONCAT('CASE WHEN ',\n           `COLUMN_NAME`,\n           ' THEN \\'',\n           `COLUMN_NAME`,\n           '\\' END')),\n    ') cols FROM yourtable'\n  )\nFROM\n  `INFORMATION_SCHEMA`.`COLUMNS` \nWHERE\n  `TABLE_NAME`='yourtable'\n  AND COLUMN_NAME!='id'\nINTO @sql;\n\nPREPARE stmt FROM @sql;\nEXECUTE stmt;\n"]], ['Select column names that match a criteria (MySQL)'], 4, 1], [(16093468, 0), [['Finally, it uses  count(distinct)  to count the distinct users that match between the two lists.'], ['You could move the conditional comparison in the  count  to the joins and just use  count(distinct) :']], [[' select pairs.app1, pairs.app2,\n       COUNT(distinct case when tleft.user = tright.user then tleft.user end) as NumCommonUsers\nfrom (select t1.app as app1, t2.app as app2\n      from (select distinct app\n            from t\n           ) t1 cross join\n           (select distinct app\n            from t\n           ) t2\n      where t1.app <= t2.app\n     ) pairs left outer join\n     t tleft\n     on tleft.app = pairs.app1 left outer join\n     t tright\n     on tright.app = pairs.app2\ngroup by pairs.app1, pairs.app2\n']], ['Over lapping in SQL'], 2, 0], [(16093468, 1), [['You could move the conditional comparison in the  count  to the joins and just use  count(distinct) :'], ['I prefer the first method because it is more explicit on what is being counted.']], [[' select pairs.app1, pairs.app2,\n       COUNT(distinct tleft.user) as NumCommonUsers\nfrom (select t1.app as app1, t2.app as app2\n      from (select distinct app\n            from t\n           ) t1 cross join\n           (select distinct app\n            from t\n           ) t2\n      where t1.app <= t2.app\n     ) pairs left outer join\n     t tleft\n     on tleft.app = pairs.app1 left outer join\n     t tright\n     on tright.app = pairs.app2 and\n        tright.user = tleft.user\ngroup by pairs.app1, pairs.app2\n']], ['Over lapping in SQL'], 2, 0], [(16127878, 0), [['http://sqlfiddle.com/#!12/391b7/6'], ['To turn these into  INSERTs  simply use  INSERT ... SELECT  eg:']], [[' SELECT p1."Subject", p1."Object" AS "prop1", p2."Object" AS "prop2"\nFROM triplestore p1\nINNER JOIN triplestore p2 ON (p1."Subject" = p2."Subject")\nWHERE p1."Property" = \'prop1\'\n  AND p2."Property" = \'prop2\'\nORDER BY p1."Subject";\n\nSELECT p1."Subject", p1."Object" AS "prop1"\nFROM triplestore p1\nWHERE p1."Property" = \'prop3\'\nORDER BY p1."Subject";\n']], ['Inserting data from one table(triplestore) to another(property table)'], 2, 0], [(16127878, 1), [['To turn these into  INSERTs  simply use  INSERT ... SELECT  eg:'], ['-10000']], [[' INSERT INTO "Property Table 1"\nSELECT p1."Subject", p1."Object" AS "prop1"\nFROM triplestore p1\nWHERE p1."Property" = \'prop3\'\nORDER BY p1."Subject";\n']], ['Inserting data from one table(triplestore) to another(property table)'], 2, 0], [(16136119, 0), [['If you have a limited number of  years , then you can hard-code the query:'], ['But if you are going to have an unknown number of values or what the query to adjust as new years are added to the database, then you can use a prepared statement to generate dynamic SQL:']], [[' select meterNo,\n  sum(case when year(readingDate) = 2009 then readingValue else 0 end) `2009`,\n  sum(case when year(readingDate) = 2010 then readingValue else 0 end) `2010`,\n  sum(case when year(readingDate) = 2011 then readingValue else 0 end) `2011`,\n  sum(case when year(readingDate) = 2012 then readingValue else 0 end) `2012`,\n  sum(case when year(readingDate) = 2013 then readingValue else 0 end) `2013`\nfrom readings\ngroup by meterno;\n']], ['MySQL - Combining multiple selects from same table into one result table with a group by'], 3, 1], [(16136119, 1), [['But if you are going to have an unknown number of values or what the query to adjust as new years are added to the database, then you can use a prepared statement to generate dynamic SQL:'], ['See  SQL Fiddle with Demo . Both give the result:']], [[" SET @sql = NULL;\nSELECT\n  GROUP_CONCAT(DISTINCT\n    CONCAT(\n      'sum(CASE WHEN year(readingDate) = ',\n      year(readingDate),\n      ' THEN readingValue else 0 END) AS `',\n      year(readingDate), '`'\n    )\n  ) INTO @sql\nFROM readings;\n\nSET @sql \n  = CONCAT('SELECT meterno, ', @sql, ' \n            from readings\n            group by meterno');\n\nPREPARE stmt FROM @sql;\nEXECUTE stmt;\nDEALLOCATE PREPARE stmt;\n"]], ['MySQL - Combining multiple selects from same table into one result table with a group by'], 3, 1], [(16136119, 2), [['See  SQL Fiddle with Demo . Both give the result:'], ['As a side note, if you want  null  to display in the rows without values instead of the zeros, then you can remove the  else 0  (see  Demo )']], [[' | METERNO | 2009 | 2010 | 2012 | 2013 | 2011 |\n----------------------------------------------\n|       1 |   90 |  180 |    0 |   90 |   90 |\n|       2 |   50 |    0 |   90 |    0 |    0 |\n|       3 |   80 |   40 |   90 |   90 |    0 |\n']], ['MySQL - Combining multiple selects from same table into one result table with a group by'], 3, 0], [(16143769, 0), [["A variation on Ben's answer to use a windowing clause, which seems to take care of your updated requirements:"], ["Except it gives  19.2  instead of  12.8  for the third row, but that's what your formula suggests it should be:"]], [[' select eventno, eventtype, totalcharge, remainingqty, outqty,\n    initial_charge - case when running_outqty = 0 then 0\n    else (running_outqty / 100) * initial_charge end as remainingcharge\nfrom (\n    select eventno, eventtype, totalcharge, remainingqty, outqty,\n        first_value(totalcharge) over (partition by null\n            order by eventno desc) as initial_charge,\n        sum(outqty) over (partition by null\n            order by eventno desc\n            rows between unbounded preceding and current row)\n            as running_outqty\n    from t42\n);\n']], ['Referencing the value of the previous calculcated value in Oracle'], 3, 1], [(16143769, 1), [["Except it gives  19.2  instead of  12.8  for the third row, but that's what your formula suggests it should be:"], ['If I add another split so it goes from 60 to zero in two steps, with another non-OUT record in the mix too:']], [['    EVENTNO EVENT TOTALCHARGE REMAININGQTY     OUTQTY REMAININGCHARGE\n---------- ----- ----------- ------------ ---------- ---------------\n         4 ACQ            32          100          0              32\n         3 OTHER                      100          0              32\n         2 OUT                         60         40            19.2\n         1 OUT                          0         60               0\n']], ['Referencing the value of the previous calculcated value in Oracle'], 3, 0], [(16143769, 2), [['If I add another split so it goes from 60 to zero in two steps, with another non-OUT record in the mix too:'], ["There's an assumption that the remaining quantity is consistent and you can effectively track a running total of what has gone before, but from the data you've shown that looks plausible. The inner query calculates that running total for each row, and the outer query does the calculation; that could be condensed but is hopefully clearer like this..."]], [['    EVENTNO EVENT TOTALCHARGE REMAININGQTY     OUTQTY REMAININGCHARGE\n---------- ----- ----------- ------------ ---------- ---------------\n         6 ACQ            32          100          0              32\n         5 OTHER                      100          0              32\n         4 OUT                         60         40            19.2\n         3 OUT                         30         30             9.6\n         2 OTHER                       30          0             9.6\n         1 OUT                          0         30               0\n']], ['Referencing the value of the previous calculcated value in Oracle'], 3, 0], [(16184493, 0), [['for all columns use:'], ['for selected columns use:']], [[' INSERT INTO dbo.Calls SELECT * fROM  dbo.Calls\n']], ['SQL Server Insert table into same table?'], 2, 1], [(16184493, 1), [['for selected columns use:'], ['-10000']], [['  INSERT INTO dbo.Calls (<column name list>) SELECT  <column name list> FROM dbo.Calls\n']], ['SQL Server Insert table into same table?'], 2, 1], [(16186786, 0), [['-10000'], ['-10000']], [[' SELECT  jamu_a,\n        jamu_b,\n        GROUP_CONCAT(khasiat) khasiat,\n        COUNT(*) total\nFROM    TableName\nGROUP   BY  jamu_a, jamu_b\n']], ['MySQL compare same values in two column'], 3, 1], [(16186786, 1), [['-10000'], ['if there are repeating values on column  KHASIAT  and you want it to be unique, you can add  DISTINCT  on  GROUP_CONCAT()']], [[' ╔════════╦════════╦═════════╦═══════╗\n║ JAMU_A ║ JAMU_B ║ KHASIAT ║ TOTAL ║\n╠════════╬════════╬═════════╬═══════╣\n║ A      ║ B      ║ Z,X,C   ║     3 ║\n╚════════╩════════╩═════════╩═══════╝\n']], ['MySQL compare same values in two column'], 3, 0], [(16186786, 2), [['if there are repeating values on column  KHASIAT  and you want it to be unique, you can add  DISTINCT  on  GROUP_CONCAT()'], ['-10000']], [[' SELECT  jamu_a,\n        jamu_b,\n        GROUP_CONCAT(DISTINCT khasiat) khasiat,\n        COUNT(*) total\nFROM    TableName\nGROUP   BY  jamu_a, jamu_b\n']], ['MySQL compare same values in two column'], 3, 1], [(16212126, 0), [['You could use something like this to get the results for each jockey in one row:'], ['ALternatively you could use  WITH ROLLUP  to get an additional row with totals:']], [[" SELECT  jockey.jockey_skey,\n        TotalRaces = COUNT(*),\n        [1sts] = COUNT(CASE WHEN raceresults.place = '01' THEN 1 END),\n        [2nds] = COUNT(CASE WHEN raceresults.place = '02' THEN 1 END),\n        [3rds] = COUNT(CASE WHEN raceresults.place = '03' THEN 1 END),\n        [4ths] = COUNT(CASE WHEN raceresults.place = '04' THEN 1 END),\n        [5ths] = COUNT(CASE WHEN raceresults.place = '05' THEN 1 END),\n        [6ths] = COUNT(CASE WHEN raceresults.place = '06' THEN 1 END),\n        [7ths] = COUNT(CASE WHEN raceresults.place = '07' THEN 1 END),\n        [8ths] = COUNT(CASE WHEN raceresults.place = '08' THEN 1 END),\n        -- etc\n        [NonRunner] = COUNT(CASE WHEN raceresults.place = 'NR' THEN 1 END),\n        [Fell] = COUNT(CASE WHEN raceresults.place = 'F' THEN 1 END),\n        [PulledUp] = COUNT(CASE WHEN raceresults.place = 'PU' THEN 1 END),\n        [Unseated] = COUNT(CASE WHEN raceresults.place = 'U' THEN 1 END),\n        [Refused] = COUNT(CASE WHEN raceresults.place = 'R' THEN 1 END),\n        [BroughtDown] = COUNT(CASE WHEN raceresults.place = 'B' THEN 1 END)\nFROM    jockey \n        INNER JOIN runnersandriders \n            ON jockey.jockey_skey = runnersandriders.jockey_skey \n        INNER JOIN horse \n            ON runnersandriders.horse_skey = horse.horse_skey \n        INNER JOIN raceresults \n            ON horse.horse_skey = raceresults.horse_skey \nGROUP  BY jockey.jockey_skey\nORDER  BY jockey.jockey_skey \n"]], ['Updating a Dataset to add caclulated fields'], 2, 1], [(16212126, 1), [['ALternatively you could use  WITH ROLLUP  to get an additional row with totals:'], ['Where  NULL  values represent totals']], [[' SELECT  jockey.jockey_skey,\n        raceresults.place,\n        [CountOfResult] = COUNT(*)\nFROM    jockey \n        INNER JOIN runnersandriders \n            ON jockey.jockey_skey = runnersandriders.jockey_skey \n        INNER JOIN horse \n            ON runnersandriders.horse_skey = horse.horse_skey \n        INNER JOIN raceresults \n            ON horse.horse_skey = raceresults.horse_skey \nGROUP  BY jockey.jockey_skey, raceresults.place\nWITH ROLLUP\nORDER  BY jockey.jockey_skey, raceresults.place;\n']], ['Updating a Dataset to add caclulated fields'], 2, 1], [(16216129, 0), [['Based on your description, this may be the query that you want:'], ['The reason your query fails is because of the correlation statement:']], [[' select person, AVG(OrderTotal), COUNT(distinct orderId)\nfrom (select Customer_id as person, Order_id, SUM(total) as OrderTotal\n      from Orders\n      group by Customer_Id, Order_Id\n     ) o\ngroup by person \n']], ['Using a current row value into a subquery'], 3, 1], [(16216129, 1), [['The reason your query fails is because of the correlation statement:'], ['You intend for this to use the value from the outer query ("person") to relate to the inner one ("Customer_Id").  However, the inner query does not know the alias in the  select  clause of the outer one.  So, "Person" is undefined.  When doing correlated subqueries, you should  always  use table aliases.  That query should look more like:']], [[' where Customer_Id = person\n']], ['Using a current row value into a subquery'], 3, 0], [(16216129, 2), [['You intend for this to use the value from the outer query ("person") to relate to the inner one ("Customer_Id").  However, the inner query does not know the alias in the  select  clause of the outer one.  So, "Person" is undefined.  When doing correlated subqueries, you should  always  use table aliases.  That query should look more like:'], ['Assuming "o" is the alias for orders in the outer query.  Correlated subqueries are not needed.  You should just simplify the query.']], [[' (select COUNT(o2.Order_Id) as timesSeen  \n from Orders o2 where  o2.Customer_Id=o.person \n group by o2.Order_Id\n)\n']], ['Using a current row value into a subquery'], 3, 1], [(16223233, 0), [["You should use CodeIgniter's input class to get all post values."], ['Then in your controller set an intermediate value to hold your data.']], [[' $formValues = $this->input->post(NULL, TRUE);\n']], ['Codeigniter - loop through post information passing value to model query and outputting result'], 4, 0], [(16223233, 1), [['Then in your controller set an intermediate value to hold your data.'], ['Pass intermediary to the view.']], [[' $products = array();\n\nforeach($formValues as $key => $value) \n{\n    $products[] = $this->sales_model->get_productdetails($key)\n}\n\n$data = array();\n$data["products"] = $products;\n']], ['Codeigniter - loop through post information passing value to model query and outputting result'], 4, 0], [(16223233, 2), [['Pass intermediary to the view.'], ['In your review reference each hashed item in the $data array as a variable.']], [[" $this->load->view('sales/new_autospread_order_lines', $data);\n"]], ['Codeigniter - loop through post information passing value to model query and outputting result'], 4, 0], [(16223233, 3), [['In your review reference each hashed item in the $data array as a variable.'], ['-10000']], [[' <?php foreach($products as $product) { ?>\n<p>\n    <?php echo $product["price"]; ?>\n</p>\n<?php } ?>\n']], ['Codeigniter - loop through post information passing value to model query and outputting result'], 4, 0], [(16291075, 0), [['-10000'], ['-10000']], [[' SELECT  a.*\nFROM    TableName a\n        INNER JOIN\n        (\n            SELECT  EmpID\n            FROM    TableName\n            GROUP   BY EmpID\n            HAVING  COUNT(*) > 1\n        ) b ON a.EmpID = b.EmpID\n']], ['oracle duplicate rows based on a single column'], 2, 1], [(16291075, 1), [['-10000'], ['-10000']], [[' SELECT  a.*\nFROM    TableName a\nWHERE   EmpId IN\n        (\n            SELECT  EmpId\n            FROM    TableName\n            GROUP   BY EmpId\n            HAVING  COUNT(*) > 1\n        ) \n']], ['oracle duplicate rows based on a single column'], 2, 1], [(16330159, 0), [['Try this.. '], ['On OP request..update using Select...']], [[" Update TableName Set Gender=Case when Gender='M' Then 'F' Else 'M' end\n"]], ['Interview : update table values using select statement'], 2, 1], [(16330159, 1), [['On OP request..update using Select...'], ['SQL FIDDLE DEMO']], [[' Update TableName T Set Gender=(\nSelect Gender from TableName B where  T.Gender!=B.Gender and rownum=1);\n']], ['Interview : update table values using select statement'], 2, 1], [(16335925, 0), [['Please try:'], ['Sample']], [[' ;with T as(\n    select *, ROW_NUMBER() over (order by User, Days) Rnum from YourTable\n)\nselect \n    distinct a.User, \n    b.Days-a.Days difference_in_day \nfrom T a left join T b on a.Rnum=b.Rnum-1 \nwhere b.User is not null\n']], ['difference in days, between two recordings'], 2, 1], [(16335925, 1), [['Sample'], ['-10000']], [[" declare @tbl as table(xUser nvarchar(1), xDays int)\ninsert into @tbl values \n('A', 1),\n('A', 1),\n('A', 2),\n('B', 2),\n('B', 5)\n\nselect *, ROW_NUMBER() over (order by xUser, xDays) Rnum from @tbl\n\n;with T as(\n    select *, ROW_NUMBER() over (order by xUser, xDays) Rnum from @tbl\n)\nselect \n    distinct a.xUser, \n    b.xDays-a.xDays difference_in_day \nfrom T a left join T b on a.Rnum=b.Rnum-1 \nwhere b.xUser is not null\n"]], ['difference in days, between two recordings'], 2, 1], [(16372169, 0), [['You can then take all your criteria and place them within the order by of a  ROW_NUMBER()  function to get the flats in the order you defined. The key part in the below query is this:'], ["The four columns ( PrevIsNationalityMatch ,  NextIsNationalityMatch ,  EmptyFloor', 'EmptyFlatsEitherSide ), are all bit fields, so if a row exists where the previous flat is owned by someone of the same nationality this will always be ranked one by the ROW_NUMBER function, otherwise it looks for if the next flat is owned by someone of the same nationality (I added this rule as it seemed logical but it could easily be removed by removing it from the order by), and so on and so on until it is left just sorting by floor and flat no."]], [[' RowNumber = ROW_NUMBER() OVER(ORDER BY PrevIsNationalityMatch DESC, \n                                        NextIsNationalityMatch DESC, \n                                        EmptyFloor DESC, \n                                        EmptyFlatsEitherSide DESC,\n                                        Floor, \n                                        FlatNo)\n']], ['return value of stored procedure based on different rules'], 3, 0], [(16426039, 0), [["Logically, you are grouping by two criteria, scale and skill name. However, if I understand it correctly, every row is supposed to represent a single skill name. Therefore, you should group by  tblSkill.Name  only. To get different counts for different scales in separate columns, you can use  conditional aggregation , i.e. aggregation on an expression that (usually) involves a  CASE  construct. Here's how you could go about it:"], ["Note that there's a special syntax for this kind of queries. It employs the  PIVOT  keyword, as what you get is essentially a grouped result set pivoted on one of the grouping criteria, scale in this case. This is how the same could be achieved with  PIVOT :"]], [[' SELECT \n   tblSkill.Name AS skillname,\n   COUNT(CASE tblSkillMetrics.Scale WHEN 1 THEN EmployeeID END) AS NotAplicable,\n   COUNT(CASE tblSkillMetrics.Scale WHEN 2 THEN EmployeeID END) AS Beginner,\n   COUNT(CASE tblSkillMetrics.Scale WHEN 3 THEN EmployeeID END) AS Proficient,\n   COUNT(CASE tblSkillMetrics.Scale WHEN 4 THEN EmployeeID END) AS Expert\nFROM\n   tblSkill\nINNER JOIN \n   tblSkillMetrics ON tblSkillMetrics.SkillID = tblSkill.ID\nGROUP BY \n   tblSkill.Name \nORDER BY \n   skillname DESC\n;\n']], ['Stored procedure for getting sum of entries in table for each ID'], 2, 1], [(16426039, 1), [["Note that there's a special syntax for this kind of queries. It employs the  PIVOT  keyword, as what you get is essentially a grouped result set pivoted on one of the grouping criteria, scale in this case. This is how the same could be achieved with  PIVOT :"], ['Basically,  PIVOT  implies grouping. All columns but one in the source dataset are grouping criteria, namely every one of them that is not used as an argument of an aggregate function in the PIVOT clause is a grouping criterion. One of them is also assigned to be the one the results are pivoted on. (Again, in this case it is scale.)']], [[' SELECT\n   skillname,\n   [1] AS NotAplicable,\n   [2] AS Beginner,\n   [3] AS Proficient,\n   [4] AS Expert\nFROM (\n   SELECT \n      tblSkill.Name AS skillname,\n      tblSkillMetrics.Scale,\n      EmployeeID\n   FROM\n      tblSkill\n   INNER JOIN \n      tblSkillMetrics ON tblSkillMetrics.SkillID = tblSkill.ID\n) s\nPIVOT (\n   COUNT(EmployeeID) FOR Scale IN ([1], [2], [3], [4])\n) p\n;\n']], ['Stored procedure for getting sum of entries in table for each ID'], 2, 1], [(16426094, 0), [["You can simply add another JOIN to the existing query that you have.  And it's a lot cleaner when you use an explicit (INNER) JOIN matching keys in the ON clause, compared with an inferred CROSS JOIN (using comma separated tables) that are filtered in the WHERE clause:"], ['And you can make this even cleaner if you make use of ROW_NUMBER():']], [[' SELECT p.VehicleKey, p.Timestamp, p.Latitude, p.Longitude, p.Speed, v.Name\nFROM AVLVehiclePosition p\nJOIN Vehicles v\n  ON p.VehicleKey = v.VehicleKey\nJOIN (SELECT max(Timestamp) as maxtime, VehicleKEy\n      FROM AVLVehiclePosition\n      GROUP BY VehicleKey) maxresults  \n  ON p.VehicleKey = maxresults.VehicleKEy  \n  AND p.Timestamp = maxresults.maxtime\n']], ['Query Data From Two Tables + One Table Must Only Query Using Most Recent Data'], 2, 1], [(16426094, 1), [['And you can make this even cleaner if you make use of ROW_NUMBER():'], ['-10000']], [[' WITH maxResults AS (\n  SELECT p.VehicleKey, p.Timestamp, p.Latitude, p.Longitude, p.Speed, v.Name,\n         ROW_NUMBER() OVER (PARTITION BY p.VehicleKey ORDER BY p.Timestamp DESC) rowNum\n  FROM AVLVehiclePosition p\n  JOIN Vehicles v\n    ON p.VehicleKey = v.VehicleKey)\nSELECT * FROM maxResults\nWHERE rowNum = 1\n']], ['Query Data From Two Tables + One Table Must Only Query Using Most Recent Data'], 2, 1], [(16442686, 0), [['If you want the sum of all dates, just remove the  where  clause:'], ['If you want the results by date, then include that in your  group by .  For instance, ']], [[' select DTTransaction.machinename, count(DTTransaction.machinename)\nfrom DTTransaction join\n     DTHotelReservation\n     on DTTransaction.TransactionID = DTHotelReservation.TransactionID and\n        DTHotelReservation.HCOMCID in (415428, 415429, 415430, 415431, 415432)\ngroup by DTTransaction.machinename\n']], ['SQL Count of columns result for all existing Dates in the table'], 2, 1], [(16442686, 1), [['If you want the results by date, then include that in your  group by .  For instance, '], ['I included an  order by  clause, so the results will be in order by date within each machine name.']], [[' select DTTransaction.machinename, convert(varchar(10),BookedOn,101), count(DTTransaction.machinename)\nfrom DTTransaction join\n     DTHotelReservation\n     on DTTransaction.TransactionID = DTHotelReservation.TransactionID and\n        DTHotelReservation.HCOMCID in (415428, 415429, 415430, 415431, 415432)\ngroup by DTTransaction.machinename, convert(varchar(10),BookedOn,101)\norder by 1, MAX(BookedOn)\n']], ['SQL Count of columns result for all existing Dates in the table'], 2, 1], [(16487093, 0), [['(assuming the OP wants a fully symmetric outer 4-join)'], ['Result:']], [[' WITH four AS (\n        SELECT id, event_dt FROM t1\n        UNION\n        SELECT id, event_dt FROM t2\n        UNION\n        SELECT id, event_dt FROM t3\n        UNION\n        SELECT id, event_dt FROM t4\n        )\nSELECT f.id, f.event_dt\n        , t1.amt1\n        , t2.amt2\n        , t3.amt3\n        , t4.amt4\nFROM four f\nLEFT JOIN t1 ON t1.id = f.id AND t1.event_dt = f.event_dt\nLEFT JOIN t2 ON t2.id = f.id AND t2.event_dt = f.event_dt\nLEFT JOIN t3 ON t3.id = f.id AND t3.event_dt = f.event_dt\nLEFT JOIN t4 ON t4.id = f.id AND t4.event_dt = f.event_dt\nORDER BY id, event_dt\n        ;\n']], ['SQL Full outer join or alternative solution'], 2, 1], [(16487093, 1), [['Result:'], ['BTW: after the  UNION  four,  LEFT JOIN s will do the same as  FULL JOIN s here (union four already has all the possible {id, event_dt} pairs)']], [['  id |  event_dt  | amt1 | amt2 | amt3 | amt4 \n----+------------+------+------+------+------\n  1 | 2012-04-01 |    1 |      |      |     \n  1 | 2012-04-02 |    1 |      |    3 |     \n  1 | 2012-04-03 |    1 |      |    3 |     \n  1 | 2012-04-06 |      |    2 |    3 |    4\n  1 | 2012-04-07 |      |    2 |      |     \n  2 | 2012-04-01 |   40 |      |      |     \n  2 | 2012-04-02 |      |      |    3 |     \n  2 | 2012-04-03 |      |      |    3 |     \n  2 | 2012-04-04 |   40 |      |      |     \n(9 rows)\n']], ['SQL Full outer join or alternative solution'], 2, 0], [(16490625, 0), [['In SQL Server syntax:'], ['Here is an example of the code that works, according to my understanding of the problem:']], [[' update tableC\n    set Name = (select top 1 b.name\n                from TableB b \n                where b.name not in (select name from TableA a where a.id = TableC.id)\n                order by NEWID()\n               )\n']], ['SQL Server 2012: JOIN 3 tables for a condition'], 2, 1], [(16490625, 1), [['Here is an example of the code that works, according to my understanding of the problem:'], ['-10000']], [[" declare @tableA table (id int, name varchar(2));\ndeclare @tableB table (name varchar(2));\ndeclare @tableC table (id int, name varchar(2))\n\ninsert into @tableA(id, name)\n    select 01, 'A4' union all\n    select 01, 'SH' union all\n    select 01, '9K' union all\n    select 02, 'M1' union all\n    select 02, 'L4' union all\n    select 03, '2G' union all\n    select 03, '99';\n\ninsert into @tableB(name)\n    select '5G' union all\n    select 'U8' union all\n    select '02' union all\n    select '45' union all\n    select '23' union all\n    select 'J7' union all\n    select '99' union all\n    select '9F' union all\n    select 'A4' union all\n    select 'H2';\n\n\ninsert into @tableC(id)\n    select 01 union all\n    select 01 union all\n    select 01 union all\n    select 02 union all\n    select 02 union all\n    select 03 union all\n    select 03;\n\n/*    \nselect * from @tableA;\nselect * from @tableB;\nselect * from @tableC;\n */\n\nupdate c\n    set Name = (select top 1 b.name\n                from @TableB b \n                where b.name not in (select name from @TableA a where a.id = c.id)\n                order by NEWID()\n               )\nfrom @tableC c\n\nselect *\nfrom @tableC\n"]], ['SQL Server 2012: JOIN 3 tables for a condition'], 2, 1], [(16507239, 0), [['Once you have this data normalized then you can easily query the data. The new table structure could be similar to this:'], ['Normalizing the tables would make it much easier for you to query the data by joining the tables:']], [[" CREATE TABLE T1\n(\n  [col1] varchar(2), \n  [col2] varchar(5),\n  constraint pk1_t1 primary key (col1)\n);\n\nINSERT INTO T1\n    ([col1], [col2])\nVALUES\n    ('C1', 'john'),\n    ('C2', 'alex'),\n    ('C3', 'piers'),\n    ('C4', 'sara')\n;\n\nCREATE TABLE T2\n(\n  [col1] varchar(2), \n  [col2] varchar(2),\n  constraint pk1_t2 primary key (col1, col2),\n  constraint fk1_col2 foreign key (col2) references t1 (col1)\n);\n\nINSERT INTO T2\n    ([col1], [col2])\nVALUES\n    ('R1', 'C1'),\n    ('R1', 'C2'),\n    ('R1', 'C4'),\n    ('R2', 'C3'),\n    ('R2', 'C4'),\n    ('R3', 'C1'),\n    ('R3', 'C4')\n;\n"]], ['join comma delimited data column'], 6, 0], [(16507239, 1), [['Normalizing the tables would make it much easier for you to query the data by joining the tables:'], ['Then if you wanted to display the data as a comma-separated list, you could use  FOR XML PATH  and  STUFF :']], [[' select t2.col1, t1.col2\nfrom t2\ninner join t1\n  on t2.col2 = t1.col1\n']], ['join comma delimited data column'], 6, 0], [(16507239, 2), [['Then if you wanted to display the data as a comma-separated list, you could use  FOR XML PATH  and  STUFF :'], ['First, you could create a split function that will convert the data stored in the list into rows that can be joined on. The split function would be similar to this:']], [[" select distinct t2.col1, \n  STUFF(\n         (SELECT distinct ', ' + t1.col2\n          FROM t1\n          inner join t2 t\n            on t1.col1 = t.col2\n          where t2.col1 = t.col1\n          FOR XML PATH ('')), 1, 1, '') col2\nfrom t2;\n"]], ['join comma delimited data column'], 6, 0], [(16507239, 3), [['First, you could create a split function that will convert the data stored in the list into rows that can be joined on. The split function would be similar to this:'], ['When you use the split, function you can either leave the data in the multiple rows or you can concatenate the values back into a comma separated list:']], [[' CREATE FUNCTION [dbo].[Split](@String varchar(MAX), @Delimiter char(1))       \nreturns @temptable TABLE (items varchar(MAX))       \nas       \nbegin      \n    declare @idx int       \n    declare @slice varchar(8000)       \n\n    select @idx = 1       \n        if len(@String)<1 or @String is null  return       \n\n    while @idx!= 0       \n    begin       \n        set @idx = charindex(@Delimiter,@String)       \n        if @idx!=0       \n            set @slice = left(@String,@idx - 1)       \n        else       \n            set @slice = @String       \n\n        if(len(@slice)>0)  \n            insert into @temptable(Items) values(@slice)       \n\n        set @String = right(@String,len(@String) - @idx)       \n        if len(@String) = 0 break       \n    end   \nreturn \nend;\n']], ['join comma delimited data column'], 6, 0], [(16507239, 4), [['When you use the split, function you can either leave the data in the multiple rows or you can concatenate the values back into a comma separated list:'], ['A final way that you could get the result is by applying  FOR XML PATH  directly.']], [[" ;with cte as\n(\n  select c.col1, t1.col2\n  from t1\n  inner join \n  (\n    select t2.col1, i.items col2\n    from t2\n    cross apply dbo.split(t2.col2, ',') i\n  ) c\n    on t1.col1 = c.col2\n) \nselect distinct c.col1, \n  STUFF(\n         (SELECT distinct ', ' + c1.col2\n          FROM cte c1\n          where c.col1 = c1.col1\n          FOR XML PATH ('')), 1, 1, '') col2\nfrom cte c\n"]], ['join comma delimited data column'], 6, 0], [(16550767, 0), [['How about:'], ['Edit :\nThe performance of minus generally suck, due to the sort operation. \nIf any of  {a,b,c}  are nullable, try the following instead:']], [[" update table1\n   set d = 'TEST'\n where (a,b,c) not in(select a,b,c from table2);\n"]], ['ORACLE Update with MINUS result'], 2, 1], [(16550767, 1), [['Edit :\nThe performance of minus generally suck, due to the sort operation. \nIf any of  {a,b,c}  are nullable, try the following instead:'], ['-10000']], [[" update table1 t1\n   set t1.d = 'TEST'\n where not exists(\n         select 'x'\n           from table2 t2\n          where t2.a = t1.a\n            and t2.b = t1.b\n            and t2.c = t1.c\n       );\n"]], ['ORACLE Update with MINUS result'], 2, 1], [(16569297, 0), [['-10000'], ['-10000']], [[' SELECT  account_code, product_id\nFROM    (\n            SELECT  account_code, product_id, num_purchases,\n                    DENSE_RANK() OVER (PARTITION BY account_code \n                                        ORDER BY num_purchases DESC) RowID\n            FROM    TableName\n        )records\nWHERE   RowID = 1\n']], ['T-SQL How to build an aggregate table based on max values from a group?'], 2, 1], [(16569297, 1), [['-10000'], ['-10000']], [[' ╔══════════════╦════════════╗\n║ ACCOUNT_CODE ║ PRODUCT_ID ║\n╠══════════════╬════════════╣\n║ abc123       ║          1 ║\n║ xyz789       ║          1 ║\n╚══════════════╩════════════╝\n']], ['T-SQL How to build an aggregate table based on max values from a group?'], 2, 0], [(16668803, 0), [['Query:'], ['Output:']], [[" DECLARE \n      @prime_schema SYSNAME = 'aaa'\n    , @next_schema SYSNAME = 'bbb'\n\nDECLARE @SQL NVARCHAR(MAX)\nSELECT @SQL = (\n    SELECT CHAR(13) + '\n        SELECT * \n        INTO [' + @next_schema + '].[' + o.name + ']\n        FROM [' + s.name + '].[' + o.name + ']\n        WHERE 1 != 1'\n    FROM sys.objects o WITH (NOWAIT)\n    JOIN sys.schemas s WITH (NOWAIT) ON o.[schema_id] = s.[schema_id]\n    WHERE o.[type] = 'U'\n        AND s.name = @prime_schema\n        AND o.name IN ('table1', 'table2', 'table3')\n    FOR XML PATH(''), TYPE).value('.', 'NVARCHAR(MAX)')\n\nPRINT @SQL\n"]], ['Sql - Fetch next value to replace variable value'], 2, 1], [(16668803, 1), [['Output:'], ['-10000']], [[' SELECT * \nINTO [bbb].[table1]\nFROM [aaa].[table1]\nWHERE 1 != 1\n\nSELECT * \nINTO [bbb].[table2]\nFROM [aaa].[table2]\nWHERE 1 != 1\n\nSELECT * \nINTO [bbb].[table3]\nFROM [aaa].[table3]\nWHERE 1 != 1\n']], ['Sql - Fetch next value to replace variable value'], 2, 0], [(16685165, 0), [['Try this:'], ['UPDATE:  for distinct values you can use :']], [[" SELECT\n    user_id,\n    SUBSTRING_INDEX(tags,'<',2) as tag\nFROM\n    t1\nUNION ALL\nSELECT\n    user_id,\n    SUBSTRING_INDEX(tags,'>',-2) as tag\nFROM\n    t1\n"]], ['Sql dividing one record into to many records'], 2, 1], [(16685165, 1), [['UPDATE:  for distinct values you can use :'], ['-10000']], [[" SELECT\n    user_id,\n    tag\nFROM (\n    SELECT\n        user_id,\n        SUBSTRING_INDEX(tags,'<',2) as tag\n    FROM\n        t1\n    UNION ALL\n    SELECT\n        user_id,\n        SUBSTRING_INDEX(tags,'>',-2) as tag\n    FROM\n        t1\n) as tmp\n    GROUP BY\n        user_id,\n        tag\n"]], ['Sql dividing one record into to many records'], 2, 1], [(16688990, 0), [['Lets imagine you have a form that has the following imports,'], ['That form has two controls']], [[' Imports System.Windows.Forms\nImports System.Threading\nImports System.Threading.Tasks\n']], ['How to display progress bar while executing big SQLCommand VB.Net'], 5, 0], [(16688990, 1), [['That form has two controls'], ['Somewhere in your application we have a  Function  called  ExecuteSlowStuff , this function is the equivalent of your  executeMyQuery . The important part is the  Action  parameter which the function uses to show it is making progress.']], [[' Private WithEvents DoSomthing As Button\nPrivate WithEvents Progress As ProgressBar\n']], ['How to display progress bar while executing big SQLCommand VB.Net'], 5, 0], [(16688990, 2), [['Somewhere in your application we have a  Function  called  ExecuteSlowStuff , this function is the equivalent of your  executeMyQuery . The important part is the  Action  parameter which the function uses to show it is making progress.'], ['Lets say this work is started by the click of the  DoSomething   Button .']], [[' Private Shared Function ExecuteSlowStuff(ByVal progress As Action) As Integer\n    Dim result = 0\n    For i = 0 To 10000\n        result += i\n        Thread.Sleep(500)\n        progress()\n    Next\n\n    Return result\nEnd Function\n']], ['How to display progress bar while executing big SQLCommand VB.Net'], 5, 0], [(16688990, 3), [['Lets say this work is started by the click of the  DoSomething   Button .'], ["You're probably wondering where  ShowProgress  comes from, that is the messier bit."]], [[' Private Sub Start() Handled DoSomething.Click\n    Dim slowStuff = Task(Of Integer).Factory.StartNew(\n        Function() ExceuteSlowStuff(AddressOf Me.ShowProgress))\nEnd Sub\n']], ['How to display progress bar while executing big SQLCommand VB.Net'], 5, 0], [(16688990, 4), [["You're probably wondering where  ShowProgress  comes from, that is the messier bit."], ['Note that because  ShowProgress  can be invoked from another thread, it checks for cross thread calls. In that case it invokes itself on the main thread.']], [[' Private Sub ShowProgress()\n    If Me.Progress.InvokeRequired Then\n        Dim cross As new Action(AddressOf Me.ShowProgress)\n        Me.Invoke(cross)\n    Else \n        If Me.Progress.Value = Me.Progress.Maximum Then\n            Me.Progress.Value = Me.Progress.Minimum\n        Else\n            Me.Progress.Increment(1)\n        End If\n\n        Me.Progress.Refresh()\n    End if\nEnd Sub\n']], ['How to display progress bar while executing big SQLCommand VB.Net'], 5, 0], [(16756054, 0), [['How about'], ['Sample output:']], [[" SELECT \n  CASE datename(dw,getdate())\n    WHEN 'Monday'    THEN Monday\n    WHEN 'Tuesday'   THEN Tuesday\n    WHEN 'Wednesday' THEN Wednesday\n    WHEN 'Thursday'  THEN Thursday\n    WHEN 'Friday'    THEN Friday\n    WHEN 'Saturday'  THEN Saturday\n    WHEN 'Sunday'    THEN Sunday\n  END today\n  FROM @MyTemp\n WHERE Name = 'Test'\n"]], ['Convert select result to column name in SQL Server'], 2, 1], [(16756054, 1), [['Sample output:'], ['SQLFiddle']], [[' | TODAY |\n---------\n| 09:30 |\n']], ['Convert select result to column name in SQL Server'], 2, 0], [(16797418, 0), [['If you want the number of each records for each day:'], ['Or if you want a sum of a field on each record:']], [[' SELECT DTTM,COUNT(*) AS Total\nFROM \n[Audits].[dbo].[Miscount]\nGroup by DTTM\nOrder by DTTM desc\n']], ['TSql Sum By Date'], 4, 0], [(16797418, 1), [['Or if you want a sum of a field on each record:'], ['Or if DTTM is a datetime then you can use:']], [[' SELECT DTTM,SUM(field1) AS Sum\nFROM \n[Audits].[dbo].[Miscount]\nGroup by DTTM\nOrder by DTTM desc\n']], ['TSql Sum By Date'], 4, 1], [(16797418, 2), [['Or if DTTM is a datetime then you can use:'], ['Newer versions of SQL Sever will support a Date type, so you can do this instead:']], [[' SELECT DATEADD(dd, 0, DATEDIFF(dd, 0, DTTM)) AS DTTM,COUNT(*) AS Total\nFROM \n[Audits].[dbo].[Miscount]\nGroup by DATEADD(dd, 0, DATEDIFF(dd, 0, DTTM))\nOrder by DATEADD(dd, 0, DATEDIFF(dd, 0, DTTM)) desc\n']], ['TSql Sum By Date'], 4, 1], [(16797418, 3), [['Newer versions of SQL Sever will support a Date type, so you can do this instead:'], ['-10000']], [[' SELECT CAST(DTTM AS Date) AS DTTM,COUNT(*) AS Total\nFROM \n[Audits].[dbo].[Miscount]\nGroup by CAST(DTTM AS Date)\nOrder by CAST(DTTM AS Date) desc\n']], ['TSql Sum By Date'], 4, 1], [(16799445, 0), [['EDIT: \nChanged to include non-workdays as valid fromDates.'], ['You could put a date rank column on the calendar table to simplify this and avoid the CTE:']], [[' WITH rankedDates AS\n    (\n        SELECT \n            thedate\n            , ROW_NUMBER()\n                OVER(\n                    ORDER BY thedate\n                    ) dateRank\n        FROM \n            calendar c\n        WHERE \n            c.isweekday = 1 \n            AND \n            c.isholiday = 0\n    )\nSELECT \n    c1.fromdate\n    , rd2.thedate todate\nFROM\n    ( \n        SELECT \n            c.thedate fromDate\n            , \n                (\n                    SELECT \n                        TOP 1 daterank\n                    FROM \n                        rankedDates rd\n                    WHERE\n                        rd.thedate <= c.thedate\n                    ORDER BY \n                        thedate DESC\n                ) dateRank\n        FROM \n            calendar c\n    ) c1        \nLEFT JOIN\n    rankedDates rd2\n    ON \n        c1.dateRank + 3 = rd2.dateRank        \n']], ['Select date + 3 days, not including weekends and holidays'], 2, 1], [(16799445, 1), [['You could put a date rank column on the calendar table to simplify this and avoid the CTE:'], ["Then you'd set the daterank column only where it's a non-holiday weekday."]], [[' CREATE TABLE\n    calendar\n    (\n        TheDate DATETIME PRIMARY KEY\n        , isweekday BIT NOT NULL\n        , isHoliday BIT NOT NULL DEFAULT 0\n        , dateRank INT NOT NULL\n    );\n']], ['Select date + 3 days, not including weekends and holidays'], 2, 0], [(16874590, 0), [['The corresponding code for Oracle 11g:'], ['The following solution is for SQL Server 2012:']], [[' select\nb.id_bus_line, b.id_bus_stop\nfrom BusLine_BusStop b\nstart with b.is_first_stop = 1\nconnect by nocycle prior b.id_next_bus_stop = b.id_bus_stop and prior b.id_bus_line = b.id_bus_line\n']], ['Order SQL request when each row contains id of the next one'], 3, 1], [(16874590, 1), [['The following solution is for SQL Server 2012:'], ['The trick consists in the creation of a dedicated temporary sequence for the current session that you can reset.']], [[' ;WITH route AS\n(\n  SELECT BusLineId, BusStopId, NextBusStopId\n  FROM BusLine_BusStop\n  WHERE IsFirstStop = 1\n  UNION ALL\n  SELECT b.BusLineId, b.BusStopId, b.NextBusStopId\n  FROM BusLine_BusStop b\n  INNER JOIN route r\n          ON r.BusLineId = b.BusLineId\n         AND r.NextBusStopId = b.BusStopId\n  WHERE IsFirstStop = 0 or IsFirstStop is null\n)\nSELECT BusLineId, BusStopId\nFROM route\nORDER BY BusLineId\n']], ['Order SQL request when each row contains id of the next one'], 3, 1], [(16874590, 2), [['The trick consists in the creation of a dedicated temporary sequence for the current session that you can reset.'], ['DEMO for PostgreSQL 9.1.9  of my own.']], [[" create temp sequence rownum;\n\nWITH final_route AS\n(\n  WITH RECURSIVE route AS\n  (\n    SELECT BusLineId, BusStopId, NextBusStopId\n    FROM BusLine_BusStop\n    WHERE IsFirstStop = 1\n    UNION ALL\n    SELECT b.BusLineId, b.BusStopId, b.NextBusStopId\n    FROM BusLine_BusStop b\n    INNER JOIN route r\n            ON r.BusLineId = b.BusLineId\n           AND r.NextBusStopId = b.BusStopId\n    WHERE IsFirstStop = 0 or IsFirstStop is null\n  )\n  SELECT BusLineId, BusStopId, nextval('rownum') as rownum\n  FROM route\n)\nSELECT BusLineId, BusStopId\nFROM final_route\nORDER BY BusLineId, rownum;\n"]], ['Order SQL request when each row contains id of the next one'], 3, 1], [(16877276, 0), [['If I understand correctly you probably meant  Fanta of Coca-Cola  not vice versa.'], ['Output:']], [[" SELECT p.id_product, \n       CONCAT(p.name_product, ' of ', p1.name_product) name_product, \n       p.has_choice, \n       p.choice_id\n  FROM products p JOIN products p1\n    ON p.choice_id = p1.id_product\n"]], ['MySQL self inner joining and seaching in it'], 4, 1], [(16877276, 1), [['Output:'], ['UPDATE1  To get list of all products wether they are choices of product or not you need to use  LEFT JOIN . To search in product names both parent product and choices use appropriate aliases of tables in  WHERE  clause.']], [[' | ID_PRODUCT |        NAME_PRODUCT | HAS_CHOICE | CHOICE_ID |\n-------------------------------------------------------------\n|          3 |  Fanta of Coca-Cola |          0 |         2 |\n|          4 | Sprite of Coca-Cola |          0 |         2 |\n']], ['MySQL self inner joining and seaching in it'], 4, 0], [(16877276, 2), [['UPDATE1  To get list of all products wether they are choices of product or not you need to use  LEFT JOIN . To search in product names both parent product and choices use appropriate aliases of tables in  WHERE  clause.'], ['Output:']], [[" SELECT p.id_product,\n       CASE WHEN p1.id_product IS NULL THEN\n           p.name_product\n       ELSE\n           CONCAT(p.name_product, ' of ', p1.name_product) \n       END name_product, \n       p.has_choice, \n       p.choice_id\n  FROM products p LEFT JOIN products p1  -- use LEFT JOIN here\n    ON p.choice_id = p1.id_product\n WHERE p.has_choice = 0                  -- filter out parent products\n   AND (p.name_product  LIKE '%a%'     -- search in product name\n        OR\n        p1.name_product LIKE '%a%') -- search in product name of a parent product\n"]], ['MySQL self inner joining and seaching in it'], 4, 1], [(16877276, 3), [['Output:'], ['Here is  SQLFiddle  demo.']], [[' | ID_PRODUCT |        NAME_PRODUCT | HAS_CHOICE | CHOICE_ID |\n-------------------------------------------------------------\n|          3 |  Fanta of Coca-Cola |          0 |         2 |\n|          4 | Sprite of Coca-Cola |          0 |         2 |\n|          5 |               Axion |          0 |         0 |\n']], ['MySQL self inner joining and seaching in it'], 4, 0], [(16887108, 0), [['Use foreign_key option:'], ['For Post model it will be']], [[' has_many :posts, :foreign_key => :poster_id\n']], ['How to specify a foreign key?'], 3, 1], [(16887108, 1), [['For Post model it will be'], ['or']], [[' belongs_to :user, :foreign_key => :poster_id\n']], ['How to specify a foreign key?'], 3, 1], [(16887108, 2), [['or'], ['-10000']], [[" belongs_to :poster, :class_name => 'User'\n"]], ['How to specify a foreign key?'], 3, 1], [(16895364, 0), [['Try this one:'], ['Result:']], [[' SELECT * FROM Table1\nWHERE item_id IN ( \n                   SELECT item_id FROM Table1\n                   GROUP BY item_id\n                   HAVING MAX(category_id) = 0\n                 )\n']], ["Select value which don't have atleast one association"], 3, 1], [(16895364, 1), [['Result:'], ['-10000']], [[' ╔═════════╦═════════════╗\n║ ITEM_ID ║ CATEGORY_ID ║\n╠═════════╬═════════════╣\n║       4 ║           0 ║\n║       5 ║           0 ║\n╚═════════╩═════════════╝\n']], ["Select value which don't have atleast one association"], 3, 0], [(16895364, 2), [['-10000'], ['-10000']], [[' SELECT DISTINCT * FROM Table1\nWHERE item_id IN ( \n                   SELECT item_id FROM Table1\n                   GROUP BY item_id\n                   HAVING MAX(category_id) = 0\n                 );\n']], ["Select value which don't have atleast one association"], 3, 1], [(16914206, 0), [['You need to use multiple joins to work across the relationships.'], ['Full Example']], [[' select e.id, e.name, e.startDate, r.RoleName \nfrom employee e \njoin user_roles ur\non e.id = ur.employee_id\njoin roles r\non r.id = ur.role_id\n']], ['SQL SELECT statement when using look up table'], 2, 1], [(16914206, 1), [['Full Example'], ['Working Example']], [[" /*DDL*/\n\ncreate table EMPLOYEE(\n   ID int,\n   Name varchar(50),\n   StartDate date\n);\n\ncreate table USER_ROLES(\n  Employee_ID int,\n  Role_ID int\n);\n\ncreate table Roles(\n  ID int,\n  RoleName varchar(50)\n);\n\ninsert into EMPLOYEE values(1, 'Jon Skeet', '2013-03-04');\ninsert into USER_ROLES values (1,1);\ninsert into ROLES values(1, 'Superman');\n\n/* Query */\nselect e.id, e.name, e.startDate, r.RoleName \nfrom employee e \njoin user_roles ur\non e.id = ur.employee_id\njoin roles r\non r.id = ur.role_id;\n"]], ['SQL SELECT statement when using look up table'], 2, 1], [(16930761, 0), [['You want an aggregation with a case statement.  The following query checks for multiple values (assuming no NULLs):'], ['If you really need the multiple rows as well:']], [[" select (case when count(distinct Reference) = 1 then 'TRUE'\n             else 'FALSE'\n        end)\nfrom t\n"]], ['Oracle 10g SQL: Return true if a column has only a value, but > 1 rows in a table'], 2, 1], [(16930761, 1), [['If you really need the multiple rows as well:'], ['-10000']], [[" select (case when count(distinct Reference) = 1 and count(*) > 1 then 'TRUE'\n             else 'FALSE'\n        end)\nfrom t\n"]], ['Oracle 10g SQL: Return true if a column has only a value, but > 1 rows in a table'], 2, 1], [(16962915, 0), [['The following query takes this approach:'], ['I actually tested this in SQL Server by placing this  with  clause in front:']], [[' select distinct MIN(id2)\nfrom (select t1.id as id1, t2.id as id2, count(*) as cnt\n      from t t1 join\n           t t2\n           on t1.color = t2.color\n      group by t1.id, t2.id\n     ) t1t2 join\n     (select t.id, COUNT(*) as cnt\n      from t\n      group by t.id\n     ) t1sum\n     on t1t2.id1 = t1sum.id and t1sum.cnt = t1t2.cnt join\n     (select t.id, COUNT(*) as cnt\n      from t\n      group by t.id\n     ) t2sum\n     on t1t2.id2 = t2sum.id and t2sum.cnt = t1t2.cnt\ngroup by t1t2.id1, t1t2.cnt, t1sum.cnt, t2sum.cnt\n']], ['Select id on grouped unique set of data'], 2, 1], [(16962915, 1), [['I actually tested this in SQL Server by placing this  with  clause in front:'], ['-10000']], [[" with t as (\n      select 1 as id, 'r' as color union all\n      select 1, 'g' union all\n      select 1, 'b' union all\n      select 2 as id, 'r' as color union all\n      select 2, 'g' union all\n      select 2, 'b' union all\n      select 3, 'r' union all\n      select 4, 'y' union all\n      select 4, 'p' union all\n      select 5 as id, 'r' as color union all\n      select 5, 'g' union all\n      select 5, 'b' union all\n      select 5, 'p'\n     )\n"]], ['Select id on grouped unique set of data'], 2, 0], [(16971556, 0), [[''], ['Long story short, you need to  study the basics  before you try to create sophisticated functions.']], [[' CREATE OR REPLACE FUNCTION ntile_loop(x integer)\nRETURNS SETOF numeric as \n$func$\nDECLARE\n   myvar text;\nBEGIN\n\nSELECT INTO myvar  max(billed)\nFROM  (\n   SELECT billed, id, cm\n         ,ntile(100) OVER (PARTITION BY id, cm ORDER BY billed) AS tile\n   FROM   table_all\n   ) sub\nWHERE  sub.tile = $1;\n\n-- do something with myvar, depending on the value of $1 ...\nEND\n$func$ LANGUAGE plpgsql;\n']], ['Convert numeric to string inside a user-defined function'], 2, 0], [(16971556, 1), [['Long story short, you need to  study the basics  before you try to create sophisticated functions.'], ['%  .. modulo operator \n GROUP  BY 1,2,3  .. positional parameter']], [[' SELECT id, cm, tile, max(billed) AS max_billed\nFROM  (\n   SELECT billed, id, cm\n         ,ntile(100) OVER (PARTITION BY id, cm ORDER BY billed) AS tile\n   FROM   table_all\n   ) sub\nWHERE (tile%10 = 0 OR tile = 5)\nAND    tile <= 90\nGROUP  BY 1,2,3\nORDER  BY 1,2,3;\n']], ['Convert numeric to string inside a user-defined function'], 2, 0], [(17003542, 0), [['-10000'], ['OR']], [[' @/path/main_script.sql:\nSTART script_one.sql\nSTART script_two.sql\nSTART script_three.sql\nSTART script_four.sql\nSTART script_five.sql\n']], ['How to compile multiple stored procedures from a single file?'], 2, 1], [(17003542, 1), [['OR'], ['-10000']], [[' @/path/main_script.sql:\n@@/path/script_one.sql\n@@/path/script_two.sql\n@@/path/script_three.sql\n@@/path/script_four.sql\n@@/path/script_five.sql\n']], ['How to compile multiple stored procedures from a single file?'], 2, 1], [(17017125, 0), [["You can then filter that through a window to get the per-event per-day lagged counts ... except that your event days aren't contiguous and unfortunately PostgreSQL window functions only support  ROWS , not  RANGE , so you have to join across a generated series of dates first."], ['Output with the sample data:']], [[' WITH\n/* First, get a listing of event counts by day */\nevent_days(event_name, event_day, event_day_count) AS (\n        SELECT event_name, date_trunc(\'day\', event_date), count(id)\n        FROM Table1\n        GROUP BY event_name, date_trunc(\'day\', event_date)\n        ORDER BY date_trunc(\'day\', event_date), event_name\n),\n/* \n * Then fill in zeros for any days within the range that didn\'t have any events.\n * If PostgreSQL supported RANGE windows, not just ROWS, we could get rid of this/\n */\nevent_days_contiguous(event_name, event_day, event_day_count) AS (\n        SELECT event_names.event_name, gen_day, COALESCE(event_days.event_day_count,0)\n        FROM generate_series( (SELECT min(event_day)::date FROM event_days), (SELECT max(event_day)::date FROM event_days), INTERVAL \'1\' DAY ) gen_day\n        CROSS JOIN (SELECT DISTINCT event_name FROM event_days) event_names(event_name)\n        LEFT OUTER JOIN event_days ON (gen_day = event_days.event_day AND event_names.event_name = event_days.event_name)\n),\n/*\n * Get the lagged counts by using the sum() function over a row window...\n */\nlagged_days(event_name, event_day_first, event_day_last, event_days_count) AS (\n        SELECT event_name, event_day, first_value(event_day) OVER w, sum(event_day_count) OVER w\n        FROM event_days_contiguous\n        WINDOW w AS (PARTITION BY event_name ORDER BY event_day ROWS 1 PRECEDING)\n)\n/* Now do a manual pivot. For arbitrary column counts use an external tool\n * or check out the \'crosstab\' function in the \'tablefunc\' contrib module \n */\nSELECT d1.event_day_first, d1.event_days_count AS "Event_A", d2.event_days_count AS "Event_B"\nFROM lagged_days d1\nINNER JOIN lagged_days d2 ON (d1.event_day_first = d2.event_day_first AND d1.event_name = \'event_A\' AND d2.event_name = \'event_B\')\nORDER BY d1.event_day_first;\n']], ['How to use "Group By" for date interval in postgres'], 5, 1], [(17017125, 1), [['Output with the sample data:'], ["SQLFiddle doesn't seem to be working at the moment, but here's the demo setup I used:"]], [['     event_day_first     | Event_A | Event_B \n------------------------+---------+---------\n 2013-04-24 00:00:00+08 |       2 |       1\n 2013-04-25 00:00:00+08 |       4 |       1\n 2013-04-26 00:00:00+08 |       3 |       0\n 2013-04-27 00:00:00+08 |       2 |       1\n(4 rows)\n']], ['How to use "Group By" for date interval in postgres'], 5, 0], [(17017125, 2), [["SQLFiddle doesn't seem to be working at the moment, but here's the demo setup I used:"], ["Here's how to express it as a view instead:"]], [[' CREATE TABLE Table1 \n(id integer primary key, "event_date" timestamp not null, "event_name" text);\n\nINSERT INTO Table1\n("id", "event_date", "event_name")\nVALUES\n(101, \'2013-04-24 18:33:37\', \'event_A\'),\n(102, \'2013-04-24 20:34:37\', \'event_B\'),\n(103, \'2013-04-24 20:40:37\', \'event_A\'),\n(104, \'2013-04-25 01:00:00\', \'event_A\'),\n(105, \'2013-04-25 12:00:15\', \'event_A\'),\n(106, \'2013-04-26 00:56:10\', \'event_A\'),\n(107, \'2013-04-27 12:00:15\', \'event_A\'),\n(108, \'2013-04-27 12:00:15\', \'event_B\');\n']], ['How to use "Group By" for date interval in postgres'], 5, 0], [(17017125, 4), [["You can then use the view in whatever crosstab queries you want to write. It'll work with the prior hand-crosstab query:"], ["... or using  crosstab  from the  tablefunc  extension, which I'll let you study up on."]], [[' SELECT d1.event_day_first, d1.event_days_count AS "Event_A", d2.event_days_count AS "Event_B"\nFROM lagged_days d1\nINNER JOIN lagged_days d2 ON (d1.event_day_first = d2.event_day_first AND d1.event_name = \'event_A\' AND d2.event_name = \'event_B\')\nORDER BY d1.event_day_first;\n']], ['How to use "Group By" for date interval in postgres'], 5, 0], [(17025457, 0), [['The resulting query should work:'], ['Because you are only choosing one product, a  group by  is probably not necessary.  You might consider this, however:']], [[' SELECT MIN(`map`.`Product_Price`) as `minProductPrice`,\n       MAX(`map`.`Product_Price`) as `maxProductPrice`,\n       `pr`.`Product_Name` as `productName`\nFROM `bm_market_products` `map` join\n     `bm_products` as `pr`\n     on map`.`Product_Id` = `pr`.`Product_Id`\nWHERE `map`.`Product_Id` = 1 \n']], ['MIN/MAX price for each product (query)'], 2, 1], [(17025457, 1), [['Because you are only choosing one product, a  group by  is probably not necessary.  You might consider this, however:'], ['That will return the information for all products.']], [[' SELECT MIN(`map`.`Product_Price`) as `minProductPrice`,\n       MAX(`map`.`Product_Price`) as `maxProductPrice`,\n       `pr`.`Product_Name` as `productName`\nFROM `bm_market_products` `map` join\n     `bm_products` as `pr`\n     on map`.`Product_Id` = `pr`.`Product_Id`\ngroup by `map`.`Product_Id`\n']], ['MIN/MAX price for each product (query)'], 2, 1], [(17043777, 0), [['The following query:'], ['would produce results like:']], [[' SELECT id, related_info, count(related_info)\nFROM my_table\nWHERE <complex filtering on related_info here>\ngroup by id, related_info with rollup\n']], ['Is it possible to get results, and count of the results, at the same time? (to filter results based on the result count)'], 5, 1], [(17043777, 1), [['would produce results like:'], ['The solution is easy in most databases:']], [[' id | related_info |  count(related_info)|\n1  |         info1|                    1|\n1  |         info2|                    1|\n1  |         info3|                    1|\n1  |         NULL |                    3|\n']], ['Is it possible to get results, and count of the results, at the same time? (to filter results based on the result count)'], 5, 0], [(17043777, 2), [['The solution is easy in most databases:'], ['A typical alternative in MySQL, if you need the list of "related_info" is to use  group_concat :']], [[' SELECT id, related_info, count(related_info) over (partition by id)\nFROM my_table\nWHERE <complex filtering on related_info here>\n']], ['Is it possible to get results, and count of the results, at the same time? (to filter results based on the result count)'], 5, 1], [(17043777, 3), [['A typical alternative in MySQL, if you need the list of "related_info" is to use  group_concat :'], ['And a final method, assuming that  related_info  is a single column that uniquely identifies each row:']], [[' select id, group_concat(related_info), count(*)\nfrom my_table\nwhere <complex filtering on related_info here>\ngroup by id;\n']], ['Is it possible to get results, and count of the results, at the same time? (to filter results based on the result count)'], 5, 1], [(17043777, 4), [['And a final method, assuming that  related_info  is a single column that uniquely identifies each row:'], ['This turns "related_info" into a list and then matches back to the original data.  This can also be done with a unique id in the original data (which  id  is not based on the sample data).']], [[' select mt.id, mt.related_info, t.cnt\nfrom my_table mt join\n     (select id, group_concat(related_info) as relatedInfoList, count(*) as cnt\n      from my_table\n      where <complex filtering on related_info here>\n      group by id\n     ) t\n     on mt.id = t.id and\n        find_in_set(related_info, relatedInfoList) > 0\n']], ['Is it possible to get results, and count of the results, at the same time? (to filter results based on the result count)'], 5, 1], [(17044086, 0), [['try to use the  coalesce  operator.'], ["if you're talking of row instead of columns :"]], [[' select sum(coalesce(columna, 0) + coalesce(columnb, 0))\n']], ['sum of two different rows(salary) in a table'], 2, 1], [(17044086, 1), [["if you're talking of row instead of columns :"], ['-10000']], [[" SELECT SUM(Salary)\nFROM yourTable\nWHERE Name IN ('Smith', 'Wong')\nGROUP BY Name\n"]], ['sum of two different rows(salary) in a table'], 2, 1], [(17057129, 0), [['For database: \nYou can check the creation time for "database-name.ns" file'], ['For collection:\nMost of time collection is created when you insert something into it. So, if you are not creating the collection using createCollection() command and you are using the default ObjectId for _id key, then you can get a rough estimate of the creation of the collection by knowing the time at which the first document inserted in that collection.']], [[' ls -l test.ns\n-rw------- 1 root root 16777216 Jun 12 07:10 test.ns\n']], ['MongoDB - How to Determine Date Created for Dynamically Created DBs and Collections?'], 2, 0], [(17057129, 1), [['For collection:\nMost of time collection is created when you insert something into it. So, if you are not creating the collection using createCollection() command and you are using the default ObjectId for _id key, then you can get a rough estimate of the creation of the collection by knowing the time at which the first document inserted in that collection.'], ['-10000']], [[' Mongo > db.test.find().sort({$natural : 1}).limit(1).toArray()[0]._id.getTimestamp()\nISODate("2013-06-12T01:40:04Z")\n']], ['MongoDB - How to Determine Date Created for Dynamically Created DBs and Collections?'], 2, 0], [(17070859, 0), [["You have not given it as null, you're trying to insert an empty string ( '' ).  You need:"], ["Although really, if you're going to be inserting dates, best to insert them in YYYYMMDD format, as:"]], [[" INSERT INTO [ABC] ([code],[updatedate],[flag],[Mfdate]) \nVALUES ('203', '6/12/2013','N/A', NULL) \n"]], ['SQL Server inserting Date as 1/1/1900'], 2, 1], [(17070859, 1), [["Although really, if you're going to be inserting dates, best to insert them in YYYYMMDD format, as:"], ['-10000']], [[" INSERT INTO [ABC] ([code],[updatedate],[flag],[Mfdate]) \nVALUES ('203', '20130612','N/A', NULL) \n"]], ['SQL Server inserting Date as 1/1/1900'], 2, 1], [(17073134, 0), [['This should work:'], ['Or alternately:']], [[' WITH Sales AS (\n   SELECT\n      S.SaleID,\n      S.SoldBy,\n      S.SalePrice,\n      S.Margin,\n      S.Date,\n      I.SalePrice,\n      I.Category\n   FROM\n      dbo.Sale S\n      INNER JOIN dbo.SaleItem I\n         ON S.SaleID = I.SaleID\n)\nSELECT *\nFROM\n   Sales\n   PIVOT (Max(SalePrice) FOR Category IN (Books, Printing, DVD)) P\n;\n']], ['SQL server join tables and pivot'], 2, 1], [(17073134, 1), [['Or alternately:'], ['These have the same resultset and may in fact be treated the same by the query optimizer, but possibly not. The big difference comes into play when you start putting conditions on the  Sale  table--you should test and see which query works better.']], [[' SELECT\n   S.SaleID,\n   S.SoldBy,\n   S.SalePrice,\n   S.Margin,\n   S.Date,\n   I.Books,\n   I.Printing,\n   I.DVD\nFROM\n   dbo.Sale S\n   INNER JOIN (\n      SELECT *\n      FROM\n         (SELECT SaleID, SalePrice, Category FROM dbo.SaleItem) I\n         PIVOT (Max(SalePrice) FOR Category IN (Books, Printing, DVD)) P\n   ) I ON S.SaleID = I.SaleID\n;\n']], ['SQL server join tables and pivot'], 2, 1], [(17099089, 0), [['What about this'], ["I personally would have done the manipulation with a language like PHP before inserting it. Much easier. Anyway, Ok is this what you want? This should work providing your json format that is being added is in the format  {'key':'value'}"]], [[" UPDATE table SET table_field1 = CONCAT(table_field1,' This will be added.');\n"]], ['MySQL query to append key:value to JSON string'], 2, 1], [(17099089, 1), [["I personally would have done the manipulation with a language like PHP before inserting it. Much easier. Anyway, Ok is this what you want? This should work providing your json format that is being added is in the format  {'key':'value'}"], ['-10000']], [['  UPDATE table\n SET col = CONCAT_WS(",", SUBSTRING(col, 1, CHAR_LENGTH(col) - 1),SUBSTRING(\'newjson\', 2));\n']], ['MySQL query to append key:value to JSON string'], 2, 1], [(17099697, 0), [['You can do it using pivot and rank:'], ["If you are using GUIDs it's a little more tricky, you need to cast them to BINARY to use min():"]], [[' select StudentID, [1] as P1, [2] as P2, [3] as P3 from (\n  select StudentID, ParentID, RANK() over (PARTITION BY StudentID ORDER BY ParentID) as rnk\n  from STUDENT_PARENTS\n) ranked PIVOT (min(ParentID) for rnk in ([1], [2], [3])) as p\n']], ['Output multiple child record ids to one row'], 2, 1], [(17099697, 1), [["If you are using GUIDs it's a little more tricky, you need to cast them to BINARY to use min():"], ['SqlFiddle here:  http://sqlfiddle.com/#!3/8d0d7/14']], [[' select StudentID, \n    cast([1] as uniqueidentifier) as P1, \n    cast([2] as uniqueidentifier) as P2, \n    cast([3] as uniqueidentifier) as P3 \nfrom (\n  select StudentID, cast(ParentID as binary(16)) as ParentID, RANK() over (PARTITION BY StudentID ORDER BY StudentParentID) as rnk\n  from STUDENT_PARENTS\n) ranked PIVOT (min(ParentID) for rnk in ([1], [2], [3])) as p\n']], ['Output multiple child record ids to one row'], 2, 1], [(17102375, 0), [['How about something like'], ['I noted that the above might return more than 1 entry based on the data in your tables, so here is another example.']], [[' SELECT  m.username\nFROM    members m INNER JOIN\n    friends f   ON  m.id IN (f.user_id,f.friend_id)\nWHERE   m.id = $variable\n']], ["How do I use SQL's JOIN to select column A if column B = column C?"], 2, 1], [(17102375, 1), [['I noted that the above might return more than 1 entry based on the data in your tables, so here is another example.'], ['-10000']], [[' SELECT  m.username\nFROM \nmembers m\nWHERE m.id = 2    \nAND     EXISTS  (\n            SELECT  1 \n            FROM    friends f \n            WHERE m.id IN (f.user_id,f.friend_id)\n        )\n']], ["How do I use SQL's JOIN to select column A if column B = column C?"], 2, 1], [(17113532, 0), [['You probably want something like this:'], ['This will import from  /path/to/file/data_file.csv  into  databasename.tablename , with each complete line in the text file being imported into a new row in the table, with all the data from that line being put into the column called  column1 . More details  here .']], [[' LOAD DATA LOCAL INFILE \'/path/to/file/data_file.csv\'\n    IGNORE\n    INTO TABLE `databasename`.`tablename`\n    CHARACTER SET utf8\n    FIELDS\n        TERMINATED BY \'\\n\'\n        OPTIONALLY ENCLOSED BY \'"\'\n    IGNORE 1 LINES\n    (column1)\nSHOW WARNINGS;\n']], ['LOAD DATA INFILE into Single Field on MySQL'], 2, 1], [(17129510, 0), [['First of all sequencing table'], ['Your actual table']], [[' CREATE TABLE table1_seq \n  (id INT NOT NULL AUTO_INCREMENT PRIMARY KEY);\n']], ['reuse the auto inserted generated field in another field'], 6, 0], [(17129510, 1), [['Your actual table'], ['A trigger']], [[' CREATE TABLE Table1\n  (`id` INT NOT NULL DEFAULT 0, \n   `folio` VARCHAR(32)\n   ...\n  );\n']], ['reuse the auto inserted generated field in another field'], 6, 0], [(17129510, 3), [['Now you can insert a new record'], ["And you'll have in your table1"]], [[" INSERT INTO Table1 (`folio`, ...)\nVALUES ('a', ...), ('e', ...);\n"]], ['reuse the auto inserted generated field in another field'], 6, 0], [(17129510, 5), [['And then insert new records using this stored procedure'], ['Here is  SQLFiddle  demo for that.']], [[" CALL sp_table1_insert ('a',...);\nCALL sp_table1_insert ('e',...);\n"]], ['reuse the auto inserted generated field in another field'], 6, 0], [(17163648, 0), [['Here is an even better and efficient solution to the problem, '], ['RESULT LOGIC']], [[' SELECT A.ID,\nCOUNT(A.ID) AS COUNTED\nFROM tableA A\nLEFT JOIN TableB B\nON A.tableB_id=B.id\nLEFT JOIN holiday C\nON TRUNC(C.hdate) BETWEEN (TRUNC(a.date1) +1) AND TRUNC(B.date2)\nWHERE c.hdate IS NOT NULL\nGROUP BY A.ID;\n']], ['How to exclude holidays between two dates?'], 2, 1], [(17163648, 1), [['RESULT LOGIC'], ['-10000']], [[' trunc(date2) - trunc(date1) = x      \nx - result of the query\n']], ['How to exclude holidays between two dates?'], 2, 0], [(17255338, 0), [['Technically you can do that with dynamic SQL, but whether you have to proceed with this approach is very questionable.'], ['Now calling our procedure']], [[" DELIMITER $$\nCREATE PROCEDURE sp_select_not_empty(IN tbl_name VARCHAR(64))\nBEGIN\n    SET @sql = NULL, @cols = NULL;\n    SELECT\n      GROUP_CONCAT(\n        CONCAT(\n          'SELECT ''',\n          column_name,\n          ''' name, COUNT(NULLIF(',\n          column_name, ', ', \n          CASE WHEN data_type IN('int', 'decimal') THEN 0 WHEN data_type IN('varchar', 'char') THEN '''''' END,\n          ')) n FROM ',\n          tbl_name\n        )\n      SEPARATOR ' UNION ALL ') INTO @sql\n     FROM INFORMATION_SCHEMA.COLUMNS \n    WHERE table_name = tbl_name;\n\n    SET @sql = CONCAT(\n                 'SELECT GROUP_CONCAT(name) INTO @cols FROM (', \n                 @sql, \n                 ') q WHERE q.n > 0'\n               );\n    PREPARE stmt FROM @sql;\n    EXECUTE stmt;\n\n    SET @sql = CONCAT('SELECT ', @cols, ' FROM ', @tbl);\n    PREPARE stmt FROM @sql;\n    EXECUTE stmt;\n    DEALLOCATE PREPARE stmt;\nEND$$\nDELIMITER ;\n"]], ["escape entire column if all of that column's fields are null (or zero)"], 2, 1], [(17255338, 1), [['Now calling our procedure'], ['And we get']], [[" CALL sp_select_not_empty('Table1');\n"]], ["escape entire column if all of that column's fields are null (or zero)"], 2, 0], [(17265080, 0), [['default.properties'], ['default.properties_en']], [[' my.example.value=1\nmy.example.type=into\n']], ['Storing app preferences in Spring app'], 2, 0], [(17265080, 1), [['default.properties_en'], ['Db:\nKey=string(256)\nValue=string(2048)']], [[' my.example.title=Example Value\nmy.example.descruption=This is..\n']], ['Storing app preferences in Spring app'], 2, 0], [(17325149, 0), [['You need to use an additional subquery to find out what the minimum radius is per mechanic (where the radius is greater than the distance), and then you can join this back to your two tables and get all the column information you need from the two tables:'], ["If you don't actually want to know the radius of the selected zone, and the zone with the lowest radius will always have the lowest letter you can just use:"]], [[' SELECT  m.ID, mz.Zone, m.distance, mz.radius\nFROM    Mechanics m\n        INNER JOIN mechanic_zones mz\n            ON mz.Mechanic_ID = m.ID\n        INNER JOIN\n        (   SELECT  m.ID, \n                    MIN(mz.radius) AS radius\n            FROM    Mechanics m\n                    INNER JOIN mechanic_zones mz\n                        ON mz.Mechanic_ID = m.ID\n            WHERE   mz.radius > M.distance\n            GROUP BY m.ID\n        ) MinZone\n            ON MinZone.ID = m.ID\n            AND MinZone.radius= mz.radius\nORDER BY mz.Zone;\n']], ['SQL query get lowest value from related record, subquery'], 12, 1], [(17325149, 1), [["If you don't actually want to know the radius of the selected zone, and the zone with the lowest radius will always have the lowest letter you can just use:"], ['Your fiddle is very close to what I would use, but I would use the following so that the calculation is only done once:']], [[' SELECT  m.ID, mz.MinZone, m.distance\nFROM    Mechanics m\n        INNER JOIN\n        (   SELECT  m.ID, \n                    MIN(mz.Zone) AS Zone\n            FROM    Mechanics m\n                    INNER JOIN mechanic_zones mz\n                        ON mz.Mechanic_ID = m.ID\n            WHERE   mz.radius > M.distance\n            GROUP BY m.ID\n        ) MinZone\n            ON MinZone.ID = m.ID\nORDER BY MinZone.Zone;\n']], ['SQL query get lowest value from related record, subquery'], 12, 1], [(17325149, 2), [['Your fiddle is very close to what I would use, but I would use the following so that the calculation is only done once:'], ['The reasoning behind this that your query has columns in the select list and not in a group by, so there is no guarantee that the radius returned will be lowest one. For example if you change the order in which the records are inserted to mechanic_zones ( as in this fiddle ) you results become:']], [[' SELECT  m.id, m.name, m.distance, m.radius, m.zone\nFROM    (   SELECT  m.ID, \n                    m.Name,\n                    m.Distance,\n                    MIN(mz.radius) AS radius\n            FROM    (   SELECT  ID, Name, (1 * Distance) AS Distance\n                        FROM    Mechanics \n                    ) m\n                    INNER JOIN mechanic_zones mz\n                        ON mz.Mechanic_ID = m.ID\n            WHERE   mz.radius > M.distance\n            GROUP BY m.ID, m.Name, m.Distance\n        ) m\n        INNER JOIN  mechanic_zones mz\n            ON mz.Mechanic_ID = m.ID\n            AND mz.radius = m.radius;\n']], ['SQL query get lowest value from related record, subquery'], 12, 1], [(17325149, 3), [['The reasoning behind this that your query has columns in the select list and not in a group by, so there is no guarantee that the radius returned will be lowest one. For example if you change the order in which the records are inserted to mechanic_zones ( as in this fiddle ) you results become:'], ['Instead of ']], [[' ID  NAME    DTJ     RADIUS  ZONE\n1   Jon     2       10      a\n2   Paul    11      50      b\n3   George  5       5       a\n']], ['SQL query get lowest value from related record, subquery'], 12, 0], [(17325149, 4), [['Instead of '], ['Imagine the following simple table (T):']], [[' ID  NAME    DTJ     RADIUS  ZONE\n1   Jon     2       5       a\n2   Paul    11      20      b\n3   George  5       5       a\n']], ['SQL query get lowest value from related record, subquery'], 12, 0], [(17325149, 5), [['Imagine the following simple table (T):'], ['In MySQL you can write']], [[' ID  | Column1 | Column2  |\n----|---------+----------|\n1   |    A    |    X     |\n2   |    A    |    Y     |\n']], ['SQL query get lowest value from related record, subquery'], 12, 0], [(17325149, 6), [['In MySQL you can write'], ['This actually breaks the SQL Standard, but it works in MySQL, however the trouble is it is non-deterministic, the result:']], [[' SELECT  ID, Column1, Column2\nFROM    T\nGROUP BY Column1;\n']], ['SQL query get lowest value from related record, subquery'], 12, 0], [(17325149, 7), [['This actually breaks the SQL Standard, but it works in MySQL, however the trouble is it is non-deterministic, the result:'], ['Is no more or less correct than ']], [[' ID  | Column1 | Column2  |\n----|---------+----------|\n1   |    A    |    X     |\n']], ['SQL query get lowest value from related record, subquery'], 12, 0], [(17325149, 8), [['Is no more or less correct than '], ["So what you are saying is give me one row for each distinct value of  Column1 , which both results sets satisfy, so how do you know which one you will get? Well you don't, it seems to be a fairly popular misconception that you can add and  ORDER BY  clause to influence the results, so for example the following query:"]], [[' ID  | Column1 | Column2  |  \n----|---------+----------|\n2   |    A    |    Y     |\n']], ['SQL query get lowest value from related record, subquery'], 12, 0], [(17325149, 9), [["So what you are saying is give me one row for each distinct value of  Column1 , which both results sets satisfy, so how do you know which one you will get? Well you don't, it seems to be a fairly popular misconception that you can add and  ORDER BY  clause to influence the results, so for example the following query:"], ['Would ensure that you get the following result:']], [[' SELECT  ID, Column1, Column2\nFROM    T\nGROUP BY Column1\nORDER BY ID DESC;\n']], ['SQL query get lowest value from related record, subquery'], 12, 0], [(17325149, 10), [['Would ensure that you get the following result:'], ['The SQL-Standard does allow columns in the select list not contained in the GROUP BY or an aggregate function, however these columns must be functionally dependant on a column in the GROUP BY. For example, ID in the sample table is the PRIMARY KEY, so we know it is unique in the table, so the following query conforms to the SQL standard and would run in MySQL and fail in many DBMS currently (At the time of writing Postgresql is the closest DBMS I know of to correctly implementing the standard):']], [[' ID  | Column1 | Column2  |  \n----|---------+----------|\n2   |    A    |    Y     |\n']], ['SQL query get lowest value from related record, subquery'], 12, 0], [(17325149, 11), [['The SQL-Standard does allow columns in the select list not contained in the GROUP BY or an aggregate function, however these columns must be functionally dependant on a column in the GROUP BY. For example, ID in the sample table is the PRIMARY KEY, so we know it is unique in the table, so the following query conforms to the SQL standard and would run in MySQL and fail in many DBMS currently (At the time of writing Postgresql is the closest DBMS I know of to correctly implementing the standard):'], ['Since ID is unique for each row, there can only be one value of  Column1  for each ID, one value of  Column2  there is no ambiguity about what to return for each row.']], [[' SELECT  ID, Column1, Column2\nFROM    T\nGROUP BY ID;\n']], ['SQL query get lowest value from related record, subquery'], 12, 0], [(17340363, 1), [['After these 4 update commands, the col2 will have something like '], ['Then I wrote a function to split this thing. The reason I went for the function is to split by "$" and the fact that the col2 still has >10k characters']], [[' 1 1331882981,ab123456$1331890329,pqr123223\n2 1331882981,abc333$1331890329,pqrs23\n']], ['Replacing Text which does not match a pattern in Oracle'], 4, 0], [(17340363, 2), [['Then I wrote a function to split this thing. The reason I went for the function is to split by "$" and the fact that the col2 still has >10k characters'], ['I then called']], [[' create or replace function parse( p_clob in clob ) return sys.odciVarchar2List\npipelined\nas\n        l_offset number := 1;\n        l_clob   clob := translate( p_clob, chr(13)|| chr(10) || chr(9), \'   \' ) || \'$\';\n        l_hit    number;\nbegin\n        loop\n          --Find occurance of "$" from l_offset\n          l_hit := instr( l_clob, \'$\', l_offset );\n          exit when nvl(l_hit,0) = 0;\n          --Extract string from l_offset to l_hit\n          pipe row ( substr(l_clob, l_offset , (l_hit - l_offset)) );\n          --Move offset\n          l_offset := l_hit+1;\n        end loop;\nend;\n']], ['Replacing Text which does not match a pattern in Oracle'], 4, 0], [(17340363, 3), [['I then called'], ['-10000']], [[" select col1,\n       REGEXP_SUBSTR(column_value, '[^,]+', 1, 1) col3,\n       REGEXP_SUBSTR(column_value, '[^,]+', 1, 2) col4\n  from temp_table, table(parse(temp_table.col2));\n"]], ['Replacing Text which does not match a pattern in Oracle'], 4, 0], [(17352572, 0), [["First off, I  strongly  suggest you look into an alternative. This will get messy very fast, as you're essentially treating rows as columns. It doesn't help much that  Table1  is already denormalized - though if it really only has 3 columns, it's not that big of a deal to normalize it again.:"], ["Since there doesn't appear to be a canonical list of  ID  and  Category , we'll generate it:"]], [[' CREATE VIEW v_Table1 AS\n   SELECT Id, Code1 as Code FROM Table1\n   UNION SELECT Id, Code2 as Code FROM Table1\n   UNION SELECT Id, Code3 as Code FROM Table1\n']], ['SQL Server - Setting multiple columns from another table'], 6, 0], [(17352572, 1), [["Since there doesn't appear to be a canonical list of  ID  and  Category , we'll generate it:"], ['Getting the list of represented  ID  and  Category  is pretty straightforward:']], [[' CREATE VIEW v_AllCategories AS\n   SELECT DISTINCT ID, Category FROM v_Table1 CROSS JOIN Table2\n']], ['SQL Server - Setting multiple columns from another table'], 6, 0], [(17352572, 2), [['Getting the list of represented  ID  and  Category  is pretty straightforward:'], ['Put those together, and we can then get the bool to tell us which exists:']], [[' CREATE VIEW v_ReportedCategories AS\n   SELECT DISTINCT ID, Category FROM Table2 \n   JOIN v_Table1 ON Table2.Code = v_Table1.Code\n']], ['SQL Server - Setting multiple columns from another table'], 6, 0], [(17352572, 3), [['Put those together, and we can then get the bool to tell us which exists:'], ['That gets you your answer in a normalized form:']], [[' CREATE VIEW v_CategoryReports AS\n    SELECT\n       T1.ID, T1.Category, CASE WHEN T2.ID IS NULL THEN 0 ELSE 1 END as Reported\n    FROM v_AllCategories as T1\n    LEFT OUTER JOIN v_ReportedCategories as T2 ON\n       T1.ID = T2.ID\n       AND T1.Category = T2.Category\n']], ['SQL Server - Setting multiple columns from another table'], 6, 0], [(17352572, 4), [['That gets you your answer in a normalized form:'], ["From there, you'd need to do a  PIVOT  to get your  Category  values as columns:"]], [[' ID  | Category | Reported\n10  | cat1     | 1\n10  | cat2     | 1\n10  | cat3     | 0    \n']], ['SQL Server - Setting multiple columns from another table'], 6, 0], [(17352572, 5), [["From there, you'd need to do a  PIVOT  to get your  Category  values as columns:"], ["Since you mentioned over 50 'Categories', I'll assume they're not really 'cat1' - 'cat50'. In which case, you'll need to code gen the pivot operation."]], [[' SELECT\n    ID,\n    cat1,\n    cat2,\n    cat3\nFROM v_CategoryReports\nPIVOT (\n    MAX([Reported]) FOR Category IN ([cat1], [cat2], [cat3])\n) p\n']], ['SQL Server - Setting multiple columns from another table'], 6, 0], [(17524409, 0), [['-10000'], ['So your whole query could be:']], [[" WHERE language IN('x','y') GROUP BY emp_id HAVING COUNT (*) = 2 \n"]], ['Compare two sets in MySQL for equality'], 2, 0], [(17524409, 1), [['So your whole query could be:'], ['-10000']], [[" SELECT e.emp_Id\n     , e.Name\n  FROM Employee e\n  JOIN Employee_Language l\n    ON e.emp_id = l.emp_id\n WHERE l.Language IN('English', 'French')\n GROUP  \n    BY e.emp_id \nHAVING COUNT(*) = 2\n"]], ['Compare two sets in MySQL for equality'], 2, 1], [(17535389, 1), [['Result:'], ["Here's the data I used:"]], [[' +----+------------+-----------+----+----+----+\n| id | first_name | surname   | A1 | A2 | A3 |\n+----+------------+-----------+----+----+----+\n|  1 | john       | smith     | on |    |    |\n|  2 | david      | russel    | on | on |    |\n|  3 | james      | duncan    | on |    | on |\n|  4 | gavin      | dow       | on | on |    |\n+----+------------+-----------+----+----+----+\n']], ['MySQL create temporary fields with values from another table'], 3, 0], [(17535389, 2), [["Here's the data I used:"], ['-10000']], [[" --\n-- Table structure for table `a`\n--\n\nCREATE TABLE IF NOT EXISTS `a` (\n  `id` int(10) unsigned NOT NULL,\n  `first_name` varchar(32) NOT NULL,\n  `surname` varchar(32) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=MyISAM DEFAULT CHARSET=latin1;\n\n--\n-- Dumping data for table `a`\n--\n\nINSERT INTO `a` (`id`, `first_name`, `surname`) VALUES\n(1, 'john', 'smith'),\n(2, 'david', 'russel'),\n(3, 'james', 'duncan'),\n(4, 'gavin', 'dow');\n\n--\n-- Table structure for table `b`\n--\n\nCREATE TABLE IF NOT EXISTS `b` (\n  `id` int(10) unsigned NOT NULL,\n  `uid` int(10) unsigned NOT NULL,\n  `type` int(10) NOT NULL,\n  `status` varchar(32) NOT NULL,\n  PRIMARY KEY (`id`),\n  KEY `uid` (`uid`)\n) ENGINE=MyISAM DEFAULT CHARSET=latin1;\n\n--\n-- Dumping data for table `b`\n--\n\nINSERT INTO `b` (`id`, `uid`, `type`, `status`) VALUES\n(1, 1, 1, 'accepted'),\n(2, 2, 1, 'accepted'),\n(3, 2, 2, 'accepted'),\n(4, 4, 1, 'accepted'),\n(5, 4, 2, 'accepted'),\n(6, 4, 3, 'declined'),\n(7, 3, 1, 'accepted'),\n(8, 3, 2, 'declined'),\n(9, 1, 2, 'declined'),\n(10, 3, 3, 'accepted');\n"]], ['MySQL create temporary fields with values from another table'], 3, 0], [(17558290, 1), [['You should have an index on  ambienceName , and then all three lookups will be more efficient.'], ['Yes, but you have to join one more time to get the full set of ambiences for the film:']], [[' ALTER TABLE Ambiences ADD KEY (ambienceName);\n']], ['Performing a simple search in MySQL db with variable amount of input'], 6, 0], [(17558290, 2), [['Yes, but you have to join one more time to get the full set of ambiences for the film:'], ['-10000']], [[' SELECT f.*, GROUP_CONCAT(a_all.ambienceName) AS ambiences\nFROM Films AS f \nINNER JOIN Films_Ambiences as fa1 ON f.id = fa1.film_id           \nINNER JOIN Ambiences AS a1 ON a1.id = fa1.ambience_id\nINNER JOIN Films_Ambiences as fa2 ON f.id = fa2.film_id           \nINNER JOIN Ambiences AS a2 ON a2.id = fa2.ambience_id\nINNER JOIN Films_Ambiences as fa3 ON f.id = fa3.film_id           \nINNER JOIN Ambiences AS a3 ON a3.id = fa3.ambience_id\nINNER JOIN Films_Ambiences AS fa_all ON f.id = fa_all.film_id\nINNER JOIN Ambiences AS a_all ON a_all.id = fa_all.ambience_id\nWHERE (a1.ambienceName, a2.ambienceName, a3.ambienceName) = (?, ?, ?)\nGROUP BY f.id;\n']], ['Performing a simple search in MySQL db with variable amount of input'], 6, 0], [(17558290, 3), [['-10000'], ["By the way, here's the EXPLAIN showing usage of indexes:"]], [[" mysql> INSERT INTO Ambiences (ambienceName) \n VALUES ('funny'), ('scary'), ('1950s'), ('London'), ('bank'), ('crime'), ('stupid');\nmysql> INSERT INTO Films (title) \n VALUES ('Mary Poppins'), ('Heist'), ('Scary Movie'), ('Godzilla'), ('Signs');\nmysql> INSERT INTO Films_Ambiences \n VALUES (1,1),(1,2),(1,4),(1,5), (2,1),(2,2),(2,5),(2,6), (3,1),(3,2),(3,7), (4,2),(4,3), (5,2),(5,7);\n\nmysql> SELECT f.*, GROUP_CONCAT(a_all.ambienceName) AS ambiences \n FROM Films AS f  \n INNER JOIN Films_Ambiences as fa1 ON f.id = fa1.film_id            \n INNER JOIN Ambiences AS a1 ON a1.id = fa1.ambience_id \n INNER JOIN Films_Ambiences as fa2 ON f.id = fa2.film_id            \n INNER JOIN Ambiences AS a2 ON a2.id = fa2.ambience_id \n INNER JOIN Films_Ambiences as fa3 ON f.id = fa3.film_id            \n INNER JOIN Ambiences AS a3 ON a3.id = fa3.ambience_id \n INNER JOIN Films_Ambiences AS fa_all ON f.id = fa_all.film_id \n INNER JOIN Ambiences AS a_all ON a_all.id = fa_all.ambience_id \n WHERE (a1.ambienceName, a2.ambienceName, a3.ambienceName) = ('funny','scary','bank') \n GROUP BY f.id;\n+----+--------------+-------------------------+\n| id | Title        | ambiences               |\n+----+--------------+-------------------------+\n|  1 | Mary Poppins | funny,scary,London,bank |\n|  2 | Heist        | funny,scary,bank,crime  |\n+----+--------------+-------------------------+\n"]], ['Performing a simple search in MySQL db with variable amount of input'], 6, 0], [(17558290, 4), [["By the way, here's the EXPLAIN showing usage of indexes:"], ['-10000']], [[' +----+-------------+--------+--------+----------------------+--------------+---------+-----------------------------+------+-----------------------------------------------------------+\n| id | select_type | table  | type   | possible_keys        | key          | key_len | ref                         | rows | Extra                                                     |\n+----+-------------+--------+--------+----------------------+--------------+---------+-----------------------------+------+-----------------------------------------------------------+\n|  1 | SIMPLE      | a1     | ref    | PRIMARY,ambienceName | ambienceName | 258     | const                       |    1 | Using where; Using index; Using temporary; Using filesort |\n|  1 | SIMPLE      | a2     | ref    | PRIMARY,ambienceName | ambienceName | 258     | const                       |    1 | Using where; Using index                                  |\n|  1 | SIMPLE      | a3     | ref    | PRIMARY,ambienceName | ambienceName | 258     | const                       |    1 | Using where; Using index                                  |\n|  1 | SIMPLE      | fa1    | ref    | PRIMARY,ambience_id  | ambience_id  | 4       | test.a1.id                  |    1 | Using index                                               |\n|  1 | SIMPLE      | f      | eq_ref | PRIMARY              | PRIMARY      | 4       | test.fa1.film_id            |    1 | NULL                                                      |\n|  1 | SIMPLE      | fa2    | eq_ref | PRIMARY,ambience_id  | PRIMARY      | 8       | test.fa1.film_id,test.a2.id |    1 | Using index                                               |\n|  1 | SIMPLE      | fa3    | eq_ref | PRIMARY,ambience_id  | PRIMARY      | 8       | test.fa1.film_id,test.a3.id |    1 | Using index                                               |\n|  1 | SIMPLE      | fa_all | ref    | PRIMARY,ambience_id  | PRIMARY      | 4       | test.fa1.film_id            |    1 | Using index                                               |\n|  1 | SIMPLE      | a_all  | eq_ref | PRIMARY              | PRIMARY      | 4       | test.fa_all.ambience_id     |    1 | NULL                                                      |\n+----+-------------+--------+--------+----------------------+--------------+---------+-----------------------------+------+-----------------------------------------------------------+\n']], ['Performing a simple search in MySQL db with variable amount of input'], 6, 0], [(17566573, 0), [['Use  STR_TO_DATE()  function to convert String to Date like this:'], ['And use  MONTH()  to get month number from the date like this:']], [[" SELECT STR_TO_DATE('Apr','%b')\n"]], ['Convert month shortname to month number'], 2, 1], [(17566573, 1), [['And use  MONTH()  to get month number from the date like this:'], ['-10000']], [[" SELECT MONTH(STR_TO_DATE('Apr','%b'))\n"]], ['Convert month shortname to month number'], 2, 1], [(17596708, 0), [['Add a unique constraint to AllowedColors. (And consider dropping the column "ID".)'], ['Now you can use that pair of columns as the target of a foreign key constraint.']], [[' alter table AllowedColors\nadd constraint your_constraint_name\nunique (FamilyID, ColorID);\n']], ['SQL Restrict Column values using another Table'], 2, 0], [(17596708, 1), [['Now you can use that pair of columns as the target of a foreign key constraint.'], ["You'll also want a foreign key from AllowedColors.FamilyID to Family.FamilyID."]], [[' alter table fruit\nadd constraint another_constraint_name\nforeign key (FamilyID, ColorID) \n  references AllowedColors (FamilyID, ColorID);\n']], ['SQL Restrict Column values using another Table'], 2, 0], [(17598953, 0), [['You could write a function doing the work in a single call. this should work in  Postgres 8.3 :'], ['Call:']], [[' CREATE OR REPLACE FUNCTION foo(_pct int)\n  RETURNS SETOF v_t AS\n$func$\nDECLARE\n   _ct     int := (SELECT count(*) FROM v_t);\n   _offset int := (_ct * $1) / 100;\n   _limit  int := (_ct * (100 - 2 * $1)) / 100;\nBEGIN\n\nRETURN QUERY\nSELECT *\nFROM   v_t\nOFFSET _offset\nLIMIT  _limit;\n\nEND\n$func$ LANGUAGE plpgsql;\n']], ['postgresql: select non-outliers from view'], 2, 1], [(17598953, 1), [['Call:'], ['This actually crops 5% from top  and  bottom.']], [[' SELECT * FROM foo(5)\n']], ['postgresql: select non-outliers from view'], 2, 0], [(17665628, 1), [['This will give you something like this:'], ['Which should be easy to display in whatever your front end is.']], [[' RowType         DPSF0010001     DPSF0010002     DPSF0010003     DPSF0010004     DPSF0010005     DPSF0010006     DPSF0010007     DPSF0010008     DPSF0010009     DPSF0010010     DPSF0010011     DPSF0010012     DPSF0010013     DPSF0010014     DPSF0010015\nColumn Head     Total:          Under 5 years   5 to 9 years    10 to 14 years  15 to 19 years  20 to 24 years  25 to 29 years  30 to 34 years  35 to 39 years  40 to 44 years  45 to 49 years  50 to 54 years  55 to 59 years  60 to 64 years  65 to 69 years\nColumn Value    4973            139             266             437             391             146             100             78              141             253             425             491             501             477             382\n']], ['alias column name by lookup query'], 2, 0], [(17670284, 0), [['You can use a strongly typed cursor and its rowtype:'], ['UPDATE : you can easily wrap the cursor and function inside a PL/SQL package:']], [[" -- example data\ncreate table t1(pk number not null primary key, val varchar2(30));\ncreate table t2(\n  pk number not null primary key, \n  t1_fk references t1(pk), \n  val varchar2(30));\n\ninsert into t1(pk, val) values(1, 'value1');\ninsert into t2(pk, t1_fk, val) values(1, 1, 'value2a');\ninsert into t2(pk, t1_fk, val) values(2, 1, 'value2b');\n\ndeclare\n  cursor cur is \n  select t1.*, t2.val as t2_val \n  from t1\n  join t2 on t1.pk = t2.t1_fk;\n\n  function get_data(arg in pls_integer) return cur%rowtype is\n      l_result cur%rowtype;\n    begin\n      select t1.*, t2.val as t2_val \n        into l_result \n        from t1 \n        join t2 on t1.pk = t2.t1_fk\n        where t2.pk = arg;\n      return l_result;\n    end;\nbegin\n  dbms_output.put_line(get_data(2).t2_val);\nend;\n"]], ['How to return record from an Oracle function with JOIN query?'], 2, 1], [(17670284, 1), [['UPDATE : you can easily wrap the cursor and function inside a PL/SQL package:'], ['(package body omitted)']], [[' create or replace package pkg_get_data as \n\n  cursor cur is \n  select t1.*, t2.val as t2_val \n  from t1\n  join t2 on t1.pk = t2.t1_fk;\n\n  function get_data(arg in pls_integer) return cur%rowtype;\nend;\n']], ['How to return record from an Oracle function with JOIN query?'], 2, 0], [(17703008, 0), [['-10000'], ['if you have your letters on two columns (say col1 and col2) you should first union them in a single one and do the count afterwards, like this:']], [[' SELECT count(letter) occurences,\n       letter\nFROM table\nGROUP BY letter\nORDER BY letter ASC\n']], ['Counting with SQL'], 2, 1], [(17703008, 1), [['if you have your letters on two columns (say col1 and col2) you should first union them in a single one and do the count afterwards, like this:'], ['the inner SELECT query appends the content of col2 to col1 and renames the resulting column to "letter". The outer select, counts the occurrences of each letter in this resulting column.']], [[' SELECT count(letter) occurences,\n       letter\nFROM (SELECT col1 letter\n      FROM table\n      UNION \n      SELECT col2 letter\n      FROM table)\nGROUP BY letter \nORDER BY letter;\n']], ['Counting with SQL'], 2, 1], [(17703863, 0), [['I have also updated the answer in the  original question , but never-mind, here is a copy also:'], ['After finding a performance issues with first query, here is an improved version. Going from top-to-bottom, instead of other way around - eliminating creating of extra rows in CTE, should be much faster on high number of recursions:']], [[' ;WITH RCTE AS\n(\n    SELECT  ParentId, ChildId, 1 AS Lvl FROM RelationHierarchy \n\n    UNION ALL\n\n    SELECT rh.ParentId, rc.ChildId, Lvl+1 AS Lvl \n    FROM dbo.RelationHierarchy rh\n    INNER JOIN RCTE rc ON rh.ChildId = rc.ParentId\n)\n,CTE_RN AS \n(\n    SELECT *, ROW_NUMBER() OVER (PARTITION BY r.ChildID ORDER BY r.Lvl DESC) RN\n    FROM RCTE r\n\n)\nSELECT pc.Id AS ChildID, pc.Name AS ChildName, r.ParentId, pp.Name AS ParentName\nFROM dbo.Person pc \nLEFT JOIN CTE_RN r ON pc.id = r.CHildId AND  RN =1\nLEFT JOIN dbo.Person pp ON pp.id = r.ParentId\n']], ['Finding Top level parent of each row of a table [SQL Server 2008]'], 2, 1], [(17703863, 1), [['After finding a performance issues with first query, here is an improved version. Going from top-to-bottom, instead of other way around - eliminating creating of extra rows in CTE, should be much faster on high number of recursions:'], ['SQLFiddle DEMO']], [[' ;WITH RCTE AS\n(\n    SELECT  ParentId, CHildId, 1 AS Lvl FROM RelationHierarchy r1\n    WHERE NOT EXISTS (SELECT * FROM RelationHierarchy r2 WHERE r2.CHildId = r1.ParentId)\n\n    UNION ALL\n\n    SELECT rc.ParentId, rh.CHildId, Lvl+1 AS Lvl \n    FROM dbo.RelationHierarchy rh\n    INNER JOIN RCTE rc ON rc.CHildId = rh.ParentId\n)\nSELECT pc.Id AS ChildID, pc.Name AS ChildName, r.ParentId, pp.Name AS ParentName\nFROM dbo.Person pc \nLEFT JOIN RCTE r ON pc.id = r.CHildId\nLEFT JOIN dbo.Person pp ON pp.id = r.ParentId \n']], ['Finding Top level parent of each row of a table [SQL Server 2008]'], 2, 1], [(17707945, 0), [['You can use binary  and  and string concatenation:'], ['If you are allergic to  case  statements, you could do this:']], [[" select (case when test&4 > 0 then '1' else '0' end) +\n       (case when test&2 > 0 then '1' else '0' end) +\n       (case when test&1 > 0 then '1' else '0' end)\nfrom (select 6 as test) t;\n"]], ["SQL - Find the binary representation from the place of '1's"], 2, 1], [(17707945, 1), [['If you are allergic to  case  statements, you could do this:'], ['-10000']], [[' select CHAR(ascii(0) + (test&4)/4) +\n       CHAR(ascii(0) + (test&2)/2) +\n       CHAR(ascii(0) + (test&1)/1)\nfrom (select 6 as test) t\n']], ["SQL - Find the binary representation from the place of '1's"], 2, 1], [(17750801, 0), [['http://dev.mysql.com/doc/refman/5.6/en/string-functions.html#function_find-in-set'], ["You can use @MikeChristensen's answer to be more standard.  Another trick with standard SQL is this:"]], [[' SELECT ...\nWHERE FIND_IN_SET(5, list_column)\n']], ['Check if mysql field contains a certain number in mysql query'], 3, 1], [(17750801, 1), [["You can use @MikeChristensen's answer to be more standard.  Another trick with standard SQL is this:"], ['Another MySQL-specific solution is to use a special word-boundary regular expression, which will match either the comma punctuation or beginning/end of string:']], [[" select * from TableName\nwhere ',' || ids || ',' LIKE '%,5,%'\n"]], ['Check if mysql field contains a certain number in mysql query'], 3, 1], [(17750801, 2), [['Another MySQL-specific solution is to use a special word-boundary regular expression, which will match either the comma punctuation or beginning/end of string:'], ["None of these solutions scale well; they all cause table-scans.  Sorry I understand you cannot change the database design, but if your project next requires to make the query faster, you can tell them it's not possible without redesigning the table."]], [[" select * from TableName\nwhere ids RLIKE '[[:<:]]5[[:>:]]'\n"]], ['Check if mysql field contains a certain number in mysql query'], 3, 1], [(17769111, 1), [['if then you need return the  ID  to the application do:    '], ['-10000']], [[' SELECT @Scope_Ident\n']], ['How to insert data into a table and get value of a column'], 2, 0], [(17810221, 0), [['-10000'], ['or']], [[' Select Min(Date) \nfrom #DATEDATA\nWhere Date>=@WeekendDate\n']], ['SQL - return records on the fist date where records exist'], 2, 1], [(17810221, 1), [['or'], ['-10000']], [[' Select * from #DATEDATA\nwhere Date=\n(\nSelect Min(Date) \nfrom #DATEDATA\nWhere Date>=@WeekendDate\n)\n']], ['SQL - return records on the fist date where records exist'], 2, 1], [(17828198, 0), [['Your database schema is not completely clear to me, but it seems you can link tourists from the  Tourist  table to their extra charges in the  EXTRA_CHARGES  table via the  Tourist_Extra_Charges  table like this:'], ["If you want to be able to filter on  Reservation_ID , you'll have to join the tables  Tourist_Reservations  and  Reservations  as well, like this:"]], [[' SELECT  T.Tourist_ID\n        ,T.Tourist_Name\n        ,EC.Extra_Charge_ID\n        ,EC.Extra_Charge_Description\nFROM    Tourist AS T\nINNER JOIN Tourist_Extra_Charges AS TEC ON T.Tourist_ID= TEC.Tourist_ID\nINNER JOIN EXTRA_CHARGES AS EC ON TEC.Extra_Charge_ID = EC.Extra_Charge_ID;\n']], ['Sql subquery with inner join'], 2, 1], [(17828198, 1), [["If you want to be able to filter on  Reservation_ID , you'll have to join the tables  Tourist_Reservations  and  Reservations  as well, like this:"], ['As for your database schema: please note that the field  Extra_Charge_ID  is not necessary in your  Tourist  table: you already link tourists to extra charges via the  Tourist_Extra_Charges  table. It can be dangerous to the sanity of your data to make these kind of double connections.']], [[' SELECT  T.Tourist_ID\n        ,T.Tourist_Name\n        ,EC.Extra_Charge_ID\n        ,EC.Extra_Charge_Description\nFROM    Tourist AS T\nINNER JOIN Tourist_Extra_Charges AS TEC ON T.Tourist_ID= TEC.Tourist_ID\nINNER JOIN EXTRA_CHARGES AS EC ON TEC.Extra_Charge_ID = EC.Extra_Charge_ID\nINNER JOIN Tourist_Reservations AS TR ON T.Tourist_ID = TR.Tourist_ID\nINNER JOIN Reservations AS R ON TR.Reservation_ID = R.Reservation_ID\nWHERE   R.Reservation_ID = 27;\n']], ['Sql subquery with inner join'], 2, 1], [(17833022, 0), [['Try this:'], ['In fact, instead of storing the column total in the database, you could just create a view:']], [[' update cartable set total = stage_1 + stage_2\n']], ['Do arithmatic inside database. Is this possible?'], 2, 1], [(17833022, 1), [['In fact, instead of storing the column total in the database, you could just create a view:'], ['-10000']], [[' create view carview as \n       select Car, state_1, stage_2, stage_1 + stage_2 as total\n       from cartable\n']], ['Do arithmatic inside database. Is this possible?'], 2, 1], [(17851492, 0), [['Join both tables with month:'], ['Result:']], [[' SELECT MONTH(I.date) AS `month`\n     , COUNT(I.ID) AS `countin`\n     , COUNT(O.ID) AS `countOUT`\n  FROM TableIN I\n LEFT JOIN TableOUT O\n    ON MONTH(I.Date) = MONTH(O.Date)\n GROUP BY MONTH(I.date)\nUNION\nSELECT MONTH(O.date) AS `month`\n     , COUNT(I.ID) AS `countin`\n     , COUNT(O.ID) AS `countOUT`\n  FROM TableIN I\n RIGHT JOIN TableOUT O\n    ON MONTH(I.Date) = MONTH(O.Date)\n GROUP BY MONTH(I.date);\n']], ['Getting count from 2 table and group by month'], 3, 1], [(17851492, 1), [['Result:'], ['-10000']], [[' | MONTH | COUNTIN | COUNTOUT |\n------------------------------\n|     5 |       1 |        1 |\n|     7 |       1 |        1 |\n|     6 |       0 |        1 |\n']], ['Getting count from 2 table and group by month'], 3, 0], [(17851492, 2), [['-10000'], ['-10000']], [[' SELECT * FROM\n(\n    SELECT MONTH(I.date) AS `month`\n         , COUNT(I.ID) AS `countin`\n         , COUNT(O.ID) AS `countOUT`\n      FROM TableIN I\n     LEFT JOIN TableOUT O\n        ON MONTH(I.Date) = MONTH(O.Date)\n     GROUP BY MONTH(I.date)\n    UNION\n    SELECT MONTH(O.date) AS `month`\n         , COUNT(I.ID) AS `countin`\n         , COUNT(O.ID) AS `countOUT`\n      FROM TableIN I\n     RIGHT JOIN TableOUT O\n        ON MONTH(I.Date) = MONTH(O.Date)\n     GROUP BY MONTH(I.date)\n    ) tbl\nORDER BY Month;\n']], ['Getting count from 2 table and group by month'], 3, 1], [(17875720, 0), [['Something like the following may be what you are after:'], ['Update \nThe critical part here is getting the lastchange subquery correct, i.e. using all the columns that describe the relation between tbl_hardware_assignment and tbl_accounts']], [[" SELECT tbl_hardware.HW_ID,\n       tbl_hardware.Aktiv,\n       tbl_hardware.typebradmodelID,\n       typebradmodel.Type,\n       typebradmodel.Brand,\n       typebradmodel.Model,\n       lastentry.Login,\n       lastentry.since\nFROM (SELECT\n        tbl_typebradmodel.typebradmodelID,\n        tbl_type.tabel AS Type,\n        tbl_brand.tabel AS Brand,\n        tbl_model.tabel AS Model\n    FROM tbl_typebradmodel\n    LEFT OUTER JOIN tbl_type ON tbl_typebradmodel.TypID = tbl_type.TypID\n    LEFT OUTER JOIN tbl_brand ON tbl_typebradmodel.MarkeID = tbl_brand.MarkeID\n    LEFT OUTER JOIN tbl_model ON tbl_typebradmodel.ModelID = tbl_model.ModelID\n    ) typebradmodel\nLEFT JOIN tbl_hardware ON tbl_hardware.typebradmodelID = typebradmodel.typebradmodelID\nLEFT JOIN      \n    (SELECT \n        MAX(tbl_hardware_assignment.since) AS lastchange, \n        tbl_hardware_assignment.HW_ID,\n        tbl_accounts.Login\n    FROM tbl_hardware_assignment\n    LEFT OUTER JOIN tbl_accounts ON tbl_hardware_assignment.namenID = tbl_accounts.PersID\n    GROUP BY tbl_hardware_assignment.HW_ID,tbl_accounts.Login ) lastentry ON tbl_hardware.HW_ID = lastentry.HW_ID\nWHERE tbl_hardware.Aktiv = 1 AND \n    typebradmodel.Brand LIKE 'Samsung' AND\n    lastentry.Login = 'MY_USERNAME'\n"]], ['SQL Joining 4 Tables'], 2, 1], [(17890157, 0), [['If you know already that you only have two values for the week, you could use this query:'], ['but if the number of weeks is not known, you should use a dynamic query, like this:']], [[' SELECT\n  CodeID,\n  MAX(CASE WHEN Week=1 THEN ItemID END) Week1,\n  MAX(CASE WHEN Week=2 THEN ItemID END) Week2\nFROM\n  yourtable\nGROUP BY\n  CodeID\n']], ['mysql show db column in multiple returned columns'], 3, 1], [(17890157, 1), [['but if the number of weeks is not known, you should use a dynamic query, like this:'], ['If there are multiple items in the same week, you could use GROUP_CONCAT aggregated function instead of MAX:']], [[" SELECT\n  CONCAT(\n    'SELECT CodeID,',\n    GROUP_CONCAT(\n      DISTINCT\n      CONCAT('MAX(CASE WHEN Week=', Week, ' THEN ItemID END) Week', Week)),\n    ' FROM yourtable GROUP BY CodeID;')\nFROM\n  yourtable\nINTO @sql;\n\nPREPARE stmt FROM @sql;\nEXECUTE stmt;\n"]], ['mysql show db column in multiple returned columns'], 3, 1], [(17890157, 2), [['If there are multiple items in the same week, you could use GROUP_CONCAT aggregated function instead of MAX:'], ['-10000']], [[' SELECT\n  CodeID,\n  GROUP_CONCAT(DISTINCT CASE WHEN Week=1 THEN ItemID END) Week1,\n  GROUP_CONCAT(DISTINCT CASE WHEN Week=2 THEN ItemID END) Week2\nFROM\n  yourtable\nGROUP BY\n  CodeID;\n']], ['mysql show db column in multiple returned columns'], 3, 1], [(17910415, 0), [['If you want it to detect the package detail for a given user and you want to use REPLACE, you must make the userid the primary key.'], ["First we add the user's first package:"]], [[' CREATE TABLE userpackages (\n  userid INT PRIMARY KEY,\n  package_detail TEXT,\n  FOREIGN KEY (userid) REFERENCES users(userid)\n);\n']], ['using where clause in REPLACE statment'], 3, 0], [(17910415, 1), [["First we add the user's first package:"], ['Next we change the package for user 1234:']], [[" REPLACE INTO userpackages (userid, package_detail) \nVALUES (1234, 'some package');\n"]], ['using where clause in REPLACE statment'], 3, 0], [(17910415, 2), [['Next we change the package for user 1234:'], ["If userid isn't your primary key, then REPLACE isn't going to work."]], [[" REPLACE INTO userpackages (userid, package_detail) \nVALUES (1234, 'some other package');\n"]], ['using where clause in REPLACE statment'], 3, 0], [(17925232, 0), [['So, the answer to your question is that your need a method in one model, and invoke it through the block, and then, pass the data in this way:\nblock:'], ['And then you can retrieve it in your phtml like this:']], [[" class Mynamespace_Mymodule_Block_Myblock extends Mage_Core_Block_Template\n{\n    public function getMyProductData()\n    {\n        $product = Mage::getModel('catalog/product')->load($id);\n        return $product;    \n    }\n} \n"]], ['How to put data from the database to the template'], 2, 0], [(17925232, 1), [['And then you can retrieve it in your phtml like this:'], ['Greetings from México :D']], [[' $_product = $this->getMyProductData();\necho $_product->getName();\n']], ['How to put data from the database to the template'], 2, 0], [(18001322, 0), [['try this'], ['EDIT2:']], [["     INSERT INTO msMenu (column1, column2 , column3)\n    SELECT  COALESCE( MAX( menuId ) , 0 ) +1 ,'My Menu', '1'  \n    FROM msMenu;\n"]], ['User Defined Variable in MySQL Insert Query'], 2, 1], [(18001322, 1), [['EDIT2:'], ['-10000']], [["  SET @newId = (select COALESCE( MAX( menuId ) , 0 ) +1 from msMenu)\n INSERT INTO msMenu (column1, column2 , column3)\n SELECT  @newId ,'My Menu', '1'  \n FROM msMenu;\n"]], ['User Defined Variable in MySQL Insert Query'], 2, 1], [(18020825, 0), [["Your current  SET  doesn't even work. When you have a  valid  datetime value coming in from a string literal, you can do this:"], ['Result:']], [[" DECLARE @adddate DATETIME;\n\nSET @adddate = '2011-07-06T22:30:07.521';\n\nSELECT CONVERT(CHAR(11), @adddate, 103) \n  + LTRIM(RIGHT(CONVERT(CHAR(20), @adddate, 22), 11));\n"]], ['Convert datetime to MM/dd/yyyy HH:MM:SS AM/PM'], 4, 1], [(18020825, 1), [['Result:'], ['If you actually want m/d/y (your question is ambiguous), there is a slightly shorter path using style 22:']], [[' 06/07/2011 10:30:07 PM\n']], ['Convert datetime to MM/dd/yyyy HH:MM:SS AM/PM'], 4, 0], [(18020825, 2), [['If you actually want m/d/y (your question is ambiguous), there is a slightly shorter path using style 22:'], ['Result:']], [[" DECLARE @adddate DATETIME;\n\nSET @adddate = '2011-07-06T22:30:07.521';\n\nSELECT STUFF(CONVERT(CHAR(20), @adddate, 22), 7, 2, YEAR(@adddate));\n"]], ['Convert datetime to MM/dd/yyyy HH:MM:SS AM/PM'], 4, 1], [(18020825, 3), [['Result:'], ['However, this is a bad idea for two reasons:']], [[' 07/06/2011 10:30:07 PM\n']], ['Convert datetime to MM/dd/yyyy HH:MM:SS AM/PM'], 4, 0], [(18105224, 0), [['You can make it a little more compact by not forcing the dashes, and using  STUFF  instead of  SUBSTRING :'], ['Results:']], [[" DECLARE @Var VARCHAR(100) = '20130120161643730';\n\nSET @Var = LEFT(@Var, 8) + ' ' \n  + STUFF(STUFF(STUFF(RIGHT(@Var, 9),3,0,':'),6,0,':'),9,0,'.');\n\nSELECT [string] = @Var, [datetime] = CONVERT(DATETIME, @Var);\n"]], ['Convert varchar data to datetime in SQL server when source data is w/o format'], 2, 1], [(18105224, 1), [['Results:'], ['-10000']], [[' string                  datetime\n---------------------   -----------------------\n20130120 16:16:43.730   2013-01-20 16:16:43.730\n']], ['Convert varchar data to datetime in SQL server when source data is w/o format'], 2, 0], [(18107553, 0), [["You should consider storing the lookup in a new table... but just so you're aware of your options, you can also use the  DATENAME(WEEKDAY)  function:"], ['Returns:']], [[' SELECT DATENAME(WEEKDAY, 0)\n']], ['How to replace an int with text in a query'], 2, 1], [(18107553, 1), [['Returns:'], ['SQL Fiddle']], [[' Monday\n']], ['How to replace an int with text in a query'], 2, 0], [(18111896, 0), [['Something pretty basic could be'], ['or using  OUTER APPLY  (it should be faster)']], [[" SELECT MT.Date, MT.Text, \n       CASE WHEN MT.Text = 'bbb' THEN Number\n            ELSE (SELECT TOP 1 Number \n                               FROM MyTable MT2 \n                               WHERE MT2.Date < MT.Date AND \n                                     MT2.Text = 'bbb'\n                               ORDER BY MT2.Date DESC)\n            END Number,\n       CASE WHEN MT.Text = 'bbb' THEN Number2\n            ELSE (SELECT TOP 1 Number2 \n                               FROM MyTable MT2 \n                               WHERE MT2.Date < MT.Date AND \n                                     MT2.Text = 'bbb'\n                               ORDER BY MT2.Date DESC)\n            END Number2 \n       FROM MyTable MT\n"]], ['Filling in missing data'], 2, 1], [(18111896, 1), [['or using  OUTER APPLY  (it should be faster)'], ['SQLFiddle:  http://sqlfiddle.com/#!3/cbee5/7']], [[" SELECT MT.Date, MT.Text, \n       CASE WHEN MT.Text = 'bbb' THEN MT.Number\n            ELSE MT2.Number \n            END Number,\n       CASE WHEN MT.Text = 'bbb' THEN MT.Number2\n            ELSE MT2.Number2\n            END Number2\n       FROM MyTable MT\n       OUTER APPLY (SELECT TOP 1 MT2.Number, MT2.Number2 \n                                 FROM MyTable MT2\n                                 WHERE MT.Text <> 'bbb' AND \n                                       MT2.Text = 'bbb' AND \n                                       MT2.Date < MT.Date\n                                 ORDER BY MT2.Date DESC\n                   ) MT2\n"]], ['Filling in missing data'], 2, 1], [(18146788, 1), [['Just extract all values with same XQuery:\n( SQLFiddle )'], ['-10000']], [[' with params as (\n  select \n    xmltype(\'\n      <ALFA>\n        <BETA>0123</BETA>\n        <GAMMA>2345</GAMMA>\n        <DELTA>\n           <EPSILON>3</EPSILON>\n        </DELTA>\n      </ALFA>\n    \') p_xml\n  from dual  \n)    \nselect\n  element_path, element_text\nfrom\n  XMLTable(\n    \'              \n      for $i in $doc/descendant-or-self::*\n        return <element>\n                 <element_path> {$i/string-join(ancestor-or-self::*/name(.), \'\'/\'\')} </element_path>\n                 <element_content> {$i/text()}</element_content>\n               </element>  \n    \'\n    passing (select p_xml from params) as "doc"\n    columns \n      element_path   varchar2(4000) path \'//element_path\',\n      element_text   varchar2(4000) path \'//element_content\'\n  )\n']], ['From XML to list of paths in Oracle PL/SQL environment'], 2, 1], [(18186212, 0), [['While i waited for an answer i found the following solutions:'], ['OR']], [['     "set define off" and using \\.\n']], ['How to escape the "." reserved symbol when using an input for an sql script'], 2, 1], [(18186212, 1), [['OR'], ['And turning the properties to its default value after using them. I ended up using Nicholas Krasnov\'s solution of using a "&1..TABLEX" because it didnt require any property change. Thank you!']], [['     "set escape ON" and using .\n']], ['How to escape the "." reserved symbol when using an input for an sql script'], 2, 1], [(18187989, 0), [['To get the latest row in MySQL, you need to use a  join  or correlated subquery:'], ['For the biggest id:']], [[' SELECT id, user_receiver, user_sender, post_id, action, date, is_read\nFROM notification n\nWHERE user_receiver=$ses_user and\n      date = (select max(date)\n              from notification n2\n              where n2.user_sender = n.user_sender and\n                    n2.action = n.action and\n                    n2.post_id = n.post_id and\n                    n2.is_read = n.is_read\n             )\norder by date desc;\n']], ['Query to get only one row from multiple rows having same values'], 3, 1], [(18187989, 1), [['For the biggest id:'], ['If you want the number of rows where  isread = 1 , then you can do something like:']], [[' SELECT id, user_receiver, user_sender, post_id, action, date, is_read\nFROM notification n\nWHERE user_receiver=$ses_user and\n      id   = (select max(id)\n              from notification n2\n              where n2.user_sender = n.user_sender and\n                    n2.action = n.action and\n                    n2.post_id = n.post_id\n             )\norder by date desc;\n']], ['Query to get only one row from multiple rows having same values'], 3, 1], [(18187989, 2), [['If you want the number of rows where  isread = 1 , then you can do something like:'], ['-10000']], [[' SELECT sum(is_read = 1)\nFROM notification n\nWHERE user_receiver=$ses_user and\n      id   = (select max(id)\n              from notification n2\n              where n2.user_sender = n.user_sender and\n                    n2.action = n.action and\n                    n2.post_id = n.post_id\n             );\n']], ['Query to get only one row from multiple rows having same values'], 3, 1], [(18251762, 0), [['if you are allowed to use CTE:'], ["as t-clausen.dk suggested in comments, you don't even need value inside the CTE:"]], [[' with cte as (\n    select\n        row_number() over(partition by Value order by Value) as row_num,\n        Value\n    from Table1\n)\ndelete from cte where row_num > 1\n']], ['Remove duplicates if you have only one column with value'], 2, 1], [(18251762, 1), [["as t-clausen.dk suggested in comments, you don't even need value inside the CTE:"], ['-10000']], [[' with cte as (\n    select\n        row_number() over(partition by Value order by Value) as row_num\n    from Table1\n)\ndelete from cte where row_num > 1;\n']], ['Remove duplicates if you have only one column with value'], 2, 1], [(18277282, 0), [['I think this is most easily done with a correlated subquery:'], ['If this assumption is not true and the transaction ids are in ascending order, you can use:']], [[' select t.*,\n       datediff((select t2.TransactionDate\n                 from t t2\n                 where t2.CustomerId = t.CustomerId and\n                       t2.TransactionDate < t.TransactionDate\n                 order by t2.TransactionDate desc\n                 limit 1\n                ), t.TransactionDate) as daysSinceLastPurchase\nfrom t;\n']], ['Time Since Last Purchase'], 2, 1], [(18289563, 1), [['If you want just a "sample" of them:'], ['-10000']], [[" select postid\nfrom (select postid\n      from post_tags\n      where find_in_set(tagid, @LIST) > 0\n      group by postid\n      having count(distinct tagid) = 1+length(@LIST) - length(replace(',', @LIST, ''))\n     ) t\norder by rand()\nlimit 5\n"]], ['How to retrieve samples from the database?'], 2, 1], [(18320028, 0), [['What you have is pretty close:'], ['Or more usefully:']], [[" select owner, object_name\nfrom all_objects\nwhere object_type = 'TRIGGER'\n"]], ['Get the names of all Triggers currently in the database via SQL statement (Oracle SQL Developer)'], 2, 1], [(18320028, 1), [['Or more usefully:'], ['all_triggers  has other columns to give you more information that  all_objects  does, like when the trigger fires. You can get more information about this and other useful data dictionary view  in the documentation .']], [[' select owner, trigger_name, table_owner, table_name, triggering_event\nfrom all_triggers\n']], ['Get the names of all Triggers currently in the database via SQL statement (Oracle SQL Developer)'], 2, 1], [(18359263, 0), [['Here is an example using  create table as  syntax:'], ['To assign a data type, use  cast()  or  convert()  to get the type you want:']], [[" CREATE TABLE NEW_TBL AS\n    SELECT Col1, Col2, Col3, 'Newcol' as Col4\n    FROM OLD_TBL;\n"]], ['Copying Data from one table into another and simultaneously add another column'], 3, 1], [(18359263, 1), [['To assign a data type, use  cast()  or  convert()  to get the type you want:'], ['By the way, you can also add the column directly to the old table:']], [[" CREATE TABLE NEW_TBL AS\n    SELECT Col1, Col2, Col3, cast('Newcol' as varchar(255) as Col4,\n           cast(123 as decimal(18, 2)) as col4\n    FROM OLD_TBL;\n"]], ['Copying Data from one table into another and simultaneously add another column'], 3, 1], [(18359263, 2), [['By the way, you can also add the column directly to the old table:'], ['You can then update the value there, if you wish.']], [[' alter table old_tbl add col4 varchar(255);\n']], ['Copying Data from one table into another and simultaneously add another column'], 3, 0], [(18377746, 0), [['Try'], ['Now, having a clear description of what you want, I can provide you with the desired  UPDATE  statement:']], [[" UPDATE ifns_code INNER JOIN\n( SELECT name n, REPLACE(fio,'**!!!**</img>','**???**</img>') f FROM ifns_code ) t ON n=name\nSET ifns_code.fio=REPLACE(REPLACE(f,'**!!!**',code),'**???**',name)\n"]], ['Change/Update part of string in MySQL'], 2, 1], [(18377746, 1), [['Now, having a clear description of what you want, I can provide you with the desired  UPDATE  statement:'], ['see here for a live demo:  http://sqlfiddle.com/#!8/3c1a4/1']], [[' UPDATE ifns_code INNER JOIN (\n  SELECT name n,instr(fio,\'Profile/\') i,instr(fio,\'"><img\') j FROM ifns_code \n) tbl ON n=name \nSET fio=CONCAT(substring(fio,1,i+7),\n               \'lrm" title="LRM (1641)\',\n               substring(fio,j))\nWHERE name IN (\'3303\',\'5007\',\'5004\')\n']], ['Change/Update part of string in MySQL'], 2, 1], [(18404055, 0), [['With the new binary JSON data type  jsonb , Postgres 9.4 introduced  largely improved index options . You can now have a GIN index on a  jsonb  array directly:'], ['No need for a function to convert the array. This would support a query:']], [[' CREATE TABLE tracks (id serial, artists <b>jsonb</b>);\nCREATE INDEX tracks_artists_gin_idx ON tracks USING gin (artists);']], ['Index for finding an element in a JSON array'], 11, 1], [(18404055, 1), [['No need for a function to convert the array. This would support a query:'], ['Or  you use the  more specialized, non-default GIN operator class  jsonb_path_ops  for the index:']], [[' SELECT * FROM tracks WHERE artists @> \'[{"name": "The Dirty Heads"}]\';\n']], ['Index for finding an element in a JSON array'], 11, 0], [(18404055, 2), [['Or  you use the  more specialized, non-default GIN operator class  jsonb_path_ops  for the index:'], ['Note the difference between JSON objects and primitive types:']], [[' CREATE INDEX tracks_artists_gin_idx ON tracks\nUSING  gin (artists <b>jsonb_path_ops</b>);']], ['Index for finding an element in a JSON array'], 11, 1], [(18404055, 7), [['jsonb_path_ops  currently only supports indexing the  @>  operator. \nThere are more index options,  details in the manual .'], ['Create this  functional  index :']], [[" CREATE OR REPLACE FUNCTION json2arr(_j json, _key text)\n  RETURNS text[] LANGUAGE sql IMMUTABLE AS\n'SELECT ARRAY(SELECT elem->>_key FROM json_array_elements(_j) elem)';\n"]], ['Index for finding an element in a JSON array'], 11, 0], [(18404055, 10), [['Updated with feedback in comments. We need to use  array operators  to support the GIN index. \nThe  "is contained by" operator  <@  in this case.'], ['Functional indexes only work with  IMMUTABLE  functions.']], [[" SELECT p.proname, p.provolatile\nFROM   pg_proc p\nJOIN   pg_namespace n ON n.oid = p.pronamespace\nWHERE  n.nspname = 'pg_catalog'\nAND    p.proname ~~* '%json%';\n"]], ['Index for finding an element in a JSON array'], 11, 0], [(18410600, 0), [['-10000'], ['-10000']], [['Current price per item for each vendor SELECT DISTINCT ON (p.item_id, p.vendor_id)\n       i.title, p.price, p.vendor_id\nFROM   prices p\nJOIN   items  i ON i.id = p.item_id\nORDER  BY p.item_id, p.vendor_id, p.created_at DESC;\n']], ['Selecting the most recent, lowest price from multiple vendors for an inventory item'], 2, 0], [(18410600, 1), [['-10000'], ['->SQLfiddle demo']], [['Optimal vendor for each item SELECT DISTINCT ON (item_id) \n       i.title, p.price, p.vendor_id -- add more columns as you need\nFROM (\n   SELECT DISTINCT ON (item_id, vendor_id)\n          item_id, price, vendor_id -- add more columns as you need\n   FROM   prices p\n   ORDER  BY item_id, vendor_id, created_at DESC\n   ) p\nJOIN   items i ON i.id = p.item_id\nORDER  BY item_id, price;\n']], ['Selecting the most recent, lowest price from multiple vendors for an inventory item'], 2, 1], [(18415438, 0), [['Try this query:'], ["In case if you don't know Locations, you can try this dynamic query:"]], [[' SELECT ITEM\n  ,SUM(CASE WHEN LOCATION = 001 THEN QUANTITY ELSE 0 END) AS Location_001\n  ,SUM(CASE WHEN LOCATION = 002 THEN QUANTITY ELSE 0 END) AS Location_002\n  ,SUM(CASE WHEN LOCATION = 003 THEN QUANTITY ELSE 0 END) AS Location_003\n  ,SUM(Quantity) AS Total\nFROM Table1\nGROUP BY ITEM;\n']], ['SQL Query Sum and total of rows'], 3, 1], [(18415438, 1), [["In case if you don't know Locations, you can try this dynamic query:"], ['Result:']], [[" SET @sql = NULL;\nSELECT\n  GROUP_CONCAT(DISTINCT\n    CONCAT(\n      'SUM(CASE WHEN `LOCATION` = ''',\n      `LOCATION`,\n      ''' THEN QUANTITY ELSE 0 END) AS `',\n      `LOCATION`, '`'\n    )\n  ) INTO @sql\nFROM Table1;\n\nSET @sql = CONCAT('SELECT ITEM, ', @sql,'\n                     ,SUM(Quantity) AS Total \n                     FROM Table1\n                    GROUP BY ITEM\n                  ');\n\nPREPARE stmt FROM @sql;\nEXECUTE stmt;\nDEALLOCATE PREPARE stmt;\n"]], ['SQL Query Sum and total of rows'], 3, 1], [(18415438, 2), [['Result:'], ['See  this SQLFiddle']], [[' |     ITEM | 1 | 2 | 3 | TOTAL |\n|----------|---|---|---|-------|\n| BLUE CAR | 0 | 2 | 5 |     7 |\n|  RED CAR | 3 | 8 | 0 |    11 |\n']], ['SQL Query Sum and total of rows'], 3, 0], [(18420123, 0), [['This seems to do it:'], ['Here is the same with better performance and also considering different customers:']], [[' library(data.table)\nset.seed(50)\nDT <- data.table(NETSALES=ifelse(runif(40)<.15,0,runif(40,1,100)), cust=rep(1:2, each=20), dt=1:20)\nDT[,dir:=ifelse(NETSALES>0,1,0)]\ndir.rle <- rle(DT$dir)\nDT <- transform(DT, indexer = rep(1:length(dir.rle$lengths), dir.rle$lengths))\nDT[,runl:=cumsum(dir),by=indexer]\n']], ['Count preceding rows that match criteria'], 2, 1], [(18420123, 1), [['Here is the same with better performance and also considering different customers:'], ['-10000']], [[' #no need for ifelse\nDT[,dir:= NETSALES>0]\n\n#use a function to avoid storing the rle, which could be huge\nrunseq <- function(x) {\n  x.rle <- rle(x)\n  rep(1:length(x.rle$lengths), x.rle$lengths)\n}\n\n#never use transform with data.table\nDT[,indexer := runseq(dir)]\n\n#include cust in by\nDT[,runl:=cumsum(dir),by=list(indexer,cust)]\n']], ['Count preceding rows that match criteria'], 2, 1], [(18477582, 1), [['Now, you might want to go a step further.  You can rename the old table and have the view take the name of the old table:'], ['That way, everything that references  table  will start using the view with the new column name.']], [[' rename table `table` to `old_table`;\ncreate view t as\n    select t.*, `old` as `new`\n    from `old_table` t;\n']], ['One column, two names, mysql'], 2, 0], [(18486580, 0), [['You can use the analytic version of  COUNT()  in a nested query, e.g.:'], ['You can also replace  rownum  with the analytic  ROW_NUMBER()  function:']], [[" SELECT * FROM\n(\n  SELECT table_name,\n    COUNT(*) OVER() AS numberofrows\n  FROM all_tables\n  WHERE owner = 'SYS'\n  ORDER BY table_name\n)\nWHERE rownum < 10;\n"]], ['Oracle - calculate number of rows before some condition is applied'], 2, 1], [(18486580, 1), [['You can also replace  rownum  with the analytic  ROW_NUMBER()  function:'], ['-10000']], [[" SELECT table_name, cnt FROM\n(\n  SELECT table_name,\n    COUNT(*) OVER () AS numberofrows,\n    ROW_NUMBER() OVER (ORDER BY table_name) AS rn\n  FROM all_tables\n  WHERE owner = 'SYS'\n)\nWHERE rn < 10;\n"]], ['Oracle - calculate number of rows before some condition is applied'], 2, 1], [(18499562, 0), [['OPENROWSET:'], ['OPENDATASOURCE:']], [[" SELECT *\nFROM OPENROWSET('SQLNCLI',\n   'DRIVER={SQL Server};SERVER=MyServer;UID=MyUserID;PWD=MyCleverPassword',\n   'select @@ServerName') \n"]], ["Connecting to a SQL Server through another Sever connection that's not linked"], 2, 1], [(18499562, 1), [['OPENDATASOURCE:'], ['-10000']], [[" SELECT * \nFROM OPENDATASOURCE ('SQLNCLI', -- or SQLNCLI\n   'Data Source=OtherServer\\InstanceName;Catalog=RemoteDB;User ID=SQLLogin;Password=Secret;').RemoteDB.dbo.SomeTable\n"]], ["Connecting to a SQL Server through another Sever connection that's not linked"], 2, 1], [(18513029, 0), [['You want to move your expression into the  select  clause:'], ['You can also do this as a  join  query with aggregation:']], [[' SELECT i.*,\n       (SELECT count(*) AS points \n        FROM `amenities_index` ai\n        WHERE amenity_id in (1, 2) AND\n              ai.item_id = i.id\n       ) as points\nFROM items i\nORDER BY points desc;\n']], ['MySQL order by points from 2nd table'], 2, 1], [(18513029, 1), [['You can also do this as a  join  query with aggregation:'], ['In most databases, I would prefer this version over the first one.  However, MySQL would allow the first in a view but not the second, so it has some strange limitations under some circumstances.']], [[' SELECT i.*, ai.points\nFROM items i join\n     (select ai.item_id, count(*) as points\n      from amenities_index ai\n      where amenity_id in (1, 2)\n     ) ai\n     on ai.item_id = i.id\nORDER BY ai.points desc;\n']], ['MySQL order by points from 2nd table'], 2, 1], [(18534648, 0), [['I assume that you want to assign  row_number()  based on the ordering, because the analytic functions do not "order" tables.  Did you try this?'], ['You could also do this without analytic functions at all:']], [[' SELECT empno, ename, deptno,\n       row_number() over (ORDER BY DECODE (deptno, NULL, 0, 2, 1, 3) as seqnum\nFROM emp ;\n']], ['Custom ordering using Analytical Functions'], 2, 1], [(18547311, 0), [['I assume that you have a DimDate table with the following structure:'], ['Solution:']], [[' CREATE TABLE DimDate\n(\nDateKey INT PRIMARY KEY\n);\n']], ['Complex rolling scenario (CROSS APPLY and OUTER APPLY example)'], 4, 0], [(18547311, 1), [['Solution:'], ['Edit #1:']], [[' DECLARE @NumDays INT = 3;\n\nWITH    basic_cte AS\n        (\n            SELECT  x.DateKey,\n                    d.Name,\n                    Amount = ISNULL(f.Amount,0)\n            FROM    \n            (\n                SELECT  t.*, CONVERT(INT,CONVERT(CHAR(8),CONVERT(DATETIME,CONVERT(DATETIME,CONVERT(CHAR(8),t.LiveKey,112))+@NumDays),112)) AS EndLiveKey\n                FROM    #target t\n            ) d \n            CROSS APPLY\n            (\n                SELECT  dm.DateKey\n                FROM    DimDate dm\n                WHERE   dm.DateKey >= d.LiveKey \n                AND     dm.DateKey < d.EndLiveKey           \n            ) x\n            LEFT OUTER JOIN #Fact f \n            ON f.PlayerKey = d.PlayerKey \n            AND f.DateKey = x.DateKey\n        )\nSELECT  rn = ROW_NUMBER() OVER(PARTITION BY Name ORDER BY DateKey),\n        y.*,\n        "RollingAmount" = SUM(Amount) OVER(PARTITION BY Name ORDER BY DateKey)\nFROM    basic_cte y;\n']], ['Complex rolling scenario (CROSS APPLY and OUTER APPLY example)'], 4, 1], [(18547311, 2), [['Edit #1:'], ['Edit #2:  ']], [[' DECLARE @NumDays INT = 3;\n\nWITH    basic_cte AS\n        (\n            SELECT  rn = ROW_NUMBER() OVER(PARTITION BY Name ORDER BY x.DateKey),\n                    x.DateKey,\n                    d.Name,\n                    Amount      = ISNULL(f.Amount,0),\n                    AmountAll   = ISNULL(fall.AmountAll,0)\n            FROM    \n            (\n                SELECT  t.*, CONVERT(INT,CONVERT(CHAR(8),CONVERT(DATETIME,CONVERT(DATETIME,CONVERT(CHAR(8),t.LiveKey,112))+@NumDays),112)) AS EndLiveKey\n                FROM    #target t\n            ) d \n            CROSS APPLY\n            (\n                SELECT  dm.DateKey\n                FROM    DimDate dm\n                WHERE   dm.DateKey >= d.LiveKey \n                AND     dm.DateKey < d.EndLiveKey           \n            ) x\n            OUTER APPLY\n            (\n                SELECT  SUM(fct.Amount) AS Amount\n                FROM    #Fact fct \n                WHERE   fct.DateKey = x.DateKey\n                AND     fct.PlayerKey = d.PlayerKey\n            ) f\n            OUTER APPLY\n            (\n                SELECT  SUM(fct.Amount) AS AmountAll \n                FROM    #Fact fct \n                WHERE   fct.DateKey = x.DateKey\n            ) fall\n        )\nSELECT  \n        y.*,\n        "RollingAmount"     = SUM(Amount) OVER(PARTITION BY Name ORDER BY DateKey),\n        "RollingAmountAll"  = SUM(AmountAll) OVER(PARTITION BY Name ORDER BY DateKey)\nFROM    basic_cte y;\n']], ['Complex rolling scenario (CROSS APPLY and OUTER APPLY example)'], 4, 1], [(18547311, 3), [['Edit #2:  '], ['-10000']], [[' DECLARE @NumDays INT = 3;\n\nWITH    basic_cte AS\n        (\n            SELECT  rn = ROW_NUMBER() OVER(PARTITION BY Name ORDER BY x.DateKey),\n                    x.DateKey,\n                    d.Name,\n                    Amount      = ISNULL(f.Amount,0),\n                    AmountAll   = ISNULL(f.AmountAll,0)\n            FROM    \n            (\n                SELECT  t.*, EndLiveKey = CONVERT(INT,CONVERT(CHAR(8),CONVERT(DATETIME,CONVERT(DATETIME,CONVERT(CHAR(8),t.LiveKey,112))+@NumDays),112))\n                FROM    #target t\n            ) d \n            CROSS APPLY\n            (\n                SELECT  dm.DateKey\n                FROM    DimDate dm\n                WHERE   dm.DateKey >= d.LiveKey \n                AND     dm.DateKey < d.EndLiveKey           \n            ) x\n            OUTER APPLY\n            (\n                SELECT  AmountAll   = SUM(fbase.Amount),\n                        Amount      = SUM(CASE WHEN PlayerKey1 = PlayerKey2 THEN fbase.Amount END)\n                FROM\n                (\n                    SELECT  fct.Amount, fct.PlayerKey AS PlayerKey1, d.PlayerKey AS PlayerKey2\n                    FROM    #Fact fct \n                    WHERE   fct.DateKey = x.DateKey\n                ) fbase\n            ) f\n        )\nSELECT  \n        y.*,\n        "RollingAmount"     = SUM(Amount) OVER(PARTITION BY Name ORDER BY DateKey),\n        "RollingAmountAll"  = SUM(AmountAll) OVER(PARTITION BY Name ORDER BY DateKey)\nFROM    basic_cte y;\n']], ['Complex rolling scenario (CROSS APPLY and OUTER APPLY example)'], 4, 1], [(18570414, 0), [["First you'll need to alter how the parameter is defined in the  CREATE PROCEDURE  definition, for example:"], ['Then change your  WHERE  clause to use the variable:']], [[' CREATE PROCEDURE prac\n(\n   @d_date in DATE\n)\n']], ['how to pass parameter to procedure and call in where clause'], 2, 0], [(18570414, 1), [['Then change your  WHERE  clause to use the variable:'], ['-10000']], [['  where glb_date= @d_date;\n']], ['how to pass parameter to procedure and call in where clause'], 2, 0], [(18575984, 0), [['This one will do what you want, but you have to specify all the dates'], ['You can create a dynamic SQL for this, something like this:']], [[" select\n   c.Name,\n   max(case when t.DateCreated = '2013-08-26' then c.Value end) as [2013-08-26],\n   max(case when t.DateCreated = '2013-08-27' then c.Value end) as [2013-08-27],\n   max(case when t.DateCreated = '2013-08-28' then c.Value end) as [2013-08-28],\n   max(case when t.DateCreated = '2013-08-29' then c.Value end) as [2013-08-29],\n   max(case when t.DateCreated = '2013-08-30' then c.Value end) as [2013-08-30],\n   max(case when t.DateCreated = '2013-08-31' then c.Value end) as [2013-08-31],\n   max(case when t.DateCreated = '2013-09-01' then c.Value end) as [2013-09-01]\nfrom test as t\n   outer apply (\n       select 'Rands', Rands union all\n       select 'Units', Units union all\n       select 'Average Price', [Average Price] union all\n       select 'Success %', [Success %] union all\n       select 'Unique Users', [Unique Users]\n   ) as C(Name, Value)\ngroup by c.Name\n"]], ['Pivot a fixed multiple column table in sql server'], 2, 1], [(18575984, 1), [['You can create a dynamic SQL for this, something like this:'], ['-10000']], [[" declare @stmt nvarchar(max)\n\nselect @stmt = isnull(@stmt + ',', '') + \n    'max(case when t.DateCreated = ''' + convert(nvarchar(8), t.DateCreated, 112) + ''' then c.Value end) as [' + convert(nvarchar(8), t.DateCreated, 112) + ']'\nfrom test as t\n\nselect @stmt = '\n   select\n       c.Name, ' + @stmt + ' from test as t\n   outer apply (\n       select ''Rands'', Rands union all\n       select ''Units'', Units union all\n       select ''Average Price'', [Average Price] union all\n       select ''Success %'', [Success %] union all\n       select ''Unique Users'', [Unique Users]\n   ) as C(Name, Value)\n   group by c.Name'\n\nexec sp_executesql @stmt = @stmt\n"]], ['Pivot a fixed multiple column table in sql server'], 2, 1], [(18613117, 0), [['Then combine the two with  UNION ALL :'], ['Then pick one column of the entire result that you want to order by.\n(The column names of the result come from the first query.)\nIn this case, the  Start  column is not part of the result, so we have to add it (and the  Date  column is duplicated in the second query, but this is necessary for its values to end up in the result column that is used for sorting):']], [[' SELECT alpha, beeta, gamma, Remark, id,   number FROM X\nUNION ALL\nSELECT Type,  Date,  gamma, Obs,    NULL, number FROM Y\n']], ['Sorting data from two different sorted cursors data of different tables into One'], 2, 0], [(18613117, 1), [['Then pick one column of the entire result that you want to order by.\n(The column names of the result come from the first query.)\nIn this case, the  Start  column is not part of the result, so we have to add it (and the  Date  column is duplicated in the second query, but this is necessary for its values to end up in the result column that is used for sorting):'], ['-10000']], [[' SELECT alpha, beeta, gamma, Remark, id,   number, Start AS SortThis FROM X\nUNION ALL\nSELECT Type,  Date,  gamma, Obs,    NULL, number, Date              FROM Y\nORDER BY SortThis\n']], ['Sorting data from two different sorted cursors data of different tables into One'], 2, 0], [(18619973, 1), [['UPDATE'], ['will get the startDate for the earliest term.']], [[' SELECT min(termStartDate)startDate FROM (\n    SELECT termStartDate \n        FROM @terms \n        GROUP BY termStartDate \n        HAVING termStartDate>=DATEADD(d,-360,@today) \n               AND termStartDate<=GETDATE()\n)z\n']], ['Date a year from now and check what is the next Term from that Date'], 2, 1], [(18629310, 0), [['Reverse the sting and search for the index of the first  \\ . Then get the right of your column using this index.'], ['If you want to turn File_1.70837292036d41139fcf8fa6b4997d3c.pdf to File_1.pdf then you could try the following, though it might look uggly:']], [[" SELECT RIGHT(Filename,PATINDEX('%\\%',REVERSE(Filename))-1)\n"]], ['Split string with proper format'], 2, 1], [(18629310, 1), [['If you want to turn File_1.70837292036d41139fcf8fa6b4997d3c.pdf to File_1.pdf then you could try the following, though it might look uggly:'], ['-10000']], [[" SELECT \nLEFT\n(\n    RIGHT\n    (\n        Filepath,\n        CASE WHEN PATINDEX('%\\%',REVERSE(Filepath)) > 0 \n        THEN PATINDEX('%\\%',REVERSE(Filepath))-1 \n        ELSE LEN(Filepath) \n        END \n    ),\n    CASE WHEN \n    PATINDEX\n    (\n        '%.%',\n        RIGHT\n        (\n            Filepath,\n            CASE WHEN PATINDEX('%\\%',REVERSE(Filepath)) > 0 \n            THEN PATINDEX('%\\%',REVERSE(Filepath))-1 \n            ELSE LEN(Filepath)  \n            END\n        )\n    )>0\n    THEN\n    PATINDEX\n    (\n        '%.%',\n        RIGHT\n        (\n            Filepath,\n            CASE WHEN PATINDEX('%\\%',REVERSE(Filepath)) > 0 \n            THEN PATINDEX('%\\%',REVERSE(Filepath))-1 \n            ELSE LEN(Filepath)  \n            END\n        )\n    )-1\n    ELSE 0 END\n)\n+\nRIGHT\n(\n    Filepath,\n    CASE WHEN PATINDEX('%.%',REVERSE(Filepath)) > 0 \n    THEN PATINDEX('%.%',REVERSE(Filepath)) \n    ELSE LEN(Filepath)  \n    END\n)\n"]], ['Split string with proper format'], 2, 1], [(18644056, 1), [['If you want to count students who got A in history, B in maths and E in Geography:'], ['-10000']], [[" select count(*)\nfrom Table1\nwhere [History] = 'A' and [Maths] = 'B' and [Geography] = 'E'\n"]], ['multiple count conditions with single query'], 2, 1], [(18651768, 1), [['or '], ['Note that you have to turn on the ad hoc distributed queries option:']], [[' OPENROWSET\n']], ['How to select data from another sql server server tables in sql script?'], 3, 0], [(18651768, 2), [['Note that you have to turn on the ad hoc distributed queries option:'], ['-10000']], [[" sp_configure 'show advanced options', 1;\nRECONFIGURE;\nsp_configure 'Ad Hoc Distributed Queries', 1;\nRECONFIGURE;\nGO\n"]], ['How to select data from another sql server server tables in sql script?'], 3, 0], [(18669731, 0), [["First, the answer is no, but if you'll change it to:"], ["Second, it's not clear from your question how is the table constructed. If it's something like:"]], [[" SELECT * FROM keywords WHERE column_name LIKE '%?%'\n"]], ['Keyword search using query'], 3, 1], [(18669731, 1), [["Second, it's not clear from your question how is the table constructed. If it's something like:"], ["then the answer I wrote in before won't work and the design is not good and should be replaced with one keyword per row. Another approach would be to query the table as follows:"]], [['  -----------------------------------------------------\n|column1 |column2 |column3 |column4 |column5 |column6 |\n -----------------------------------------------------\n|blablaa1|blablaa2|blablaa3|blablaa4|blabla?5|blablaa6|\n -----------------------------------------------------\n...\n']], ['Keyword search using query'], 3, 0], [(18669731, 2), [["then the answer I wrote in before won't work and the design is not good and should be replaced with one keyword per row. Another approach would be to query the table as follows:"], ["but, as I just mentioned, this is NOT a good way to construct your table and you'd better think how to re-design it for better performance & maintenance."]], [[" SELECT * FROM keywords WHERE column1 LIKE '%?%' OR \ncolumn2 LIKE '%?%' OR \ncolumn3 LIKE '%?%' OR \n...\n"]], ['Keyword search using query'], 3, 1], [(18708680, 0), [['In the datastep where I clean the names for matching, I create the following pattern:'], ['Then I do my sql join like this:']], [[" pattern = cats('/\\b(',substr(upcase(first_name),1,1),'|',upcase(first_name),').?\\s?',upcase(last_name),'\\b/');\n"]], ['Efficiently joining/merging based on matching part of a string'], 2, 0], [(18708680, 1), [['Then I do my sql join like this:'], ['Being able to compile the regex once per name in B, and then run it on each piece of text in A seems to be dramatically faster than a couple of index statements (not sure about the case of a regex vs a single index).']], [[' proc sql noprint;\ncreate table matched as\n  select  B.*, \n          prxparse(B.pattern) as prxm, \n          A.* \n  from  search_text as A,\n        search_names as B\n  where prxmatch(calculated prxm,A.notes)\n  order by A.id;\nquit;\nrun;\n']], ['Efficiently joining/merging based on matching part of a string'], 2, 0], [(18724492, 0), [['Point 1 : To get a list of rows that do not have the same  pid  as other rows, you would need to do a query before your update. For example:'], ["For example, the following code creates a temporary table called  badpids  that contains all  pid s that appear multiple times in the  orders  table. Then, we execute the  UPDATE , but only for rows that don't have a  pid  in the list of  badpids :"]], [[' SELECT id FROM `order` \nWHERE pid NOT IN (\n   SELECT pid FROM `order`\n   GROUP BY pid\n   HAVING COUNT(*) > 1\n)\n']], ['Deleting database existing record while asigning values from one row to other with unique values'], 2, 0], [(18724492, 1), [["For example, the following code creates a temporary table called  badpids  that contains all  pid s that appear multiple times in the  orders  table. Then, we execute the  UPDATE , but only for rows that don't have a  pid  in the list of  badpids :"], ['-10000']], [[' CREATE TEMPORARY TABLE badpids (pid int);\n\nINSERT INTO badpids\n   SELECT pid FROM `order`\n   GROUP BY pid\n   HAVING COUNT(*) > 1;\n\nUPDATE `order` SET cid = 1\nWHERE cid= 2 \nAND pid NOT IN (SELECT pid FROM badpids);\n']], ['Deleting database existing record while asigning values from one row to other with unique values'], 2, 1], [(18737626, 0), [['using this table structure:'], ['You can perform this query']], [[" CREATE TABLE Fruits (Id INT PRIMARY KEY auto_increment, Title VARCHAR(63), Colour VARCHAR(63));\n\nINSERT INTO Fruits (Title, Colour)\n  SELECT 'Apple', 'Green'\n  UNION ALL\n  SELECT 'Apple', 'Green'\n  UNION ALL\n  SELECT 'Apple', 'Blue'\n  UNION\n  SELECT 'Orange', 'Yellow'\n  UNION ALL\n  SELECT 'Orange', 'Yellow';\n"]], ['SQL: selecting things ONLY associated with one value'], 2, 0], [(18747853, 0), [['To get all birthdays in next 7 days, add the year difference between the date of birth and today to the date of birth and then find if it falls within next seven days. '], ["If you want to exclude today's birthdays just change  >  to  >=  "]], [[' SELECT * \nFROM  persons \nWHERE  DATE_ADD(birthday, \n                INTERVAL YEAR(CURDATE())-YEAR(birthday)\n                         + IF(DAYOFYEAR(CURDATE()) > DAYOFYEAR(birthday),1,0)\n                YEAR)  \n            BETWEEN CURDATE() AND DATE_ADD(CURDATE(), INTERVAL 7 DAY);\n']], ['mySQL SELECT upcoming birthdays'], 2, 1], [(18747853, 1), [["If you want to exclude today's birthdays just change  >  to  >=  "], ['Here is a  DEMO  of all queries']], [[" SELECT * \nFROM  persons \nWHERE  DATE_ADD(birthday, \n                INTERVAL YEAR(CURDATE())-YEAR(birthday)\n                         + IF(DAYOFYEAR(CURDATE()) >= DAYOFYEAR(birthday),1,0)\n                YEAR)  \n            BETWEEN CURDATE() AND DATE_ADD(CURDATE(), INTERVAL 7 DAY);\n\n-- Same as above query with another way to exclude today's birthdays \nSELECT * \nFROM  persons \nWHERE  DATE_ADD(birthday, \n                INTERVAL YEAR(CURDATE())-YEAR(birthday)\n                         + IF(DAYOFYEAR(CURDATE()) > DAYOFYEAR(birthday),1,0)\n                YEAR) \n            BETWEEN CURDATE() AND DATE_ADD(CURDATE(), INTERVAL 7 DAY)\n     AND DATE_ADD(birthday, INTERVAL YEAR(CURDATE())-YEAR(birthday) YEAR) <> CURDATE();\n\n\n-- Same as above query with another way to exclude today's birthdays \nSELECT * \nFROM  persons \nWHERE  DATE_ADD(birthday, \n                INTERVAL YEAR(CURDATE())-YEAR(birthday)\n                         + IF(DAYOFYEAR(CURDATE()) > DAYOFYEAR(birthday),1,0)\n                YEAR) \n            BETWEEN CURDATE() AND DATE_ADD(CURDATE(), INTERVAL 7 DAY)\n     AND (MONTH(birthday) <> MONTH(CURDATE()) OR DAY(birthday) <> DAY(CURDATE()));\n"]], ['mySQL SELECT upcoming birthdays'], 2, 1], [(18749306, 0), [['Try this'], ['Create a UDF to calculate sum of the cost column:']], [[' --create table without realization column\nCREATE TABLE [dbo].[CostCategory](\n[ID_CostCategory] [int] NOT NULL,\n[Name] [varchar](150) NOT NULL,\n[Plan] [money] NOT NULL\n) go\n\nCREATE TABLE [dbo].[Cost](\n[ID_Cost] [int] NOT NULL,\n[Name] [varchar](50) NULL,\n[ID_CostCategory] [int] NULL,\n[ID_Department] [int] NULL,\n[ID_Project] [int] NULL,\n[Value] [money] NULL,\n\n) go \n']], ['Create table and get data from another table'], 6, 0], [(18749306, 1), [['Create a UDF to calculate sum of the cost column:'], ['Now Alter your CostCategory table to add computed column:']], [[' CREATE FUNCTION [dbo].[CalculateRealization](@Id INT) \nRETURNS money\nAS \nBEGIN\n  DECLARE @cost money\n\n  SELECT @cost = SUM(Value)\n  FROM [dbo].[Cost]\n  WHERE [ID_CostCategory] = @ID\n\n  return @cost\nEND\n']], ['Create table and get data from another table'], 6, 0], [(18749306, 2), [['Now Alter your CostCategory table to add computed column:'], ['Now you can select Realization from Costcategory']], [[' ALTER TABLE [dbo].[CostCategory]\n   ADD [Realization] AS dbo.CalculateRealization(ID_CostCategory);\n']], ['Create table and get data from another table'], 6, 0], [(18749306, 3), [['Now you can select Realization from Costcategory'], ['Create Another UDF']], [[' SELECT ID_CostCategory, Realization\nFROM [dbo].[CostCategory]\n']], ['Create table and get data from another table'], 6, 0], [(18749306, 4), [['Create Another UDF'], ['Now add Constraint on Cost Table:']], [[' CREATE FUNCTION [dbo].[CheckValue](@Id INT, @value Money) \nRETURNS INT\nAS \nBEGIN\n  DECLARE @flg INT\n  SELECT @flg = CASE WHEN [Plan] >= @value THEN 1 ELSE 0 END\n  FROM [dbo].[CostCategory]\n  WHERE [ID_CostCategory] = @ID\n\n  return @flg;\nEND\n']], ['Create table and get data from another table'], 6, 0], [(18749306, 5), [['Now add Constraint on Cost Table:'], ['-10000']], [[' ALTER TABLE ALTER TABLE [dbo].[Cost]\n  ADD CONSTRAINT CHK_VAL_PLAN_COSTCATG\n    CHECK(dbo.CheckValue(ID_CostCategory, Value) = 1)\n']], ['Create table and get data from another table'], 6, 0], [(18757944, 0), [['If you just want "fake" the value of a column in a result set, try'], ['If you want to change the underlying data, do']], [[' select id, name, NULL as [date] from samp\n']], ['How change non nullable column to nullable column'], 2, 1], [(18757944, 1), [['If you want to change the underlying data, do'], ['-10000']], [[' UPDATE samp set [date] = NULL\n']], ['How change non nullable column to nullable column'], 2, 1], [(18764988, 0), [['If you are using MS SQL Server try this code:'], ['For MySQL try:']], [[' SELECT tb.date_added\n  FROM MyTable tb\n WHERE tb.date_added > DATEADD(week, -2, GETDATE())\n']], ['SQL Query Comparing Date'], 2, 1], [(18764988, 1), [['For MySQL try:'], ['-10000']], [[' SELECT tb.date_added\n  FROM MyTable tb\n WHERE DATE_ADD(tb.date_added, INTERVAL 2 WEEK) >= NOW();\n']], ['SQL Query Comparing Date'], 2, 1], [(18777437, 1), [['SECOND ATTEMPT:'], ['Based on your data (starting with  3245 ) it gives the following chain:']], [[' SELECT DISTINCT * \nFROM LinkedTable\nSTART WITH code = 3245\nCONNECT BY NOCYCLE\n           PRIOR code = code  AND PRIOR link_sequence+1 = link_sequence OR\n           PRIOR code <> code AND PRIOR link_sequence =   link_sequence\nORDER BY link_sequence, code\n;\n']], ['SQL: Linking Multiple Rows in Table Based on Data Chain in Select'], 3, 1], [(18777437, 2), [['Based on your data (starting with  3245 ) it gives the following chain:'], ['-10000']], [[' ID  CODE    LINK_SEQUENCE   NAME\n2   3245    1              Potato\n1   3267    1              Potato\n3   3245    2              Potato\n4   3975    2              Potato\n5   3975    3              Potato\n6   5478    3              Potato\n']], ['SQL: Linking Multiple Rows in Table Based on Data Chain in Select'], 3, 0], [(18778492, 0), [['Try running these:'], ['Then run']], [[' ALTER TABLE table1 ADD NewDate DATE\n']], ['MS Access Alter Statement: change column data type to DATETIME'], 2, 0], [(18778492, 1), [['Then run'], ['You can then delete the  RecordTime  and rename  NewDate .']], [[" UPDATE table1\nSET NewDate = RecordTime\nWHERE RIGHT(RecordTime,4) <> '- ::'\n"]], ['MS Access Alter Statement: change column data type to DATETIME'], 2, 0], [(18799810, 0), [['1) A function that shows total for every department'], ['2) A function which has two parameters, the second parameter being optional']], [[' CREATE FUNCTION [dbo].[Table2](@pID_CostCategory INT) \nRETURNS TABLE\nAS \nRETURN\n    SELECT  [ID_Department], SUM(Value) AS koszt\n    FROM    [dbo].[Cost]\n    WHERE   [ID_CostCategory] = @pID_CostCategory\n    GROUP BY[ID_Department];\nGO  \n']], ['function with multiple where'], 2, 1], [(18799810, 1), [['2) A function which has two parameters, the second parameter being optional'], ['-10000']], [[' CREATE FUNCTION [dbo].[Table2](@pID_CostCategory INT, @pID_Department INT=NULL) \nRETURNS TABLE\nAS \nRETURN\n    SELECT  SUM(Value) AS koszt\n    FROM    [dbo].[Cost]\n    WHERE   [ID_CostCategory] = @pID_CostCategory\n    AND     ([ID_Department] = @pID_Department OR @pID_Department IS NULL)\nGO\n']], ['function with multiple where'], 2, 1], [(18852505, 0), [['Use  DISTINCT  to count the distinct  Box.id  in your query - '], ['Use this query to see the actual data used by the query before grouping and decide on which columns to group by. Mostly, it will be the columns where you see duplicate data in multiple rows.']], [[' SELECT \n    Box.expected_delivery_date, count(DISTINCT Box.id) num_boxes\nFROM\n    Box\n        JOIN\n    Subscription ON Box.subscription_id = Subscription.id\n        JOIN\n    BoxContent ON Subscription.id = BoxContent.subscription_id\n        JOIN\n    Schedule ON Schedule.id = BoxContent.schedule_id\nWHERE\n    Box.state = 3 AND Box.status = 2\nGROUP BY Box.expected_delivery_date;\n']], ['Join distant SQL tables without pulling data in between'], 2, 1], [(18852505, 1), [['Use this query to see the actual data used by the query before grouping and decide on which columns to group by. Mostly, it will be the columns where you see duplicate data in multiple rows.'], ['You may even try  SELECT Box.*, Schedule.*  in above query to come up with a final grouping. ']], [[' SELECT \n    Box.expected_delivery_date, Box.id BoxID, Schedule.id SchID\nFROM\n    Box\n        JOIN\n    Subscription ON Box.subscription_id = Subscription.id\n        JOIN\n    BoxContent ON Subscription.id = BoxContent.subscription_id\n        JOIN\n    Schedule ON Schedule.id = BoxContent.schedule_id\nWHERE\n    Box.state = 3 AND Box.status = 2\n']], ['Join distant SQL tables without pulling data in between'], 2, 1], [(18858779, 0), [['This SQL will compute the permutations without repetitions:'], ["The first part of SQL sets the starting records.  Assuming 3 rows named 'A', 'B', and 'C' in  MyTable , this will generate these rows:"]], [[" WITH recurse(Result, Depth) AS\n(\n    SELECT CAST(Value AS VarChar(100)), 1\n    FROM MyTable\n\n    UNION ALL\n\n    SELECT CAST(r.Result + '+' + a.Value AS VarChar(100)), r.Depth + 1\n    FROM MyTable a\n    INNER JOIN recurse r\n    ON CHARINDEX(a.Value, r.Result) = 0\n)\n\nSELECT Result\nFROM recurse\nWHERE Depth = (SELECT COUNT(*) FROM MyTable)\nORDER BY Result\n"]], ['T-SQL "Dynamic" Join'], 6, 1], [(18858779, 1), [["The first part of SQL sets the starting records.  Assuming 3 rows named 'A', 'B', and 'C' in  MyTable , this will generate these rows:"], ['Then the next block of SQL performs the first level of recursion:']], [['     Result     Depth\n    ------     -----\n    A          1\n    B          1\n    C          1\n']], ['T-SQL "Dynamic" Join'], 6, 0], [(18858779, 2), [['Then the next block of SQL performs the first level of recursion:'], ["This takes all of the records generated so far (which will be in the  recurse  table) and joins them to all of the records in  MyTable  again.  The  ON  clause filters the list of records in  MyTable  to only return the ones that do not exist already in this row's permutation.  This would result in these rows:"]], [["     SELECT CAST(r.Result + '+' + a.Value AS VarChar(100)), r.Depth + 1\n    FROM MyTable a\n    INNER JOIN recurse r\n    ON CHARINDEX(a.Value, r.Result) = 0\n"]], ['T-SQL "Dynamic" Join'], 6, 0], [(18858779, 3), [["This takes all of the records generated so far (which will be in the  recurse  table) and joins them to all of the records in  MyTable  again.  The  ON  clause filters the list of records in  MyTable  to only return the ones that do not exist already in this row's permutation.  This would result in these rows:"], ['Then the recursion loops again giving these rows:']], [['     Result     Depth\n    ------     -----\n    A          1\n    B          1\n    C          1\n    A+B        2\n    A+C        2\n    B+A        2\n    B+C        2\n    C+A        2\n    C+B        2\n']], ['T-SQL "Dynamic" Join'], 6, 0], [(18858779, 4), [['Then the recursion loops again giving these rows:'], ['The last SQL filters all of the resulting rows where the computed  Depth  column matches the # of records in  MyTable .  This throws out all of the rows except for the ones generated by the last depth of recursion.  So the final result will be these rows:']], [['     Result     Depth\n    ------     -----\n    A          1\n    B          1\n    C          1\n    A+B        2\n    A+C        2\n    B+A        2\n    B+C        2\n    C+A        2\n    C+B        2\n    A+B+C      3\n    A+C+B      3\n    B+A+C      3\n    B+C+A      3\n    C+A+B      3\n    C+B+A      3\n']], ['T-SQL "Dynamic" Join'], 6, 0], [(18858779, 5), [['The last SQL filters all of the resulting rows where the computed  Depth  column matches the # of records in  MyTable .  This throws out all of the rows except for the ones generated by the last depth of recursion.  So the final result will be these rows:'], ['-10000']], [['     Result\n    ------\n    A+B+C\n    A+C+B\n    B+A+C\n    B+C+A\n    C+A+B\n    C+B+A\n']], ['T-SQL "Dynamic" Join'], 6, 0], [(18865590, 1), [['And the following for your results in several rows:'], ["I renamed your columns, because you can't use brackets as columnname in a sql-statement."]], [[" SELECT 'CountSearch', COUNT(*)\nFROM Table\nWHERE task = 'search' or task = 'Basic' or task = 'natural search'\nUNION ALL\nSELECT 'CountQuery', COUNT(*)\nFROM Table\nWHERE task = 'Query1' or task = 'Query2' or task = 'Query3'\nUNION ALL\nSELECT 'CountSample', COUNT(*)\nFROM Table\nWHERE task = 'sample1' or task = 'sample2'\nUNION ALL\nSELECT 'CountTest', COUNT(*)\nFROM Table\nWHERE task = 'test1' or task = 'test2' or task = 'test3'\n"]], ['Applying multiple condition on a column'], 2, 1], [(18873251, 0), [['Assumption: a set of queries that looks something like this:'], ['So, for a "level 3" query, you\'d want to generate the following:']], [[' Level1Q:  select * from users where name=:param_user\nLevel2Q:  select * from projects where id=:param_id\nLevel3Q:  select * from details where id=:param_id\nLevel4Q:  <etc>\n']], ['Is it possible to reference columns from one common table expression in another, without using joins?'], 3, 0], [(18873251, 1), [['So, for a "level 3" query, you\'d want to generate the following:'], ['This, or something much like it, should produce that query:']], [[' ;WITH\n   Level1Q as (select * from users where name=:param_user)\n  ,Level2Q as (select * from projects where id=:param_id)\n  ,Level3Q as (select * from details where id=:param_id)\n select * from Level3Q\n']], ['Is it possible to reference columns from one common table expression in another, without using joins?'], 3, 0], [(18885583, 1), [['and the whole example:'], ['-10000']], [[" DECLARE @Table TABLE (ID INT, Code NVARCHAR(50), RequiredID INT);\n\nINSERT INTO @Table (ID, Code, RequiredID)   VALUES\n    (1, 'Physics', NULL),\n    (2, 'Advanced Physics', 1),\n    (3, 'Nuke', 2),\n    (4, 'Health', NULL);    \n\nDECLARE @DefaultSeed TABLE (ID INT, Code NVARCHAR(50), RequiredID INT);\n\nWITH hierarchy \nAS (\n    --anchor\n    SELECT  t.ID , t.Code , t.RequiredID\n    FROM @Table AS t\n    WHERE t.RequiredID IS NULL\n\n    UNION ALL   \n\n    --recursive\n    SELECT  t.ID \n          , t.Code \n          , h.ID        \n    FROM hierarchy AS h\n        JOIN @Table AS t \n            ON t.RequiredID = h.ID\n    )\n\nINSERT INTO @DefaultSeed (ID, Code, RequiredID)\nSELECT  ID \n        , Code \n        , RequiredID\nFROM hierarchy\nOPTION (MAXRECURSION 10)\n\n\nDECLARE @NewSeed TABLE (ID INT IDENTITY(10, 1), Code NVARCHAR(50), RequiredID INT)\n\nDeclare @MapIds Table (aOldID int,aNewID int)\n\n;MERGE INTO @NewSeed AS TargetTable\nUsing @DefaultSeed as Source on 1=0\nWHEN NOT MATCHED then\n Insert (Code,RequiredID)\n Values\n (Source.Code,Source.RequiredID)\nOUTPUT Source.ID ,inserted.ID into @MapIds;\n\n\nUpdate @NewSeed Set RequiredID=aNewID\nfrom @MapIds\nWhere RequiredID=aOldID\n\n\n/*\n--@NewSeed should read like the following...\n[ID]  [Code]           [RequiredID]\n10....Physics..........NULL\n11....Health...........NULL\n12....AdvancedPhysics..10\n13....Nuke.............12\n*/\n\nSELECT *\nFROM @NewSeed\n"]], ['CTE to build hierarchy from source table'], 2, 1], [(18904109, 1), [['PhoneCarrier  will look something like:'], ["You won't have a foreign key directly from  Phone  to  Carrier  in that scenario."]], [[' PhoneCarrierID\nPhoneID (FK)\nCarrierID (FK)\n']], ['Link one record to multiple records in separate table'], 2, 0], [(18920393, 0), [['1) Your solution uses a non-deterministic function:  datepart(dw...)  . Because of this aspect, changing  DATEFIRST  setting will gives different results. For example, you should try: '], ['and then ']], [[' SET DATEFIRST 7;\nyour solution;\n']], ['SQL Server : get next relative day of week. (Next Monday, Tuesday, Wed.....)'], 6, 0], [(18920393, 1), [['and then '], ['2) Following solution is independent of  DATEFIRST / LANGUAGE  settings:']], [[' SET DATEFIRST 1;\nyour solution;\n']], ['SQL Server : get next relative day of week. (Next Monday, Tuesday, Wed.....)'], 6, 0], [(18920393, 2), [['2) Following solution is independent of  DATEFIRST / LANGUAGE  settings:'], ['Result:']], [[' DECLARE @NextDayID INT  = 0 -- 0=Mon, 1=Tue, 2 = Wed, ..., 5=Sat, 6=Sun\nSELECT DATEADD(DAY, (DATEDIFF(DAY, @NextDayID, GETDATE()) / 7) * 7 + 7, @NextDayID) AS NextDay\n']], ['SQL Server : get next relative day of week. (Next Monday, Tuesday, Wed.....)'], 6, 1], [(18920393, 3), [['Result:'], ['Edit #1:']], [[' NextDay\n-----------------------\n2013-09-23 00:00:00.000\n']], ['SQL Server : get next relative day of week. (Next Monday, Tuesday, Wed.....)'], 6, 0], [(18920393, 4), [['Edit #1:'], ['Result:']], [[' DECLARE @NextDayID INT;\nSET @NextDayID = 1; -- Next Sunday\nSELECT DATEADD(DAY, (DATEDIFF(DAY, ((@NextDayID + 5) % 7), GETDATE()) / 7) * 7 + 7, ((@NextDayID + 5) % 7)) AS NextDay\n']], ['SQL Server : get next relative day of week. (Next Monday, Tuesday, Wed.....)'], 6, 1], [(18920393, 5), [['Result:'], ['Note: my current date is  20130923 .']], [[' NextDay\n-----------------------\n2013-09-29 00:00:00.000 \n']], ['SQL Server : get next relative day of week. (Next Monday, Tuesday, Wed.....)'], 6, 0], [(18922620, 0), [['Try this'], ["If you want to report only those records with a score above a threshold such as 0.75\nthen add the 'having' clause "]], [['     select r.mediaid, \n       count(*) as total_rows, \n       sum(rating) as id_sum,\n       SUM(rating)/count(*) AS score\n    from rating r, media m\n    where r.mediaid=m.mediaid\n    group by r.mediaid\n']], ['MySQL: SELECT Row Based on Ratio of True to False in Second Table'], 3, 1], [(18922620, 1), [["If you want to report only those records with a score above a threshold such as 0.75\nthen add the 'having' clause "], ['One way is to sort by scores  desc  and then limit to 1 record like this  SQL Fiddle#2']], [['  select r.mediaid, \n        count(*) as total_rows, \n        sum(rating) as id_sum,\n        SUM(rating)/count(*) AS score\n   from rating r, media m\n  where r.mediaid=m.mediaid\n  group by r.mediaid\n  having score > .75  \n']], ['MySQL: SELECT Row Based on Ratio of True to False in Second Table'], 3, 1], [(18922620, 2), [['One way is to sort by scores  desc  and then limit to 1 record like this  SQL Fiddle#2'], ['-10000']], [['     select r.mediaid, \n     count(*) as total_rows, \n     sum(rating) as id_sum,\n     SUM(rating)/count(*) AS score\nfrom rating r, media m\n where r.mediaid=m.mediaid\n group by r.mediaid\norder by score desc limit 1\n']], ['MySQL: SELECT Row Based on Ratio of True to False in Second Table'], 3, 1], [(18992088, 0), [['You can use this to help build the query:'], ['Update: Dynamic SQL version (still have to plop table names in manually):']], [[" SELECT ',' + name \nFROM sys.columns\nWHERE object_id IN (OBJECT_ID('Table1'),OBJECT_ID('Table2'))\nORDER BY name\n"]], ['Order 2 tables by column names'], 2, 1], [(18992088, 1), [['Update: Dynamic SQL version (still have to plop table names in manually):'], ['-10000']], [[" DECLARE @sql VARCHAR(MAX)\n       ,@cols VARCHAR(MAX)\nSET @cols = (SELECT STUFF((SELECT ',' + Name\n                           FROM (SELECT DISTINCT Name\n                                  FROM sys.columns\n                                  WHERE object_id IN (OBJECT_ID('Table1'),OBJECT_ID('Table2'))\n                                     AND Name <> 'ID'\n                                  )sub\n                            ORDER BY name\n                            FOR XML PATH('')        \n                            ), 1, 1, '' ))\nSET @sql = 'SELECT ' +@cols+'\n            FROM Table1 a\n            JOIN Table2 b\n              ON a.ID = b.ID\n           '\nEXEC (@sql)\n"]], ['Order 2 tables by column names'], 2, 1], [(19005246, 0), [['I see two ways to do it.\nI would go for an array approach, since it will probably be the fastest (single data step) and is not that complex:'], ['Alternatively, you can prepare a table for the transpose to work by creating one record per week per id::']], [[' data RESULT (drop=start_week end_week);\n    set YOUR_DATA;\n    array week_array{62} week0-week61;\n    do week=0 to 61;\n        if week between start_week and end_week then week_array[week+1]=1;\n        else week_array[week+1]=0;\n    end;\nrun;\n']], ['tracking customer retension on weekly basis'], 2, 1], [(19005246, 1), [['Alternatively, you can prepare a table for the transpose to work by creating one record per week per id::'], ['-10000']], [[' data BEFORE_TRANSPOSE (drop=start_week end_week);\n    set YOUR_DATA;\n    do week=0 to 61;\n        if week between start_week and end_week then subscribed=1;\n        else subscribed=0;\n        output;\n    end;\nrun;\n']], ['tracking customer retension on weekly basis'], 2, 1], [(19006430, 0), [['I would use CROSS APPLY to unpivot the columns in pairs:'], ['This can also be written using CROSS APPLY with UNION ALL:']], [[" select t.employee_id,\n  t.employee_name,\n  c.data,\n  c.old,\n  c.new\nfrom yourtable t\ncross apply\n(\n  values \n  ('Address', Address_Old, Address_new),\n  ('Income', cast(income_old as varchar(15)), cast(income_new as varchar(15)))\n) c (data, old, new);\n"]], ['Converting a pivot table to a flat table in SQL'], 2, 1], [(19006430, 1), [['This can also be written using CROSS APPLY with UNION ALL:'], ['See  Demo']], [[" select t.employee_id,\n  t.employee_name,\n  c.data,\n  c.old,\n  c.new\nfrom yourtable t\ncross apply\n(\n  select 'Address', Address_Old, Address_new union all\n  select 'Income', cast(income_old as varchar(15)), cast(income_new as varchar(15))\n) c (data, old, new)\n"]], ['Converting a pivot table to a flat table in SQL'], 2, 1], [(19041847, 0), [['You can do it like this'], ['Sample output from issuing']], [[' CREATE VIEW OverBudgetProjects AS\n  SELECT p.department, p.projectid\n    FROM project p LEFT JOIN assignment a\n      ON p.projectid = a.projectid\n   GROUP BY p.department, p.projectid\n  HAVING MAX(p.maxhours) < SUM(a.hoursworked);\n\nCREATE VIEW Projects AS\n  SELECT DepartmentName, \n         COUNT(DISTINCT p.projectid) NumberOfProjects,\n         COUNT(DISTINCT o.Projectid) NumberOfOverBudgetProjects,\n         OfficeNumber,\n         Phone\n    FROM department d JOIN project p\n      ON d.DepartmentName = p.Department LEFT JOIN OverBudgetProjects o\n      ON d.DepartmentName = o.Department\n   GROUP BY p.Department;\n']], ['Best way to display number of overspent projects'], 2, 1], [(19041847, 1), [['Sample output from issuing'], ['is']], [[' SELECT * FROM Projects\n']], ['Best way to display number of overspent projects'], 2, 0], [(19053225, 0), [['Since you seem to want  every row in the result individually , you cannot aggregate. Use a  window function  instead to get the count per day. The well known aggregate function  count()  can also serve as  window aggregate function :'], ['If you want a  running count  in the sense of "n rows have been out of stock for this number of days  or more ", use:']], [[" SELECT current_date - ped.data_envio::date AS days_out_of_stock\n      <b>,count(*) OVER (PARTITION BY ped.data_envio::date)\n                                        AS count_per_days_out_of_stock</b>\n      ,ped.data_envio::date AS date\n      ,p.id                 AS product_id\n      ,opl.id               AS storage_id\nFROM   sub_produtos_pedidos spp\nLEFT   JOIN cad_produtos    p   ON p.cod_ean = spp.ean_produto\nLEFT   JOIN sub_pedidos     sp  ON sp.id     = spp.id_pedido\nLEFT   JOIN op_logisticos   opl ON opl.id    = sp.id_op_logistico\nLEFT   JOIN pedidos         ped ON ped.id    = sp.id_pedido\nWHERE  spp.motivo = '201'                   -- code for 'not in inventory'\nORDER  BY ped.data_envio::date, p.id, opl.id"]], ['Count the number of occurrences grouped by some rows'], 2, 1], [(19053225, 1), [['If you want a  running count  in the sense of "n rows have been out of stock for this number of days  or more ", use:'], ['You get the same count for the same day, peers are lumped together.']], [[' count(*) OVER (ORDER BY ped.data_envio::date) -- ascending order!\n                                        AS running_count_per_days_out_of_stock\n']], ['Count the number of occurrences grouped by some rows'], 2, 0], [(19068044, 1), [['UPDATE. It appears that the OP also wants the tuples with  column1 IS NULL , if there a more of them. The simple solution is to use a sentinel value (a value that is not natively present in  columnn1 ) and use that as a surrogate: (in the fragment below  -1  is used as a surrogate value)'], ['The other (obvious) way would be to explicitely check for NULLs, but this will require an  OR  clause and a bunch of parentheses, like:']], [[' SELECT tt.id\nFROM thetable tt\nWHERE EXISTS (\n    SELECT * FROM thetable ex\n    WHERE COALESCE(ex.column1, -1) = COALESCE(tt.column1, -1)\n    AND ex.id <> tt.id\n);\n']], ['Select from list of values received from a subquery, possibly null'], 3, 1], [(19068044, 2), [['The other (obvious) way would be to explicitely check for NULLs, but this will require an  OR  clause and a bunch of parentheses, like:'], ['-10000']], [[' SELECT tt.id\nFROM thetable tt\nWHERE EXISTS (\n    SELECT * FROM thetable ex\n    WHERE (ex.column1 = tt.column1 \n          OR (ex.column1 IS NULL AND tt.column1 IS NULL)\n          )\n    AND ex.id <> tt.id\n);\n']], ['Select from list of values received from a subquery, possibly null'], 3, 1], [(19073500, 0), [['You can do it with pure SQL like this'], ['Output:']], [[" SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(t.values, ',', n.n), ',', -1) value\n  FROM table1 t CROSS JOIN \n(\n   SELECT a.N + b.N * 10 + 1 n\n     FROM \n    (SELECT 0 AS N UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9) a\n   ,(SELECT 0 AS N UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9) b\n    ORDER BY n\n) n\n WHERE n.n <= 1 + (LENGTH(t.values) - LENGTH(REPLACE(t.values, ',', '')))\n ORDER BY value\n"]], ['SQL split comma separated row'], 2, 1], [(19073500, 1), [['Output:'], ['Here is  SQLFiddle  demo']], [[" SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(t.values, ',', n.n), ',', -1) value\n  FROM table1 t CROSS JOIN tally n\n WHERE n.n <= 1 + (LENGTH(t.values) - LENGTH(REPLACE(t.values, ',', '')))\n ORDER BY value\n"]], ['SQL split comma separated row'], 2, 1], [(19101688, 0), [["This isn't pretty or short but it is simple."], ["It occurs to me that you didn't specify what to do for a place that has two of one vowel and three of another. Does that qualify? If not (Say  Alaska StatE PEak Park  was bad even though it has exactly 2 E's in it) then you might want this instead:"]], [[" SELECT word\nFROM tabl\nWHERE\n  -- assuming case sensitive based on your example\n  (word LIKE '%[Aa]%[Aa]%' AND word NOT LIKE '%[Aa]%[Aa]%[Aa]%')\n  OR\n  (word LIKE '%[Ee]%[Ee]%' AND word NOT LIKE '%[Ee]%[Ee]%[Ee]%')\n  OR\n  (word LIKE '%[Ii]%[Ii]%' AND word NOT LIKE '%[Ii]%[Ii]%[Ii]%')\n  OR\n  (word LIKE '%[Oo]%[Oo]%' AND word NOT LIKE '%[Oo]%[Oo]%[Oo]%')\n  OR\n  (word LIKE '%[Uu]%[Uu]%' AND word NOT LIKE '%[Uu]%[Uu]%[Uu]%')\n"]], ['SQL: 2 same vowels regex'], 2, 1], [(19101688, 1), [["It occurs to me that you didn't specify what to do for a place that has two of one vowel and three of another. Does that qualify? If not (Say  Alaska StatE PEak Park  was bad even though it has exactly 2 E's in it) then you might want this instead:"], ['-10000']], [[" SELECT word \nFROM tabl \nWHERE\n  -- assuming case sensitive based on your example\n  ( word LIKE '%[Aa]%[Aa]%'\n    OR word LIKE '%[Ee]%[Ee]%'\n    OR word LIKE '%[Ii]%[Ii]%'\n    OR word LIKE '%[Oo]%[Oo]%'\n    OR word LIKE '%[Uu]%[Uu]%' \n  )\n  AND word NOT LIKE '%[Aa]%[Aa]%[Aa]%'\n  AND word NOT LIKE '%[Ee]%[Ee]%[Ee]%'\n  AND word NOT LIKE '%[Ii]%[Ii]%[Ii]%'\n  AND word NOT LIKE '%[Oo]%[Oo]%[Oo]%'\n  AND word NOT LIKE '%[Uu]%[Uu]%[Uu]%'\n"]], ['SQL: 2 same vowels regex'], 2, 1], [(19136921, 1), [['It produces the following sql statment:'], ['The following is my test setup and random data which got generated']], [[" select cast(count(*) as INT) as col_0_0_ \nfrom Posts post0_ \nwhere (\n    select cast(count(*) as INT)\n    from PostsToTags tags1_, Tags tag2_ \n    where post0_.Id=tags1_.Post_id \n    and tags1_.Tag_id=tag2_.Id \n    and (tag2_.Title='C#' or tag2_.Title='C++'))>=2\n"]], ['How to count all posts belonging to multiple tags in NHibernate?'], 4, 0], [(19136921, 2), [['The following is my test setup and random data which got generated'], ['test run:']], [[' public class Post\n{\n    public Post()\n    {\n        Tags = new List<Tag>();\n    }\n    public virtual void AddTag(Tag tag)\n    {\n        this.Tags.Add(tag);\n        tag.Posts.Add(this);\n    }\n    public virtual string Title { get; set; }\n    public virtual string Content { get; set; }\n    public virtual ICollection<Tag> Tags { get; set; }\n    public virtual int Id { get; set; }\n}\n\npublic class PostMap : ClassMap<Post>\n{\n    public PostMap()\n    {\n        Table("Posts");\n\n        Id(p => p.Id).GeneratedBy.Native();\n\n        Map(p => p.Content);\n\n        Map(p => p.Title);\n\n        HasManyToMany<Tag>(map => map.Tags).Cascade.All();\n    }\n}\n\npublic class Tag\n{\n    public Tag()\n    {\n        Posts = new List<Post>();\n    }\n    public virtual string Title { get; set; }\n    public virtual string Description { get; set; }\n    public virtual ICollection<Post> Posts { get; set; }\n    public virtual int Id { get; set; }\n}\n\npublic class TagMap : ClassMap<Tag>\n{\n    public TagMap()\n    {\n        Table("Tags");\n        Id(p => p.Id).GeneratedBy.Native();\n\n        Map(p => p.Description);\n        Map(p => p.Title);\n        HasManyToMany<Post>(map => map.Posts).LazyLoad().Inverse();\n    }\n}\n']], ['How to count all posts belonging to multiple tags in NHibernate?'], 4, 0], [(19155321, 0), [["If you're combining a WHERE and an ORDER BY you'll need  to reflect this in the design of your index to enable MySQL to continue to benefit from the index for sorting.  For example if your query is:"], ['If your query is:']], [[" SELECT * FROM mytable WHERE year='2012' ORDER BY date LIMIT 0, 200\n"]], ['MySQL paging large data based on a specific order'], 2, 0], [(19155321, 1), [['If your query is:'], ['Then your index will need to be on the two columns (firstletter, date) in that order.']], [[" SELECT * FROM mytable WHERE firstletter='P' ORDER BY date LIMIT 0, 200\n"]], ['MySQL paging large data based on a specific order'], 2, 0], [(19163959, 0), [['You could use '], ['Maybe better in general from a performance aspect:']], [[' TRUNC(TableT.STARTDATETIME) = TRUNC(sysdate-1)\n']], ["Yesterday's date in where clase with HH:MM:SS"], 2, 1], [(19163959, 1), [['Maybe better in general from a performance aspect:'], ['This includes yesterday 00:00:00 (the  >=  ), but excludes today 00:00:00 (the  < ).']], [[' TableT.STARTDATETIME >= trunc(sysdate-1) AND TableT.STARTDATETIME < trunc(sysdate);\n']], ["Yesterday's date in where clase with HH:MM:SS"], 2, 1], [(19181164, 0), [['First check for UTF8 compatibility with this query. If it supports you should see the output as '], ['SHOW VARIABLES LIKE ']], [[' “Character_set_system”| “UTF8″\n']], ['how to change font in mysql database to store unicode charactors'], 3, 0], [(19181164, 1), [['SHOW VARIABLES LIKE '], ['Now that being checked, alter the table and just modify the column, Posts in our above example and specify it as UTF8']], [[' ‘character_set_system’;\n']], ['how to change font in mysql database to store unicode charactors'], 3, 0], [(19181164, 2), [['Now that being checked, alter the table and just modify the column, Posts in our above example and specify it as UTF8'], ['Now, try to insert the hindi value and save it. Query it and u shud see the hindi text']], [[' ALTER TABLE articles MODIFY Posts VARCHAR(20) CHARACTER SET UTF8;\n']], ['how to change font in mysql database to store unicode charactors'], 3, 1], [(19189050, 0), [['-10000'], ['Results:']], [[" DECLARE @CurrentDate SMALLDATETIME; -- Or DATE\n\nSET @CurrentDate = '20131004'\n\nSELECT  DATEADD(DAY, (DATEDIFF(DAY, 0, @CurrentDate) / 7) * 7, 0)  AS FirstDayOfTheWeek,\n        DATEADD(DAY, (DATEDIFF(DAY, 0, @CurrentDate) / 7) * 7 + 4, 0)  AS LastDayOfTheWeek\n"]], ['T-SQL Query to Select current, previous or next week'], 3, 1], [(19189050, 1), [['Results:'], ['All days between Monday and Friday:']], [[' FirstDayOfTheWeek       LastDayOfTheWeek\n----------------------- -----------------------\n2013-09-30 00:00:00.000 2013-10-04 00:00:00.000\n']], ['T-SQL Query to Select current, previous or next week'], 3, 0], [(19189050, 2), [['All days between Monday and Friday:'], ['-10000']], [[" DECLARE @CurrentDate DATE;\nDECLARE @WeekNum SMALLINT;\n\nSET @CurrentDate = '20131004'\nSET @WeekNum = +1; -- -1 Previous WK, 0 Current WK, +1 Next WK\n\nSELECT   DATEADD(DAY, dof.DayNum, fdow.FirstDayOfTheWeek) AS DayAsDateTime\nFROM    (VALUES (DATEADD(DAY, (DATEDIFF(DAY, 0, @CurrentDate) / 7) * 7 + @WeekNum*7, 0)))  fdow(FirstDayOfTheWeek)\nCROSS JOIN (VALUES (0), (1), (2), (3), (4)) dof(DayNum)\n\n/*\nDayAsDateTime\n-----------------------\n2013-10-07 00:00:00.000\n2013-10-08 00:00:00.000\n2013-10-09 00:00:00.000\n2013-10-10 00:00:00.000\n2013-10-11 00:00:00.000\n*/\n\nSELECT  *\nFROM\n(\nSELECT   DATEADD(DAY, dof.DayNum, fdow.FirstDayOfTheWeek) AS DayAsDateTime, dof.DayNum\nFROM    (VALUES (DATEADD(DAY, (DATEDIFF(DAY, 0, @CurrentDate) / 7) * 7 + @WeekNum*7, 0)))  fdow(FirstDayOfTheWeek)\nCROSS JOIN (VALUES (0), (1), (2), (3), (4)) dof(DayNum)\n) src \nPIVOT( MAX(DayAsDateTime) FOR DayNum IN ([0], [1], [2], [3], [4]) ) pvt\n\n/*\n0                       1                       2                       3                       4\n----------------------- ----------------------- ----------------------- ----------------------- -----------------------\n2013-10-07 00:00:00.000 2013-10-08 00:00:00.000 2013-10-09 00:00:00.000 2013-10-10 00:00:00.000 2013-10-11 00:00:00.000\n*/\n"]], ['T-SQL Query to Select current, previous or next week'], 3, 1], [(19211707, 1), [['An alternative solution is to build the query dynamically:'], ['-10000']], [[' $where = array();\nif ($category) {\n    $where[] = "category = ?";\n    $params[] = $category;\n}\n\n... perhaps add more terms to $where conditionally ...\n\n$query = "SELECT * FROM table";\nif ($where) {\n    $query .= " WHERE " . implode(" AND ", $where);\n}\n']], ['How to query specific category or all categories inside the same query?'], 2, 1], [(19256123, 0), [['I think that should do the job on a DB2 as well:'], ['Result:']], [[' SELECT Column1, Column2, \n       MAX (CASE Column3 WHEN 2 THEN 2 ELSE NULL END)\n  FROM t\n GROUP BY Column1, Column2;\n']], ['In SQL query to find duplicates in one column then use a second column to determine which record to return'], 2, 1], [(19256123, 1), [['Result:'], ['-10000']], [[' COLUMN1     COLUMN2         COLUMN3\n---------   -----------     -------\n134024323   81999000004     (null)\n127001126   90489495251     2\n346122930   346000016       2\n346207637   346000016       (null)\n']], ['In SQL query to find duplicates in one column then use a second column to determine which record to return'], 2, 0], [(19268811, 0), [['Use the following:'], ['or as, @Lieven noted:']], [[" SELECT RegName,\n       RegEmail,\n       RegPhone,\n       RegOrg,\n       RegCountry,\n       DateReg,\n       ISNULL(Website,'no website')  AS WebSite \nFROM   RegTakePart \nWHERE  Reject IS NULL\n"]], ['Set default value in query when value is null'], 2, 1], [(19268811, 1), [['or as, @Lieven noted:'], ['The dynamic of COALESCE is that you may define more arguments, so if the first is null then get the second, if the second is null get the third etc etc...']], [[" SELECT RegName,\n       RegEmail,\n       RegPhone,\n       RegOrg,\n       RegCountry,\n       DateReg,\n       COALESCE(Website,'no website')  AS WebSite \nFROM   RegTakePart \nWHERE  Reject IS NULL\n"]], ['Set default value in query when value is null'], 2, 1], [(19270316, 0), [['Package specification:'], ['Package body:']], [[' create or replace package PKG is\n  function NumOfSeqWords(\n    p_str1 in varchar2,\n    p_str2 in varchar2\n  ) return number;\nend;\n']], ['Count sequential matching words in two strings oracle'], 4, 0], [(19270316, 2), [['Test case:'], ['Result:']], [["  with t1(Id1, col1, col2) as(\n   select 1, 'foo bar live'  ,'foo bar'     from dual union all\n   select 2, 'foo live tele' ,'foo tele'    from dual union all\n   select 3, 'bar foo live'  ,'foo bar live'from dual\n  )\n  select id1\n       , col1\n       , col2\n       , pkg.NumOfSeqWords(col1, col2) as res\n    from t1\n  ;\n"]], ['Count sequential matching words in two strings oracle'], 4, 0], [(19270316, 3), [['Result:'], ['-10000']], [['        ID1 COL1          COL2                RES\n---------- ------------- ------------ ----------\n         1 foo bar live  foo bar               2\n         2 foo live tele foo tele              1\n         3 bar foo live  foo bar live          0\n']], ['Count sequential matching words in two strings oracle'], 4, 0], [(19270491, 0), [['This is our raw data:'], ['We can then number the rows, ordering by precedence:']], [[" -- the product weights (use INNER JOIN to only find \n--   the products with their own weights)\nSELECT\n    p.ProductId,\n    p.ProductName,\n    m.MaterialId,\n    m.MaterialName,\n    pw.Weight,\n    'Product' WeightSource,\n    20 Precedence\nFROM\n    @Product p\n    INNER JOIN @ProductWeight pw ON pw.ProductId = p.ProductId\n    INNER JOIN @Material m ON m.MaterialId = pw.MaterialId\nUNION ALL\n-- the group weight\nSELECT\n    p.ProductId,\n    p.ProductName,\n    m.MaterialId,\n    m.MaterialName,\n    gw.Weight,\n    'Group' WeightSource,\n    10 Precedence\nFROM\n    @Product p\n    INNER JOIN @GroupWeight gw on gw.GroupId = p.GroupId\n    INNER JOIN @Material m ON m.MaterialId = gw.MaterialId\n"]], ['What is the best way to SELECT data when there are two possible tables holding the detail information?'], 5, 0], [(19270491, 1), [['We can then number the rows, ordering by precedence:'], ['Which gives us the same data with an additional indication of which row for a given product-material is the relevant one, so finally we can get just that:']], [[' -- assume the above is in a CTE named AllWeights\nSELECT \n    *,\n    ROW_NUMBER() OVER (PARTITION BY ProductId, MaterialId \n                       ORDER BY Precedence DESC) rn\nFROM \n    AllWeights\n']], ['What is the best way to SELECT data when there are two possible tables holding the detail information?'], 5, 0], [(19270491, 2), [['Which gives us the same data with an additional indication of which row for a given product-material is the relevant one, so finally we can get just that:'], ['Putting it all together:']], [[' -- assume the above is in a CTE named RowNumbered\nSELECT\n    ProductName,\n    MaterialName,\n    WeightSource,\n    Weight\nFROM\n    RowNumbered\nWHERE\n    rn = 1\n;\n']], ['What is the best way to SELECT data when there are two possible tables holding the detail information?'], 5, 0], [(19270491, 4), [['Output:'], ['which except for order is the same as yours, I think.']], [[' ProductName          MaterialName WeightSource Weight\n-------------------- ------------ ------------ ------------\nCan of soup          Paper        Product      5.20\nCan of soup          Steel        Product      23.10\nCan of beans         Paper        Group        5.20\nCan of beans         Steel        Group        23.10\nBottle of beer       Paper        Product      4.60\nBottle of beer       Steel        Product      2.40\nBottle of beer       Glass        Product      185.90\nBottle of wine       Paper        Product      5.10\nBottle of wine       Steel        Product      2.60\nBottle of wine       Glass        Product      650.40\nBottle of sauce      Paper        Group        4.85\nBottle of sauce      Steel        Group        2.50\nBottle of sauce      Glass        Group        418.15\n']], ['What is the best way to SELECT data when there are two possible tables holding the detail information?'], 5, 0], [(19279889, 0), [['Try this :'], ['May be you will find this one "cleaner" :']], [[" RIGHT(words, LEN(words) - (LEN(prefix+'?')-1))\n"]], ['Removing the prefix of a string in TSQL'], 2, 1], [(19279889, 1), [['May be you will find this one "cleaner" :'], ['-10000']], [[' RIGHT(words, LEN(words) - DATALENGTH(CONVERT(VARCHAR(100),prefix)))\n']], ['Removing the prefix of a string in TSQL'], 2, 1], [(19307842, 0), [['The stored procedure is populating  RT  but you then need to select out of it:'], ['or you could simplify it to get rid of the  RT  variable:']], [[" CREATE OR REPLACE PROCEDURE MDC_UTIL_PROCEDURE (results OUT SYS_REFCURSOR)\nAS\n    RT MDC_CAT_PARAMETROS%ROWTYPE;\nBEGIN\n    SELECT * INTO RT FROM MDC_CAT_PARAMETROS WHERE PARAM_LLAVE='SMTP_SERVER';\n    OPEN results FOR SELECT * FROM RT;\nEND MDC_UTIL_PROCEDURE; \n"]], ['Calling a stored procedure with a select'], 2, 1], [(19307842, 1), [['or you could simplify it to get rid of the  RT  variable:'], ['-10000']], [[" CREATE OR REPLACE PROCEDURE MDC_UTIL_PROCEDURE (results OUT SYS_REFCURSOR)\nAS\nBEGIN\n    OPEN results FOR \n    SELECT * FROM MDC_CAT_PARAMETROS WHERE PARAM_LLAVE='SMTP_SERVER';\nEND MDC_UTIL_PROCEDURE; \n"]], ['Calling a stored procedure with a select'], 2, 1], [(19329816, 1), [['You can also use that to get all leafs:'], ['Which is probably faster than your solution with a sub-select']], [[' select level,  first_name ||\' \'|| last_name "FullName" \nfrom more_employees\nwhere connect_by_isleaf = 1\nstart with employee_id = 1\nconnect by prior employee_id = manager_id;\n']], ['Hierarchical Query( how to retrieve middle nodes)'], 2, 0], [(19353473, 0), [['Your first couple joins (Video/VideoTags/Tags) yields a table like so:'], ['When you join to VideoChannels, it duplicates the above entries for each channel']], [[' VideoID = 1 will bring in TagID = 2,5 (Dogs, orlyowl) so you have this\n\n| 1 | Dogs\n| 1 | orlyowl\n']], ['SQL multiple table join throwing dupes'], 3, 0], [(19353473, 1), [['When you join to VideoChannels, it duplicates the above entries for each channel'], ['group_concat has a DISTINCT attribute']], [[' | 1 | Dogs    | 1\n| 1 | orlyowl | 1\n| 1 | Dogs    | 4\n| 1 | orlyowl | 4\n| 1 | Dogs    | 6\n| 1 | orlyowl | 6\n']], ['SQL multiple table join throwing dupes'], 3, 0], [(19353473, 2), [['group_concat has a DISTINCT attribute'], ['-10000']], [[' select v.*\n  , group_concat(distinct t.tagName) Tags\n  , group_concat(distinct c.channelName) Channels\nfrom videos as v \ninner join videoTags as vt on v.videoId = vt.videoid\ninner join tags as t on t.tagId = vt.tagId\ninner join videoChannels as vc on v.videoId = vc.videoId\ninner join channels as c on c.channelId = vc.channelId\ngroup by v.videoId;\n']], ['SQL multiple table join throwing dupes'], 3, 0], [(19356906, 0), [['Just add'], ['Could you tell me if there is a way to list the complete domains one by one with your addition?']], [[' GROUP BY Keydomain\nHAVING COUNT(*) > 1\n']], ['Show modified strings that appear more than once'], 2, 0], [(19359464, 0), [['Please try:'], ['OR']], [[" select \n    a.col2+'#'+b.col2 \nfrom \n    T1 a, T1 b \nwhere a.col1='Con'and \n    b.col1='Arr'\n"]], ['create 1 column from 2 column with in SQL'], 2, 1], [(19359464, 1), [['OR'], ['-10000']], [[" select \n    a.col2+'#'+b.col2 \nfrom \n    T1 a CROSS JOIN T1 b \nwhere a.col1='Con'and \n    b.col1='Arr'\n"]], ['create 1 column from 2 column with in SQL'], 2, 1], [(19408757, 0), [['in your ImagesController'], ['somewhere in your add.ctp view file']], [[" public function add() {\n    //\n    // ...\n    //\n    $albums = $this->Image->Album->find('list');\n    $this->set('albums', $albums);\n}\n"]], ['Cakephp - Adding data to relational database'], 2, 0], [(19408757, 1), [['somewhere in your add.ctp view file'], ['-10000']], [[" echo $this->Form->input('album_id');\n"]], ['Cakephp - Adding data to relational database'], 2, 0], [(19436954, 3), [['It would look something like the following:'], ['-10000']], [[' VALUES \n  ("Hello!", \n  "Click here.",\n  "Can you tell me your name?",\n  "example.com/img.jpg",\n  "google.com",\n  CAST((Counter / 5) AS UNSIGNED),\n  40,\n  2013);\n']], ['Change some value each 5 inserts (MySQL Stored Procedure)'], 4, 1], [(19447701, 0), [['use this query'], ['OR']], [[" SELECT CONVERT(VARCHAR(10), convert(date,'2013/10/18'), 103) AS [DD/MM/YYYY]\n"]], ['Change single database datetime format'], 2, 1], [(19447701, 1), [['OR'], ['-10000']], [[' SELECT CONVERT(VARCHAR(10), getdate(), 103) AS [DD/MM/YYYY]\n']], ['Change single database datetime format'], 2, 1], [(19459274, 0), [['The best performing solution will likely be '], ['If the  ID  values were not guaranteed contiguous as stated then you would need to use ']], [[' WITH T\n     AS (SELECT *,\n                ID - ROW_NUMBER() OVER (PARTITION BY [STATUS] ORDER BY [ID]) AS Grp\n         FROM   YourTable)\nSELECT [STATUS],\n       SUM([VALUE]) AS [SUM(VALUE)]\nFROM   T\nGROUP  BY [STATUS],\n          Grp\nORDER  BY MIN(ID)\n']], ['Sequential Group By in sql server'], 2, 1], [(19459274, 1), [['If the  ID  values were not guaranteed contiguous as stated then you would need to use '], ['Instead in the CTE definition.']], [[' ROW_NUMBER() OVER (ORDER BY [ID]) - \n       ROW_NUMBER() OVER (PARTITION BY [STATUS] ORDER BY [ID]) AS Grp\n']], ['Sequential Group By in sql server'], 2, 0], [(19499472, 0), [['If you are selecting  email  and  phone  in subqueries these two joins are probably unnecessary:'], ['Final query might look like:']], [[' left join StaffContactInformation as sci on sr.ID = sci.StaffID\ninner join dictStaffContactTypes as dsct on sci.ContactTypeID = dsct.ID\n']], ['sql query get multiple values from same column for one row'], 2, 0], [(19499472, 1), [['Final query might look like:'], ['-10000']], [[' SELECT sr.LastName, sr.FirstName, dd.Name, \n    Email = (\n        select sc.ContactValue FROM StaffContactInformation as sc\n        INNER JOIN StaffRoster as roster on sc.StaffID = roster.ID\n        where sc.ContactTypeID = 3 and roster.ID = sr.ID\n    ),\n    Phone = (\n        SELECT sc1.ContactValue FROM StaffContactInformation as sc1 \n        INNER JOIN StaffRoster as roster on sc1.StaffID = roster.ID\n        where sc1.ContactTypeID = 1\n    ) \nFROM StaffRoster as sr\nleft join dictDivisions as dd on sr.DivisionID = dd.Id  \nwhere (sr.Active = 1 and sr.isContractor = 0 )\nORDER BY sr.LastName, sr.FirstName\n']], ['sql query get multiple values from same column for one row'], 2, 1], [(19532288, 0), [["You don't need to make  GROUP BY start_time, end_time  if you have a column date (i suggest you to create column date to groups the 'time diff').  \nhere's my example:  \nmy table (named time)"], ['this is my query to display the different time between starttime and endtime:']], [[' ++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n    date   |     starttime       |       endtime       |\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n2013-10-23 | 2013-10-23 08:00:00 | 2013-10-23 16:30:00 |\n2013-10-24 | 2013-10-24 08:30:00 | 2013-10-24 17:00:00 |\n']], ['MySQL Adding Timestamp Values, Adding Resultset, and Grouping by Date'], 5, 0], [(19532288, 1), [['this is my query to display the different time between starttime and endtime:'], ['it will return :']], [[' SELECT *, TIMEDIFF(endtime,starttime) AS duration FROM time\n']], ['MySQL Adding Timestamp Values, Adding Resultset, and Grouping by Date'], 5, 1], [(19532288, 2), [['it will return :'], ["that's if you have a  date  column as different column from starttime and endtime.  \nyou didn't give me the structure of your table, so i can't see you problem clearly. \n UPDATE : \nI imagine that you have a table like this :\n   \nAnd may be your matter is :  calculate the time between starting time and ending time from a day of a user that the user could start and stop in anytime (at that day) . \nI run this query to do that :"]], [[' +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n    date   |     starttime       |       endtime       | duration |\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n2013-10-23 | 2013-10-23 08:00:00 | 2013-10-23 16:30:00 | 08:30:00 |\n2013-10-24 | 2013-10-24 08:30:00 | 2013-10-24 17:00:00 | 08:30:00 |\n']], ['MySQL Adding Timestamp Values, Adding Resultset, and Grouping by Date'], 5, 0], [(19532288, 3), [["that's if you have a  date  column as different column from starttime and endtime.  \nyou didn't give me the structure of your table, so i can't see you problem clearly. \n UPDATE : \nI imagine that you have a table like this :\n   \nAnd may be your matter is :  calculate the time between starting time and ending time from a day of a user that the user could start and stop in anytime (at that day) . \nI run this query to do that :"], ['It will return this: \n   \nor if you run this query :']], [[' SELECT *, TIMEDIFF(MAX(end),MIN(start)) AS duration FROM time\nGROUP BY user_id, date \nORDER BY date ASC;\n']], ['MySQL Adding Timestamp Values, Adding Resultset, and Grouping by Date'], 5, 1], [(19532288, 4), [['It will return this: \n   \nor if you run this query :'], ['it will return this : \n']], [[' SELECT \nuser_id,\nMIN(start) AS start, \nMAX(end) AS end, \nTIMEDIFF(MAX(end),MIN(start)) AS duration \nFROM time\nGROUP BY user_id, date \nORDER BY date ASC\n']], ['MySQL Adding Timestamp Values, Adding Resultset, and Grouping by Date'], 5, 1], [(19532801, 0), [['e.g'], ['while you retrieve the data, the sql may look like below:']], [[" UPDATE TABLE SET start_time= STR_TO_DATE('14:00:00', '%k:%i:%s');\n"]], ['Inserting a TIME value'], 2, 1], [(19562212, 0), [['This should do the trick:'], ['EDIT: New version:']], [[' SELECT * FROM (\n    SELECT *, CASE application WHEN ? THEN 1 WHEN NULL THEN 0 ELSE NULL END\n            + CASE dstIP WHEN ? THEN 1 WHEN NULL THEN 0 ELSE NULL END\n            + CASE dstPort WHEN ? THEN 1 WHEN NULL THEN 0 ELSE NULL END AS Matches\n    FROM table WHERE Matches IS NOT NULL\n) GROUP BY application, dstIP, dstPort ORDER BY Matches DESC;\n']], ['SQL - select row with most matching columns'], 2, 1], [(19562212, 1), [['EDIT: New version:'], ['Advantages: You can compare  NULL  also. Disvantages: only 1 match is showed when equally ranked matches are found.']], [[' SELECT *, CASE WHEN application IS ? THEN 1 WHEN application IS NULL THEN 0 ELSE NULL END\n        + CASE WHEN dstIP IS ? THEN 1 WHEN dstIP IS NULL THEN 0 ELSE NULL END\n        + CASE WHEN dstPort IS ? THEN 1 WHEN dstPort IS NULL THEN 0 ELSE NULL END AS Matches\nFROM t\nWHERE Matches IS NOT NULL\nORDER BY Matches DESC\nLIMIT 1;\n']], ['SQL - select row with most matching columns'], 2, 1], [(19577349, 0), [['So you query has to become:'], ['Edit: \nTo list all columns of you table you can use the following query']], [['       SELECT FLIGHTS.*, \n             SEATS_MAX-COUNT(BOOKING_ID) \n        FROM FLIGHTS \n  INNER JOIN PLANES \n          ON FLIGHTS.PLANE_ID = PLANES.PLANE_ID \n   LEFT JOIN BOOKINGS \n          ON FLIGHTS.FLIGHT_ID = BOOKINGS.FLIGHT_ID \n    GROUP BY FLIGHTS.Column1,\n             ...\n             FLIGHTS.ColumN,\n             SEATS_MAX;\n']], ['SQL select all from one table of joint tables'], 2, 1], [(19577349, 1), [['Edit: \nTo list all columns of you table you can use the following query'], ['This should make your life a bit easier, then copy and paste']], [["   SELECT 'FLIGHTS.' || column_name\n    FROM user_tab_columns\n   WHERE table_name = 'FLIGHTS'\nORDER BY column_id;\n"]], ['SQL select all from one table of joint tables'], 2, 0], [(19582011, 0), [["You can't, because it's the  UPDATE FROM  transaction.  \nYou can either increase max size of the log file:"], ['Or you can try something like this:']], [[' ALTER DATABASE DB_NAME\nMODIFY FILE (NAME=LOG_FILE_NAME,MAXSIZE=UNLIMITED);\n']], ['How can I copy one column to from one table to another in SQL Server'], 2, 1], [(19582011, 1), [['Or you can try something like this:'], ['IF the database has SIMPLE recovery model this should work, if FULL or BULK_LOAD you need also do backup of transaction log in every iteration. ']], [[' WHILE EXISTS\n(select *\nfrom ExceptionRow\n     inner join HashFP ON ExceptionRow.Hash=HashFP.FingerPrintMD5\nwhere ExceptionRow.Message is null\n      AND not HashFP.MessageFP is null\n)\nUPDATE TOP (1000) ExceptionRow\nSET Exceptionrow.Message = HashFP.MessageFP\nFROM ExceptionRow \n     INNER JOIN HashFP ON ExceptionRow.Hash=HashFP.FingerPrintMD5\nWHERE ExceptionRow.Message IS NULL\n      AND NOT HashFP.MessageFP IS NULL\n']], ['How can I copy one column to from one table to another in SQL Server'], 2, 1], [(19582702, 0), [['How the returning result is displayed heavily depends on a client you are using to execute that query. It would be better if you explicitly specified those properties of an object instance you want to be displayed. For example:'], ['result:']], [[' create or replace type T_Obj as object(\n  prop1 number,\n  prop2 date\n)  \n\ncreate or replace function F_1(\n   p_var1 in number,\n   p_var2 in date\n ) return t_obj is\n begin\n   return t_obj(p_var1, p_var2);\n end;\n\nselect t.obj.prop1\n     , t.obj.prop2\n from (select F_1(1, sysdate) as obj\n         from dual) t\n']], ['Get data from object in SQL'], 2, 1], [(19582702, 1), [['result:'], ['-10000']], [['  OBJ.PROP1  OBJ.PROP2\n----------  -----------\n         1  25-Oct-2013\n']], ['Get data from object in SQL'], 2, 0], [(19645073, 0), [['For one user:'], ['For all users:']], [[' SELECT ifnull(wins, 0) wins, ifnull(loses,0) loses, \n       ifnull(wins, 0)+ifnull(loses,0) total, \n       ifnull(wins, 0) / ( ifnull(wins, 0)+ifnull(loses,0)) percent\nFROM (\nSELECT\n (SELECT COUNT(*) FROM user_versus WHERE id_user_winner = 6 ) wins,\n (SELECT COUNT(*) FROM user_versus WHERE id_user_loser = 6 ) loses\n) subqry\n']], ['SQL for list of winners that have won at least a specific percentage of times'], 2, 1], [(19645073, 1), [['For all users:'], ['-10000']], [[' SELECT id_user_winner AS id_user, \n       ifnull(wins, 0) wins\n       ifnull(loses,0) loses\n       ifnull(wins, 0)+ifnull(loses,0) total, \n       ifnull(wins, 0) / ( ifnull(wins, 0)+ifnull(loses,0)) percent\nFROM (\n   SELECT id_user_winner AS id_user FROM user_versus \n   UNION\n   SELECT id_user_loser FROM user_versus \n) u\nLEFT JOIN\nFROM (\n  SELECT id_user_winner, count(*) wins\n  FROM user_versus \n  GROUP BY id_user_winner\n) w\nON u.id_user = id_user_winner\nLEFT JOIN (\n  SELECT id_user_loser, count(*) loses\n  FROM user_versus \n  GROUP BY id_user_loser\n) l\nON u.id_user = l.id_user_loser\n']], ['SQL for list of winners that have won at least a specific percentage of times'], 2, 1], [(19663813, 0), [['-10000'], ['This is its version, checking projects table:']], [[' select status_id, count(1) cnt\nfrom statushistory h\nwhere not exists \n (select 1 from statushistory h1 \n  where h1.project_id=h.project_id and h1.date_added>h.date_added)\ngroup by status_id\n']], ['MySQL: Counting Latest Occurrences of Field in Another Table'], 3, 1], [(19663813, 1), [['This is its version, checking projects table:'], ["I am not sure if low perfomace caused by subquery in where-clause is a myth or not, but here is a version without it (based partly on  Mosty Mostacho 's code). You are welcome to compare these queries and tell us which is performing better."]], [[' select status_id, count(1) cnt\nfrom statushistory h, projects p\nwhere p.project_id=h.project_id and p.active=1\n and not exists \n (select 1 from statushistory h1 \n  where h1.project_id=h.project_id and h1.date_added>h.date_added)\ngroup by status_id\n']], ['MySQL: Counting Latest Occurrences of Field in Another Table'], 3, 1], [(19663813, 2), [["I am not sure if low perfomace caused by subquery in where-clause is a myth or not, but here is a version without it (based partly on  Mosty Mostacho 's code). You are welcome to compare these queries and tell us which is performing better."], ['See it in fiddle  here']], [[' select h.status_id, count(*) cnt FROM (\n select project_id, max(date_added) maxdate \n from statushistory\n group by project_id\n) h1, statushistory h, projects p\nwhere h.project_id=h1.project_id and h.date_added=h1.maxdate\n and p.project_id=h.project_id and p.active=1\ngroup by h.status_id\n']], ['MySQL: Counting Latest Occurrences of Field in Another Table'], 3, 1], [(19680651, 0), [['You can still use a FULL JOIN, just use  ISNULL  on the second join condition:'], ['-10000']], [[' SELECT  RowNumber = COALESCE(t.RowNumber, e.RowNumber, d.RowNumber),\n        EmployeeID = COALESCE(t.EmployeeID, e.EmployeeID, d.EmployeeID),\n        t.FirstName,\n        t.MiddleName,\n        t.LastName,\n        t.SSN,\n        t.EmployeeCode,\n        t.TaxName,\n        t.Amount,\n        t.GrossPay,\n        t.CompanyId,\n        e.EarningDescription,\n        EarningAmount = e.Amount,\n        d.DeductionDescription,\n        DeductionAmount = d.Amount\nFROM    @Tax t\n        FULL JOIN @Earnings e\n            ON t.EmployeeID = e.EmployeeID\n            AND t.RowNumber = e.RowNumber\n        FULL JOIN @Deductions D\n            ON d.EmployeeID = ISNULL(t.EmployeeID, e.EmployeeID)\n            AND d.RowNumber = ISNULL(t.RowNumber, e.RowNumber);\n']], ['FULL OUTER JOIN with temp tables'], 2, 1], [(19680651, 1), [['-10000'], ['-10000']], [[' DECLARE @Tax Table \n(\n   RowNumber int , \n   FirstName nvarchar(50),\n   MiddleName  nvarchar(50),\n   LastName nvarchar(50),\n   SSN nvarchar(50),\n   EmployeeCode nvarchar(50),\n   TaxName nvarchar(50),\n   Amount decimal(18,2),   \n   GrossPay decimal(18,2),\n   CompanyId int,\n   EmployeeId int\n)\nINSERT @Tax  (RowNumber, EmployeeID)\nVALUES (1, 1), (2, 1), (3, 1), (4, 1);\n\nDECLARE @Earnings TABLE\n(\n   RowNumber int , \n   EmployeeId int,  \n   EarningDescription nvarchar(50),  \n   Amount decimal(18,2)\n)\nINSERT @Earnings  (RowNumber, EmployeeID)\nVALUES (1, 1), (2, 1);\n\nDECLARE @Deductions TABLE \n(\n    RowNumber int , \n    EmployeeId int,  \n    DeductionDescription nvarchar(50),  \n    Amount decimal(18,2)\n) \nINSERT @Deductions  (RowNumber, EmployeeID)\nVALUES (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1);  \n\n\nSELECT  RowNumber = COALESCE(t.RowNumber, e.RowNumber, d.RowNumber),\n        EmployeeID = COALESCE(t.EmployeeID, e.EmployeeID, d.EmployeeID),\n        t.FirstName,\n        t.MiddleName,\n        t.LastName,\n        t.SSN,\n        t.EmployeeCode,\n        t.TaxName,\n        t.Amount,\n        t.GrossPay,\n        t.CompanyId,\n        e.EarningDescription,\n        EarningAmount = e.Amount,\n        d.DeductionDescription,\n        DeductionAmount = d.Amount\nFROM    @Tax t\n        FULL JOIN @Earnings e\n            ON t.EmployeeID = e.EmployeeID\n            AND t.RowNumber = e.RowNumber\n        FULL JOIN @Deductions D\n            ON d.EmployeeID = ISNULL(t.EmployeeID, e.EmployeeID)\n            AND d.RowNumber = ISNULL(t.RowNumber, e.RowNumber);\n']], ['FULL OUTER JOIN with temp tables'], 2, 1], [(19690325, 0), [['In order to provide an answer, however, I first created a view that eliminates such invalid entries, and used  that  instead of  Emp_Table :'], ['So it boils down to the following, with a little help of a recursive CTE:']], [[' create view valid_mng as \nselect Emp_Id,Manager_id from Emp_Table\nwhere Emp_Id<>Manager_Id\n']], ['SQL Query to get recursive count of employees under each manager'], 2, 0], [(19707228, 1), [['EDIT:\nAfter reading your latest edit with extra care to the desired result,\nI also suggest a double replace:'], ['The inner replace which runs first, replaces all double newline chars with your desired extra string just once, plus one newline, ']], [[" select replace(\n  replace(details, E'\\n\\n', '</text></line><line><text>'||E'\\n'),\nE'\\n', '</text></line><line><text>'||E'\\n')\nfrom personal_details\n"]], ['XML/SQL - Adding a string at the end of each line in individual fields'], 2, 1], [(19716510, 0), [['If you want to grant the privileges directly to the user'], ['More commonly, though, you would create a role, grant the role to the user, and grant the privileges to the role.  That makes it easier in the future when there is a new user created that you want to have the same privileges as USER_A to just grant a couple of roles rather than figuring out all the privileges that potentially need to be granted.  It also makes it easier as new tables are created and new privileges are granted to ensure that users that should have the same privileges continue to have the same privileges.']], [[' GRANT select, update, insert \n   ON table_owner.feed_data_a\n   TO user_a;\nGRANT select, update, insert \n   ON table_owner.feed_data_b\n   TO user_a;\n']], ['Add Select and Write Privileges to User for Specific Table Names'], 2, 1], [(19716510, 1), [['More commonly, though, you would create a role, grant the role to the user, and grant the privileges to the role.  That makes it easier in the future when there is a new user created that you want to have the same privileges as USER_A to just grant a couple of roles rather than figuring out all the privileges that potentially need to be granted.  It also makes it easier as new tables are created and new privileges are granted to ensure that users that should have the same privileges continue to have the same privileges.'], ['-10000']], [[' CREATE ROLE feed_data_role;\n\nGRANT select, update, insert \n   ON table_owner.feed_data_a\n   TO feed_data_role;\nGRANT select, update, insert \n   ON table_owner.feed_data_b\n   TO feed_data_role;\n\nGRANT feed_data_role\n   TO user_a\n']], ['Add Select and Write Privileges to User for Specific Table Names'], 2, 1], [(19718193, 0), [["Personally, I'd use a  MINUS"], ['If you want to  list all differences between the two tables  (i.e. list all rows that exist in dev but not prod and prod but not dev), you can add a UNION ALL']], [[" SELECT *\n  FROM code_mapping\n WHERE soure_system_id = '&LHDNUMBER'\nMINUS\nSELECT *\n  FROM dm.code_mapping@prod_check\n"]], ["SQL query to return rows from one table that don't exist in another"], 2, 1], [(19718193, 1), [['If you want to  list all differences between the two tables  (i.e. list all rows that exist in dev but not prod and prod but not dev), you can add a UNION ALL'], ['-10000']], [[" (SELECT a.*, 'In dev but not prod' descriptio\n   FROM dev_table a\n MINUS \n SELECT a.*, 'In dev but not prod' description\n   FROM prod_table a)\nUNION ALL\n(SELECT a.*, 'In prod but not dev' descriptio\n   FROM prod_table a\n MINUS \n SELECT a.*, 'In prod but not dev' description\n   FROM dev_table a)\n"]], ["SQL query to return rows from one table that don't exist in another"], 2, 1], [(19748723, 0), [['Are you looking for something like this?'], ['Based on your comments']], [[' SELECT *\n  FROM users\n ORDER BY (COALESCE(subs_end_datetime, 0) <= CURDATE()), id\n']], ['how I can use mysql date greater in order by case?'], 2, 1], [(19748723, 1), [['Based on your comments'], ['Here is  SQLFiddle  demo']], [[' SELECT *, subs_end_datetime <= CURDATE() aa\n  FROM users\n ORDER BY (COALESCE(subs_end_datetime, 0) <= CURDATE()), subs_end_datetime DESC\n']], ['how I can use mysql date greater in order by case?'], 2, 1], [(19752084, 1), [['Instead of :'], ['In your first query.']], [[' AND table1.counter=table2.counter\n']], ['SQL case statement in join condition'], 2, 0], [(19765962, 1), [['But if this is not an option then  you can generate a table of dates relatively easily on the fly and use this'], ['-10000']], [[" SET DATEFIRST 1;\nDECLARE @StartDate DATETIME = '20131103', \n        @EndDate DATETIME = '20131104';\n\n-- GENERATE A LIST OF ALL DATES BETWEEN THE START DATE AND THE END DATE\nWITH AllDates AS\n(   SELECT  TOP (DATEDIFF(DAY, @StartDate, @EndDate))\n            D = DATEADD(DAY, ROW_NUMBER() OVER(ORDER BY a.Object_ID), @StartDate)\n    FROM    sys.all_objects a\n            CROSS JOIN sys.all_objects b\n)\nSELECT  WeekDays = COUNT(*)\nFROM    AllDates\nWHERE   DATEPART(WEEKDAY, D) NOT IN (6, 7);\n"]], ['Calculating days to excluding weekends (Monday to Friday) in SQL Server'], 3, 1], [(19835090, 0), [['SPLIT FUNCTION'], ['Code used in procedure:  ']], [[' create function [dbo].[Split](@String varchar(8000), @Delimiter char(1))       \nreturns @temptable TABLE (items varchar(8000))       \nas       \nbegin       \n    declare @idx int       \n    declare @slice varchar(8000)       \n\n    select @idx = 1       \n        if len(@String)<1 or @String is null  return       \n\n    while @idx!= 0       \n    begin       \n        set @idx = charindex(@Delimiter,@String)       \n        if @idx!=0       \n            set @slice = left(@String,@idx - 1)       \n        else       \n            set @slice = @String       \n\n        if(len(@slice)>0)  \n            insert into @temptable(Items) values(@slice)       \n\n        set @String = right(@String,len(@String) - @idx)       \n        if len(@String) = 0 break       \n    end   \nreturn       \nend\n']], ['Replace multiple characters from string without using any nested replace functions'], 3, 0], [(19835090, 1), [['Code used in procedure:  '], ['OUTPUT']], [[" DECLARE @NEWSTRING VARCHAR(100) \nSET @NEWSTRING = '(N_100-(6858)*(6858)*N_100/0_2)%N_35' ;\nSELECT @NEWSTRING = REPLACE(@NEWSTRING, items, '~') FROM dbo.Split('+,-,*,/,%,(,)', ',');\nPRINT @NEWSTRING\n"]], ['Replace multiple characters from string without using any nested replace functions'], 3, 0], [(19835090, 2), [['OUTPUT'], ['-10000']], [[' ~N_100~~6858~~~6858~~N_100~0_2~~N_35\n']], ['Replace multiple characters from string without using any nested replace functions'], 3, 0], [(19837655, 0), [['Before you execute your script:'], ['After you execute your script and have done your checking:']], [[' BEGIN TRANSACTION;\n']], ['SQL Server query dry run'], 2, 0], [(19837655, 1), [['After you execute your script and have done your checking:'], ['Every change in your script will then be undone.']], [[' ROLLBACK TRANSACTION;\n']], ['SQL Server query dry run'], 2, 0], [(19866409, 0), [['In this example we add one nanosecond:'], ['Result:']], [[" select timestamp '2013-11-11 22:10:10.111111111' + \n       interval '0 00:00:00.000000001' day to second(9) as res\n  from dual\n"]], ['How to add one nanosecond to a timestamp in PL/SQL'], 6, 1], [(19866409, 1), [['Result:'], ["Note : When you are using  to_timestamp()  function to convert character literal to a value of timestamp data type, it's a good idea to specify a format mask(not relay on NLS settings)."]], [[' RES                           \n-------------------------------\n11-NOV-13 10.10.10.111111112 PM \n']], ['How to add one nanosecond to a timestamp in PL/SQL'], 6, 0], [(19866409, 2), [["Note : When you are using  to_timestamp()  function to convert character literal to a value of timestamp data type, it's a good idea to specify a format mask(not relay on NLS settings)."], ['Result:']], [[" select TO_TIMESTAMP('11-11-2013 22:10:10:111111111', 'dd-mm-yyyy hh24:mi:ss:ff9') + \n       interval '0 00:00:00.000000001' day to second(9) as res\n  from dual\n"]], ['How to add one nanosecond to a timestamp in PL/SQL'], 6, 1], [(19866409, 3), [['Result:'], ['Note : As you intend to process values of timestamp data type using PL/SQL you should be aware of the following. The default precision of fractional seconds for values of timestamp data type, in PL/SQL, is 6 not 9 as it is in SQL, so you may expect truncation of fractional second. In order to avoid truncation of fractional seconds use  timestamp_unconstrained  and  dsinterval_unconstrained  data types instead of  timestamp  and  interval day to second :']], [[' RES                           \n-------------------------------\n11-NOV-13 10.10.10.111111112 PM \n']], ['How to add one nanosecond to a timestamp in PL/SQL'], 6, 0], [(19866409, 4), [['Note : As you intend to process values of timestamp data type using PL/SQL you should be aware of the following. The default precision of fractional seconds for values of timestamp data type, in PL/SQL, is 6 not 9 as it is in SQL, so you may expect truncation of fractional second. In order to avoid truncation of fractional seconds use  timestamp_unconstrained  and  dsinterval_unconstrained  data types instead of  timestamp  and  interval day to second :'], ['Result:']], [[" declare\n  l_tmstmp timestamp_unconstrained := to_timestamp('11-11-2013 22:10:10:111111111',\n                                                   'dd-mm-yyyy hh24:mi:ss:ff9');\n  l_ns     dsinterval_unconstrained :=  interval '0.000000001' second;\nbegin\n  l_tmstmp := l_tmstmp + l_ns;\n  dbms_output.put_line(to_char(l_tmstmp, 'dd-mm-yyyy hh24:mi:ss:ff9'));\nend;\n"]], ['How to add one nanosecond to a timestamp in PL/SQL'], 6, 1], [(19866409, 5), [['Result:'], ['-10000']], [[' anonymous block completed\n11-11-2013 22:10:10:111111112\n']], ['How to add one nanosecond to a timestamp in PL/SQL'], 6, 0], [(19872492, 1), [['Now to simplify your insert statement you can also use  VALUES()  in  ON DUPLICATE KEY  like this'], ['Here is  SQLFIddle  demo']], [[" INSERT INTO Table1 (`value1`, `value2`, `value3`)\nVALUES ('$valueForValue1', '$valueForValue2', '$valueForValue3')\nON DUPLICATE KEY UPDATE value1 = VALUES(value1);\n"]], ['Detect if MySQL has duplicates when inserting'], 2, 1], [(19902526, 0), [['In your case the schema might look like'], ['To insert new items and associate them with categories']], [[' CREATE TABLE categories\n(\n  category_id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, \n  category_name VARCHAR(128)\n);\n\nCREATE TABLE items\n(\n  item_id int NOT NULL AUTO_INCREMENT PRIMARY KEY, \n  category_id INT, \n  item_name VARCHAR(128),\n  FOREIGN KEY (category_id) REFERENCES categories (category_id)\n);\n']], ['table into a table row'], 4, 0], [(19902526, 1), [['To insert new items and associate them with categories'], ['To get items in category  Hardware']], [[" INSERT INTO items (category_id, item_name)\nVALUES (1, 'Hard disk');\nINSERT INTO items (category_id, item_name)\nVALUES (2, 'Java');\n"]], ['table into a table row'], 4, 0], [(19902526, 2), [['To get items in category  Hardware'], ['or to easily get a count of items per category']], [[" SELECT item_id, item_name\n  FROM items i JOIN categories c\n    ON i.category_id = c.category_id\n WHERE c.category_name = 'Hardware'\n"]], ['table into a table row'], 4, 0], [(19902526, 3), [['or to easily get a count of items per category'], ['Here is  SQLFiddle  demo']], [[' SELECT category_name, COUNT(item_id) no_items\n  FROM categories c LEFT JOIN items i\n    ON c.category_id = i.category_id\n GROUP BY c.category_id, c.category_name;\n']], ['table into a table row'], 4, 0], [(19939624, 0), [['You have to use  XMLSERIALIZE :'], ["It is not working for you, because, most probably, you are using Oracle 10g, and the  INDENT  option was introduced in version 11g. If this is the case, try below approach with the  EXTRACT('*') :"]], [[' SELECT\n  XMLSERIALIZE(DOCUMENT\n    XMLElement("Sample-Test" ,\n        XMLAgg(\n        XMLElement("Sample",\n              XMLElement("SAMPLE_NUM", s.sample_number), \n              XMLElement("LABEL_ID", s.label_id),\n              XMLElement("STATUS", s.status),\n               (SELECT \n                  XMLAgg( \n                  XMLElement("Test-Details",\n                      XMLElement("TEST_NUM", t.test_number),\n                      XMLElement("ANALYSIS", t.analysis),                                                                   \n                          (SELECT \n                           XMLAgg( \n                              XMLElement("Result-Details",\n                              XMLElement("RESULT_NUM", R.RESULT_NUMBER),\n                              XMLElement("RESULT_NAME", R.NAME))) \n                              FROM RESULT R WHERE t.test_number = R.test_number \n                              and t.SAMPLE_number = R.SAMPLE_NUMBER\n                                                          )))                                                                            \n                 FROM TEST T WHERE t.SAMPLE_number = S.SAMPLE_NUMBER))) \n                 ) AS CLOB INDENT SIZE = 2) as XML                                             \n FROM sample s \n WHERE s.sample_number = 720000020018;\n']], ['Format the XML String Generated using Oracle XMLAgg'], 2, 1], [(19939624, 1), [["It is not working for you, because, most probably, you are using Oracle 10g, and the  INDENT  option was introduced in version 11g. If this is the case, try below approach with the  EXTRACT('*') :"], ['-10000']], [[' SELECT\n        XMLElement("Sample-Test" ,\n            XMLAgg(\n            XMLElement("Sample",\n                  XMLElement("SAMPLE_NUM", s.sample_number), \n                  XMLElement("LABEL_ID", s.label_id),\n                  XMLElement("STATUS", s.status),\n                   (SELECT \n                      XMLAgg( \n                      XMLElement("Test-Details",\n                          XMLElement("TEST_NUM", t.test_number),\n                          XMLElement("ANALYSIS", t.analysis),                                                                   \n                              (SELECT \n                               XMLAgg( \n                                  XMLElement("Result-Details",\n                                  XMLElement("RESULT_NUM", R.RESULT_NUMBER),\n                                  XMLElement("RESULT_NAME", R.NAME))) \n                                  FROM RESULT R WHERE t.test_number = R.test_number \n                                  and t.SAMPLE_number = R.SAMPLE_NUMBER\n                                                              )))                                                                            \n                     FROM TEST T WHERE t.SAMPLE_number = S.SAMPLE_NUMBER))) \n                     ).EXTRACT(\'*\') as XML                                             \n     FROM sample s \n     WHERE s.sample_number = 720000020018;\n']], ['Format the XML String Generated using Oracle XMLAgg'], 2, 1], [(19941944, 0), [['Simply do:'], ['Based on your requirement; this does exactly what you asked for based on the below example:']], [[' DELETE FROM A WHERE Id IN (SELECT Id FROM B); DELETE FROM B;\n']], ['How to execute two DELETE queries one after another'], 2, 1], [(19941944, 1), [['Based on your requirement; this does exactly what you asked for based on the below example:'], ['You can do this with  mysql -e  command and virtually any mysql library (such as the one with php).']], [[' mysql> select sleep(5); show databases;\n+----------+\n| sleep(5) |\n+----------+\n|        0 |\n+----------+\n1 row in set (5.00 sec)\n\n+--------------------+\n| Database           |\n+--------------------+\n|         ...        |\n+--------------------+\n9 rows in set (0.01 sec)\n']], ['How to execute two DELETE queries one after another'], 2, 0], [(19949250, 0), [['You should remove the  FM  from your format model mask and it will work as you expect:'], ['Output:']], [[" select to_char(TRUNC(sysdate), 'mm/dd/yyyy hh12:mi:ss am') from dual;\n"]], ['oracle date to string'], 2, 1], [(19949250, 1), [['Output:'], ['Output:']], [[" SELECT TO_CHAR(\n         TO_DATE('01-01-2013 10:00:00', 'DD-MM-YYYY HH12:MI:SS'),\n         'fmmm/dd/yyyy fmhh12:mi:ss am')\nFROM dual;\n"]], ['oracle date to string'], 2, 1], [(19968525, 0), [['First some first aid for your data model:'], ['Then the transaction code would be:']], [[' CREATE TABLE [Orders] (\nCustomerId INT,\nProductId INT,\nQuantity INT,\nOrderDate datetime2 default GetDate(),\nEnteredBy SYSNAME default original_login() \n)\nGO\n']], ['How to Insert a value from column to another colum?'], 2, 0], [(19985833, 0), [['But you have a function on MySql wich will give you something to work with. You will not see the  Passenger1..PassengerN  you will see a result like this:'], ['If that is good enough to you this is your query:']], [[' 1 Steve, Gary, Tom\n2 John, Chris, Thomas\n']], ['Get mysql column values to row'], 2, 0], [(19985833, 1), [['If that is good enough to you this is your query:'], ['-10000']], [[' select passengers.Bookingid, group_concat(bookings.Customer)\n  from bookings inner join passengers on ( bookings.Bookingid = passengers.Bookingid )\ngroup by passengers.Bookingid \n']], ['Get mysql column values to row'], 2, 1], [(19998376, 0), [['Using a  GROUP BY  and  CASE  will do the trick:'], ['Output:']], [[" CREATE TABLE extended_values (\n  name VARCHAR(20),\n  value VARCHAR(20),\n  userkey INT\n);\n\nINSERT INTO extended_values VALUES ('cs1', 'tgb', 100);\nINSERT INTO extended_values VALUES ('cs2', 'hhy', 100);\nINSERT INTO extended_values VALUES ('cs3', 'ttr', 100);\nINSERT INTO extended_values VALUES ('cs1', 'hht', 104);\nINSERT INTO extended_values VALUES ('cs2', 'iyu', 104);\nINSERT INTO extended_values VALUES ('cs3', 'uyt', 104);\nINSERT INTO extended_values VALUES ('cs1', 'tjg', 106);\nINSERT INTO extended_values VALUES ('cs2', 'yyt', 106);\nINSERT INTO extended_values VALUES ('cs3', 'try', 106);\n\nCOMMIT;\n\nCREATE TABLE user_custom_property (\n  userkey INT,\n  cs1 VARCHAR(20),\n  cs2 VARCHAR(20),\n  cs3 VARCHAR(20)\n);\n\nINSERT INTO user_custom_property\n  SELECT\n      userkey,\n      MIN(CASE WHEN name = 'cs1' THEN value END),\n      MIN(CASE WHEN name = 'cs2' THEN value END),\n      MIN(CASE WHEN name = 'cs3' THEN value END)\n    FROM extended_values\n  GROUP BY userkey;\n\nSELECT * FROM user_custom_property;\n"]], ['Getting Values from a table column and inserting to another table'], 2, 1], [(19998376, 1), [['Output:'], ['-10000']], [[" INSERT INTO user_custom_property\n  SELECT\n      userkey,\n      MIN(CASE WHEN name = 'ea1' THEN value END),\n      MIN(CASE WHEN name = 'ea2' THEN value END),\n      MIN(CASE WHEN name = 'ea3' THEN value END)\n    FROM extended_values\n  GROUP BY userkey;\n"]], ['Getting Values from a table column and inserting to another table'], 2, 0], [(20028832, 0), [["Consider the following data DDL's..."], ['From here, we can obtain an intermediate result as follows...']], [[' CREATE TABLE results\n(id     INT NOT NULL AUTO_INCREMENT PRIMARY KEY\n,homeTeam    INT NOT NULL\n,awayTeam    INT NOT NULL\n,homeScore    INT NOT NULL\n,awayScore INT NOT NULL\n);\n\nINSERT INTO results VALUES\n(1,1,2,3,2),\n(2,3,4,0,1),\n(3,2,1,2,0),\n(4,4,3,1,0),\n(5,3,2,1,2),\n(6,2,3,0,2),\n(7,1,4,4,1),\n(8,4,1,1,2),\n(9,1,3,3,0),\n(10,3,1,1,0),\n(11,4,2,1,0),\n(12,2,4,1,2);\n']], ['longest winning streak by query'], 3, 0], [(20049984, 0), [["This is a CTE solution but, as has been indicated, this may not always perform well - because we're having to compute functions against the  DateTime  column, most indexes will be useless:"], ['Once the recursion is complete, we then exclude the intermediate rows that the CTE produces. E.g. for the "4" island, it generated the following rows:']], [[" declare @t table (ID int not null,[DateTime] datetime not null,\n                  PID int not null,TIU int not null)\ninsert into @t(ID,[DateTime],PID,TIU) values\n(1,'2013-11-18 00:15:00',1551,1005  ),\n(2,'2013-11-18 00:16:03',1551,1885  ),\n(3,'2013-11-18 00:16:30',9110,75527 ),\n(4,'2013-11-18 00:22:01',1022,75    ),\n(5,'2013-11-18 00:22:09',1019,1311  ),\n(6,'2013-11-18 00:23:52',1022,89    ),\n(7,'2013-11-18 00:24:19',1300,44433 ),\n(8,'2013-11-18 00:38:57',9445,2010  )\n\n;With Islands as (\n    select ID as MinID,[DateTime],ID as RecID from @t t1\n    where not exists\n        (select * from @t t2\n            where t2.ID < t1.ID and --Or by date, if needed\n                    --Use 300 seconds to avoid most transition issues\n            DATEDIFF(second,t2.[DateTime],t1.[DateTime]) < 300\n        )\n    union all\n    select i.MinID,t2.[DateTime],t2.ID\n    from Islands i\n        inner join\n        @t t2\n            on\n                i.RecID < t2.ID and\n                DATEDIFF(second,i.[DateTime],t2.[DateTime]) < 300\n), Ends as (\n    select MinID,MAX(RecID) as MaxID from Islands group by MinID\n)\nselect * from @t t\nwhere exists(select * from Ends e where e.MinID = t.ID or e.MaxID = t.ID)\n"]], ['Calculate time difference between rows'], 2, 1], [(20049984, 1), [['Once the recursion is complete, we then exclude the intermediate rows that the CTE produces. E.g. for the "4" island, it generated the following rows:'], ['And all that we care about is that final row where we\'ve identified an "island" of time from ID 4 to ID 7 - that\'s what the second CTE ( Ends ) is finding for us.']], [[' 4,00:22:01,4\n4,00:22:09,5\n4,00:23:52,6\n4,00:24:19,7\n']], ['Calculate time difference between rows'], 2, 0], [(20062208, 0), [['If you have an existing table you can do: '], ['From your sql']], [[' INSERT INTO ExistingTable (Columns,..)\nSELECT Columns,...\nFROM OtherTable\n']], ['Simple SQL Table Insert'], 3, 1], [(20062208, 1), [['From your sql'], ['If you do not have a table and want to create it,']], [[" insert into newEmpTable (employee_id, first_name, \n  last_name, email, phone_number, hire_date, \n  job_id, salary, commission_pct, manager_id, department_id)\nselect e.employee_id, e.first_name, e.last_name, e.email, e.phone_number, e.hire_date, e.job_id,       e.salary, e.commission_pct, e.manager_id, e.department_id\nfrom employees e\njoin departments d\non e.department_id = d.department_id\njoin jobs j\non e.job_id = j.job_id\njoin locations l\non d.location_id = l.location_id\nwhere l.city = 'Seattle';\n"]], ['Simple SQL Table Insert'], 3, 1], [(20062208, 2), [['If you do not have a table and want to create it,'], ['-10000']], [[" create table new_table as \nselect e.employee_id, e.first_name, e.last_name, e.email, e.phone_number, e.hire_date,     e.job_id,       e.salary, e.commission_pct, e.manager_id, e.department_id\nfrom employees e\njoin departments d\non e.department_id = d.department_id\njoin jobs j\non e.job_id = j.job_id\njoin locations l\non d.location_id = l.location_id\nwhere l.city = 'Seattle';\n"]], ['Simple SQL Table Insert'], 3, 1], [(20072250, 0), [["It's about selecting data from mentioned service schema in MySQL and working with  GROUP_CONCAT  function:"], ["-what will this do? Actually, I recommend to execute it step-by-step (i.e. add more complex layer to that which you've already understood) - I doubt there's short way to describe what's happening. It's not a wizardry, it's about constructing valid text SQL from input conditions. End result will be like:"]], [[" select \n  concat('SELECT CASE(seq) ', \n    group_concat(groupcase separator ''), \n    ' END AS result FROM (select *, @j:=@j+1 as seq from test cross join (select @j:=0) as initj) as inittest') \nfrom \n  (select \n    concat(' WHEN ', rownum, ' THEN ', groupvalue) as groupcase \n   from \n     (select \n       rownum, \n       group_concat(COLUMN_NAME SEPARATOR '+') as groupvalue \n      from \n       (select \n         *, \n         @row:=@row+1 as rownum \n        from test \n          cross join (select @row:=0) as initrow) as tablestruct \n        left join \n          (select \n             COLUMN_NAME, \n             @num:=@num+1 as num \n           from \n             INFORMATION_SCHEMA.COLUMNS cross join (select @num:=0) as init \n           where \n             TABLE_SCHEMA='test' && \n             TABLE_NAME='test' && \n             COLUMN_NAME!='constant') as struct \n          on tablestruct.constant>=struct.num \n        group by \n          rownum) as groupvalues) as groupscase\n"]], ['Find sum across varying no of columns'], 2, 0], [(20072250, 1), [["-what will this do? Actually, I recommend to execute it step-by-step (i.e. add more complex layer to that which you've already understood) - I doubt there's short way to describe what's happening. It's not a wizardry, it's about constructing valid text SQL from input conditions. End result will be like:"], ["(I didn't add formatting because that SQL is  generated  string, not the one you'll write by yourself)."]], [[' SELECT CASE(seq)  WHEN 1 THEN value1+value2 WHEN 2 THEN value1 WHEN 3 THEN value3+value2+value1 WHEN 4 THEN value3+value2+value1 WHEN 5 THEN value2+value1+value4+value3 END AS result FROM (select *, @j:=@j+1 as seq from test cross join (select @j:=0) as initj) as inittest\n']], ['Find sum across varying no of columns'], 2, 0], [(20096624, 0), [["you cannot use derived column in  where  clause, there're many discussions on SO about this. One way to do this is to use subquery or CTE"], ['or']], [[' select val\nfrom (select 1+3 as val) as v\nwhere val > 2\n']], ['sum with sql and direct condition'], 2, 1], [(20096624, 1), [['or'], ['-10000']], [[' with cte (\n    select 1+3 as val\n)\nselect val\nfrom cte\nwhere val > 2\n']], ['sum with sql and direct condition'], 2, 1], [(20146719, 0), [['The layout of the two tables are the same you just do:'], ['Or we can copy only the columns we want to into another, existing table:']], [[' INSERT INTO table2\nSELECT * FROM table1;\n']], ['Copy row from table 1 to table 2'], 2, 1], [(20146719, 1), [['Or we can copy only the columns we want to into another, existing table:'], ['-10000']], [[' INSERT INTO table2\n(column_name(s))\nSELECT column_name(s)\nFROM table1;\n']], ['Copy row from table 1 to table 2'], 2, 1], [(20147303, 0), [['-10000'], ['or, more generically (substitute 30 and 10 respectively as required):']], [[" select to_char(123.56, '99999999999999999999.00000000000')\nfrom dual;\n"]], ['Sybase STR-function in Oracle'], 2, 1], [(20147303, 1), [['or, more generically (substitute 30 and 10 respectively as required):'], ['Note: the string length will be 31 to allow room for the possible "-" (negative) sign.']], [[" select to_char(123.56, lpad(rpad('.',10,'0'),30,'9'))\nfrom dual;\n"]], ['Sybase STR-function in Oracle'], 2, 1], [(20197566, 0), [['To actually answer your question, it is always the values before the update that are used, so with this table:'], ['Running:']], [[' A   |   B\n----+-----\n1   |   2\n3   |   4\n']], ['UDF Field Reference In SQL Server UPDATE statement'], 9, 0], [(20197566, 1), [['Running:'], ['Will give:']], [[' UPDATE  T\nSET     A = B,\n        B = 1;\n']], ['UDF Field Reference In SQL Server UPDATE statement'], 9, 0], [(20197566, 2), [['Will give:'], ['PermissionCode']], [[' A   |   B\n----+-----\n2   |   1\n4   |   3           \n']], ['UDF Field Reference In SQL Server UPDATE statement'], 9, 0], [(20197566, 3), [['PermissionCode'], ['UserPermission']], [[' PermissionCode\n-------\nA               \nB               \nC\nD\nZ\n']], ['UDF Field Reference In SQL Server UPDATE statement'], 9, 0], [(20197566, 4), [['UserPermission'], ['You can then use another other table to manage linked Permissions:']], [[' UserID  |   PermissionCode\n--------+--------------------\n1       |   A\n1       |   B\n1       |   C\n1       |   D\n']], ['UDF Field Reference In SQL Server UPDATE statement'], 9, 0], [(20197566, 5), [['You can then use another other table to manage linked Permissions:'], ['You can then get all permissions by a user using this table, e.g. by creating a view:']], [[' ParentCode  |   ChildCode\n------------+---------------\n    A       |       C\n    A       |       G\n']], ['UDF Field Reference In SQL Server UPDATE statement'], 9, 0], [(20197566, 6), [['You can then get all permissions by a user using this table, e.g. by creating a view:'], ['Then you can get permissions that a user does not have using something like this:']], [[' CREATE VIEW dbo.AllUserPermission\nAS\nSELECT  p.UserID, p.PermissionCode\nFROM    UserPermission p\nUNION \nSELECT  p.UserID, lp.ChildCode\nFROM    UserPermission p\n        INNER JOIN LinkedPermission lp\n            ON lp.ParentCode = p.PermissionCode;\n']], ['UDF Field Reference In SQL Server UPDATE statement'], 9, 0], [(20197566, 7), [['Then you can get permissions that a user does not have using something like this:'], ['If you specifically need to store codes that people have expcitly opted out of in addition to those they are not receiving then you could add a column to the  UserPermission  table to store this, you can also store dates and times so you know when various actions were taken:']], [[' SELECT  u.UserID, P.PermissionCode\nFROM    UserTable u\n        CROSS JOIN PermissionCode p\nWHERE   NOT EXISTS\n        (   SELECT  1\n            FROM    AllUserPermission up\n            WHERE   up.UserID = u.UserID\n            AND     up.PermissionCode = p.PermissionCode\n        );\n']], ['UDF Field Reference In SQL Server UPDATE statement'], 9, 0], [(20197566, 8), [['If you specifically need to store codes that people have expcitly opted out of in addition to those they are not receiving then you could add a column to the  UserPermission  table to store this, you can also store dates and times so you know when various actions were taken:'], ['By querying on whether certain columns are NULL or not you can determine various states.']], [[' UserID  |   PermissionCode  |   AddedDateTime   |   DoNotPromoteDateTime    |   RemovedDateTime\n--------+-------------------+-------------------+---------------------------+--------------------\n1       |       A           | 2013-11-25 16:55  |           NULL            |       NULL\n1       |       B           | 2013-11-25 16:55  |       2013-11-25 16:55    |       NULL\n1       |       C           | 2013-11-25 16:55  |       2013-11-25 16:56    |   2013-11-25 16:57\n1       |       D           | 2013-11-25 16:55  |           NULL            |   2013-11-25 16:57\n']], ['UDF Field Reference In SQL Server UPDATE statement'], 9, 0], [(20250357, 1), [['Then, put a field in your query like this:'], ['Put another one in like this:']], [[' MyFirstField: GetCSWord([FieldForms],1)\n']], ['Parsing string values in Access'], 3, 0], [(20250357, 2), [['Put another one in like this:'], ['Etc... for as many as you need.']], [[' MySecondField: GetCSWord([FieldForms],2)\n']], ['Parsing string values in Access'], 3, 0], [(20299075, 0), [['This:-'], ['produces:-']], [[" create table #source (\n    aid int,\n    qid int,\n    answer char(2),\n    istrue bit\n)\ninsert into #source values\n    (1,11,'a1',1),\n    (2,11,'a2',0),\n    (3,11,'a3',0),\n    (4,11,'a4',0),\n    (1,12,'a5',0),\n    (2,12,'a6',0),\n    (3,12,'a7',1),\n    (4,12,'a8',0)\n\nselect s.qid,\n    q1.aid as aid1, q1.answer as answer1, q1.istrue as istrue1,\n    q2.aid as aid2, q2.answer as answer2, q2.istrue as istrue2,\n    q3.aid as aid3, q3.answer as answer3, q3.istrue as istrue3,\n    q4.aid as aid4, q4.answer as answer4, q4.istrue as istrue4\nfrom (\n    select distinct qid\n    from #source\n) s\njoin #source q1 on q1.qid=s.qid and q1.aid=1\njoin #source q2 on q2.qid=s.qid and q2.aid=2\njoin #source q3 on q3.qid=s.qid and q3.aid=3\njoin #source q4 on q4.qid=s.qid and q4.aid=4\norder by s.qid\n"]], ['Convert Multiple Rows into Multiple Columns'], 2, 1], [(20299075, 1), [['produces:-'], ['-10000']], [[' qid aid1 answer1 istrue1 aid2 answer2 istrue2 aid3 answer3 istrue3 aid4 answer4 istrue4\n11  1    a1      1       2    a2      0       3    a3      0       4    a4      0\n12  1    a5      0       2    a6      0       3    a7      1       4    a8      0\n']], ['Convert Multiple Rows into Multiple Columns'], 2, 0], [(20304400, 0), [['2) You could dynamically generate a sql statement that includes the list of EXEC sp_send_dbmail statements like this: '], ['or']], [[" DECLARE @SqlStatement NVARCHAR(MAX) = N'\n    EXEC msdb.dbo.sp_send_dbmail @recipients=''dest01@domain.com'', ...; \n    EXEC msdb.dbo.sp_send_dbmail @recipients=''dest02@domain.com'', ...; \n    EXEC msdb.dbo.sp_send_dbmail @recipients=''dest03@domain.com'', ...;\n    ...';\nEXEC(@SqlStatement);\n"]], ['Use send_dbmail to send an email for each row in sql table'], 2, 1], [(20304400, 1), [['or'], ['-10000']], [[" DECLARE @bodyText NVARCHAR(MAX);\nSET @bodyText = ...;\n\nDECLARE @SqlStatement NVARCHAR(MAX) = N'\n    EXEC msdb.dbo.sp_send_dbmail @recipients=''dest01@domain.com'', @body = @pBody, ...; \n    EXEC msdb.dbo.sp_send_dbmail @recipients=''dest02@domain.com'', @body = @pBody, ...; \n    EXEC msdb.dbo.sp_send_dbmail @recipients=''dest03@domain.com'', @body = @pBody, ...; \n    ...';\nEXEC sp_executesql @SqlStatement, N'@pBody NVARCHAR(MAX)', @pBody = @bodyText;\n"]], ['Use send_dbmail to send an email for each row in sql table'], 2, 1], [(20358637, 0), [['The upper limit of the  varray2  data type can be increased with  alter type  statement:'], ['Current information about  varray2  data type:']], [[' create or replace type Varray2 is varray(50) of varchar2(20);\n/\nTYPE VARRAY2 compiled\n\n\ncreate table owner (\n  modified        date,          \n  id1             Varchar2(18),  --   use varchar2 data type, not varchar. \n  state           Varchar2(2),  \n  contributer_ids Varray2\n)\n/\n\ntable OWNER created.\n']], ['Retaining data while modifying column data type'], 4, 0], [(20358637, 1), [['Current information about  varray2  data type:'], ['Change the upper limit of the  varray2  data type:']], [[" SQL> clear screen;\nSQL> column type_name format a11;\nSQL> column upper_bound format a11\n\nSQL> select t.type_name\n  2       , t.upper_bound\n  3   from all_coll_types t\n  4  where type_name = 'VARRAY2';\n\nTYPE_NAME   UPPER_BOUND\n----------- -----------\nVARRAY2              50 \n"]], ['Retaining data while modifying column data type'], 4, 0], [(20358637, 3), [['After the upper limit of the  varray2  data type has changed:'], ["cascade  clause of the  alter type  statement propagates the data type change to the dependent objects, whether it's a table or another data type."]], [[" SQL> clear screen;\nSQL> column type_name format a11;\nSQL> column upper_bound format a11\n\nSQL> select t.type_name\n  2       , t.upper_bound\n  3   from all_coll_types t\n  4  where type_name = 'VARRAY2';\n\nTYPE_NAME   UPPER_BOUND\n----------- -----------\nVARRAY2             150 \n"]], ['Retaining data while modifying column data type'], 4, 0], [(20371389, 0), [['UDF stands for "user defined function" - unless you did not define the the function with the name "udf_StripHTML" this simply won\'t work. I think you refer to this function:'], ['to test this function do:']], [[" CREATE FUNCTION [dbo].[udf_StripHTML]\n(@HTMLText VARCHAR(MAX))\nRETURNS VARCHAR(MAX)\nAS\nBEGIN\nDECLARE @Start INT\nDECLARE @End INT\nDECLARE @Length INT\nSET @Start = CHARINDEX('<',@HTMLText)\nSET @End = CHARINDEX('>',@HTMLText,CHARINDEX('<',@HTMLText))\nSET @Length = (@End - @Start) + 1\nWHILE @Start > 0\nAND @End > 0\nAND @Length > 0\nBEGIN\nSET @HTMLText = STUFF(@HTMLText,@Start,@Length,'')\nSET @Start = CHARINDEX('<',@HTMLText)\nSET @End = CHARINDEX('>',@HTMLText,CHARINDEX('<',@HTMLText))\nSET @Length = (@End - @Start) + 1\nEND\nRETURN LTRIM(RTRIM(@HTMLText))\nEND\nGO\n"]], ['update column to remove html tags'], 2, 1], [(20371389, 1), [['to test this function do:'], ['Result Set:']], [[' SELECT dbo.udf_StripHTML(\'<b>UDF at stackoverflow.com </b><br><br><a href="http://www.stackoverflow.com">Stackoverflow.com</a>\')\n']], ['update column to remove html tags'], 2, 0], [(20401247, 0), [['I advice you to change  peopleTable  table to follow structure'], ['And by the question you need follow sql ']], [[' peopleTable\nperson fruit_id\njohn   1\n...\n']], ['Getting the number of rows on MySQL with SQL and PHP'], 4, 0], [(20401247, 1), [['And by the question you need follow sql '], ['This will output follows (Example data)']], [[' SELECT a.id, COUNT(*) as count FROM fruitsTable a\nLEFT JOIN peopleTable b ON a.id = b.fruit_id\nGROUP BY a.id\n']], ['Getting the number of rows on MySQL with SQL and PHP'], 4, 1], [(20401247, 2), [['This will output follows (Example data)'], ['And update query']], [[' id  count\n1   2\n2   4\n... \n']], ['Getting the number of rows on MySQL with SQL and PHP'], 4, 0], [(20435406, 0), [['You can do it in three steps, assuming  tout  is your data frame:'], ['Now  cart  is a cartesian product of  tout  by itself, using  ProductID  as the key.']], [[' > library(data.table)\n> tout <- as.data.table(tout)\n> setkey(tout, ProductID)\n> cart <- tout[tout, allow.cartesian = TRUE]\n     ProductID Id Price Index Id.1 Price.1 Index.1\n  1:         1  1     1     1    1       1       1\n  2:         1 10     1     2    1       1       1\n  3:         1 21     1     3    1       1       1\n  4:         1 34     1     4    1       1       1\n  5:         1  1     1     1   10       1       2\n ---                                              \n168:        14 46    11     4   33      11       3\n169:        14 33    11     3   46      11       4\n170:        14 46    11     4   46      11       4\n171:        15 47    12     4   47      12       4\n172:        16 48    12     4   48      12       4\n']], ['How to compute the sum of a variable in R considering ID variable and Index variable and save results in a matrix'], 4, 0], [(20435406, 1), [['Now  cart  is a cartesian product of  tout  by itself, using  ProductID  as the key.'], ['x  is almost what you need, but in a data table (long) form. You need to cast to matrix (wide) form with the help of  avast  from  reshape2  package:']], [[' > x <- cart[, sum(Price), by = list(Index, Index.1)]\n    Index Index.1  V1\n 1:     1       1  45\n 2:     2       1  45\n 3:     3       1  45\n 4:     4       1  45\n 5:     1       2  45\n 6:     2       2  66\n 7:     3       2  66\n 8:     4       2  66\n 9:     1       3  45\n10:     2       3  66\n11:     3       3  88\n12:     4       3  88\n13:     1       4  45\n14:     2       4  66\n15:     3       4  88\n16:     4       4 112\n']], ['How to compute the sum of a variable in R considering ID variable and Index variable and save results in a matrix'], 4, 0], [(20435406, 2), [['x  is almost what you need, but in a data table (long) form. You need to cast to matrix (wide) form with the help of  avast  from  reshape2  package:'], ['Finally, to set upper triangular part of the matrix to NA:']], [[' > library(reshape2)\n> a <- acast(x, Index ~ Index.1, value.var = "V1")\n   1  2  3   4\n1 45 45 45  45\n2 45 66 66  66\n3 45 66 88  88\n4 45 66 88 112\n']], ['How to compute the sum of a variable in R considering ID variable and Index variable and save results in a matrix'], 4, 0], [(20435406, 3), [['Finally, to set upper triangular part of the matrix to NA:'], ['-10000']], [[' > a[upper.tri(a)] <- NA\n   1  2  3   4\n1 45 NA NA  NA\n2 45 66 NA  NA\n3 45 66 88  NA\n4 45 66 88 112\n']], ['How to compute the sum of a variable in R considering ID variable and Index variable and save results in a matrix'], 4, 0], [(20454604, 1), [['You need to add an IF statement for the part "also add code that inserts placeholders in the first_name and last_name columns for employee ID 2000". Like this:'], ['-10000']], [[" IF i = 2000\nTHEN\n   INSERT INTO emp2 \n   ( EMPLOYEE_ID, FIRST_NAME, LAST_NAME, HIRE_DATE, SALARY, DEPARTMENT_ID )\n   VALUES \n   ( i, 'Fname ' || i, 'Lname ' || i, sysdate, 100, 10 );\nELSE\n   INSERT INTO emp2 \n   ( EMPLOYEE_ID, FIRST_NAME, LAST_NAME, HIRE_DATE, SALARY, DEPARTMENT_ID )\n   VALUES \n   ( i, 'Fname', 'Lname', sysdate, 100, 10 );\nEND IF;\n"]], ['PL/SQL help. How to write a anonymous block that inserts 100 new rows'], 2, 1], [(20510051, 0), [['Instead of constantly hitting the database with multiple queries, consider to do it at once like this'], ['or with two statements, leveraging user variables and  ORDER BY  in  UPDATE']], [[' UPDATE bank t JOIN \n(\n  SELECT id, bankaccount, \n  (\n    SELECT COUNT(*)\n      FROM bank\n     WHERE id = b.id\n       AND bankbalance > b.bankbalance\n  ) + 1 rank\n    FROM bank b\n   WHERE id = 1\n) s \n   ON t.id = s.id\n  AND t.bankaccount = s.bankaccount\n  SET t.bankaccountranking = rank;\n']], ['Getting the $rank variable and updating it in the table'], 5, 1], [(20510051, 3), [['-10000'], ['or with user(session) variables']], [[' UPDATE bank t JOIN \n(\n  SELECT id, bankaccount, \n  (\n    SELECT COUNT(DISTINCT bankbalance)\n      FROM bank\n     WHERE id = b.id\n       AND bankbalance > b.bankbalance\n  ) + 1 rank\n    FROM bank b\n   WHERE id = 1\n) s \n   ON t.id = s.id\n  AND t.bankaccount = s.bankaccount\n  SET t.bankaccountranking = rank;\n']], ['Getting the $rank variable and updating it in the table'], 5, 1], [(20519532, 0), [["This is a good case for a bridge table.  Let's say you have in your database:"], ['tag_id  is a surrogate key, and would be a unique, incrementing value for each new tag.  So it may look like:']], [[' file_info\n---------\nfile_id\nauthor\ncreate_date\n\ntag_info\n--------\ntag_id\ntag_name\n']], ['Storing multiple tags in one column'], 4, 0], [(20519532, 1), [['tag_id  is a surrogate key, and would be a unique, incrementing value for each new tag.  So it may look like:'], ['You then create the bridge, which links files to the applicable tags:']], [[' tag_id  tag_name\n------  --------\n     1  Apples\n     2  Pears\n     3  Peaches\n']], ['Storing multiple tags in one column'], 4, 0], [(20519532, 2), [['You then create the bridge, which links files to the applicable tags:'], ['You will have one row in this table for each tag associated with a file:']], [[' file_tag_bridge\n---------------\nfile_id\ntag_id\n']], ['Storing multiple tags in one column'], 4, 0], [(20519532, 3), [['You will have one row in this table for each tag associated with a file:'], ['In this case, file 1 is associated with the  Apples  tag; file 2 is associated with  Pears  and  Peaches .  File 3 is not associated with any tags, and therefore is not represented in the bridge table. ']], [[' file_id   tag_id\n-------   ------\n      1        1\n      2        2\n      2        3\n']], ['Storing multiple tags in one column'], 4, 0], [(20546039, 0), [['Use  CASE  instead of  IF :'], ["You should also use LEFT JOIN syntax instead of the old (+) syntax (but that's more of a style choice in this case - it does not change the result):"]], [[" SELECT \n    FIRST_NAME,\n    LAST_NAME,\n    ULTIMATE_PARENT_NAME, \n    CASE WHEN LOCATION_ACCOUNT_ID IS NULL THEN 'Y' ELSE '' END AS IMPACT\nFROM (\n    SELECT DISTINCT \n        A.FIRST_NAME,\n        A.LAST_NAME,\n        B.LOCATION_ACCOUNT_ID,\n        A.ULTIMATE_PARENT_NAME\n    FROM ACTIVE_ACCOUNTS A,\n    QL_ASSETS B\n    WHERE A.ACCOUNT_ID = B.LOCATION_ACCOUNT_ID(+)\n"]], ['Create custom field in SELECT if other field is null'], 3, 1], [(20546039, 1), [["You should also use LEFT JOIN syntax instead of the old (+) syntax (but that's more of a style choice in this case - it does not change the result):"], ["In fact, since you aren't  using  any of the columns from  B  in your result (only checking for  existence ) you can just use  EXISTS :"]], [[" SELECT \n    FIRST_NAME,\n    LAST_NAME,\n    ULTIMATE_PARENT_NAME, \n    CASE WHEN LOCATION_ACCOUNT_ID IS NULL THEN 'Y' ELSE '' END AS IMPACT\nFROM (\n    SELECT DISTINCT \n        A.FIRST_NAME,\n        A.LAST_NAME,\n        B.LOCATION_ACCOUNT_ID,\n        A.ULTIMATE_PARENT_NAME\n    FROM ACTIVE_ACCOUNTS A\n    LEFT JOIN QL_ASSETS B\n        ON A.ACCOUNT_ID = B.LOCATION_ACCOUNT_ID\n     )\n"]], ['Create custom field in SELECT if other field is null'], 3, 1], [(20546039, 2), [["In fact, since you aren't  using  any of the columns from  B  in your result (only checking for  existence ) you can just use  EXISTS :"], ['-10000']], [[" SELECT \n    FIRST_NAME,\n    LAST_NAME,\n    ULTIMATE_PARENT_NAME, \n    CASE WHEN EXISTS(SELECT NULL \n                     FROM QL_ASSETS \n                     WHERE LOCATION_ACCOUNT_ID = A.ACCOUNT_ID)\n         THEN 'Y' \n         ELSE '' \n         END AS IMPACT\n    FROM ACTIVE_ACCOUNTS A\n"]], ['Create custom field in SELECT if other field is null'], 3, 1], [(20551358, 0), [['Assuming this is declared:'], ["It's just one line of code:"]], [[' Dim xml = <db>\n            <User>DBUser2</User>\n            <Password><![CDATA[xka2bOHaQZWesxHLFHlWaVw7JscbNFCobXbqYWc5rwppoNkAn3K1uqriSCHdEzyY/FNDdbgRJTzDEIM8Jc5PYTBzfMUC5UIDtr16a64Xj7MRGI4/AvRcys/fIQDZQ947GesAc1rF/kbZu8AaZDVTjwObbNPT2L/h+IA6WjM9lqv6BOCi4dUeKxx5AneCBy2TJdifxEPdAIOT9lqTm5/aHFD0JgqSn0OTtWbLuYX9KX9uvA8L8zEH51yEmGl258aRVfpGfyxph/cpdnW1miRk4Q==]]></Password>\n            <Server>N127.0.0.1\\CESSQL</Server>\n            <ServerDatabase>Marino</ServerDatabase>\n            <BackupServer></BackupServer>\n            <BackupDatabase></BackupDatabase>\n            <MasterPassword><![CDATA[EFmUxlkmQfIx4w18oQZ1dtCxAIXIyBZPCelL8csYX3E5NuHBZNI42UXNhFxmu87Ksj5CbQpC1WNTj4jnLaaq7nX6Oa4z3M7glLAeRaXWGAd3VqWfADRQAW3RCKKSJRMK3jwRWHJjY1Vp2hgn9CuMACvYHZUrUyK6nJ9HMiwaXcUJKtm4vl0toQNpwIuGvT2cfMJgvpjXJhTBfxKE75ZWeAldXhX5h/c6LYMQ6DE79uuhdbisfmIrXTskKTcceiRjWU2jTFumpjhM1tUqEoBFLw==]]></MasterPassword>\n          </db>\n']], ['Use the value an XML element as a variable for a procedure'], 3, 0], [(20551358, 2), [['Or, to keep your variable names:'], ['Always specify variable types. To help you with that, you can set  Option Strict On  and  Option Infer Off  in your project settings. This can improve your code quality by forcing you into certain (good) development habits.']], [[' Dim ServerDatabaseValue As String = xml.Element("ServerDatabase").Value\n']], ['Use the value an XML element as a variable for a procedure'], 3, 0], [(20589984, 0), [['In order to get the fieldnames, you would have to write something like this'], ["Then you can add your code which iterates over the table. Here's the entire code:"]], [['    for I := 0 to ADODataSet.FieldCount - 1 do \n    Write (WOLFile,ADODataSet.Fields[I].displayname);\n   writeln (WOLFile);\n']], ["listing SQL table's rows in text file"], 2, 0], [(20637482, 0), [['Based on your sample data, you can easily get the result using an aggregate function with a CASE expression:'], ['You could use the PIVOT function to get the result as well:']], [[" select userlicenseid,\n  startdate,\n  max(case when name = 'Other' then value end) Other,\n  max(case when name = 'Pathways' then value end) Pathways,\n  max(case when name = 'Execution' then value end) Execution,\n  max(case when name = 'Focus' then value end) Focus,\n  max(case when name = 'Profit' then value end) Profit\nfrom yourtable\ngroup by userlicenseid, startdate;\n"]], ['Pivot without aggregate - again'], 2, 1], [(20637482, 1), [['You could use the PIVOT function to get the result as well:'], ['See  SQL Fiddle with Demo']], [[' select userlicenseid, startdate,\n  Other, Pathways, Execution, Focus, Profit\nfrom\n(\n  select userlicenseid, startdate,\n    name, value\n  from yourtable\n) d\npivot\n(\n  max(value)\n  for name in (Other, Pathways, Execution, Focus, Profit)\n) piv;\n']], ['Pivot without aggregate - again'], 2, 1], [(20643084, 0), [['Run once per database:'], ['However , what you are trying to do is the opposite of a pivot function! A counter-pivot. I would use  UNION ALL :']], [[' CREATE EXTENSION tablefunc;\n']], ['Combine sql rows into additional columns'], 2, 0], [(20659137, 1), [['... my answer did not satisfy myself and I doublechecked it. And I think the next answer is more adequate (and even runs on no-mysql)'], ['-10000']], [[' \nSELECT \n    AAA.user, AAA.tone, BBB.color, AAA.toneCounter \nFROM (\n    SELECT\n    AA.user, AA.tone, MAX(AA.toneCounter) as toneCounter\n    FROM (\n    SELECT\n        user, tone, color, COUNT(tone) as toneCounter\n    FROM\n        experiments\n    LEFT JOIN\n        pairings\n    ON\n        experiments.experimentId = pairings.experimentId \n    GROUP BY\n        user, tone, color\n    ) AA\n    Group by\n    AA.user, AA.tone\n) AAA\njoin (\n    SELECT\n    BB.user, BB.tone, BB.color, MAX(BB.toneCounter) as toneCounter\n    FROM (\n    SELECT\n        user, tone, color, COUNT(tone) as toneCounter\n    FROM\n        experiments\n    LEFT JOIN\n        pairings\n    ON\n        experiments.experimentId = pairings.experimentId \n    GROUP BY\n        user, tone, color\n    ) BB\n    Group by\n    BB.user, BB.tone, BB.color \n) BBB\nON\n    BBB.user = AAA.user\n    AND BBB.tone = AAA.tone \n    AND BBB.toneCounter = AAA.toneCounter \n']], ['MySQL: Getting the highest number of a combination of two fields'], 2, 1], [(20661535, 0), [['i believe if you want to combine both times you need to take them out of the group by and add sum them. based on the results the reporting can check total hours and break hours. you can add case statements if you want to flag them.'], ['I made this quick test in sql and it appears to work the way you want. did you add something to the group by?']], [[' SELECT  ftc.lEmployeeID\n       ,ftc.sFirstName\n       ,ftc.sLastName\n       ,SUM(ftc.TotalHours) AS TotalHours\n       ,DATEDIFF(mi, MIN(ftc.dtTimeOut), MAX(ftc.dtTimeIn)) AS BreakTimeMinutes\nFROM dbo.fTimeCard(@StartDate, @EndDate,\n                   @DeptList, @iActive,@ EmployeeList) AS ftc\nWHERE SUM(ftc.TotalHours) >= 0 AND (ftc.DID IS NOT NULL) OR\n                     (ftc.DID IS NOT NULL) AND (ftc.dtTimeOut IS NULL)\nGROUP BY ftc.lEmployeeID, ftc.sFirstName, ftc.sLastName\n']], ['How to Group time segments and check break time'], 2, 1], [(20707736, 0), [['This query should give you a list of unique  priStkCode  values for which at least one row exists with False in  priPriceConfirmed .'], ['Then you can select the matching  tblPriData  rows with an  INNER JOIN  to that query.']], [[' SELECT DISTINCT priStkCode\nFROM tblPriData\nWHERE priPriceConfirmed = False;\n']], ['Access query to return several similar records when one is flagged'], 2, 0], [(20707736, 1), [['Then you can select the matching  tblPriData  rows with an  INNER JOIN  to that query.'], ['-10000']], [[' SELECT pd.*\nFROM\n    tblPriData AS pd\n    INNER JOIN\n    (\n        SELECT DISTINCT priStkCode\n        FROM tblPriData\n        WHERE priPriceConfirmed = False\n    ) AS sub\n    ON pd.priStkCode = sub.priStkCode;\n']], ['Access query to return several similar records when one is flagged'], 2, 0], [(20757884, 0), [['The easiest option is to have a  calendar table , with a last day of the month flag, so your query would simply be:'], ["Assuming of course that you don't have a calendar table you can generate a list of dates on the fly:'"]], [[' SELECT  *\nFROM    dbo.Calendar\nWHERE   Date >= @StartDate\nAND     Date <= @EndDate\nAND     EndOfMonth = 1;\n']], ['Calculate last days of months for given period in SQL Server'], 3, 0], [(20757884, 1), [["Assuming of course that you don't have a calendar table you can generate a list of dates on the fly:'"], ['Then once you have your dates you can limit them to where the date is the last day of the month (where adding one day makes it the first of the month):']], [[" DECLARE @s_date DATE = '20130101',\n        @e_date DATE = '20130601';\n\nSELECT  Date = DATEADD(DAY, ROW_NUMBER() OVER(ORDER BY Object_ID) - 1, @s_date)\nFROM    sys.all_objects;\n"]], ['Calculate last days of months for given period in SQL Server'], 3, 0], [(20757884, 2), [['Then once you have your dates you can limit them to where the date is the last day of the month (where adding one day makes it the first of the month):'], ['Example on SQL Fiddle']], [[" DECLARE @s_date DATE = '20130101',\n        @e_date DATE = '20130601';\n\nWITH Dates AS\n(   SELECT  Date = DATEADD(DAY, ROW_NUMBER() OVER(ORDER BY Object_ID) - 1, @s_date)\n    FROM    sys.all_objects\n)\nSELECT  *\nFROM    Dates\nWHERE   Date <= @e_Date\nAND     DATEPART(DAY, DATEADD(DAY, 1, Date)) = 1;\n"]], ['Calculate last days of months for given period in SQL Server'], 3, 0], [(20783264, 0), [['Try this: '], ['OR']], [[" DELETE FROM posts \nWHERE id IN (SELECT id \n             FROM (SELECT post_title, MAX(id) id \n                   FROM posts \n                   WHERE post_title IN ('abc', 'xyz') \n                   GROUP BY post_title \n                  ) A \n            )\n"]], ['Making select and delete queries as single statement'], 2, 1], [(20783264, 1), [['OR'], ['-10000']], [[" DELETE FROM posts \nWHERE id IN (SELECT id \n             FROM (SELECT post_title, id \n                   FROM posts \n                   WHERE post_title IN ('abc', 'xyz') \n                   ORDER BY post_title, id DESC\n                 ) A \n            GROUP BY post_title)\n"]], ['Making select and delete queries as single statement'], 2, 1], [(20792891, 0), [['I guess you can make use of ROW_NUMBER Function something like this ....'], ['Your Query']], [[' ;WITH OrderedData\n AS\n (\n  SELECT * , rn = ROW_NUMBER() OVER (ORDER BY SomeColumn)\n  FROM Table_Name\n )\nSELECT * FROM OrderedData\nWHERE rn >= @LowerLimit AND rn <= @UpperLimit\n']], ['Selecting Spicific data placed in the middle of the database table'], 4, 1], [(20792891, 1), [['Your Query'], ['Your Stored Procedure']], [[' select * from articles \nwhere articleid between @indexOfSelection AND @LimitOfselection\n']], ['Selecting Spicific data placed in the middle of the database table'], 4, 0], [(20792891, 3), [['To Select A range Of Rows'], ['-10000']], [[' CREATE PROCEDURE ordered_articles \n@LowerBound int, \n@UpperBound int \nAS \nBEGIN\n  SET NOCOUNT ON;\nWITH OrderedData\nAS\n (\n  SELECT * , rn = ROW_NUMBER() OVER (ORDER BY articleid)\n  FROM articles\n )\nSELECT * FROM OrderedData\nWHERE rn >= @LowerBound AND rn <= @UpperBound\n\nEND\n\n EXECUTE ordered_articles 10, 15  --<-- this will return 10 to 15 number row ordered by ArticleID\n']], ['Selecting Spicific data placed in the middle of the database table'], 4, 1], [(20794860, 0), [['Try this: '], ['OUTPUT']], [[" SELECT '129387 store' REGEXP '^[0-9]* store$';\n\nSELECT * FROM shop WHERE `name` REGEXP '^[0-9]+ store$';\n"]], ['regex in SQL to detect one or more digit'], 2, 1], [(20794860, 1), [['OUTPUT'], ['-10000']], [[' |         NAME |\n|--------------|\n| 129387 store |\n']], ['regex in SQL to detect one or more digit'], 2, 0], [(20830315, 0), [['This query gives a  running total (month to end-of-week date)  ordered by Representative_Id, Week'], ['-10000']], [[' SELECT a.Representative_ID, l.month, l.Week, Count(*) AS Total_Week_Activity_Count\n    ,(SELECT  count(*)\n        FROM ACTIVITIES_FACT a2\n        INNER JOIN LU_TIME l2 ON a2.Date = l2.Date\n        AND a.Representative_ID = a2.Representative_ID\n        WHERE l2.week <=  l.week\n        AND l2.month = l.month) Month_To_Date_Activities_Count\nFROM ACTIVITIES_FACT a\nINNER JOIN LU_TIME l ON a.Date = l.Date\nGROUP BY a.Representative_ID, l.Week, l.month\nORDER BY a.Representative_ID, l.Week\n']], ['How to calculate running total (month to date) in SQL Server 2008'], 2, 1], [(20830315, 1), [['-10000'], ['SQL Fiddle Sample']], [[' | REPRESENTATIVE_ID | MONTH | WEEK | TOTAL_WEEK_ACTIVITY_COUNT | MONTH_TO_DATE_ACTIVITIES_COUNT |\n|-------------------|-------|------|---------------------------|--------------------------------|\n|                40 |     7 | 7/08 |                         1 |                              1 |\n|                40 |     8 | 8/09 |                         1 |                              1 |\n|                40 |     8 | 8/10 |                         1 |                              2 |\n|                41 |     7 | 7/08 |                         2 |                              2 |\n|                41 |     8 | 8/08 |                         4 |                              4 |\n|                41 |     8 | 8/09 |                         3 |                              7 |\n|                41 |     8 | 8/10 |                         1 |                              8 |\n']], ['How to calculate running total (month to date) in SQL Server 2008'], 2, 0], [(20838921, 0), [['You can use  OUTER APPLY :'], ['Or a  correlated subquery :']], [[' CREATE TABLE #T (Amount INT);\nINSERT #T (Amount) VALUES (1), (2), (3), (4), (5), (6), (7);\n\nSELECT  T.Amount, T2.Amount\nFROM    #T T\n        OUTER APPLY\n        (   SELECT  Amount = SUM(Amount)\n            FROM    #T T2\n            WHERE   T2.Amount <= T.Amount\n        ) T2;\n\nDROP TABLE #T;\n']], ['Add values from the previous row of one column to another column in current row'], 9, 1], [(20838921, 1), [['Or a  correlated subquery :'], ['First I just wrote out a query that was exactly what the logic was, essentially:']], [[' CREATE TABLE #T (Amount INT);\nINSERT #T (Amount) VALUES (1), (2), (3), (4), (5), (6), (7);\n\nSELECT  T.Amount, \n        (   SELECT  Amount = SUM(Amount)\n            FROM    #T T2\n            WHERE   T2.Amount <= T.Amount\n        ) \nFROM    #T T\n\nDROP TABLE #T;\n']], ['Add values from the previous row of one column to another column in current row'], 9, 1], [(20838921, 2), [['First I just wrote out a query that was exactly what the logic was, essentially:'], ['So by copy and pasting the formula from the previous line I got to:']], [[' f(x) = x - f(x - 1);\n']], ['Add values from the previous row of one column to another column in current row'], 9, 0], [(20838921, 3), [['So by copy and pasting the formula from the previous line I got to:'], ['I then expanded out all the parentheses to give:']], [[' SELECT  [1] = 1,\n        [2] = 2 - 1,\n        [3] = 3 - (2 - 1),\n        [4] = 4 - (3 - (2 - 1)),\n        [5] = 5 - (4 - (3 - (2 - 1))),\n        [6] = 6 - (5 - (4 - (3 - (2 - 1)))),\n        [7] = 7 - (6 - (5 - (4 - (3 - (2 - 1)))));\n']], ['Add values from the previous row of one column to another column in current row'], 9, 0], [(20838921, 4), [['I then expanded out all the parentheses to give:'], ['This means you need to find out the position of each value to work out whether or not to add or subtract it. So using this:']], [[' SELECT  [1] = 1,\n        [2] = 2 - 1,\n        [3] = 3 - 2 + 1,\n        [4] = 4 - 3 + 2 - 1,\n        [5] = 5 - 4 + 3 - 2 + 1,\n        [6] = 6 - 5 + 4 - 3 + 2 - 1,\n        [7] = 7 - 6 + 5 - 4 + 3 - 2 + 1;\n']], ['Add values from the previous row of one column to another column in current row'], 9, 0], [(20838921, 5), [['This means you need to find out the position of each value to work out whether or not to add or subtract it. So using this:'], ['You end up with:']], [[' SELECT  T.Amount, \n        T2.RowNum,\n        T2.Amount\nFROM    #T T\n        OUTER APPLY\n        (   SELECT  Amount, RowNum = ROW_NUMBER() OVER(ORDER BY Amount DESC)\n            FROM    #T T2\n            WHERE   T2.Amount < T.Amount\n        ) T2\nWHERE   T.Amount IN (4, 5)\n']], ['Add values from the previous row of one column to another column in current row'], 9, 0], [(20838921, 6), [['You end up with:'], ['So remembering the previous formala for these two:']], [[' Amount  RowNum  Amount\n-------------------------\n4       1       3\n4       2       2\n4       3       1\n-------------------------\n5       1       4\n5       2       3\n5       3       2\n5       4       1\n']], ['Add values from the previous row of one column to another column in current row'], 9, 0], [(20838921, 7), [['So remembering the previous formala for these two:'], ["We can see that where RowNum is odd we need to - the second amount, where it is even we need to add it. We can't use ROW_NUMBER() inside a SUM function, so we then need to perform a second aggregate, giving a final query of:"]], [[' [4] = 4 - 3 + 2 - 1,\n[5] = 5 - 4 + 3 - 2 + 1,\n']], ['Add values from the previous row of one column to another column in current row'], 9, 0], [(20838921, 8), [["We can see that where RowNum is odd we need to - the second amount, where it is even we need to add it. We can't use ROW_NUMBER() inside a SUM function, so we then need to perform a second aggregate, giving a final query of:"], ['Example on SQL Fiddle']], [[' SELECT  T.Amount, \n        Subtraction = T.Amount - SUM(ISNULL(T2.Amount, 0))\nFROM    #T T\n        OUTER APPLY\n        (   SELECT  Amount = CASE WHEN ROW_NUMBER() OVER(ORDER BY Amount DESC) % 2 = 0 THEN -Amount ELSE Amount END\n            FROM    #T T2\n            WHERE   T2.Amount < T.Amount\n        ) T2\nGROUP BY T.Amount;\n']], ['Add values from the previous row of one column to another column in current row'], 9, 1], [(20922520, 0), [['Oracle 11g R2 Schema Setup :'], ['Query 1 :']], [[' CREATE TABLE Test ( A, B, C, D, E ) AS\nSELECT LEVEL, LEVEL * 500, SQRT( LEVEL ), CHR( 64 + LEVEL ), RPAD( CHR( 64 + LEVEL ), 8, CHR( 64 + LEVEL ) )\nFROM DUAL\nCONNECT BY LEVEL <= 26\n/\n\nCREATE TYPE Test_Record AS OBJECT (\n  A NUMBER,\n  B NUMBER,\n  C NUMBER,\n  D CHAR(1),\n  E CHAR(8)\n)\n/\n\nCREATE TYPE Test_Record_Table AS TABLE OF Test_Record\n/\n\nCREATE PROCEDURE get_Table_Of_Test_Records (\n  p_records OUT Test_Record_Table\n)\nIS\nBEGIN\n  SELECT Test_Record( A, B, C, D, E )\n  BULK COLLECT INTO p_records\n  FROM   Test;\nEND get_Table_Of_Test_Records;\n/\n']], ['Select data from rows into collection of oracle udt objects'], 2, 0], [(20922520, 1), [['Query 1 :'], ['-10000']], [[' DECLARE\n  trt Test_Record_Table;\nBEGIN\n  get_Table_Of_Test_Records( trt );\n\n  -- Do something with the collection.\nEND;\n']], ['Select data from rows into collection of oracle udt objects'], 2, 1], [(20935221, 0), [['How about'], ['That would give you a record per person, and the merge_id will be ascending:']], [[' SELECT firstname, lastname, merge_id \nFROM table t\nORDER BY t.merge_id\n']], ['SQL - select a list of lists'], 4, 1], [(20935221, 1), [['That would give you a record per person, and the merge_id will be ascending:'], ['Otherwise, you can use GROUP_CONCAT:']], [[' 1 | Jane Doe \n1 | John Doe\n2 | max payne\n3 | sub zero\n']], ['SQL - select a list of lists'], 4, 0], [(20935221, 2), [['Otherwise, you can use GROUP_CONCAT:'], ['Which will give one record per merge_id:']], [[" SELECT merge_id , GROUP_CONCAT(CONCAT(firstname, ' ', lastname))\nFROM table t\nGROUP BY t.merge_id\nORDER BY t.merge_id\n"]], ['SQL - select a list of lists'], 4, 1], [(20935221, 3), [['Which will give one record per merge_id:'], ['-10000']], [[' 1 | Jane Doe, John Doe\n2 | max payne\n3 | sub zero\n']], ['SQL - select a list of lists'], 4, 0], [(20935240, 0), [['Test Data'], ['Query']], [[' DECLARE @t TABLE (x NUMERIC(10,2), y NUMERIC(10,2), radius NUMERIC(10,2))\nINSERT INTO @t\nVALUES (3.5,3.5, 5.5),(20.5,20.5, 10.5), (30.5,30.5, 20.5)\n']], ['Point exist in circle'], 4, 0], [(20935240, 2), [['Result Set'], ['As question was closed, could not add another answer, so I edited this to include solution using Sql Server  Geometry  types... [Uses same data points as above, plus one to demo exactly on the circle]']], [[' ╔═══════╦═══════╦════════╦════════════════════╗\n║   x   ║   y   ║ radius ║   Inside/Outside   ║\n╠═══════╬═══════╬════════╬════════════════════╣\n║ 3.50  ║ 3.50  ║ 5.50   ║ Inside The Circle  ║\n║ 20.50 ║ 20.50 ║ 10.50  ║ Outside the Circle ║\n║ 30.50 ║ 30.50 ║ 20.50  ║ Outside the Circle ║\n╚═══════╩═══════╩════════╩════════════════════╝\n']], ['Point exist in circle'], 4, 0], [(20954662, 0), [['You can do this with nested subqueries:'], ['You can also do this by joining pre-aggregated queries:']], [[' select u.user_id, count(*) as numusers,\n       (SELECT COUNT(user_id), FROM visitors v WHERE v.user_id = u.user_id) as NumVisitors,\n       (SELECT SUM(amount) FROM visitors v WHERE v.user_id = u.user_id) as VisitorAmount,\n       (SELECT COUNT(user_id) FROM sales s WHERE s.user_id = u.user_id) as NumSales\nfrom users u\ngroup by u.user_id;\n']], ['Merge queries into 1 for sorting'], 2, 1], [(20954662, 1), [['You can also do this by joining pre-aggregated queries:'], ['-10000']], [[' select u.user_id, v.NumVisitors, v.VisitorAmount, s.NumSales\nfrom (select u.user_id, count(*) as NumUsers\n      from users u\n      group by u.user_id\n     ) u left outer join\n     (select v.user_id, count(user_id) as NumVisitors, sum(amount) as VisitorAmount\n      from visitors v\n      group by v.user_id\n     ) v\n     on u.user_id = v.visitor_id left outer join\n     (select s.user_id, count(user_id) as NumSales\n      from sales s\n      group by s.user_id\n     ) s\n     on s.user_id = u.user_id;\n']], ['Merge queries into 1 for sorting'], 2, 1], [(21075815, 0), [['Assuming you are coding an app wherein the user supplies the inputs, there are multiple ways to create a query that uses those values as variables - one way is as follows:'], ['So for your particular case, replacing all the instances of  X  with the MySQL syntax for a user-defined variable  @X , it would look something like this:']], [[' SET @t1=1, @t2=2, @t3:=4;\nSELECT @t1, @t2;\n']], ['Interactive Query'], 2, 1], [(21075815, 1), [['So for your particular case, replacing all the instances of  X  with the MySQL syntax for a user-defined variable  @X , it would look something like this:'], ['-10000']], [[" SET @X = user_input;\nSELECT @X AS DISTANCE,\nSUM(ABS(LOCX) <= @X AND ABS(LOCY) <= @X) AS QUANTITY,\nCOUNT(*) AS TOTAL,\nCONCAT(AVG(ABS(LOCX) <= @X AND ABS(LOCY) <= @X)*100, '%') AS PERCENTAGE\nFROM CUSTOMER;\n"]], ['Interactive Query'], 2, 1], [(21136618, 0), [['with   '], ['you can get the the structure. This you can modify and create your new table. And finally you can   ']], [[" SELECT sql FROM sqlite_master WHERE type='table' AND name='mytable' \n"]], ['SQLite create table from table'], 2, 0], [(21136618, 1), [['you can get the the structure. This you can modify and create your new table. And finally you can   '], ['-10000']], [[" INSERT INTO 'MyTableCopy' (*) SELECT * FROM 'mytable'\n"]], ['SQLite create table from table'], 2, 0], [(21167225, 0), [['This is one of the times you need to denormalise. Create a table'], ['You can then use:']], [[' create table PreProcessedTotal (\n   JaccardTotal decimal(18, 4) not null\n)\n']], ['Select from table during update'], 2, 0], [(21167225, 1), [['You can then use:'], ["The  with (nolock)  may not be needed. You'll also need to populate the PreProcessedTotal table with the current total when you put it live."]], [[' select Jaccard / JaccardTotal\nfrom Preprocessed with (nolock)\ncross join PreProcessedTotal with (nolock)\n']], ['Select from table during update'], 2, 0], [(21234177, 0), [['-10000'], ['Result:']], [[' CREATE TABLE T1 (A decimal(8,0), B int, C decimal(8,0))\nINSERT INTO T1 (A, B, C) VALUES (123, 0, 20130101),\n(123, 0, 20130102),(123, 1, 20130103),\n(123, 1, 20130104),(123, 0, 20130105),\n(123, 2, 20130106),(123, 2, 20130107),\n(123, 2, 20130108),(123, 0, 20130109),\n(123, 3, 20130110),(123, 3, 20130111),\n(123, 3, 20130112),(123, 3, 20130113)\n\n\n;with x as\n(\n  select t1.A, t1.B, t1.C, \n  row_number() over (partition by a order by c) rn \n  from T1\n)\nselect x1.A, x1.B, x1.C \nfrom x x1\nleft join x x2\non x1.rn = x2.rn +1 and x1.A = x2.A\nwhere x2.A is null\nor x1.B <> x2.B\n']], ['Find first rows of change in historical table'], 2, 1], [(21234177, 1), [['Result:'], ['-10000']], [[' A   B   C\n123 0   20130101\n123 1   20130103\n123 0   20130105\n123 2   20130106\n123 0   20130109\n123 3   20130110\n']], ['Find first rows of change in historical table'], 2, 0], [(21250631, 1), [['The unpivot process will convert your multiple columns into multiple rows of data.  You did not specify what version of SQL Server you are using but you can use a  SELECT  with  UNION ALL  with  CROSS APPLY  or even the  UNPIVOT  function to perform the first conversion:'], ['See  SQL Fiddle with Demo . This converts your data into the format:']], [[" select col = col + cast(rowid as varchar(10)), value\nfrom yourtable\ncross apply \n(\n  select 'First', First union all\n  select 'Last', Last\n) c (col, value)\n"]], ['SQL Server - PIVOT - two columns into rows'], 5, 0], [(21250631, 2), [['See  SQL Fiddle with Demo . This converts your data into the format:'], ['Once the data is in multiple rows, then you can easily apply the PIVOT function:']], [[' |    COL |       VALUE |\n|--------|-------------|\n| First1 | RandomName1 |\n|  Last1 | RandomLast1 |\n| First2 | RandomName2 |\n|  Last2 | RandomLast2 |\n']], ['SQL Server - PIVOT - two columns into rows'], 5, 0], [(21250631, 4), [['Both give a result of:'], ['-10000']], [[' |      FIRST1 |       LAST1 |      FIRST2 |       LAST2 |      FIRST3 |       LAST3 |      FIRST4 |       LAST4 |      FIRST5 |       LAST5 |\n|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|\n| RandomName1 | RandomLast1 | RandomName2 | RandomLast2 | RandomName3 | RandomLast3 | RandomName4 | RandomLast4 | RandomName5 | RandomLast5 |\n']], ['SQL Server - PIVOT - two columns into rows'], 5, 0], [(21251963, 0), [['Could it be as simple as:'], ['Or, just add stuff to the partition by clause:']], [[' SELECT DISTINCT Code, Stuff FROM MyTable\n']], ['Select Single and Duplicate Row and Return Multiple Columns'], 2, 1], [(21251963, 1), [['Or, just add stuff to the partition by clause:'], ['-10000']], [[' PARTITION BY Code,Stuff ORDER BY Code\n']], ['Select Single and Duplicate Row and Return Multiple Columns'], 2, 1], [(21259677, 0), [['-10000'], ['-10000']], [[' if (file != null && file.ContentLength > 0)\n            {\n                string contentType = file.ContentType;\n\n                byte[] fileData = new byte[file.InputStream.Length];\n                file.InputStream.Read(fileData, 0, fileData.Length);\n\n                string OriginalName = Path.GetFileName(file.FileName);\n                string Username = User.Identity.Name;\n\n                Models.File myFile = new Models.File(contentType, OriginalName, fileData, Username);\n                myFile.Save();\n            }\n']], ['How to store Word documents in SQL Server 2008?'], 2, 0], [(21259677, 1), [['-10000'], ['-10000']], [['    public ActionResult Download()\n    {\n        string Originalname = string.Empty;\n        byte[] FileData = null;\n        var requestedID = RouteData.Values["id"];\n        if (requestedID.ToString() != null)\n        {\n            Guid id = new Guid(requestedID.ToString());\n            DataSet ds = new DataSet();\n            Models.UsersGroups dt = new Models.UsersGroups();\n            ds = dt.GetItem(id);\n            foreach (DataRow item in ds.Tables[0].Rows)\n            {\n                Originalname = item["OriginalName"].ToString();\n                FileData = (byte[])item["FileData"];\n            }\n            Response.AppendHeader("Content-Disposition", "attachment;filename=\\"" + Originalname + "\\"");\n            Response.BinaryWrite(FileData);\n        }\n        return File(FileData, "application/x-unknown");\n    }\n']], ['How to store Word documents in SQL Server 2008?'], 2, 0], [(21270528, 0), [["Don't - leave  Member Name  in the member table.  There should not be any reason to have a  Member Name  field in the  Member_Fees_Record  table if you can join it back to  Member  through the ID:"], ['Example query:']], [[' Member (Member ID, Member_Name, Age, Address)\n\nMember_Fees_Record (Member ID, Fee)\n']], ['How to add more than one foreign key?'], 2, 0], [(21270528, 1), [['Example query:'], ['-10000']], [[' SELECT m.MemberId, f.Fee, m.Member_Name, m.Address, m.Age\nFROM Member m\nINNER JOIN Member_Fees_Record mf ON m.MemberID = f.MemberID\n']], ['How to add more than one foreign key?'], 2, 1], [(21280605, 0), [['You can enumerate selected items in each ListBox and build the SQL. Something like this'], ['And the function GetValuesFromList:']], [[' sql = "UPDATE tableName SET ColumnToUpdate = \'" & txtZ & "\' "\nsql = sql & "WHERE Column1 IN (" & GetValuesFromList(listBoxX) & ") "\nsql = sql & "AND Column2 IN (" & GetValuesFromList(listBoxy) & ")"\n']], ['Update Multiple SQL Server Columns from Access 2010 Form'], 2, 0], [(21280605, 1), [['And the function GetValuesFromList:'], ['If the selected values in the list boxes are string values, you should modify the function to concatenate the quotes.']], [[' Private Function GetValuesFromList(ListBox lst) as String\nDim Items As String\nDim Item As Variant\n\n    Items = ""\n    For Each Item In lst.ItemsSelected\n        Items = Items & lst.ItemData(Item) & ","\n    Next\n    GetValuesFromList = Left(Items, Len(Items) - 1)\nEnd Function\n']], ['Update Multiple SQL Server Columns from Access 2010 Form'], 2, 0], [(21281481, 0), [['MySQL RIGHT() extracts a specified number of characters from the right side of a string.'], ['Or']], [[' UPDATE user SET phone_last_ten = RIGHT(phone, 10) \n']], ['making a new column with last 10 digits of an other colulmn'], 2, 1], [(21281481, 1), [['Or'], ['-10000']], [[' UPDATE user SET phone_last_ten = RIGHT(CONVERT(Phone, CHAR(50)), 10) \n']], ['making a new column with last 10 digits of an other colulmn'], 2, 1], [(21286642, 0), [['You can use the  substring_index() / group_concat()  trick:'], ['If you just want the  last  record from b, you can do:']], [[" select a.title,\n       substring_index(group_concat(status order by id desc), ',', 1) as laststatus\nfrom b join\n     a\n     on a.id - b.a_id\ngroup by a.title;\n"]], ['Return latest row ordered by ID while using group by'], 2, 1], [(21286642, 1), [['If you just want the  last  record from b, you can do:'], ['-10000']], [[' select a.title, b.status\nfrom b join\n     a\n     on a.id - b.a_id\norder by b.id desc\nlimit 1;\n']], ['Return latest row ordered by ID while using group by'], 2, 1], [(21286804, 0), [['It is possible that this or a variation may suit:'], ['For example:']], [['  SELECT t.Field1, Mid([Field1],InStr([field1],"(")+1,4) AS Stripped\n FROM TheTable As t\n']], ['How to select only numbers from a text field'], 3, 1], [(21286804, 1), [['For example:'], ['If the field ends  u) , that is, alpha bracket, you can say:']], [['  UPDATE TheTable AS t SET [field2] = Mid([Field1],InStr([field1],"(")+1,4);\n']], ['How to select only numbers from a text field'], 3, 1], [(21302307, 0), [['1) rename the tables you need to migrate'], ['2) create all your migrations with your  and migrate them:']], [[' php artisan migrate:make\n']], ['How to migrate from CodeIgniter database to Laravel database'], 5, 0], [(21302307, 1), [['2) create all your migrations with your  and migrate them:'], ['3) use your database server sql utility to copy data from one table to another, it will be way faster than creating everything in Laravel, believe me. Most databases will let you do things like:']], [[' php artisan migrate\n']], ['How to migrate from CodeIgniter database to Laravel database'], 5, 0], [(21302307, 2), [['3) use your database server sql utility to copy data from one table to another, it will be way faster than creating everything in Laravel, believe me. Most databases will let you do things like:'], ["And in some you'll be able to do the same using two different databases and columns names"]], [[' INSERT INTO users (FirstName, LastName)\nSELECT FirstName, LastName\nFROM users_old\n']], ['How to migrate from CodeIgniter database to Laravel database'], 5, 0], [(21302307, 3), [["And in some you'll be able to do the same using two different databases and columns names"], ['Or you can just export data to a CSV file and then create a method in your Laravel seeding class to load that data into your database, with a lot of data to import, you just have to remember to execute:']], [[" INSERT INTO NEWdatabasename.users (firstName+' '+Lastname, email)\nSELECT name, email\nFROM OLDdatabasename.\n"]], ['How to migrate from CodeIgniter database to Laravel database'], 5, 0], [(21302307, 4), [['Or you can just export data to a CSV file and then create a method in your Laravel seeding class to load that data into your database, with a lot of data to import, you just have to remember to execute:'], ["So your PHP doesn't run out of memory."]], [[' DB::disableQueryLog();\n']], ['How to migrate from CodeIgniter database to Laravel database'], 5, 0], [(21311393, 0), [['Lets create a database named [test] based on model.'], ['Lets create a table type named [InputToLinearReg].']], [[" --\n-- Create a simple db\n--\n\n-- use master\nuse master;\ngo\n\n-- delete existing databases\nIF EXISTS (SELECT name FROM sys.databases WHERE name = N'Test')\nDROP DATABASE Test\nGO\n\n-- simple db based on model\ncreate database Test;\ngo\n\n-- switch to new db\nuse [Test];\ngo\n"]], ['MS SQL - User Defined Function - Slope Intercept RSquare ; How to Group by Portfolio'], 4, 0], [(21311393, 1), [['Lets create a table type named [InputToLinearReg].'], ["Okay, here is the multi-layered SELECT statement that uses CTE's.  The query analyzer treats this as a SQL statement which can be executed in parallel versus a regular function that can't.  See the black box section of Wayne's article."]], [[" --\n-- Create table type to pass data\n--\n\n-- Delete the existing table type\nIF  EXISTS (SELECT * FROM sys.systypes WHERE name = 'InputToLinearReg')\nDROP TYPE dbo.InputToLinearReg\nGO\n\n--  Create the table type\nCREATE TYPE InputToLinearReg AS TABLE\n(\nportfolio_cd char(1),\nmonth_num int,\ncollections_amt money\n);\ngo\n"]], ['MS SQL - User Defined Function - Slope Intercept RSquare ; How to Group by Portfolio'], 4, 0], [(21311393, 3), [['Last but not least, setup a Table Variable and get the answers.  Unlike you solution above, it groups by portfolio id.'], ['Here is a picture of the results using your data.']], [[" -- Load data into variable\nDECLARE @InTable AS InputToLinearReg;\n\n-- insert data\ninsert into @InTable\nvalues\n('A', 1, 100.00),\n('A', 2, 90.00),\n('A', 3, 80.00),\n('A', 4, 70.00),\n('B', 1, 100.00),\n('B', 2, 90.00),\n('B', 3, 80.00);\n\n-- show data\nselect * from CalculateLinearReg(@InTable)\ngo\n"]], ['MS SQL - User Defined Function - Slope Intercept RSquare ; How to Group by Portfolio'], 4, 0], [(21313983, 1), [["To get the quantity, let's join back to this:"], ['No accounting for bad date formats.  Here is a version for this situation:']], [[' select tt.*\nfrom timtest tt join\n     (select itemcode,\n             coalesce(min(case when qty_available > 0 then date end), min(date)) as thedate\n      from timtest tt\n      where date >= date(now())\n      group by itemcode\n     ) id\n     on tt.itemcode = id.itemcode and tt.date = id.thedate;\n']], ['How to return only 1 (specific) instance of column value when multiple instances exist'], 3, 1], [(21313983, 2), [['No accounting for bad date formats.  Here is a version for this situation:'], ['Advice for the future:  store dates in the database as a date/datetime data time and not as strings.  If you  have  store store them as strings, use the YYYY-MM-DD format, because you can use comparisons and  order by .']], [[" select tt.*\nfrom timtest tt join\n     (select itemcode,\n             coalesce(min(case when qty_available > 0 then thedate end), min(thedate)) as thedate\n      from (select tt.*, str_to_date(date, '%m/%d/%Y') as thedate\n            from timtest tt\n           ) tt\n      where thedate >= date(now())\n      group by itemcode\n     ) id\n     on tt.itemcode = id.itemcode and str_to_date(tt.date, '%m/%d/%Y') = id.thedate;\n"]], ['How to return only 1 (specific) instance of column value when multiple instances exist'], 3, 1], [(21352556, 0), [['The generic SQL approach is to use conditional aggregation:'], ['The Access query is:']], [[" select s.studentName,\n       max(case when s.subjectName = 'subject1' then g.grade end) as Subject1,\n       max(case when s.subjectName = 'subject2' then g.grade end) as Subject2,\n       max(case when s.subjectName = 'subject3' then g.grade end) as Subject3\nfrom (students s join\n      grades g\n      on s.student_id = g.student_id\n     ) join\n     subjects su\n     on g.subject_id = su.subject_id\ngroup by s.studentid, s.studentName;\n"]], ['Using unique records as table header'], 2, 1], [(21352556, 1), [['The Access query is:'], ['-10000']], [[" select s.studentName,\n       max(iif(s.subjectName = 'subject1', grade,  NULL)) as Subject1,\n       max(iif(s.subjectName = 'subject2', grade,  NULL)) as Subject2,\n       max(iif(s.subjectName = 'subject3', grade,  NULL)) as Subject3\nfrom students s inner join\n     grades g\n     on s.student_id = g.student_id inner join\n     subjects su\n     on g.subject_id = su.subject_id\ngroup by s.studentid, s.studentName;\n"]], ['Using unique records as table header'], 2, 1], [(21367807, 0), [['Try one of following solutions:'], ['or    ']], [[' SELECT  src.Id, src.FirstName, src.LastName, src.Comment, src.InsertAt\nFROM \n(\n    SELECT  s.Id, s.FirstName, s.LastName, sc.Comment, sc.InsertAt,\n            ROW_NUMBER() OVER(PARTITION BY sc.StudentId ORDER BY sc.InsertAt DESC) RowNum\n    FROM    dbo.Students s INNER JOIN dbo.StudentComments sc ON s.Id = sc.StudentId\n    --WHERE sc.IsPublished = 1\n) src\nWHERE   src.RowNum = 1; \n']], ['How to select last published comment created by student?'], 2, 1], [(21367807, 1), [['or    '], ['-10000']], [[' SELECT  s.Id, s.FirstName, s.LastName, lc.Comment, lc.InsertAt\nFROM    dbo.Students s \nCROSS APPLY (\n    SELECT  TOP(1) sc.Comment, sc.InsertAt\n    FROM    dbo.StudentComments sc \n    WHERE   s.Id = sc.StudentId\n    --AND       sc.IsPublished = 1\n    ORDER BY sc.InsertAt DESC\n) lc; -- Last comment\n']], ['How to select last published comment created by student?'], 2, 1], [(21384239, 1), [['My guess is you need to group by room and property fields, using the max aggregate function for address and city fields, because a property (building) can have multiple addresses, one for each entrance...'], ['-10000']], [[' SELECT \n     premises.field_1\n    ,premises.field_2\n    ,premises.field_3\n\n    ,room.field_1\n    ,room.field_2\n    ,room.field_3\n\n    ,max(address.field1) as adr_f1\n    ,max(address.field2) as adr_f2\n    ,max(address.field3) as adr_f3   \nFROM Whatever\n\nJOIN WHATEVER\n\nWHERE (1=1) \nAND (whatever)\n\nGROUP BY \n\n     premises.field_1\n    ,premises.field_2\n    ,premises.field_3\n\n    ,room.field_1\n    ,room.field_2\n    ,room.field_3\n\nHAVING (WHATEVER)\n\nORDER BY premises.field_x, room.field_y\n']], ['SQL Query to show all available rooms under a property'], 2, 1], [(21389431, 0), [['Either:'], ['Or:']], [[' select min(stamp) from tbl\n']], ['how do I know the minimum date in a query?'], 4, 1], [(21389431, 1), [['Or:'], ['If you need the date in the stamp, cast it:']], [[' select stamp from tbl order by stamp asc limit 1\n']], ['how do I know the minimum date in a query?'], 4, 1], [(21389431, 2), [['If you need the date in the stamp, cast it:'], ['Or:']], [[' select min(stamp::date) from tbl\n']], ['how do I know the minimum date in a query?'], 4, 1], [(21389431, 3), [['Or:'], ['-10000']], [[' select stamp::date from tbl order by stamp asc limit 1\n']], ['how do I know the minimum date in a query?'], 4, 1], [(21400367, 0), [["You're almost there. Just remove the  AttendanceTime  from the group by."], ['If you want the entire row (incase you have other columns) you can use something like this:']], [[' SELECT tal.PersonNo, min(tal.AttendanceTime) \n  FROM mqa.T_AttendanceLog tal\n GROUP BY tal.PersonNo;\n']], ['Separate rows based on a column that has min value'], 2, 1], [(21400367, 1), [['If you want the entire row (incase you have other columns) you can use something like this:'], ['-10000']], [[' select *\n  from mqa.T_AttendanceLog a\n where (PersonNo, AttendanceTime) in(\n         select b.PersonNo, min(b.AttendanceTime)\n           from mqa.T_AttendanceLog b\n          group by b.PersonNo);\n']], ['Separate rows based on a column that has min value'], 2, 1], [(21409033, 0), [['Change MySQL statement to be'], ['or reverse the array using PHPs reverse array function ']], [[" SELECT * FROM 'mytable' ORDER BY 'id' DESC\n"]], ['How to iterate through a table from last row to first?'], 2, 1], [(21424132, 1), [['But you  better normalize  your data by introducing a many-to-many table that may look like'], ['Your query then may look like']], [[' CREATE TABLE request_location\n(\n  request_id INT NOT NULL,\n  loc_id INT NOT NULL,\n  PRIMARY KEY (request_id, loc_id),\n  FOREIGN KEY (request_id) REFERENCES request (request_id),\n  FOREIGN KEY (loc_id) REFERENCES locations (loc_id)\n);\n']], ['Replace values in an sql query according to results of a nested query'], 4, 0], [(21438881, 0), [["Let's suppose you have the following schema"], ['Now to delete all child records knowing an email of the customer you can use multi-table delete syntax']], [[' CREATE TABLE customers\n(\n  customer_id INT, \n  customer_email VARCHAR(17),\n  PRIMARY KEY (customer_id)\n);\nCREATE TABLE child_table\n(\n  child_id INT,\n  customer_id INT, \n  value INT,\n  PRIMARY KEY (child_id),\n  FOREIGN KEY (customer_id) REFERENCES customers (customer_id)\n);\n']], ['How to pass the returned value of SELECT statement to DELETE query in stored procedure?'], 4, 0], [(21481598, 0), [['Just add this to your  WHERE  clause:'], ['Say I have the following two tables:']], [[' AND DU.das_id_fk IS NULL\n']], ['How to SELECT records from One table If Matching Record In Not Found In Other Table'], 7, 0], [(21481598, 3), [['If I want a list of  Person s that have no pets:'], ["If I want a list of all  Person s and their pets (even if they don't have pets):"]], [[' SELECT pr.PersonID, pr.`Name`\nFROM\n    Person pr\n    LEFT JOIN Pet pt ON pr.PersonID = pt.PersonID\nWHERE\n    pt.`PetID` IS NULL\n']], ['How to SELECT records from One table If Matching Record In Not Found In Other Table'], 7, 1], [(21528762, 0), [['If you only want the latest row you can turn each of your subqueries into an  APPLY :'], ['Or you can add  ROW_NUMBER()  to each of your subqueries and limit it to the top result (RowNum = 1):']], [[" SELECT  Account.Name, \n        AnnAccs.PeriodEnd AS AnnAccsPeriodEnd, \n        AnnAccs.LastPeriod AS AnnAccsLastPeriod,\n        CorpTax.PeriodEnd AS CorpTaxPeriodEnd, \n        CorpTax.LastPeriod AS CorpTaxLastPeriod,\n        SelfAss.PeriodEnd AS SAPeriodEnd, \n        SelfAss.LastPeriod AS SALastPeriod\nFROM    dbo.Account \n        OUTER APPLY\n        (   SELECT  TOP 1\n                    ca.new_PeriodEnd AS PeriodEnd, \n                    ca.new_LastPeriod AS LastPeriod, \n                    new_CorporationTaxActivityId AS AccId \n            FROM    new_corporationtaxactivity ca\n            WHERE   ca.AccId = Account.AccountId \n            ORDER BY ca.new_PeriodEnd DESC\n        ) AS CorpTax \n        OUTER APPLY\n        (   SELECT  TOP 1 aa.new_PeriodEnd AS PeriodEnd, \n                    aa.new_LastPeriod AS LastPeriod, \n                    aa.new_AnnualAccountsActivityId AS AccId \n            FROM    new_annualaccountsactivity aa\n            WHERE   aa.new_AnnualAccountsActivityId = Account.AccountId \n            ORDER BY aa.new_PeriodEnd DESC\n        ) AS AnnAccs \n        OUTER APPLY\n        (   SELECT  TOP 1 sa.new_PeriodEnd AS PeriodEnd, \n                    sa.new_LastPeriod AS LastPeriod, \n                    sa.new_SelfAssessmentActivityId AS AccId \n            FROM    new_selfassessmentactivity sa\n            WHERE   sa.new_SelfAssessmentActivityId = Account.AccountId\n            ORDER BY sa.new_PeriodEnd DESC\n        ) As SelfAss \nWHERE   (Account.new_ClientStatus = '100000000' OR Account.new_ClientStatus = '100000001')\nAND     (AnnAccs.LastPeriod = '1' OR CorpTax.LastPeriod = '1' OR SelfAss.LastPeriod = '1')\n"]], ['(Possibly) Complex Join across four tables using aggregates'], 2, 1], [(21528762, 1), [['Or you can add  ROW_NUMBER()  to each of your subqueries and limit it to the top result (RowNum = 1):'], ['-10000']], [[" SELECT  Account.Name, \n        AnnAccs.PeriodEnd AS AnnAccsPeriodEnd, \n        AnnAccs.LastPeriod AS AnnAccsLastPeriod,\n        CorpTax.PeriodEnd AS CorpTaxPeriodEnd, \n        CorpTax.LastPeriod AS CorpTaxLastPeriod,\n        SelfAss.PeriodEnd AS SAPeriodEnd, \n        SelfAss.LastPeriod AS SALastPeriod\nFROM    dbo.Account \n        LEFT JOIN \n        (   SELECT  ca.new_PeriodEnd AS PeriodEnd, \n                    ca.new_LastPeriod AS LastPeriod, \n                    ca.new_CorporationTaxActivityId AS AccId,\n                    ROW_NUMBER() OVER(PARTITION BY ca.new_CorporationTaxActivityId ORDER BY ca.new_PeriodEnd DESC) AS RowNum\n            FROM    new_corporationtaxactivity  ca\n        ) AS CorpTax \n            ON CorpTax.AccId = Account.AccountId \n            AND CorpTax.RowNum = 1\n        LEFT JOIN \n        (   SELECT  aa.new_PeriodEnd AS PeriodEnd, \n                    aa.new_LastPeriod AS LastPeriod, \n                    aa.new_AnnualAccountsActivityId AS AccId,\n                    ROW_NUMBER() OVER(PARTITION BY aa.new_AnnualAccountsActivityId ORDER BY aa.new_PeriodEnd DESC) AS RowNum\n            FROM    new_annualaccountsactivity aa\n        ) AS AnnAccs \n            ON AnnAccs.AccId = Account.AccountId\n            AND AnnAccs.RowNum = 1\n        LEFT JOIN \n        (   SELECT  sa.new_PeriodEnd AS PeriodEnd, \n                    sa.new_LastPeriod AS LastPeriod, \n                    sa.new_SelfAssessmentActivityId AS AccId,\n                    ROW_NUMBER() OVER(PARTITION BY sa.new_SelfAssessmentActivityId ORDER BY sa.new_PeriodEnd DESC) AS RowNum\n            FROM    new_selfassessmentactivity sa\n        ) As SelfAss \n            ON SelfAss.AccId = Account.AccountId\n            AND SelfAss.RowNum = 1\nWHERE   (Account.new_ClientStatus = '100000000' OR Account.new_ClientStatus = '100000001')\nAND     (AnnAccs.LastPeriod = '1' OR CorpTax.LastPeriod = '1' OR SelfAss.LastPeriod = '1');\n"]], ['(Possibly) Complex Join across four tables using aggregates'], 2, 1], [(21532604, 0), [['Using @DaveZych sample data I have managed to calculated the same results as him, using the SQL statement below:'], ['-10000']], [[' ;WITH DataSource ([StartOrEnd], [badge_no], [punch_timestamp]) AS\n(\n    SELECT ROW_NUMBER() OVER (PARTITION BY [badge_no] ORDER BY [punch_timestamp]) +\n           ROW_NUMBER() OVER (PARTITION BY [badge_no] ORDER BY [punch_timestamp])  % 2\n          ,[badge_no]\n          ,[punch_timestamp]\n    FROM #Time\n),\nTimesPerBadge_No ([badge_no], [StartOrEnd], [Minutes]) AS\n(\n    SELECT  [badge_no]\n           ,[StartOrEnd] \n           ,DATEDIFF(MINUTE, MIN([punch_timestamp]), MAX([punch_timestamp]))\n    FROM DataSource\n    GROUP BY [badge_no]\n            ,[StartOrEnd] \n)\nSELECT [badge_no]\n      ,SUM([Minutes])\nFROM TimesPerBadge_No\nGROUP BY [badge_no]\n']], ['SUM of DATEDIFF in minutes for each 2 rows'], 4, 1], [(21532604, 1), [['-10000'], ['Now, we can calculate the minutes difference in each group:']], [['  SELECT ROW_NUMBER() OVER (PARTITION BY [badge_no] ORDER BY [punch_timestamp]) +\n           ROW_NUMBER() OVER (PARTITION BY [badge_no] ORDER BY [punch_timestamp])  % 2\n          ,[badge_no]\n          ,[punch_timestamp]\n    FROM #Time\n']], ['SUM of DATEDIFF in minutes for each 2 rows'], 4, 0], [(21532604, 2), [['Now, we can calculate the minutes difference in each group:'], ['and finally sumarize the minutes for each badge_no:']], [[' SELECT  [badge_no]\n        ,[StartOrEnd] \n        ,DATEDIFF(MINUTE, MIN([punch_timestamp]), MAX([punch_timestamp]))\nFROM DataSource\nGROUP BY [badge_no]\n        ,[StartOrEnd] \n']], ['SUM of DATEDIFF in minutes for each 2 rows'], 4, 0], [(21532604, 3), [['and finally sumarize the minutes for each badge_no:'], ['']], [[' SELECT [badge_no]\n      ,SUM([Minutes])\nFROM TimesPerBadge_No\nGROUP BY [badge_no]\n']], ['SUM of DATEDIFF in minutes for each 2 rows'], 4, 0], [(21535167, 0), [["Using your sample query to populate a new table with only records from  Table1  where the  item  value wasn't in  Table2 :"], ["If you didn't want a new table and just want to add to  Table2  the records from  Table1  that aren't already there:"]], [[' SELECT a.Item \nINTO new_table2\nFROM table1 a\nLEFT JOIN Table2 b\n  ON a.item = b.item\nWHERE b.item IS NULL\n']], ['SQL Copy only data from table1 where it doesnt exist in table 2?'], 2, 1], [(21535167, 1), [["If you didn't want a new table and just want to add to  Table2  the records from  Table1  that aren't already there:"], ['-10000']], [[' INSERT INTO Table2 (Item) \nSELECT a.Item\nFROM table1 a\nLEFT JOIN Table2 b\n  ON a.item = b.item\nWHERE b.item IS NULL\n']], ['SQL Copy only data from table1 where it doesnt exist in table 2?'], 2, 1], [(21540219, 0), [['Sometimes simple is best- No need for an intro to statistics yet.  I would recommend starting with simple grouping.  Within that function you can Average, get the minimum, the Maximum and other useful bits of data.  Here are a couple of examples to get you started:'], ['Or (in case you want month data included)']], [['     SELECT Table1.State, Table1.Yr, Count(Table1.Price) AS CountOfPrice, Min(Table1.Price) AS MinOfPrice, Max(Table1.Price) AS MaxOfPrice, Avg(Table1.Price) AS AvgOfPrice\nFROM Table1\nGROUP BY Table1.State, Table1.Yr;\n']], ['Finding Outliers In SQL'], 2, 1], [(21540219, 1), [['Or (in case you want month data included)'], ["Obviously you'll need to modify the table and field names (Just so you know though- 'Year' and 'Date' are both reserved words and best not used for field names.)"]], [['     SELECT Table1.State, Table1.Yr, Month([Dt]) AS Mnth, Count(Table1.Price) AS CountOfPrice, Min(Table1.Price) AS MinOfPrice, Max(Table1.Price) AS MaxOfPrice\nFROM Table1\nGROUP BY Table1.State, Table1.Yr, Month([Dt]);\n']], ['Finding Outliers In SQL'], 2, 1], [(21546809, 0), [['Create this function:'], ['Testing the function']], [[" create function f_parca\n(\n @name varchar(100)\n) returns varchar(max)\nas\nbegin\ndeclare @rv varchar(max) = ''\n\nif @name is not null\nselect top (len(@name)) @rv += ','+ left(@name, number + 1) \nfrom master..spt_values v\nwhere type = 'p'\n\nreturn stuff(@rv, 1,1,'')\nend\n"]], ['Split text value insert another cell'], 4, 1], [(21546809, 1), [['Testing the function'], ['Result:']], [[" select dbo.f_parca('TClausen')\n"]], ['Split text value insert another cell'], 4, 0], [(21546809, 2), [['Result:'], ['Update your table like this:']], [[' T,TC,TCl,TCla,TClau,TClaus,TClause,TClausen\n']], ['Split text value insert another cell'], 4, 0], [(21546809, 3), [['Update your table like this:'], ['-10000']], [[' UPDATE export1\nSET PARCA = dbo.f_parca(name)\n']], ['Split text value insert another cell'], 4, 0], [(21613270, 0), [['Of course. You just need a sub-query to identify the most recent record for each agent. Something like (untested):'], ["Per your comment about avoiding the nested query and handling the skipping of agentid values already seen, that's a fairly trivial client-side solution. I don't know exactly how you're handling this on the PHP side, but you'd basically want to do something like this:"]], [[" select a.eventdatetime\n        ,b.resourcename\n        ,b.extension\n        ,a.eventtype \n    from agentstatedetail as a\n        ,resource as b\n        ,team as c\n        ,(SELECT agentid, MAX(eventdatetime) AS lastevent\n           FROM agentstatedetail \n           WHERE DATE(eventdatetime) = TODAY\n           GROUP BY agentid) AS d \nwhere (a.agentid = b.resourceid) \n    and (b.assignedteamid = 10) \n    and (c.teamname like 'teamnamehere %') \n    and (d.agentid = a.agentid and a.eventdatetime = d.lastevent)\ngroup by a.eventdatetime\n    ,b.resourcename\n    ,b.extension\n    ,a.eventtype \norder by eventdatetime desc\n"]], ['Returning only the most recent values of a query'], 2, 1], [(21613270, 1), [["Per your comment about avoiding the nested query and handling the skipping of agentid values already seen, that's a fairly trivial client-side solution. I don't know exactly how you're handling this on the PHP side, but you'd basically want to do something like this:"], ["The associative array  $agent  tracks how many records have been seen for a particular agent. When that's empty, it's the first occurrence. The exact non-zero number is not really useful, we just use a post-increment for efficiency, rather than setting  $agent[$row['RESOURCENAME']]  explicitly in the loop."]], [[' $data = $db->query("select a.eventdatetime, b.resourcename, b.extension, a.eventtype\n                    from agentstatedetail as a, resource as b, team as c \n                    where date(eventdatetime) = date(current)\n                    and (a.agentid = b.resourceid) and (b.assignedteamid = 10)\n                    and (c.teamname like \'ITS Help Desk %\')\n                    group by a.eventdatetime, b.resourcename,\n                             b.extension, a.eventtype\n                    order by eventdatetime desc");\n\n$agent = Array();\n\nforeach($data as $row){\n    if(!$agent[$row[\'RESOURCENAME\']]++) {\n        echo\n        "<TR bgcolor=\'#D0D0D0\'><TD class=\'body\'>" . $row[\'RESOURCENAME\'] . \n        "<TD class=\'body\'>" . $row[\'EVENTTYPE\'] . \n        "</TD>";\n    }\n}\n']], ['Returning only the most recent values of a query'], 2, 1], [(21622435, 0), [['Query:'], ['Result:']], [[" SELECT CASE WHEN mark = 'Ford' THEN 'Ford' END AS Mark,\nCOUNT(*)\nFROM Table1 t\nWHERE mark = 'Ford'\nGROUP BY mark\nUNION ALL\nSELECT CASE WHEN mark = 'Ford' AND Transmition = 'A' \n              THEN 'including Fords with automatic transmitions' END AS Mark,\nCOUNT(*)\nFROM Table1 t\nWHERE mark = 'Ford'\nAND Transmition = 'A' \nGROUP BY CASE WHEN mark = 'Ford' AND Transmition = 'A' \n              THEN 'including Fords with automatic transmitions' END\n"]], ['SQL CASE WHEN, when i want an "including" row'], 2, 1], [(21622435, 1), [['Result:'], ['-10000']], [[' |                                        MARK | COUNT(*) |\n|---------------------------------------------|----------|\n|                                        Ford |        4 |\n| including Fords with automatic transmitions |        3 |\n']], ['SQL CASE WHEN, when i want an "including" row'], 2, 0], [(21626432, 0), [["!=/<> ''  is not the same as  IS NOT NULL ! You need this:"], ['If  Name  or  Phone  can be  NULL , you need this:']], [[" IF(Name <> '')\n    // Do some stuff\nELSE IF(Phone  <> '')\n    // Do some stuff\nELSE\n    // Do some other stuff\n"]], ['Comparing String,if it is NULL in Sql Server 2008'], 2, 1], [(21626432, 1), [['If  Name  or  Phone  can be  NULL , you need this:'], ["In SQL,  NULL  is always  <> '' . In fact, in most configurations,  NULL  is also  <> NULL ."]], [[" IF(ISNULL(Name, '') <> '')\n    // Do some stuff\nELSE IF(ISNULL(Phone, '')  <> '')\n    // Do some stuff\nELSE\n    // Do some other stuff\n"]], ['Comparing String,if it is NULL in Sql Server 2008'], 2, 1], [(21640927, 0), [['This works for sql server;'], ['Same or following should work on oracle;']], [[' delete a from newproducts as a\n where \nexists(\nselect * from newproducts b\nwhere a.id = b.id and a.date < b.date)\n']], ['remove duplicate records in oracle'], 2, 1], [(21640927, 1), [['Same or following should work on oracle;'], ['-10000']], [[' delete from newproducts a\n where \nexists(\nselect * from newproducts b\nwhere a.id = b.id and a.date < b.date)\n']], ['remove duplicate records in oracle'], 2, 1], [(21646708, 0), [['How about this:'], ['This will give you output such as:']], [[' select group_concat(name) as names, time\nfrom table t\ngroup by time\nhaving count(*) > 1;\n']], ['check which names have the same field in a database'], 2, 1], [(21646708, 1), [['This will give you output such as:'], ['Which can then format on the application side.']], [[' Names               Time\nRichard,Luigi       8:00\n. . .\n']], ['check which names have the same field in a database'], 2, 0], [(21669936, 0), [['You can select only one imageId (the minimum) per each productId by joining to filtered imageId like this :'], ['or by filtering imageId using  WHERE  clause :']], [[' SELECT p.ProductId, ProductName, i.imageId, imagePath\nFROM product p\n    INNER JOIN Image i \n        ON i.ProductId = p.ProductId\n    INNER JOIN\n        (SELECT MIN(imageId) As imageId, ProductId\n         FROM image\n         GROUP BY ProductId\n         ) o \n         ON o.imageId = i.imageId\n']], ['Join and get only single row with respect to each id'], 2, 1], [(21669936, 1), [['or by filtering imageId using  WHERE  clause :'], ['-10000']], [[' SELECT p.ProductId, ProductName, imageId, imagePath\nFROM product p\n    INNER JOIN Image i \n        ON i.ProductId = p.ProductId\nWHERE imageId IN\n    (SELECT MIN(imageId) As imageId\n     FROM image\n     GROUP BY ProductId\n     )\n']], ['Join and get only single row with respect to each id'], 2, 1], [(21692871, 0), [['I would do it using dynamic sql, but this is ( http://sqlfiddle.com/#!6/a63a6/1/0 ) the PIVOT solution:'], ['Bonus: This how PIVOT could be combined with dynamic SQL ( http://sqlfiddle.com/#!6/a63a6/7/0 ), again I would prefer to do it simpler, without PIVOT, but this is just good exercising for me :']], [[" SELECT badge, name, [AP_KDa], [AP_Match], [ADC_KDA],[ADC_Match],[TOP_KDA],[TOP_Match] FROM\n(\nSELECT badge, name, col, val FROM(\n SELECT *, Job+'_KDA' as Col, KDA as Val FROM @T \n UNION\n SELECT *, Job+'_Match' as Col,Match as Val  FROM @T\n) t\n) tt\nPIVOT ( max(val) for Col in ([AP_KDa], [AP_Match], [ADC_KDA],[ADC_Match],[TOP_KDA],[TOP_Match]) ) AS pvt\n"]], ['Combine multiple rows into multiple columns dynamically in SQL Server'], 2, 1], [(21692871, 1), [['Bonus: This how PIVOT could be combined with dynamic SQL ( http://sqlfiddle.com/#!6/a63a6/7/0 ), again I would prefer to do it simpler, without PIVOT, but this is just good exercising for me :'], ['-10000']], [[" SELECT badge, name, cast(Job+'_KDA' as nvarchar(128)) as Col, KDA as Val INTO #Temp1 FROM Temp \nINSERT INTO #Temp1 SELECT badge, name, Job+'_Match' as Col, Match as Val FROM Temp\n\nDECLARE @columns nvarchar(max)\nSELECT @columns = COALESCE(@columns + ', ', '') + Col FROM #Temp1 GROUP BY Col\n\nDECLARE @sql nvarchar(max) = 'SELECT badge, name, '+@columns+' FROM #Temp1 PIVOT ( max(val) for Col in ('+@columns+') ) AS pvt'\nexec (@sql)\n\nDROP TABLE #Temp1\n"]], ['Combine multiple rows into multiple columns dynamically in SQL Server'], 2, 1], [(21731573, 0), [['You can test it here:  http://sqlfiddle.com/#!4/d41d8/25188/0'], ['Regarding your last edit, the query below would show "0" for any amount for which there is neither a penalty nor a discount (the version of my query above would just show no rows for such a situation). You may prefer that it show zero, like this:']], [[' with discounts as\n( select 25 as from_amount, 39 as to_amount, .02 as discount from dual union all\n  select 40 as from_amount, 49 as to_amount, .05 as discount from dual union all\n  select 50 as from_amount, 99999 as to_amount, .10 as discount from dual  ) \n   , penalties as\n( select 5 as from_amount, 9 as to_amount, .10 as penalty from dual union all\n  select 10 as from_amount, 19 as to_amount, .05 as penalty from dual)\nselect discount as change\nfrom discounts\nwhere 2 between from_amount and to_amount\nunion all\nselect -penalty as change\nfrom penalties\nwhere 2 between from_amount and to_amount\nunion all\nselect -penalty as change\nfrom penalties\nwhere 2 < (select min(from_amount) from penalties)\nand from_amount = (select min(from_amount) from penalties)\n']], ['Infering missing ranges in a continuous scale'], 3, 1], [(21731573, 1), [['Regarding your last edit, the query below would show "0" for any amount for which there is neither a penalty nor a discount (the version of my query above would just show no rows for such a situation). You may prefer that it show zero, like this:'], ['If you change the SQL for that view to the below, you should get the range in between to show zero:']], [[' select discount as change\nfrom discounts\nwhere 22 between from_amount and to_amount\nunion all\nselect -penalty as change\nfrom penalties\nwhere 22 between from_amount and to_amount\nunion all\nselect -penalty as change\nfrom penalties\nwhere 22 < (select min(from_amount) from penalties)\nand from_amount = (select min(from_amount) from penalties)\nunion all\nselect 0 as change\nfrom dual\nwhere not exists (select 1 from discounts where 22 between from_amount and to_amount)\n  and not exists (select 1 from penalties where 22 between from_amount and to_amount)\n  and 22 >= (select min(from_amount) from penalties)\n']], ['Infering missing ranges in a continuous scale'], 3, 1], [(21731573, 2), [['If you change the SQL for that view to the below, you should get the range in between to show zero:'], ['-10000']], [[' select discounts.from_amount as from_amount,\n       discounts.to_amount as to_amount,\n       discounts.discount * -1 as change\n  from discounts\nunion\nselect penalties.from_amount as from_amount,\n       penalties.to_amount   as to_amount,\n       penalties.penalty     as change\n  from penalties\nunion\nselect p.to_amount + 1, d.from_amount - 1, 0 as change\n  from discounts d, penalties p\n where d.from_amount = (select min(from_amount) from discounts) and\n p.to_amount = (select max(to_amount) from penalties)\n order by from_amount desc\n']], ['Infering missing ranges in a continuous scale'], 3, 1], [(21740326, 0), [['Test Data'], ['Result Set']], [[" DECLARE @MyTable TABLE (Column1 INT,Column2 INT)\nINSERT INTO @MyTable VALUES\n(1,1),(1,2),(1,3),(2,1),(2,2),(2,3),(3,1),(3,2),(3,3)\n\nSELECT CASE\n         WHEN GROUPING(Column1) = 1 THEN 'Total'\n         ELSE CAST(Column1 AS VARCHAR(10))     --<-- Cast as Varchar\n       END  Column1\n      , SUM(Column2) AS MySum\nFROM @MyTable\nGROUP BY Column1 \nWITH ROLLUP;\n"]], ["ROLLUP Function; Replace NULL with 'Total' w/ Column data type INT not VARCHAR"], 2, 1], [(21740326, 1), [['Result Set'], ['Note']], [[' ╔═════════╦═══════╗\n║ Column1 ║ MySum ║\n╠═════════╬═══════╣\n║ 1       ║     6 ║\n║ 2       ║     6 ║\n║ 3       ║     6 ║\n║ Total   ║    18 ║\n╚═════════╩═══════╝\n']], ["ROLLUP Function; Replace NULL with 'Total' w/ Column data type INT not VARCHAR"], 2, 0], [(21746336, 0), [['Try this query'], ['or ']], [[" SELECT ENAME, EID, Salary FROM <TABLENAME> WHERE ENAME IN ('AAA','DDD','ZZZ');\n"]], ['How to repeat the same SQL query for different column values'], 2, 1], [(21746336, 1), [['or '], ['-10000']], [[' SELECT ENAME, EID, Salary FROM <TABLENAME1> WHERE ENAME IN (SELECT ENAME FROM <TABLENAME2> WHERE <CRITERIA>);\n']], ['How to repeat the same SQL query for different column values'], 2, 1], [(21765911, 0), [['This will work for your particular example:'], ['You could do something like this:']], [[" select comment \nfrom tbl\nwhere soundex(comment) like '%D510%' or comment like '%dumb%';\n"]], ['In MySQL how to write SQL to search for words in a field?'], 2, 1], [(21765911, 1), [['You could do something like this:'], ['A bit brute force.']], [[" select comment\nfrom tbl\nwhere soundex(comment) = soundex('dumb') or\n      soundex(substring_index(substring_index(comment, ' ', 2), -1)  = soundex('dumb') or\n      soundex(substring_index(substring_index(comment, ' ', 3), -1)  = soundex('dumb') or\n      soundex(substring_index(substring_index(comment, ' ', 4), -1)  = soundex('dumb') or\n      soundex(substring_index(substring_index(comment, ' ', 5), -1)  = soundex('dumb');\n"]], ['In MySQL how to write SQL to search for words in a field?'], 2, 1], [(21786302, 0), [['-10000'], ['The (complicated) conditions at the  WHERE  clauses are used instead of the  YEAR(column) = YEAR(GETDATE()  and the other you had previously, so indexes can be used. WHen you apply a function to a column, you make indexes unsuable (with some minor exceptions for some functions and some verios of SQL-Server.) So, the best thing is to try to convert the conditions to this type: ']], [[" SELECT\n  Period = 'MTD',\n  Total_value = SUM(T0.TotalSumSy) \nFROM dbo.INV1  T0 \n  INNER JOIN dbo.OINV  T1 \n     ON T1.DocEntry = T0.DocEntry\nWHERE \n    T1.DocDate >= DATEADD(month,DATEDIFF(month,'20010101',GETDATE()),'20010101')\n  AND \n    T1.DocDate < DATEADD(month,1+DATEDIFF(month,'20010101',GETDATE()),'20010101')\n\nUNION ALL\n\nSELECT\n  'YTD', \n  SUM(T0.TotalSumSy) \nFROM dbo.INV1  T0 \n  INNER JOIN dbo.OINV  T1 \n     ON T1.DocEntry = T0.DocEntry\nWHERE \n    T1.DocDate >= DATEADD(year,DATEDIFF(year,'20010101',GETDATE()),'20010101')\n  AND \n    T1.DocDate < DATEADD(year,1+DATEDIFF(year,'20010101',GETDATE()),'20010101') ;\n"]], ['SQL Sum MTD & YTD'], 2, 1], [(21786302, 1), [['The (complicated) conditions at the  WHERE  clauses are used instead of the  YEAR(column) = YEAR(GETDATE()  and the other you had previously, so indexes can be used. WHen you apply a function to a column, you make indexes unsuable (with some minor exceptions for some functions and some verios of SQL-Server.) So, the best thing is to try to convert the conditions to this type: '], ['-10000']], [[' column <operator> AnyComplexFunction()\n']], ['SQL Sum MTD & YTD'], 2, 0], [(21832842, 0), [['You can use the  ROW_NUMBER()  Function to assign each of your messages a rank by Message date (starting at 1 again for each message type), then just limit the results to the top ranked message:'], ["If you can't use  ROW_NUMBER  then you can use a subquery to get the latest message date per type:"]], [[" WITH AllMessages AS\n(   SELECT  MessageTypes.MessageType, \n            Messages.MessageDate, \n            Messages.ValueDate, \n            Messages.MessageReference, \n            Messages.Beneficiary, \n            Messages.StatusId,\n            MessageStatus.Status, \n            BICProfile.BIC,\n            RowNumber = ROW_NUMBER() OVER(PARTITION BY Messages.MessageTypeId \n                                            ORDER BY Messages.MessageDate DESC)\n    FROM    Messages \n            INNER JOIN MessageStatus \n                ON Messages.StatusId = MessageStatus.Id \n            INNER JOIN MessageTypes \n                ON Messages.MessageTypeId = MessageTypes.MessageTypeId \n            INNER JOIN BICProfile  \n                ON Messages.SenderId = dbo.BICProfile.BicId \n    WHERE   BICProfile.BIC = 'someValue'\n    AND     Messages.StatusId IN (4, 5, 6)\n)\nSELECT  MessageType, \n        MessageDate, \n        ValueDate, \n        MessageReference, \n        Beneficiary, \n        StatusId,\n        Status, \n        BIC \nFROM    AllMessages\nWHERE   RowNumber = 1;\n"]], ['Get Last message loaded based on message type'], 5, 1], [(21832842, 1), [["If you can't use  ROW_NUMBER  then you can use a subquery to get the latest message date per type:"], ['Then inner join the results of this back to your main query to filter the results:']], [[" SELECT  Messages.MessageTypeID, MessageDate = MAX(Messages.MessageDate)\nFROM    Messages\n        INNER JOIN BICProfile  \n            ON Messages.SenderId = dbo.BICProfile.BicId \nWHERE   BICProfile.BIC = 'someValue'\nAND     Messages.StatusId IN (4, 5, 6)\nGROUP BY Messages.MessageTypeID\n"]], ['Get Last message loaded based on message type'], 5, 0], [(21832842, 3), [['If you will have multiple messages with the same date and only want to return one of them you need to expand the ordering within the row_number function, i.e. if you wanted to pick the message with the maximum id when there were ties you could make it:'], ['So the full query would be:']], [[' RowNumber = ROW_NUMBER() OVER(PARTITION BY Messages.MessageTypeId \n                                ORDER BY Messages.MessageDate DESC,\n                                        Messages.MessageID DESC)\n']], ['Get Last message loaded based on message type'], 5, 0], [(21832842, 4), [['So the full query would be:'], ['-10000']], [[" WITH AllMessages AS\n(   SELECT  MessageTypes.MessageType, \n            Messages.MessageDate, \n            Messages.ValueDate, \n            Messages.MessageReference, \n            Messages.Beneficiary, \n            Messages.StatusId,\n            MessageStatus.Status, \n            BICProfile.BIC,\n            RowNumber = ROW_NUMBER() OVER(PARTITION BY Messages.MessageTypeId \n                                            ORDER BY Messages.MessageDate DESC,\n                                                    Messages.MessageID DESC)\n    FROM    Messages \n            INNER JOIN MessageStatus \n                ON Messages.StatusId = MessageStatus.Id \n            INNER JOIN MessageTypes \n                ON Messages.MessageTypeId = MessageTypes.MessageTypeId \n            INNER JOIN BICProfile  \n                ON Messages.SenderId = dbo.BICProfile.BicId \n    WHERE   BICProfile.BIC = 'someValue'\n    AND     Messages.StatusId IN (4, 5, 6)\n)\nSELECT  MessageType, \n        MessageDate, \n        ValueDate, \n        MessageReference, \n        Beneficiary, \n        StatusId,\n        Status, \n        BIC \nFROM    AllMessages\nWHERE   RowNumber = 1;\n"]], ['Get Last message loaded based on message type'], 5, 1], [(21835289, 0), [['Product database will be '], ['feature table will ']], [[' pid, p_name, p_description, p_price, ...\ninsert query \nINSERT INTO (p_name, p_description, p_price, ....) VALUES(?,?,?,...)\n']], ['Store multiple data tables in single database table'], 4, 0], [(21835289, 1), [['feature table will '], ['now the product_feature table will be']], [[' fid, f_name, f_description, ...\ninsert query \nINSERT INTO (F_name, F_description, ....) VALUES(?,?,?,...)\n']], ['Store multiple data tables in single database table'], 4, 0], [(21835289, 3), [['then maybe the photo table '], ['use InnoDB for all the tables']], [[' foto_id, photo_name, photo_path ....\n']], ['Store multiple data tables in single database table'], 4, 0], [(21841623, 0), [['I am not quite sure how the  index  in your query matches the  index  column in your data.  But the query that you want is:'], ['Give your data, the query seems more like:']], [[' SELECT index,\n       max(CASE WHEN index = 1 THEN Booknumber END) AS BookNumber1 ,\n       max(CASE WHEN index = 2 THEN Booknumber END) AS BookNumber2,\n       max(CASE WHEN index = 3 THEN Booknumber END) AS BookNumber3\nFROM Mytable\nGROUP BY index;\n']], ['Combing multiple rows into one row'], 2, 1], [(21841623, 1), [['Give your data, the query seems more like:'], ['By the way, "index" is a reserved word, so I assume that it is just a placeholder for another column name.  Otherwise, you need to escape it with double quotes or square braces.']], [[' SELECT index,\n       max(CASE WHEN ind = 1 THEN Booknumber END) AS BookNumber1 ,\n       max(CASE WHEN ind = 2 THEN Booknumber END) AS BookNumber2,\n       max(CASE WHEN ind = 3 THEN Booknumber END) AS BookNumber3\nFROM (select mt.*, row_number() over (partition by index order by BookNumber) as ind\n      from Mytable mt\n     ) mt\nGROUP BY index;\n']], ['Combing multiple rows into one row'], 2, 1], [(21869166, 1), [['The INNER JOIN is result in this dataset'], ['You then are grouping by changes.id, which is going to result in (showing with values in CSV list after grouping)']], [[' +---------+--------+--------+------------+---------------+---------------+-----------+\n| data.id | data.c | data.g | changes.id | changes.c_old | changes.c_new | changes.g |\n+---------+--------+--------+------------+---------------+---------------+-----------+\n|       1 |      1 |      2 |          1 |             1 |             2 |         2 |\n|       1 |      1 |      2 |          3 |             1 |             2 |         2 |\n|       2 |      1 |      2 |          1 |             1 |             2 |         2 |\n|       2 |      1 |      2 |          3 |             1 |             2 |         2 |\n|       3 |      1 |      2 |          1 |             1 |             2 |         2 |\n|       3 |      1 |      2 |          3 |             1 |             2 |         2 |\n|       6 |      2 |      3 |          2 |             2 |             1 |         3 |\n|       7 |      2 |      3 |          2 |             2 |             1 |         3 |\n+---------+--------+--------+------------+---------------+---------------+-----------+\n']], ['MySQL: For each row in table, change one row in another table'], 3, 0], [(21869166, 2), [['You then are grouping by changes.id, which is going to result in (showing with values in CSV list after grouping)'], ['Since no aggregate or deterministic way of choosing the values from the available options, you are getting the 1 from data.id chosen for both changes.id 1 and 3']], [[' +---------+--------+--------+------------+---------------+---------------+-----------+\n| data.id | data.c | data.g | changes.id | changes.c_old | changes.c_new | changes.g |\n+---------+--------+--------+------------+---------------+---------------+-----------+\n|   1,2,3 |  1,1,1 |  2,2,2 |          1 |         1,1,1 |         2,2,2 |     2,2,2 |\n|   1,2,3 |  1,1,1 |  2,2,2 |          3 |         1,1,1 |         2,2,2 |     2,2,2 |\n|     6,7 |    2,2 |    3,3 |          2 |           2,2 |           1,1 |       3,3 |\n+---------+--------+--------+------------+---------------+---------------+-----------+\n']], ['MySQL: For each row in table, change one row in another table'], 3, 0], [(21875568, 0), [['Using subquery, i would have done something like this in place of last condition :'], ['So final SQL would have been :']], [[" messages.from = 'Jack' AND \ntype = 'message' AND \n1 =(select count(primary_key) from messages /* 1=count : this would ensure that \n                                               condition works only if \n                                               1 row is returned*/\nwhere (messages.from='Jack' AND type='message')  )\n"]], ['using if count in the part of the sql statement'], 2, 0], [(21875568, 1), [['So final SQL would have been :'], ['-10000']], [[" SELECT \n    *\nFROM\n    messages\nWHERE\n       (messages.to = 'Jack' AND (type = 'message' OR type = 'reply'))\n    OR (messages.from = 'Jack' AND type = 'reply')\n    OR (messages.from = 'Jack' AND \n        type = 'message' AND \n        1 =(select count(primary_key) from messages\n        where (messages.from='Jack' AND type='message')  ))\n\n        ORDER BY messages.message_id DESC , messages.id DESC\n"]], ['using if count in the part of the sql statement'], 2, 1], [(21950759, 0), [['Use  union  '], ['-10000']], [[' UNION is used to combine the result from multiple SELECT statements into a single result set.\n']], ['Extracting data from two tables with same in the form of appending'], 2, 0], [(21950759, 1), [['-10000'], ['-10000']], [[' select * from jay\nUNION \nselect * from Ren\n']], ['Extracting data from two tables with same in the form of appending'], 2, 1], [(21956650, 0), [["Change the select list for whatever columns you want to display, but this will limit the results as you want, for a given testid (replace testXYZ with the actual test you're searching on)"], ['Note: To run this for ALL tests, and have scores limited to those that are below the average for each test, you would just leave that one line out of the where clause and run:']], [[" SELECT t.Test_name, s.*, sc.*\n  FROM Tests t\n  JOIN Scores sc\n    ON t.id_Tests = sc.Tests_id_Tests\n  JOIN Students s\n    ON sc.Students_id_Students = s.id_Students\n WHERE t.id_Tests = 'textXYZ'\n   and sc.result <\n       (select avg(x.result)\n          from scores x\n         where sc.Tests_id_Tests = x.Tests_id_Tests)\n"]], ['SQL - How to list items which are below the average'], 2, 1], [(21956650, 1), [['Note: To run this for ALL tests, and have scores limited to those that are below the average for each test, you would just leave that one line out of the where clause and run:'], ['-10000']], [[' SELECT t.Test_name, s.*, sc.*\n  FROM Tests t\n  JOIN Scores sc\n    ON t.id_Tests = sc.Tests_id_Tests\n  JOIN Students s\n    ON sc.Students_id_Students = s.id_Students\n WHERE sc.result <\n       (select avg(x.result)\n          from scores x\n         where sc.Tests_id_Tests = x.Tests_id_Tests)\n']], ['SQL - How to list items which are below the average'], 2, 1], [(21969425, 0), [['Try:'], ['Or if they need to type in multiple values to search on:']], [[" Select columnA, columnB, columnC, columnD\nfrom myTable t\nwhere t.&searchColumn in ('&searchParam')\n"]], ['SQL Plus - Running a query based on user input'], 3, 1], [(21969425, 1), [['Or if they need to type in multiple values to search on:'], ['If you want them to be able to type the substitution values into the file (at the top) using DEFINE, this is what you would do:']], [[' Select columnA, columnB, columnC,columnD\nfrom myTable t\nwhere t.&searchColumn in (&searchParam)\n']], ['SQL Plus - Running a query based on user input'], 3, 1], [(21977220, 0), [["To solve the first of these, instead of selecting data purely from the sample table,\nwe can join together the data with a generated series that matches the user's\nrequest. The latter can be generated using this:"], ['The above query will generate a series of ranges, from 0 to 10 with a step size\nof 1. The output looks like this:']], [[' SELECT int4range(rstart, rstart+1) AS srange \nFROM generate_series(0,10,1) AS seq(rstart)\n']], ['Querying time series in Postgress'], 4, 0], [(21977220, 1), [['The above query will generate a series of ranges, from 0 to 10 with a step size\nof 1. The output looks like this:'], ['Here is the full query:']], [['  srange\n---------\n [0,1)\n [1,2)\n [2,3)\n [3,4)\n [4,5)\n [5,6)\n [6,7)\n [7,8)\n [8,9)\n [9,10)\n [10,11)\n(11 rows)\n']], ['Querying time series in Postgress'], 4, 0], [(21977220, 3), [['Result:'], ['It is not likely any index will be used on ts in this query as it stands, and\nif the data table is large then performance is going to be dreadful.']], [['  t  |      value\n----+------------------\n  0 |                5\n  1 |                2\n  2 | 3.33333333333333\n  3 | 3.33333333333333\n  4 | 3.33333333333333\n  5 |\n  6 |\n  7 |\n  8 |\n  9 |\n 10 |\n(11 rows)\n']], ['Querying time series in Postgress'], 4, 0], [(22021194, 0), [['Create an  OUTPUT  parameter inside your stored procedure and use that Parameter to store the value and then use that parameter inside your Update statement. Something like this....'], ['I havent tested it But in this situation I guess you could do something like this.. I dont recomend this method if you have a large table. in that case you are better off with a table type parameter Procedure.']], [[' DECLARE @OutParam Datatype;\n\nEXECUTE SP1 @param1=C1, @OUT_Param = @OutParam OUTPUT  --<--\n\n--Now you can use this OUTPUT parameter in your Update statement.\n\nUPDATE Table1 \nSET C2 = @OutParam\n']], ['How to set a value with the return value of a stored procedure'], 2, 1], [(22021194, 1), [['I havent tested it But in this situation I guess you could do something like this.. I dont recomend this method if you have a large table. in that case you are better off with a table type parameter Procedure.'], ['-10000']], [[' -- Get C1 Values In a Temp Table\n\nSELECT DISTINCT C1 INTO #temp\nFROM Table1\n\n-- Declare Two Varibles \n--1) Return Type of Stored Procedure\n--2) Datatype of C1\n\nDECLARE @C1_Var DataType;\nDECLARE @param1 DataType;\n\nWHILE EXISTS(SELECT * FROM #temp)\nBEGIN\n     -- Select Top 1 C1 to @C1_Var\n      SELECT TOP 1 @C1_Var = C1 FROM #temp\n\n      --Execute Proc and returned Value in @param1\n      EXECUTE SP1 @param1 = @C1_Var \n\n      -- Update the table\n      UPDATE Table1\n      SET   C2 = @param1\n      WHERE C1 = @C1_Var\n\n      -- Delete from Temp Table to entually exit the loop\n      DELETE FROM  #temp WHERE C1 =  @Var    \n\nEND\n']], ['How to set a value with the return value of a stored procedure'], 2, 1], [(22040663, 0), [["You don't need the  ROW  constructor there, and so you can expand the record by using  (foo).* :"], ['Although this query could be simple written as:']], [[' WITH RECURSIVE t AS (\n    SELECT d as foo FROM some_multicolumn_table as d\nUNION ALL\n    SELECT foo FROM t WHERE random() < .5\n)\nSELECT (foo).* FROM t;\n']], ['Flattening nested record in postgres'], 2, 1], [(22040663, 1), [['Although this query could be simple written as:'], ["And I recommend trying to keep it as simple as possible. But I'm assuming it was just an exemplification."]], [[' WITH RECURSIVE t AS (\n    SELECT d.* FROM some_multicolumn_table as d\nUNION ALL\n    SELECT t.* FROM t WHERE random() < .5\n)\nSELECT * FROM t;\n']], ['Flattening nested record in postgres'], 2, 1], [(22052942, 0), [['If you want to hard-code the translations'], ["Normally, though, you'd create a lookup table and join to that"]], [[" SELECT (CASE paymentType\n             WHEN 'ePay' THEN 'electronic payment'\n             WHEN 'cPay' THEN 'cash payment'\n             WHEN 'dPay' THEN 'deposit account payment' \n             WHEN 'ccPay' THEN 'credit card payment'\n             ELSE paymentType\n         END) payment_type,\n       other_columns\n  FROM payment\n"]], ['Replace column output in a more readable form Oracle - SQL'], 2, 1], [(22052942, 1), [["Normally, though, you'd create a lookup table and join to that"], ['-10000']], [[' SELECT payment_type.payment_type_description,\n       <<other columns>>\n  FROM payment pay\n       JOIN payment_type ON (pay.paymentType = payment_type.paymentType)\n']], ['Replace column output in a more readable form Oracle - SQL'], 2, 1], [(22055558, 0), [["You can write a stored procedure, like you've done and pass the date to it.   "], ['However, rather than a cursor, do something like']], [[' CREATE PROCEDURE check_scoretable  \n( \n    @pDate DATE = NULL\n)\nas\n']], ['Stored procedure to update temp table based on Date in SQL Server'], 3, 0], [(22055558, 1), [['However, rather than a cursor, do something like'], ['CAVEAT: Your database design is not good, because of the redundant data in it.  For example, you are tracking the number of matches in the team table, when you can compute the number of matches by ']], [[' SELECT tm.name,sum(tm.noMatches) as NumberMatches,sum(tm.ownGoals) as OwnGoals,\n       sum(tm.otherGoals) as Othergoals,sum(tm.Points) as Points\nFROM Team tm\nJOIN Matches mc on mc.homeId=tm.id or mc.outId=tm.id\nWHERE mc.matchDate <= @pDate\n']], ['Stored procedure to update temp table based on Date in SQL Server'], 3, 0], [(22055558, 2), [['CAVEAT: Your database design is not good, because of the redundant data in it.  For example, you are tracking the number of matches in the team table, when you can compute the number of matches by '], ['Same type of operation for total goals, etc.']], [[' SELECT count(*) FROM matches WHERE homeId=@id or OutId=@id\n']], ['Stored procedure to update temp table based on Date in SQL Server'], 3, 0], [(22134638, 1), [['There are several ways to get the option corresponding to the maximum value.  I think the easiest in this case is the  substring_index() / group_concat()  method:'], ['-10000']], [[" select `group`,\n       substring_index(group_concat(`option` order by cnt desc), ',', 1) as maxoption\nfrom (select `group`, `option`, count(*) as cnt\n      from table t\n      group by `group`, `option`\n     ) tgo\ngroup by `group`;\n"]], ['Max count() for every group of GROUP BY'], 2, 1], [(22170964, 1), [['Now since we already know your product, I actually think lazy-loading is easier to read and understand.'], ['-10000']], [[" // Find your product\n$product = Product::find(1);\n\n// Eager load variants with closest price\n$product->load('variants')->ofSimilarPrice($productPrice);\n\nforeach($product->variants as $variant) {\n    echo $variant->details;\n    echo $variant->price;\n}\n"]], ['Laravel 4 Eloquent - Similar products based on price'], 2, 0], [(22180392, 0), [['You can get the results you seem to want using aggregation:'], ['I think you can get the same result with this query:']], [[' select max(MONITOR_ALERT_INSTANCE_ID) as Id, description, max(created_date) as created_date\nfrom monitor_alert_instance \nwhere description in (select description \n                      from monitor_alert_instance\n                      where co_mod_asset_id = 1223\n                     )\ngroup by description;\n']], ['How to get results for distinct values using sql in oracle'], 2, 1], [(22180392, 1), [['I think you can get the same result with this query:'], ['The  having  clause makes sure that the description is for asset  1223 .']], [[' select max(MONITOR_ALERT_INSTANCE_ID) as Id, description, max(created_date) as created_date\nfrom monitor_alert_instance \ngroup by description\nhaving max(case when co_mod_asset_id = 1223 then 1 else 0 end) = 1;\n']], ['How to get results for distinct values using sql in oracle'], 2, 1], [(22184025, 0), [['The simple way to do this in Postgres uses  distinct on :'], ['Your original query would be, assuming that  id  increases along with the  time  field:']], [[' select distinct on (unit_id) r.*\nfrom reports r\norder by unit_id, time desc;\n']], ['using a single query to eliminate N+1 select issue'], 3, 1], [(22184025, 2), [['You might also try this as a  not exists :'], ['I thought the  distinct on  would perform well.  This last version (and maybe the previous) would really benefit from an index on  reports(unit_id, time) .']], [[' select r.*\nfrom reports r\nwhere not exists (select 1\n                  from reports r2\n                  where r2.unit_id = r.unit_id and\n                        r2.time > r.time\n                 );\n']], ['using a single query to eliminate N+1 select issue'], 3, 1], [(22205060, 1), [['Include Edit in the merge statement. See the below query (not tested with the real data)\nIn this way we do not run the update on entire table.'], ['-10000']], [[' Merge into table1 t1\nusing table1_staging t1s\non t1.name = t1s.name\nwhen matched then\nupdate t1.value_a = t1s.value_a,\nt1.Update_time = (case when t1s.value_a < 0.1 and t1.Update_time is null then sysdate\n                            when t1s.value_a > 0.1 and t1.Update_time is not null then null\n                       else t1.Update_time end)\nwhen not matched then\nINSERT (name, values_a)\n    VALUES (t1s.name, t1s.values_a);\n']], ["Insert based on another column's value (Oracle 11g)"], 2, 1], [(22228967, 0), [['The way I would go about this is to create your own table of values using a  table value constructor :'], ['This gives a table you can select from, then left join to your existing table:']], [[" SELECT  OldSeverity, NewSeverity\nFROM    (VALUES \n            ('Critical', 'Critical'),\n            ('High', 'Critical'),\n            ('Medium', 'Medium'),\n            ('Low', 'Medium')\n        ) s (OldSeverity, NewSeverity);\n"]], ['Showing all values in Group By with inclusion of CASE'], 3, 0], [(22228967, 1), [['This gives a table you can select from, then left join to your existing table:'], ['The problem you have with the way that you are implimenting the query, is that although you have immediately left joined to  DimWorkItem  you then inner join to subsequent tables and refer to columns in  WorkItem  in the where clause, which undoes your left join and turns it back into an inner join. You need to place your whole logic into a subquery, and left join to this:']], [[" SELECT  Severity = s.NewSeverity,\n        Total = COUNT(t.Severity)\nFROM    (VALUES \n            ('Critical', 'Critical'),\n            ('High', 'Critical'),\n            ('Medium', 'Medium'),\n            ('Low', 'Medium')\n        ) s (OldSeverity, NewSeverity)\n        LEFT JOIN #Test t\n            ON t.Severity = s.OldSeverity\nGROUP BY s.NewSeverity;\n"]], ['Showing all values in Group By with inclusion of CASE'], 3, 0], [(22228967, 2), [['The problem you have with the way that you are implimenting the query, is that although you have immediately left joined to  DimWorkItem  you then inner join to subsequent tables and refer to columns in  WorkItem  in the where clause, which undoes your left join and turns it back into an inner join. You need to place your whole logic into a subquery, and left join to this:'], ['-10000']], [[" SELECT  s.NewSeverity AS 'Severity'\n        ,COUNT(WI.microsoft_vsts_common_severity) AS 'Total'\nFROM   ( VALUES\n            ('Critical','I-High')\n            ,('High','I-High')\n            ,('Medium','I-Low')\n            ,('Low','I-Low')\n        )s(OldSeverity,NewSeverity)\n       LEFT JOIN \n       (    SELECT  wi.Severity\n            FROM    DimWorkItem WI (NOLOCK) \n                   JOIN dbo.DimPerson P \n                     ON p.personsk = WI.system_assignedto__personsk \n                   JOIN DimTeamProject TP \n                     ON WI.TeamProjectSK = TP.ProjectNodeSK \n                   JOIN DimIteration Itr (NOLOCK) \n                     ON Itr.IterationSK = WI.IterationSK \n                   JOIN DimArea Ar (NOLOCK) \n                     ON Ar.AreaSK = WI.AreaSK \n            WHERE  TP.ProjectNodeName = 'ABC' \n                   AND WI.System_WorkItemType = 'Bug' \n                   AND WI.Microsoft_VSTS_CMMI_RootCause <> 'Change Request' \n                   AND Itr.IterationPath LIKE '%\\ABC\\R1234\\Test\\IT%' \n                   AND WI.System_State NOT IN ( 'Rejected', 'Closed' ) \n                   AND WI.System_RevisedDate = CONVERT(datetime, '9999', 126)         \n        ) WI\n            ON WI.Severity = s.OldSeverity   \nGROUP BY s.NewSeverity;\n"]], ['Showing all values in Group By with inclusion of CASE'], 3, 1], [(22232282, 0), [['Use a sub-query to find out at what point you should stop, then return all row from your starting point to the calculated stop point.'], ["Note, this assumes that the last record is always an 'F'. You can deal with the last record being a 'T' using a  COALESCE ."]], [[" SELECT\n  *\nFROM\n  yourTable\nWHERE\n      id >= 4\n  AND id <= (SELECT MIN(id) FROM yourTable WHERE b = 'F' AND id >= 4)\n"]], ['Select rows until condition met'], 2, 1], [(22232282, 1), [["Note, this assumes that the last record is always an 'F'. You can deal with the last record being a 'T' using a  COALESCE ."], ['-10000']], [[" SELECT\n  *\nFROM\n  yourTable\nWHERE\n      id >= 4\n  AND id <= COALESCE(\n              (SELECT MIN(id) FROM yourTable WHERE b = 'F' AND id >= 4),\n              (SELECT MAX(id) FROM yourTable                          )\n            )\n"]], ['Select rows until condition met'], 2, 1], [(22258390, 0), [['Try this'], ['however, this is extremely bad design. You should consider redesigning your  Table2  to contain something like']], [[' select * \n  from Table1 a\n       join Table2 b on a.Col1=case @nivel\n                                   when 1 then b.Col1\n                                   when 2 then b.Col2\n                                   when 3 then b.Col3\n                                   ...\n                                 end\n']], ['Concatenate string with real table SQL SERVER'], 3, 1], [(22258390, 1), [['however, this is extremely bad design. You should consider redesigning your  Table2  to contain something like'], ['then your query will be more straightforward']], [[' | ColNo | ColumnData\n|   1   | Data of column 1\n|   2   | Data of column 2\n|   3   | Data of column 3\n']], ['Concatenate string with real table SQL SERVER'], 3, 0], [(22311646, 0), [['You just need to add distinct to the counts'], ['Alternatively you can use inline views in the from clause']], [[' SELECT u.*, COUNT(DISTINCT q.id), COUNT(DISTINCT a.id)\n FROM users u\n LEFT JOIN questions q ON u.id = q.author_id\n LEFT JOIN answers a ON u.id = a.author_id\n GROUP BY u.id\n']], ['How do I combine two LEFT JOINS without getting crossover?'], 2, 1], [(22311646, 1), [['Alternatively you can use inline views in the from clause'], ['Demo']], [[' SELECT u.*, q.QuestionCount, a.AnswerCount\nFROM   users u \n       LEFT JOIN (SELECT Count(id) QuestionCount, \n                         author_id \n                  FROM   questions \n                  GROUP  BY author_id) q \n              ON u.id = q.author_id \n       LEFT JOIN (SELECT Count(id) AnswerCount, \n                         author_id \n                  FROM   answers \n                  GROUP  BY author_id) a \n              ON u.id = q.author_id \n']], ['How do I combine two LEFT JOINS without getting crossover?'], 2, 1], [(22348948, 0), [['If I understand correctly, you want to "pivot" the data.  In SQLite, one way to do this by using  group by :'], ['Another way is by using  join :']], [[' select AP_idx,\n       max(case when RF_idx = 0 then Channel end) as ChannelA,\n       max(case when RF_idx = 1 then Channel end) as ChannelB\nfrom table t\ngroup by AP_idx;\n']], ['SQL: How to extract data from one column as different columns, according to different condition?'], 2, 1], [(22348948, 1), [['Another way is by using  join :'], ['This might have better performance with the right indexes.  On the other hand, the aggregation method is safer if some of the channel values are missing.']], [[' select ta.AP_idx, ta.channel as ChannelA, tb.channel as ChannelB\nfrom table ta join\n     table tb\n     on ta.AP_idx = tb.AP_idx and\n        ta.RF_idx = 0 and\n        tb.RF_idx = 1;\n']], ['SQL: How to extract data from one column as different columns, according to different condition?'], 2, 1], [(22366810, 0), [['tblSurveys:'], ['tblEmployees:']], [[' employeeid    score\n----------    -----\n1             10\n2             3\n2             2\n3             7\n\netc...\n']], ['Calculating a field based on totals from queries in MS Access 2010'], 7, 0], [(22366810, 1), [['tblEmployees:'], ['tblSupervisors: ']], [[' employeeid    EmployeeName    SupervisorId    \n----------    -------------   ------------    \n1             Employee 1      1               \n\netc...\n']], ['Calculating a field based on totals from queries in MS Access 2010'], 7, 0], [(22366810, 2), [['tblSupervisors: '], ['tblRegManagers: ']], [[' SuperVisorId   SuperVisorName   RegManagerId\n------------   --------------   -------------\n1              Super 1          1\n2              Super 2          1\n\netc...\n']], ['Calculating a field based on totals from queries in MS Access 2010'], 7, 0], [(22366810, 3), [['tblRegManagers: '], ['Query1: This gives you the employee stats']], [[' RegManagerId    RegManagerName\n-------------   -----------------\n1               Regional Manager 1\n2               Regional Manager 2\n\netc...\n']], ['Calculating a field based on totals from queries in MS Access 2010'], 7, 0], [(22366810, 4), [['Query1: This gives you the employee stats'], ['Query2: This gives you the supervisor stats but also uses employee stats (Query1)']], [[' select SupervisorName,RegManagerId,EmployeeName,\n    Promoter,Detractor,surveys,Promoter-Detractor AS score,\n    (Promoter-Detractor)/surveys as result \n    from \n    (       \n    select a.EmployeeName,b.SupervisorName, b.RegManagerId,\n    (select count(*) from tblSurveys where \n    employeeid=a.employeeid and score<7) as Detractor,\n    (select count(*) from tblSurveys where \n    employeeid=a.employeeid and score>6)  as Promoter,\n    (select count(*) from tblSurveys where employeeid=a.employeeid) as surveys \n    from tblEmployees a left join tblSupervisors b on a.supervisorid=b.supervisorid\n    ) \n']], ['Calculating a field based on totals from queries in MS Access 2010'], 7, 0], [(22366810, 5), [['Query2: This gives you the supervisor stats but also uses employee stats (Query1)'], ['Query3: This gives you Regional Manager stats but also uses supervisor stats (Query2)']], [[' select supervisorname,RegManagerId, \n    promotersum, detractorsum, surveyssum,(promotersum-detractorsum)/surveyssum \n    from \n    (select SuperVisorName,RegManagerId, sum(Promoter) as PromoterSum, \n    sum(Detractor) as DetractorSum, \n    sum(surveys) as surveyssum from query1 group by SuperVisorName,RegManagerId )\n']], ['Calculating a field based on totals from queries in MS Access 2010'], 7, 0], [(22366810, 6), [['Query3: This gives you Regional Manager stats but also uses supervisor stats (Query2)'], ['So, while each query serves as a report by themselves, the first two are used as source queries.']], [[' select RegManagerName, promoter_cnt, detractor_cnt, survey_cnt, promoter_cnt-detractor_cnt as score, \n    (promoter_cnt-detractor_cnt)/survey_cnt as result \n    from \n    (select a.RegManagerName, b.RegManagerId, sum(b.promotersum) as promoter_cnt, \n    sum(b.detractorsum) as detractor_cnt, sum(b.surveyssum) as survey_cnt \n    from tblRegManagers a left join query2 b on a.RegManagerId=b.RegManagerId \n    group by a.RegManagerName, b.RegManagerId) \n']], ['Calculating a field based on totals from queries in MS Access 2010'], 7, 0], [(22390896, 0), [['-10000'], ['that the startdate or end date should not fall in the interval of s_adate and s_ddate.']], [[' If I understand this problem correctly, what you want is \n']], ['mysql query for give array in the date not into interval'], 2, 0], [(22390896, 1), [['that the startdate or end date should not fall in the interval of s_adate and s_ddate.'], ['-10000']], [['         Try this:\n\n        select * from table where ($datestart  NOT BETWEEN s_adate and s_ddate) OR($enddate NOT BETWEEN s_adate and s_ddate);\n']], ['mysql query for give array in the date not into interval'], 2, 1], [(22393469, 0), [['You can use the  dateadd  and  getdate  functions to generate the dates you want. Try something like this to test it:'], ['This would return:']], [[" declare @d1 date\nset @d1 = '02/01/2007'\n\nselect \n    @d1 as d1, \n    dateadd(YEAR, year(getdate())-year(@d1), @d1) as d2, \n    dateadd(day, 59, dateadd(YEAR, year(getdate())-year(@d1), @d1)) as d3\n"]], ['Insert into a colum the month/day/currentyear that is the same month/day as a previous column'], 3, 1], [(22393469, 1), [['This would return:'], ['To adapt it to an update statement you would do something like:']], [[' d1         d2         d3\n---------- ---------- ----------\n2007-02-01 2014-02-01 2014-04-01\n']], ['Insert into a colum the month/day/currentyear that is the same month/day as a previous column'], 3, 0], [(22393469, 2), [['To adapt it to an update statement you would do something like:'], ['-10000']], [[' update myTable\n    set date 2 = dateadd(YEAR, year(getdate())-year(date1), date1) , \n    date3 = dateadd(day, 59, dateadd(YEAR, year(getdate())-year(date1), date1)) \n']], ['Insert into a colum the month/day/currentyear that is the same month/day as a previous column'], 3, 1], [(22399836, 0), [['SELECT  the  MAX imum of  modification_date  for each  GROUP  of ( A ,  B ), then  JOIN  back to the original row to get the values (necessary to get the  id  column):'], ['-10000']], [[' SELECT t1.*\nFROM Person t1\nJOIN\n(\n    SELECT MAX(modification_date) max_date, A, B\n    FROM Person\n    GROUP BY A, B\n) t2 ON t1.A = t2.A AND t1.B = t2.B AND t1.modification_date = t2.max_date\n']], ['SQL Query, latest rows for each unique duo'], 2, 1], [(22399836, 1), [['-10000'], ['-10000']], [[' SELECT MIN(id) id, A, B, MAX(modification_date) modification_date\nFROM Person\nGROUP BY A, B\n']], ['SQL Query, latest rows for each unique duo'], 2, 1], [(22452123, 1), [['EDIT \nChanging the left join to this ensures that the join only occurs on secondary elements and only every second element: '], ["That means we don't need the case statement, just this:"]], [[' LEFT JOIN T1 AS T1Next ON T1.propertyid = T1Next.propertyid \n    AND T1.isprimary = 0\n    AND T1Next.isprimary = 0\n    AND T1.PropNo = T1Next.PropNo - 1\n    AND T1Next.PropNo % 2 = 0\n']], ['How to conditionally adjust date on subsequent rows'], 4, 0], [(22452123, 2), [["That means we don't need the case statement, just this:"], ['But the where statement is not quite right. This works:']], [[' ISNULL(T1Next.date, T1.date) AS [date]\n']], ['How to conditionally adjust date on subsequent rows'], 4, 0], [(22452123, 3), [['But the where statement is not quite right. This works:'], ['-10000']], [[' WHERE T1.isprimary = 1\n    OR (T1.PropNo % 2 = 0)     --every 2nd one\n    OR T1Next.date IS NOT NULL --and the 1st if there is a 2nd\n']], ['How to conditionally adjust date on subsequent rows'], 4, 0], [(22468717, 0), [['Try this:'], ['If you have a unique id, then the solution is a bit easier.  I wish you could do this:']], [[" update city cross join\n       (select @city := '', @prevcity := '', @i := 0) const\n    set `index` = (case when (@prevcity := @city) is null then null\n                        when (@city := city) is null then null\n                        else @i := if(@prevcity = city, @i + 1, 1) is null then null\n                   end)\n    order by city; \n"]], ['How to update duplicated rows with a index (Mysql)'], 3, 1], [(22468717, 2), [['But instead, you can do it with more joins:'], ['-10000']], [[' update city c join\n       (select id, (select count(*) from city c2 where c2.city = c1.city and c2.id <= c1.id) as newind\n        from city c1\n       ) ci\n       on c.id = ci.id\n    set c.`index` = ci.newind;\n']], ['How to update duplicated rows with a index (Mysql)'], 3, 1], [(22512709, 0), [['You should be able to do exactly the same thing (although I cannot imagine what you are trying to accomplish):'], ["Personally, I like doing this kind of thing with CTE's:"]], [[" Select  *\nFrom (\n        SELECT DISTINCT ROW_NUMBER() Over(Order By c.UserId) rn, c.UserId, (u.FirstName + ' ' + u.LastName) AS [UserName], Count(c.UserId +c.CaseId+c.LineNumber) AS [CompletedCase]\n        FROM T.dbo.CompletedCase c join T.dbo.User u on c.UserId = u.UserID\n        WHERE c.PrintDateTime >= '2014-01-27 7:00' AND c.PrintDateTime <= '2014-01-27 17:00'\n        Group By u.FirstName, u.LastName, c.UserId\n    ) x\nWhere   x.rn Between 0 and 25\nOrder By [UserName]\n"]], ['In SQL how can I add my Row_Number() to my current subquery in the from clause?'], 3, 1], [(22512709, 2), [['But, it kind of seems like you just want the first 25 rows, so why not just:'], ['-10000']], [[" SELECT DISTINCT Top 25, c.UserId, (u.FirstName + ' ' + u.LastName) AS [UserName], Count(c.UserId +c.CaseId+c.LineNumber) AS [CompletedCase]\nFROM T.dbo.CompletedCase c join T.dbo.User u on c.UserId = u.UserID\nWHERE c.PrintDateTime >= '2014-01-27 7:00' AND c.PrintDateTime <= '2014-01-27 17:00'\nGroup By u.FirstName, u.LastName, c.UserId\nOrder By [UserName]\n"]], ['In SQL how can I add my Row_Number() to my current subquery in the from clause?'], 3, 1], [(22537662, 0), [['I suspect that you really want the  lag()  function:'], ['In SQL Server, you can use this in an update statement:']], [[' select t.*,\n       lag(code) over (order by date) as lastcode\nfrom table t;\n']], ['transfer the value of a field to variable in SQL Server 2012'], 2, 1], [(22537662, 1), [['In SQL Server, you can use this in an update statement:'], ['This assumes the column already exists in the table.']], [[' with toupdate as (\n      select t.*,\n             lag(code) over (order by date) as new_lastcode\n      from table t\n     )\nupdate toupdate\n    set lastcode = new_lastcode;\n']], ['transfer the value of a field to variable in SQL Server 2012'], 2, 1], [(22544486, 0), [['Try this:'], ['or better simplified (a subquery is not needed):']], [[" INSERT INTO tblUsers (State,City,Code)\nSELECT 'IN','Indy', UserCode\nFROM tblAccounts\nWHERE UserCode IN\n    (SELECT UserCode\n     FROM tblAccounts\n     WHERE State = 'IN')\n"]], ['How to insert multiple rows with one insert statement'], 2, 1], [(22544486, 1), [['or better simplified (a subquery is not needed):'], ['-10000']], [[" INSERT INTO tblUsers (State,City,Code)\nSELECT 'IN','Indy', UserCode\nFROM tblAccounts\nWHERE State = 'IN'\n"]], ['How to insert multiple rows with one insert statement'], 2, 1], [(22583760, 1), [['The idea is to use a Recursive CTE to explode the date ranges into one record per day.  Also, the logic of  value / (1+datediff(day, startdate, enddate))  distributes the total value evenly over the number of days in each range.  Finally, we group by day and sum together all the values corresponding to that day to get the output:'], ['From here you can join with your result table (Table B) by date, and update/insert the value as needed.  That logic might look something like this (test it first of course before running in production!):']], [[' | ID |                            DATE | VALUE |\n|----|---------------------------------|-------|\n|  1 |  January, 01 2014 00:00:00+0000 |    11 |\n|  2 |  January, 02 2014 00:00:00+0000 |    16 |\n|  3 |  January, 03 2014 00:00:00+0000 |    16 |\n|  4 | February, 01 2014 00:00:00+0000 |    10 |\n|  5 | February, 02 2014 00:00:00+0000 |    10 |\n']], ['Select Every Date for Date Range and Insert'], 3, 0], [(22583760, 2), [['From here you can join with your result table (Table B) by date, and update/insert the value as needed.  That logic might look something like this (test it first of course before running in production!):'], ['-10000']], [[' update B set B.VALUE = R.VALUE from TableB B join Result R on B.DATE = R.DATE\ninsert TableB (DATE, VALUE)\n  select DATE, VALUE from Result R where R.DATE not in (select DATE from TableB)\n']], ['Select Every Date for Date Range and Insert'], 3, 0], [(22622841, 0), [['Test Data'], ['Query']], [[" DECLARE @TABLE TABLE (id INT,name VARCHAR(100),value INT)\nINSERT INTO @TABLE VALUES    \n(1,'kermit',100),(2,'piggy',200),(3,'tiffy',300)\n"]], ['SQL Server : Calculate a percentual value in a row out of a sum of multiple rows'], 3, 0], [(22622841, 2), [['Result Set'], ['-10000']], [[' ╔════╦════════╦═══════╦═══════════════════════════╗\n║ id ║  name  ║ value ║ % of sum of matching rows ║\n╠════╬════════╬═══════╬═══════════════════════════╣\n║  1 ║ kermit ║   100 ║ 16.67%                    ║\n║  2 ║ piggy  ║   200 ║ 33.33%                    ║\n║  3 ║ tiffy  ║   300 ║ 50.00%                    ║\n╚════╩════════╩═══════╩═══════════════════════════╝\n']], ['SQL Server : Calculate a percentual value in a row out of a sum of multiple rows'], 3, 0], [(22629022, 0), [['Make room for the key'], ['Insert your row ']], [[' update mytable\nset key = key + 1\nwhere key >= 87\n']], ['Inserting a row at the specific place in SQLite database'], 3, 0], [(22629022, 1), [['Insert your row '], ['And finally update the key for the new row ']], [[' insert into mytable ...\n']], ['Inserting a row at the specific place in SQLite database'], 3, 0], [(22629022, 2), [['And finally update the key for the new row '], ['-10000']], [[' update mytable\nset key = 87\nwhere key = NEW_ROW_KEY\n']], ['Inserting a row at the specific place in SQLite database'], 3, 0], [(22655631, 0), [["For PostgreSQL 9.3, you'd write:"], ["or on older PostgreSQL versions I  think  in this case it's safe to write:"]], [[" INSERT INTO element_authors(element_id, author_id)\nSELECT\n  element_id,\n  CAST (author_id AS integer) AS author_id\nFROM\n  element,\n  LATERAL regexp_split_to_table(nullif(authors, ''), ',') author_id;\n"]], ['Normalize comma separated foreign key'], 2, 1], [(22655631, 1), [["or on older PostgreSQL versions I  think  in this case it's safe to write:"], ['-10000']], [[" INSERT INTO element_authors(element_id, author_id)\nSELECT\n  element_id,\n  CAST( regexp_split_to_table(nullif(authors, ''), ',') AS integer) AS author_id\nFROM\n  element;\n"]], ['Normalize comma separated foreign key'], 2, 1], [(22668248, 0), [['Custom TYPE Definitions'], ['PROCEDURE Source Code']], [['  CREATE OR REPLACE TYPE  "COURSE_REC_TYPE" IS OBJECT (DEPID NUMBER(10,0), COURSE VARCHAR2(10));\n\n CREATE OR REPLACE TYPE  "COURSE_TBL_TYPE" IS TABLE of course_rec_type;\n']], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22668248, 1), [['PROCEDURE Source Code'], ['Procedure OUTPUT:']], [["  create or replace PROCEDURE ZZ_PROC_COURSE_SEARCH IS\n\n    my_input   course_tbl_type:= course_tbl_type();\n    my_output  course_tbl_type:= course_tbl_type();\n    cur_loop_counter   pls_integer;\n\n    c_output_template   constant  varchar2(100):=\n        'DEPID: <<DEPID>>,  COURSE: <<COURSE>>';\n    v_output   VARCHAR2(200);\n\n    CURSOR find_course_cur IS           \n       SELECT crs.depid, crs.course\n         FROM zz_course crs,\n             (SELECT depid, course\n                FROM TABLE (CAST (my_input AS course_tbl_type))\n                ) search_values\n        WHERE crs.depid = search_values.depid\n          AND crs.course = search_values.course;\n\n BEGIN\n    my_input.extend(2);\n    my_input(1):= course_rec_type(1, 'A');\n    my_input(2):= course_rec_type(4, 'D');\n\n    cur_loop_counter:= 0;\n    for i in find_course_cur\n    loop\n       cur_loop_counter:= cur_loop_counter + 1;\n       my_output.extend;\n       my_output(cur_loop_counter):= course_rec_type(i.depid, i.course);\n\n    end loop;\n\n for j in my_output.first .. my_output.last\n loop\n     v_output:= replace(c_output_template, '<<DEPID>>', to_char(my_output(j).depid));\n     v_output:= replace(v_output, '<<COURSE>>', my_output(j).course);\n\n     dbms_output.put_line(v_output);\n\n end loop;\n\n end ZZ_PROC_COURSE_SEARCH;\n"]], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22668248, 2), [['Procedure OUTPUT:'], ['MY COMMENTS:   I wasn\'t particularly satisfied with the way the input variables were stored.  There was a clumsy kind of problem with "loading" values into the nested table structure... If you can consider using a single search key instead of a composite pair (i.e., depid and course), the problem condenses to a simpler form.']], [['  DEPID: 1,  COURSE: A\n DEPID: 4,  COURSE: D\n\n Statement processed.\n\n\n 0.03 seconds\n']], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22668248, 3), [['MY COMMENTS:   I wasn\'t particularly satisfied with the way the input variables were stored.  There was a clumsy kind of problem with "loading" values into the nested table structure... If you can consider using a single search key instead of a composite pair (i.e., depid and course), the problem condenses to a simpler form.'], ['This will be passed directly through an input parameter from the procedure call.']], [['  CREATE OR REPLACE TYPE  "NUM_TBL_TYPE" IS TABLE of INTEGER;\n']], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22668248, 4), [['This will be passed directly through an input parameter from the procedure call.'], ['The following can be removed from the main procedure and presented as part of the call to the procedure.']], [['  -- REMOVE\n my_input   course_tbl_type:= course_tbl_type();\n']], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22668248, 5), [['The following can be removed from the main procedure and presented as part of the call to the procedure.'], ['Becomes:']], [["  BEGIN\n    my_input.extend(2);\n    my_input(1):= course_rec_type(1, 'A');\n    my_input(2):= course_rec_type(4, 'D');\n"]], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22668248, 6), [['Becomes:'], ['and']], [['  create or replace PROCEDURE ZZ_PROC_COURSE_SEARCH (p_search_ids IN num_tbl_type) IS...\n']], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22668248, 7), [['and'], ['The cursor looks about the same.  You can just as easily use an  IN-LIST  now that there is only one search parameter.']], [['  my_external_input.extend(2);\n my_external_input:= num_tbl_type(1, 4);\n']], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22668248, 8), [['The cursor looks about the same.  You can just as easily use an  IN-LIST  now that there is only one search parameter.'], ['The searching portion of this operation is now isolated and dynamic.  It does not need to be changed.  All the Changes happen in the calling PL/SQL block where the search ID values are a lot easier to read and change.']], [['  CURSOR find_course_cur IS           \n    SELECT crs.depid, crs.course\n      FROM zz_course_new crs, \n           (SELECT column_value as recid\n              FROM TABLE (CAST (p_search_ids AS num_tbl_type))\n           ) search_values\n     WHERE crs.recid = search_values.recid;\n']], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22668248, 9), [['The searching portion of this operation is now isolated and dynamic.  It does not need to be changed.  All the Changes happen in the calling PL/SQL block where the search ID values are a lot easier to read and change.'], ['-10000']], [['  DECLARE\n    my_input_external   num_tbl_type:= num_tbl_type();\n\n BEGIN\n    my_input_external.extend(3);\n    my_input_external:= num_tbl_type(1,3,22);\n\n    ZZ_PROC_COURSE_SEARCH (p_search_ids => my_input_external);\n\n END; \n\n\n -- The OUTPUT (Currently set to DBMS_OUT)\n\n\n DEPID: 1,  COURSE: A\n DEPID: 4,  COURSE: D\n DEPID: 7,  COURSE: G\n\n Statement processed.\n\n 0.01 seconds\n']], ["Using array of Records in 'IN' operator in Oracle"], 10, 0], [(22697790, 0), [['You can just subtract the two values:'], ['Alternatively, construct a value of +1 or -1 for each record, and take the sum over that:']], [[" SELECT (SELECT COUNT(ID)\n        FROM Used\n        WHERE ID = 54\n          AND QTY = 1.875\n          AND DateReceived = '2014-03-27 00:00:00'\n          AND VendorID = 12400\n          AND WithDrawn = 0) -\n       (SELECT COUNT(ID)\n        FROM Used\n        WHERE ID = 54\n          AND QTY = 1.875\n          AND DateReceived = '2014-03-27 00:00:00'\n          AND VendorID = 12400\n          AND WithDrawn = 1);\n"]], ['Get the difference returned from two queries as the return of one query'], 2, 1], [(22697790, 1), [['Alternatively, construct a value of +1 or -1 for each record, and take the sum over that:'], ['-10000']], [[" SELECT SUM(CASE WithDrawn WHEN 0 THEN 1 ELSE -1 END)\nFROM Used\nWHERE ID = 54\n  AND QTY = 1.875\n  AND DateReceived = '2014-03-27 00:00:00'\n  AND VendorID = 12400;\n"]], ['Get the difference returned from two queries as the return of one query'], 2, 1], [(22724852, 0), [['Grouped by month: '], ['OR Grouped by year: ']], [[" SELECT c1.monthNum\n    , sum(c1.cost) as cost\nFROM \n(\n    SELECT to_char(t1.date1, 'MM') as monthNum, SUM(t1.cost1)  as cost\n    FROM table1 t1\n    WHERE ..your table1 where clause here...\n    GROUP BY to_char(t1.date1, 'MM') \n\n    UNION ALL\n\n    SELECT to_char(t2.date1, 'MM') as monthNum, SUM(t2.cost1)  as cost\n    FROM table1 t2\n    WHERE ..your table2 where clause here...    \n    GROUP BY to_char(t2.date1, 'MM')\n) c1\nGROUP BY c1.monthNum\n"]], ['Oracle combining two monthly sums from to different tables'], 2, 1], [(22724852, 1), [['OR Grouped by year: '], ['-10000']], [[" SELECT c1.yearNum\n    , c1.monthNum\n    , sum(c1.cost) as cost\nFROM \n(\n    SELECT to_char(t1.date1, 'YYYY') AS yearNum, to_char(t1.date1, 'MM') as monthNum, SUM(t1.cost1)  as cost\n    FROM table1 t1\n    WHERE ..your table1 where clause here...\n    GROUP BY to_char(t1.date1, 'YYYY'), to_char(t1.date1, 'MM') \n\n    UNION ALL\n\n    SELECT to_char(t2.date1, 'YYYY') AS yearNum, to_char(t2.date1, 'MM') as monthNum, SUM(t2.cost1)  as cost\n    FROM table1 t2\n    WHERE ..your table2 where clause here...    \n    GROUP BY to_char(t2.date1, 'YYYY'), to_char(t2.date1, 'MM')\n) c1\nGROUP BY c1.yearNum, c1.monthNum\n"]], ['Oracle combining two monthly sums from to different tables'], 2, 1], [(22738933, 0), [['Download  Solr  distribution:'], ['Start Solr using embedded Jetty container:']], [[' wget http://www.apache.org/dist/lucene/solr/4.7.0/solr-4.7.0.tgz\ntar zxvf solr-4.7.0.tgz\n']], ['What are the ways to store and search complex numeric data?'], 7, 0], [(22738933, 1), [['Start Solr using embedded Jetty container:'], ['Solr should now be running locally']], [[' cd solr-4.7.0/example\njava -jar start.jar\n']], ['What are the ways to store and search complex numeric data?'], 7, 0], [(22738933, 2), [['Solr should now be running locally'], ['-10000']], [[' http://localhost:8983/solr\n']], ['What are the ways to store and search complex numeric data?'], 7, 0], [(22738933, 3), [['-10000'], ['Notes:']], [[' <add>\n  <doc>\n    <field name="id">1</field>\n    <field name="toy_type_s">Dog</field>\n    <field name="toy_subtype_s">Spotted</field>\n    <field name="toy_maker_s">John</field>\n    <field name="color_s">White</field>\n    <field name="estimated_spots_i">10</field>\n    <field name="actual_spots_i">11</field>\n  </doc>\n  <doc>\n    <field name="id">2</field>\n    <field name="toy_type_s">Cat</field>\n    <field name="toy_subtype_s">Striped</field>\n    <field name="toy_maker_s">Jane</field>\n    <field name="color_s">White</field>\n    <field name="estimated_spots_i">5</field>\n  </doc>\n</add>\n']], ['What are the ways to store and search complex numeric data?'], 7, 0], [(22738933, 4), [['Notes:'], ["It's worth noting that Solr supports other data formats, such as JSON and CSV."]], [[' curl http://localhost:8983/solr/update?commit=true -H "Content-Type: text/xml" --data-binary @data.xml\n']], ['What are the ways to store and search complex numeric data?'], 7, 0], [(22742235, 0), [['Maybe try:'], ['c.txt  will contain:']], [[" paste a.txt b.txt | sed -n '/\\([0-9]\\+\\)[[:space:]]\\+\\1/p' > c.txt\n"]], ['comparing the two values line by line from two different text files'], 4, 0], [(22742235, 1), [['c.txt  will contain:'], ['And']], [[' 10 10\n']], ['comparing the two values line by line from two different text files'], 4, 0], [(22742235, 2), [['And'], ['d.txt  will contain:']], [[" paste a.txt b.txt | sed '/\\([0-9]\\+\\)[[:space:]]\\+\\1/d' > d.txt\n"]], ['comparing the two values line by line from two different text files'], 4, 0], [(22742235, 3), [['d.txt  will contain:'], ['-10000']], [[' 20 30\n30 20\n']], ['comparing the two values line by line from two different text files'], 4, 0], [(22783242, 0), [['-10000'], ['Result:']], [[" with xmlnamespaces('http://schemas.microsoft.com/office/infopath/2003/myXSD/2014-03-29T09:41:23' as my)\nselect M.XMLData.value('(/my:myFields/my:field1/text())[1]', 'int') as field1,\n       M.XMLData.value('(/my:myFields/my:field2/text())[1]', 'int') as field2,\n       M.XMLData.value('(/my:myFields/my:field3/text())[1]', 'bit') as field3,\n       M.XMLData.value('(/my:myFields/my:FormName/text())[1]', 'datetime') as FormName,\n       (\n         select ','+R.X.value('text()[1]', 'nvarchar(max)')\n         from M.XMLData.nodes('/my:myFields/my:Repeating') as R(X)\n         for xml path(''), type\n       ).value('substring(text()[1], 2)', 'nvarchar(max)') as Repeating\nfrom XMLMain as M\n"]], ['How to read XML column in SQL Server 2008?'], 2, 1], [(22783242, 1), [['Result:'], ['-10000']], [[' field1      field2      field3 FormName                Repeating\n----------- ----------- ------ ----------------------- -----------------------\n1           2           1      2014-04-01 15:11:47.000 hi,hello,how are  you?\n']], ['How to read XML column in SQL Server 2008?'], 2, 0], [(22861123, 0), [['Adjusted script to allow for gaps in Sequence'], ['Result:']], [[" DECLARE @t TABLE(Text char(5), Sequence int)\nINSERT @t VALUES\n('ITEM1',1),('ITEM1',2),('ITEM1',3),('ITEM2',4),('ITEM2',5),\n('ITEM3',6),('ITEM2',7),('ITEM2',8),('ITEM1',9),('ITEM1',10)\n\n;WITH x as\n(\n  SELECT Text,Sequence,\n    row_number() OVER (order by Sequence)\n    - row_number() OVER (partition by text order by Sequence) grp\n  FROM @t\n)\nSELECT text, MIN(Sequence) seq, \nFROM x\nGROUP BY text, grp\nORDER BY seq\n"]], ['Preventing removal of rows in a SQL query based on ordinal position'], 2, 1], [(22861123, 1), [['Result:'], ['-10000']], [[' text  seq\nITEM1 1\nITEM2 4\nITEM3 6\nITEM2 7\nITEM1 9\n']], ['Preventing removal of rows in a SQL query based on ordinal position'], 2, 0], [(22872278, 1), [['Edit 1:  \nTo select  city  and  state  as well you need to include it as a  group by  expression:'], ['http://sqlfiddle.com/#!6/4527c/1']], [[' select \naddress_1,max(address_2) as address_2, addressinfo,\ncity, state\nfrom \ntable1 \ngroup by address_1,addressinfo, city, state\n']], ['Remove duplicate address values where length of second column is less than the length of the greatest matching address'], 2, 1], [(22876321, 0), [['Try this:'], ['OR']], [[" SELECT T1.Name, T1.Category, T1.Average\nFROM\n(SELECT  B1.Name, B2.Category, AVG(R1.Stars) as Average\nFROM Business B1\nINNER JOIN Reviews R1\nON B1.ID=R1.BusinessID \nINNER JOIN BusinessCategories B2\nON B2.BusinessID=R1.BusinessID\nWHERE R1.Date >= convert(datetime,'01-6-2011') AND R1.Date <= convert(datetime,'30-6-   2011')\nGROUP BY Name, Category\nORDER BY Category, AVG(R1.Stars) DESC) T1\n\nLEFT JOIN (\nSELECT  B1.Name, B2.Category, AVG(R1.Stars) as Average\nFROM Business B1\nINNER JOIN Reviews R1\nON B1.ID=R1.BusinessID \nINNER JOIN BusinessCategories B2\nON B2.BusinessID=R1.BusinessID\nWHERE R1.Date >= convert(datetime,'01-6-2011') AND R1.Date <= convert(datetime,'30-6-   2011')\nGROUP BY Name, Category\nORDER BY Category, AVG(R1.Stars) DESC) T2 on T2.Average> T1.Average AND T1.Category= T2.Category\nWHERE T2.Name IS NULL\n"]], ['Join 3 tables and select only the top average for each category'], 2, 1], [(22876321, 1), [['OR'], ['-10000']], [[" SELECT Name,Category,Average FROM\n(\nSELECT ROW_NUMBER() OVER(Partition By Category ORDER BY AVG(R1.Stars) DESC) as RN, B1.Name, B2.Category, AVG(R1.Stars) as Average\nFROM Business B1\nINNER JOIN Reviews R1\nON B1.ID=R1.BusinessID \nINNER JOIN BusinessCategories B2\nON B2.BusinessID=R1.BusinessID\nWHERE R1.Date >= convert(datetime,'01-6-2011') AND R1.Date <= convert(datetime,'30-6-   2011')\nGROUP BY Name, Category\nORDER BY Category, AVG(R1.Stars) DESC\n) T\nWHERE RN=1\n"]], ['Join 3 tables and select only the top average for each category'], 2, 1], [(22909997, 0), [['MySQL  LIKE  to the resque:'], ['Alternative -  REGEXP :']], [[" SELECT col1 FROM table1 WHERE col1 LIKE 'FEL%';\n"]], ['Get an array of all columns starting with the same characters.'], 2, 1], [(22909997, 1), [['Alternative -  REGEXP :'], ["Then it's just a matter of writing proper regex. "]], [[" SELECT col1 FROM table1 WHERE col1 REGEXP '(FEL|PRO|VAI).*'\n"]], ['Get an array of all columns starting with the same characters.'], 2, 1], [(22910039, 0), [['Should be the last message so either max(id) or latest datetime in this case, counter_party_id is just an user id the most recent counter_party_id does not mean the max counter_party_id(I found the solution in the answers and I gave props):'], ['or ']], [[' SELECT * \nFROM yourTable \nWHERE counter_party_id = ( SELECT MAX(id) FROM yourTable )\n']], ['SQL select id from a table to query again all at once'], 2, 1], [(22910039, 1), [['or '], ['Reason being is that I simplified the example but I had to implement this in a much more complicated scheme.']], [[' SELECT * \nFROM yourTable \nWHERE counter_party_id = ( SELECT counter_party_id FROM yourTable ORDER BY m.time_send DESC LIMIT 1)\n']], ['SQL select id from a table to query again all at once'], 2, 1], [(22914453, 0), [['then we can reproduce our alter statement with:'], ['the result would be:']], [[" SELECT \n  CONCAT(\n    COLUMN_NAME, \n    ' @new_type', \n    IF(IS_NULLABLE='NO', ' NOT NULL ', ' '), \n    EXTRA\n  ) AS s\nFROM \n  INFORMATION_SCHEMA.COLUMNS \nWHERE \n  TABLE_SCHEMA='test' \n  AND \n  TABLE_NAME='t'\n"]], ['Change column data type in MySQL without losing other metadata (DEFAULT, NOTNULL...)'], 5, 0], [(22914453, 1), [['the result would be:'], ['-10000']], [[" mysql> SET @new_type := 'VARCHAR(10)', @column_name := 'value';\nQuery OK, 0 rows affected (0.00 sec)\n"]], ['Change column data type in MySQL without losing other metadata (DEFAULT, NOTNULL...)'], 5, 0], [(22914453, 2), [['-10000'], ['-10000']], [[" SET @sql = (SELECT CONCAT('ALTER TABLE t CHANGE `',COLUMN_NAME, '` `', COLUMN_NAME, '` ', @new_type, IF(IS_NULLABLE='NO', ' NOT NULL ', ' '), EXTRA) AS s FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA='test' AND TABLE_NAME='t' AND COLUMN_NAME=@column_name);\n"]], ['Change column data type in MySQL without losing other metadata (DEFAULT, NOTNULL...)'], 5, 0], [(22914453, 3), [['-10000'], ['-10000']], [[' mysql> prepare stmt from @sql;\nQuery OK, 0 rows affected (0.00 sec)\nStatement prepared\n']], ['Change column data type in MySQL without losing other metadata (DEFAULT, NOTNULL...)'], 5, 0], [(22914453, 4), [['-10000'], ['-10000']], [[' mysql> execute stmt;\nQuery OK, 0 rows affected (0.22 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n']], ['Change column data type in MySQL without losing other metadata (DEFAULT, NOTNULL...)'], 5, 0], [(22921153, 0), [['Use UNION ALL operator and basic join:'], ['If there is another table that contains pattern values, the task is even easier, just:']], [[" SELECT t.* \nFROM TABLENAME t\nJOIN(\n   SELECT '<val>123</val>' As pattern FROM dual UNION ALL\n   SELECT '<val>245</val>' FROM dual UNION ALL\n   SELECT '<val>234</val>' FROM dual UNION ALL\n   SELECT '<val>323</val>' FROM dual UNION ALL\n   SELECT '<val>163</val>' FROM dual \n) p\nON t.col1 LIKE '%' || p.pattern || '%'\n"]], ['SQL - find all records where col like <pattern>'], 2, 1], [(22921153, 1), [['If there is another table that contains pattern values, the task is even easier, just:'], ['Demo:  http://sqlfiddle.com/#!4/e0318/1']], [[" SELECT t.* \nFROM TABLENAME t\nJOIN AnotherTable p\nON t.col1 LIKE '%' || p.pattern || '%'\n"]], ['SQL - find all records where col like <pattern>'], 2, 1], [(22959571, 0), [["That's easy. You must use a where clause and evaluate the minimum type there."], ['EDIT: In case the types are not ascending as in your example, you will have to get the type of the minimum/maximum id instead of getting the minimum/maximum type:']], [[' SELECT * \nFROM mytable\nWHERE type = (select min(type) from mytable) \nORDER BY id;\n']], ['SQL: Limit by unknown number of occurences'], 2, 1], [(22959571, 1), [['EDIT: In case the types are not ascending as in your example, you will have to get the type of the minimum/maximum id instead of getting the minimum/maximum type:'], ['-10000']], [[' SELECT * \nFROM mytable\nWHERE type = (select type from mytable where id = (select min(id) from mytable)) \nORDER BY id;\n']], ['SQL: Limit by unknown number of occurences'], 2, 1], [(22963994, 0), [['Possibly using a sub query (not tested):-'], ['EDIT - Having played with the test data I think I may have a solution. Not sure if there are any edge cases it fails on though:-']], [[' SELECT problem_id, IF(b.user_id IS NULL, 0, COUNT(*))\nFROM solution a\nLEFT OUTER JOIN\n(\n    SELECT user_id, problem_id, MIN(date) AS min_date\n    FROM solution\n    WHERE correct = true\n    GROUP BY user_id, problem_id\n) b\nON a.problem_id = b.problem_id\nAND a.user_id = b.user_id\nAND a.date < b.min_date\nWHERE a.user_id = ?\nGROUP BY problem_id\n']], ['(Query) Number of tries before the first correct solution'], 2, 1], [(22963994, 1), [['EDIT - Having played with the test data I think I may have a solution. Not sure if there are any edge cases it fails on though:-'], ['This has a sub query to find the lowest date with a correct solution for a user problem and joins that against the list of solutions. It the does a SUM of 1 or 0, with a row counting as 1 if there is no correct solution, or if there is a correct solution and the date of that correct solution is greater or equal this this solutions date.']], [[" SELECT a.user_id, a.problem_id, SUM(IF(b.user_id IS NULL OR a.date <= b.min_date, 1, 0))\nFROM solution a\nLEFT OUTER JOIN \n(\n    SELECT user_id, problem_id, MIN(date) AS min_date\n    FROM solution\n    WHERE correct = 'true'\n    GROUP BY user_id, problem_id\n) b\nON a.problem_id = b.problem_id\nAND a.user_id = b.user_id\nGROUP BY a.user_id, problem_id\n"]], ['(Query) Number of tries before the first correct solution'], 2, 1], [(22986618, 0), [["Example of last year's report"], ['Here is an example of that query with comparisons']], [[' SELECT YEAR(`date`) AS `year`\n    , WEEKOFYEAR(`date`) AS weekno\n    ,Storecode AS storecode\n    , SUM(amount) AS amount\nFROM transactions\nWHERE YEAR(`date`) = YEAR(DATE_SUB(NOW(), INTERVAL 1 YEAR))\nGROUP BY YEAR(`date`), WEEKOFYEAR(`date`), Storecode\n']], ['Compare financial data from this week to the same week last year'], 2, 0], [(22986618, 1), [['Here is an example of that query with comparisons'], ['-10000']], [[' SELECT this.storecode \n   , this.weekno\n   , this.amount AS current_amount\n   , history.amount AS past_amount\nFROM (SELECT YEAR(`date`) AS `year`\n        , WEEKOFYEAR(`date`) AS weekno\n        ,Storecode AS storecode\n        , SUM(amount) AS amount\n      FROM transactions\n      WHERE YEAR(`date`) = YEAR(NOW())\n      GROUP BY YEAR(`date`), WEEKOFYEAR(`date`), Storecode) AS this\nJOIN (SELECT YEAR(`date`) AS `year`\n        , WEEKOFYEAR(`date`) AS weekno\n        ,Storecode AS storecode\n        , SUM(amount) AS amount\n      FROM transactions\n      WHERE YEAR(`date`) = YEAR(DATE_SUB(NOW(), INTERVAL 1 YEAR))\n      GROUP BY YEAR(`date`), WEEKOFYEAR(`date`), Storecode) AS history\n  ON this.weekno = history.weekno\n    AND this.storecode = history.storecode;\n']], ['Compare financial data from this week to the same week last year'], 2, 1], [(23034365, 0), [['Oracle does not support lookaheads.\nWith the products as you show, you can use this:'], ['Another option: it\'s a hack, but if you\'re confident that "product_digits " should never be followed by a "t", you can use this:']], [[" SELECT * FROM TABLENAME WHERE REGEXP_LIKE(PRODUCT, 'product_\\d+(\\s*\\d+)*', 'c');\n"]], ['How to exclude a word from a regular expression in oracle?'], 2, 1], [(23034365, 1), [['Another option: it\'s a hack, but if you\'re confident that "product_digits " should never be followed by a "t", you can use this:'], ['-10000']], [[" SELECT * FROM TABLENAME WHERE REGEXP_LIKE(PRODUCT, 'product_\\d+($|\\s)($|[^t]).*', 'c');\n"]], ['How to exclude a word from a regular expression in oracle?'], 2, 1], [(23035651, 1), [["What isn't clear from your question yet is whether you ultimately only want  bob 's rows returned. If that is the case, both sides of the join need to be filtered in the  WHERE  clause, or usernames matched in the  ON  clause:"], ['-10000']], [[" FROM\n  logs AS main\n  LEFT JOIN logs as rng \n    ON rng.epoch BETWEEN main.epoch AND (a.epoch + INTERVAL 3 HOUR)\n    /* match usernames so the related rows are only bob's\n    AND main.username = rng.username\n"]], ['mySQL show logs within a time range from each message?'], 2, 0], [(23069422, 0), [['Well Basically you want '], ['Answers is just']], [[' Questions, ID and Text\nChoices ID, QuestionID and the text\n']], ['How to create MySQL database for "type" quiz'], 2, 0], [(23069422, 1), [['Answers is just'], ['-10000']], [[" QuestionID, ChoiceID\n\n\nQuestions Table\nId Text \n1  'What is your favourite colour?'\n\nChoices Table\nId, QuestionID, Text\n1   1           'Red'\n2   1           'Blue'\n3   1           'Green'\n4   1           'Pale Blue Green with yellow dots'\n\nAnswers\nVictimID QuestionID ChoiceID\n(userID?)1          4\n"]], ['How to create MySQL database for "type" quiz'], 2, 0], [(23091177, 0), [['One way to do this which is easy to follow is:'], ['But a better, cleaner way:']], [[' SELECT column1, name, column2\nFROM MyTable as mt1\nWHERE column1 in (SELECT Min(column1) FROM MyTable as mt2 GROUP BY column2)\n']], ['Find lowest value in particular group'], 2, 1], [(23091177, 1), [['But a better, cleaner way:'], ['SQLFiddle']], [[' SELECT column1, name, column2\nFROM MyTable as mt1\nINNER JOIN\n(SELECT Min(column1) as minc1 FROM MyTable as mt2 GROUP BY column2) as mt2\nON mt1.column1=mt2.minc1;\n']], ['Find lowest value in particular group'], 2, 1], [(23096845, 0), [['I would first work out where the islands are in your data set, and only after that, work out which ones are overlapped by your query ranges:'], ['Result:']], [[" declare @t table (ID int,StartDate date,EndDate date)\ninsert into @t(ID,StartDate,EndDate) values\n(1   ,'20140105','20140110'),\n(2   ,'20140106','20140111'),\n(3   ,'20140107','20140112'),\n(4   ,'20140108','20140113'),\n(5   ,'20140109','20140114'),\n(6   ,'20140126','20140131'),\n(7   ,'20140127','20140201'),\n(8   ,'20140128','20140202'),\n(9   ,'20140129','20140203'),\n(10  ,'20140130','20140204')\n\ndeclare @Start date\ndeclare @End date\nselect @Start='20140106',@End='20140107'\n\n;With PotIslands as (\n    --Find ranges which aren't overlapped at their start\n    select StartDate,EndDate from @t t where\n        not exists (select * from @t t2 where\n                      t2.StartDate < t.StartDate and\n                      t2.EndDate >= t.StartDate)\n    union all\n    --Extend the ranges by any other ranges which overlap on the end\n    select pi.StartDate,t.EndDate\n    from PotIslands pi\n            inner join\n        @t t\n            on\n                pi.EndDate >= t.StartDate and pi.EndDate < t.EndDate\n), Islands as (\n    select StartDate,MAX(EndDate) as EndDate from PotIslands group by StartDate\n)\nselect * from Islands i where @Start <= i.EndDate and @End >= i.StartDate\n"]], ['How to find overlapping periods recursively in SQL Server'], 2, 1], [(23096845, 1), [['Result:'], ['If you need the individual rows, you can now join the selected islands back to the  @t  table for a simple range query.']], [[' StartDate  EndDate\n---------- ----------\n2014-01-05 2014-01-14\n']], ['How to find overlapping periods recursively in SQL Server'], 2, 0], [(23106523, 0), [['You can use conditional aggregation:'], ['To group this just by date:']], [[" SELECT i.DSTAMP, i.NAME,\n       SUM(CASE WHENn i.CODE = 'IN' THEN i.WEIGHT END) as IN_KG_Weight,\n       SUM(CASE WHENn i.CODE = 'OUT' THEN i.WEIGHT END) as OUT_KG_Weight\nFROM inventory i\nWHERE i.code = 'In'\nGROUP BY i.DSTAMP, i.NAME;\n"]], ['SQL Joining Of Queries'], 2, 1], [(23106523, 1), [['To group this just by date:'], ['This converts the value to a date string, which is fine for ordering.']], [[" SELECT to_char(i.DSTAMP, 'YYYY-MM-DD') as yyyymmdd, i.NAME,\n       SUM(CASE WHENn i.CODE = 'IN' THEN i.WEIGHT END) as IN_KG_Weight,\n       SUM(CASE WHENn i.CODE = 'OUT' THEN i.WEIGHT END) as OUT_KG_Weight\nFROM inventory i\nWHERE i.code = 'In'\nGROUP BY to_char(i.DSTAMP, 'YYYY-MM-DD'), i.NAME;\n"]], ['SQL Joining Of Queries'], 2, 1], [(23116249, 1), [['The variables you are using in this line:'], ['are only visible to awk and in this command. They are not shell variables.\nAlso in your  sed  commands remove those single quotes then you can get the values:']], [[' cat temp1 | awk \'email="$1"; transaction="$2"; ccreceipt="$3";\'\n']], ['string substitution from text file to another string'], 3, 0], [(23116249, 2), [['are only visible to awk and in this command. They are not shell variables.\nAlso in your  sed  commands remove those single quotes then you can get the values:'], ['-10000']], [[' sed "s/EMAIL/$email/"\n']], ['string substitution from text file to another string'], 3, 0], [(23124414, 2), [['my full code is below'], ['-10000']], [[' package com.example.employeeinduction;\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.InputStreamReader;\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.Iterator;\nimport java.util.List;\n\nimport org.apache.http.HttpResponse;\nimport org.apache.http.NameValuePair;\nimport org.apache.http.client.HttpClient;\nimport org.apache.http.client.entity.UrlEncodedFormEntity;\nimport org.apache.http.client.methods.HttpPost;\nimport org.apache.http.impl.client.DefaultHttpClient;\nimport org.apache.http.message.BasicNameValuePair;\nimport org.apache.http.params.BasicHttpParams;\nimport org.apache.http.params.HttpConnectionParams;\nimport org.apache.http.params.HttpParams;\nimport org.json.JSONArray;\nimport org.json.JSONObject;\n\nimport android.app.Activity;\nimport android.app.AlertDialog;\nimport android.app.ProgressDialog;\nimport android.content.Context;\nimport android.content.DialogInterface;\nimport android.content.Intent;\nimport android.content.res.TypedArray;\nimport android.os.AsyncTask;\nimport android.os.Bundle;\nimport android.os.Handler;\nimport android.support.v4.widget.DrawerLayout;\nimport android.util.Log;\nimport android.view.Menu;\nimport android.view.MenuItem;\nimport android.view.View;\nimport android.widget.AdapterView;\nimport android.widget.AdapterView.OnItemClickListener;\nimport android.widget.ArrayAdapter;\nimport android.widget.ImageView;\nimport android.widget.ListView;\nimport android.widget.PopupMenu;\nimport android.widget.PopupMenu.OnMenuItemClickListener;\nimport android.widget.Toast;\n\n\npublic class pdf extends Activity\n{\n\n    ImageView iv;\n    public boolean connect=false,logged=false;\n    public String db_select;\n    ListView l1;\n    AlertDialog alertDialog;\n    String mPwd,UName1="Success",UName,ret,receivedName;\n    public Iterator<String> itr;\n    //private String SERVICE_URL = "http://61.12.7.197:8080/pdf";\n    //private String SERVICE_URL1 = "http://61.12.7.197:8080/url";\n    //private final String SERVICE_URL = "http://10.54.3.208:8080/Employee/person/pdf";\n    //private final String SERVICE_URL1 = "http://10.54.3.208:8080/Employee/person/url";\n    private final String SERVICE_URL = Urlmanager.Address+"pdf";\n    private final String SERVICE_URL1 = Urlmanager.Address+"url";\n    private final String TAG = "Pdf";\n    ArrayList<String> todoItems;\n    Boolean isInternetPresent = false;\n    ConnectionDetector cd;\n    ArrayAdapter<String> aa;\n    public List<String> list1=new ArrayList<String>();\n    public DrawerLayout mDrawerLayout;\n    public ListView mDrawerList;\n    //public ActionBarDrawerToggle mDrawerToggle;\n\n    // NavigationDrawer title "Nasdaq" in this example\n    public CharSequence mDrawerTitle;\n\n    //  App title "Navigation Drawer" in this example \n    public CharSequence mTitle;\n\n    // slider menu items details \n    public String[] navMenuTitles=null;\n    public TypedArray navMenuIcons;\n\n    public ArrayList<NavDrawerItem> navDrawerItems;\n    public NavDrawerListAdapter adapter;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) \n    {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.sliding_project);\n         iv = (ImageView)findViewById(R.id.imageView2);\n        l1 = (ListView)findViewById(R.id.list);\n\n\n        mTitle = mDrawerTitle = getTitle();\n\n        // getting items of slider from array\n        navMenuTitles = getResources().getStringArray(R.array.nav_drawer_items);\n\n        // getting Navigation drawer icons from res \n        navMenuIcons = getResources()\n                .obtainTypedArray(R.array.nav_drawer_icons);\n\n        mDrawerLayout = (DrawerLayout) findViewById(R.id.drawer_layout);\n        mDrawerList = (ListView) findViewById(R.id.list_slidermenu);\n\n        navDrawerItems = new ArrayList<NavDrawerItem>();\n\n\n        // list item in slider at 1 Home Nasdaq details\n        navDrawerItems.add(new NavDrawerItem(navMenuTitles[0], navMenuIcons.getResourceId(0, -1)));\n        // list item in slider at 2 Facebook details\n        navDrawerItems.add(new NavDrawerItem(navMenuTitles[1], navMenuIcons.getResourceId(1, -1)));\n        // list item in slider at 3 Google details\n        navDrawerItems.add(new NavDrawerItem(navMenuTitles[2], navMenuIcons.getResourceId(2, -1)));\n        // list item in slider at 4 Apple details\n\n\n        // Recycle array\n        navMenuIcons.recycle();\n\n        mDrawerList.setOnItemClickListener(new SlideMenuClickListener());\n\n        // setting list adapter for Navigation Drawer\n        adapter = new NavDrawerListAdapter(getApplicationContext(),\n                navDrawerItems);\n        mDrawerList.setAdapter(adapter);\n\n        if (savedInstanceState == null) {\n              displayView(0);\n        }\n\n          iv.setOnClickListener(new View.OnClickListener() {\n\n                @Override\n                public void onClick(View v) {\n\n\n                    PopupMenu popup = new PopupMenu(getBaseContext(), v);\n\n                    /** Adding menu items to the popumenu */\n                    popup.getMenuInflater().inflate(R.menu.main, popup.getMenu());\n\n                    popup.setOnMenuItemClickListener(new OnMenuItemClickListener() {\n\n                        @Override\n                        public boolean onMenuItemClick(MenuItem item) {\n\n                            switch (item.getItemId()){\n                            case R.id.Home:\n                                Intent a = new Intent(pdf.this,Design_Activity.class);\n                                startActivity(a);\n                                //Projects_Accel.this.finish();\n                            //  return true;\n                                break;\n                            case R.id.Logout:\n                                /*Intent z = new Intent(this,MainActivity.class);\n                                z.addFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP);\n                                startActivity(z);\n                                this.finish();*/\n                                Intent z = new Intent(pdf.this,MainActivity.class);\n                                z.setFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP | \n                                        Intent.FLAG_ACTIVITY_CLEAR_TASK |\n                                        Intent.FLAG_ACTIVITY_NEW_TASK);\n                                startActivity(z);\n                                pdf.this.finish();\n                            //  return true;\n                                break;\n                            }\n\n                            return true;\n                        }\n                    });\n                        popup.show();\n                }\n            });\n\n             todoItems = new ArrayList<String>();\n                aa = new ArrayAdapter<String>(this,R.layout.list_row,R.id.title,todoItems);\n                l1.setAdapter(aa);\n                todoItems.clear();\n                Intent intent = getIntent();\n                receivedName = (String) intent.getSerializableExtra("PROJECT");\n                cd = new ConnectionDetector(getApplicationContext());\n                isInternetPresent = cd.isConnectingToInternet();\n                if(isInternetPresent)\n                {\n                try\n                {\n                    validat_user(receivedName);\n                    final Handler handler = new Handler();\n                    handler.postDelayed( new Runnable() {\n\n                        @Override\n                        public void run() {\n                            todoItems.clear();\n                            //alertDialog.cancel();\n                            validat_user(receivedName);\n                            handler.postDelayed( this, 60 * 1000 );\n                        }\n                    }, 60 * 1000 );\n\n\n                }\n\n                catch(Exception e)\n                {\n                    display("Network error.\\nPlease check with your network settings.");\n                }\n                }\n                else\n                {\n                    display("No Internet Connection..");\n                }\n\n                l1.setOnItemClickListener(new OnItemClickListener() {\n                    public void onItemClick(AdapterView<?> parent, View view,\n                        int position, long id) {\n\n                     String name=(String)parent.getItemAtPosition(position);\n\n                     /*Toast.makeText(getBaseContext(), name, Toast.LENGTH_LONG).show();\n                      Intent i = new Intent(getBaseContext(),Webview.class);\n                      i.putExtra("USERNAME", name);\n                      startActivity(i);*/\n                     cd = new ConnectionDetector(getApplicationContext());\n                        isInternetPresent = cd.isConnectingToInternet();\n                     if(isInternetPresent)\n                        {\n                     try\n                        {\n                            validat_user1(receivedName,name);\n\n                        }\n                        catch(Exception e)\n                        {\n                            display("Network error.\\nPlease check with your network settings.");\n\n                        }\n\n                        }\n                     else\n                        {\n                            display("No Internet Connection..");\n                        }\n                    }\n                });\n\n             }      \n    private class SlideMenuClickListener implements\n    ListView.OnItemClickListener {\n@Override\npublic void onItemClick(AdapterView<?> parent, View view, int position,\n        long id) {\n    // display view for selected item\n    displayView(position);\n}\n}\n\n@Override\npublic boolean onCreateOptionsMenu(Menu menu) {\ngetMenuInflater().inflate(R.menu.main, menu);\n//setMenuBackground();\nreturn true;\n}\n\n\n/*@Override\npublic boolean onOptionsItemSelected(MenuItem item) {\n//  title/icon\nif (mDrawerToggle.onOptionsItemSelected(item)) {\n    return true;\n}\n// Handle action bar actions click\nswitch (item.getItemId()) {\ncase R.id.action_settings:\n    return true;\ndefault:\n    return super.onOptionsItemSelected(item);\n}\n}*/\n\n//called when invalidateOptionsMenu() invoke \n\n@Override\npublic boolean onPrepareOptionsMenu(Menu menu) {\n// if Navigation drawer is opened, hide the action items\n//boolean drawerOpen = mDrawerLayout.isDrawerOpen(mDrawerList);\n//menu.findItem(R.id.action_settings).setVisible(!drawerOpen);\nreturn super.onPrepareOptionsMenu(menu);\n}\n\nprivate void displayView(int position) {\n// update the main content with called Fragment\nswitch (position) {\n\ncase 1:\n    //fragment = new Fragment2Profile();\n    Intent i = new Intent(pdf.this,Design_Activity.class);\n    startActivity(i);\n    pdf.this.finish();\n    break;\ncase 2:\n    //fragment = new Fragment3Logout();\n    Intent z = new Intent(pdf.this,MainActivity.class);\n    z.setFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP | \n             Intent.FLAG_ACTIVITY_CLEAR_TASK |\n             Intent.FLAG_ACTIVITY_NEW_TASK);\n        startActivity(z);\n        pdf.this.finish();\n    break;\n\ndefault:\n    break;\n}\n\n\n\n}\n\n\n\n\n        public void display(String msg) \n        {\n            Toast.makeText(pdf.this, msg, Toast.LENGTH_LONG).show();\n        }\n        private void validat_user(String st)\n        {\n\n            WebServiceTask wst = new WebServiceTask(WebServiceTask.POST_TASK, this, "");\n\n           wst.addNameValuePair1("TABLE_NAME", st);\n           // wst.addNameValuePair("Emp_PWD", stg2);\n           // db_select=stg1;\n            //display("I am");\n            wst.execute(new String[] { SERVICE_URL });\n            //display(SERVICE_URL);\n\n        }\n        private void validat_user1(String stg1,String stg2)\n        {\n            db_select=stg1;\n            WebServiceTask wst = new WebServiceTask(WebServiceTask.POST_TASK, this, "Loading...");\n\n            wst.addNameValuePair1("PDF_NAME", stg1);\n            wst.addNameValuePair1("TABLE_NAME1", stg2);\n            wst.execute(new String[] { SERVICE_URL1 });\n\n        }\n        @SuppressWarnings("deprecation")\n        public void no_net()\n        {\n            display( "No Network Connection");\n            final AlertDialog alertDialog = new AlertDialog.Builder(pdf.this).create();\n            alertDialog.setTitle("No Internet Connection");\n            alertDialog.setMessage("You don\'t have internet connection.\\nElse please check the Internet Connection Settings.");\n            //alertDialog.setIcon(R.drawable.error_info);\n            alertDialog.setCancelable(false);\n            alertDialog.setButton("Close", new DialogInterface.OnClickListener() \n            {\n                public void onClick(DialogInterface dialog, int which)\n                {   \n                    alertDialog.cancel();\n                    pdf.this.finish();\n                    System.exit(0);\n                }\n            });\n            alertDialog.setButton2("Use Local DataBase", new DialogInterface.OnClickListener() \n            {\n                public void onClick(DialogInterface dialog, int which)\n                {\n                    display( "Accessing local DataBase.....");\n                    alertDialog.cancel();\n                }\n            });\n            alertDialog.show();\n        }\n\n        private class WebServiceTask extends AsyncTask<String, Integer, String> {\n\n            public static final int POST_TASK = 1;\n\n            private static final String TAG = "WebServiceTask";\n\n            // connection timeout, in milliseconds (waiting to connect)\n            private static final int CONN_TIMEOUT = 12000;\n\n            // socket timeout, in milliseconds (waiting for data)\n            private static final int SOCKET_TIMEOUT = 12000;\n\n            private int taskType = POST_TASK;\n            private Context mContext = null;\n            private String processMessage = "Processing...";\n\n            private ArrayList<NameValuePair> params = new ArrayList<NameValuePair>();\n\n            private ProgressDialog pDlg = null;\n\n            public WebServiceTask(int taskType, Context mContext, String processMessage) {\n\n                this.taskType = taskType;\n                this.mContext = mContext;\n                this.processMessage = processMessage;\n            }\n\n            public void addNameValuePair1(String name, String value) {\n\n                params.add(new BasicNameValuePair(name, value));\n            }\n            @SuppressWarnings("deprecation")\n            private void showProgressDialog() {\n\n                pDlg = new ProgressDialog(mContext);\n                pDlg.setMessage(processMessage);\n                pDlg.setProgressDrawable(mContext.getWallpaper());\n                pDlg.setProgressStyle(ProgressDialog.STYLE_SPINNER);\n                pDlg.setCancelable(false);\n                pDlg.show();\n\n            }\n\n            @Override\n            protected void onPreExecute() {\n\n                showProgressDialog();\n\n            }\n\n            protected String doInBackground(String... urls) {\n\n                String url = urls[0];\n                String result = "";\n\n                HttpResponse response = doResponse(url);\n\n                if (response == null) {\n                    return result;\n                } else {\n\n                    try {\n\n                        result = inputStreamToString(response.getEntity().getContent());\n\n                    } catch (IllegalStateException e) {\n                        Log.e(TAG, e.getLocalizedMessage(), e);\n\n                    } catch (IOException e) {\n                        Log.e(TAG, e.getLocalizedMessage(), e);\n                    }\n\n                }\n\n                return result;\n            }\n\n            @Override\n            protected void onPostExecute(String response) {\n\n                handleResponse(response);\n                pDlg.dismiss();\n\n            }\n\n\n            // Establish connection and socket (data retrieval) timeouts\n            private HttpParams getHttpParams() {\n\n                HttpParams htpp = new BasicHttpParams();\n\n                HttpConnectionParams.setConnectionTimeout(htpp, CONN_TIMEOUT);\n                HttpConnectionParams.setSoTimeout(htpp, SOCKET_TIMEOUT);\n\n                return htpp;\n            }\n\n            private HttpResponse doResponse(String url) {\n\n                // Use our connection and data timeouts as parameters for our\n                // DefaultHttpClient\n                HttpClient httpclient = new DefaultHttpClient(getHttpParams());\n\n                HttpResponse response = null;\n\n                try {\n                    switch (taskType) {\n\n                    case POST_TASK:\n                        HttpPost httppost = new HttpPost(url);\n                        // Add parameters\n                        httppost.setEntity(new UrlEncodedFormEntity(params));\n\n                        response = httpclient.execute(httppost);\n                        break;\n                    }\n                } catch (Exception e) {\n                    display("Remote DataBase can not be connected.\\nPlease check network connection.");\n\n                    Log.e(TAG, e.getLocalizedMessage(), e);\n                    return null;\n\n                }\n\n                return response;\n            }\n\n            private String inputStreamToString(InputStream is) {\n\n                String line = "";\n                StringBuilder total = new StringBuilder();\n\n                // Wrap a BufferedReader around the InputStream\n                BufferedReader rd = new BufferedReader(new InputStreamReader(is));\n\n                try {\n                    // Read response until the end\n                    while ((line = rd.readLine()) != null) {\n                        total.append(line);\n                    }\n                } catch (IOException e) {\n                    Log.e(TAG, e.getLocalizedMessage(), e);\n                }\n\n                // Return full string\n                return total.toString();\n            }\n\n        }\n        public void handleResponse(String response) \n        {    //display("JSON responce is : "+response);\n            if(!response.equals(""))\n            {\n           try {\n\n                JSONObject jso = new JSONObject(response);\n\n\n                      int UName = jso.getInt("status1");\n\n                      if(UName==1)\n                      {\n                            String status = jso.getString("reps1");\n                            ret=status.substring(12,status.length()-2);\n                            todoItems.add(0, ret);\n                            aa.notifyDataSetChanged();\n                      }\n                      else if(UName==-1)\n                      {\n                          String status = jso.getString("status");\n                          //ret=status.substring(12,status.length()-2);\n                          //display(status);\n                            Intent intObj=new Intent(pdf.this,Webview.class);\n                             intObj.putExtra("USERNAME",status);\n                            startActivity(intObj);\n                      }\n                      else if(UName>1)\n                      {\n//                       int count=Integer.parseInt(UName);\n//                       display("Number of Projects have been handling in AFL right now: "+count);\n                        list1=new ArrayList<String>();\n\n                        JSONArray array=jso.getJSONArray("reps1");\n                        for(int i=0;i<array.length();i++)\n                        {\n                            list1.add(array.getJSONObject(i).getString("pdfName"));\n\n                        }Collections.sort(list1);\n                        Collections.reverse(list1);\n                        itr=list1.iterator();\n                        while(itr.hasNext())\n                        {\n                             //str1=itr.next()+"\\n";\n                            todoItems.add(0, itr.next().toString());\n                            aa.notifyDataSetChanged();\n                        }\n\n                        //tv1.setText(str1);\n\n\n                      }  \n                      else\n                      {\n                          final Context context = this;\n                            AlertDialog.Builder alertDialogBuilder = new AlertDialog.Builder(\n                                context);\n\n                            // set title\n                            alertDialogBuilder.setTitle("");\n\n                            // set dialog message\n                            alertDialogBuilder\n                                .setMessage("Records unavailable for this project!")\n                                .setCancelable(false)\n                                .setPositiveButton("Exit",new DialogInterface.OnClickListener() {\n                                    public void onClick(DialogInterface dialog,int id) {\n                                        // if this button is clicked, close\n                                        // current activity\n                                        pdf.this.finish();\n                                    }\n                                  });\n\n                                // create alert dialog\n                                alertDialog = alertDialogBuilder.create();\n\n                                // show it\n                                alertDialog.show();\n                      }\n            } catch (Exception e) {\n                Log.e(TAG, e.getLocalizedMessage(), e);\n                return;\n            }\n            }\n            else\n            {\n                display("unable to reach the server");\n            }\n\n\n        }\n\n\n\n        /**\n         * Slider menu item click listener\n         * */\n        /*private class SlideMenuClickListener implements\n                ListView.OnItemClickListener {\n            @Override\n            public void onItemClick(AdapterView<?> parent, View view, int position,\n                    long id) {\n                // display view for selected item\n                displayView(position);\n            }\n        }\n\n\n        private void displayView(int position) {\n            // update the main content with called Fragment\n        //  Fragment fragment = null;\n            switch (position) {\n            case 0:\n            //  fragment = new Fragment1User();\n                break;\n            case 1:\n            //  fragment = new Fragment2Profile();\n                break;\n            case 2:\n            //  fragment = new Fragment3Logout();\n                break;\n\n            default:\n                break;\n            }\n        }*/\n\n\n}\n']], ['Android auto refresh when new data inserted into listview'], 3, 1], [(23129852, 0), [['Query1 returns a record for each record in the original table, adding the year and quarter from the quarters table.  Note that instead of using the quarters table, you could just as easily calculate the year and quarter from the date.'], ['Query2 uses the results of Query1 and finds the minimum values you need:']], [[' SELECT Table.FName, Table.FValue, Table.VDate, Quarters.Yr, Quarters.Qtr\nFROM [Table], Quarters\nWHERE (((Table.VDate)>=[start] And (Table.VDate)<=[end]));\n']], ['How to use another table fields as a criteria for MS Access'], 3, 0], [(23129852, 1), [['Query2 uses the results of Query1 and finds the minimum values you need:'], ['Query3 matches the results of Query1 and Query2 to show the data on which the minimum value was reached.  Note that I made this a Sum query and used First(VDate), assumining that the minimum value may have occurred more than once and you need only the 1st time it happened.']], [[' SELECT Query1.FName, Query1.Yr, Query1.Qtr, Min(Query1.FValue) AS MinValue\nFROM Query1\nGROUP BY Query1.FName, Query1.Yr, Query1.Qtr;\n']], ['How to use another table fields as a criteria for MS Access'], 3, 0], [(23129852, 2), [['Query3 matches the results of Query1 and Query2 to show the data on which the minimum value was reached.  Note that I made this a Sum query and used First(VDate), assumining that the minimum value may have occurred more than once and you need only the 1st time it happened.'], ["There's probably a clever way to do this all in one query, but this is the way  usually solve similar problems."]], [[' SELECT Query1.FName, Query1.Yr, Query1.Qtr, Query2.MinValue, First(Query1.VDate) AS MidDate, Query1.FValue\nFROM Query1 INNER JOIN Query2 ON (Query1.Qtr = Query2.Qtr) AND (Query1.FValue = Query2.MinValue) AND (Query1.FName = Query2.FName)\nGROUP BY Query1.FName, Query1.Yr, Query1.Qtr, Query2.MinValue, Query1.FValue;\n']], ['How to use another table fields as a criteria for MS Access'], 3, 0], [(23146750, 0), [['If you have table  Projects  then you can correct your query as follows:'], ['OR without table  Projects']], [[" select\n     projectId,\n     IDs = STUFF(\n    (SELECT ','+ CAST(g2.[value] AS VARCHAR(255)) as 'data()' \n      FROM ProjectDetail g2\n      WHERE g2.recordType=1\n            and g1.value=g2.value\n            and g1.recordType=g2.recordType\n            and g1.projectId=g2.projectIdand\n            and g2.auditDate > '01-01-2014'\n      For XML PATH('')\n      ),1,1,'')\nFROM Projects P\nWHERE EXISTS (select projectID\n              from ProjectDetail PD ON P.projectID=PD.ProjectID\n              having count(*)>1)\n"]], ['List records with duplicate values'], 2, 1], [(23146750, 1), [['OR without table  Projects'], ['-10000']], [["    select\n         projectId,\n         IDs = STUFF(\n        (SELECT ','+ CAST(g2.[value] AS VARCHAR(255)) as 'data()' \n          FROM ProjectDetail g2\n          WHERE g2.recordType=1\n                and g1.value=g2.value\n                and g1.recordType=g2.recordType\n                and g1.projectId=g2.projectIdand\n                and g2.auditDate > '01-01-2014'\n          For XML PATH('')\n          ),1,1,'')\n    FROM  (select projectID\n           from ProjectDetail PD\n           having count(*)>1) P\n"]], ['List records with duplicate values'], 2, 1], [(23151081, 0), [["It' a bit different, but I would try something like this:"], ['As an alternative... this should give the same result. Not sure which would be more efficient:']], [[" SELECT a.col1, a.total_count, b.match_count,\n  (100*b.match_count/a.total_count) AS match_percentage\nFROM (\n  SELECT col1, COUNT(*) AS total_count\n  FROM LogTable\n  WHERE Category LIKE '2014-04%'\n  GROUP BY col1\n) a\nJOIN (\n  SELECT col1, COUNT(*) AS match_count\n  FROM LogTable\n  WHERE Category LIKE '2014-04%' AND col2=col3\n  GROUP BY col1\n) b ON a.col1=b.col1\n"]], ['SQL Server: compare two columns in Select and count matches'], 2, 1], [(23151081, 1), [['As an alternative... this should give the same result. Not sure which would be more efficient:'], ["But... beware... I'm not sure all engines are able to reference the subselect column match_count directly in the expression used to build the match_percentage column."]], [[" SELECT col1, total_count,\n  (SELECT COUNT(*)\n   FROM LogTable\n   WHERE Category LIKE '2014-04%' AND col1=a.col1 AND col2=col3\n  ) AS match_count,\n  (100*match_count/total_count) AS match_percentage\nFROM (\n  SELECT col1, COUNT(*) AS total_count\n  FROM LogTable\n  WHERE Category LIKE '2014-04%'\n  GROUP BY col1\n) a\n"]], ['SQL Server: compare two columns in Select and count matches'], 2, 1], [(23151241, 0), [['The SQL standard and most databases support the  DEFAULT VALUES  clause for this:'], ['If the above is not supported, you can still write this statement as a workaround. In fact, the first is specified by the SQL standard to be equivalent to the second:']], [[' INSERT INTO "MIGRATION"."VERSION" DEFAULT VALUES;\n']], ['Create row in table with only auto generated fields - SQL'], 2, 1], [(23151241, 1), [['If the above is not supported, you can still write this statement as a workaround. In fact, the first is specified by the SQL standard to be equivalent to the second:'], ['This will then also work with:']], [[' INSERT INTO "MIGRATION"."VERSION" (ID, VERSION_DATE) VALUES (DEFAULT, DEFAULT);\n']], ['Create row in table with only auto generated fields - SQL'], 2, 1], [(23166266, 0), [['A PL/SQL Stored Procedure is a great way to accomplish your task.  An alternate approach to breaking down your single name field into  FIRST NAME  and  LAST NAME  components could be to use an  Oracle Regular Expression , as in:'], ['A procedure based approach is a good idea; first wrap this query into a cursor definition.  Integrate the cursor within a complete PL/SQL stored procedure DDL script.']], [[" SELECT REGEXP_SUBSTR('MYFIRST MYLAST','[^ ]+', 1, 1) from dual\n-- Result: MYFIRST\n\nSELECT REGEXP_SUBSTR('MYFIRST MYLAST','[^ ]+', 1, 2) from dual\n-- Result: MYLAST\n"]], ['Procedure to insert data from one column into two columns in another table'], 4, 0], [(23166266, 1), [['A procedure based approach is a good idea; first wrap this query into a cursor definition.  Integrate the cursor within a complete PL/SQL stored procedure DDL script.'], ["As you can see from the example block, a long series of DML statements can take place (not just two) for a given cursor record and its values as it is handled by each loop iteration.  Each field may be referenced by the name assigned to them within the cursor SQL statement.  There is a '.' (dot) notation where the handle assigned to the cursor call is the prefix, as in:"]], [[' CREATE or REPLACE PROCEDURE PROC_MYNAME_IMPORT IS\n\n    -- Queries parsed name values from STAFF (the source) table \n\n    CURSOR name_cursor IS\n       SELECT REGEXP_SUBSTR(staff.name,...) as FirstName,\n              REGEXP_SUBSTR(... ) as LastName\n         FROM STAFF;\n\n    BEGIN\n\n       FOR i IN name_cursor LOOP\n\n          --DML Command 1:\n          INSERT INTO Table_One ( first_name, last_name )\n          VALUES (i.FirstName, i.LastName);\n          COMMIT;\n\n          --DML Command 2:\n          INSERT INTO Table_Two ...\n          COMMIT;\n\n          END LOOP;\n\n    END proc_myname_import;\n']], ['Procedure to insert data from one column into two columns in another table'], 4, 0], [(23166266, 2), [["As you can see from the example block, a long series of DML statements can take place (not just two) for a given cursor record and its values as it is handled by each loop iteration.  Each field may be referenced by the name assigned to them within the cursor SQL statement.  There is a '.' (dot) notation where the handle assigned to the cursor call is the prefix, as in:"], ['Then the cursor call for looping through the main record set:']], [[' CURSOR c1 IS\n   SELECT st.col1, st.col2, st.col3\n     FROM sample_table st\n    WHERE ...\n']], ['Procedure to insert data from one column into two columns in another table'], 4, 0], [(23166266, 3), [['Then the cursor call for looping through the main record set:'], ['-10000']], [[' FOR my_personal_loop IN c1 LOOP\n    ...do this\n    ...do that\n\n    INSERT INTO some_other_table (column_one, column_two, column_three)\n    VALUES (my_personal_loop.col1, my_personal_loop.col2, ...);\n\n    COMMIT;\nEND LOOP;\n\n... and so on.\n']], ['Procedure to insert data from one column into two columns in another table'], 4, 0], [(23176321, 0), [['First thing is in the constructor of the DbContext cast it to IObjectContextAdapter and get access to the ObjectContext.  I make a property for this'], ["Once you have that subscribe to the SavingChanges event - this isn't our exact code some things are copied out of other methods and redone.  This just gives you an idea of what you need to do."]], [[' public virtual ObjectContext ObjContext\n{\n    get\n    {\n        return ((IObjectContextAdapter)this).ObjectContext;\n    }\n}\n']], ['"Convert" Entity Framework program to raw SQL'], 3, 0], [(23176321, 1), [["Once you have that subscribe to the SavingChanges event - this isn't our exact code some things are copied out of other methods and redone.  This just gives you an idea of what you need to do."], ['Why we set the entity to unmodified after the update because you can do ']], [[' ObjContext.SavingChanges += SaveData;\n\nprivate void SaveData(object sender, EventArgs e)\n{\n    var context = sender as ObjectContext;\n    if (context != null)\n    {\n        context.DetectChanges();\n        var tsql = new StringBuilder();\n        var dbParams = new List<KeyValuePair<string, object>>();\n\n        var deletedEntites = context.ObjectStateManager.GetObjectStateEntries(EntityState.Deleted);\n        foreach (var delete in deletedEntites)\n        {\n            // Set state to unchanged - so entity framework will ignore\n            delete.ChangeState(EntityState.Unchanged);\n            // Method to generate tsql for deleting entities\n            DeleteData(delete, tsql, dbParams);\n        }\n\n        var addedEntites = context.ObjectStateManager.GetObjectStateEntries(EntityState.Added);\n        foreach (var add in addedEntites)\n        {\n            // Set state to unchanged - so entity framework will ignore\n            add.ChangeState(EntityState.Unchanged);\n            // Method to generate tsql for added entities\n            AddData(add, tsql, dbParams);\n        }\n\n        var editedEntites = context.ObjectStateManager.GetObjectStateEntries(EntityState.Modified);\n        foreach (var edit in editedEntites)\n        {\n            // Method to generate tsql for updating entities\n            UpdateEditData(edit, tsql, dbParams);\n            // Set state to unchanged - so entity framework will ignore\n            edit.ChangeState(EntityState.Unchanged);\n        }\n        if (!tsql.ToString().IsEmpty())\n        {\n            var dbcommand = Database.Connection.CreateCommand();\n            dbcommand.CommandText = tsql.ToString();\n\n            foreach (var dbParameter in dbParams)\n            {\n                var dbparam = dbcommand.CreateParameter();\n                dbparam.ParameterName = dbParameter.Key;\n                dbparam.Value = dbParameter.Value;\n                dbcommand.Parameters.Add(dbparam);\n            }\n            var results = dbcommand.ExecuteNonQuery();\n        }\n    }\n}\n']], ['"Convert" Entity Framework program to raw SQL'], 3, 0], [(23176321, 2), [['Why we set the entity to unmodified after the update because you can do '], ['to get a list of all the changed properties.  Since all the entities are now marked as unchanged EF will not send any updates to SQL.  ']], [[' var changed properties = edit.GetModifiedProperties();\n']], ['"Convert" Entity Framework program to raw SQL'], 3, 0], [(23219081, 0), [['If you will only have one value per tag per month, you can use a conditional aggregate to choose your record. I have gone for the  MAX  function, but if you only have one value it is arbitrary:'], ['If you will have multiple values then you will need to apply some sort of logic to chose the correct one. In the below example I have gone for the first value for each month:']], [[" DECLARE @Year INT;\nSET @Year = 2013;\n\n-- CONVERT TO A DATE TO ALLOW A SARGEABLE PREDICATE IN THE WHERE CLAUSE\nDECLARE @Date SMALLDATETIME;\nSET @Date = CONVERT(SMALLDATETIME, CONVERT(CHAR(4), @Year) + '0101', 112);\n\nSELECT  Tagname,\n        Jan = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 1 THEN value END),\n        Feb = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 2 THEN value END),\n        Mar = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 3 THEN value END),\n        Apr = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 4 THEN value END),\n        May = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 5 THEN value END),\n        Jun = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 6 THEN value END),\n        Jul = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 7 THEN value END),\n        Aug = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 8 THEN value END),\n        Sep = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 9 THEN value END),\n        Oct = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 10 THEN value END),\n        Nov = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 11 THEN value END),\n        Dec = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 12 THEN value END)\nFROM    runtime.dbo.History\nWHERE   Tagname IN ('Tag1', 'Tag2')\nAND     wwVersion = 'Latest'\nAND     DateTime >= @Date\nAND     DateTime < DATEADD(YEAR, 1, @Date)\nGROUP BY TagName;\n"]], ['SQL code for DB query by date'], 2, 1], [(23219081, 1), [['If you will have multiple values then you will need to apply some sort of logic to chose the correct one. In the below example I have gone for the first value for each month:'], ['-10000']], [[" DECLARE @Year INT;\nSET @Year = 2013;\n\n-- CONVERT TO A DATE TO ALLOW A SARGEABLE PREDICATE IN THE WHERE CLAUSE\nDECLARE @Date SMALLDATETIME;\nSET @Date = CONVERT(SMALLDATETIME, CONVERT(CHAR(4), @Year) + '0101', 112);\n\nSELECT  Tagname,\n        Jan = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 1 THEN value END),\n        Feb = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 2 THEN value END),\n        Mar = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 3 THEN value END),\n        Apr = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 4 THEN value END),\n        May = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 5 THEN value END),\n        Jun = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 6 THEN value END),\n        Jul = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 7 THEN value END),\n        Aug = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 8 THEN value END),\n        Sep = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 9 THEN value END),\n        Oct = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 10 THEN value END),\n        Nov = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 11 THEN value END),\n        Dec = MAX(CASE WHEN DATEPART(MONTH, DateTime) = 12 THEN value END)\nFROM    (   SELECT  TagName, \n                    DateTime,\n                    Value,\n                    RowNum = ROW_NUMBER() OVER(PARTITION BY TagName, DATEPART(MONTH, DateTime), DATEPART(YEAR, DateTime)\n                                                ORDER BY DateTime)\n            FROM    runtime.dbo.History\n            WHERE   Tagname IN ('Tag1', 'Tag2')\n            AND     wwVersion = 'Latest'\n            AND     DateTime >= @Date\n            AND     DateTime < DATEADD(YEAR, 1, @Date)\n        ) h\nWHERE   h.RowNum = 1\nGROUP BY TagName;\n"]], ['SQL code for DB query by date'], 2, 1], [(23225721, 0), [["You can't directly - you have no control over what has been written to the buffer. So you need to not write it in the first place. One way is to keep track of where you are in the output, the list of columns in this case, and only add the comma if you are not on the last item. Using the analytic  row_number()  function can be used for this:"], ['The  rn  pseudocolumn generates a numeric row counter, in descending order in this case. This is the reverse of the order the columns actually appear in - both  order by  clauses use the same value,  column_id , with one descending and the other ascending:']], [[" begin\n  for v_rec in (\n    select column_name,data_type,\n      row_number() over (order by column_id desc) as rn\n    from user_tab_cols\n    where table_name = 'RFI_ATCH_CHKLST_DTL'\n    order by column_id\n  ) loop\n    dbms_output.put('p' || v_rec.column_name);\n    if v_rec.rn != 1 then\n      dbms_output.put(',');\n    end if;\n    dbms_output.new_line;\n  end loop;\nend;\n/\n\npRACD_REMARKS,\npRACD_NA_STS,\npRACD_VAL2_STS,\npRACD_VAL_STS,\npBCLI_CODE,\npBAI_CODE,\npRAH_ID,\npRACD_ID\n"]], ['Remove last character in dbms_output.put_line'], 2, 1], [(23225721, 1), [['The  rn  pseudocolumn generates a numeric row counter, in descending order in this case. This is the reverse of the order the columns actually appear in - both  order by  clauses use the same value,  column_id , with one descending and the other ascending:'], ["So when the row counter goes down to 1, you know you're on the last row from the cursor, and you can use that knowledge to omit the comma."]], [[" select column_id, column_name,\n  row_number() over (order by column_id desc) as rn\nfrom user_tab_cols\nwhere table_name = 'RFI_ATCH_CHKLST_DTL'\norder by column_id;\n\n COLUMN_ID COLUMN_NAME                            RN\n---------- ------------------------------ ----------\n         1 RACD_REMARKS                            8 \n         2 RACD_NA_STS                             7 \n         3 RACD_VAL2_STS                           6 \n         4 RACD_VAL_STS                            5 \n         5 BCLI_CODE                               4 \n         6 BAI_CODE                                3 \n         7 RAH_ID                                  2 \n         8 RACD_ID                                 1 \n"]], ['Remove last character in dbms_output.put_line'], 2, 0], [(23303779, 0), [['UPDATE'], ['INSERT']], [[' UPDATE O\nSET O.Initials  = N.Initials  \nFROM Original_Table O INNER JOIN New_Table N \nON O.ID = N.ID\n']], ['update a table from another table and add new values'], 2, 0], [(23303779, 1), [['INSERT'], ['Important Note']], [[' INSERT INTO Original_Table (ID , Initials)\nSELECT ID , Initials  \nFROM New_Table\nWHERE NOT EXISTS ( SELECT 1 \n                   FROM Original_Table\n                   WHERE ID = Original_Table.ID)\n']], ['update a table from another table and add new values'], 2, 0], [(23349694, 0), [['-10000'], ['Edit']], [[" SELECT  first_name,last_name,school,contest FROM table \nWHERE contest IN ('blah','mah','wah')\nGROUP BY  first_name, last_name, school \nHAVING COUNT(DISTINCT contest)>1\n"]], ['MySQL query to find partial duplicates'], 2, 1], [(23349694, 1), [['Edit'], ['FIDDLE']], [[' SELECT * FROM table t JOIN\n(SELECT  GROUP_CONCAT(id)as ids,first_name,last_name,school,contest FROM table\nWHERE contest IN (1001,1002,1003)\nGROUP BY  first_name, last_name, school \nHAVING COUNT(DISTINCT contest)>1)x\nON FIND_IN_SET(t.id,x.ids)>0\n']], ['MySQL query to find partial duplicates'], 2, 1], [(23369574, 0), [['You can make use of  utl_i18n  package and  unescape_reference()  function in particular. Here is an example:'], ['Result:']], [[" clear screen;\ncolumn res format a7;\n\nselect utl_i18n.unescape_reference(\n          rtrim(\n               xmlagg( -- use of xmlagg() function in \n                       -- this situation seems to be unnecessary \n                       XMLELEMENT(E,'I''m'||':')\n                      ).extract('//text()'),':'\n                )\n        ) as res\n from dual;\n"]], ['How to replace &apos; or any special character in when using XMLELEMENT Oracle'], 2, 1], [(23369574, 1), [['Result:'], ['-10000']], [[" RES   \n-------\nI'm  \n"]], ['How to replace &apos; or any special character in when using XMLELEMENT Oracle'], 2, 0], [(23400658, 0), [['I think what you are after is a inner join. Not sure from your questions which way around you want your data. However this should give you a good clue how to procede and what keywords to lock for in the documentation to go further.'], ['Seems I misunderstood the original question.. sorry. To get what you want you can just do:']], [[' SELECT a.*\nFROM xyz a\nINNER JOIN abc b ON b.account_number = a.account_number;\n']], ['SQL - ALL, Including all values'], 2, 0], [(23400658, 1), [['Seems I misunderstood the original question.. sorry. To get what you want you can just do:'], ['This is called relational division if you want to investigate further.']], [[" SELECT  campaign_id\nFROM    xyz \nWHERE   account_number IN ('1', '2', '3', '5')\nGROUP BY campaign_id\nHAVING  COUNT(DISTINCT account_number) = 4;\n"]], ['SQL - ALL, Including all values'], 2, 1], [(23433143, 0), [['To return all the subscription plan IDs in one row, use GROUP_CONCAT:'], ['To return them in multiple rows:']], [[" SELECT user_id, GROUP_CONCAT(DISTINCT subscription_plan_id), MIN(created_at), MAX(created_at)\nFROM\n  subscriptions\nWHERE \n  created_at BETWEEN '2014-01-01' AND '2014-01-31'\nGROUP BY\n  user_id\nHAVING\n  COUNT(DISTINCT subscription_plan_id) > 1\n"]], ['How to select records that have multiple values in sql?'], 2, 1], [(23433143, 1), [['To return them in multiple rows:'], ['-10000']], [[" SELECT DISTINCT user_id, subscription_plan_id, created_at\nFROM subscriptions s\nWHERE user_id IN (\n    SELECT user_id\n    FROM subscriptions\n    WHERE \n      created_at BETWEEN '2014-01-01' AND '2014-01-31'\n    GROUP BY\n      user_id\n    HAVING\n      COUNT(DISTINCT subscription_plan_id) > 1)\nAND created_at BETWEEN '2014-01-01' AND '2014-01-31'\nORDER BY user_id, created_at\n"]], ['How to select records that have multiple values in sql?'], 2, 1], [(23470309, 0), [['This is a recursive query: For all rooms go to the connecting room till you find the one that has no more connecting room (i.e. connecting room id is 0).'], ['The WITH clause is used to create a recursion here. You see I named it rooms and inside rooms I select from rooms itself. Here is how to read it: Start with the part before UNION ALL. Then recursively do the part after UNION ALL. So, before UNION ALL I only select the records where connectingroomid is zero. In your example you show every room with its connectingroomid except for those with connectingroomid for which you show the room with itself. I use CASE here to do the same. But now that I am explaining this, I notice that connectingroomid is always zero because of the WHERE clause. So the statement can be simplified thus:']], [[' with rooms (roomid, connectingroomid) as \n(\n  select \n    roomid,\n    case when connectingroomid = 0 then \n      roomid \n    else \n      connectingroomid \n    end as connectingroomid\n  from room\n  where connectingroomid = 0\n  union all\n  select room.roomid, rooms.connectingroomid \n  from room\n  inner join rooms on room.connectingroomid = rooms.roomid\n) \nselect * from rooms\norder by connectingroomid, roomid;\n']], ['sql select query self join or loop through to fetch records'], 2, 1], [(23470309, 1), [['The WITH clause is used to create a recursion here. You see I named it rooms and inside rooms I select from rooms itself. Here is how to read it: Start with the part before UNION ALL. Then recursively do the part after UNION ALL. So, before UNION ALL I only select the records where connectingroomid is zero. In your example you show every room with its connectingroomid except for those with connectingroomid for which you show the room with itself. I use CASE here to do the same. But now that I am explaining this, I notice that connectingroomid is always zero because of the WHERE clause. So the statement can be simplified thus:'], ['The SQL fiddle:  http://www.sqlfiddle.com/#!3/46ed0/2 .']], [[' with rooms (roomid, connectingroomid) as \n(\n  select \n    roomid,\n    roomid as connectingroomid\n  from room where connectingroomid = 0\n  union all\n  select room.roomid, rooms.connectingroomid \n  from room\n  inner join rooms on room.connectingroomid = rooms.roomid\n) \nselect * from rooms\norder by connectingroomid, roomid;\n']], ['sql select query self join or loop through to fetch records'], 2, 1], [(23478919, 0), [['Yes, the kind of reference you describe is called a table synonym in SQL Server.'], ['Then you may query it as though it is a table in your primary database.']], [[' USE DBS\nGO\n\nCREATE SYNONYM [dbo].[secondaryTableReference] FOR [DBS].[dbo].[secondaryTable]\nGO\n']], ['Referencing table in another database'], 2, 1], [(23478919, 1), [['Then you may query it as though it is a table in your primary database.'], ['-10000']], [[' SELECT * FROM [dbo].[secondaryTableReference]\n']], ['Referencing table in another database'], 2, 0], [(23507472, 0), [['Try using:'], ['and to output the results:']], [[' $result = mysql_query("SELECT productLine, SUM(buyPrice) AS sum_buy_price, SUM(MSRP) AS sum_msrp FROM myTable group by productLine"); // selecting data through mysql_query()\n']], ['SUM of columns and displaying multiple queries'], 2, 1], [(23507472, 1), [['and to output the results:'], ['-10000']], [[' echo "<table>";\nwhile($row = mysql_fetch_array($result))\n{\n    // we are running a while loop to print all the rows in a table\n    echo "<tr>";  \n    echo "<td align=\'center\' width=\'200\'>" . $row[\'productLine\'] . "</td>";  \n    echo "<td align=\'center\' width=\'200\'>" . $row[\'sum_buy_price\'] . "</td>";  \n    echo "<td align=\'center\' width=\'200\'>" . $row[\'sum_msrp\'] . "</td>";  \n    echo "</tr>"; \n}\necho "</table>";\n']], ['SUM of columns and displaying multiple queries'], 2, 0], [(23527871, 1), [['Once you have verified that the CAST expression is correct, then you can apply it using an UPDATE statement. Again, you can update only those rows which have  [Rate] - FLOOR([Rate]) , thus getting good performance.'], ['This way, you would not need to drop the Rate column.']], [[' UPDATE [dbo].[TES_Tracks]\nSET [Rate] = CAST([Rate] as decimal(28, 6))\nWHERE [Rate] - FLOOR([Rate]) < 0.000001;\n\nALTER TABLE [dbo].[TES_Tracks] ALTER COLUMN [Rate] DECIMAL(28,6);\n']], ['change SQL column from Float to Decimal Type'], 2, 1], [(23552848, 0), [['Depending on what your function is, you can use window functions (sometimes called analytic functions).  For instance, if you wanted the maximum value of  b  for a given  a :'], ['You should be able to do this with analytic functions:']], [[' select a, b, c, max(b) over (partition by a) as d\nfrom table1;\n']], ['Can I add aggregated column without performing a join?'], 2, 1], [(23552848, 1), [['You should be able to do this with analytic functions:'], ['-10000']], [[' select count , avg, variance,\n       (sum(count * avg) over (partition by b) /\n        sum(count) over (partition by b)\n       ) as weighted_average\nfrom view_1;\n']], ['Can I add aggregated column without performing a join?'], 2, 1], [(23594298, 0), [['You can do so'], ['Or if you need the documents with only label 1 and 2 then change']], [[' SELECT * FROM documents d\nRIGHT JOIN doc_labels dl\nON(d.id = dl.doc_id)\nWHERE dl.label_id IN(1,2)\nGROUP BY d.id\nHAVING COUNT(DISTINCT dl.label_id) >= 2 /*this will give you the documents that must have lable 1,2 and can have more lables*/\n']], ['Select all data which is associated in and combination'], 2, 1], [(23594298, 1), [['Or if you need the documents with only label 1 and 2 then change'], ['-10000']], [[' HAVING COUNT(DISTINCT dl.label_id) = 2\n']], ['Select all data which is associated in and combination'], 2, 0], [(23608624, 0), [['You can do so '], ['This will give all the messages from user 1 which are not deleted']], [[' select *\nfrom messages m\nleft join deleted_messages d on d.message_id = m.id\nwhere \n d.message_id IS NULL\nAND m.user_id = 1\n']], ['select rows mysql where the value of the left join is different'], 2, 1], [(23608624, 1), [['This will give all the messages from user 1 which are not deleted'], ['-10000']], [[' select *\nfrom messages m\nwhere not exists\n(select 1 from deleted_messages d where d.message_id = m.id)\nAND m.user_id = 1\n']], ['select rows mysql where the value of the left join is different'], 2, 1], [(23626176, 0), [['Table 1 - partners'], ['Table 2 - single_partners']], [[' |  partner_id  |  name  |  type  |  logo  |\n']], ['Combining data between three tables'], 3, 0], [(23626176, 1), [['Table 2 - single_partners'], ["Now your query to select all that becomes extremely simple (just select the partners, filter the city, order them and you're done), and with a little grouping and a join, you can also select partners sorted by popularity summarized in all cities :"]], [[' |  id  |  partner_id  |  address  |  zipcode  |  city  | pop_men | pop_women | pop_family\n']], ['Combining data between three tables'], 3, 0], [(23626176, 2), [["Now your query to select all that becomes extremely simple (just select the partners, filter the city, order them and you're done), and with a little grouping and a join, you can also select partners sorted by popularity summarized in all cities :"], ['-10000']], [[' SELECT p.*,\n       SUM(pop_men) AS total_pop_men,\n       SUM(pop_women) AS total_pop_women,\n       SUM(pop_family) AS total_pop_family\nFROM partners p\nJOIN single_partners sp ON sp.partner_id = p.partner_id\nGROUP BY partner_id\nORDER BY total_pop_men DESC,\n         total_pop_women DESC,\n         total_pop_family DESC\n']], ['Combining data between three tables'], 3, 1], [(23642201, 1), [['Working from your added attempt:'], ['-10000']], [[" DECLARE @RowsPerPage INT = 10\nDECLARE @PageNumber INT = 6\n\nSELECT *\nFROM (\n    SELECT t1.*\n        ,t3.[timestamp]\n        ,t3.comments\n        ,ROW_NUMBER() OVER (\n            ORDER BY t1.id\n            ) AS RowNum\n    FROM crm_main t1\n    INNER JOIN crm_group_relationships t2 ON t1.id = t2.customerid\n    OUTER APPLY (\n        SELECT TOP 1 t3.[timestamp]\n            ,t3.customerid\n            ,t3.comments\n        FROM crm_comments t3\n        WHERE t1.id = t3.customerid\n        ORDER BY t3.TIMESTAMP ASC\n        ) t3\n    WHERE t1.dealerid = '9999'\n        AND t2.groupid = '251'\n    ) AS x\nWHERE x.RowNum BETWEEN ((@PageNumber - 1) * @RowsPerPage) + 1\n        AND @RowsPerPage * (@PageNumber)\n"]], ['How do I write paging/limits into a SQL query for 2008 R2?'], 2, 1], [(23676371, 0), [['Create a custom instrumentation file named, say CustomInstrumentation.xml, in C:\\ProgramData\\New Relic.NET Agent\\Extensions along side CoreInstrumentation.xml. Add the following content to your custom instrumentation file:'], ['Here is a more concrete example.  First, the instrumentation file:']], [[' <?xml version="1.0" encoding="utf-8"?>\n<extension xmlns="urn:newrelic-extension">\n  <instrumentation>\n    <tracerFactory name="NewRelic.Agent.Core.Tracer.Factories.BackgroundThreadTracerFactory" metricName="Category/Name">\n      <match assemblyName="AssemblyName" className="NameSpace.ClassName">\n        <exactMethodMatcher methodName="MethodName" />\n      </match>\n    </tracerFactory>\n  </instrumentation>\n</extension>\n']], ['Performance monitoring for standalone .NET desktop application with New Relic'], 5, 0], [(23676371, 1), [['Here is a more concrete example.  First, the instrumentation file:'], ['Now some code:']], [[' <?xml version="1.0" encoding="utf-8"?>\n<extension xmlns="urn:newrelic-extension">\n  <instrumentation>\n    <tracerFactory name="NewRelic.Agent.Core.Tracer.Factories.BackgroundThreadTracerFactory" metricName="Background/Bars">\n      <match assemblyName="Foo" className="Foo.Bar">\n        <exactMethodMatcher methodName="Bar1" />\n        <exactMethodMatcher methodName="Bar2" />\n      </match>\n    </tracerFactory>\n    <tracerFactory metricName="Custom/some custom metric name">\n      <match assemblyName="Foo" className="Foo.Bar">\n        <exactMethodMatcher methodName="Bar3" />\n      </match>\n    </tracerFactory>\n  </instrumentation>\n</extension>\n']], ['Performance monitoring for standalone .NET desktop application with New Relic'], 5, 0], [(23676371, 2), [['Now some code:'], ['Here is a simple console app that demonstrates Custom Transactions:']], [[' var foo = new Foo();\nfoo.Bar1(); // Creates a transaction named Bars in category Background\nfoo.Bar2(); // Same here.\nfoo.Bar3(); // Won\'t create a new transaction.  See notes below.\n\npublic class Foo\n{\n    // this will result in a transaction with an External Service request segment in the transaction trace\n    public void Bar1()\n    {\n        new WebClient().DownloadString("http://www.google.com/);\n    }\n\n    // this will result in a transaction that has one segment with a category of "Custom" and a name of "some custom metric name"\n    public void Bar2()\n    {\n        // the segment for Bar3 will contain your SQL query inside of it and possibly an execution plan\n        Bar3();\n    }\n\n    // if Bar3 is called directly, it won\'t get a transaction made for it.\n    // However, if it is called inside of Bar1 or Bar2 then it will show up as a segment containing the SQL query\n    private void Bar3()\n    {\n        using (var connection = new SqlConnection(ConnectionStrings["MsSqlConnection"].ConnectionString))\n        {\n            connection.Open();\n            using (var command = new SqlCommand("SELECT * FROM table", connection))\n            using (var reader = command.ExecuteReader())\n            {\n                reader.Read();\n            }\n        }\n    }\n}\n']], ['Performance monitoring for standalone .NET desktop application with New Relic'], 5, 0], [(23676371, 3), [['Here is a simple console app that demonstrates Custom Transactions:'], ['Use the following custom instrumentation file:']], [[' using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\n\nnamespace ConsoleApplication1\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            Console.WriteLine("Custom Transactions");\n            var t = new CustomTransaction();\n            for (int i = 0; i < 100; ++i )\n                t.StartTransaction();\n        }\n    }\n    class CustomTransaction\n    {\n        public void StartTransaction()\n        {\n            Console.WriteLine("StartTransaction");     \n            Dummy();\n        }\n        void Dummy()\n        {\n            System.Threading.Thread.Sleep(5000);\n        }\n    }\n\n}\n']], ['Performance monitoring for standalone .NET desktop application with New Relic'], 5, 0], [(23676371, 4), [['Use the following custom instrumentation file:'], ['-10000']], [[' <?xml version="1.0" encoding="utf-8"?>\n<extension xmlns="urn:newrelic-extension">\n    <instrumentation>\n        <tracerFactory name="NewRelic.Agent.Core.Tracer.Factories.BackgroundThreadTracerFactory" metricName="Background/CustomTransaction">\n          <match assemblyName="ConsoleApplication1" className="ConsoleApplication1.CustomTransaction">\n            <exactMethodMatcher methodName="StartTransaction" />\n          </match>\n        </tracerFactory>\n        <tracerFactory metricName="Custom/Dummy">\n          <match assemblyName="ConsoleApplication1" className="ConsoleApplication1.CustomTransaction">\n            <exactMethodMatcher methodName="Dummy" />\n          </match>\n        </tracerFactory>\n    </instrumentation>\n</extension>\n']], ['Performance monitoring for standalone .NET desktop application with New Relic'], 5, 0], [(23705421, 0), [['I would think this would solve your problem:'], ['That gets the latest end date.  If you want the end date for the last session, use  row_number() :']], [[' SELECT who.employee_id, course.course_id,\n       MAX(add_months(sess.end_date, vers.valid_for_months))\n']], ['Get the rest of the row in a max group by'], 2, 1], [(23705421, 1), [['That gets the latest end date.  If you want the end date for the last session, use  row_number() :'], ['-10000']], [[" SELECT employee_id, course_id, end_date\nFROM (SELECT who.employee_id, course.course_id, sess.end_date,\n             row_number() over (partition by who.employee_id, course.course_id\n                                order by sess.end_date\n                               ) as seqnum\n      FROM employee_session_join esj\n      JOIN training_session sess on sess.session_id = esj.session_id\n      JOIN course_version vers on vers.version_id = sess.version_id\n      JOIN course course on course.course_id = vers.course_id\n      JOIN employee who on who.employee_id = esj.employee_id\n      WHERE esj.active_flag = 'Y'\n        AND sess.active_flag = 'Y'\n        AND course.active_flag = 'Y'\n        AND who.active_flag = 'Y'\n        AND esj.approval_status = 5 -- successfully passed\n) e\nWHERE seqnum = 1;\n"]], ['Get the rest of the row in a max group by'], 2, 1], [(23768482, 0), [['The destination table structure be'], ['I am getting the result as expected.']], [[' Create table Destination\n(\nid int,\nname varchar(15),\nhike decimal(8,2)\n)\n']], ['SSIS Converting Percent to Decimal'], 2, 0], [(23768482, 1), [['I am getting the result as expected.'], ['']], [[' Select * from Destination\n']], ['SSIS Converting Percent to Decimal'], 2, 0], [(23803359, 0), [['Sub query to get the latest price date, and join to prices:-'], ['EDIT - to cope with multiple rows on sales for an id / size using an additional subquery:-']], [[' SELECT stocks.id, stocks.size, prices.price, SUM(stocks.qty) - sales.qtySold   \nFROM stocks\nINNER JOIN\n(\n    SELECT id, size, MAX(priceDT) AS MaxPriceDate\n    FROM prices\n    GROP BY id, size\n) Sub1\nON stocks.id = Sub1.id AND stocks.size = Sub1.size\nINNER JOIN prices\nON Sub1.id = prices.id AND Sub1.size = prices.size AND Sub1.MaxPriceDate = prices.priceDT\nINNER JOIN sales\nON stocks.id = sales.id AND stocks.size = sales.size\nGROUP BY stocks.id, stocks.size\n']], ['SQL selecting a column, SUM and ORDER BY using three tables'], 6, 1], [(23803359, 1), [['EDIT - to cope with multiple rows on sales for an id / size using an additional subquery:-'], ['So for brandid 100 and size of 90 there are these 2 records from stocks:-']], [[' SELECT stocks.id, stocks.size, prices.price, SUM(stocks.qty) - Sub2.tot_qtySold   \nFROM stocks\nINNER JOIN\n(\n    SELECT id, size, MAX(priceDT) AS MaxPriceDate\n    FROM prices\n    GROUP BY id, size\n) Sub1\nON stocks.id = Sub1.id AND stocks.size = Sub1.size\nINNER JOIN prices\nON Sub1.id = prices.id AND Sub1.size = prices.size AND Sub1.MaxPriceDate = prices.priceDT\nINNER JOIN\n(\n    SELECT id, size, SUM(qtySold) AS tot_qtySold\n    FROM sales\n    GROUP BY id, size\n) Sub2\nON stocks.id = Sub2.id AND stocks.size = Sub2.size\nGROUP BY stocks.id, stocks.size\n']], ['SQL selecting a column, SUM and ORDER BY using three tables'], 6, 1], [(23803359, 2), [['So for brandid 100 and size of 90 there are these 2 records from stocks:-'], ['and this one from sales:-']], [[' brandId size    qtyArr\n(100 ,  90   ,  10),\n(100 ,  90   ,  100),\n']], ['SQL selecting a column, SUM and ORDER BY using three tables'], 6, 0], [(23803359, 3), [['and this one from sales:-'], ['So MySQL will build up table initially containing a set of 2 rows. The first row will contain the first row from stocks and the only matching row from sales. The 2nd row will have the 2nd row from stocks and (again the matching row from sales).']], [[' brandId size    qtySold\n(100,   90, 35),\n']], ['SQL selecting a column, SUM and ORDER BY using three tables'], 6, 0], [(23803359, 4), [['So MySQL will build up table initially containing a set of 2 rows. The first row will contain the first row from stocks and the only matching row from sales. The 2nd row will have the 2nd row from stocks and (again the matching row from sales).'], ['To get around this will likely need a sub query to get the total qtysold for each brand / size, then join the results of that sub query against the stocks table']], [[' brandId size    qtyArr  brandId size    qtySold\n(100,   90, 10, 100,    90, 35),\n(100,   90, 100,    100,    90, 35),\n']], ['SQL selecting a column, SUM and ORDER BY using three tables'], 6, 0], [(23803359, 5), [['To get around this will likely need a sub query to get the total qtysold for each brand / size, then join the results of that sub query against the stocks table'], ['-10000']], [[" SELECT SUM(s.qtyArr), SUM(l.qtySold) \nFROM stocks s \nINNER join \n(\n    SELECT brandId, size, sum(l.qtySold)\n    FROM sales\n    GROUP BY brandId, size\n) l \nON l.brandId = s.brandId\nAND l.size = s.size\nWHERE s.brandId='100' AND s.size='90';\n"]], ['SQL selecting a column, SUM and ORDER BY using three tables'], 6, 0], [(23807485, 1), [['You should be able to use your original query as a subquery that gets a single line and then use a CASE WHEN to convert it to a single string:'], ['Or, you could use my earlier query as subquery and use the MAX function to reduce it to a single line:']], [[" SELECT CASE WHEN has9 = 1 THEN 'has9'\n            WHEN has8 = 1 THEN 'has8'\n            ELSE 'FIX'\n       END as test_version\nFROM (  SELECT MAX(CASE WHEN SUBSTRING(article_code,5,1) IN ('9') THEN 1 ELSE 0 END) AS has9,\n               MAX(CASE WHEN SUBSTRING(article_code,5,1) IN ('8') THEN 1 ELSE 0 END) AS has8\n        FROM xxxx )\n"]], ['How to nest multiple MAX (...) statements in one CASE WHEN Query'], 3, 1], [(23807485, 2), [['Or, you could use my earlier query as subquery and use the MAX function to reduce it to a single line:'], ['-10000']], [[" SELECT CASE WHEN MAX(result_rank) = 3 THEN 'has9'\n            WHEN MAX(result_rank) = 2 THEN 'has8'\n            ELSE 'FIX'\n       END as test_version\nFROM ( SELECT CASE WHEN SUBSTRING(article_code,5,1) IN ('9') THEN 3\n                   ELSE SUBSTRING(article_code,5,1) IN ('8') THEN 2\n                   ELSE 1\n              END as result_rank\n       FROM xxxx )\n"]], ['How to nest multiple MAX (...) statements in one CASE WHEN Query'], 3, 1], [(23821632, 0), [["This is written in SQL Server syntax (for the table variable for the sample data) but it's fairly standard SQL and by looking at the  query reference , I think it should run in BigQuery (once adapted to your actual table):"], ["CTE variant (but, like I said, I couldn't see support for CTEs in the documentation):"]], [[" declare @t table ([order] int, event char(1))\ninsert into @t([order],event) values\n(1,'C'),    (2,'C'),    (3,'C'),    (4,'S'),    (5,'C'),\n(6,'S'),    (7,'C'),    (8,'C'),    (9,'S')\n\nselect\n    t.*,\n    s1.rn\nfrom @t t\n    inner join\n(\nselect\n    *,\n    ROW_NUMBER() OVER (ORDER BY [order]) as rn\nfrom\n    @t\nwhere\n    event='S'\n) s1\n    on\n        t.[order] <= s1.[order]\n    left join\n(\nselect\n    *,\n    ROW_NUMBER() OVER (ORDER BY [order]) as rn\nfrom\n    @t\nwhere\n    event='S'\n) s2\n    on\n        t.[order] <= s2.[order] and\n        s2.[order] < s1.[order]\nwhere\n    s2.[order] is null\n"]], ['How to segment a sequence of event by signal in SQL?'], 2, 1], [(23821632, 1), [["CTE variant (but, like I said, I couldn't see support for CTEs in the documentation):"], ['-10000']], [[" declare @t table ([order] int, event char(1))\ninsert into @t([order],event) values\n(1,'C'),    (2,'C'),    (3,'C'),    (4,'S'),    (5,'C'),\n(6,'S'),    (7,'C'),    (8,'C'),    (9,'S')\n\n;With Numbered as (\n    select\n    *,\n    ROW_NUMBER() OVER (ORDER BY [order]) as rn\nfrom\n    @t\nwhere\n    event='S'\n)\nselect\n    t.*,\n    s1.rn\nfrom @t t\n    inner join\nNumbered s1\n    on\n        t.[order] <= s1.[order]\n    left join\nNumbered s2\n    on\n        t.[order] <= s2.[order] and\n        s2.[order] < s1.[order]\nwhere\n    s2.[order] is null\n"]], ['How to segment a sequence of event by signal in SQL?'], 2, 1], [(23828906, 0), [['-10000'], ['Result:']], [[' SELECT CONVERT(CHAR(5), GETDATE(), 10)\n']], ['Getting Month and Day from a date'], 2, 1], [(23828906, 1), [['Result:'], ['-10000']], [[' 05-23\n']], ['Getting Month and Day from a date'], 2, 0], [(23892604, 0), [['If you are using SQL to merge, a simple SQL can do the delete as well:'], ['An example  not exists :']], [[' delete from database_production.table\nwhere pk not in (select pk from database_temporary.table)\n']], ['Compare two MySQL tables and remove rows that no longer exist'], 2, 1], [(23892604, 1), [['An example  not exists :'], ['Performance Notes: \nAs pointed out by @mgonzalez in the comments on the question, you may want to use a timestamp column (something like last modified) for comparing/merging in general so that you vompare only changed rows. This does not apply to the delete specifically, you cannot use timestamp for the delete because, well, the row would not exist.']], [[' delete from database_production.table p\nwhere not exists (select 1 from database_temporary.table t where t.pk = p.pk)\n']], ['Compare two MySQL tables and remove rows that no longer exist'], 2, 1], [(23907556, 0), [['The query to copy everything to the new table goes like this:'], ['Then:']], [[' SELECT * INTO dbo.NewTable FROM dbo.OldTable WHERE [event id] <> 6030\n']], ['Copying data want to keep to a new table and then rename'], 4, 0], [(23907556, 1), [['Then:'], ['And:']], [[' ALTER TABLE dbo.OldTable\n  RENAME TO dbo.OldTable_History;\n']], ['Copying data want to keep to a new table and then rename'], 4, 0], [(23907556, 2), [['And:'], ['If you want to create the table manually do it then and after that run this:']], [['  ALTER TABLE dbo.NewTable \n  RENAME TO dbo.OldTable;\n']], ['Copying data want to keep to a new table and then rename'], 4, 0], [(23907556, 3), [['If you want to create the table manually do it then and after that run this:'], ['-10000']], [[' INSERT INTO dbo.NewTable\nSELECT * FROM dbo.OldTable WHERE [event id] <> 6030\n']], ['Copying data want to keep to a new table and then rename'], 4, 0], [(23908145, 0), [['Try like this'], ['Query would be like this']], [[" SELECT LEFT(DATENAME(dw, GETDATE()), 3) + ' , ' + CAST(Day(GetDate()) AS Varchar(10))\n"]], ['SQL Server - Change Date Format'], 3, 1], [(23908145, 1), [['Query would be like this'], ['O/P']], [[" SELECT mydate,LEFT(DATENAME(dw, mydate), 3) + ' , ' + CAST(Day(mydate) AS Varchar(10)) As Date \nFrom tbl\n"]], ['SQL Server - Change Date Format'], 3, 1], [(23908145, 2), [['O/P'], ['-10000']], [[' MYDATE        DATE\n2014-04-21    Mon ,21\n2014-04-22    Tue ,22\n2014-04-23    Wed ,23\n2014-04-24    Thu ,24\n']], ['SQL Server - Change Date Format'], 3, 0], [(23924244, 0), [['You can use  EXISTS  for this:'], ['-10000']], [[' select * \nfrom yourtable y\nwhere exists (\n  select 1\n  from yourtable y2\n  where y.id <> y2.id \n    and y.name = y2.name\n    and (y2.startfield between y.startfield and y.endfield\n         or\n         y.startfield between y2.startfield and y2.endfield))\n']], ['How to identify duplicate rows having value within data range in oracle'], 2, 1], [(23948815, 0), [['Use  substring()  to extract the produce code, and group-by with having to find the hits:'], ['If you want a specific one, add a where clause:']], [[' select substring(product_id, 5, len(product_id)) code\nfrom products\ngroup by substring(product_id, 5, len(product_id))\nhaving count(*) > 1\n']], ['SQL: How to find product codes'], 2, 1], [(23948815, 1), [['If you want a specific one, add a where clause:'], ['-10000']], [[" select substring(product_id, 5, len(product_id)) code\nfrom products\nwhere substring(product_id, 5, len(product_id)) = '0700400B'\ngroup by substring(product_id, 5, len(product_id))\nhaving count(*) > 1\n"]], ['SQL: How to find product codes'], 2, 1], [(23950035, 0), [['slower option'], ['faster option']], [[' SELECT id, TIME_TO_SEC(TIMEDIFF(MAX(created_at),MIN(created_at))) as seconds_difference\nFROM table\nGROUP BY id\nHAVING seconds_difference > 3600*24\n']], ["How would you select records from a table based on the difference between 'created' dates with MySQL?"], 2, 1], [(23950035, 1), [['faster option'], ['-10000']], [[' SELECT t1.id, TIME_TO_SEC(TIMEDIFF(t2.created_at, t1.created_at) as seconds_difference\nFROM table t1\nINNER JOIN table t2 ON (t2.id = t1.id AND t2.created_at > t1.created_at)\nWHERE TIME_TO_SEC(TIMEDIFF(t2.created_at, t1.created_at) > 3600*24\n']], ["How would you select records from a table based on the difference between 'created' dates with MySQL?"], 2, 1], [(23954139, 0), [['SQL is still the best way to get all the data you need.  What I would recommend is creating a temp table with the limited values list you want, for instance Monday, Tuesday, etc.  Then you can use the apply operator against your data table and get the not matching day values.'], ['Would return something like:']], [[' SELECT * FROM Days D \nOUTER APPLY \n   ( \n   SELECT * FROM Orders E \n   WHERE DATEPART(wd,e.OrderDate) = D.DayName\n   ) A \n']], ['SSRS report to show missing/ NULL entries Mon to Fri.'], 2, 1], [(23954139, 1), [['Would return something like:'], ['Below you can find an article on the apply operators that you can use:']], [[' DayName    OrderCount  Amount\nMonday     2           50.00\nTuesday    NULL        NULL\nWednesday  5           125.00\nThursday   NULL        NULL\nFriday     7           225.00\n']], ['SSRS report to show missing/ NULL entries Mon to Fri.'], 2, 0], [(23959544, 0), [['Lets start with a table definition and some INSERT statements. This reflects your data before you changed the question.'], ['Now we build a table of integers. This kind of table is useful in many ways; mine has several million rows in it. (There are ways to automate the insert statements.)']], [[" create table log_test (\n  datetime date not null,\n  action varchar(15) not null,\n  username varchar(15) not null,\n  primary key (datetime, action, username)\n);\n\ninsert into log_test values\n('2013-09-30', 'update', 'username'),\n('2013-12-15', 'update', 'username'),\n('2014-03-01', 'update', 'username'),\n('2014-03-02', 'update', 'username'),\n('2014-03-03', 'update', 'username'),\n('2014-03-05', 'update', 'username'),\n('2015-05-20', 'update', 'username');\n"]], ['Sliding, variable "window" with highest density of rows'], 6, 0], [(23959544, 1), [['Now we build a table of integers. This kind of table is useful in many ways; mine has several million rows in it. (There are ways to automate the insert statements.)'], ['This statement gives us the dates from log_test, along with the number of days in the "window" we want to look at. You need to  select distinct , because there might be multiple users with the same dates.']], [[' create table integers (\n  n integer not null,\n  primary key n\n);\ninsert into n values \n (0),  (1),  (2),  (3),  (4),  (5),  (6),  (7),  (8),  (9),\n(10), (11), (12), (13), (14), (15), (16), (17), (18), (19),\n(20), (21), (22), (23), (24), (25), (26), (27), (28), (29),\n(30), (31), (32), (33), (34), (35), (36), (37), (38), (39),\n(40), (41), (42), (43), (44), (45), (46), (47), (48), (49);\n']], ['Sliding, variable "window" with highest density of rows'], 6, 0], [(23959544, 2), [['This statement gives us the dates from log_test, along with the number of days in the "window" we want to look at. You need to  select distinct , because there might be multiple users with the same dates.'], ['-10000']], [[' select distinct datetime, t.n\nfrom log_test\ncross join (select n from integers where n between 10 and 40) t\norder by datetime, t.n;\n']], ['Sliding, variable "window" with highest density of rows'], 6, 0], [(23959544, 3), [['-10000'], ['-10000']], [[' select datetime period_start, datetime + interval t2.n day period_end\nfrom (\n  select distinct datetime, t.n\n  from log_test\n  cross join (select n from integers where n between 10 and 40) t ) t2\norder by period_start, period_end;\n']], ['Sliding, variable "window" with highest density of rows'], 6, 0], [(23959544, 4), [['-10000'], ['-10000']], [[' select username, t3.period_start, t3.period_end, count(datetime) num_rows\nfrom log_test\ninner join (\n  select datetime period_start, datetime + interval t2.n day period_end\n  from (\n    select distinct datetime, t.n\n    from log_test\n    cross join (select n from integers where n between 10 and 40) t ) t2\n  order by period_start, period_end ) t3\non log_test.datetime between t3.period_start and t3.period_end\ngroup by username, t3.period_start, t3.period_end\norder by username, t3.period_start, t3.period_end;\n']], ['Sliding, variable "window" with highest density of rows'], 6, 0], [(23959544, 5), [['-10000'], ['-10000']], [[' select username, \n       t3.period_start, t3.period_end, t3.n, \n       count(datetime) num_rows,\n       count(datetime)/t3.n density\nfrom log_test\ninner join (\n  select datetime period_start, t2.n, datetime + interval t2.n day period_end\n  from (\n    select distinct datetime, t.n\n    from log_test\n    cross join (select n from integers where n between 10 and 40) t ) t2\n  order by period_start, period_end ) t3\non log_test.datetime between t3.period_start and t3.period_end\ngroup by username, t3.period_start, t3.period_end, t3.n\norder by username, density desc;\n']], ['Sliding, variable "window" with highest density of rows'], 6, 0], [(23963860, 0), [['The stylesheet below has two templates. The second one is an identity transform: it simply copies elements and attributes to the result tree. The first template creates an attribute named  id  containing an unique ID. '], ['If you had a XML such as this one:']], [[' <xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">\n    <xsl:strip-space elements="*"/>\n    <xsl:output indent="yes"/>\n\n    <xsl:template match="book">\n        <xsl:copy>\n            <xsl:attribute name="id">\n                <xsl:value-of select="generate-id(.)"/>\n            </xsl:attribute>\n            <xsl:apply-templates select="node()|@*[name() != \'id\']"/>\n        </xsl:copy>\n    </xsl:template>\n\n    <xsl:template match="@*|node()">\n        <xsl:copy>\n            <xsl:apply-templates select="@*|node()"/>\n        </xsl:copy>\n    </xsl:template>\n\n</xsl:stylesheet>\n']], ['Making ID attributes unique in XML'], 6, 0], [(23963860, 1), [['If you had a XML such as this one:'], ['the XSLT above would transform it into this XML:']], [[' <bookstore>\n    <books>\n        <book id="1" other="123"/>\n        <book id="2"/>\n        <book id="2"/>\n        <book id="3">\n            <chapter number="123" id="ch1">Text</chapter>\n        </book>\n        <book id="10"/>\n    </books>\n    <magazines>\n        <mag id="non-book-id"></mag>\n    </magazines>\n</bookstore>\n']], ['Making ID attributes unique in XML'], 6, 0], [(23963860, 2), [['the XSLT above would transform it into this XML:'], ["For creating ID/IDREF links the generated string sequences are better than numbers since you can use them anywhere (numbers and identifiers that start with numbers can't always be used as IDs). But if string sequences are not acceptable and you need  sequential  numbers, you can use XPath node  position()  in XQuery or XSLT to generate a number based on the element's position  in the whole document  (which will be unique). If  all books  are siblings in the same context, you can simply replace the  generate-id(.)  in the stylesheet above for  position() :"]], [[' <bookstore>\n   <books>\n      <book id="d2e3" other="123"/>\n      <book id="d2e4"/>\n      <book id="d2e5"/>\n      <book id="d2e6">\n         <chapter number="123" id="ch1">Text</chapter>\n      </book>\n      <book id="d2e9"/>\n   </books>\n   <magazines>\n      <mag id="non-book-id"/>\n   </magazines>\n</bookstore>\n']], ['Making ID attributes unique in XML'], 6, 0], [(23963860, 3), [["For creating ID/IDREF links the generated string sequences are better than numbers since you can use them anywhere (numbers and identifiers that start with numbers can't always be used as IDs). But if string sequences are not acceptable and you need  sequential  numbers, you can use XPath node  position()  in XQuery or XSLT to generate a number based on the element's position  in the whole document  (which will be unique). If  all books  are siblings in the same context, you can simply replace the  generate-id(.)  in the stylesheet above for  position() :"], ['If you want to  retain the existing IDs  and only generate sequential ones for the duplicates, it will be a bit more complicated but you can achieve that with keys (or XQuery instead of XSLT). The maximum  id  can be obtained in XPath 2.0 using the  max()  function:']], [[' <xsl:template match="book">\n    <xsl:copy>\n        <xsl:attribute name="id">\n            <xsl:value-of select="position()"/>\n        </xsl:attribute>\n        <xsl:apply-templates select="node()|@*[name() != \'id\']"/>\n    </xsl:copy>\n</xsl:template>\n']], ['Making ID attributes unique in XML'], 6, 0], [(23963860, 4), [['If you want to  retain the existing IDs  and only generate sequential ones for the duplicates, it will be a bit more complicated but you can achieve that with keys (or XQuery instead of XSLT). The maximum  id  can be obtained in XPath 2.0 using the  max()  function:'], ['That function does not exist in XPath 1.0, but you can obtain the maximum ID by using:']], [[' max(//book/@id)\n']], ['Making ID attributes unique in XML'], 6, 0], [(23963860, 5), [['That function does not exist in XPath 1.0, but you can obtain the maximum ID by using:'], ['-10000']], [[' //book[not(@id < //book/@id)]/@id\n']], ['Making ID attributes unique in XML'], 6, 0], [(23992536, 0), [['By  extract , do you mean something like:'], ['Explain Regex']], [[" DECLARE\n    match VARCHAR2(255);\nBEGIN\n    match := REGEXP_SUBSTR(subject, '\\d{2}-\\w{3}-\\d{4}', 1, 1, 'im');\nEND;\n"]], ['Extract Date from VARCHAR string ORacle'], 2, 1], [(23992536, 1), [['Explain Regex'], ['-10000']], [[" \\d{2}                    # digits (0-9) (2 times)\n-                        # '-'\n\\w{3}                    # word characters (a-z, A-Z, 0-9, _) (3\n                         # times)\n-                        # '-'\n\\d{4}                    # digits (0-9) (4 times)\n"]], ['Extract Date from VARCHAR string ORacle'], 2, 0], [(23997222, 0), [['This statement will probably prevent everything from working:'], ['You need a space after the table name:']], [[" EXEC ('SELECT *  FROM '+ @tablename +'where  EmployeeID = 102')\n"]], ['Select by a key for all associated records from a denormalizing database'], 2, 0], [(23997222, 1), [['You need a space after the table name:'], ['In addition, your cursor logic seems off.  You should be checking for  @@FETCH_STATUS  and then closing and deallocating the cursor.']], [[" EXEC ('SELECT *  FROM '+ @tablename +' where  EmployeeID = 102')\n"]], ['Select by a key for all associated records from a denormalizing database'], 2, 0], [(24012213, 0), [['Example:'], ['query 1:']], [[' user 1 = John, user 2 = John\nproduct a = toy, product b = toy\norders: 1 a, 1 a, 1 b, 2 a\n']], ['COUNT on Sub Query and Join'], 3, 0], [(24012213, 1), [['query 1:'], ['query 2:']], [[' 2, John, toy\n1, John, toy\n1, John, toy\n']], ['COUNT on Sub Query and Join'], 3, 0], [(24012213, 2), [['query 2:'], ['-10000']], [[' 4, John, toy\n']], ['COUNT on Sub Query and Join'], 3, 0], [(24035933, 1), [['-10000'], ["we just initialize the variables  @prev_toner  and  @prev_sn  on the fly. It's the same as not having this line in the query at all but writing in front of the query"]], [['     , (select @prev_toner:=0, @prev_sn:=SerialNumber from Table1 order by SerialNumber \n']], ['Select a record just if the one before it has a lower value takes too long and fail'], 7, 0], [(24035933, 2), [["we just initialize the variables  @prev_toner  and  @prev_sn  on the fly. It's the same as not having this line in the query at all but writing in front of the query"], ["The columns in the select clause are evaluated one after another, so it's important that you first select this line"]], [[' SET @prev_toner = 0;\nSET @prev_sn = (select serialnumber from your_table order by serialnumber limit 1);\nSELECT ...\n']], ['Select a record just if the one before it has a lower value takes too long and fail'], 7, 0], [(24035933, 3), [["The columns in the select clause are evaluated one after another, so it's important that you first select this line"], ['before you select these two lines']], [[' if(@prev_toner < Remain_Toner_Black and @prev_sn = SerialNumber, 1, 0) as select_it,\n']], ['Select a record just if the one before it has a lower value takes too long and fail'], 7, 0], [(24035933, 4), [['before you select these two lines'], ['Why is that? The last two lines assign just the values of the current rows to the variables. Therefor in this line']], [[' @prev_sn := SerialNumber,\n@prev_toner := Remain_Toner_Black\n']], ['Select a record just if the one before it has a lower value takes too long and fail'], 7, 0], [(24035933, 5), [['Why is that? The last two lines assign just the values of the current rows to the variables. Therefor in this line'], ["Given your query, you don't need all these subqueries. They are very expensive and unnecessary. Actually it's quite insane. In this part of the query"]], [[' if(@prev_toner < Remain_Toner_Black and @prev_sn = SerialNumber, 1, 0) as select_it,\n']], ['Select a record just if the one before it has a lower value takes too long and fail'], 7, 0], [(24035933, 6), [["Given your query, you don't need all these subqueries. They are very expensive and unnecessary. Actually it's quite insane. In this part of the query"], ["you select the  whole table  and  for every row  you count the rows within that group. That's a dependent subquery. All just to have some sort of row number. Then you do this a second time, just so you can join those two temporary tables to get the previous row. Really, no wonder the performance is horrible."]], [['     SELECT  a.ID, \n            a.Time, \n            a.SerialNumber, \n            a.Remain_Toner_Black,\n            a.Remain_Toner_Cyan,\n            a.Remain_Toner_Magenta,\n            a.Remain_Toner_Yellow,\n            (\n                SELECT  COUNT(*)\n                FROM    Reports c\n                WHERE   c.SerialNumber = a.SerialNumber AND\n                        c.ID <= a.ID) AS RowNumber\n    FROM    Reports a\n']], ['Select a record just if the one before it has a lower value takes too long and fail'], 7, 0], [(24040834, 0), [['There is a little trick because of the  T  inside your format, so you have to cut it in two:'], ['EDIT :  A better way exists in a single call to  to_char , as shown in  this other SO post :']], [[" with w as\n(\n  select sysdate d from dual\n)\nselect to_char(w.d, 'yyyy-mm-dd') || 'T' || to_char(w.d, 'hh24:mi:ss')\nfrom w;\n"]], ['converting sysdate to datetime format'], 2, 1], [(24040926, 0), [['-10000'], ['This will find all bookings for rooms on Floor 1']], [[' `SELECT * from Room R\nINNER JOIN Booking B on B.Room_ID = R.Room_ID\nwhere Room_Floor = 1\nAND From_date BETWEEN GETDATE() AND To_date\n`\n']], ['SQL Query Hotel Room from two tables (Type and Availability)'], 2, 1], [(24040926, 1), [['This will find all bookings for rooms on Floor 1'], ['This will find all available rooms on floor 2']], [[' `SELECT * from Room R\nwhere not exists (select * from bookings where Room_ID = R.RoomID and GETDATE()\nBetween From_date AND To_date)\nand Room_Floor = 2`\n']], ['SQL Query Hotel Room from two tables (Type and Availability)'], 2, 1], [(24082669, 0), [['To get all nodes not only from the first level use   /form//*  with  //  instead of  /form/*'], ['To get also parent nodes use syntax  ../.  in  local-name()  call.\nTo get an Index of child inside a parent node and order by it you can use  XQuery expression ']], [[" SELECT distinct Parent.Items.value('local-name(.)', 'varchar(100)') as 'Item'\n    FROM    dbo.FormResults \n    CROSS APPLY xmlformfields.nodes('/form//*') as Parent(Items)\n"]], ['Finding Unknown XML Grandchildren Using SQL'], 3, 0], [(24082669, 1), [['To get also parent nodes use syntax  ../.  in  local-name()  call.\nTo get an Index of child inside a parent node and order by it you can use  XQuery expression '], ['So the final query with order:']], [[' for $i in . return count(../*[. << $i])\n']], ['Finding Unknown XML Grandchildren Using SQL'], 3, 0], [(24082669, 2), [['So the final query with order:'], ['SQLFiddle example']], [[" SELECT distinct \n          Parent.Items.value('local-name(.)', 'varchar(100)') as 'Item',\n          Parent.Items.value('local-name(../.)', 'varchar(100)') as 'ParentItem',\n          Parent.Items.value('for $i in . return count(../*[. << $i])','int') \n              as ChildIndex\n    FROM    dbo.FormResults \n    CROSS APPLY xmlformfields.nodes('/form//*') as Parent(Items)\n    ORDER BY ParentItem,ChildIndex\n"]], ['Finding Unknown XML Grandchildren Using SQL'], 3, 1], [(24116066, 1), [['A superkey is columns with a unique value. A key is a superkey containing no superkey. Figure them out. Here are some:'], ['A foreign key is columns whose value is a value of some key columns. Figure them out. Here are some:']], [[' user_is_teacher keys (uid),(tid)\nmessage_was_sent key mid,(sid,rid,date)\n']], ['Database schema for private messages with many different types of users'], 3, 0], [(24116066, 2), [['A foreign key is columns whose value is a value of some key columns. Figure them out. Here are some:'], ['Suggest you write every design in this format.']], [[' user_is_teacher fk uid to user uid, fk tid to teacher tid\nmessage_was_sent fk sid to user uid, rid to user uid\n']], ['Database schema for private messages with many different types of users'], 3, 0], [(24170440, 1), [['You can  UPDATE  the  NumCars  column with the following statement:'], ['-10000']], [[' UPDATE Driver\nSET NumCars = (\n    SELECT COUNT(*)\n    FROM Cars\n    WHERE Driver.DriverID = Cars.DriverID\n    )\n']], ['SQL set column to row count'], 2, 1], [(24194784, 0), [['Just add hours:'], ['If you need to get results within working hours for each day you need to set the time ranges separately:']], [[' BETWEEN DATEADD(hh, 7, DATEADD(wk, DATEDIFF(wk, 7, GETDATE()), 7))\n    AND DATEADD(hh, 17, DATEADD(wk, DATEDIFF(wk, 11, GETDATE()), 11))\n']], ['Get SQL Results Between Specific Weekdays and Times'], 3, 1], [(24194784, 2), [['Update: if you have other conditions that follows the date/time condition in your WHERE clause do not forget to enclose the conditions with  OR  operator into brackets:'], ['Read about SQL Server operator precedence  here  for more information']], [[' WHERE\n(myDate BETWEEN DATEADD(hh, 7, DATEADD(wk, DATEDIFF(wk, 7, GETDATE()), 7)) \n   AND DATEADD(hh, 17, DATEADD(wk, DATEDIFF(wk, 7, GETDATE()), 7)) OR \n myDate BETWEEN DATEADD(hh, 7, DATEADD(wk, DATEDIFF(wk, 8, GETDATE()), 8)) \n   AND DATEADD(hh, 17, DATEADD(wk, DATEDIFF(wk, 8, GETDATE()), 8)) OR \n myDate BETWEEN DATEADD(hh, 7, DATEADD(wk, DATEDIFF(wk, 9, GETDATE()), 9)) \n   AND DATEADD(hh, 17, DATEADD(wk, DATEDIFF(wk, 8, GETDATE()), 8)) etc.\n) AND Direction = 1 AND VMDuration = 0 AND ... etc.\n']], ['Get SQL Results Between Specific Weekdays and Times'], 3, 1], [(24207240, 0), [['Here is a recursive example that I believe meets your criteria. I added a  ParentId  to the result set, which will be NULL for the root/base file, since it does not have a parent.'], ['Results for @BaseTableID = 1: ']], [[' declare @BaseTableId int;\nset @BaseTableId  = 1;\n\n; WITH cteRecursive as (\n    --anchor/root parent file\n    SELECT null as ParentFileId\n        , f.FileId as ChildFileID\n        , lt.RecursiveId \n        , 0 as [level]\n        , bt.BaseTableId\n    FROM BaseTable bt\n        INNER JOIN Files f\n            on bt.BaseTableId = f.BaseTableId\n        INNER JOIN LinkingTable lt\n            on f.FileId = lt.FileId\n    WHERE bt.BaseTableId = @BaseTableId \n\n    UNION ALL \n\n    SELECT cte.ChildFileID as ParentFileID \n        , f.FileId as ChildFileID\n        , lt.RecursiveId\n        , cte.level + 1 as [level]\n        , cte.BaseTableId\n    FROM cteRecursive cte\n        INNER JOIN Files f on cte.RecursiveId = f.RecursiveId\n        INNER JOIN LinkingTable lt ON lt.FileId = f.FileId\n)\nSELECT * \nFROM cteRecursive\n;\n']], ['Recursive CTE with alternating tables'], 3, 1], [(24207240, 1), [['Results for @BaseTableID = 1: '], ['Results for @BaseTableID = 2: ']], [[' ParentFileId ChildFileID RecursiveId level       BaseTableId\n------------ ----------- ----------- ----------- -----------\nNULL         1           1           0           1\n1            3           2           1           1\n3            4           3           2           1\n']], ['Recursive CTE with alternating tables'], 3, 0], [(24207240, 2), [['Results for @BaseTableID = 2: '], ['-10000']], [[' ParentFileId ChildFileID RecursiveId level       BaseTableId\n------------ ----------- ----------- ----------- -----------\nNULL         2           1           0           2\nNULL         2           4           0           2\n2            6           5           1           2\n6            7           6           2           2\n2            3           2           1           2\n3            4           3           2           2\n']], ['Recursive CTE with alternating tables'], 3, 0], [(24275420, 0), [["For older versions, I guess  WM_CONCAT  would work. Modifying Gordon Linoff's query:"], ['Also refer  this  link for an alternate approach: Including the answer in the link for refernce:']], [[' SELECT T1."PN" as "Part Number", max(T2."QTY") as "Quantity", T2."BRANCH" AS "Location",\n       WM_CONCAT(T3."STOCK") as Bins\nFROM "XYZ"."PARTS" T1 JOIN\n     "XYZ"."BALANCES" T2\n     ON T2."PART_ID" = T1."PART_ID" JOIN\n     "XYZ"."DETAILS" T3\n     ON T3."PART_ID" = T1."PART_ID"\nGROUP BY t1.PN, t2.Branch\nORDER BY "Part Number", "Location";\n']], ['How to group multiple values into a single column in SQL'], 2, 1], [(24275420, 1), [['Also refer  this  link for an alternate approach: Including the answer in the link for refernce:'], ['-10000']], [[" create table countries ( country_name varchar2 (100));\ninsert into countries values ('Albania');\ninsert into countries values ('Andorra');\ninsert into countries values ('Antigua');\n\n\nSELECT SUBSTR (SYS_CONNECT_BY_PATH (country_name , ','), 2) csv\n      FROM (SELECT country_name , ROW_NUMBER () OVER (ORDER BY country_name ) rn,\n                   COUNT (*) OVER () cnt\n              FROM countries)\n     WHERE rn = cnt\nSTART WITH rn = 1\nCONNECT BY rn = PRIOR rn + 1;\n\nCSV                                                                             \n--------------------------\nAlbania,Andorra,Antigua    \n"]], ['How to group multiple values into a single column in SQL'], 2, 1], [(24287463, 0), [['It looks like you want to add'], ['eg:']], [['  WITH ROLLUP\n']], ['Create SQL summary using union'], 2, 0], [(24287463, 1), [['eg:'], ['Depending on the full nature of your query, you may prefer to use  with cube , which is similar. See  http://technet.microsoft.com/en-us/library/ms189305(v=sql.90).aspx']], [[' Select sum(a) as col1, sum(b) as col2\nfrom yourtable\ngroup by something\nwith rollup\n']], ['Create SQL summary using union'], 2, 1], [(24291644, 0), [['MS SQL Server 2008 Schema Setup :'], ['Query 1 :']], [[" CREATE TABLE Table1\n    ([dosage] varchar(144))\n;\n\nINSERT INTO Table1\n    ([dosage])\nVALUES\n    ('Pain Medication. 20 mg/100 mL NS (0.2mg/mL) \n      Therapy: IV PCA Adult / Qualifier: Standard Continuous Rate = 0 mg/hr, \n      IV, Routine PCA Dose = 0.4 mg')\n;\n"]], ['Extracting first available number and its following text from a string'], 3, 0], [(24291644, 1), [['Query 1 :'], ['Results :']], [[" SELECT substring(dosage,\n                 PATINDEX('%[0-9]%',dosage),\n                 PATINDEX('%/%',dosage)-PATINDEX('%[0-9]%',dosage)\n                )\nFROM Table1\n"]], ['Extracting first available number and its following text from a string'], 3, 1], [(24291644, 2), [['Results :'], ['-10000']], [[' | COLUMN_0 |\n|----------|\n|    20 mg |\n']], ['Extracting first available number and its following text from a string'], 3, 0], [(24310683, 0), [['You can do this by using the  GROUPING SETS  extension of the  GROUP BY  clause:'], ['or you could use:']], [[" SELECT  Description, \n        COALESCE(Parition, 'Total') AS Partition,\n        SUM(Total) AS Total\nFROM    MyTable\nGROUP BY GROUPING SETS ((Description, Partition), (Description));\n"]], ['Cursor? Loop? Aggregate up rows data along with row results'], 3, 1], [(24310683, 1), [['or you could use:'], ['Without ROLLUP, you can do this using  UNION ALL :']], [[" SELECT  Description, \n        COALESCE(Parition, 'Total') AS Partition,\n        SUM(Total) AS Total\nFROM    MyTable\nGROUP BY ROLLUP (Description, Partition);\n"]], ['Cursor? Loop? Aggregate up rows data along with row results'], 3, 1], [(24310683, 2), [['Without ROLLUP, you can do this using  UNION ALL :'], ['-10000']], [[" SELECT  Description, \n        Parition,\n        Total\nFROM    MyTable\nUNION ALL\nSELECT  Description, \n        'Total' AS Partition,\n        SUM(Total) AS Total\nFROM    MyTable\nGROUP BY Description;\n"]], ['Cursor? Loop? Aggregate up rows data along with row results'], 3, 1], [(24316425, 1), [['Sybase may or may not support the above.  There are so many different versions of that database that it is hardly worth anything as a tag.  I think this will work on most versions:'], ['-10000']], [[' select sum(a*revcumb) as a_sum, sum(b*revcuma) as b_sum\nfrom (select t.*,\n             (select sum(b) from table t2 where t2.id > t.id) as revcumb,\n             (select sum(a) from table t2 where t2.id > t.id) as revcuma\n      from table t\n     ) t;\n']], ['strange calculate data on a table'], 2, 1], [(24342739, 0), [['You can use CTE :'], ["And then concatenate all rows with the same  NominationId  and  NominationOrderId  with  FOR XML PATH('')  and after that replace the first comma  ,  with  STUFF :"]], [[' WITH cteTbl (NominationId, NominationOrderId, GiftName) AS ( Your Query here)\n']], ['Concatenate rows from a complex select in SQL'], 2, 0], [(24342739, 1), [["And then concatenate all rows with the same  NominationId  and  NominationOrderId  with  FOR XML PATH('')  and after that replace the first comma  ,  with  STUFF :"], ['-10000']], [[" SELECT t.NominationId\n     , t.NominationOrderId\n     , STUFF( ( SELECT ', ' + GiftName\n                FROM cteTbl\n                WHERE NominationId = t.NominationId\n                  AND NominationOrderId = t.NominationOrderId\n                ORDER BY GiftName DESC\n                FOR XML PATH('') ), 1, 1, '')\nFROM cteTbl t \nGROUP BY t.NominationId\n       , t.NominationOrderId\n"]], ['Concatenate rows from a complex select in SQL'], 2, 0], [(24372541, 0), [["Interesting.  Pivot requires an aggregate function to build the 1-5 values, so you'll have to rewrite your inner query probably as a union, and use MAX() as a throwaway aggregate function (throwaway because every record should be unique, so MAX, MIN, SUM, etc. should all return the same value:"], ['Then']], [[' SELECT * INTO #newblah from (\n   SELECT PersonFK, 1 as StrengthIndex, Strength1 as Strength from blah UNION ALL\n   SELECT PersonFK, 2 as StrengthIndex, Strength2 as Strength from blah UNION ALL\n   SELECT PersonFK, 3 as StrengthIndex, Strength3 as Strength from blah UNION ALL\n   SELECT PersonFK, 4 as StrengthIndex, Strength4 as Strength from blah UNION ALL\n   SELECT PersonFK, 5 as StrengthIndex, Strength5 as Strength from blah\n )\n']], ['SQL PIVOT, JOIN, and aggregate function to generate report'], 2, 0], [(24372541, 1), [['Then'], ["The result of that query should be able to be joined back to your other tables to get the Person name, Strength Category, and Team name, so I'll leave that to you.  You don't HAVE to do the first join as a temporary table -- you could do it as a subselect inline, so this could all be done in one SQL query, but that seems painful if you can avoid it."]], [[' select PersonFK, [Achiever], [Activator], [Adaptability], [Analytical], [Belief] .....\nfrom\n(\n  select PersonFK, StrengthIndex, Strength\n  from #newblah\n) pivotsource\npivot\n(\n  max(StrengthIndex)\n  for Strength in ([Achiever], [Activator], [Adaptability], [Analytical], [Belief] ..... )\n) myPivot;\n']], ['SQL PIVOT, JOIN, and aggregate function to generate report'], 2, 0], [(24375773, 0), [['I think you might be looking for something like this:'], ['So when you run:']], [[" CREATE OR REPLACE FUNCTION FUBAR_STR(in_str VARCHAR2) RETURN VARCHAR2 AS\n  out_str VARCHAR2(4000) := '';\nBEGIN\n  FOR i IN 1..LENGTH(in_str) LOOP\n    out_str := out_str || TO_CHAR(ASCII(SUBSTR(in_str,i,1)) - 55);\n  END LOOP;\n  RETURN out_str;\nEND FUBAR_STR;\n"]], ["Replace each letter with it's ASCII code in a string in PL/SQL"], 6, 1], [(24375773, 1), [['So when you run:'], ['Here is the reversible, safer one to use.']], [[" select fubar_str('abcd') from dual;\n"]], ["Replace each letter with it's ASCII code in a string in PL/SQL"], 6, 0], [(24375773, 2), [['Here is the reversible, safer one to use.'], ['So when you run:']], [[" CREATE OR REPLACE FUNCTION FUBAR_STR(in_str VARCHAR2) RETURN VARCHAR2 AS\n  out_str VARCHAR2(32676) := '';\nBEGIN\n  FOR i IN 1..LEAST(LENGTH(in_str),10892) LOOP\n    out_str := out_str || LPAD(TO_CHAR(ASCII(SUBSTR(in_str,i,1)) - 55),3,'0');\n  END LOOP;\n  RETURN out_str;\nEND FUBAR_STR;\n"]], ["Replace each letter with it's ASCII code in a string in PL/SQL"], 6, 1], [(24375773, 3), [['So when you run:'], ["And because I'm really bored tonight:"]], [[" select fubar_str('abcd') from dual;\n"]], ["Replace each letter with it's ASCII code in a string in PL/SQL"], 6, 0], [(24375773, 4), [["And because I'm really bored tonight:"], ['So when you run:']], [[" CREATE OR REPLACE FUNCTION UNFUBAR_STR(in_str VARCHAR2) RETURN VARCHAR2 AS\n  out_str VARCHAR2(10892) := '';\nBEGIN\n  FOR i IN 0..(((LENGTH(in_str) - MOD(LENGTH(in_str),3))/3) - 1) LOOP\n    out_str := out_str || CHR(TO_NUMBER(LTRIM(SUBSTR(in_str,(i * 3) + 1,3),'0')) + 55);\n  END LOOP;\n  RETURN out_str;\nEND UNFUBAR_STR;\n"]], ["Replace each letter with it's ASCII code in a string in PL/SQL"], 6, 1], [(24375773, 5), [['So when you run:'], ['You get: abcd.']], [[" select unfubar_str('042043044045') from dual;\n"]], ["Replace each letter with it's ASCII code in a string in PL/SQL"], 6, 0], [(24391293, 0), [['A CTE is not even necessary. A  plain subquery  does the job as well (tested with pg 9.3):'], ['Or,  what @Richard wrote , a  LATERAL JOIN  works, too. The syntax can be simpler:']], [[' SELECT i, (f).*                     -- decompose here\nFROM  (\n   SELECT i, (slow_func(i)) AS f    -- do not decompose here\n   FROM   generate_series(1, 3) i\n   ) sub;\n']], ['Avoid multiple calls on same function when expanding composite result'], 3, 1], [(24391293, 1), [['Or,  what @Richard wrote , a  LATERAL JOIN  works, too. The syntax can be simpler:'], ['-10000']], [[' SELECT * FROM generate_series(1, 3) i, slow_func(i) f\n']], ['Avoid multiple calls on same function when expanding composite result'], 3, 1], [(24391293, 2), [['-10000'], ['Per documentation:']], [[' CREATE OR REPLACE FUNCTION slow_function(int)\n  RETURNS result_t AS\n$func$\n    -- expensive body\n$func$ LANGUAGE sql IMMUTABLE <b>COST 100000</b>;']], ['Avoid multiple calls on same function when expanding composite result'], 3, 0], [(24438529, 0), [['There may be a simpler way to do this, but often when trying to find missing numbers/dates you need to create those numbers/dates then  LEFT JOIN  to your existing data to find what is missing. You can create the dates in question with a recursive cte:'], ['Then, you  LEFT JOIN  to your table to get a list of missing dates:']], [[" WITH cal AS (SELECT CAST('2014-07-01' AS DATE) dt\n              UNION  ALL\n              SELECT DATEADD(DAY,1,dt)\n              FROM cal\n              WHERE dt < '2014-07-30')\nSELECT *\nFROM cal\n"]], ['How can I find missing date range in sql server 2008?'], 4, 0], [(24438529, 1), [['Then, you  LEFT JOIN  to your table to get a list of missing dates:'], ['Then you need to find out whether or not consecutive rows belong in the same range, or if they have a gap between them, using  DATEDIFF()  and  ROW_NUMBER() :']], [[" WITH cal AS (SELECT CAST('2014-07-01' AS DATE) dt\n              UNION  ALL\n              SELECT DATEADD(DAY,1,dt)\n              FROM cal\n              WHERE dt < '2014-07-30')\nSELECT DISTINCT cal.dt \nFROM  cal\nLEFT JOIN YourTable a\n   ON cal.dt BETWEEN CAST(SS_StartDate AS DATE) AND CAST(SS_EndDate AS DATE)\nWHERE a.SS_StartDate IS NULL\n"]], ['How can I find missing date range in sql server 2008?'], 4, 0], [(24438529, 2), [['Then you need to find out whether or not consecutive rows belong in the same range, or if they have a gap between them, using  DATEDIFF()  and  ROW_NUMBER() :'], ['Then use  MIN()  and  MAX()  to get the ranges:']], [[" WITH cal AS (SELECT CAST('2014-07-01' AS DATE) dt\n              UNION  ALL\n              SELECT DATEADD(DAY,1,dt)\n              FROM cal\n              WHERE dt < '2014-07-30')\n    ,dt_list AS (SELECT DISTINCT cal.dt \n                  FROM  cal\n                  LEFT JOIN YourTable a\n                    ON cal.dt BETWEEN CAST(SS_StartDate AS DATE) AND CAST(SS_EndDate AS DATE)\n                  WHERE a.SS_StartDate IS NULL)        \nSELECT dt\n      ,DATEDIFF(D, ROW_NUMBER() OVER(ORDER BY dt), dt) AS dt_range\nFROM dt_list\n"]], ['How can I find missing date range in sql server 2008?'], 4, 0], [(24438529, 3), [['Then use  MIN()  and  MAX()  to get the ranges:'], ['Demo:   SQL Fiddle']], [[" WITH cal AS (SELECT CAST('2014-07-01' AS DATE) dt\n              UNION  ALL\n              SELECT DATEADD(DAY,1,dt)\n              FROM cal\n              WHERE dt < '2014-07-30')\n    ,dt_list AS (SELECT DISTINCT cal.dt \n                  FROM  cal\n                  LEFT JOIN YourTable a\n                    ON cal.dt BETWEEN CAST(SS_StartDate AS DATE) AND CAST(SS_EndDate AS DATE)\n                  WHERE a.SS_StartDate IS NULL)        \n    ,dt_range AS (SELECT dt\n                         ,DATEDIFF(D, ROW_NUMBER() OVER(ORDER BY dt), dt) AS dt_range\n                  FROM dt_list)\nSELECT  MIN(dt) AS BeginRange\n       ,MAX(dt) AS EndRange\nFROM dt_range\nGROUP BY dt_range;\n--OPTION (MAXRECURSION 0)\n"]], ['How can I find missing date range in sql server 2008?'], 4, 0], [(24497436, 0), [['You could start by looking at all the information:'], ['So replace that  *  with specific column names, alias "class", and go after the data represented by  parent_id . This information is stored in the  category  table - you might be thinking, but I already joined that table! Don\'t care; do it again, only give it a new alias. Remember that your  ON  condition is a bit different - the  products_categories  has done its job already, now you want the row that matches  C.parent_id  - and that you only need certain columns to find the next parent:']], [[' SELECT * FROM products AS P\n        JOIN\n    products_categories AS PC ON P.id = PC.product_id\n        JOIN\n    categories AS C ON PC.category_id = C.id\nWHERE P.id = 1 AN D C.depth = 2;\n\n+----+------------+------------+-------------+----+-----------+-------+---------+\n| id | name       | product_id | category_id | id | parent_id | depth | name    |\n+----+------------+------------+-------------+----+-----------+-------+---------+\n| 1  | Rad Widget | 1          | 3           | 3  | 2         | 2     | Widgets |\n+----+------------+------------+-------------+----+-----------+-------+---------+\n']], ['Select values from different rows in a mysql join'], 3, 0], [(24497436, 1), [['So replace that  *  with specific column names, alias "class", and go after the data represented by  parent_id . This information is stored in the  category  table - you might be thinking, but I already joined that table! Don\'t care; do it again, only give it a new alias. Remember that your  ON  condition is a bit different - the  products_categories  has done its job already, now you want the row that matches  C.parent_id  - and that you only need certain columns to find the next parent:'], ['Repeat the process one more time, aliasing the column you just added and using the new  C1.parent_id  in your next join condition:']], [[" SELECT\n    P.id,\n    P.name,\n    C1.parent_id,\n    C1.depth,\n    C1.name,\n    C.name AS 'class'\nFROM\n    products AS P\n        JOIN\n    products_categories AS PC ON P.id = PC.product_id\n        JOIN\n    categories AS C ON PC.category_id = C.id\n        JOIN\n    categories AS C1 ON C.parent_id = C1.id\nWHERE\n    P.id = 1\n        AND C.depth = 2;\n\n+----+------------+-----------+---------------+---------+\n| id | name       | parent_id | name          | class   |\n+----+------------+-----------+---------------+---------+\n| 1  | Rad Widget | 1         | Miscellaneous | Widgets |\n+----+------------+-----------+---------------+---------+\n"]], ['Select values from different rows in a mysql join'], 3, 0], [(24550681, 0), [['There is a better and cheaper way to do this. This is very very simple and works perfectly.\n With  SELECT INTO  statement you can copy the structure of a table as well as data to another table in same or external databases. \nReference: http://www.w3schools.com/sql/sql_select_into.asp'], ["Here  OrigialDB  is the name of database where you have this table. \n \nIf your table in  OrginalDB  carries data and you don't want to copy data and need to copy only the structure then you may try this-"]], [[" DECLARE @sql VARCHAR(8000)\nSET @sql=''\nSELECT @sql=@sql+'; SELECT * INTO '+name+'.dbo.E_Invent2 FROM OriginalDB.dbo.E_Invent2' FROM sysdatabases WHERE name LIKE 'CM_0%' and name<>'OriginalDB'\nSELECT @sql\nEXEC(@sql)\n"]], ["How to create new table where database's name begin with ...?"], 2, 1], [(24550681, 1), [["Here  OrigialDB  is the name of database where you have this table. \n \nIf your table in  OrginalDB  carries data and you don't want to copy data and need to copy only the structure then you may try this-"], ['This should work else let me know if I can help you.']], [[" DECLARE @sql VARCHAR(8000)   \n\nSET @sql=''\n    SELECT @sql=@sql+'; SELECT * INTO '+name+'.dbo.E_Invent2 FROM OriginalDB.dbo.E_Invent2 WHERE 1<>1' FROM sysdatabases WHERE name LIKE 'CM_0%' and name<>'OriginalDB'\n    SELECT @sql\n    EXEC(@sql)\n"]], ["How to create new table where database's name begin with ...?"], 2, 1], [(24610143, 0), [["I'm not sure if I understood your question correctly, but this gives you all the users created per day:"], ['this one by month:']], [[' SELECT year(userCreated), month(userCreated), day(userCreated), count(*)\nFROM Users\nGROUP BY year(userCreated), month(userCreated), day(userCreated)\n']], ['How to create grouped daily,weekly and monthly reports including calculated fields in SQL Server'], 4, 0], [(24610143, 1), [['this one by month:'], ['and this one by week:']], [[' SELECT year(userCreated), month(userCreated), count(*)\nFROM Users\nGROUP BY year(userCreated), month(userCreated)\n']], ['How to create grouped daily,weekly and monthly reports including calculated fields in SQL Server'], 4, 0], [(24610143, 2), [['and this one by week:'], ['Edit according to you the missing total field I give you here the example for the month query:']], [[' SELECT year(userCreated), datepart(week, userCreated), count(*)\nFROM Users\nGROUP BY year(userCreated), datepart(week, userCreated)\n']], ['How to create grouped daily,weekly and monthly reports including calculated fields in SQL Server'], 4, 0], [(24622282, 0), [['Try  CDate()  to convert your string into a date.'], ['If it doesn\'t work because CDate does not reconize your format you can use DateSerial(year, month, day) to build a Date. You will need to use mid$ and Cint() to build the year, month and day arguments. Something like this for a format "yyyy-mm-dd": ']], [[' select  *  from audience \nwhere CDate(audate) between #01/06/2014# and #01/08/2014#;\n']], ['Select from MS Access Table between two dates?'], 2, 1], [(24622282, 1), [['If it doesn\'t work because CDate does not reconize your format you can use DateSerial(year, month, day) to build a Date. You will need to use mid$ and Cint() to build the year, month and day arguments. Something like this for a format "yyyy-mm-dd": '], ['Hope this helps.']], [[' DateSerial(CInt(mid(audate, 1, 4)), CInt(mid(audate, 6, 2)), CInt(mid(audate, 9, 2))\n']], ['Select from MS Access Table between two dates?'], 2, 1], [(24633875, 0), [['Assuming that you have something like'], ['then the way to do a bulk  insert  of the data from the collection into a heap-organized table would be to use a  FORALL']], [[' CREATE TYPE my_nested_table_type\n    AS TABLE OF <<something>>;\n\nDECLARE\n  l_nt my_nested_table_type;\nBEGIN\n  <<something that populates l_nt>>\n']], ['Oracle: insert from type table'], 2, 0], [(24633875, 1), [['then the way to do a bulk  insert  of the data from the collection into a heap-organized table would be to use a  FORALL'], ['-10000']], [[' FORALL i in 1..l_nt.count\n  INSERT INTO some_table( <<list of columns>> )\n    VALUES( l_nt(i).col1, l_nt(i).col2, ... , l_nt(i).colN );\n']], ['Oracle: insert from type table'], 2, 1], [(24636896, 0), [['How you combine values depends on the database.  That is the only tricky part of a question that is otherwise basic SQL.  Here is an example using the standard  concat()  function:'], ['Depending on the database, the syntax might be:']], [[' select date, concat(event1, event2, event3) as comb_event, count(*)\nfrom example\ngroup by date, concat(event1, event2, event3)\norder by date, concat(event1, event2, event3);\n']], ['SQL sum of all unique values per date'], 4, 1], [(24636896, 1), [['Depending on the database, the syntax might be:'], ['or:']], [[' select date, event1 || event2 || event3 as comb_event, count(*)\nfrom example\ngroup by date, event1 || event2 || event3\norder by date, event1 || event2 || event3;\n']], ['SQL sum of all unique values per date'], 4, 1], [(24636896, 2), [['or:'], ['or event:']], [[' select date, event1 + event2 + event3 as comb_event, count(*)\nfrom example\ngroup by date, event1 + event2 + event3\norder by date, event1 + event2 + event3;\n']], ['SQL sum of all unique values per date'], 4, 1], [(24636896, 3), [['or event:'], ['-10000']], [[' select date, event1 & event2 & event3 as comb_event, count(*)\nfrom example\ngroup by date, event1 & event2 & event3\norder by date, event1 & event2 & event3;\n']], ['SQL sum of all unique values per date'], 4, 1], [(24656842, 0), [['-10000'], ['-- 2020-06-01 00:00:00.000 ']], [[' SELECT CAST(CAST(0xABCD AS INT) AS DATETIME)\n']], ['Revert CAST(0xABCD AS date)'], 2, 1], [(24657408, 0), [['file.sql'], ['mybatch.bat']], [[' set serveroutput on\nvariable out_val varchar2;\nexec &1;\nprint out_val\nexit\n']], ['Pass EXEC command as a variable into .sql'], 2, 0], [(24657408, 1), [['mybatch.bat'], ['-10000']], [[' set procedure=%1\nset param1=%2\nset param2=%3\nset strYN = \' \'\nset command=%procedure%(\'%param1%\', \'%param2%\', :out_val)\n\nrem ** This line stores out_val value Y or N as strYN.\nfor /F "usebackq" %%i in (`sqlplus database/pw@user @"file.sql" "%command%"`) do (\n    set stryn=%%i\n    if /I "!strYN!"=="N" (goto:nextN) else (if /I "!strYN!"=="Y" goto:nextY)\n)\n']], ['Pass EXEC command as a variable into .sql'], 2, 0], [(24660075, 0), [['Using this environment:'], ['CTX_DOC.HIGHLIGHT  has an OUT parameter of a HIGHLIGHT_TAB type, which contains the count of the number of hits within a document.']], [[" create table docs ( id number, text clob, primary key (id) );\n\nTable created.\n\ninsert all\n into docs values (1, to_clob('a dog and a dog'))\n into docs values (2, to_clob('a dog and a cat'))\n into docs values (3, to_clob('just a cat'))\nselect * from dual;\n\n3 rows created.\n\ncreate index i_text_docs on docs(text) indextype is ctxsys.context;\n\nIndex created.\n"]], ['Counting the number of hits for a given search query/term per document in Oracle'], 5, 0], [(24660075, 3), [['This can then be called normally'], ["If possible, it might be simpler to replace the keywords as Gordon notes. I'd use  DBMS_LOB.GETLENGTH()  function instead of simply  LENGTH()  to avoid potential problems, but  REPLACE()  works on CLOBs so this won't be a problem. Something like the following (assuming we're still searching for dogs)"]], [[" select id\n     , to_char(text) as text\n     , docs_count(id, 'dog') as dogs\n     , docs_count(id, 'cat') as cats\n  from docs;\n\n        ID TEXT                  DOGS       CATS\n---------- --------------- ---------- ----------\n         1 a dog and a dog          2          0\n         2 a dog and a cat          1          1\n         3 just a cat               0          1\n"]], ['Counting the number of hits for a given search query/term per document in Oracle'], 5, 0], [(24660075, 4), [["If possible, it might be simpler to replace the keywords as Gordon notes. I'd use  DBMS_LOB.GETLENGTH()  function instead of simply  LENGTH()  to avoid potential problems, but  REPLACE()  works on CLOBs so this won't be a problem. Something like the following (assuming we're still searching for dogs)"], ["It's worth noting that string searching gets progressively slower as strings get larger (hence the need for text indexing) so while this performs fine on the tiny example given it might suffer from performance problems on larger documents."]], [[" select (dbms_lob.getlength(text) - dbms_lob.getlength(replace(text, 'dog')))\n         / length('dog')\n  from docs\n"]], ['Counting the number of hits for a given search query/term per document in Oracle'], 5, 0], [(24669926, 0), [['2 Next, the maximum rank ( next_rank_no ) of the range of ranks which has the same value for  NAME  is determined. Thus, for the example data, row 1 of id=5 would have next_rank_no=5 and row 2 of id=4 would have next_rank_no=3. This version only handles the  NAME  column. If you want to handle additional columns, they must be included in the condition as well. For example, if you want to include a  LOCATION  column, then the join conditions would read as:'], ['3 Finally, the first row for each id is selected. Then, the row corresponding to the  next_rank_no  is selected in a recursive fashion.']], [['   left join sorted_versions sv2 on sv2.id = sv1.id and sv2.rank_no > sv1.rank_no and sv2.name = sv1.name and sv2.location = sv1.location\n  left join sorted_versions sv3 on sv3.id = sv1.id and sv3.rank_no > sv1.rank_no and (sv3.name <> sv1.name or sv3.location <> sv1.location)\n']], ['Use SQL to remove duplicates from a type 2 slowly changing dimension'], 2, 0], [(24669926, 1), [['3 Finally, the first row for each id is selected. Then, the row corresponding to the  next_rank_no  is selected in a recursive fashion.'], ['SQL Fiddle demo']], [[' with sorted_versions as --ranks are assigned within each id group\n(\n  select \n    v1.id,\n    v1.name,\n    v1.RowStartDate,\n    v1.RowEndDate,\n    rank() over (partition by v1.id order by v1.RowStartDate) rank_no\n  from versions v1\n  left join versions v2 on (v1.id = v2.id and v2.RowStartDate = v1.RowEndDate)\n),\nnext_rank as --the maximum rank of the range of ranks which has the same value for NAME\n(\n  select \n  sv1.id id, sv1.rank_no rank_no, COALESCE(min(sv3.rank_no)-1 , COALESCE(max(sv2.rank_no), sv1.rank_no)) next_rank_no\n  from sorted_versions sv1\n  left join sorted_versions sv2 on sv2.id = sv1.id and sv2.rank_no > sv1.rank_no and sv2.name = sv1.name\n  left join sorted_versions sv3 on sv3.id = sv1.id and sv3.rank_no > sv1.rank_no and sv3.name <> sv1.name\n  group by sv1.id, sv1.rank_no\n),\nversions_cte as --the rowenddate of the "maximum rank" is selected \n(\n  select sv.id, sv.name, sv.rowstartdate, sv3.rowenddate, nr.next_rank_no rank_no\n  from sorted_versions sv\n  inner join next_rank nr on sv.id = nr.id and sv.rank_no = nr.rank_no and sv.rank_no = 1\n  inner join sorted_versions sv3 on nr.id = sv3.id and nr.next_rank_no = sv3.rank_no  \n  union all\n  select\n    sv2.id,\n    sv2.name, \n    sv2.rowstartdate,\n    sv3.rowenddate,\n    nr.next_rank_no\n  from versions_cte vc\n  inner join sorted_versions sv2 on sv2.id = vc.id and sv2.rank_no = vc.rank_no + 1\n  inner join next_rank nr on sv2.id = nr.id and sv2.rank_no = nr.rank_no  \n  inner join sorted_versions sv3 on nr.id = sv3.id and nr.next_rank_no = sv3.rank_no\n)\nselect id, name, rowstartdate, rowenddate\nfrom versions_cte\norder by id, rowstartdate;\n']], ['Use SQL to remove duplicates from a type 2 slowly changing dimension'], 2, 0], [(24707125, 0), [["You're correct in thinking of  partition by ; though you'll also need to use a join (or an inline SQL in the results).  Simplified example below:"], ["Here's the alternate version which doesn't use a join:"]], [[' select firstRow.id\n, firstRow.upc\n, firstRow.name\n, sum(d.value) TotalUPCValue\nfrom (\n  select id, upc, name\n  , row_number() over (partition by upc order by id) r\n  from demo\n) firstRow\ninner join demo d on d.upc = firstRow.upc\nwhere firstRow.r = 1\ngroup by firstRow.id\n, firstRow.upc\n, firstRow.name\n']], ["How to merge two SQL rows (same item ID) with the SUM() qty but show only the last row's info?"], 3, 1], [(24707125, 1), [["Here's the alternate version which doesn't use a join:"], ['Thanks to @AndriyM for improving my second version:']], [[' select id\n, upc\n, name\n, (select sum(d.value) from demo d where d.upc = firstRow.upc) TotalUPCValue\nfrom (\n  select id, upc, name\n  , row_number() over (partition by upc order by id) r\n  from demo\n) firstRow\nwhere firstRow.r = 1\n']], ["How to merge two SQL rows (same item ID) with the SUM() qty but show only the last row's info?"], 3, 1], [(24726688, 0), [['Without Dropping the table'], ['If for some reason you have to drop table and re-create it again you could execute the following statements inside your execute sql task.']], [[' TRUNCATE TABLE Test_myTable;\nGO\n\nINSERT INTO Test_myTable (Col1, Col2, Col3, .....)\nSELECT Col1, Col2, Col3, .....\nFROM myTable\nGO\n']], ["Use SSIS To Copy A Table's Structure And Data With A Different Name"], 2, 1], [(24726688, 1), [['If for some reason you have to drop table and re-create it again you could execute the following statements inside your execute sql task.'], ['-10000']], [[" --Drop tables if exists\n\nIF OBJECT_ID('dbo.Test_myTable', 'U') IS NOT NULL\n  DROP TABLE dbo.Test_myTable\nGO\n\n--Create and populate table\nSELECT Col1, Col2, Col3, .....\nINTO dbo.Test_myTable\nFROM myTable\nGO\n"]], ["Use SSIS To Copy A Table's Structure And Data With A Different Name"], 2, 1], [(24779447, 0), [['You need to create a cursor, and set its value to last_insert_id().\nFor example:'], ['Then, in the cursor, you set the last inserted pk(s) for that iteration:']], [['     declare last_insert_pk int;\n    declare last_insert2_pk int;\n']], ["MySQL - Return group of last inserted ID's"], 2, 0], [(24779447, 1), [['Then, in the cursor, you set the last inserted pk(s) for that iteration:'], ['I had to use 8 different primary keys in a giant relation table, however it worked really well.  There may be a better way, but this is understandable and repeatable.']], [['     set last_insert_pk = last_insert_id();\n    -- ...some stuff...\n    set _insert2_pk = last_insert_id();\n']], ["MySQL - Return group of last inserted ID's"], 2, 0], [(24794466, 0), [['It could look like this:'], ['Then, whenever you add a transaction, you update the balance like this:']], [[' CREATE TABLE users (\n    user_id INT PRIMARY KEY,\n    balance BIGINT NOT NULL DEFAULT 0 CHECK(balance>=0)\n);\n']], ['Database Schema Design: Tracking User Balance with concurrency'], 2, 0], [(24794466, 1), [['Then, whenever you add a transaction, you update the balance like this:'], ['You must do this inside a transaction, in which you also insert the transaction record.']], [[' UPDATE user SET balance=balance+$1 WHERE user_id=$2;\n']], ['Database Schema Design: Tracking User Balance with concurrency'], 2, 0], [(24795288, 0), [['Something like this:-'], ['Possible to simplify this a bit to:-']], [[' SELECT orderid, stockid, 0, SEC_TO_TIME((TIME_TO_SEC(next_poss_order_report) + TIME_TO_SEC(last_order_report)) / 2)\nFROM\n(\n    SELECT a.orderid, a.stockid, last_order_report, MIN(b.reported) next_poss_order_report\n    FROM \n    (\n        SELECT orderid, stockid, MAX(reported) last_order_report\n        FROM orders_table\n        GROUP BY orderid, stockid\n    ) a\n    INNER JOIN orders_table b\n    ON a.stockid = b.stockid\n    AND a.last_order_report < b.reported\n    GROUP BY a.orderid, a.stockid, a.last_order_report\n) sub0;\n']], ['INSERT interpolated rows into existing table'], 2, 1], [(24795288, 1), [['Possible to simplify this a bit to:-'], ['These queries might take a while, but are probably more efficient than running many queries from scripted code.']], [[' SELECT a.orderid, a.stockid, 0, SEC_TO_TIME((TIME_TO_SEC(MIN(b.reported)) + TIME_TO_SEC(last_order_report)) / 2)\nFROM \n(\n    SELECT orderid, stockid, MAX(reported) last_order_report\n    FROM orders_table\n    GROUP BY orderid, stockid\n) a\nINNER JOIN orders_table b\nON a.stockid = b.stockid\nAND a.last_order_report < b.reported\nGROUP BY a.orderid, a.stockid, a.last_order_report;\n']], ['INSERT interpolated rows into existing table'], 2, 1], [(24833153, 1), [['With multiple recipients, you need to do the inner joins on  threads :'], ['-10000']], [[' WITH ...\n)\nSELECT *\nFROM threads\nINNER JOIN threads_users tu\nON threads.id = tu.msg_id\nINNER JOIN users\nON users.id = tu.user_id\nWHERE root_id=:root\n']], ['How to store messages with multiple recipients in PostgreSQL?'], 2, 0], [(24848880, 0), [['As one of the approaches, you can turn a month into a list of days(dates) that constitute it (ease filtering operation), and perform calculation as follows:'], ['Result:']], [[" /* sample of data that you've provided */\nwith t1(mnth,val) as(\n  select 1, 93  from dual union all\n  select 2, 56  from dual union all\n  select 3, 186 from dual union all\n  select 4, 60  from dual\n), \n/*\n    Generates current year dates \n    From January 1st 2014 to December 31st 2014  \n */\ndates(dt) as(\n  select trunc(sysdate, 'YEAR') - 1 + level\n    from dual\n  connect by extract(year from (trunc(sysdate, 'YEAR') - 1 + level)) <= \n             extract(year from sysdate)\n)\n/* \n   The query that performs calculations based on range of dates \n */\nselect sum(val / extract(day from last_day(dt))) as result\n  from dates d\n  join t1\n    on (extract(month from d.dt) = t1.mnth)\n where dt between date '2014-01-17' and        -- January 17th 2014 to    \n                  date '2014-03-31'            -- March 31st 2014\n"]], ['oracle month to day'], 2, 1], [(24848880, 1), [['Result:'], ['-10000']], [['     RESULT\n----------\n       287 \n']], ['oracle month to day'], 2, 0], [(24855053, 0), [["You can do what you want by pre-aggregating the table before the join.  If there are only two values and you don't care about the order, then this will work:"], ['For more than two values, you have to do string concatenation.  That is "unpleasant" in SQL Server.  Here is the approach:']], [[" DECLARE @DocHoldReasons VARCHAR(8000);\nSET @DocHoldReasons = 'DocType Hold';\n\nUPDATE dbo.EpnPackages \n    SET Error = 1,\n        Msg = (COALESCE(@DocHoldReasons + ': ', '') + minv +\n               (case when minv <> maxv then ': ' + maxv else '' end)\n              )\n    FROM EpnPackages p INNER JOIN\n         (select cv.CountyId, min(cv.value) as minv, max(cv.value) as maxv\n          from EpnCountyValues cv\n          where cv.ValueName = 'DocHoldReason'\n         ) cv\n        ON cv.CountyId = p.CountyId\n    WHERE p.Status = 1000 AND p.Error = 0;\n"]], ['Concatenating row values using Inner Join'], 3, 1], [(24855053, 1), [['For more than two values, you have to do string concatenation.  That is "unpleasant" in SQL Server.  Here is the approach:'], ['You can fix this with an additional  coalesce :']], [[" DECLARE @DocHoldReasons VARCHAR(8000);\nSET @DocHoldReasons = 'DocType Hold';\n\nUPDATE dbo.EpnPackages \n    SET Error = 1,\n        Msg = (COALESCE(@DocHoldReasons + ': ', '') + \n               stuff((select ': ' + cv.value\n                      from EpnCountyValues cv\n                      where cv.ValueName = 'DocHoldReason' and\n                            cv.CountyId = p.CountyId\n                      for xml path ('')\n                     ), 1, 2, '')\n               )\n    WHERE p.Status = 1000 AND p.Error = 0;\n"]], ['Concatenating row values using Inner Join'], 3, 1], [(24855053, 2), [['You can fix this with an additional  coalesce :'], ['-10000']], [[" DECLARE @DocHoldReasons VARCHAR(8000);\nSET @DocHoldReasons = 'DocType Hold';\n\nUPDATE dbo.EpnPackages \n    SET Error = 1,\n        Msg = (COALESCE(@DocHoldReasons + ': ', '') + \n               COALESCE(stuff((select ': ' + cv.value\n                               from EpnCountyValues cv\n                               where cv.ValueName = 'DocHoldReason' and\n                                     cv.CountyId = p.CountyId\n                               for xml path ('')\n                              ), 1, 2, ''), '')\n               )\n    WHERE p.Status = 1000 AND p.Error = 0;\n"]], ['Concatenating row values using Inner Join'], 3, 1], [(24910861, 1), [['Demo-data:'], ['SQL Fiddle  (including your tests).']], [[' INSERT INTO test.status VALUES\n  (1, TRUE)\n, (2, TRUE)\n, (3, FALSE);     -- not valid for sub-entities\n\nINSERT INTO test.entity(entity_id, status_id, sub) VALUES\n  (11, 1, TRUE)   -- sub-entity (can be main, UPDATES to status.sub cascaded)\n, (13, 3, FALSE)  -- entity  (cannot be sub,  UPDATES to status.sub cascaded)\n, (14, 2, NULL)   -- entity  (can    be sub,  UPDATES to status.sub NOT cascaded)\n, (15, 3, NULL)   -- entity  (cannot be sub,  UPDATES to status.sub NOT cascaded)\n']], ['Restrict foreign key relationship to rows of related subtypes'], 3, 0], [(24910861, 2), [['SQL Fiddle  (including your tests).'], ['Etc.']], [[' CREATE TABLE test.status(\n   status_id  integer\n  ,sub        bool DEFAULT FALSE\n  ,PRIMARY KEY (status_id, sub)\n);\n\nCREATE TABLE test.entity(\n   entity_id  integer PRIMARY KEY\n  ,status_id  integer NOT NULL  -- cannot be NULL in this case\n  ,sub        bool NOT NULL     -- cannot be NULL in this case\n  ,additional_col1 text\n  ,additional_col2 text\n  ,FOREIGN KEY (status_id, sub) REFERENCES test.status\n     MATCH SIMPLE ON UPDATE CASCADE  -- optionally enforce sub-status\n);\n\nINSERT INTO test.status VALUES\n  (1, TRUE)       -- can be sub ...\n  (1, FALSE)      -- ... and main\n, (2, TRUE)\n, (2, FALSE)\n, (3, FALSE);     -- only main\n']], ['Restrict foreign key relationship to rows of related subtypes'], 3, 1], [(24920949, 0), [['-10000'], ['-10000']], [["Test Data DECLARE @TABLE TABLE (partnum VARCHAR(100))\nINSERT INTO @TABLE VALUES       \n('H24897-D-001'),\n('BHF44-82-V-1325'),\n('BKNG5222'),\n('YAKJD-78AB')\n"]], ['Remove text of a field after last repeating character'], 3, 0], [(24920949, 1), [['-10000'], ['-10000']], [["Query SELECT   PartNum\n        ,REVERSE(\n                SUBSTRING(REVERSE(Partnum), \n              CHARINDEX('-',REVERSE(Partnum)) \n               , LEN(Partnum) - CHARINDEX('-',REVERSE(Partnum)) + 1)\n               ) AS Result\nFROM @TABLE\n"]], ['Remove text of a field after last repeating character'], 3, 1], [(24920949, 2), [['-10000'], ['-10000']], [['OUTPUT ╔═════════════════╦═════════════╗\n║     PartNum     ║   Result    ║\n╠═════════════════╬═════════════╣\n║ H24897-D-001    ║ H24897-D-   ║\n║ BHF44-82-V-1325 ║ BHF44-82-V- ║\n║ BKNG5222        ║ BKNG5222    ║\n║ YAKJD-78AB      ║ YAKJD-      ║\n╚═════════════════╩═════════════╝\n']], ['Remove text of a field after last repeating character'], 3, 0], [(24921796, 0), [['-10000'], ['It is very common to confuse  GROUP BY  with  DISTINCT  (please look at  here  and  here ) since they return the same values if no aggregation function is in the  SELECT  clause. In your example:']], [[' SELECT\n  O.FileNumber,\n  O.CloseDate,\n  SUM(CL.Amount) as Total\nFROM dbo.Orders O\n    LEFT JOIN dbo.Checks C\n        ON O.OrdersID = C.OrdersID\n    LEFT JOIN dbo.CheckLine CL\n        ON C.ChecksID = CL.ChecksID\n GROUP BY O.FileNumber, O.CloseDate\n']], ['SUM subquery for total amount for each line'], 3, 1], [(24921796, 1), [['It is very common to confuse  GROUP BY  with  DISTINCT  (please look at  here  and  here ) since they return the same values if no aggregation function is in the  SELECT  clause. In your example:'], ['will return the same of']], [[' SELECT DISTINCT FileNumber FROM ORDERS \n']], ['SUM subquery for total amount for each line'], 3, 0], [(24921796, 2), [['will return the same of'], ['Use  GROUP BY  if you are wanting to aggregate information (like your field  TOTAL ).']], [[' SELECT FileNumber FROM ORDERS GROUP BY FileNumber\n']], ['SUM subquery for total amount for each line'], 3, 0], [(24939702, 0), [["Here's what the syntax may look like:"], ["I also took out the NVL function, but if you want to protect against null values I would put them in the second and/or third parameters. Definitely in the second, but if your scheddate column doesn't accept null values, then you won't need it."]], [[' UPDATE scpomgr.schedrcpts sr\nSET sr.scheddate = dateadd(\n                        minute, \n                        (SELECT n.transleadtime FROM scpomgr.network n WHERE n.source = sr.loc),\n                        (SELECT sr.scheddate)\n                   );\n']], ['Increase Date datatype by Number'], 3, 1], [(24939702, 1), [["I also took out the NVL function, but if you want to protect against null values I would put them in the second and/or third parameters. Definitely in the second, but if your scheddate column doesn't accept null values, then you won't need it."], ["If you're looking for the highest transleadtime, I do think the MAX function would be the simplest way. Try adjusting the subquery in the second parameter to:"]], [[' UPDATE scpomgr.schedrcpts sr\nSET sr.scheddate = dateadd(\n                        minute, \n                        NVL((SELECT n.transleadtime FROM scpomgr.network n WHERE n.source = sr.loc), 0),\n                        (SELECT sr.scheddate)\n                   );\n']], ['Increase Date datatype by Number'], 3, 1], [(24939702, 2), [["If you're looking for the highest transleadtime, I do think the MAX function would be the simplest way. Try adjusting the subquery in the second parameter to:"], ['-10000']], [[' SELECT MAX(n.transleadtime) FROM scpomgr.network n WHERE n.source = sr.loc\n']], ['Increase Date datatype by Number'], 3, 0], [(24970105, 0), [[''], ['Now I can query the best connection from point x to point y like this:']], [[" CREATE TABLE [dbo].[T_Hops](\n    [UID] [uniqueidentifier] NULL,\n    [From] [nvarchar](1000) NULL,\n    [To] [nvarchar](1000) NULL,\n    [Distance] [decimal](18, 5) NULL\n) ON [PRIMARY]\n\nGO\n\n\n\n\n      INSERT INTO [dbo].[T_Hops]             ([UID]             ,[From]             ,[To]             ,[Distance])       VALUES             (newid()              ,'A'              ,'E'              ,10.00000              );   \n      INSERT INTO [dbo].[T_Hops]             ([UID]             ,[From]             ,[To]             ,[Distance])       VALUES             (newid()              ,'E'              ,'D'              ,20.00000              );   \n      INSERT INTO [dbo].[T_Hops]             ([UID]             ,[From]             ,[To]             ,[Distance])       VALUES             (newid()              ,'A'              ,'B'              ,5.00000              );   \n      INSERT INTO [dbo].[T_Hops]             ([UID]             ,[From]             ,[To]             ,[Distance])       VALUES             (newid()              ,'B'              ,'C'              ,10.00000              );   \n      INSERT INTO [dbo].[T_Hops]             ([UID]             ,[From]             ,[To]             ,[Distance])       VALUES             (newid()              ,'C'              ,'D'              ,5.00000              );   \n      INSERT INTO [dbo].[T_Hops]             ([UID]             ,[From]             ,[To]             ,[Distance])       VALUES             (newid()              ,'A'              ,'F'              ,2.00000              );   \n      INSERT INTO [dbo].[T_Hops]             ([UID]             ,[From]             ,[To]             ,[Distance])       VALUES             (newid()              ,'F'              ,'G'              ,6.00000              );   \n      INSERT INTO [dbo].[T_Hops]             ([UID]             ,[From]             ,[To]             ,[Distance])       VALUES             (newid()              ,'G'              ,'H'              ,3.00000              );   \n      INSERT INTO [dbo].[T_Hops]             ([UID]             ,[From]             ,[To]             ,[Distance])       VALUES             (newid()              ,'H'              ,'D'              ,1.00000              );   \n"]], ['How do I find the shortest bus route when there is more than 1 switch?'], 2, 0], [(24970105, 1), [['Now I can query the best connection from point x to point y like this:'], ['-10000']], [[" WITH AllRoutes \n(\n     [UID]\n    ,[FROM]\n    ,[To]\n    ,[Distance]\n    ,[Path]\n    ,[Hops]\n)\nAS\n(\n    SELECT \n         [UID]\n        ,[FROM]\n        ,[To]\n        ,[Distance]\n        ,CAST(([dbo].[T_Hops].[FROM] + [dbo].[T_Hops].[To]) AS varchar(MAX)) AS [Path]\n        ,1 AS [Hops]\n      FROM [dbo].[T_Hops]\n      WHERE [FROM] = 'A'\n\n    UNION ALL\n\n\n    SELECT \n         [dbo].[T_Hops].[UID]\n        --,[dbo].[T_Hops].[FROM]\n        ,Parent.[FROM]\n        ,[dbo].[T_Hops].[To]\n        ,CAST((Parent.[Distance] + [dbo].[T_Hops].[Distance]) AS [decimal](18, 5)) AS distance\n        ,CAST((Parent.[Path] + '/' + [dbo].[T_Hops].[FROM] + [dbo].[T_Hops].[To]) AS varchar(MAX)) AS [Path]\n        ,(Parent.[Hops] + 1) AS [Hops]\n     FROM [dbo].[T_Hops]\nINNER JOIN AllRoutes AS Parent \n            ON Parent.[To] = [dbo].[T_Hops].[FROM] \n\n)\n\nSELECT TOP 100 PERCENT * FROM AllRoutes\n\n\n/*\nWHERE [FROM] = 'A' \nAND [To] = 'D'\nAND CHARINDEX('F', [Path]) != 0 -- via F\nORDER BY Hops, Distance ASC\n*/\n\nGO\n"]], ['How do I find the shortest bus route when there is more than 1 switch?'], 2, 1], [(25032106, 0), [['-10000'], ['If col2 can be negative and the requirement is that the sum of col2 has "non-zero" data then the above is OK, however, if it is the requirement that any col2 value has "non-zero" data then it should be changed to:']], [[' SELECT col1,\n       col2,\n       col3\nFROM (SELECT col1,\n             col2,\n             col3,\n             sum(col2) OVER (PARTITION BY col1) sum_col2\n      FROM tab1)\nWHERE (  (   sum_col2 <> 0\n         AND col2 <> 0)\n      OR sum_col2 = 0)\n']], ['selection based on certain condition'], 2, 1], [(25032106, 1), [['If col2 can be negative and the requirement is that the sum of col2 has "non-zero" data then the above is OK, however, if it is the requirement that any col2 value has "non-zero" data then it should be changed to:'], ['-10000']], [[' SELECT col1,\n       col2,\n       col3\nFROM (SELECT col1,\n             col2,\n             col3,\n             sum(abs(col2)) OVER (PARTITION BY col1) sum_col2\n      FROM tab1)\nWHERE (  (   sum_col2 <> 0\n         AND col2 <> 0)\n      OR sum_col2 = 0)\n']], ['selection based on certain condition'], 2, 1], [(25036420, 0), [['I think you can get what you want using conditional aggregation:'], ['If you want counts of distinct dates for the total, then use  count(distinct) :']], [[" SELECT EID,\n       sum(case when shift = 'd' then 1 else 0 end) as dayshifts,\n       sum(case when shift = 'n' then 1 else 0 end) as nightshifts,\n       count(*) as total\nFROM Attendance a\nWHERE (in_time BETWEEN CONVERT(DATETIME, '2014-01-07 00:00:00', 102) AND\n                       CONVERT(DATETIME, '2014-07-31 00:00:00', 102)) AND\n      PID = 'A002';\n"]], ['Shift manipulation in SQL to get counts'], 2, 1], [(25036420, 1), [['If you want counts of distinct dates for the total, then use  count(distinct) :'], ['-10000']], [[" SELECT EID,\n       sum(case when shift = 'd' then 1 else 0 end) as dayshifts,\n       sum(case when shift = 'n' then 1 else 0 end) as nightshifts,\n       count(distinct case when shift in ('d', 'n') then cast(in_time as date) end) as total\nFROM Attendance a\nWHERE (in_time BETWEEN CONVERT(DATETIME, '2014-01-07 00:00:00', 102) AND\n                       CONVERT(DATETIME, '2014-07-31 00:00:00', 102)) AND\n      PID = 'A002';\n"]], ['Shift manipulation in SQL to get counts'], 2, 1], [(25046224, 0), [["I know you aren't keen on a PL/SQL approach but if you do have to then you could do this to just update that value:"], ["If you're updating other things as well then you might prefer a function that returns the object list with the relevant value updated:"]], [[" declare\n  l_object_list my_object_varray;\n  cursor c is\n    select l.id, l.object_list, t.*\n    from my_object_table l,\n    table(l.object_list) t\n    where t.value1 = 10\n    for update of l.object_list;\nbegin\n  for r in c loop\n    l_object_list := r.object_list;\n    for i in 1..l_object_list.count loop\n      if l_object_list(i).value1 = 10 then\n        l_object_list(i).value2 := 'obj 4 upd';\n      end if;\n    end loop;\n\n    update my_object_table\n    set object_list = l_object_list\n    where current of c;\n  end loop;\nend;\n/\n\nanonymous block completed\n\nselect l.id, t.* from my_object_table l, table(l.object_list) t;\n\n        ID     VALUE1 VALUE2         VALUE3\n---------- ---------- ---------- ----------\n         1          1 object 1           10 \n         1          2 object 2           20 \n         1          3 object 3           30 \n         2         10 obj 4 upd          10 \n         2         20 object 5           20 \n         2         30 object 6           30 \n"]], ['How to update a varray type within a table with a simple update statement?'], 6, 1], [(25046224, 1), [["If you're updating other things as well then you might prefer a function that returns the object list with the relevant value updated:"], ["Then call that as part of an update; but you still can't update your in-line view directly:"]], [[' create or replace function get_updated_varray(p_object_list my_object_varray,\n  p_value1 number, p_new_value2 varchar2)\nreturn my_object_varray as\n  l_object_list my_object_varray;\nbegin\n  l_object_list := p_object_list;\n  for i in 1..l_object_list.count loop\n    if l_object_list(i).value1 = p_value1 then\n      l_object_list(i).value2 := p_new_value2;\n    end if;\n  end loop;\n\n  return l_object_list;\nend;\n/\n']], ['How to update a varray type within a table with a simple update statement?'], 6, 0], [(25046224, 2), [["Then call that as part of an update; but you still can't update your in-line view directly:"], ['You need to update based on relevant the ID(s):']], [[" update (\n  select l.id, l.object_list\n  from my_object_table l, table(l.object_list) t\n  where t.value1 = 10\n)\nset object_list = get_updated_varray(object_list, 10, 'obj 4 upd');\n\nSQL Error: ORA-01779: cannot modify a column which maps to a non key-preserved table\n"]], ['How to update a varray type within a table with a simple update statement?'], 6, 0], [(25046224, 3), [['You need to update based on relevant the ID(s):'], ['If you wanted to hide the complexity even further you could create a view with an instead-of trigger that calls the function:']], [[" update my_object_table\nset object_list = get_updated_varray(object_list, 10, 'obj 4 upd')\nwhere id in (\n  select l.id\n  from my_object_table l, table(l.object_list) t\n  where t.value1 = 10\n);\n\n1 rows updated.\n\nselect l.id, t.* from my_object_table l, table(l.object_list) t;\n\n        ID     VALUE1 VALUE2         VALUE3\n---------- ---------- ---------- ----------\n         1          1 object 1           10 \n         1          2 object 2           20 \n         1          3 object 3           30 \n         2         10 obj 4 upd          10 \n         2         20 object 5           20 \n         2         30 object 6           30 \n"]], ['How to update a varray type within a table with a simple update statement?'], 6, 0], [(25046224, 4), [['If you wanted to hide the complexity even further you could create a view with an instead-of trigger that calls the function:'], ['Then the update is pretty much what you wanted, superficially at least:']], [[' create view my_object_view as\n  select l.id, t.* from my_object_table l, table(l.object_list) t\n/\n\ncreate or replace trigger my_object_view_trigger\ninstead of update on my_object_view\nbegin\n  update my_object_table\n  set object_list = get_updated_varray(object_list, :old.value1, :new.value2)\n  where id = :old.id;\nend;\n/\n']], ['How to update a varray type within a table with a simple update statement?'], 6, 0], [(25046224, 5), [['Then the update is pretty much what you wanted, superficially at least:'], ['SQL Fiddle .']], [[" update my_object_view\nset value2 = 'obj 4 upd'\nwhere value1 = 10;\n\n1 rows updated.\n\nselect * from my_object_view;\n\n        ID     VALUE1 VALUE2         VALUE3\n---------- ---------- ---------- ----------\n         1          1 object 1           10 \n         1          2 object 2           20 \n         1          3 object 3           30 \n         2         10 obj 4 upd          10 \n         2         20 object 5           20 \n         2         30 object 6           30 \n"]], ['How to update a varray type within a table with a simple update statement?'], 6, 0], [(25076117, 0), [['Just add a comma to  all  occurrences of  0. :'], ['then remove the duplicates:']], [["                replace(TheColumn, '0.', ',0.')\n"]], ['sqlite replace() function to perform a string replace'], 3, 0], [(25076117, 1), [['then remove the duplicates:'], ['and the comma at the beginning:']], [["        replace(replace(TheColumn, '0.', ',0.'), ',,', ',')\n"]], ['sqlite replace() function to perform a string replace'], 3, 0], [(25076117, 2), [['and the comma at the beginning:'], ['-10000']], [[" substr(replace(replace(TheColumn, '0.', ',0.'), ',,', ','), 2)\n"]], ['sqlite replace() function to perform a string replace'], 3, 0], [(25095284, 0), [['-10000'], ['This belongs in the WHERE clause:']], [[' SELECT a.auction_id\n  FROM auctions AS a\n  LEFT JOIN winners AS w\n    ON a.auction_id = w.auction_id\n WHERE a.owner_id = 1234567\n   AND a.is_draft = 0\n   AND a.creation_in_progress = 0\n   AND w.winner_id IS NULL\n']], ["Using LEFT JOIN to returns rows that don't have a match"], 2, 1], [(25095284, 1), [['This belongs in the WHERE clause:'], ["Criteria on the outer joined table belongs in the ON clause when you want to ALLOW nulls. In this case, where you're filtering in on nulls, you put that criteria into the WHERE clause. Everything in the ON clause is designed to allow nulls."]], [['    AND w.winner_id IS NULL\n']], ["Using LEFT JOIN to returns rows that don't have a match"], 2, 0], [(25140883, 1), [["In your case, for a table's column (sorry for not given this example first):"], ['Hope it helps.']], [[' create table dbo.example_xml\n(\n    my_column XML not null\n);\ngo\n\ninsert into dbo.example_xml\nvalues(\'<locale en-US="Test &amp; Data" />\');\ngo\n\nselect\n  my_column.value(\'(/locale/@en-US)[1]\', \'varchar(11)\') [en-US]\nfrom dbo.example_xml;\ngo\n']], ['Converting XML in SQL Server'], 2, 1], [(25144691, 1), [['-10000'], ['-10000']], [[" SELECT U.username\n     , COUNT(Q.question_id)\n  FROM p1209279x.questions Q\n  JOIN p1209279x.users U\n    ON U.user_id=Q.author_id\n WHERE Q.approved='Y'\n   AND Q.role='0'\n GROUP BY Q.author_id\n ORDER BY COUNT(Q.question_id) DESC\n"]], ['MySQL counting and sorting rows returned from a query'], 2, 1], [(25207558, 0), [['Try this to get the 100 records:'], ['However you may try to check if the value exists in the table using this:']], [["   select \np.attr_value product,\nm.attr_value model,\nu.attr_value usage,\nl.attr_value location\n    from table1 t1 join table2 t2 on t1.e_subid = t2.e_subid\n                   join table4 t4 on t4.loc_id = t1.loc_id\n                   join table3 p  on t2.e_cid = p.e_cid \n                   join table3 m  on t2.e_cid = m.e_cid \n                   join table3 u  on t2.e_cid = u.e_cid \n  Where\n      t4.attr_name = 'SiteName' \n      and p.attr_name  = 'Product'\n      and m.attr_name  = 'Model'\n      and u.attr_name  = 'Usage'\n      and ROWNUM <= 100\n      order by product,location;\n"]], ['Get first 100 records in a table'], 2, 1], [(25207558, 1), [['However you may try to check if the value exists in the table using this:'], ['-10000']], [[" select case \n            when exists (select 1\n        from table1 t1 join table2 t2 on t1.e_subid = t2.e_subid\n                       join table4 t4 on t4.loc_id = t1.loc_id\n                       join table3 p  on t2.e_cid = p.e_cid \n                       join table3 m  on t2.e_cid = m.e_cid \n                       join table3 u  on t2.e_cid = u.e_cid \n      Where\n          t4.attr_name = 'SiteName' \n          and p.attr_name  = 'Product'\n          and m.attr_name  = 'Model'\n          and u.attr_name  = 'Usage'\n          order by product,location;\n) \n    then 'Y' \n            else 'N' \n        end as rec_exists\nfrom dual;\n"]], ['Get first 100 records in a table'], 2, 1], [(25238315, 0), [['Try this query:'], ["You can't use a simple DISTINCT because you're asking to display a single value, but order by  all  the dates that the value may have associated with it. What if your data looks like this?"]], [[' WITH Names AS (\n   SELECT\n      Name,\n      Seq = Dense_Rank() OVER (ORDER BY SomeDate)\n         - Dense_Rank() OVER (PARTITION BY Name ORDER BY SomeDate)\n   FROM\n      dbo.Names\n)\nSELECT Name\nFROM Names\nGROUP BY Name, Seq\nORDER BY Min(Seq)\n;\n']], ['select distinct of a column and order by date column but without showing the date column'], 2, 1], [(25238315, 1), [["You can't use a simple DISTINCT because you're asking to display a single value, but order by  all  the dates that the value may have associated with it. What if your data looks like this?"], ['How do you decide whether to put A first, or B first, based one some theoretical ordering by the date?']], [[' Name  Date\n----  ----\nA     2014-01-01\nB     2014-02-01\nB     2014-03-01\nA     2014-04-01\n']], ['select distinct of a column and order by date column but without showing the date column'], 2, 0], [(25259434, 0), [['this will not work in classic asp:'], ['you have to use server.createobject like so:']], [[' Dim cmdPrep1 As New ADODB.Command\n']], ['Simple fetch ASP prepared statement'], 2, 0], [(25259434, 1), [['you have to use server.createobject like so:'], ['now you have an  ADODB.Recordset  in your variable rs.']], [[' dim cmdPrep1 : set cmdPrep1 = server.createobject("ADODB.Command")\n\ncmdPrep1.ActiveConnection = cn\ncmdPrep1.CommandType = adCmdText\ncmdPrep1.CommandText = "SELECT ID,NAME FROM MEMBERS WHERE ID =?"\n\n\ncmdPrep1.parameters.Append cmd.createParameter( "ID", adInteger, , , Request.Form("nameOfIDField") )\n\ndim rs : set rs = cmdPrep1.execute\n']], ['Simple fetch ASP prepared statement'], 2, 1], [(25275552, 0), [['I think you want this logic:'], ['As a note:  if the constants should really be integers, then drop the single quotes.  In fact, you can then simplify the query to:']], [[" UPDATE table\n    SET frontpage = (case when poll_id = '555' then '1' else '0' end)\n    WHERE user_id = '999';\n"]], ['MySQL UPDATE - SET field in column to 1, all other fields to 0, with one query'], 2, 1], [(25275552, 1), [['As a note:  if the constants should really be integers, then drop the single quotes.  In fact, you can then simplify the query to:'], ['-10000']], [[' UPDATE table\n    SET frontpage = (poll_id = 555)\n    WHERE user_id = 999;\n']], ['MySQL UPDATE - SET field in column to 1, all other fields to 0, with one query'], 2, 1], [(25292138, 0), [['A direct translation into Access would be:'], ['EDIT:\nTo make an exact match, you could do:']], [[" select * from tblClient\nwhere company & dba1 & dba2 & dba3 like '*jbl*'\n"]], ['How to convert SQL Server Query into Access'], 2, 1], [(25292138, 1), [['EDIT:\nTo make an exact match, you could do:'], ['-10000']], [[" select * from tblClient\nwhere '|' & company & '|' & dba1 & '|' & dba2 & '|' & dba3 & '|' like '*|' & 'jbl' & '|*'\n"]], ['How to convert SQL Server Query into Access'], 2, 1], [(25319348, 0), [['Example result (from sample data), blank lines added manually:'], ['The query:']], [[' | N |  CODE | DESC | CODE_0 | DESC_0 |   THEDATE | PERCENTAGE |\n|---|-------|------|--------|--------|-----------|------------|\n| 1 | CTR07 | Risk |     P1 | Phase1 | 29-Nov-13 |        0.2 |\n| 1 | CTR07 | Risk |     P1 | Phase1 | 29-Nov-13 |        0.2 |\n| 1 | CTR07 | Risk |     P1 | Phase1 | 29-Nov-13 |        0.2 |\n| 1 | CTR08 | Oper |     P1 | Phase1 | 29-Nov-13 |        0.6 |\n| 1 | CTR08 | Oper |     P1 | Phase1 | 29-Nov-13 |        0.6 |\n| 1 | CTR08 | Oper |     P1 | Phase1 | 29-Nov-13 |        0.6 |\n\n| 2 | CTR07 | Risk |     P1 | Phase1 |  6-Dec-13 |        0.4 |\n| 2 | CTR07 | Risk |     P1 | Phase1 |  6-Dec-13 |        0.4 |\n| 2 | CTR07 | Risk |     P1 | Phase1 |  6-Dec-13 |        0.4 |\n| 2 | CTR08 | Oper |     P1 | Phase1 |  6-Dec-13 |        0.6 |\n| 2 | CTR08 | Oper |     P1 | Phase1 |  6-Dec-13 |        0.6 |\n| 2 | CTR08 | Oper |     P1 | Phase1 |  6-Dec-13 |        0.6 |\n\n| 3 | CTR07 | Risk |     P1 | Phase1 | 13-Dec-13 |        0.6 |\n| 3 | CTR07 | Risk |     P1 | Phase1 | 13-Dec-13 |        0.6 |\n| 3 | CTR07 | Risk |     P1 | Phase1 | 13-Dec-13 |        0.6 |\n| 3 | CTR08 | Oper |     P1 | Phase1 | 13-Dec-13 |        0.9 |\n| 3 | CTR08 | Oper |     P1 | Phase1 | 13-Dec-13 |        0.9 |\n| 3 | CTR08 | Oper |     P1 | Phase1 | 13-Dec-13 |        0.9 |\n\n| 4 | CTR07 | Risk |     P1 | Phase1 | 20-Dec-13 |        1.1 |\n| 4 | CTR07 | Risk |     P1 | Phase1 | 20-Dec-13 |        1.1 |\n| 4 | CTR07 | Risk |     P1 | Phase1 | 20-Dec-13 |        1.1 |\n| 4 | CTR08 | Oper |     P1 | Phase1 | 20-Dec-13 |        2.7 |\n| 4 | CTR08 | Oper |     P1 | Phase1 | 20-Dec-13 |        2.7 |\n| 4 | CTR08 | Oper |     P1 | Phase1 | 20-Dec-13 |        2.7 |\n']], ['Unpivot Multiple Columns in MySQL'], 3, 0], [(25321698, 0), [['Use  LEFT()  and  RIGHT()  since the length on your values is fixed and use  STR_TO_DATE()  to convert your string to date. Here is the example:'], ['If the data type of financial_year is  VARCHAR()  you should use  STR_TO_DATE()  too like on this one']], [[" SELECT financial_year\nFROM financial_years\nWHERE STR_TO_DATE('03-05-2011','%d-%m-%Y') >= DATE( LEFT(financial_year,10) )\nAND STR_TO_DATE('03-05-2011','%d-%m-%Y') <= DATE( RIGHT(financial_year,10) );\n"]], ['How to split a mysql field into two and compare string between both splited fields'], 3, 1], [(25321698, 1), [['If the data type of financial_year is  VARCHAR()  you should use  STR_TO_DATE()  too like on this one'], ['and ']], [[" STR_TO_DATE(LEFT(financial_year,10),'%d-%m-%Y') \n"]], ['How to split a mysql field into two and compare string between both splited fields'], 3, 0], [(25321698, 2), [['and '], ['-10000']], [[" STR_TO_DATE(RIGHT(financial_year,10),'%d-%m-%Y')\n"]], ['How to split a mysql field into two and compare string between both splited fields'], 3, 0], [(25361410, 0), [["Your  con_name  variable is out of scope within the DDL statement you're executing; you're trying to drop a constraint called  con_name , not one named with the value that holds - as you suspected. You can't use a bind variable here so you'll need to concatenate the name:"], ["As Nicholas Krasnov pointed out in a comment, you don't need to do this at all; you can  drop the primary key without specifying its name , without using dynamic SQL or a PL/SQL block:"]], [[" DECLARE\n  con_name all_constraints.constraint_name%type;\nBEGIN\n  select constraint_name into con_name\n  from all_constraints\n  where table_name = 'MY_TABLE' and constraint_type = 'P';\n\n  EXECUTE immediate 'ALTER TABLE MY_TABLE drop constraint ' || con_name;\n\n  EXECUTE immediate 'ALTER TABLE MY_TABLE ADD CONSTRAINT MT_PK PRIMARY KEY (REV, ID)';\nEND;\n/\n"]], ['Drop auto generated constraint name'], 2, 1], [(25361410, 1), [["As Nicholas Krasnov pointed out in a comment, you don't need to do this at all; you can  drop the primary key without specifying its name , without using dynamic SQL or a PL/SQL block:"], ["Hopefully you don't already have any tables with foreign key constraints against this PK."]], [[' ALTER TABLE MY_TABLE DROP PRIMARY KEY;\nALTER TABLE MY_TABLE ADD CONSTRAINT MT_PK PRIMARY KEY (REV, ID);\n']], ['Drop auto generated constraint name'], 2, 1], [(25380801, 0), [['The easiest way to do this is with  union all :'], ['If you want to put this into a new table, use either  insert  or  select into .  For instance:']], [[' select col0, col1, col2, col5\nfrom oldtable\nunion all\nselect col0, col1, col3, col4\nfrom oldtable\nwhere col3 is not null;\n']], ['Moving or inserting data to other SQL table with format'], 2, 1], [(25380801, 1), [['If you want to put this into a new table, use either  insert  or  select into .  For instance:'], ['-10000']], [[' select col0, col1, col3, col4\ninto newtable\nfrom (select col0, col1, col2 as col3, col5 as col4\n      from oldtable\n      union all\n      select col0, col1, col3, col4\n      from oldtable\n      where col3 is not null\n     ) t\n']], ['Moving or inserting data to other SQL table with format'], 2, 1], [(25390857, 0), [['This query will replace all instances of  url.com/images  to  [PLACEHOLDER] .'], ['Now run your original query to append  /images  to the  url.com :']], [[" UPDATE wp_posts\nSET post_content = REPLACE(post_content,'url.com/images','[PLACEHOLDER]')\nWHERE post_content LIKE '%url.com/images%';\n"]], ['Replace partial value inside row'], 4, 0], [(25390857, 1), [['Now run your original query to append  /images  to the  url.com :'], ["And now you're free to move the  [PLACEHOLDER]  back:"]], [[" UPDATE wp_posts\nSET post_content = REPLACE(post_content,'url.com','url.com/images')\nWHERE post_content LIKE '%url.com%';\n"]], ['Replace partial value inside row'], 4, 0], [(25390857, 2), [["And now you're free to move the  [PLACEHOLDER]  back:"], ['All in one lump, for copy & paste ease:']], [[" UPDATE wp_posts\nSET post_content = REPLACE(post_content,'[PLACEHOLDER]','url.com/images')\nWHERE post_content LIKE '%[PLACEHOLDER]%';\n"]], ['Replace partial value inside row'], 4, 0], [(25420950, 0), [['You need to use pivot:'], ["If you don't have the id field you can generate it, but you will have XML type:"]], [[" with t(id, d) as (\n  select 1, 'field1 = test2' from dual union all\n  select 2, 'field1 = test3' from dual \n)\nselect *\n  from t\npivot (max (d) for id in (1, 2))\n"]], ['How do I combine 2 records with a single field into 1 row with 2 fields (Oracle 11g)?'], 2, 1], [(25420950, 1), [["If you don't have the id field you can generate it, but you will have XML type:"], ['-10000']], [[" with t(d) as (\n  select 'field1 = test2' from dual union all\n  select 'field1 = test3' from dual \n), t1(id, d) as (\n  select ROW_NUMBER() OVER(ORDER BY d), d from t\n)\nselect *\n  from t1\npivot xml (max (d) for id in (select id from t1))\n"]], ['How do I combine 2 records with a single field into 1 row with 2 fields (Oracle 11g)?'], 2, 1], [(25428684, 0), [['-10000'], ['SEE DEMO']], [[' SELECT country, profession, MAX(money) AS money \nFROM\n(   SELECT u.country, g.profession, SUM(um.money) AS money\n    FROM user_money um\n    JOIN users u ON u.id = um.user_id\n    JOIN groups g ON g.id = um.group_id\n    GROUP BY g.profession, u.country\n    ORDER BY um.money DESC\n) t\nGROUP BY country\nORDER BY money DESC\n']], ['MySQL Select from three tables'], 2, 1], [(25428684, 1), [['SEE DEMO'], ['-10000']], [[' +---------------+------------+-------+\n| country       | profession | money |\n+---------------+------------+-------+\n| Luxembourg    | Hacker     |  200  |\n| Albania       | Hacker     |  120  |\n| United States | Boss       |  55   |\n+---------------+------------+-------+\n']], ['MySQL Select from three tables'], 2, 0], [(25472241, 0), [['Query:'], ['The output at that point is:']], [[" select id, category_id\nfrom(\nselect x.*,\n       @row_number:=case when @category_id=x.category_id then @row_number+1 else 1 end as row_number,\n       @category_id:=x.category_id as grp\n  from (select art.id, art.category_id, count(*) as num_art_views\n          from articles art\n          join (select art.category_id, count(*)\n                 from view_counts cnt\n                 join articles art\n                   on cnt.article_id = art.id\n                group by art.category_id\n                order by 2 desc limit 5) topcats\n            on art.category_id = topcats.category_id\n          join view_counts cnt\n            on art.id = cnt.article_id\n         group by art.id, art.category_id\n         order by art.category_id, num_art_views desc) x\n cross join (select @row_number := 0, @category_id := '') as r\n) x where row_number <= 5\n"]], ['mysql most popular articles in most popular categories'], 2, 1], [(25472241, 1), [['The output at that point is:'], ['You can easily exclude anything not <= 5 at that point (which is what the above query does).']], [[' |        ID | CATEGORY_ID | NUM_ART_VIEWS | ROW_NUMBER |    GRP |\n|-----------|-------------|---------------|------------|--------|\n| article16 |       autos |             2 |          1 |  autos |\n| article14 |      planes |             2 |          1 | planes |\n| article12 |       sport |             4 |          1 |  sport |\n|  article3 |       sport |             3 |          2 |  sport |\n|  article4 |       sport |             3 |          3 |  sport |\n|  article1 |       sport |             3 |          4 |  sport |\n|  article2 |       sport |             3 |          5 |  sport |\n|  article5 |       sport |             2 |          6 |  sport |\n| article15 |      trains |             2 |          1 | trains |\n| article13 |          tv |             6 |          1 |     tv |\n|  article9 |          tv |             3 |          2 |     tv |\n|  article6 |          tv |             3 |          3 |     tv |\n|  article7 |          tv |             3 |          4 |     tv |\n|  article8 |          tv |             3 |          5 |     tv |\n| article10 |          tv |             2 |          6 |     tv |\n']], ['mysql most popular articles in most popular categories'], 2, 0], [(25522070, 0), [['change the varchar2_table type to CLOB'], ['-10000']], [[' TYPE varchar2_table IS TABLE OF CLOB INDEX BY BINARY_INTEGER;\n']], ['Creating a table from a Comma Separated List in Oracle (> 11g) - Input string limit 4000 chars'], 2, 0], [(25531666, 0), [['remove the  AND'], ['Based on comments, with  pseudo code']], [[" select * from employees \nWHERE job_id NOT like '%CLERK' \norder by last_name\n"]], ['Using WHERE and ORDER BY together in Oracle 10g'], 2, 1], [(25531666, 1), [['Based on comments, with  pseudo code'], ['-10000']], [[" select * from employees \nWHERE job_id != 'CLERKS'\nAND DateAppointedFielName BETWEEN StartDate AND EndDate \norder by last_name\n"]], ['Using WHERE and ORDER BY together in Oracle 10g'], 2, 1], [(25537492, 0), [['You can do this using  union all  and  limit :'], ['MySQL puts  NULL  values last with a descending sort.  But you can also be specific:']], [[' (SELECT Diameter\n FROM  `TreeDiameters` \n WHERE TreeID = ?\n) union all\n(select NULL as Diameter\n from (select 1 as n union all select 2 union all select 3 union all select 4 union all\n       select 5 union all select 6\n      ) n \n)\nORDER BY Diameter DESC\nLIMIT 0, 6;\n']], ['MySQL - Always return exactly n records'], 2, 1], [(25537492, 1), [['MySQL puts  NULL  values last with a descending sort.  But you can also be specific:'], ['-10000']], [[' ORDER BY (Diameter is not null) DESC, Diameter DESC\n']], ['MySQL - Always return exactly n records'], 2, 0], [(25538698, 0), [['The result looks like this:'], ['[Results][2] :']], [[' with qwry as (\nSELECT  \nROW_NUMBER() OVER (PARTITION BY PersonId order by TeamPersonId) as rownum_nofloor\n, floor((ROW_NUMBER() OVER (PARTITION BY PersonId order by TeamPersonId)-1)/3)+1 as batchid_person_specific\n, *\nFROM TeamPersonMap \n  )\nselect \nDENSE_RANK() OVER (ORDER BY PersonId, batchid_person_specific) as BatchGroupId_Final\n,* from qwry\nORDER BY PersonId\n']], ['Batch SQL Server Results by Max Number of Rows'], 2, 1], [(25538698, 1), [['[Results][2] :'], ['-10000']], [[' | BATCHGROUPID_FINAL | ROWNUM_NOFLOOR | BATCHID_PERSON_SPECIFIC | TEAMPERSONID | TEAMID | PERSONID |\n|--------------------|----------------|-------------------------|--------------|--------|----------|\n|                  1 |              1 |                       1 |            1 |      1 |      101 |\n|                  1 |              2 |                       1 |            6 |      2 |      101 |\n|                  1 |              3 |                       1 |           11 |      3 |      101 |\n|                  2 |              4 |                       2 |           16 |      4 |      101 |\n|                  2 |              5 |                       2 |           21 |      5 |      101 |\n|                  3 |              1 |                       1 |            2 |      1 |      102 |\n|                  3 |              2 |                       1 |            7 |      2 |      102 |\n|                  3 |              3 |                       1 |           12 |      3 |      102 |\n|                  4 |              4 |                       2 |           17 |      4 |      102 |\n|                  4 |              5 |                       2 |           22 |      5 |      102 |\n|                  5 |              1 |                       1 |            3 |      1 |      103 |\n|                  5 |              2 |                       1 |            8 |      2 |      103 |\n|                  5 |              3 |                       1 |           13 |      3 |      103 |\n|                  6 |              4 |                       2 |           18 |      4 |      103 |\n|                  6 |              5 |                       2 |           23 |      5 |      103 |\n|                  7 |              1 |                       1 |            4 |      1 |      104 |\n|                  7 |              2 |                       1 |            9 |      2 |      104 |\n|                  7 |              3 |                       1 |           14 |      3 |      104 |\n|                  8 |              4 |                       2 |           19 |      4 |      104 |\n|                  8 |              5 |                       2 |           24 |      5 |      104 |\n|                  9 |              1 |                       1 |            5 |      1 |      105 |\n|                  9 |              2 |                       1 |           10 |      2 |      105 |\n|                  9 |              3 |                       1 |           15 |      3 |      105 |\n|                 10 |              4 |                       2 |           20 |      4 |      105 |\n|                 10 |              5 |                       2 |           25 |      5 |      105 |\n']], ['Batch SQL Server Results by Max Number of Rows'], 2, 0], [(25543723, 1), [['And when you have to access it:'], ['-10000']], [[" import os\nmyconst1 = os.environ['MY_DAILY_CONST_1']\n...\n"]], ['How to efficiently define daily constant?'], 2, 0], [(25547827, 0), [['You may use  INFORMATION_SCHEMA  for this:'], ["So you're interested in  FOREIGN KEY  type. This will show you which table on which column has the constraint, but won't show you targeted constraint column and table. To find them, you need to use another table,  INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS  which has such information, so, basically, to reconstruct relation between tables, you'll need:"]], [[" SELECT \n  * \nFROM  \n  INFORMATION_SCHEMA.TABLE_CONSTRAINTS \nWHERE \n  CONSTRAINT_TYPE='FOREIGN KEY'\n"]], ['Query to find foreign keys on database schema'], 3, 1], [(25547827, 1), [["So you're interested in  FOREIGN KEY  type. This will show you which table on which column has the constraint, but won't show you targeted constraint column and table. To find them, you need to use another table,  INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS  which has such information, so, basically, to reconstruct relation between tables, you'll need:"], ["But that's, again, is missing columns (because it doesn't belongs to those tables) and will show only relations via FK between tables. To reconstruct full relation (i.e. with columns involved) you'll need to refer to  KEY_COLUMN_USAGE  table:"]], [[" SELECT \n  t.TABLE_SCHEMA, \n  t.TABLE_NAME, \n  r.REFERENCED_TABLE_NAME \nFROM  \n  INFORMATION_SCHEMA.TABLE_CONSTRAINTS AS t \n    JOIN INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS AS r \n    ON t.CONSTRAINT_NAME=r.CONSTRAINT_NAME \nWHERE \n  t.CONSTRAINT_TYPE='FOREIGN KEY'\n"]], ['Query to find foreign keys on database schema'], 3, 1], [(25547827, 2), [["But that's, again, is missing columns (because it doesn't belongs to those tables) and will show only relations via FK between tables. To reconstruct full relation (i.e. with columns involved) you'll need to refer to  KEY_COLUMN_USAGE  table:"], ["This query will show all relations where referenced entity is not null, and, since it's applicable only in FK case - it's an answer to the question of finding FK relations. It's quite universal, but I've provided methods above since it may be useful to get info about PK or unique constraints too."]], [[' SELECT \n  TABLE_SCHEMA, \n  TABLE_NAME, \n  COLUMN_NAME, \n  REFERENCED_TABLE_SCHEMA, \n  REFERENCED_TABLE_NAME, \n  REFERENCED_COLUMN_NAME \nFROM \n  INFORMATION_SCHEMA.KEY_COLUMN_USAGE \nWHERE \n  REFERENCED_TABLE_SCHEMA IS NOT NULL\n']], ['Query to find foreign keys on database schema'], 3, 1], [(25560497, 0), [["Executing the query doesn't set the columns.  To create the columns do:"], ['To assign them use  update :']], [[' alter table users_profiles add column latitude decimal(10, 4);\nalter table users_profiles add column longitude decimal(10, 4);\n']], ['Split Mysql Location entry into 2 columns?'], 2, 0], [(25570210, 0), [['First, you need to wrap the Xml  Select  statement in another select against the Unit table, in order to ensure that we end up with xml representing only that unit.'], ['Then, you can wrap this in another select, grouping the xml up by content.']], [[" Select\nId,\n(\n  Select\n    Action, \n    TriggerType,\n    IU.TypeId,\n    IU.Message,\n    (\n        Select C.Value, I.QuestionId, I.Sequence\n        From UnitCondition C\n          Inner Join Item I on C.ItemId = I.Id\n        Where C.UnitId = IU.Id\n        Order by C.Value, I.QuestionId, I.Sequence\n        For XML RAW('Condition'), TYPE\n    ) as Conditions\n  from UnitType T\n    Inner Join Unit IU on T.Id = IU.TypeId\n  WHERE IU.Id = U.Id\n  For XML RAW ('Unit')\n)\nFrom Unit U\n"]], ['Identify Duplicate Xml Nodes'], 2, 0], [(25570210, 1), [['Then, you can wrap this in another select, grouping the xml up by content.'], ['This will allow you to group entire units where the whole content is identical. ']], [[" Select content, count(*) as cnt\nFrom\n  (\n    Select\n      Id,\n      (\n        Select\n          Action, \n          TriggerType,\n          IU.TypeId,\n          IU.Message,\n          (\n              Select C.Value, C.ItemId, I.QuestionId, I.Sequence\n              From UnitCondition C\n                Inner Join Item I on C.ItemId = I.Id\n              Where C.UnitId = IU.Id\n              Order by C.Value, I.QuestionId, I.Sequence\n              For XML RAW('Condition'), TYPE\n          ) as Conditions\n        from UnitType T\n          Inner Join Unit IU on T.Id = IU.TypeId\n        WHERE IU.Id = U.Id\n        For XML RAW ('Unit')\n      ) as content\n    From Unit U\n  ) as data\ngroup by content\nhaving count(*) > 1\n"]], ['Identify Duplicate Xml Nodes'], 2, 0], [(25579264, 0), [["Here's one solution:"], ["'NULL' is a string and MySQL have very weird ideas on how to cast between types:"]], [[" SELECT least(MIN(nullif(sgl_ro,0))\n            ,MIN(nullif(sgl_bb,0))\n            ,MIN(nullif(sgl_hb,0))\n            ,MIN(nullif(sgl_fb,0)) ) as min_rate\nFROM room_rates\nWHERE hotel_id='1'\n;\n"]], ['MySQL: Get the MIN value of a table from all columns & rows'], 5, 1], [(25579264, 1), [["'NULL' is a string and MySQL have very weird ideas on how to cast between types:"], ["I.e. you solution will work fine by removing the ' from NULL:"]], [[" select case when 0 = 'NULL' \n            then 'ohoy' \n            else 'sailor' \n       end \nfrom room_rates;\n\nohoy\nohoy\nohoy\n"]], ['MySQL: Get the MIN value of a table from all columns & rows'], 5, 0], [(25579264, 3), [['I tested the following scenario for all DBMS availible in sqlfiddle + DB2 10.5:'], ['Edit: handle situation where all columns in a row (or all rows for a column) = 0']], [[" create table t(x int);\ninsert into t(x) values (1);\nselect case when 0 = 'NULL' \n        then 'ohoy' \n        else 'sailor' \n   end \nfrom t;\n"]], ['MySQL: Get the MIN value of a table from all columns & rows'], 5, 0], [(25579264, 4), [['Edit: handle situation where all columns in a row (or all rows for a column) = 0'], ['-10000']], [[" select min(least(coalesce(nullif(sgl_ro,0), 2147483647)\n                ,coalesce(nullif(sgl_bb,0), 2147483647)\n                ,coalesce(nullif(sgl_hb,0), 2147483647) \n                ,coalesce(nullif(sgl_fb,0), 2147483647) ) )  \nFROM room_rates\nWHERE hotel_id='1'\n  AND coalesce(nullif(sgl_ro,0), nullif(sgl_bb,0)\n              ,nullif(sgl_hb,0), nullif(sgl_fb,0)) IS NOT NULL;   \n"]], ['MySQL: Get the MIN value of a table from all columns & rows'], 5, 1], [(25585674, 0), [['You can use a join in your update query with a union set '], ['Also if you have same structure for  sub_trans_a  and  sub_trans_a  so why 2 tables why not just a single table or with a single column for the type as type a or type b ']], [[" UPDATE main_trans m  \njoin\n(SELECT id,SUM(prc) prc\nFROM (\nSELECT id,SUM(prc) prc FROM sub_trans_a WHERE id = 'TR01'\nunion all\nSELECT id,SUM(prc) prc FROM sub_trans_b WHERE id = 'TR01'\n) t1\n) t\non(t.id = m.id)\nSET m.tot = t.prc \nWHERE m.id = 'TR01'\n"]], ['Query for updating a table value based on the total of a column found in multiple tables'], 3, 1], [(25585674, 1), [['Also if you have same structure for  sub_trans_a  and  sub_trans_a  so why 2 tables why not just a single table or with a single column for the type as type a or type b '], ['-10000']], [[' UPDATE main_trans m  \njoin\n(SELECT id,SUM(prc) prc\nFROM (\nSELECT id,SUM(prc) prc FROM sub_trans_a group by id\nunion all\nSELECT id,SUM(prc) prc FROM sub_trans_b group by id\n) t1  group by id\n) t\non(t.id = m.id)\nSET m.tot = t.prc \n']], ['Query for updating a table value based on the total of a column found in multiple tables'], 3, 1], [(25585674, 2), [['-10000'], ['-10000']], [[" UPDATE main_trans m  \njoin\n(SELECT id,SUM(prc) prc\nFROM (\nSELECT id,prc FROM sub_trans_a\nunion all\nSELECT id,prc FROM sub_trans_b \n) t1 WHERE id = 'TR01'\n) t\non(t.id = m.id)\nSET m.tot = t.prc \nWHERE m.id = 'TR01'\n"]], ['Query for updating a table value based on the total of a column found in multiple tables'], 3, 1], [(25652248, 0), [['-10000'], ['EDIT:']], [[' update table1 t1\n   set roleid = 11\n where roleid = 10 and\n       (case when userid = 1 then 1 when userid = 2 then 2 when userid = 3 then 3 else 4 end) =\n         (select min(case when userid = 1 then 1 when userid = 2 then 2 when userid = 3 then 3 else 4 end)\n            from table1\n           where projectid = t1.projectid);\n']], ['In Oracle SQL, how do I UPDATE columns specified by a priority list?'], 2, 1], [(25652248, 1), [['EDIT:'], ['-10000']], [[' SQL> create table table1 (projectid number, userid number, roleid number);\n\nTable created.\n\nSQL> insert into table1 values (101, 1, 10);\n\n1 row created.\n\nSQL> insert into table1 values (101, 2, 10);\n\n1 row created.\n\nSQL> insert into table1 values (102, 2, 10);\n\n1 row created.\n\nSQL> insert into table1 values (102, 3, 10);\n\n1 row created.\n\nSQL> insert into table1 values (103, 1, 10);\n\n1 row created.\n\nSQL> select * from table1;\n\n PROJECTID     USERID     ROLEID\n---------- ---------- ----------\n       101          1         10\n       101          2         10\n       102          2         10\n       102          3         10\n       103          1         10\n\nSQL> update table1 t1\n  2     set roleid = 11\n  3   where roleid = 10 and\n  4         (case when userid = 1 then 1 when userid = 2 then 2 when userid = 3 then 3 else 4 end) = \n  5           (select min(case when userid = 1 then 1 when userid = 2 then 2 when userid = 3 \nthen 3 else 4 end)\n  5                     from table1\n  6                    where projectid = t1.projectid);\n\n3 rows updated.\n\nSQL> select * from table1;           \n\n PROJECTID     USERID     ROLEID\n---------- ---------- ----------\n       101          1         11\n       101          2         10\n       102          2         11\n       102          3         10\n       103          1         11\n']], ['In Oracle SQL, how do I UPDATE columns specified by a priority list?'], 2, 1], [(25687106, 1), [['Assigning an object to other is exactly as standard object assigning:'], ['Same for using an object as a function argument:']], [[' o2 := o1;\n']], ['PL/SQL: Any trick to avoid cloning of objects?'], 8, 0], [(25687106, 2), [['Same for using an object as a function argument:'], ['Internally, afunc() will just use o1 with the same special syntax to access methods or attributes (and no special syntax to assign):']], [[' afunc(o1);\n']], ['PL/SQL: Any trick to avoid cloning of objects?'], 8, 0], [(25687106, 3), [['Internally, afunc() will just use o1 with the same special syntax to access methods or attributes (and no special syntax to assign):'], ['Update : The index value based on the variable name:']], [[" eo.o(o1).attrib := 5;\neo.o(o1).method('nice');\no3 := o1;\n"]], ['PL/SQL: Any trick to avoid cloning of objects?'], 8, 0], [(25687106, 4), [['Update : The index value based on the variable name:'], ['could be a problem if, for example, we create the object in a funcion, since the function would have to know all values used in the rest of the program in order to avoid repeating a value. A solution is to take the value from the hash size:']], [[" o1 := 'o1';\n"]], ['PL/SQL: Any trick to avoid cloning of objects?'], 8, 0], [(25687106, 5), [['could be a problem if, for example, we create the object in a funcion, since the function would have to know all values used in the rest of the program in order to avoid repeating a value. A solution is to take the value from the hash size:'], ['That takes us into other problem: The hash content is persitent (since it is into a package), so more and more objects will be added to the hash as we create objects (even if the objects are created by the same function). A solution is to remove the object from the hash when we are done with the object:']], [[' o1 := eo.o.count;\n']], ['PL/SQL: Any trick to avoid cloning of objects?'], 8, 0], [(25687106, 6), [['That takes us into other problem: The hash content is persitent (since it is into a package), so more and more objects will be added to the hash as we create objects (even if the objects are created by the same function). A solution is to remove the object from the hash when we are done with the object:'], ['So the fixed program would be:']], [[' eo.o(o1) = null;\n']], ['PL/SQL: Any trick to avoid cloning of objects?'], 8, 0], [(25687106, 7), [['So the fixed program would be:'], ['-10000']], [[" create or replace type cla as object        -- complex class\n(\n    name varchar2(10)\n);\n\n\ncreate or replace package eo as     -- package to encapsulate objects\n    type ao_t                       -- type for hash (associative array)\n        is table of cla\n        index by varchar2(100);\n    o ao_t;                         -- hash of objects\nend;\n\n\ndeclare\n    o1 varchar2(100);\n    o2 varchar2(100);\nbegin\n    o1 := eo.o.count;                   -- index based on hash size\n    eo.o(o1) := new cla('hi');          -- store new object into the hash\n    o2 := o1;                           -- assign object == assign index\n    eo.o(o1).name := 'bye';             -- change object attribute\n\n    dbms_output.put_line('eo.o(o1).name: ' || eo.o(o1).name);\n    dbms_output.put_line('eo.o(o2).name: ' || eo.o(o2).name);   -- equal?\n\n    eo.o(o1) = null;                    -- remove object\n    eo.o(o2) = null;                    -- remove object (redundant)\nend;\n"]], ['PL/SQL: Any trick to avoid cloning of objects?'], 8, 1], [(25734598, 0), [['First, get all the posts for a given tag:'], ['Second, you want to tags, I guess, linked to the one you are looking for via posts:']], [[' SELECT * FROM blog_posts bp \nWHERE EXISTS (SELECT * FROM blog_tags bt INNER JOIN\n               tags t ON t.id = bt.tag_id\n              WHERE bp.id = bt.post_id\n               AND t.tag = @SearchTag)\n']], ['Get all posts for specific tag with SQL'], 2, 0], [(25734598, 1), [['Second, you want to tags, I guess, linked to the one you are looking for via posts:'], ['-10000']], [[' SELECT * FROM tags t\nWHERE EXISTS ( -- Here we link two tags via blog_tags\n               SELECT * FROM blog_tags bt1 INNER JOIN\n               blog_tags bt2 ON bt1.post_id = bt2.post_id\n                     AND bt1.tag_id != bt2.tag_id INNER JOIN\n               tags t ON t.id = bt1.tag_id\n               WHERE t.tag = @SearchTag\n                  AND t.id = bt2.tag_id\n)\n']], ['Get all posts for specific tag with SQL'], 2, 0], [(25790263, 1), [["If you're still on an earlier version that doesn't support pivot then you can use a manual approach to do the same thing:"], ['To show the total for each school as well, just add a  sum :']], [[" select school,\n  max(case when class = 'I' then class_size end) as i,\n  max(case when class = 'II' then class_size end) as ii,\n  max(case when class = 'III' then class_size end) as iii\nfrom classes\ngroup by school\norder by school;\n\nSCHOOL          I         II        III\n------ ---------- ---------- ----------\nS1             23         12         54 \nS2             57         12         81 \nS3             12         25         65 \n"]], ['How to convert 2d table into 3d table using SQL'], 4, 1], [(25839647, 0), [['first check your arguments and then build your query according to it for example:'], ['and at the end ']], [['     String[] myArray = new String[] { "31", "" ,"3", ""};\n\n    List<String> myQueryValue = new ArrayList<String>();\n\n    String myQueryParam = "";\n\n    if(!myArray[0].equal("")){\n\n       myQueryParam =  myQueryParam + "UID = ? AND ";\n       myQueryValue.add(myArray[0]);\n    }\n\n    if(!myArray[1].equal("")){\n\n         myQueryParam =  myQueryParam + "Age > ? AND "; \n         myQueryValue.add(myArray[1]);\n    }\n\n   if(!myArray[2].equal("")){\n\n         myQueryParam =  myQueryParam + "Room = ? AND ";\n         myQueryValue.add(myArray[2]);\n    }\n\n    if(!myArray[3].equal("")){\n\n         myQueryParam =  myQueryParam + "AND Adre = ?";\n         myQueryValue.add(myArray[3]);\n    }\n']], ['Write query SQLite with selectionArgs'], 2, 0], [(25839647, 1), [['and at the end '], ['you can also use  loop  to create your values and query param.']], [[' String[] finalValue = new String[ myQueryValue.size() ];\nmyQueryValue.toArray( finalValue );\nCursor cur = sqlite_obj.query(TableName, null, myQueryParam, finalValue , null, null, null, null);\n']], ['Write query SQLite with selectionArgs'], 2, 0], [(25916350, 0), [['You want the  USING  clause to  ALTER TABLE ... ALTER COLUMN ... TYPE , and  the  to_timestamp  function .'], ["In this case as the data looks like it's already a valid timestamp you can probably simplify it with a cast instead:"]], [[" ALTER TABLE mytable \n  ALTER COLUMN thecolumn \n   TYPE TIMESTAMP WITH TIME ZONE \n     USING to_timestamp(thecolumn, 'YYYY-MM-DD HH24:MI:SS');\n"]], ['How to change VARCHAR type to DATETIME using ALTER in Postgresql?'], 2, 1], [(25916350, 1), [["In this case as the data looks like it's already a valid timestamp you can probably simplify it with a cast instead:"], ['You will note that I\'ve used the type name "timestamp with time zone" instead of "datetime". That\'s because in PostgreSQL,  datetime  is just an alias for  timestamp without time zone ... but in most cases you actually want to use  timestamp with time zone  instead. To learn more about timestamps,  see the manual .']], [[' ALTER TABLE mytable \n  ALTER COLUMN thecolumn \n   TYPE TIMESTAMP WITH TIME ZONE \n     USING to_timestamp(thecolumn::timestamp with time zone);\n']], ['How to change VARCHAR type to DATETIME using ALTER in Postgresql?'], 2, 1], [(25940181, 0), [['A simple solution would be a pattern like this:'], ['To match only strings that contain  different  letters, you could use a negative lookahead ( (?!…) ) and a backreference ( \\ N ):']], [[' (.*[abcxyz]){3}\n']], ['Contains at least a count of different character in a set'], 2, 1], [(25940181, 1), [['To match only strings that contain  different  letters, you could use a negative lookahead ( (?!…) ) and a backreference ( \\ N ):'], ['This will match zero or more of any character, followed by one of  a ,  b ,  c ,  x ,  y , or  z , as long as another instance of that character does not appear later in the string (i.e. it will match the last instance of that character in the string), all of which must appear at least 3 times in the subject string.']], [[' (.*([abcxyz])(?!.*\\2)){3}\n']], ['Contains at least a count of different character in a set'], 2, 1], [(25941109, 1), [['You can test this... just put this in your query criteria field:'], ['Run it with False instead of True... experiment.']], [[' IIf(True,"*","")\n']], ['Access query to include all values, including Null'], 2, 0], [(25961419, 0), [['You can get the maximum value by using this construct:'], ['If you want to use  max() , then you need to deconstruct the number.  Something like:']], [[' select s_id\nfrom stock_detail\norder by length(s_id) desc, s_id desc\nlimit 1;\n']], ['I want to get the maximum value from my S_ID column which is declared as varchar type'], 2, 1], [(25961419, 1), [['If you want to use  max() , then you need to deconstruct the number.  Something like:'], ['This allows you to get a  numeric  maximum value rather than a  character  maximum value, which is the root of your problem.']], [[" select concat('S_', max(replace(s_id, 'S_', '') + 0))\nfrom stock_detail;\n"]], ['I want to get the maximum value from my S_ID column which is declared as varchar type'], 2, 1], [(25992186, 0), [['You can create a Table-Valued Function which takes the nVarChar and creates a new record for each value, where you tell it the delimiter.  My example here returns a table with a single Value column, you can then use this as a sub query for your IN Selection :'], ['Then in your where statement you could do the following:']], [[" Create  FUNCTION [dbo].[fnSplitVariable]\n(\n    @List nvarchar(2000),\n    @delimiter nvarchar(5)\n)  \nRETURNS @RtnValue table \n(\n\n    Id int identity(1,1),\n    Variable varchar(15),\n    Value nvarchar(100)\n) \nAS  \nBEGIN\nDeclare @Count int\nset @Count = 1\n    While (Charindex(@delimiter,@List)>0)\n    Begin \n        Insert Into @RtnValue (Value, Variable)\n        Select \n            Value = ltrim(rtrim(Substring(@List,1,Charindex(@delimiter,@List)-1))),\n        Variable = 'V' + convert(varchar,@Count)\n            Set @List = Substring(@List,Charindex(@delimiter,@List)+len(@delimiter),len(@List))\n        Set @Count = @Count + 1\n    End  \n\n    Insert Into @RtnValue (Value, Variable)\n        Select Value = ltrim(rtrim(@List)), Variable = 'V' + convert(varchar,@Count)\n\n        Return\nEND\n"]], ['cast list of strings as int list in sql query / stored procedure'], 3, 0], [(25992186, 1), [['Then in your where statement you could do the following:'], ['I have included your original Procedure, and updated it to use the function above:']], [[" WHERE (b.CityID IN (Select Value from fnSplitVariable(@CityIDs, ','))\n"]], ['cast list of strings as int list in sql query / stored procedure'], 3, 0], [(26001924, 0), [['A simple, "brute-force" method would be to  cast the array to  text  and check:'], ['A clean and elegant solution with  unnest()  in a  NOT EXISTS  semi-join :']], [[" SELECT title, short_url, categories, winning_offer_amount\nFROM   auctions\nWHERE  ended_at IS NOT NULL\nAND    categories::text NOT LIKE '% > %';  -- including blanks?\n"]], ['Where array does not contain value Postgres'], 2, 1], [(26001924, 1), [['A clean and elegant solution with  unnest()  in a  NOT EXISTS  semi-join :'], ['SQL Fiddle.']], [[" SELECT title, short_url, categories, winning_offer_amount\nFROM   auctions a\nWHERE  ended_at IS NOT NULL\nAND    NOT EXISTS (\n   SELECT 1\n   FROM   unnest(a.categories) AS cat\n   WHERE  cat LIKE '% > %'\n   );\n"]], ['Where array does not contain value Postgres'], 2, 1], [(26004152, 0), [["It's slightly ambiguous, but it sounds like you want to  union all  the two results together:"], ["or as Tab suggeted, union first then join. This might deal better with cases where there's an entry in one table but not the other:"]], [[' select\n    c.CustomerID ID,\n    c.CustomerName Cname,\n    o.TotalAmt,\n    o.OrderType\nfrom\n    Customers c\n        left join\n    AM_Orders o\n        on c.CustomerID = o.CustomerID\nunion all    \nselect\n    c.CustomerID ID,\n    c.CustomerName Cname,\n    o.TotalAmt,\n    o.OrderType\nfrom\n    Customers c\n        left join\n    PM_Orders o\n        on c.CustomerID = o.CustomerID\norder by\n    ID;\n']], ['Combining 2 fields into 1 field'], 2, 1], [(26004152, 1), [["or as Tab suggeted, union first then join. This might deal better with cases where there's an entry in one table but not the other:"], ['-10000']], [[' ;with all_orders as (\n    select\n        o.CustomerID,\n        o.TotalAmt,\n        o.OrderType\n    from\n        AM_Orders o\n    union all\n    select\n        o.CustomerID,\n        o.TotalAmt,\n        o.OrderType\n    from\n        PM_Orders o\n) select\n    c.CustomerID ID,\n    c.CustomerName Cname,\n    a.TotalAmt,\n    a.OrderType\nfrom\n    Customers c\n        left join\n    all_orders a\n        on c.CustomerID = a.CustomerID\norder by\n    ID;\n']], ['Combining 2 fields into 1 field'], 2, 1], [(26019476, 0), [["Isn't  USER  a function in H2?"], ['will return the current user. Works as expected as a default value for a column:']], [[' SELECT USER()\n']], ["H2 equivalent to Oracle's user"], 4, 1], [(26019476, 1), [['will return the current user. Works as expected as a default value for a column:'], ['As an other user:']], [[" create table MY_TABLE(\n  CREATED_BY Varchar2(100) DEFAULT USER() NOT NULL,\n  value Varchar2(10)\n)\nINSERT INTO MY_TABLE (value) VALUES ('XXX');\n"]], ["H2 equivalent to Oracle's user"], 4, 0], [(26019476, 3), [['Result:'], ['-10000']], [[' CREATED_BY      VALUE  \nSA              XXX\nSYLVAIN         YYY\n']], ["H2 equivalent to Oracle's user"], 4, 0], [(26046622, 0), [['-10000'], ["Since these are FACT and DIM tables I think you will be deleting Large amount of data, otherwise you wouldn't care much about the performance. Another thing you can consider when delete large amount of data is, Deleting it in Smaller chunks. By doing something as below "]], [[" DELETE FROM [FACT]\nWHERE NOT EXISTS (SELECT 1\n                  FROM [DIMENSION]\n                  WHERE [FACT].[FK] = [DIMENSION].[PK]\n                   AND  [FACT].[TYPE] LIKE 'LAB%')\n"]], ['T-SQL: efficiently DELETE records in right table that are not in left table when using RIGHT JOIN'], 2, 1], [(26046622, 1), [["Since these are FACT and DIM tables I think you will be deleting Large amount of data, otherwise you wouldn't care much about the performance. Another thing you can consider when delete large amount of data is, Deleting it in Smaller chunks. By doing something as below "], ['-10000']], [[" DECLARE @Deleted_Rows INT;\nSET @Deleted_Rows = 1;\n\n\nWHILE (@Deleted_Rows > 0)\n  BEGIN\n   -- Delete some small number of rows at a time\n    DELETE TOP (10000) FROM [FACT]\n    WHERE NOT EXISTS (SELECT 1\n                      FROM [DIMENSION]\n                      WHERE [FACT].[FK] = [DIMENSION].[PK]\n                       AND  [FACT].[TYPE] LIKE 'LAB%')\n\n  SET @Deleted_Rows = @@ROWCOUNT;\nEND\n"]], ['T-SQL: efficiently DELETE records in right table that are not in left table when using RIGHT JOIN'], 2, 1], [(26063286, 0), [['Provided you use a 3rd Table to hold you Long/Short Names as so.'], ['The following query should give you what you are looking for.']], [[" CREATE TABLE TableNames\n    ([Id] int, [OfficialName] varchar(7), [Alias] varchar(7))\n;\n\nINSERT INTO TableNames\n    ([Id], [OfficialName], [Alias])\nVALUES\n    (1, 'Andrew', 'Andy'),\n    (2, 'Andrew', 'Andrew'),\n    (3, 'William', 'Bill'),\n    (4, 'William', 'William'),\n    (5, 'David', 'Dave'),\n    (6, 'David', 'David')\n"]], ['Matching First and Last Name on two different tables'], 2, 0], [(26063286, 1), [['The following query should give you what you are looking for.'], ['I set up my solution sqlfiddle at  http://sqlfiddle.com/#!3/64514/2']], [[' SELECT *\nFROM (\n    SELECT TableA.Id AS T1_Id\n        ,CompanyId AS T1_CompanyId\n        ,FirstName AS T1_FirstName\n        ,LastName AS T1_LastName\n        ,TableNames.OfficialName AS OfficialName\n    FROM tableA\n    INNER JOIN tableNames ON TableA.FirstName = TableNames.Alias\n    ) T1\n    ,(\n        SELECT tableB.Id AS T2_Id\n            ,CompanyId AS T2_CompanyId\n            ,FirstName AS T2_FirstName\n            ,LastName AS T2_LastName\n            ,TableNames.OfficialName AS OfficialName\n        FROM tableB\n        INNER JOIN tableNames ON TableB.FirstName = TableNames.Alias\n        ) T2\nWHERE T1.T1_CompanyId = T2.T2_CompanyId\n    AND T1.OfficialName = T2.OfficialName\n    AND T1.T1_LastName = T2.T2_LastName\n']], ['Matching First and Last Name on two different tables'], 2, 1], [(26063793, 0), [['Start with a  SELECT  query which identifies the rows you want deleted.'], ['After you verify that query identifies the correct rows, convert it to a  DELETE  query.']], [[' SELECT y.CreatedBy, y.FileId, y.FileName, y.CreationDate\nFROM YourTable AS y\nWHERE\n    y.CreationDate <  \n        DMax(\n            "CreationDate",\n            "YourTable",\n            "FileName=\'" & y.FileName & "\'"\n            );\n']], ['Finding duplicate records from table and deleting all but one with latest date'], 2, 0], [(26088814, 0), [['Here I used the  row_number  function to get a running count of rows and incremented the date by 1 day for each row:'], ["With the result set of dates now, it's trivial to check the day of week using  datepart()"]], [[" select \ndateadd(d, row_number() over (order by name), cast('31 Dec 2013' as datetime)) as dt \nfrom sys.columns a\n"]], ['How to select every Monday date and every Friday date in the year'], 3, 0], [(26102456, 0), [['This can be done with a check constraint that verifies null value and matches the result with or'], ['The following are the test cases']], [[' create table #t (i int\n               , j int\n               , constraint chk_null check (i is not null or j is not null))\n']], ['I need a check constraint on two columns, at least one must be not null'], 2, 1], [(26102456, 1), [['The following are the test cases'], ['-10000']], [[' insert into #t values (null, null) --> error\ninsert into #t values (1, null) --> ok\ninsert into #t values (null, 1) --> ok\ninsert into #t values (1, 1) --> ok\n']], ['I need a check constraint on two columns, at least one must be not null'], 2, 0], [(26162762, 0), [['Using MS SQL it would be:'], ['I think the Postgresql could be this:']], [[' select \n    dateadd(second, -DATEPART(second,ts),ts) as ts, \n    SUM(val) as v_sum \nfrom your_table\ngroup by dateadd(second, -DATEPART(second,ts),ts)\n']], ['sql select query from a single table, results separated by intervals'], 2, 1], [(26162762, 1), [['I think the Postgresql could be this:'], ["I tried the MSSQL version and got the desired result,  but as SQL Fiddle is down at the moment I couldn't try the PG version.  and also the PG version, which seems to work."]], [[" SELECT \n  date_trunc('minute', ts),\n  sum(val) v_sum \nFROM\n  your_table\nGROUP BY date_trunc('minute', ts)\nORDER BY 1\n"]], ['sql select query from a single table, results separated by intervals'], 2, 1], [(26167223, 0), [['-10000'], ['or']], [[' select columnname, count(*)\nfrom YourTable\ngroup by columnName\n']], ['How can I count a column with values'], 2, 1], [(26167223, 1), [['or'], ['-10000']], [[" select \nsum(case when columnname='present' then =1 end) 'present',\nsum(case when columnname='absent' then =1 end) 'absent',\nsum(case when columnname='leave' then =1 end) 'leave'\nfrom myTable\n"]], ['How can I count a column with values'], 2, 1], [(26208027, 0), [['If the requirement is to not use an  OR , you could use  UNION  instead. Since you filter the department on its number, not on its name, you do not need the second table at all:'], ['If you wanted to filter the department by name, a join or a subquery would be required:']], [[' SELECT name FROM employee WHERE salary > 20000\n    UNION\nSELECT name FROM employee WHERE dNumber = 1\n']], ['Select from two tables without using an OR'], 2, 1], [(26208027, 1), [['If you wanted to filter the department by name, a join or a subquery would be required:'], ['-10000']], [[" SELECT name FROM employee WHERE salary > 20000\n    UNION\nSELECT name FROM employee e\nJOIN department d ON e.dNumber=d.departmentNumber\nWHERE departmentName = 'math'\n"]], ['Select from two tables without using an OR'], 2, 1], [(26227103, 0), [['Just loop through the  getRole  query and use list functions as braketsage suggested. Dan makes a good point about checkboxes, but I will use your original code to better illustrate:'], ['Note:  I added a boolean flag that I like to use in my apps. Using an OUTER JOIN and CASE statement you can create a boolean column called  IsAssigned  that indicates whether or not each role is assigned to the selected user. That flag comes in handy for pre-selecting list items (or checkboxes) on the edit screen.']], [[' <select name="role" multiple="multiple" size="7">\n   <cfoutput query="getRole">\n      <option value="#getRole.role_name#" \n        <!--- if the current role is found in the list of user roles --->\n        <cfif listFindNoCase(getUser.ListOfRoles, getRole.role_name)>\n           selected\n        </cfif>>\n        #GetRole.role_name#\n       </option>\n   </cfoutput>\n</select>\n']], ['SQL query inner join tables, print to HTML <select> tag'], 2, 0], [(26227103, 1), [['Note:  I added a boolean flag that I like to use in my apps. Using an OUTER JOIN and CASE statement you can create a boolean column called  IsAssigned  that indicates whether or not each role is assigned to the selected user. That flag comes in handy for pre-selecting list items (or checkboxes) on the edit screen.'], ['NB:  Be sure to read up on  CROSS JOIN']], [[' SELECT  ur.roleID\n        , ur.roleTitle\n        , ur.UserID\n        , ur.UserName\n        , CASE WHEN p.UserID IS NOT NULL THEN 1 ELSE 0 END AS IsAssigned\nFROM   (\n          SELECT u.UserID\n                 , u.UserName\n                 , r.RoleID\n                 , r.RoleTitle\n          FROM   Users u CROSS JOIN Roles r\n          WHERE  u.UserID = <cfqueryparam value="#FORM.id#" cfsqltype="cf_sql_integer">\n\n       ) \n       ur LEFT JOIN Permissions p\n                ON p.RoleID = ur.RoleID\n                AND p.UserID = ur.UserID\n']], ['SQL query inner join tables, print to HTML <select> tag'], 2, 1], [(26285750, 0), [['So, your custom adapter class could be somthing like:'], ['And your Person.java class could as simple as I describe below:']], [['     public class CustomAdapter extends BaseAdapter {\n        private final Activity activity;\n        private final List list;\n\n        public CustomAdapter(Activity activity, ArrayList<Person> list) {\n            this.activity = activity;\n            this.list = list;\n        }\n\n    @Override\n    public int getCount() {\n        return list.size();\n    }\n\n    @Override\n    public Object getItem(int arg0) {\n        // TODO Auto-generated method stub\n        return null;\n    }\n\n    @Override\n    public long getItemId(int arg0) {\n        // TODO Auto-generated method stub\n        return 0;\n    }\n\n        @Override\n        public View getView(int position, View convertView, ViewGroup parent) {\n            View rowView = convertView;\n            ViewHolder view;\n\n            if(rowView == null)\n            {\n                // Get a new instance of the row layout view\n                LayoutInflater inflater = activity.getLayoutInflater();\n                rowView = inflater.inflate(R.layout.rowlayout, null);\n\n                // Hold the view objects in an object, that way the don\'t need to be "re-  finded"\n                view = new ViewHolder();\n                view.person_name= (TextView) rowView.findViewById(R.id.name);\n                view.person_address= (TextView) rowView.findViewById(R.id.address);\n\n                rowView.setTag(view);\n            } else {\n                view = (ViewHolder) rowView.getTag();\n            }\n\n            /** Set data to your Views. */\n            Person item = list.get(position);\n            view.person_name.setText(item.getTickerSymbol());\n            view.person_address.setText(item.getQuote().toString());\n\n            return rowView;\n        }\n\n        protected static class ViewHolder{\n            protected TextView person_name;\n            protected TextView person_address;\n        }\n    }\n']], ['Android sql element to listview'], 3, 0], [(26285750, 1), [['And your Person.java class could as simple as I describe below:'], ['Now, in you main activity just bind you list with some data, like;']], [[' public class Person {\n    private String name;\n    private String address;\n\n    public Person(String name, String address) {\n        this.name = name;\n        this.address = address;\n    }\n    public void setName(String name) {\n        this.name= name;\n    }\n    public String getName() {\n        return name;\n    }\n    public void setAddress(String address) {\n        this.address= address;\n    }\n    public String getAddress() {\n        return address;\n    }\n}\n']], ['Android sql element to listview'], 3, 0], [(26285750, 2), [['Now, in you main activity just bind you list with some data, like;'], ['-10000']], [[' /** Declare and initialize list of Person. */\nArrayList<Person> list = new ArrayList<Person>();\n\n/** Add some restaurants to the list. */\nlist.add(new Person("name1", "address1"));\nlist.add(new Person("name2", "address2"));\nlist.add(new Person("name3", "address3"));\nlist.add(new Person("name4", "address4"));\nlist.add(new Person("name5", "address5"));\nlist.add(new Person("name6", "address6"));\nAt this point you\'re able to set the custom adapter to your list\n\nListView lv = (ListView) findViewById(R.id.mylist);\n\nCustomAdapter adapter = new CustomAdapter(YourMainActivityName.this, list);\nlv.setAdapter(adapter);\n']], ['Android sql element to listview'], 3, 0], [(26313466, 0), [['(note, untested code)'], ['As a union:']], [[" select\n    case when SenderID=@ID then ReciverID else SenderID end as OtherPersonID\nfrom\n    Friend_Table\nwhere\n    ReqStatus='True'\n    and (SenderID=@ID or ReciverID=@ID)\n"]], ['How to get Friends UniqID with Sql Query'], 2, 1], [(26313466, 1), [['As a union:'], ["Also, the correct spelling is actually 'Receiver'."]], [[" select ReciverID as OtherPersonID from Friend_Table where (ReqStatus='True' and SenderID=@ID)\nunion\nselect SenderID as OtherPersonID from Friend_Table where (ReqStatus='True' and ReciverID=@ID)\n"]], ['How to get Friends UniqID with Sql Query'], 2, 1], [(26332939, 0), [['MySQL 5.5.32 Schema Setup :'], ['Query 1 :']], [[" CREATE TABLE facility\n    (`Id_facility` int, `time_start` varchar(8), `time_end` varchar(8))\n;\n\nINSERT INTO facility\n    (`Id_facility`, `time_start`, `time_end`)\nVALUES\n    (1, '07:00:00', '19:00:00'),\n    (2, '08:00:00', '20:00:00')\n;\n"]], ['Get minimum hours and maximum hours from mysql'], 3, 0], [(26332939, 2), [['Results :'], ['-10000']], [[' | MIN( TIME_START) | MAX( TIME_END) |\n|------------------|----------------|\n|         07:00:00 |       20:00:00 |\n']], ['Get minimum hours and maximum hours from mysql'], 3, 0], [(26341790, 0), [['This should work:'], ['EDIT']], [[' SELECT   [Barcode], max([TimeStamp])\nFROM     [InventoryLocatorDB].[dbo].[Inventory]\nGROUP BY [Barcode]\n']], ['Select unique barcode with max timestamp'], 3, 1], [(26341790, 1), [['EDIT'], ['E.g. only one tuple per  BarCode , latest  TimeStamp , greatest value of  Products :']], [[' SELECT [Barcode], [Products], [TimeStamp]\nFROM   [InventoryLocatorDB].[dbo].[Inventory] AS I\nWHERE  [TimeStamp] = (SELECT MAX([TimeStamp])\n                      FROM   [InventoryLocatorDB].[dbo].[Inventory]\n                      WHERE  [Barcode] = I.[Barcode])\n']], ['Select unique barcode with max timestamp'], 3, 1], [(26341790, 2), [['E.g. only one tuple per  BarCode , latest  TimeStamp , greatest value of  Products :'], ['Demo 3']], [[' SELECT [Barcode], [Products], [TimeStamp]\nFROM   [InventoryLocatorDB].[dbo].[Inventory] AS I\nWHERE  [TimeStamp] = (SELECT MAX([TimeStamp])\n                      FROM   [InventoryLocatorDB].[dbo].[Inventory]\n                      WHERE  [Barcode] = I.[Barcode]) AND\n       [Products]  = (SELECT MAX([Products])\n                      FROM   [InventoryLocatorDB].[dbo].[Inventory]\n                      WHERE  [Barcode] = I.[Barcode] and [TimeStamp] = I.[TimeStamp])\n']], ['Select unique barcode with max timestamp'], 3, 1], [(26381169, 0), [['Just add the  WHERE  condition in your  SELECT  part like'], ["In that case, if you  INSERT  then you will add new records with  null  in rest of the field but not  update  old records. Moreover, for your case you don't need a  WHERE  clause rather a  JOIN clause  and specify the condition."]], [[' INSERT INTO Notifications (imageUri, DOB) \nSELECT d.imageUri, d.birthDate \nFROM Details d\nJOIN Notifications n\nON d._id = n.PrimaryId\n']], ['SQL copy from one table insert into another - using a where clause'], 2, 1], [(26383863, 1), [['This will return your current results.'], ['Try the following query to UNPIVOT your data.']], [[' BatchID     TestType TestOne     TestTwo     TestThree   TestFour\n----------- -------- ----------- ----------- ----------- -----------\n1           A        1.20        0.00        16.00       8.20\n2           A        1.30        1.00        15.00       7.40\n']], ['SQL Selecting one row, displaying several'], 4, 0], [(26383863, 2), [['Try the following query to UNPIVOT your data.'], ['This should return the desired results.']], [[' SELECT BatchID, 1 AS Test, TestOne AS Result FROM @TestResults UNION ALL\nSELECT BatchID, 2 AS Test, TestTwo FROM @TestResults  UNION ALL\nSELECT BatchID, 3 AS Test, TestThree FROM @TestResults  UNION ALL\nSELECT BatchID, 4 AS Test, TestFour  FROM @TestResults \nORDER BY BatchID, Test\n']], ['SQL Selecting one row, displaying several'], 4, 1], [(26383863, 3), [['This should return the desired results.'], ['-10000']], [[' BatchID     Test        Result\n----------- ----------- -----------\n1           1           1.20\n1           2           0.00\n1           3           16.00\n1           4           8.20\n2           1           1.30\n2           2           1.00\n2           3           15.00\n2           4           7.40\n']], ['SQL Selecting one row, displaying several'], 4, 0], [(26398902, 0), [["This unpacks your  specific  data into the result set you've asked for, but how reusable this is depends a lot on what other pieces of XML you might want to unpack:"], ['Result:']], [[' declare @inp xml = \'<root>\n <log realm="ABC" at="Wed Oct 15 00:00:02 2014.211" lifespan="2279ms">\n  <receive>\n    <isomsg direction="IN">\n      <header>6000911384</header>\n      <field id="0" value="0800"/>\n      <field id="3" value="980000"/>\n      <field id="11" value="000852"/>\n    </isomsg>\n  </receive>\n</log>\n</root>\'\n\nselect\n    n.value(\'@at\',\'varchar(10)\') + SUBSTRING(n.value(\'@at\',\'varchar(30)\'),20,5) as AT,\n    n.value(\'@lifespan\',\'varchar(20)\') as lifespan,\n    n.value(\'receive[1]/isomsg[1]/@direction\',\'varchar(10)\') as direction,\n    n.value(\'receive[1]/isomsg[1]/field[@id="0"][1]/@value\',\'varchar(10)\') as id_0,\n    n.value(\'receive[1]/isomsg[1]/field[@id="3"][1]/@value\',\'varchar(10)\') as id_3,\n    n.value(\'receive[1]/isomsg[1]/field[@id="11"][1]/@value\',\'varchar(10)\') as id_11\nfrom @inp.nodes(\'/root/log\') n(n)\n']], ['How to transform XML data into SQL Server table (part 2)'], 2, 1], [(26398902, 1), [['Result:'], ['-10000']], [[' AT              lifespan             direction  id_0       id_3       id_11\n--------------- -------------------- ---------- ---------- ---------- ----------\nWed Oct 15 2014 2279ms               IN         0800       980000     000852\n']], ['How to transform XML data into SQL Server table (part 2)'], 2, 0], [(26429966, 0), [['Rows can be excluded from the row number by using two  case  statements.  The first one creates two separate  partition by , one for excluded rows and one\n for rows you care about.  The outer  case  then displays null for the excluded rows.'], ["The results don't exactly match.  The example uses 1 twice for the new row number - is that a mistake?"]], [[" select\n    case\n        when status = 'Exclude' then\n            null\n        else\n            row_number() over\n            (\n                partition by case when status = 'Exclude' then 0 else 1 end\n                order by numb\n            )\n    end new_rownumber,\n    data.*\nfrom\n(\n    select 1 numb, 'Bill' name, 'blah1' text, 'GOOD'    status from dual union all\n    select 1 numb, 'Bill' name, 'blah2' text, 'Exclude' status from dual union all\n    select 2 numb, 'Jack' name, 'blah3' text, 'GOOD'    status from dual union all\n    select 2 numb, 'Jack' name, 'blah4' text, 'Exclude' status from dual union all\n    select 3 numb, 'Will' name, 'blah5' text, 'GOOD'    status from dual union all\n    select 3 numb, 'Will' name, 'blah6' text, 'Exclude' status from dual union all\n    select 4 numb, 'Andy' name, 'blah7' text, 'GOOD'    status from dual union all\n    select 4 numb, 'Andy' name, 'blah8' text, 'GOOD'    status from dual \n) data\norder by numb, status desc;\n"]], ['Partition by ignoring some columns'], 2, 1], [(26429966, 1), [["The results don't exactly match.  The example uses 1 twice for the new row number - is that a mistake?"], ['-10000']], [[' NEW_ROWNUMBER   NUMB   NAME   TEST    STATUS\n-------------   ----   ----   ----    ------\n1               1      Bill    blah1  GOOD\n                1      Bill    blah2  Exclude\n2               2      Jack    blah3  GOOD\n                2      Jack    blah4  Exclude\n3               3      Will    blah5  GOOD\n                3      Will    blah6  Exclude\n5               4      Andy    blah7  GOOD\n4               4      Andy    blah8  GOOD\n']], ['Partition by ignoring some columns'], 2, 0], [(26430013, 0), [['You should create three separate tables:'], ['And the third table gives you the relationship between the two:']], [[' "persons"\nint ID (primary key, auto-increment)\nvarchar username\nvarchar email ... (all other info needed)\n\n"places"\nint ID (primary key, auto-increment)\nvarchar name\netc.\n']], ['Creating a Table in SQL, where each tuple can have mutiple values'], 2, 0], [(26430013, 1), [['And the third table gives you the relationship between the two:'], ['This way, every time a person starts working in a new place, you just add an entry to the "person_places". Same thing when they leave a place, or a place goes out of business or whatever, you just need to touch the "person_places" table.']], [[' "person_places" (or place_persons, depends on what you like)\nint ID (primary key, auto-increment)\nint place_id (linked to the ID of the "places" entry)\nint person_id (linked to the ID of the "persons" entry)\n']], ['Creating a Table in SQL, where each tuple can have mutiple values'], 2, 0], [(26449233, 0), [['SQL Server 2005 supports window functions, so you can do something like this:'], ["If there is more than one nation with the same minimum value, you will get each of them. If you don't want that, you need to use  row_number()"]], [[' select id,\n       name, \n       NaID,\n       name, \n       qty\nfrom  (\n  select p.id,\n         p.name, \n         p.NaID,\n         n.name,\n         min(P.Qty) over (partition by n.naid) as min_qty, \n         p.qty\n  from Product p\n     join Nation n on p.NaID=n.NaID\n) t\nwhere qty = min_qty;\n']], ['SQL:How to get min Quantity?'], 2, 1], [(26449233, 1), [["If there is more than one nation with the same minimum value, you will get each of them. If you don't want that, you need to use  row_number()"], ["As your example output with only includes the NaID but not the nation's name you don't really need the the join between  product  and  nation ."]], [[' select id,\n       name, \n       NaID,\n       name, \n       qty\nfrom  (\n  select p.id,\n         p.name, \n         p.NaID,\n         n.name,\n         row_number() over (partition by n.naid order by p.qty) as rn, \n         p.qty\n  from Product p\n     join Nation n on p.NaID = n.NaID\n) t\nwhere rn = 1;\n']], ['SQL:How to get min Quantity?'], 2, 1], [(26494428, 0), [['Add a redundant predicate to the query to convince Oracle that the expression will not return null values and an index can be used:'], ['-10000']], [[" select regexp_replace(film.title, '(\\w+).*$','\\1') first_word\nfrom film\nwhere regexp_replace(film.title, '(\\w+).*$','\\1') is not null;\n"]], ['Using function based index (oracle) to speed up count(X)'], 4, 1], [(26494428, 1), [['-10000'], ['Even with an index hint, the normal query will not use an index.  Remember that hints are directives, and this query  would  use the index if it was possible.']], [[" create table film (\nfilm_id number(5) not null,\ntitle varchar2(255) not null);\n\ninsert into film select rownumber, column_value\nfrom\n(\n    select rownum rownumber, column_value from table(sys.odcivarchar2list(\n    q'<The Shawshank Redemption>',\n    q'<The Godfather>',\n    q'<The Godfather: Part II>',\n    q'<The Dark Knight>',\n    q'<Pulp Fiction>',\n    q'<The Good, the Bad and the Ugly>',\n    q'<Schindler's List>',\n    q'<12 Angry Men>',\n    q'<The Lord of the Rings: The Return of the King>',\n    q'<Fight Club>'))\n);\n\ncreate index film_idx1 on film(regexp_replace(title, '(\\w+).*$','\\1'));\n\nbegin\n    dbms_stats.gather_table_stats(user, 'FILM');\nend;\n/\n"]], ['Using function based index (oracle) to speed up count(X)'], 4, 0], [(26496183, 0), [['You can do this using window functions:'], ['If you know the agent names are never duplicated, you could just do:']], [[' select t.account_number, t.agent_name\nfrom (select t.*, min(agent_name) over (partition by account_number) as minan,\n             max(agent_name) over (partition by account_number) as maxan\n      from table t\n     ) t\nwhere minan <> maxan;\n']], ['sql that identifies which account numbers have multiple agents'], 2, 1], [(26496183, 1), [['If you know the agent names are never duplicated, you could just do:'], ['-10000']], [[' select t.account_number, t.agent_name\nfrom (select t.*, count(*) over (partition by account_number) as cnt\n      from table t\n     ) t\nwhere cnt > 1;\n']], ['sql that identifies which account numbers have multiple agents'], 2, 1], [(26518526, 0), [['I think what you are asking for will work by joining the  Initial  table to both  Option_A  and  Option_B  using  LEFT JOIN , which will produce something like this:'], ['Example code:']], [[' Initial LEFT JOIN Option_A LEFT JOIN NULL\nOR\nInitial LEFT JOIN NULL LEFT JOIN Option_B\n']], ['Conditional JOIN Statement SQL Server'], 2, 0], [(26518526, 1), [['Example code:'], ["Once you have done this, you 'ignore' the set of NULLS.  The additional trick here is in the SELECT line, where you need to decide what to do with the NULL fields.  If the Option_A and Option_B tables are similar, then you can use the  COALESCE  function to return the first NON NULL value (as per the example).  "]], [[' SELECT i.*, COALESCE(a.id, b.id) as Option_Id, COALESCE(a.name, b.name) as Option_Name\nFROM Initial_Table i\nLEFT JOIN Option_A_Table a ON a.initial_id = i.id AND i.special_value = 1234\nLEFT JOIN Option_B_Table b ON b.initial_id = i.id AND i.special_value <> 1234\n']], ['Conditional JOIN Statement SQL Server'], 2, 1], [(26548087, 0), [["If the column is already XML data type in SQL Server, then the code below should work by using the value function with XPATH. If it's stored as a varchar, you'd just need to replace  ClassXML.value  with  CONVERT(XML, ClassXML).value . Hope this helps!"], ['Yields output']], [[" DECLARE @Data TABLE (ClassXML XML)\nINSERT @Data VALUES ('<CustomContentData><prpIsRSSFeed>false</prpIsRSSFeed></CustomContentData>')\n\nSELECT\n    CONVERT(BIT, CASE WHEN ClassXML.value ('(/CustomContentData/prpIsRSSFeed)[1]',\n        'VARCHAR(50)') = 'true' THEN 1 ELSE 0 END) AS IsRssFeed\nFROM @Data\n"]], ['Easiest way to query a SQL Server 2008 R2 XML data type?'], 2, 1], [(26548087, 1), [['Yields output'], ['-10000']], [[' IsRssFeed\n---------\n0\n']], ['Easiest way to query a SQL Server 2008 R2 XML data type?'], 2, 0], [(26592173, 0), [["Given your new requirements, I'm actually going to point you towards  this answer  that suggests (strongly) you use the Full Text Search functionality in SQL Server.  If that is unavailable, though, you can take the performance hit of doing this yourself and use the following code:"], ['Full example with sample data:']], [[" SELECT MyWord, @String AS SearchPhrase \nFROM MyLookup \nWHERE '.' + @String + '.' LIKE '%[^a-z]'+MyWord+'[^a-z]%'\n"]], ['SQL identify whether a word in nvarchar variable is listed in lookup table'], 3, 1], [(26592173, 1), [['Full example with sample data:'], ["Note that if the word shows multiple times in the same search string, this will replace all instances. I don't have access to an instance with full text search enabled, so you'll have to confirm that this is working as expected."]], [[" DECLARE @MyLookup TABLE (MyWord VARCHAR(20))\nINSERT INTO @MyLookup (MyWord) VALUES ('Flubber')\n\nDECLARE @String nVARCHAR(4000)\n\n\nSET @String = N'I really like watching Flubbers'\nSELECT MyWord, @String AS SearchPhrase FROM @MyLookup WHERE '.' + @String + '.' LIKE '%[^a-z]'+MyWord+'[^a-z]%'\n\nSET @String = N'I really like watching Flubber.'\nSELECT MyWord, @String AS SearchPhrase FROM @MyLookup WHERE '.' + @String + '.' LIKE '%[^a-z]'+MyWord+'[^a-z]%'\n\nSET @String = N'I really like watching Flubber, is that weird?'\nSELECT MyWord, @String AS SearchPhrase FROM @MyLookup WHERE '.' + @String + '.' LIKE '%[^a-z]'+MyWord+'[^a-z]%'\n\nSET @String = N'I really like watching the Flubber movie'\nSELECT MyWord, @String AS SearchPhrase FROM @MyLookup WHERE '.' + @String + '.' LIKE '%[^a-z]'+MyWord+'[^a-z]%'\n\nSET @String = N'I really like watching Flubber!'\nSELECT MyWord, @String AS SearchPhrase FROM @MyLookup WHERE '.' + @String + '.' LIKE '%[^a-z]'+MyWord+'[^a-z]%'\n\nSET @String = N'I really like watchingFlubber'\nSELECT MyWord, @String AS SearchPhrase FROM @MyLookup WHERE '.' + @String + '.' LIKE '%[^a-z]'+MyWord+'[^a-z]%'\n"]], ['SQL identify whether a word in nvarchar variable is listed in lookup table'], 3, 1], [(26592173, 2), [["Note that if the word shows multiple times in the same search string, this will replace all instances. I don't have access to an instance with full text search enabled, so you'll have to confirm that this is working as expected."], ['-10000']], [[" DECLARE @String NVARCHAR(4000) \nDECLARE @MatchedWord NVARCHAR(100) \nDECLARE @ReturnString NVARCHAR(4000) \nSET @String = 'i really like watching Flubber' \n\nSELECT \n    @MatchedWord = MyWord,\n    @ReturnString = REPLACE(@String, MyWord, REPLICATE('*', LEN(MyWord)))\nFROM MyLookup \nWHERE FREETEXT (DESCR,@String) \n\nPRINT CONVERT(VARCHAR(4000), @MatchedWord)\nPRINT CONVERT(VARCHAR(4000), @ReturnString)\n"]], ['SQL identify whether a word in nvarchar variable is listed in lookup table'], 3, 1], [(26607450, 0), [['1.Flashback by SCN'], ['2.Flashback by TIMESTAMP']], [[' SELECT column_list\nFROM table_name\nAS OF SCN scn_number;\n']], ['Roll back Update or delete data Through Flashback query'], 8, 1], [(26607450, 1), [['2.Flashback by TIMESTAMP'], ['To get current_scn and systimestamp, query :']], [[" SELECT column_list\nFROM table_name\nAS OF TIMESTAMP TO_TIMESTAMP('the timestamp value');\n"]], ['Roll back Update or delete data Through Flashback query'], 8, 1], [(26607450, 2), [['To get current_scn and systimestamp, query :'], ['To flashback the table to the old scn, use  FLASHBACK TABLE..TO SCN  clause.']], [[' SELECT current_scn, SYSTIMESTAMP\nFROM v$database;\n']], ['Roll back Update or delete data Through Flashback query'], 8, 0], [(26607450, 4), [['I have four rows in the table .'], ['Row movement is required.']], [[' SQL> ALTER TABLE string_ex ENABLE ROW MOVEMENT;\n\nTable altered.\n\nSQL>\n']], ['Roll back Update or delete data Through Flashback query'], 8, 0], [(26607450, 5), [['Row movement is required.'], ['I deleted a row now and committed the changes.']], [[' SQL> DELETE FROM string_ex WHERE ROWNUM =1;\n\n1 row deleted.\n\nSQL>\nSQL> COMMIT;\n\nCommit complete.\n\nSQL>\nSQL> SELECT * FROM string_ex;\n\nSL_PS_CODE\n---------------\nAR14SFT0018\nAR14SFT0019\nAR14SFT0062\n']], ['Roll back Update or delete data Through Flashback query'], 8, 0], [(26607450, 7), [['Flashback is complete'], ['I now have my table to old state and the row is back']], [[' SQL> SELECT * FROM string_ex;\n\nSL_PS_CODE\n---------------\nAR14ASM0002\nAR14SFT0018\nAR14SFT0019\nAR14SFT0062\n\nSQL>\n']], ['Roll back Update or delete data Through Flashback query'], 8, 0], [(26682614, 0), [['EXISTS OPERATOR'], ['LEFT JOIN']], [[' SELECT *\nFROM updated u\nWHERE NOT EXISTS (SELECT 1\n                  FROM accounts \n                  WHERE `name` = u_s_customer)\n']], ['Finding Non Matches in SQL Statement'], 3, 1], [(26682614, 1), [['LEFT JOIN'], ['NOT IN']], [[' SELECT *\nFROM updated LEFT JOIN accounts \nON `name` = u_s_customer\nWHERE name IS NULL\n']], ['Finding Non Matches in SQL Statement'], 3, 1], [(26682614, 2), [['NOT IN'], ['-10000']], [[' SELECT *\nFROM updated \nWHERE name NOT IN (SELECT u_s_customer\n                   FROM accounts )\n']], ['Finding Non Matches in SQL Statement'], 3, 1], [(26711455, 0), [['Query:'], ['Desired result with current day = 1:']], [[' SELECT * FROM (\n    SELECT\n    oh.*\n    FROM\n    opening_hours oh\n    ORDER BY restaurant_id, \n    `day` + IF(`day` < $current_day, 7, 0)\n) sq\nGROUP BY restaurant_id;\n']], ['SQL "First relevant day"'], 3, 1], [(26718516, 0), [["Like in the comment, it's impossible to setup such relationship with builtin methods of Eloquent. Here's how you can get the  files  using a bit of trickery:"], ['Then:']], [[" Person::with(['events.files' => function ($q) use (&$files) {\n  $files = $q->get()->unique();\n}])->find($id);\n"]], ['HasMany with belongsToMany relationship'], 3, 0], [(26718516, 1), [['Then:'], ['Mind that this code will run additional query to get the files, so in the example above:']], [[' $files; // collection of files related to the Person through collection of his events\n']], ['HasMany with belongsToMany relationship'], 3, 0], [(26718516, 2), [['Mind that this code will run additional query to get the files, so in the example above:'], ['-10000']], [[' 1 fetch Person\n2 fetch Events related to Person\n3 fetch Files related to all the Events\n4 again fetch Files related to all the Events\n']], ['HasMany with belongsToMany relationship'], 3, 0], [(26728011, 0), [['It is easy to delete data from a specific partition: this statement clears down all the data for February 2012:'], ['A quicker method is to truncate the partition:']], [[' delete from t23 partition (feb2012);\n']], ['Oracle how to delete from a table except few partitions data'], 5, 1], [(26728011, 1), [['A quicker method is to truncate the partition:'], ['If we never again want to store data for that month we can drop the partition:']], [[' alter table t23 truncate partition feb2012;\n']], ['Oracle how to delete from a table except few partitions data'], 5, 1], [(26728011, 2), [['If we never again want to store data for that month we can drop the partition:'], ['As you want to remove most of the data but retain the partition structure truncating the partitions is the best option.  Remember to invalidate any integrity constraints (and to reinstate them afterwards).']], [[' alter table t23 drop partition feb2012;\n']], ['Oracle how to delete from a table except few partitions data'], 5, 1], [(26728011, 3), [['As you want to remove most of the data but retain the partition structure truncating the partitions is the best option.  Remember to invalidate any integrity constraints (and to reinstate them afterwards).'], ['Afterwards run this query to see which partitions you should rebuild:']], [[" declare\n    stmt varchar2(32767);\nbegin\n    for lrec in ( select partition_name\n                  from user_tab_partitions\n                  where table_name = 'T23'\n                  and partition_name like '%2012'\n                )\n    loop\n        stmt := 'alter table t23 truncate partition '\n                    || lrec.partition_name\n                  ;\n        dbms_output.put_line(stmt);\n        execute immediate stmt;\n    end loop;\nend;\n/\n"]], ['Oracle how to delete from a table except few partitions data'], 5, 1], [(26728011, 4), [['Afterwards run this query to see which partitions you should rebuild:'], ['You can automate the rebuild statements in a similar fashion.']], [[" select ip.index_name, ip.partition_name, ip.status \nfrom user_indexes i\n     join user_ind_partitions ip\n      on  ip.index_name = i.index_name\nwhere i.table_name = 'T23'\nand ip.status = 'UNUSABLE';\n"]], ['Oracle how to delete from a table except few partitions data'], 5, 0], [(26729494, 0), [['Using only regexp_replace,'], ['Pattern:']], [[" with string_table(slno, old_string)\nas (\n        select 1, '1,2,3,4,5,6' from dual union all\n        select 2, '1,2,3,4,5' from dual union all\n        select 3, 'a,b,c,d,e,f' from dual union all\n        select 4, 'a,b,c,d,e' from dual\n)\nselect\n        slno,\n        old_string,\n        regexp_replace(old_string,'([^,]+),([^,]+)','\\2,\\1')    new_string\nfrom \n        string_table;\n\n      SLNO  OLD_STRING   NEW_STRING\n----------  -----------  ------------------------------------------------------------\n         1  1,2,3,4,5,6  2,1,4,3,6,5\n         2  1,2,3,4,5    2,1,4,3,5\n         3  a,b,c,d,e,f  b,a,d,c,f,e\n         4  a,b,c,d,e    b,a,d,c,e\n"]], ['swapping comma separated values in oracle'], 3, 1], [(26729494, 1), [['Pattern:'], ['Replace_String:']], [[' ([^,]+) -- any string without a comma. Enclosed in brackets to form first capture group.\n,       -- a comma\n([^,]+) -- any string without a comma. Enclosed in brackets to form second capture group.\n']], ['swapping comma separated values in oracle'], 3, 0], [(26729494, 2), [['Replace_String:'], ['So, this replaces the matched pattern with the same string, but interchanging the position.']], [[' \\2  -- the second capture group from the Pattern\n,   -- a comma\n\\1  -- the first capture group from the Pattern\n']], ['swapping comma separated values in oracle'], 3, 0], [(26804962, 0), [['Assuming the values in the two columns are distinct for a given  gid , you can do this with a  full outer join  and  group by :'], ['You could also express this using  not exists :']], [[' select coalesce(t.gid, t2.gid) as gid,\n       (case when count(t.gid) = count(*) and count(t2.gid) = count(*)\n             then 1\n             else 0\n        end)\nfrom invertica t full outer join\n     invertica t2\n     on t.gid = t2.gid and t.a = t2.b\ngroup by coalesce(t.gid, t2.gid);\n']], ['vertica check if unique elements for each group from two columns are identical'], 2, 1], [(26804962, 1), [['You could also express this using  not exists :'], ['-10000']], [[' select t.gid, max(val)\nfrom (select t.gid,\n             (case when not exists (select 1 from invertica t2 where t.gid = t2.gid and t.a = t2.b)\n                   then 0\n                   when not exists (select 1 from invertica t2 where t.gid = t2.gid and t.b = t2.a)\n                   then 0\n                   else 1\n              end) as val\n      from invertica t\n     ) t\ngroup by t.gid;\n']], ['vertica check if unique elements for each group from two columns are identical'], 2, 1], [(26849766, 0), [['Using  CASE Statement  you can find the largest value among the columns.'], ['If you are using  SQL SERVER 2008 or later versions  then try this']], [[' SELECT ID,\n       amt_1,\n       amt_2,\n       amt_3,\n       amt_4,\n       CASE\n         WHEN amt_1 >= amt_2 AND amt_1 >= amt_3 AND amt_1 >= amt_4 THEN amt_1\n         WHEN amt_2 >= amt_1 AND amt_2 >= amt_3 AND amt_2 >= amt_4 THEN amt_2\n         WHEN amt_3 >= amt_1 AND amt_3 >= amt_2 AND amt_3 >= amt_4 THEN amt_3\n         WHEN amt_4 >= amt_1 AND amt_4 >= amt_2 AND amt_4 >= amt_3 THEN amt_4\n       END NEW_COL\nFROM   Tablename \n']], ['Need the greatest value in new column'], 2, 1], [(26849766, 1), [['If you are using  SQL SERVER 2008 or later versions  then try this'], ['-10000']], [[' SELECT ID,amt_1,amt_2,amt_3,amt_4,\n  (SELECT Max(amt) FROM (VALUES (amt_1), (amt_2), (amt_3),(amt_4)) AS value(amt))  NEW_COL\nFROM tablename\n']], ['Need the greatest value in new column'], 2, 1], [(26862578, 1), [['SCRIPT which creates some testing data:'], ['-10000']], [[" create table tblCategories(cat_id int, cat_name varchar(20));\n\ncreate table tblCategoryHierarchy(cat_parent_id int, cat_child_id int);\n\ninsert into tblCategories(cat_id, cat_name) values ( 1, 'cat 1');\ninsert into tblCategories(cat_id, cat_name) values ( 2, 'cat 2');\ninsert into tblCategories(cat_id, cat_name) values ( 3, 'cat 3');\ninsert into tblCategories(cat_id, cat_name) values ( 4, 'cat 4');\ninsert into tblCategories(cat_id, cat_name) values ( 5, 'cat 5');\n\ninsert into tblCategories(cat_id, cat_name) values ( 6, 'cat 6');\ninsert into tblCategories(cat_id, cat_name) values ( 7, 'cat 7');\ninsert into tblCategories(cat_id, cat_name) values ( 8, 'cat 8');\ninsert into tblCategories(cat_id, cat_name) values ( 9, 'cat 9');\ninsert into tblCategories(cat_id, cat_name) values (10, 'cat 10');\n\ninsert into tblCategories(cat_id, cat_name) values (11, 'cat 11');\ninsert into tblCategories(cat_id, cat_name) values (12, 'cat 12');\n\ninsert into tblCategoryHierarchy (cat_parent_id, cat_child_id) values ( 1, 2);\ninsert into tblCategoryHierarchy (cat_parent_id, cat_child_id) values ( 1, 3);\n\ninsert into tblCategoryHierarchy (cat_parent_id, cat_child_id) values ( 4, 6);\ninsert into tblCategoryHierarchy (cat_parent_id, cat_child_id) values ( 4, 8);\n\ninsert into tblCategoryHierarchy (cat_parent_id, cat_child_id) values ( 8, 10);\ninsert into tblCategoryHierarchy (cat_parent_id, cat_child_id) values ( 8, 11);\n\ninsert into tblCategoryHierarchy (cat_parent_id, cat_child_id) values (11, 12);\n\ninsert into tblCategoryHierarchy (cat_parent_id, cat_child_id) values ( 5, 7);\ninsert into tblCategoryHierarchy (cat_parent_id, cat_child_id) values ( 5, 9);\n"]], ['SQL Server Return All Sub Categories'], 2, 0], [(26906460, 0), [['Try this,'], ['If you want the marks separately use this']], [[" SELECT Sum(B.English) Total\nFROM   #Table_1 A\nJOIN   #Table_2 B ON A.Name = B.Name\nWHERE  Grade = 'AA' \n"]], ['Extracting Data from two tables in SQL'], 2, 1], [(26906460, 1), [['If you want the marks separately use this'], ['-10000']], [[" SELECT A.Name,\n       Sum(B.English) Total\nFROM   #Table_1 A\nJOIN   #Table_2 B ON A.Name = B.Name\nWHERE  Grade = 'AA'\nGROUP  BY A.Name \n"]], ['Extracting Data from two tables in SQL'], 2, 1], [(26929769, 0), [["If you can't change the format of the data in the file, and can't manipulate the file before loading it, you could replace a specific EDT value with the region value  US/Eastern  (or any suitable value like  America/New_York ) with  an SQL operator :"], ['When your sample data file is loaded the table contains:']], [[' "DOC_DATE_ADDED" TIMESTAMP WITH TIME ZONE "DY MON DD HH24:MI:SS TZR YYYY"\n  "REPLACE(:DOC_DATE_ADDED, \'EDT\', \'US/Eastern\')"  \n']], ['EDT and EST timestamp sqlldr data load in oracle'], 5, 1], [(26929769, 1), [['When your sample data file is loaded the table contains:'], ['... so you preserve the EST/EDT split; though the  TZR  shows  US/EASTERN  and  EST  - so it might be better to change the  EST  value as well, with a nested  REPLACE  or with:']], [[" select to_char(doc_date_added, 'YYYY-MM-DD HH24:MI:SS TZD') as TZD,\n   to_char(doc_date_added, 'YYYY-MM-DD HH24:MI:SS TZR') as TZR\nfrom my_table;\n\nTZD                     TZR                          \n----------------------- ------------------------------\n2013-03-07 14:27:14 EST 2013-03-07 14:27:14 EST        \n2013-03-07 14:27:27 EST 2013-03-07 14:27:27 EST        \n2013-04-09 18:20:54 EDT 2013-04-09 18:20:54 US/EASTERN \n2013-04-09 18:24:26 EDT 2013-04-09 18:24:26 US/EASTERN \n"]], ['EDT and EST timestamp sqlldr data load in oracle'], 5, 0], [(26929769, 2), [['... so you preserve the EST/EDT split; though the  TZR  shows  US/EASTERN  and  EST  - so it might be better to change the  EST  value as well, with a nested  REPLACE  or with:'], ["Or if all your values are always EST/EDT, you could do the timestamp conversion explicitly and just cut out the actual string you're given:"]], [[' "DOC_DATE_ADDED" TIMESTAMP WITH TIME ZONE "DY MON DD HH24:MI:SS TZR YYYY"\n  "REGEXP_REPLACE(:DOC_DATE_ADDED, \'E[SD]T\', \'US/Eastern\')"\n']], ['EDT and EST timestamp sqlldr data load in oracle'], 5, 1], [(26929769, 3), [["Or if all your values are always EST/EDT, you could do the timestamp conversion explicitly and just cut out the actual string you're given:"], ['Which loads your data as:']], [[' "DOC_DATE_ADDED" CHAR "FROM_TZ(TO_TIMESTAMP(SUBSTR(:DOC_DATE_ADDED, 1, 19)\n  || SUBSTR(:DOC_DATE_ADDED, 25, 29), \'DY MON DD HH24:MI:SS YYYY\'), \'US/Eastern\')"\n']], ['EDT and EST timestamp sqlldr data load in oracle'], 5, 1], [(26929769, 4), [['Which loads your data as:'], ["The danger with that is that if you ever do get a value in a different time zone it'll silently be recorded against the wrong region, whereas the first version will either process it successfully or reject it, depending on whether it's recognised (i.e. in Wernfried's first list)."]], [[' TZD                     TZR                          \n----------------------- ------------------------------\n2013-03-07 14:27:14 EST 2013-03-07 14:27:14 US/EASTERN \n2013-03-07 14:27:27 EST 2013-03-07 14:27:27 US/EASTERN \n2013-04-09 18:20:54 EDT 2013-04-09 18:20:54 US/EASTERN \n2013-04-09 18:24:26 EDT 2013-04-09 18:24:26 US/EASTERN \n']], ['EDT and EST timestamp sqlldr data load in oracle'], 5, 0], [(26942697, 0), [['-10000'], ['returns']], [[" select arrival_time,\n       maketime(mod(HOUR(date_add(arrival_time, INTERVAL 1 HOUR)), 24),\n                mod(minute(date_add(arrival_time, INTERVAL 2 MINUTE)), 60),\n                mod(second(date_add(arrival_time, INTERVAL 2 SECOND)), 60)) sooner_or_later,\n       TIME((ADDTIME(TIME('23:59:59'), TIME('01:02:02')))%(TIME('24:00:00'))) or_rather_so\nfrom table1;\n"]], ["how to add hours ,minutes or seconds in 'TIME' Datatype in mysql"], 2, 1], [(26942697, 1), [['returns'], ['Second column pushing bits. Last column doing proper arithmetic - borrowed from  ADDTIME() return 24 hour time']], [[' |                   ARRIVAL_TIME |                SOONER_OR_LATER |                   OR_RATHER_SO |\n|--------------------------------|--------------------------------|--------------------------------|\n| January, 01 1970 23:59:59+0000 | January, 01 1970 00:01:01+0000 | January, 01 1970 01:02:01+0000 |\n']], ["how to add hours ,minutes or seconds in 'TIME' Datatype in mysql"], 2, 0], [(26945528, 0), [['Since you have a computed column you have to specify the columns you insert into:'], ['a  select * from db  after the insert above would give you:']], [[' insert into db (col, col2) values (10, 20);\n']], ['insert into derived column with in same table'], 2, 1], [(26945528, 1), [['a  select * from db  after the insert above would give you:'], ['-10000']], [[' | COL | COL2 | CAL3 |\n|-----|------|------|\n|  10 |   20 |   30 |\n']], ['insert into derived column with in same table'], 2, 0], [(26965377, 1), [['Sgeddes is correct.  If you consistently want the second name and can have three or four parts, then  reverse()  can be used:'], ['(It seems that one of the values does have four parts; I originally read it as "Delete From TableName".)']], [[" select reverse(parsename(replace(reverse(val), ' ', '.'), 2))\n"]], ['sql server get value between spaces in one column'], 2, 1], [(27004031, 0), [['You could try doing something like this.'], ['or ']], [['         ComboBox1.Text = DataGridView1.SelectedRows.Item(0).Cells(0).FormattedValue + " " + DataGridView1.SelectedRows.Item(0).Cells(1).FormattedValue\n']], ['Selected item from Datagridview to Show in ComboBox'], 3, 1], [(27004031, 1), [['or '], ['However if your drop down list box has an ID in the value you and you have it in the Grid, you set the ']], [['         ComboBox1.Text = DataGridView1.SelectedRows.Item(0).Cells(0).FormattedValue + " " + _\n                         DataGridView1.SelectedRows.Item(0).Cells(1).FormattedValue\n']], ['Selected item from Datagridview to Show in ComboBox'], 3, 1], [(27055911, 0), [['I would create a function to return the difference since there is no datediff in oracle. Something like this:'], ['Then I would change you original query to:']], [[" CREATE OR REPLACE FUNCTION datediff (options   IN VARCHAR2,\n                                     p_d1      IN DATE,\n                                     p_d2      IN DATE)\n   RETURN NUMBER\nAS\n   l_result   NUMBER;\nBEGIN\n   SELECT   (p_d2 - p_d1)\n          * DECODE (UPPER (options),\n                    'SS', 24 * 60 * 60,\n                    'MI', 24 * 60,\n                    'HH', 24,\n                    NULL)\n     INTO l_result\n     FROM DUAL;\n\n   RETURN l_result;\nEND;\n"]], ['Using datediff in oracle'], 2, 0], [(27055911, 1), [['Then I would change you original query to:'], ['-10000']], [[" Select * from myTable where datediff ('ss', Receive_Date, Update_Date) >= 60\n"]], ['Using datediff in oracle'], 2, 0], [(27107093, 0), [['Consider the following. How does this result differ from the desired result?'], ["OK. I'm going to take a wild stab in the dark here..."]], [[' +-----+------------+-------------+----------+------------+--------------+-----+-------+-----+--------+\n| uid | name       | description | url      | picurl     | mapurl       | pid | price | rid | rating |\n+-----+------------+-------------+----------+------------+--------------+-----+-------+-----+--------+\n|   5 | Havana Pub |             |          |            |              |  35 |    74 |  11 |      5 |\n|   3 | Hos Naboen |             |          |            |              |  33 |    74 |   9 |      5 |\n|   2 | Javel      | Musikk      | javel.no | pic.jave.. | map.javel.no |  38 |    88 |   8 |      5 |\n|   1 | Kick       | Yay         | kick.no  | http://p.. | map.kick.no  |  31 |    74 |  15 |      1 |\n|   6 | Leopold    |             |          |            |              |  36 |    74 |  12 |      5 |\n|   4 | Victoria   |             |          |            |              |  37 |    75 |  10 |      5 |\n+-----+------------+-------------+----------+------------+--------------+-----+-------+-----+--------+\n']], ['Select average from join MYSQL'], 2, 0], [(27112737, 0), [["Here's how I'd approach it (though using PowerShell rather than SQL):"], ['NB: to ignore the protocol, simply remove it from the string using a similar technique to our split on spaces; i.e. a regex, this time going with replace instead of split.']], [[' clear\npushd c:\\myPath\\myFolder\\\n\n#read in the contents of the files\n$file1 = get-content("file1.txt") \n$file2 = get-content("file2.txt")\n\n#loop through each row of the whitespace separated file\n$file1 = $file1 | %{\n    #for each line, split on whitespace characters, returning the results back in a single column\n    $_ -split "\\s" | %{$_}\n}\n#compare the two files for matching data & output this info\ncompare-object $file1 $file2 -IncludeEqual -ExcludeDifferent | ft -AutoSize \n\npopd\n']], ['How do I find one matching strings in two txt files'], 3, 1], [(27112737, 2), [['However, should you prefer a SQL solution, try this (MS SQL Server):'], ['-10000']], [[" create table f1(url nvarchar(1024))\ncreate table f2(url nvarchar(1024))\n\nBULK INSERT f1\nFROM 'C:\\myPath\\myFolder\\file1.txt' \nWITH ( ROWTERMINATOR =' ', FIRSTROW = 1 )\n\nBULK INSERT f2\nFROM 'C:\\myPath\\myFolder\\file2.txt' \nWITH ( FIRSTROW = 1 )\ngo\n\ndelete from f1 where coalesce(rtrim(url),'') = ''\ndelete from f2 where coalesce(rtrim(url),'') = ''\n\nselect x.url, x.x, y.y\nfrom\n(\n    select SUBSTRING(url,patindex('%://%',url)+3, len(url)) x\n    , url \n    from f1 \n) x\ninner join \n(\n    select SUBSTRING(url,patindex('%://%',url)+3, len(url)) y\n    , url \n    from f2 \n) y \non y.y = x.x\n"]], ['How do I find one matching strings in two txt files'], 3, 1], [(27122437, 0), [['Try this:'], ['Conditions testing for ROWNUM values greater than a positive integer\n  are always false. For example, this query returns no rows:']], [[' SELECT xml_to_string(XMLRECORD) FROM (select t.*, rownum rw from TABLENAME t) \nWHERE  rw>10000 AND rw<=20000\n']], ['Oracle Row fetch within limit'], 2, 1], [(27122437, 1), [['Conditions testing for ROWNUM values greater than a positive integer\n  are always false. For example, this query returns no rows:'], ['-10000']], [[' SELECT *\nFROM employees\nWHERE ROWNUM > 1;\n']], ['Oracle Row fetch within limit'], 2, 0], [(27162998, 0), [['The "highest" 20 entries suggests a sort.  You would do something like this:'], ['If you are using Oracle 12g or more recent, you can use the  fetch first  clause instead:']], [[' select t.*\nfrom (select t.*\n      from table t\n      order by highestcol desc\n     ) t\nwhere rownum <= 20;\n']], ['how to display only 20 items of the result in oracle sql?'], 2, 1], [(27166043, 0), [['You can do this by joining with a number table. This query uses the spt_values table and should work:'], ['Note that this table only has a sequence of numbers  0-2047 so if your BatchNo can be higher you need another source for the query (could be another table or a recursive cte); something like this would work:']], [[" ;with cte as (\n    select category , min(batchno) min_batch, max(batchno) max_batch\n    from #tmp\n    group by category\n)\nselect number, category\nfrom master..spt_values\ncross join cte\nwhere type = 'p'\n  and number > min_batch\n  and number < max_batch\ngroup by category, number\n"]], ['Find the missing number group by category'], 2, 1], [(27166043, 1), [['Note that this table only has a sequence of numbers  0-2047 so if your BatchNo can be higher you need another source for the query (could be another table or a recursive cte); something like this would work:'], ['-10000']], [[' ;with \n    cte (category, min_batch, max_batch) as (\n       select category , min(batchno), max(batchno)\n       from #tmp\n       group by category\n    ), \n    numbers (number, max_number) as (\n       select 1 as number, (select MAX(batchno) from #tmp) max_number\n       union all\n       select number + 1, max_number\n       from numbers\n       where number < max_number\n    )\n\nselect number, category\nfrom numbers cross join cte\nwhere number > min_batch\n  and number < max_batch\ngroup by category, number\noption (maxrecursion 0)\n']], ['Find the missing number group by category'], 2, 1], [(27218389, 0), [['I did this in my model:'], ['Underneath I made it a 2dsphere index.']], [[' loc :  { type: {type:String}, coordinates: [Number]},\n']], ['Location in mongoose, mongoDB'], 3, 0], [(27218389, 1), [['Underneath I made it a 2dsphere index.'], ['And to add data to it:']], [[" eventSchema.index({loc: '2dsphere'});\n"]], ['Location in mongoose, mongoDB'], 3, 0], [(27218389, 2), [['And to add data to it:'], ['-10000']], [[' loc: { type: "Point", coordinates: [ longitude, latitude ] },\n']], ['Location in mongoose, mongoDB'], 3, 0], [(27251701, 0), [["Before using dynamic sql, I'd first write a static version of the query to get the correct logic. Since you are using SQL Server 2012, you can use CROSS APPLY and VALUES to unpivot the data:"], ['See  Demo .  Your data now looks like this:']], [[" select \n  m.docId,\n  m.Date,\n  m.column1,\n  m.column2,\n  c.value\nfrom dbo.mappingTest m\ncross apply\n(\n  values\n    ('Column3', Column3),\n    ('Column4', Column4),\n    ('Column5', convert(varchar(10), Column5, 120))\n) c (Col, Value)\nwhere c.value is not null\n"]], ['TSQL - row values to column headings including further column values'], 5, 0], [(27251701, 1), [['See  Demo .  Your data now looks like this:'], ["You have multiple rows for each  DocID  with the values you'll eventually want under the  Column2  items in a single column.  Now you can apply the PIVOT function:"]], [[' |      DOCID |       DATE |  COLUMN1 |      COLUMN2 |   VALUE |\n|------------|------------|----------|--------------|---------|\n| ABC000123  | 2014-04-11 | approval | project name |     ABC |\n| ABC000123  | 2014-04-11 | approval | article name |  Art 01 |\n| ABC000123  | 2014-04-11 | approval |     customer |    ACME |\n| ABC000123  | 2014-04-11 | approval |   department | Dept. A |\n| ABC000123  | 2014-04-11 | approval |        plant |  Europe |\n| ABC000123  | 2014-04-11 | approval |    sop month |      10 |\n']], ['TSQL - row values to column headings including further column values'], 5, 0], [(27251701, 4), [['See  SQL Fiddle with Demo . Both versions will give a result of:'], ['-10000']], [[' |      DOCID |       DATE |  COLUMN1 | ARTICLE NAME | BUDGET | CUSTOMER | DEPARTMENT | EOP MONTH | EOP YEAR |  PLANT | PROJECT NAME | SAVINGS | SOP MONTH | SOP YEAR |\n|------------|------------|----------|--------------|--------|----------|------------|-----------|----------|--------|--------------|---------|-----------|----------|\n| ABC000123  | 2014-04-11 | approval |       Art 01 |  17890 |     ACME |    Dept. A |         0 |    21019 | Europe |          ABC |  (null) |        10 |     2014 |\n| ABC000123  | 2014-04-11 |  project |       (null) | (null) |   (null) |     (null) |    (null) |   (null) | (null) |       (null) |  -0,020 |    (null) |   (null) |\n| DEF000123  | 2014-05-11 | approval |       Art 02 | (null) |   (null) |     (null) |    (null) |   (null) | (null) |          DEF |  (null) |    (null) |   (null) |\n']], ['TSQL - row values to column headings including further column values'], 5, 0], [(27304683, 0), [['The error message you get when you try to run the first query is a pretty big clue:'], ['From your revised question, the first thing that jumps out at me is that the  SAMPLE  clause must be in the  FROM  clause, between the table name and any alias. I was able to sample in a query with joins like this:']], [[' ORA-01446: cannot select ROWID from, or sample, a view with DISTINCT, GROUP BY, etc.\n']], ['Sample Oracle SQL Randomly - in absense of ROWID'], 4, 0], [(27304683, 2), [["Regarding your actual query, I tried using the tables (again, actually views) that you're trying to sample one at a time:"], ['The following query should work to manually create a random sample, using  DBMS_RANDOM .']], [[' select * from all_constraints sample(10)\n\nORA-01445: cannot select ROWID from, or sample, a join view without a key-preserved table\n\nselect * from all_cons_columns sample(10)\n\nORA-01445: cannot select ROWID from, or sample, a join view without a key-preserved table\n']], ['Sample Oracle SQL Randomly - in absense of ROWID'], 4, 0], [(27304683, 3), [['The following query should work to manually create a random sample, using  DBMS_RANDOM .'], ['-10000']], [[' SELECT   *\nFROM     (SELECT cols.table_name,\n                 cols.column_name,\n                 cols.position,\n                 cons.status,\n                 cons.owner,\n                 cons.constraint_type,\n                 DBMS_RANDOM.VALUE rnd\n          FROM   all_constraints cons\n                 JOIN all_cons_columns cols\n                    ON     cons.constraint_name = cols.constraint_name\n                       AND cons.owner = cols.owner)\nWHERE    rnd < .1\nORDER BY table_name, position\n']], ['Sample Oracle SQL Randomly - in absense of ROWID'], 4, 1], [(27309001, 0), [['Try this:'], ['OR']], [[' SELECT id, IF(integer_val = 10, 100, 0) AS new_val \nFROM my_table;\n']], ['SQL statement equivalent to ternary operator'], 2, 1], [(27309001, 1), [['OR'], ['-10000']], [[' SELECT id, (CASE WHEN integer_val = 10 THEN 100 ELSE 0 END) AS new_val \nFROM my_table;\n']], ['SQL statement equivalent to ternary operator'], 2, 1], [(27315388, 0), [["Your query could be written like this, if it didn't have to match ARUNKUMAR with ARUN KUMAR. "], ["To deal with the case where the spaces don't match between the two names, you could eliminate the spaces entirely, from both names.  That would then look something like this."]], [[" SELECT c.name, b.name \nFROM   S1DM c JOIN G1DM b \nON  c.name IN ( \n    TRIM( REPLACE(b.abbrevi, '.', ' ') || ' ' || b.name), \n    TRIM( b.name || ' ' || REPLACE(b.abbrevi, '.', ' ')))\nAND c.dob = b.dob\n"]], ['how to match strings from different tables considering the spaces,hyphons,dot etc in oracle'], 2, 1], [(27315388, 1), [["To deal with the case where the spaces don't match between the two names, you could eliminate the spaces entirely, from both names.  That would then look something like this."], ['-10000']], [[" SELECT c.name, b.name \nFROM   S1DM c JOIN G1DM b \nON  REPLACE(c.name, ' ', '') IN ( \n    REPLACE(b.abbrevi, '.', '') || REPLACE(b.name, ' ', ''), \n    REPLACE(b.name, ' ', '') || REPLACE(b.abbrevi, '.', ''))\nAND c.dob = b.dob\n"]], ['how to match strings from different tables considering the spaces,hyphons,dot etc in oracle'], 2, 1], [(27326723, 0), [['The most elegant way would be to use the  USING  clause in an explicit join condition:'], ['To get the average  epatmpg  for the selected rows:']], [[' SELECT houseid, v.vehid, v.epatmpg, d.houseid, d.trpmiles\nFROM   vehv2pub v\nJOIN   dayv2pub d <b>USING (houseid)</b>\nWHERE  v.vehid >= 1\nAND    d.trpmiles < 15;']], ['Remove duplicate column after SQL query'], 2, 1], [(27326723, 1), [['To get the average  epatmpg  for the selected rows:'], ['If there are multiple matches in  dayv2pub , the derived table can hold multiple instances of each row in  vehv2pub  after the join.  avg()  is based on the derived table.']], [[' SELECT avg(v.epatmpg) AS avg_epatmpg\nFROM   vehv2pub v\nJOIN   dayv2pub d USING (houseid)\nWHERE  v.vehid >= 1\nAND    d.trpmiles < 15;\n']], ['Remove duplicate column after SQL query'], 2, 0], [(27379264, 0), [['Does a simple inner join to the same table not do what you need?'], ['This would give you the "Parent->Child" row for each match, like so:']], [[' SELECT table1.Parent as Row, table1.Child as OtherRow\nFROM table table1\n    inner join table table2\n    ON table1.Parent = table2.Child\n    AND table1.Child = table2.Parent\n']], ['Looking for infinite relation in SQL'], 4, 1], [(27379264, 1), [['This would give you the "Parent->Child" row for each match, like so:'], ['eg']], [[' Row | OtherRow\n----|----------\n  1 |  2\n']], ['Looking for infinite relation in SQL'], 4, 0], [(27379264, 2), [['eg'], ['This would give you']], [[' SELECT table.Parent as Parent, table.Child as Child\nFROM table\n    INNER JOIN (that query) query\n    ON (table.Parent = query.Row AND table.Child = query.OtherRow)\n        OR (table.Parent = query.OtherRow AND table.Child = query.Row)\n']], ['Looking for infinite relation in SQL'], 4, 1], [(27379264, 3), [['This would give you'], ['-10000']], [[' Parent | Child\n-------|------\n   1   |   2\n   2   |   1\n']], ['Looking for infinite relation in SQL'], 4, 0], [(27381225, 0), [['This will do what you want:'], ['Before:']], [['     UPDATE Table1, (SELECT TOP 1 Field1 As F FROM Table1 WHERE Field1 Is Not Null)\n    SET Field1 = F\n    WHERE Field1 Is Null\n']], ['Changing the values in a column with a value from the same column'], 3, 1], [(27381225, 1), [['Before:'], ['After:']], [['     Field1  Field2  \n            apple \n    pet     cat    \n            dog    \n    color   red    \n            blue     \n']], ['Changing the values in a column with a value from the same column'], 3, 0], [(27381225, 2), [['After:'], ['-10000']], [['     Field1  Field2  \n    pet     apple \n    pet     cat    \n    pet     dog    \n    color   red    \n    pet     blue     \n']], ['Changing the values in a column with a value from the same column'], 3, 0], [(27399755, 0), [['First, create yourself a simple  schema-level  collection type'], ['then a function']], [[' create or replace type arr_integers as table of integer;\n']], ['hierarchy records'], 5, 0], [(27399755, 1), [['then a function'], ['-10000']], [[' create or replace\nfunction f_parent_child_xml\n    ( i_parent_id                   in t_hierarchy.parent_id%type\n    , i_visited_nodes               in arr_integers default null )\n    return xmltype\nis\n    l_result                        xmltype;\n\n    l_contained_by_xml              xmltype;\n    l_contained_by#                 integer;\n    l_contains_xml                  xmltype;\n    l_contains#                     integer;\n\n    l_new_visited_nodes             arr_integers;\nbegin\n    if i_visited_nodes is null then\n        select\n            xmlelement("view_hierarchy",\n                xmlattributes(\'com.hierarchy\' as "chm"),\n                xmlelement("link",\n                    f_parent_child_xml(i_parent_id, arr_integers())\n            ))\n        into l_result\n        from dual;\n    else\n        select parent_id\n        bulk collect into l_new_visited_nodes\n        from t_hierarchy\n        where i_parent_id in (child_id, parent_id)\n        union\n        select child_id\n        from t_hierarchy\n        where i_parent_id in (child_id, parent_id)\n        union\n        select column_value\n        from table(i_visited_nodes);\n\n        select\n            xmlagg(\n                f_parent_child_xml(H1.parent_id, l_new_visited_nodes)\n            ) as xml$,\n            count(1) as rows#\n        into l_contained_by_xml, l_contained_by#\n        from t_hierarchy H1\n        where H1.child_id = i_parent_id\n            and not exists (\n                select 1\n                from table(i_visited_nodes) X\n                where X.column_value = H1.parent_id\n            )\n        ;\n\n        select\n            xmlagg(\n                f_parent_child_xml(H2.child_id, l_new_visited_nodes)\n            ) as xml$,\n            count(1) as rows#\n        into l_contains_xml, l_contains#\n        from t_hierarchy H2\n        where H2.parent_id = i_parent_id\n            and not exists (\n                select 1\n                from table(i_visited_nodes) X\n                where X.column_value = H2.child_id\n            );\n\n        select\n            xmlelement("ID",\n                xmlattributes(i_parent_id as "refno"),\n                case when l_contained_by# > 0 then xmlelement("contained_by", l_contained_by_xml) end,\n                case when l_contains# > 0 then xmlelement("contains", l_contains_xml) end\n            )\n        into l_result\n        from dual;\n    end if;\n\n    return l_result;\nend;\n']], ['hierarchy records'], 5, 0], [(27399755, 2), [['-10000'], ['or']], [[' select f_parent_child_xml(101)\nfrom dual;\n']], ['hierarchy records'], 5, 0], [(27399755, 3), [['or'], ['yields (after manual reformatting):']], [[' select f_parent_child_xml(101).getStringVal()\nfrom dual;\n']], ['hierarchy records'], 5, 0], [(27399755, 4), [['yields (after manual reformatting):'], ['Enjoy!']], [[' <view_hierarchy chm="com.hierarchy">\n    <link>\n        <ID refno="101">\n            <contained_by>\n                <ID refno="100">\n                    <contained_by>\n                        <ID refno="1000"></ID>\n                    </contained_by>\n                    <contains>\n                        <ID refno="102">\n                            <contains>\n                                <ID refno="1021"></ID>\n                                <ID refno="1020"></ID>\n                            </contains>\n                        </ID>\n                    </contains>\n                </ID>\n                <ID refno="200"></ID>\n            </contained_by>\n            <contains>\n                <ID refno="1011"></ID>\n                <ID refno="1010"></ID>\n            </contains>\n        </ID>\n    </link>\n</view_hierarchy>\n']], ['hierarchy records'], 5, 0], [(27417566, 0), [['his will do for you using CTE'], ['Or you can do a direct Update']], [[' WITH crows AS (\n     SELECT MIN(contactID) contactID, ContactName \n     FROM tbl_contact \n     GROUP BY ContactName\n)\nUPDATE tbl_l_contact_fund \n    SET contactID = (SELECT ContactID \n                                            FROM crows cr \n                                            WHERE ContactName in \n            (SELECT ContactName \n             FROM tbl_contact \n             WHERE ContactID = a.contactID))\nFROM tbl_l_contact_fund a\nGO\nDELETE tbl_contact WHERE ContactID NOT IN (SELECT MIN(contactID) contactID \n                                           FROM tbl_contact GROUP BY ContactName)\n']], ['Delete duplicates in sql server'], 2, 1], [(27417566, 1), [['Or you can do a direct Update'], ['-10000']], [[' UPDATE tbl_l_contact_fund \n        SET contactID = (SELECT MIN(ContactID) \n                         FROM tbl_contact cr \n                         WHERE ContactName in \n            (Select ContactName \n             FROM tbl_contact \n             WHERE ContactID = a.contactID))\nFROM tbl_l_contact_fund a\nGO\nDELETE tbl_contact WHERE ContactID NOT IN (SELECT MIN(contactID) contactID \n                                            FROM tbl_contact GROUP BY ContactName)\n']], ['Delete duplicates in sql server'], 2, 1], [(27418411, 0), [['So firstly set up a variable to hold the  datetime  checkpoint:'], ["I'm not sure how you're running the checks as you've not provided any code, but you would use this value to query the databases across the servers:"]], [[' declare @dateTimeCutOff datetime = GETDATE()\n']], ['Three way server table check'], 2, 0], [(27418411, 1), [["I'm not sure how you're running the checks as you've not provided any code, but you would use this value to query the databases across the servers:"], ['If you run this query against the 3 database tables with the same variable value (which is only set up once and shared between the checks), they should produce the same result.']], [[' SELECT COUNT(1) \nFROM TransactionTable\nWHERE DateAdded <= @dateTimeCutOff\n']], ['Three way server table check'], 2, 0], [(27471951, 0), [['You want:'], ['I see, you want the names with the smallest id first.  For this, use a  join :']], [[' order by name desc, id asc\n']], ['Order and reverse order by group?'], 2, 1], [(27471951, 1), [['I see, you want the names with the smallest id first.  For this, use a  join :'], ['-10000']], [[' select t.*\nfrom table t join\n     (select name, max(id) as maxid\n      from table t\n      group by name\n     ) n\n     on t.name = n.name\norder by n.maxid, t.name, t.id\n']], ['Order and reverse order by group?'], 2, 1], [(27473908, 0), [['You can get the latest entry by using a simple group by'], ['use the result from the group by in the WHERE Clause like this:']], [[' select userid, max(TimeInserted) from content group by userid\n']], ['How to Write MySQL Select Statement to Show Latest Entry by Each UserID?'], 2, 0], [(27473908, 1), [['use the result from the group by in the WHERE Clause like this:'], ['-10000']], [[' select * \n   from content \nwhere (userid, TimeInserted) in\n\n(\n  select userid, max(TimeInserted) from content group by userid  \n)\n']], ['How to Write MySQL Select Statement to Show Latest Entry by Each UserID?'], 2, 1], [(27476006, 0), [['If I understand your question you should simply be able to delete based on the  sec_id .  This assumes that it is part of the table.'], ["If it's not part of the table but you have another table that contains both, then I you might use something like:"]], [[' DELETE FROM main WHERE sec_id = @sec_id\n']], ['Sql delete value from database'], 2, 1], [(27476006, 1), [["If it's not part of the table but you have another table that contains both, then I you might use something like:"], ['-10000']], [[' DELETE FROM main \nWHERE EXISTS(SELECT 1 FROM other \n             WHERE main.id = other.id AND other.sec_id = @sec_id)\n']], ['Sql delete value from database'], 2, 1], [(27512053, 1), [['In this solution your fixture class has to implement the  ContainerAwareInterface  with the method'], ['-10000']], [[' public function setContainer( ContainerInterface $container = null )\n{\n    $this->container = $container;\n}\n']], ['Symfony2 execute SQL file in Doctrine Fixtures Load'], 2, 0], [(27521297, 0), [['your example data - I have renamed some things to make life easier.'], ['the join:']], [[" create schema a; create schema b;\ncreate table a.t (id int primary key ,a text,b text);\ninsert into a.t values(1,'A','B'),(2,'C','D');\ncreate table a.f (id int references a.t(id),field1 text);\ninsert into a.f values (1,'XYZ'),(1,'WVU'),(2,'STR'),(2,'PQR');\ncreate table b.t (id int primary key ,a text,b text);\ninsert into b.t values(11,'A''','B'''),(22,'C''','D''');\ncreate table b.f (id int references b.t(id),field1 text);\ninsert into b.f values (11,'XYZ'),(11,'WVU'),(22,'STR'),(22,'PQR');\n"]], ['How to match rows in the same table across schemas by using foreign key restraints'], 4, 0], [(27521297, 1), [['the join:'], ['an update?:']], [[' SELECT * FROM a.t \n  JOIN a.f ON a.t.id = a.f.id\n  JOIN b.f ON a.f.field1 = b.f.field1 \n  JOIN b.t ON b.t.id = b.f.id \n']], ['How to match rows in the same table across schemas by using foreign key restraints'], 4, 0], [(27521297, 2), [['an update?:'], ['the cleanup']], [[" UPDATE b.t \n  SET b=b.t.b||'('||a.t.id||')'\n  FROM a.f \n    JOIN b.f ON a.f.field1 = b.f.field1 \n    JOIN a.t ON a.t.id = a.f.id \n  WHERE b.t.id = b.f.id\n;\n"]], ['How to match rows in the same table across schemas by using foreign key restraints'], 4, 0], [(27521297, 3), [['the cleanup'], ['-10000']], [[' drop schema a cascade;drop schema b cascade;\n']], ['How to match rows in the same table across schemas by using foreign key restraints'], 4, 0], [(27547669, 0), [["The best way is to break down the query into two simple queries and then join them together. This solution assumes that a job will always have someone working it but might not have any fitting costs (hence the left join from wages to fittings). Really this is a deficiency in the schema design as there should be a job table (maybe there is one that you haven't included in your example) which you would left join both wages and fittings to."], ['-10000']], [[' WITH  job_wage_costs AS\n(\n   SELECT   job_id,\n            SUM(hours) * 30 AS wage_costs\n   FROM     staff_on_job\n   GROUP BY job_id\n),\njob_fitting_costs AS (\n   SELECT   job_id,\n            SUM(COST) AS fitting_costs\n   FROM     job_fittings jf\n   JOIN     fittings f ON (f.fitting_name = jf.fitting_name)\n   GROUP BY job_id\n)\nSELECT   jw.job_id,\n         jw.wage_costs,\n         jf.fitting_costs\nFROM     job_wage_costs jw\nLEFT OUTER JOIN job_fitting_costs jf ON (jf.job_id = jw.job_id);\n']], ['Calculate sum from two queries?'], 2, 1], [(27547669, 1), [['-10000'], ["As an aside, the design of your fittings table could do with changing as it isn't a  normalized design . By reproducing the fitting type in every row you make it very difficult to change the wording of those fitting types in the future as you'd need to change every row - they should be in a fitting_type table which can then be joined to fittings."]], [[' JOB_ID   WAGE_COSTS  FITTING_COSTS \n1        60          20\n2        480         164.99\n6        1200        199.99\n12       1200        320.98\n9        90 \n']], ['Calculate sum from two queries?'], 2, 0], [(27554417, 0), [['Try this:'], ['So this will find Flop and extract it wherever it is in the field']], [[" select SUBSTRING(field,charindex('keyword',field), LEN('keyword'))\n"]], ['Trim String After Keyword'], 5, 1], [(27554417, 1), [['So this will find Flop and extract it wherever it is in the field'], ['To get the remainder then just set LEN to the field  LEN(field)']], [[" select SUBSTRING('bullflop',charindex('flop','bullflop'), LEN('flop'))\n"]], ['Trim String After Keyword'], 5, 1], [(27554417, 2), [['To get the remainder then just set LEN to the field  LEN(field)'], ['Now I understand, here is  a quick and dirty version...']], [[" declare @field varchar(200)\nset @field = 'this is bullflop and other such junk'\nselect SUBSTRING(@field,charindex('flop',@field), LEN(@field) )\n"]], ['Trim String After Keyword'], 5, 1], [(27554417, 3), [['Now I understand, here is  a quick and dirty version...'], ['Cory is right, this is cleaner.']], [[" declare @field varchar(200)\nset @field = 'From X to Y'\nselect Replace(SUBSTRING(@field,charindex('to ',@field), LEN(@field) ), 'to ','')\n"]], ['Trim String After Keyword'], 5, 1], [(27563140, 0), [['The  ROW_NUMBER  analytical function might help with such queries:'], ['Even if is is probably  not  a good idea to rely on  id  to order things is you think you need that, you will have to change the  ORDER BY  clause to:']], [[' SELECT  "owner_id", "id", "box_id", "last_activity" FROM\n(\n\n    SELECT "owner_id", "id", "box_id", "last_activity",\n           ROW_NUMBER() \n            OVER (PARTITION BY "box_id" ORDER BY "last_activity" DESC NULLS LAST) rn\n            --                                                   ^^^^^^^^^^^^^^^\n            --               descending order, reject nulls after not null values\n            --                                 (this is the default, but making it\n            --                                  explicit here for self-documentation\n            --                                  purpose)\n    FROM T\n    WHERE "owner_id" = 2\n\n) V\nWHERE rn = 1 or "box_id" IS NULL\nORDER BY "id" -- <-- probably not necessary, but matches your example\n']], ['Select last changed row in sub-query'], 2, 1], [(27563140, 1), [['Even if is is probably  not  a good idea to rely on  id  to order things is you think you need that, you will have to change the  ORDER BY  clause to:'], ['-10000']], [[' ... ORDER BY "last_activity" DESC NULLS LAST, "id" DESC\n--                                          ^^^^^^^^^^^\n']], ['Select last changed row in sub-query'], 2, 0], [(27571493, 0), [['This will select all PanelIDs that have been installed and have not been removed after installation'], ["or using not exists if your db doesn't support row_number()"]], [[' select PanelID from (\n    select PanelID,\n    row_number() over (partition by PanelID order by ActualCompleteDate desc) rn,\n    WorkType\n    from mytable\n) t1 where rn = 1 and WorkType = "electrical install"\n']], ['Determine if last action performed on each item was an install or a removal'], 2, 1], [(27571493, 1), [["or using not exists if your db doesn't support row_number()"], ['-10000']], [[' select PanelID from mytable t1\nwhere WorkType = "electrical install"\nand not exists (\n    select 1 from mytable t2\n    where t2.PanelID = t1.PanelID\n    and t2.ActualCompleteDate > t1.ActualCompleteDate\n    and t2.WorkType = "electrical removal"\n)\n']], ['Determine if last action performed on each item was an install or a removal'], 2, 1], [(27573760, 0), [['You can write this as:'], ['If you are looking for only one row, you can use  order by  for prioritization:']], [[" SELECT  Stuff\nFROM    Foo\nWHERE   X = 'Y' AND\n        (FullOrderNumber = @FullOrderNo OR\n         (NOT EXISTS (SELECT 1 FROM Foo WHERE FullOrderNumber = @FullOrderNo) and OrderNumber = @OrderNo) )\n"]], ['Moving IF EXISTS to the WHERE clause'], 3, 1], [(27573760, 1), [['If you are looking for only one row, you can use  order by  for prioritization:'], ['Actually, even if there are duplicates, you can use  with ties  like this:']], [[" SELECT  TOP (1) Stuff\nFROM    Foo\nWHERE   X = 'Y' AND\n        (FullOrderNumber = @FullOrderNo OR OrderNumber = @OrderNo)\nORDER BY (CASE WHEN FullOrderNumber = @FullOrderNo THEN 1 ELSE 2 END)\n"]], ['Moving IF EXISTS to the WHERE clause'], 3, 1], [(27573760, 2), [['Actually, even if there are duplicates, you can use  with ties  like this:'], ['-10000']], [[" SELECT  TOP (1) WITH TIES Stuff\nFROM    Foo\nWHERE   X = 'Y' AND\n        (FullOrderNumber = @FullOrderNo OR OrderNumber = @OrderNo)\nORDER BY (CASE WHEN FullOrderNumber = @FullOrderNo THEN 1 ELSE 2 END)\n"]], ['Moving IF EXISTS to the WHERE clause'], 3, 1], [(27585801, 0), [['Try this: '], ['OUTPUT']], [[" SELECT (CASE WHEN Action1 = 'Add' THEN col1 \n             WHEN Action1 = 'Subtr' THEN col1 + 1 \n             ELSE 0 \n        END) col1, \n       (CASE WHEN Action2 = 'Add' THEN col2 \n             WHEN Action2 = 'Subtr' THEN col2 - 1 \n             ELSE 0 \n        END) col2\nFROM (SELECT CEILING(RowNum / 2) AS RowId, \n             MAX(CASE WHEN RowNum % 2 = 1 THEN col ELSE 0 END) AS col1, \n             MAX(CASE WHEN RowNum % 2 = 1 THEN Action ELSE '' END) AS Action1,         \n             MAX(CASE WHEN RowNum % 2 = 0 THEN col ELSE 0 END) AS col2, \n             MAX(CASE WHEN RowNum % 2 = 0 THEN Action ELSE '' END) AS Action2\n      FROM (SELECT (@id:=@id+1) AS RowNum, col, Action \n            FROM (SELECT col1 AS col, Action \n                  FROM tableA \n                  UNION \n                  SELECT col2 AS col, Action \n                  FROM tableA \n                 ) AS A, \n                 (SELECT @id:=0) AS B\n            ORDER BY col\n           ) AS A\n      GROUP BY RowId\n     ) AS A;\n"]], ['Perform calculations on number ranges mysql'], 3, 1], [(27585801, 1), [['OUTPUT'], ['As you see in my query that first I had fetched all start-range and end-range in single column with its action type and then given a row number for each records to transpose that data in two columns because I want to create an inner table as below: ']], [[' | COL1 | COL2 |\n|------|------|\n|    1 |   19 |\n|   41 |   59 |\n|   66 |  100 |\n|  200 |  210 |\n']], ['Perform calculations on number ranges mysql'], 3, 0], [(27585801, 2), [['As you see in my query that first I had fetched all start-range and end-range in single column with its action type and then given a row number for each records to transpose that data in two columns because I want to create an inner table as below: '], ['And in last I had used CASE statement to generate specific output.']], [[' | ROWID | COL1 | ACTION1 | COL2 | ACTION2 |\n|-------|------|---------|------|---------|\n|     1 |    1 |     Add |   20 |   Subtr |\n|     2 |   40 |   Subtr |   60 |   Subtr |\n|     3 |   65 |   Subtr |  100 |     Add |\n|     4 |  200 |     Add |  210 |     Add |\n']], ['Perform calculations on number ranges mysql'], 3, 0], [(27610637, 0), [['To resolve such issues, you need to generate some  group number  for each consecutive rows. Here I first use  LAG  to generate a tick mark each time we start a new group. An outer query using  SUM  will count the number of tick marks from the first from to the current one to generate a group number:'], ['A little bit more difficult to grasp, but this works too:']], [[' SELECT "Area", \n       MIN("Start Time") as "Start Time", \n       MAX("End Time") as "End Time",  \n       SUM("End Time" - "Start Time")*24*60 as "Total Minutes", \n       COUNT("Transaction ID") as "#Transaction ID"\nFROM (\n  SELECT SUM(clk)\n         OVER (ORDER BY "Start Time"\n               ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) grp,\n--       ^^^^^^^^^^^^^\n--        Generate a group number by summing the tick marks\n         V1.*\n  FROM (\n    SELECT CASE\n             WHEN LAG("Area", 1, NULL) OVER (ORDER BY "Start Time") = "Area"\n             THEN 0\n             ELSE 1\n           END clk,\n--         ^^^^^^^^\n--         Set a tick mark ("clock") to 1 each time we change group\n         T.*\n    FROM T\n    ) V1\n  ) V2\nGROUP BY GRP, "Area"\nORDER BY "Start Time"\n']], ['Group and Summarize Time Series Transactions with Start and Stop Times'], 2, 1], [(27610637, 1), [['A little bit more difficult to grasp, but this works too:'], ['See  http://sqlfiddle.com/#!4/07d43/6']], [[' SELECT "Area", \n       MIN("Start Time") as "Start Time", \n       MAX("End Time") as "End Time",  \n       SUM("End Time" - "Start Time")*60 as "Total Minutes", \n       COUNT("Transaction ID") as "#Transaction ID"\nFROM (\n  SELECT ROWNUM-ROW_NUMBER() \n                   OVER (PARTITION BY "Area" ORDER BY "Start Time") grp,\n       T.*\n  FROM T\n  ORDER BY "Start Time"\n) V\nGROUP BY GRP, "Area"\nORDER BY "Start Time"\n']], ['Group and Summarize Time Series Transactions with Start and Stop Times'], 2, 1], [(27682228, 0), [['Every base table has a statement template, aka  predicate , parameterized by column names, by which we put a row in or leave it out. We can use a shorthand for the predicate that is like its SQL declaration.'], ['Plugging a row into a predicate gives a statement aka  proposition . The rows that make a true proposition go in a table and the rows that make a false proposition stay out. (So a table states the proposition of each present row  and  states NOT the proposition of each absent row.)']], [[' // facilitator [facilID] is named [facilFname] [facilLname]\nfacilitator(facilID,facilLname,facilFname)\n// class [classID] named [className] has prime [primeFacil] & backup [secondFacil]\nclass(classID,className,primeFacil,secondFacil)\n']], ['How to get matching data from another SQL table for two different columns: Inner Join and/or Union?'], 3, 0], [(27682228, 1), [['Plugging a row into a predicate gives a statement aka  proposition . The rows that make a true proposition go in a table and the rows that make a false proposition stay out. (So a table states the proposition of each present row  and  states NOT the proposition of each absent row.)'], ['So to query we find a way of phrasing the predicate for the rows that we want in  natural language using base table predicates, then in shorthand using base table predicates, then in SQL using base table names (plus conditions wherever needed). If we need to mention a table twice then we give it aliases.']], [[" // facilitator f1 is named Jane Doe\nfacilitator(f1,'Jane','Doe')\n// class c1 named CSC101 has prime f1 & backup f8\nclass(c1,'CSC101',f1,f8)\n"]], ['How to get matching data from another SQL table for two different columns: Inner Join and/or Union?'], 3, 0], [(27689846, 0), [['You can use  charindex()  and  substring() :'], ['If you want the  date  component of the login:']], [[" order by lastLogin,\n         substring(email, charindex('@', email) + 1, len(email))\n"]], ['How can I order a query by the domains of email addresses?'], 2, 1], [(27689846, 1), [['If you want the  date  component of the login:'], ['-10000']], [[" order by cast(lastLogin as date),\n         substring(email, charindex('@', email) + 1, len(email))\n"]], ['How can I order a query by the domains of email addresses?'], 2, 1], [(27744850, 0), [['Create a  trigger'], ['Or as Mentioned by King.code create a view instead of having a table']], [[' CREATE TRIGGER test\nON DiskUsage\nafter INSERT, UPDATE\nAS\n  BEGIN\n      UPDATE StatisticsTable\n      SET    TotalDiskUsage = (SELECT Sum(DiskUsage)\n                               FROM   DiskUsage)\n  END \n']], ['SQL computed column for sum of data in another table'], 2, 1], [(27789682, 1), [['Results :'], ['Query 2 :']], [[' | TACO_ID | TACO_NAME | TACO_PRNTID | MEAT_ID | MEAT_INHT |\n|---------|-----------|-------------|---------|-----------|\n|       1 |         1 |      (null) |       1 |         N |\n|       2 |       1.1 |           1 |       1 |         Y |\n|       3 |     1.1.1 |           2 |  (null) |         N |\n|       4 |       1.2 |           1 |       2 |         N |\n|       5 |     1.2.1 |           4 |       2 |         Y |\n|       6 |     1.1.2 |           2 |       1 |         Y |\n']], ['Oracle 11g hierarchical query needs some inherited data'], 4, 0], [(27789682, 3), [['Results :'], ['-10000']], [[' | TACO_ID | TACO_NAME | TACO_PRNTID | MEAT_ID | MEAT_INHT | LEVEL | MEAT_ID2 |\n|---------|-----------|-------------|---------|-----------|-------|----------|\n|       1 |         1 |      (null) |       1 |         N |     0 |     1    |\n|       2 |       1.1 |           1 |  (null) |         Y |     1 |     1    |\n|       3 |     1.1.1 |           2 |  (null) |         N |     2 |     1    |\n|       6 |     1.1.2 |           2 |  (null) |         Y |     2 |     1    |\n|       4 |       1.2 |           1 |       2 |         N |     1 |     1 2  |\n|       5 |     1.2.1 |           4 |  (null) |         Y |     2 |     1 2  |\n']], ['Oracle 11g hierarchical query needs some inherited data'], 4, 0], [(27817195, 0), [['Adding this piece to your code, '], ['Modified query-']], [[" RTRIM(REGEXP_REPLACE(listagg (tm_redir.team_code, ',') \n                     WITHIN GROUP (ORDER BY tm_redir.team_code),\n                     '([^,]+)(,\\1)+', '\\1'),\n                     ',')\n"]], ['Distinct LISTAGG that is inside a subquery in the SELECT list'], 2, 0], [(27817195, 1), [['Modified query-'], ['-10000']], [[" SQL> with tran_party as -- ALL DUMMY DATA ARE IN THESE CTE FOR YOUR REFERENCE\n  2           (select 1 tran_party_id, 11 transaction_id, 101 team_id_redirect\n  3              from dual\n  4            union all\n  5            select 2, 11, 101 from dual\n  6            union all\n  7            select 3, 11, 102 from dual\n  8            union all\n  9            select 4, 12, 103 from dual\n 10            union all\n 11            select 5, 12, 103 from dual\n 12            union all\n 13            select 6, 12, 104 from dual\n 14            union all\n 15            select 7, 13, 104 from dual\n 16            union all\n 17            select 8, 13, 105 from dual),\n 18       tran as\n 19           (select 11 transaction_id, 1001 account_id, 1034.93 amount from dual\n 20            union all\n 21            select 12, 1001, 2321.89 from dual\n 22            union all\n 23            select 13, 1002, 3201.47 from dual),\n 24       account as\n 25           (select 1001 account_id, 111 team_id from dual\n 26            union all\n 27            select 1002, 112 from dual),\n 28       team as\n 29           (select 101 team_id, 'UUU' as team_code from dual\n 30            union all\n 31            select 102, 'VV' from dual\n 32            union all\n 33            select 103, 'WWW' from dual\n 34            union all\n 35            select 104, 'XXXXX' from dual\n 36            union all\n 37            select 105, 'Z' from dual)\n 38  -- The Actual Query\n 39  select a.account_id,\n 40         t.transaction_id,\n 41         (SELECT  RTRIM(\n 42           REGEXP_REPLACE(listagg (tm_redir.team_code, ',')\n 43                     WITHIN GROUP (ORDER BY tm_redir.team_code),\n 44             '([^,]+)(,\\1)+', '\\1'),\n 45           ',')\n 46            from tran_party tp_redir\n 47                 inner join team tm_redir\n 48                     on tp_redir.team_id_redirect = tm_redir.team_id\n 49                 inner join tran t_redir\n 50                     on tp_redir.transaction_id = t_redir.transaction_id\n 51           where     t_redir.account_id = a.account_id\n 52                 and t_redir.transaction_id != t.transaction_id)\n 53             AS teams_redirected\n 54    from tran t inner join account a on t.account_id = a.account_id\n 55  /\n\nACCOUNT_ID TRANSACTION_ID TEAMS_REDIRECTED\n---------- -------------- --------------------\n      1001             11 WWW,XXXXX\n      1001             12 UUU,VV\n      1002             13\n\nSQL>\n"]], ['Distinct LISTAGG that is inside a subquery in the SELECT list'], 2, 1], [(27832430, 0), [['I think you could use this:'], ['But you would be better off with a subquery:']], [[' select a1.person\n  from awards a1\n  join awards a2\n    on a1.person = a2.person\n   and a1.year = a2.year\n   and a1.award <> a2.award\n group by a1.person\nhaving count(distinct a1.year) > 1\n']], ['How to query for a count within a count (without using a sub query)?'], 2, 1], [(27855167, 0), [['Depending on what you want to do if the value is null, you can try'], ['Will return ']], [[" SELECT CONCAT(\nc.custom_param1, '=', IFNULL(c.custom_value1, ''), '; ',\nc.custom_param2, '=', IFNULL(c.custom_value2, ''), '; ',\nc.custom_param3, '=', IFNULL(c.custom_value3, ''), '; ') as 'Custom Parameters'\nFROM campaign as c;\n"]], ['mysql concatenate columns if column is not null'], 4, 1], [(27855167, 1), [['Will return '], ['Or you can exclude the whole value pair like this....']], [[' param1=value1; param2=value2; param3=;\n']], ['mysql concatenate columns if column is not null'], 4, 0], [(27855167, 2), [['Or you can exclude the whole value pair like this....'], ['which will return']], [[" SELECT CONCAT(\nIFNULL(CONCAT(c.custom_param1, '=', c.custom_value1, '; '), ''),\nIFNULL(CONCAT(c.custom_param2, '=', c.custom_value2, '; '), ''),\nIFNULL(CONCAT(c.custom_param3, '=', c.custom_value3, '; '), '')) AS 'Custom Parameters'\nFROM campaign as c;\n"]], ['mysql concatenate columns if column is not null'], 4, 1], [(27855167, 3), [['which will return'], ['Hope that helps']], [[' param1=value1; param2=value2;\n']], ['mysql concatenate columns if column is not null'], 4, 0], [(27876454, 0), [['Use a  union :'], ['Just a little extra, if you  do  want to know the origin of the email address, you could do this:']], [[' select email\nfrom   teachers\nunion\nselect email\nfrom   students\n']], ['Merge two columns from different tables'], 2, 1], [(27876454, 1), [['Just a little extra, if you  do  want to know the origin of the email address, you could do this:'], ['-10000']], [[" select 'teacher' origin\n,      id\n,      email\nfrom   teachers\nunion\nselect 'student' origin\n,      id\n,      email\nfrom   students\n"]], ['Merge two columns from different tables'], 2, 1], [(27916519, 0), [['You could use a  case  expression:'], ["EDIT: \nThe above statement assumes, for simplicity's sake, that  'M'  and  'F'  are the only two options - no  null s, no unknowns, no nothing. A more robust query could eliminate this assumption and just strictly replace  M s and  F s leaving other possible values untouched:"]], [[" UPDATE emp\nSET    gender = CASE gender WHEN 'M' THEN 'F' ELSE 'M' END\n"]], ['Update column data without using temporary tables'], 2, 1], [(27916519, 1), [["EDIT: \nThe above statement assumes, for simplicity's sake, that  'M'  and  'F'  are the only two options - no  null s, no unknowns, no nothing. A more robust query could eliminate this assumption and just strictly replace  M s and  F s leaving other possible values untouched:"], ['-10000']], [[" UPDATE emp\nSET    gender = CASE gender WHEN 'M' THEN 'F' \n                            WHEN 'F' THEN 'M'\n                            ELSE gender\n                END\n"]], ['Update column data without using temporary tables'], 2, 1], [(27922122, 0), [['According to this you can pass time and date parameters can be passed as arguments, along with the  **strftime**  it proves to be a very powerful tool. Some specifiers are--'], ['For example if you want to do a select * for the month of april, it will be like,']], [[' %d      day of month: 00\n%f      fractional seconds: SS.SSS\n%H      hour: 00-24\n%m      month: 01-12 where, Jan=01, Feb=02, ... ... ... December==12.\n%M      minute: 00-59\n%S      seconds: 00-59\n%w      day of week 0-6 with Sunday==0, Monday==1, ... ... Saturday==6.\n%Y      year: 0000-9999 \n']], ['sqlite How to get whole month data from table'], 2, 0], [(27932305, 0), [['-10000'], ['-10000']], [[' // question [question_id] has available answer [answer_id]\nquestion_answers(question_id, answerid)\n']], ['Database Design for Conditional Questionnaire'], 3, 0], [(27932305, 1), [['-10000'], ['PPS \nIf different user traces through questions can mean that which question follows another is context-dependent:']], [[' // for question [this_id] if answer [answer_id] is chosen then go to question [next_id]\nnext_question(this_id, answer_id, next_id)\n']], ['Database Design for Conditional Questionnaire'], 3, 0], [(27932305, 2), [['PPS \nIf different user traces through questions can mean that which question follows another is context-dependent:'], ['What a "context" is depends on aspects of your application that you have not given. What you have given suggests that your only notion of context is the current question. Also, depending on what a context contains, this table may need normalization. You might want independent notions of current context vs current question. (Topic:  finite state machines .)']], [[' // in context [this_id] if answer [answer_id] is chosen then go to context[next_id]\nnext_context(this_id, answer_id, next_id)\n']], ['Database Design for Conditional Questionnaire'], 3, 0], [(27979526, 0), [['In SQL Server 2012+ you can use the  FORMAT  function to format a decimal in a custom format, eg: '], ["Your desired output truncates the decimals yet displays the value  with  decimals. In case this isn't a typo, you can either replace the decimals with literals, eg:"]], [[" declare @data decimal(19,6)=1050.850000\nselect FORMAT(@data,'#,###.00')\n"]], ['Convert decimal data to custom format in SQL'], 4, 1], [(27979526, 1), [["Your desired output truncates the decimals yet displays the value  with  decimals. In case this isn't a typo, you can either replace the decimals with literals, eg:"], ['Or truncate the value before formatting']], [[" select FORMAT(@data,'#,###\\.\\0\\0')\n"]], ['Convert decimal data to custom format in SQL'], 4, 1], [(27979526, 2), [['Or truncate the value before formatting'], ['In previous SQL Server versions you are restricted to the predefined money type formats of the  CONVERT  function :']], [[" declare @data decimal(19,6)=1050.850000\nselect FORMAT(floor(@data),'#,###.00')\n"]], ['Convert decimal data to custom format in SQL'], 4, 1], [(27979526, 3), [['In previous SQL Server versions you are restricted to the predefined money type formats of the  CONVERT  function :'], ['Note that  nvarchar  defaults to  nvarchar(30) . Strings larger than 30 characters will be truncated to the first 30 characters.  ']], [[' select CONVERT(nvarchar,cast(@data as money),1)\n']], ['Convert decimal data to custom format in SQL'], 4, 1], [(28031438, 0), [["I've placed the tables in a more logic other:"], ['This can be avoided by creating a virtual table with a subquery with the distinct vehicletypes a person is allowed to drive.']], [[' SELECT DISTINCT\n    p.name,\n    v.VehicleType,\n    v.make,\n    v.model,\n    CASE\n       WHEN ltvt.VehicleType_ID =  v.VehicleType_ID THEN 1\n       ELSE 0\n    END allowed\nFROM\n    Person p\nJOIN\n    Vehicles v\n    ON p.ID = v.person_id\nLEFT JOIN\n    DrivingLicense dl\n    ON p.ID = dl.Person_ID\nLEFT JOIN\n    DrivingLicenseLicenceType dlt\n    ON dl.ID = dlt.DrivingLicense_ID\nLEFT JOIN\n    LicenseTypes lt\n    ON dlt.LicenseType_ID = lt.ID\nLEFT JOIN\n    LicenseTypeVehicleTypes ltvt\n    ON dlt.LicenseType_ID = ltvt.LicenseType_ID\n    AND ltvt.VehicleType_ID = v.VehicleType_ID\n    AND dl.ExpiryDate >= CURRENT_DATE \n']], ['JOINS between 7 tables'], 2, 1], [(28031438, 1), [['This can be avoided by creating a virtual table with a subquery with the distinct vehicletypes a person is allowed to drive.'], ['Note that it might be wise to include the persons table in the subquery, if you want information about a certain person, so you can narrow down the number of results from the subquery.']], [[' SELECT\n    p.name,\n    v.VehicleType_ID,\n    v.make,\n    v.model,\n    CASE\n        WHEN dls.VehicleType_ID =  v.VehicleType_ID THEN 1\n        ELSE 0\n    END allowed\nFROM\n    Person p\nJOIN\n    Vehicles v\n    ON p.ID = v.Person_ID\nLEFT JOIN\n    (SELECT DISTINCT\n        dl.Person_ID,\n        ltvt.VehicleType_ID\n    FROM\n        DrivingLicense dl       \n    JOIN\n        DrivingLicenseLicenseTypes dlt\n        ON dl.ID = dlt.DrivingLicense_ID\n    JOIN\n        LicenseTypes lt\n        ON dlt.LicenseType_ID = lt.ID\n    JOIN\n        LicenseTypeVehicleTypes ltvt\n        ON dlt.LicenseType_ID = ltvt.LicenseType_ID\n    WHERE\n        dl.ExpiryDate >= CURRENT_DATE\n    ) dls\n    ON p.ID = dls.Person_ID\n        AND dls.VehicleType_ID =  v.VehicleType_ID\n']], ['JOINS between 7 tables'], 2, 1], [(28043394, 0), [['You can write a small PHP program to do that. First, read in the file:'], ['Now,  $fh  is a handler to read the-file.txt. Now we can use  fgetcsv() :']], [[" $fh = fopen('the-file.txt', 'r');\n"]], ['Import file with : separators into MySQL database'], 3, 0], [(28043394, 1), [['Now,  $fh  is a handler to read the-file.txt. Now we can use  fgetcsv() :'], ['An example with PDO and a prepared statement:']], [[" while (($data = fgetcsv($fh, 1000, ':', '')) !== false) {\n    // insert data in database\n}\n"]], ['Import file with : separators into MySQL database'], 3, 0], [(28061347, 1), [['-10000'], ['-10000']], [[" ;WITH CTE AS\n(\n    -- Since CSV values is scattered with non-alphabetical order, we use ROW_NUMBER()\n    -- to maintain the order by default\n    SELECT *,\n    ROW_NUMBER() OVER(PARTITION BY ID ORDER BY (SELECT(0))) RNO,'Primary_Kwd' Colum \n    FROM\n    (\n        -- Convert CSV to rows\n        SELECT ID,LTRIM(RTRIM(Split.a.value('.', 'VARCHAR(100)'))) 'KeyWords' \n        FROM  \n        (\n             -- To change ',' to any other delimeter, just change ',' before '</M><M>' to your desired one\n             SELECT ID,CAST ('<M>' + REPLACE(Primary_Kwd, ',', '</M><M>') + '</M>' AS XML) AS Data \n             FROM #Kwd_UploadRecored     \n        ) AS A \n        CROSS APPLY Data.nodes ('/M') AS Split(a)\n    )TAB\n\n    UNION ALL\n\n    SELECT *,\n    ROW_NUMBER() OVER(PARTITION BY ID ORDER BY (SELECT(0))) RNO,'Sec_Kwd'  \n    FROM\n    (\n        SELECT ID,LTRIM(RTRIM(Split.a.value('.', 'VARCHAR(100)'))) 'KeyWords' \n        FROM  \n        (\n             -- To change ',' to any other delimeter, just change ',' before '</M><M>' to your desired one\n             SELECT ID,CAST ('<M>' + REPLACE(Sec_Kwd, ',', '</M><M>') + '</M>' AS XML) AS Data \n             FROM #Kwd_UploadRecored     \n        ) AS A \n        CROSS APPLY Data.nodes ('/M') AS Split(a)\n    )TAB\n\n    UNION ALL\n\n    SELECT *,\n    ROW_NUMBER() OVER(PARTITION BY ID ORDER BY (SELECT(0))) RNO,'Main_Kwd'  \n    FROM\n    (\n        SELECT ID,LTRIM(RTRIM(Split.a.value('.', 'VARCHAR(100)'))) 'KeyWords' \n        FROM  \n        (\n             -- To change ',' to any other delimeter, just change ',' before '</M><M>' to your desired one\n             SELECT ID,CAST ('<M>' + REPLACE(Main_Kwd, ',', '</M><M>') + '</M>' AS XML) AS Data \n             FROM #Kwd_UploadRecored     \n        ) AS A \n        CROSS APPLY Data.nodes ('/M') AS Split(a)\n    )TAB\n)\n,CTE2 AS\n(\n    -- Check for German word, if matched German word else English\n    SELECT C.ID,C.RNO,C.Colum,ISNULL(T.German_Keywords,C.KeyWords) German_Keywords \n    FROM CTE C\n    LEFT JOIN #Englishgermankwds_tbl T ON C.KeyWords=T.English_Keywords \n) \n,CTE3 AS\n(\n    -- Convert back to CSV values with the old order of strings\n    SELECT  ID,COLUM,\n    SUBSTRING(\n            (SELECT  ', ' + German_Keywords\n            FROM CTE2 \n            WHERE C2.Id=Id AND C2.COLUM=COLUM \n            ORDER BY RNO\n            FOR XML PATH('')),2,200000) German_Keywords\n    FROM CTE2 C2\n)\n-- Now we convert back Primary_Kwd,Sec_Kwd,Main_Kwd to columns with CSV values\nSELECT ID,\nMIN(CASE Colum WHEN 'Primary_Kwd' THEN German_Keywords END) Primary_Kwd,\nMIN(CASE Colum WHEN 'Sec_Kwd' THEN German_Keywords END) Sec_Kwd,\nMIN(CASE Colum WHEN 'Main_Kwd' THEN German_Keywords END) Main_Kwd \nFROM CTE3\nGROUP BY ID\n"]], ['Replace comma separated values'], 3, 1], [(28068971, 0), [['Here you will select the values in a column to show as column in pivot'], ['Now pivot the query']], [[" DECLARE @cols NVARCHAR (MAX)\n\nSELECT @cols = COALESCE (@cols + ',[' + AvJT + ']', '[' + AvJT + ']')\n               FROM    (SELECT DISTINCT AvJT FROM YourTable) PV  \n               ORDER BY AvJT\n"]], ['SQL Pivot Table dynamic'], 6, 0], [(28068971, 1), [['Now pivot the query'], ['-10000']], [[" DECLARE @query NVARCHAR(MAX)\nSET @query = 'SELECT * FROM \n             (\n                 SELECT date_1, StartHour,AvJT, data_source \n                 FROM YourTable\n             ) x\n             PIVOT \n             (\n                 -- Values in each dynamic column\n                 SUM(data_source)\n                 FOR AvJT IN (' + @cols + ')                      \n            ) p;' \n\nEXEC SP_EXECUTESQL @query\n"]], ['SQL Pivot Table dynamic'], 6, 0], [(28068971, 2), [['-10000'], ['-10000']], [[" SELECT DATE_1,STARTHOUR,\nMIN(CASE WHEN AvJT='00001a' THEN data_source END) [00001a],\nMIN(CASE WHEN AvJT='00002a' THEN data_source END) [00002a],\nMIN(CASE WHEN AvJT='00003a' THEN data_source END) [00003a],\nMIN(CASE WHEN AvJT='00004a' THEN data_source END) [00004a]\nFROM YOURTABLE\nGROUP BY  DATE_1,STARTHOUR\n"]], ['SQL Pivot Table dynamic'], 6, 0], [(28068971, 3), [['-10000'], ['Instead of  QUOTENAME , you can use another format to get the columns for pivot']], [[" DECLARE @DATASOURCE VARCHAR(20) = '1' \n"]], ['SQL Pivot Table dynamic'], 6, 0], [(28068971, 4), [['Instead of  QUOTENAME , you can use another format to get the columns for pivot'], ['Now pivot                 ']], [[" DECLARE @cols NVARCHAR (MAX)\n\nSELECT @cols = COALESCE (@cols + ',[' + Link_ID + ']', '[' + Link_ID + ']')\n               FROM    (SELECT DISTINCT Link_ID FROM C1_May_Routes WHERE data_source=@DATASOURCE) PV  \n               ORDER BY Link_ID\n"]], ['SQL Pivot Table dynamic'], 6, 0], [(28068971, 5), [['Now pivot                 '], ['-10000']], [[" DECLARE @query NVARCHAR(MAX)\nSET @query = 'SELECT * FROM \n             (\n                 -- We will select the data that has to be shown for pivoting\n                 -- with filtered data_source\n                 SELECT date_1, StartHour,AvJT, Link_ID\n                 FROM C1_May_Routes\n                 WHERE data_source = '+@DATASOURCE+'\n             ) x\n             PIVOT \n             (\n                 -- Values in each dynamic column\n                 SUM(AvJT)\n                 -- Select columns from @cols \n                 FOR Link_ID IN (' + @cols + ')                      \n            ) p;' \n\nEXEC SP_EXECUTESQL @query\n"]], ['SQL Pivot Table dynamic'], 6, 0], [(28082687, 0), [['If the data is really stored in the way you show us, then this can be achieved using a  hstore  because that value can directly be cast to a  hstore :'], ['You might need to  create  the  hstore  extension to be able to use that:']], [[" select *\nfrom the_table\nwhere extract(month from ((meta::hstore -> 'date_approved')::timestamp)) = 1\n"]], ['Search through meta array in database field'], 2, 1], [(28082687, 1), [['You might need to  create  the  hstore  extension to be able to use that:'], ['This needs to be done as the superuser.']], [[' create extension hstore;\n']], ['Search through meta array in database field'], 2, 0], [(28109037, 0), [['Either way, a function with a  VARIADIC  parameter does  exactly  what you ask for:'], ['Call (as desired):']], [[' CREATE OR REPLACE FUNCTION test_function(VARIADIC varchar[])\n RETURNS SETOF integer AS\n$func$\nSELECT column2\nFROM   test_table\nWHERE  column1 = ANY($1);\n$func$  LANGUAGE sql;\n']], ['Passing multiple values in single parameter'], 2, 1], [(28109037, 1), [['Call (as desired):'], ['Using a simple SQL function, plpgsql is not required for the simple example. But  VARIADIC  works for plpgsql functions, too.  ']], [[" SELECT * FROM test_function('data1', 'data2', 'data3');\n"]], ['Passing multiple values in single parameter'], 2, 0], [(28129007, 0), [['In SQL Server, the default scale for a decimal is 0 (see the  documentation ).  So,'], ['is equivalent to:']], [[' declare @ret decimal;\n']], ['Sql function - disregarding the decimal place in returning value'], 3, 0], [(28129007, 1), [['is equivalent to:'], ['Just be explicit about the precision and scale, something like:']], [[' declare @ret decimal(18, 0);\n']], ['Sql function - disregarding the decimal place in returning value'], 3, 0], [(28129007, 2), [['Just be explicit about the precision and scale, something like:'], ['-10000']], [[' declare @ret decimal(18, 2);\n']], ['Sql function - disregarding the decimal place in returning value'], 3, 1], [(28147528, 1), [['One way to achieve this is with a nested query as follow'], ['The result is the one you described above.']], [[' SELECT ss.athlete_id,ss.perform,category_id\nFROM performs ss\ninner join\n(SELECT\n    athlete_id, MIN(perform) AS perform\nFROM \n    performs\nWHERE\n    discipline_id = 4 AND category_id IN (1,3,5,7,9) \nGROUP BY\n    athlete_id) tt\n    on tt.athlete_id = ss.athlete_id and ss.perform = tt.perform\n']], ['Find MIN value based on two columns in MySQL'], 2, 1], [(28152970, 0), [['You can use the  FM   format modifier  to have trailing decimal zeros blanked out:'], ['But as you can see that leaves the decimal character behind; you can trim that off though:']], [[" select to_char(1, 'FM9G999G999D999', 'NLS_NUMERIC_CHARACTERS='',.''') from dual;\n\nTO_CHAR(1,'FM9G999G999D999','NLS_NUMERIC_CHARACTERS='',.''')\n------------------------------------------------------------\n1,      \n"]], ['Oracle - Format number with fullstop for thousand and comma for decimals'], 3, 1], [(28152970, 1), [['But as you can see that leaves the decimal character behind; you can trim that off though:'], ['If you want to preserve the zero befor the decimal separator, just make the last  9  before the  D  into a  0 :']], [[" with t as (\n select 3.69 as n from dual\n union all select 1000 from dual\n union all select 150.20 from dual\n union all select 1 from dual\n union all select 0.16 from dual\n)\nselect n,\n  to_char(n, '9G999G999D000') original,\n  to_char(n, 'FM9G999G999D999', 'NLS_NUMERIC_CHARACTERS='',.''') new,\n  rtrim(to_char(n, 'FM9G999G999D999', 'NLS_NUMERIC_CHARACTERS='',.'''),\n    ',') as trimmed\nfrom t;\n\n         N ORIGINAL       NEW            TRIMMED       \n---------- -------------- -------------- --------------\n      3.69          3.690 3,69           3,69           \n      1000      1,000.000 1.000,         1.000          \n     150.2        150.200 150,2          150,2          \n         1          1.000 1,             1            \n       .16           .160 ,16            ,16            \n"]], ['Oracle - Format number with fullstop for thousand and comma for decimals'], 3, 1], [(28152970, 2), [['If you want to preserve the zero befor the decimal separator, just make the last  9  before the  D  into a  0 :'], ['-10000']], [[" with t as (\n select 3.69 as n from dual\n union all select 1000 from dual\n union all select 150.20 from dual\n union all select 1 from dual\n union all select 0.16 from dual\n)\nselect n,\n  to_char(n, '9G99G990D000') original,\n  to_char(n, 'FM9G999G990D999', 'NLS_NUMERIC_CHARACTERS='',.''') new,\n  rtrim(to_char(n, 'FM9G999G990D999', 'NLS_NUMERIC_CHARACTERS='',.'''),\n    ',') as trimmed\nfrom t;\n\n         N ORIGINAL      NEW            TRIMMED       \n---------- ------------- -------------- --------------\n      3.69         3.690 3,69           3,69           \n      1000     1,000.000 1.000,         1.000          \n     150.2       150.200 150,2          150,2          \n         1         1.000 1,             1              \n       .16         0.160 0,16           0,16           \n"]], ['Oracle - Format number with fullstop for thousand and comma for decimals'], 3, 1], [(28190592, 0), [['If you are going with package, in data flow use derived column and in that use replace function '], ['Or if you want to change data in database you can use update statement in "OLEDB command" transformation ']], [["         replace('NAN',column,null)\n"]], ["Treat NaN's as NULL in SSIS package"], 2, 1], [(28190592, 1), [['Or if you want to change data in database you can use update statement in "OLEDB command" transformation '], ['-10000']], [[" Update table\nset column_name=null\nwhere column_name='NAN'\n"]], ["Treat NaN's as NULL in SSIS package"], 2, 1], [(28219230, 0), [["I found the answer to this question from gnarly's suggestion of LIMIT on SQL"], ['Where LIMIT only gives the X number of rows you want, and OFFSET gives the Y starting point.  So showing rows 0 through 30:']], [[' $sql = "SELECT * FROM my_table LIMIT X OFFSET Y";\n']], ['PHP / SQL - Show specific number of rows per query'], 3, 1], [(28219230, 1), [['Where LIMIT only gives the X number of rows you want, and OFFSET gives the Y starting point.  So showing rows 0 through 30:'], ['And showing rows 31 through 60:']], [[' $sql = "SELECT * FROM my_table LIMIT 30 OFFSET 0";\n']], ['PHP / SQL - Show specific number of rows per query'], 3, 1], [(28219230, 2), [['And showing rows 31 through 60:'], ['-10000']], [[' $sql = "SELECT * FROM my_table LIMIT 30 OFFSET 30";\n']], ['PHP / SQL - Show specific number of rows per query'], 3, 1], [(28243845, 0), [['It should work like this:'], ['Cleaner alternative (may or may not be faster, depending on data distribution):']], [[' SELECT id \nFROM   post_table p\nWHERE  post_user_id = $user_id  -- this is your input parameter\nORDER  BY <b>GREATEST(</b>\n   (\n   SELECT max(comment_created_date) \n   FROM   comments_table\n   WHERE  comments_post_id = p.id\n   )\n , post_created_date<b>)</b> DESC NULLS LAST;']], ['ORDER BY alternative values from main- and subquery'], 3, 1], [(28243845, 1), [['Cleaner alternative (may or may not be faster, depending on data distribution):'], ['Since you have pg 9.3 you can also use a  LATERAL  join. Probably faster:']], [[' SELECT id \nFROM   post_table p\nLEFT   JOIN  (\n   SELECT comments_post_id AS id, max(comment_created_date) AS max_date\n   FROM   comments_table\n   GROUP  BY 1\n   ) c USING (id)\nWHERE  post_user_id = $user_id\nORDER  BY GREATEST(c.max_date, p.post_created_date) DESC NULLS LAST;\n']], ['ORDER BY alternative values from main- and subquery'], 3, 1], [(28243845, 2), [['Since you have pg 9.3 you can also use a  LATERAL  join. Probably faster:'], ['-10000']], [[' SELECT id \nFROM   post_table p\nLEFT   JOIN  LATERAL (\n   SELECT max(comment_created_date) AS max_date\n   FROM   comments_table\n   WHERE  comments_post_id = p.id\n   GROUP  BY comments_post_id\n   ) c ON TRUE\nWHERE  post_user_id = $user_id\nORDER  BY GREATEST(c.max_date, p.post_created_date) DESC NULLS LAST;\n']], ['ORDER BY alternative values from main- and subquery'], 3, 1], [(28252370, 0), [["You've missed the need to order your data. Try the following:  SQL Fiddle"], ['Output:']], [[' select t.nodeid, @pv := t.parentid parentid\nfrom (select * from table1 order by nodeid desc) t\njoin (select @pv := 8) tmp\nwhere t.nodeid = @pv\n']], ['Selecting hierarchical data using MySQL variable'], 2, 1], [(28252370, 1), [['Output:'], ['-10000']], [[' | NODEID | PARENTID |\n|--------|----------|\n|      8 |        6 |\n|      6 |        5 |\n|      5 |        3 |\n|      3 |        0 |\n']], ['Selecting hierarchical data using MySQL variable'], 2, 0], [(28263926, 0), [['One way is using a  case  statement:'], ['An alternative is to do this with two separate  update s:']], [[" UPDATE transactions\n    SET transactions = (case when tran_date >= date_sub(CURDATE(), interval 1 month)\n                             then transactions + 1 else 0\n                        end),\n        tran_date = (case when tran_date >= date_sub(CURDATE(), interval 1 month)\n                          then CURDATE() \n                          else '0000-00-00'\n                     end),\n        date_created = (case when tran_date >= date_sub(CURDATE(), interval 1 month)\n                             then date_created \n                             else CURDATE()\n                         end)\n    WHERE name = 'jim';\n"]], ['If satetment: when date field is 1 month or older'], 2, 1], [(28263926, 1), [['An alternative is to do this with two separate  update s:'], ['I think the logic might be a bit clearer, but there is more overhead for two  update  statements.']], [[" UPDATE transactions\n    SET transactions = transactions + 1 \n    WHERE name = 'jim' and tran_date >= date_sub(CURDATE(), interval 1 month)\n\nUPDATE transactions\n    SET transactions = 0,\n        tran_date = '0000-00-00',\n        date_created = CURDATE()\n    WHERE name = 'jim' and tran_date < date_sub(CURDATE(), interval 1 month)\n"]], ['If satetment: when date field is 1 month or older'], 2, 1], [(28277247, 0), [['You can do this with a  group by  and  having  clause:'], ['This returns all the values in  colb  that have more than one value in  cola .  You could also use:']], [[' select colb\nfrom table t\ngroup by colb\nhaving min(cola) <> max(cola);\n']], ['Find different values in one column according to same value in second column'], 2, 1], [(28277247, 1), [['This returns all the values in  colb  that have more than one value in  cola .  You could also use:'], ['This works, but  count(distinct)  is less efficient than  min()  and  max() .']], [[' having count(distinct cola) > 1\n']], ['Find different values in one column according to same value in second column'], 2, 0], [(28278115, 0), [['You could add those dates with Access SQL if you have a suitable table of numbers.'], ['Or start from 1 in  tblNumbers  and add an offset ...']], [[' INSERT INTO dates ([Date])\nSELECT CDate(n.the_number)\nFROM tblNumbers AS n\nWHERE n.the_number BETWEEN 29221 AND 42037;\n']], ['Populate Date Column in Access with dates from 1980-01-01 to today with sql query'], 3, 1], [(28278115, 1), [['Or start from 1 in  tblNumbers  and add an offset ...'], ['The original task is simple enough that I would use a throwaway VBA procedure instead of Access SQL.  This one took less than 2 seconds to load my  dates  table with the required 12,817 date values:']], [[' INSERT INTO dates ([Date])\nSELECT CDate(n.the_number + 29220)\nFROM tblNumbers AS n\nWHERE n.the_number BETWEEN 1 AND 12817;\n']], ['Populate Date Column in Access with dates from 1980-01-01 to today with sql query'], 3, 1], [(28278115, 2), [['The original task is simple enough that I would use a throwaway VBA procedure instead of Access SQL.  This one took less than 2 seconds to load my  dates  table with the required 12,817 date values:'], ['-10000']], [[' Dim db As DAO.Database\nDim rs As DAO.Recordset\nDim dte As Date\nSet db = CurrentDb\nSet rs = db.OpenRecordset("dates", dbOpenTable, dbAppendOnly)\nWith rs\n    For dte = #1/1/1980# To Date\n        .AddNew\n        ![Date].Value = dte\n        .Update\n    Next\n    .Close\nEnd With\n']], ['Populate Date Column in Access with dates from 1980-01-01 to today with sql query'], 3, 1], [(28285834, 1), [['By the way, I think your query is simpler if you use conditional aggregation with  avg() :'], ['-10000']], [[' select avg(case when quality_score >= 25 then 100.0 else 0 end)\nfrom k12_read;\n']], ['How to work out Percent in PostgreSQL using Count'], 2, 1], [(28308752, 0), [['And join that with your select with something like this:'], ['Edit, Including the function code:']], [[" select\n  t.ID,\n  s.Item,\n  t.TEXT\nfrom\n  table t\n  cross apply dbo.DelimitedSplit8K(t.VALUE, ',') s \n"]], ['Parsing a column value in SQL'], 2, 0], [(28308752, 1), [['Edit, Including the function code:'], ['-10000']], [[' CREATE FUNCTION [dbo].[DelimitedSplit8K]\n--===== Define I/O parameters\n        (@pString VARCHAR(8000), @pDelimiter CHAR(1))\n--WARNING!!! DO NOT USE MAX DATA-TYPES HERE!  IT WILL KILL PERFORMANCE!\nRETURNS TABLE WITH SCHEMABINDING AS\n RETURN\n--===== "Inline" CTE Driven "Tally Table" produces values from 1 up to 10,000...\n     -- enough to cover VARCHAR(8000)\n  WITH E1(N) AS (\n                 SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL\n                 SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL\n                 SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1\n                ),                          --10E+1 or 10 rows\n       E2(N) AS (SELECT 1 FROM E1 a, E1 b), --10E+2 or 100 rows\n       E4(N) AS (SELECT 1 FROM E2 a, E2 b), --10E+4 or 10,000 rows max\n cteTally(N) AS (--==== This provides the "base" CTE and limits the number of rows right up front\n                     -- for both a performance gain and prevention of accidental "overruns"\n                 SELECT TOP (ISNULL(DATALENGTH(@pString),0)) ROW_NUMBER() OVER (ORDER BY (SELECT NULL)) FROM E4\n                ),\ncteStart(N1) AS (--==== This returns N+1 (starting position of each "element" just once for each delimiter)\n                 SELECT 1 UNION ALL\n                 SELECT t.N+1 FROM cteTally t \n                 WHERE SUBSTRING(@pString,t.N,1) = @pDelimiter\n                ),\ncteLen(N1,L1) AS(--==== Return start and length (for use in substring)\n                 SELECT s.N1,\n                    ISNULL(NULLIF(CHARINDEX(@pDelimiter,@pString,s.N1),0)-s.N1,8000)\n                   FROM cteStart s\n                )\n--===== Do the actual split. The ISNULL/NULLIF combo handles the length for the final element when no delimiter is found.\n SELECT ItemNumber = ROW_NUMBER() OVER(ORDER BY l.N1),\n        Item       = SUBSTRING(@pString, l.N1, l.L1)\n   FROM cteLen l\n;\n']], ['Parsing a column value in SQL'], 2, 1], [(28339885, 0), [['Use a full outer join, like so:'], ['While SQL Server supports full outer joins, MySQL does not. This query can be rewritten in that situation as follows:']], [[' select *\nfrom table1 t1 \nfull outer join table2 t2\non t1.c4 = t2.c1 and t1.c5 = t2.c2\n']], ['SQL join using UNION ALL with some columns common and some outer'], 3, 1], [(28339885, 1), [['While SQL Server supports full outer joins, MySQL does not. This query can be rewritten in that situation as follows:'], ['Based on your  updated  requirements, the form of this join specified above can be used with slight modifications like so:']], [[' select *\nfrom table1 t1 \nleft outer join table2 t2\non t1.c4 = t2.c1 and t1.c5 = t2.c2\nunion\nselect *\nfrom table1 t1 \nright outer join table2 t2\non t1.c4 = t2.c1 and t1.c5 = t2.c2\n']], ['SQL join using UNION ALL with some columns common and some outer'], 3, 1], [(28339885, 2), [['Based on your  updated  requirements, the form of this join specified above can be used with slight modifications like so:'], ['Note that you will still need to include the literal value  null  in your select clause, once for each column that needs to be defaulted to null.']], [[' select null,null,null,t.* from table1 s\nright outer join table2  t on s.c4 = t.c1  and s.c5 = t.c2\nunion\nselect s.*,null,null from table1 s\nleft outer join table2  t on s.c4 = t.c1  and s.c5 = t.c2\n']], ['SQL join using UNION ALL with some columns common and some outer'], 3, 1], [(28371337, 0), [['There  WHERE  condition is done to select the rows first, then  MAX()  is applied to those results. Use  HAVING  to operate on the results after aggregating.'], ['Note that this will not necessarily show the  id  of the line with the maximum date. For that, you need a join:']], [[' SELECT id, account, MAX(mydate) AS maxdate\nFROM awesometable\nGROUP BY account\nHAVING maxdate < DATE_SUB(NOW(), INTERVAL 12 MONTH)\n']], ['How to select none if condition is not?'], 2, 1], [(28371337, 1), [['Note that this will not necessarily show the  id  of the line with the maximum date. For that, you need a join:'], ['-10000']], [[' SELECT a.id, a.account, a.mydate\nFROM awesometable AS a\nJOIN (\n    SELECT account, MAX(mydate) AS maxdate\n    FROM awesometable\n    GROUP BY account\n    HAVING maxdate < DATE_SUB(NOW(), INTERVAL 12 MONTH)) AS b\nON a.account = b.account AND a.mydate = b.maxdate\n']], ['How to select none if condition is not?'], 2, 1], [(28397342, 0), [['Just tried it with  SQL Fiddle :'], ['now you can use below query to update it like as you wanted:']], [[" create table tbl_SO_19\n(\ncol1 int,\ncol2 varchar(50),\ncol3 bit,\ncol4 int\n)\ngo\ninsert into tbl_SO_19\nvalues\n(1,'John',0,null),\n(2,'Hony',0,null),\n(3,'John',1,null),\n(4,'Rohn',0,null),\n(5,'Hony',1,null)\n"]], ['Update column according to another column'], 2, 0], [(28397342, 1), [['now you can use below query to update it like as you wanted:'], ['-10000']], [[' Update tbl_SO_19\nset col4 = t.col1\nfrom tbl_SO_19 join tbl_SO_19 t on t.col2=tbl_SO_19.col2 and t.col3=1\nwhere tbl_SO_19.col3 = 0\n']], ['Update column according to another column'], 2, 1], [(28474871, 0), [["Isn't this just a plain group by?"], ['If contents also is required:']], [[' SELECT a, b, c, d, MAX(issue)\nFROM tablename\nGROUP BY a, b, c, d\n']], ['Select multiple records grouped by primary key with max value on a column'], 2, 1], [(28474871, 1), [['If contents also is required:'], ["Will list both rows if it's a tie!"]], [[' SELECT a, b, c, d, issue, contents\nFROM tablename t1\nWHERE issue = (select max(issue) from tablename t2\n               where t1.a = t2.a\n                 and t1.b = t2.b\n                 and t1.c = t2.c\n                 and t1.d = t2.d)\n']], ['Select multiple records grouped by primary key with max value on a column'], 2, 1], [(28481148, 0), [['Query:'], ['Result:']], [[' WITH A\nAS (\n    SELECT id\n        ,trancode\n        ,trandate\n        ,lead(trancode) OVER (ORDER BY id,trancode) leadcode\n    FROM #t\n    )\n    ,cte\nAS (\n    SELECT id\n        ,trandate\n        ,trancode\n        ,lead(trancode) OVER (ORDER BY id,trancode) leadcode\n        ,1 batchnum\n        ,1 nextbatchnum\n        ,id + 1 nxtId\n    FROM #t\n    WHERE id = 1\n\n    UNION ALL\n\n    SELECT A.id\n        ,A.trandate\n        ,A.trancode\n        ,A.leadcode\n        ,nextbatchnum\n        ,CASE \n            WHEN A.trancode <> A.leadcode THEN nextbatchnum + 1 ELSE nextbatchnum END nextbatchnum\n        ,A.id + 1 nxtid\n    FROM A\n    INNER JOIN CTE B ON A.id = B.nxtId\n    )\nSELECT id\n    ,trandate\n    ,trancode\n    ,batchnum\nFROM CTE\nOPTION (MAXRECURSION 100)\n']], ['Set based solution to generate batch number based on proximity and type of record in SQL server'], 2, 1], [(28481148, 1), [['Result:'], ['-10000']], [[' id  trandate    trancode    batchnum\n1   2015-02-12 10:19:06.717 1   1\n2   2015-02-12 10:20:06.717 1   1\n3   2015-02-12 10:21:06.717 1   1\n4   2015-02-12 10:22:06.717 1   1\n5   2015-02-12 10:23:06.717 2   2\n6   2015-02-12 10:24:06.717 2   2\n7   2015-02-12 10:25:06.717 2   2\n8   2015-02-12 10:26:06.717 2   2\n9   2015-02-12 10:27:06.717 2   2\n10  2015-02-12 10:28:06.717 1   3\n11  2015-02-12 10:29:06.717 1   3\n12  2015-02-12 10:30:06.717 1   3\n13  2015-02-12 10:31:06.717 2   4\n14  2015-02-12 10:32:06.717 2   4\n15  2015-02-12 10:33:06.717 1   5\n16  2015-02-12 10:34:06.717 1   5\n17  2015-02-12 10:35:06.717 1   5\n18  2015-02-12 10:36:06.717 2   6\n19  2015-02-12 10:37:06.717 2   6\n20  2015-02-12 10:38:06.717 1   7\n21  2015-02-12 10:39:06.717 1   7\n22  2015-02-12 10:40:06.717 1   7\n23  2015-02-12 10:40:06.717 1   7\n']], ['Set based solution to generate batch number based on proximity and type of record in SQL server'], 2, 0], [(28483426, 0), [["You'll need to use some conditional logic in your  ORDER BY .  This will sort the data in the specific order that you want,  Red  always being last:"], ['This could also be written testing for the Colour being equal to  Red  first:']], [[" SELECT id, colour\nFROM colours\nORDER BY \n  CASE \n    WHEN colour <> 'Red' \n    THEN 1 ELSE 2 END, colour;\n"]], ['Specify value to appear last in ordered results'], 3, 1], [(28483426, 1), [['This could also be written testing for the Colour being equal to  Red  first:'], ['See  Demo . Both versions will return:']], [[" SELECT id, colour\nFROM colours\nORDER BY \n  CASE \n    WHEN colour = 'Red' \n    THEN 2 ELSE 1 END, colour;\n"]], ['Specify value to appear last in ordered results'], 3, 1], [(28483426, 2), [['See  Demo . Both versions will return:'], ['-10000']], [[' | ID | COLOUR |\n|----|--------|\n|  1 |   Blue |\n|  4 |  Green |\n|  5 | Orange |\n|  6 |   Teal |\n|  3 | Yellow |\n|  2 |    Red |\n']], ['Specify value to appear last in ordered results'], 3, 0], [(28537722, 0), [["Amend the Query Field (Note i'm referring to field and not criteria)\nFor the first Text Box Assuming name is COD and Field Name is also COD\nIf the Current field name is COD insert another field with the same name and amend to"], ['For the second Text Box Assuming name is COD2 and Field Name is also COD2\nIf the Current field name is COD2 insert another field with the same name and amend to ']], [['   [COD]=[Forms]![frmRICmp]![cod] OR [Forms]![frmRICmp]![cod] Is NULL\nthen in the criteria field use the following value\n  TRUE\n']], ['Multisearch form for a query in access'], 2, 0], [(28537722, 1), [['For the second Text Box Assuming name is COD2 and Field Name is also COD2\nIf the Current field name is COD2 insert another field with the same name and amend to '], ['and continue the same process for all 4 text boxes.']], [[' [COD2]=[Forms]![frmRICmp]![cod2] OR [Forms]![frmRICmp]![cod2] Is NULL\nthen in the criteria field use the following value\n  TRUE\n']], ['Multisearch form for a query in access'], 2, 0], [(28544816, 0), [["I didn't think this was possible with a single statement, but it turns out it is, as shown  in the examples in the documentation :"], ['A complete example:\n    ALTER TABLE MY_TABLE ADD UNIQUE (col1, col2);']], [[' ALTER TABLE MY_TABLE DROP UNIQUE(col1, col2);\n']], ['How to remove constraint based on columns from oracle database?'], 2, 1], [(28566000, 0), [['What you want to do instead is parse the string as a hexadecimal representation of the bytes ( 00 03 f8 00 75 71 77 fe 66 ).  CONVERT  accepts an extra "style" parameter that allows you to convert hexstrings:'], ['Note that if there are less than 16 bytes (as in this case), the value is right-padded with zeroes ( 0x0003F80075177FE60000000000000000 ). If you need it left-padded instead, you have to do that yourself:']], [[" SELECT CONVERT(BINARY(16), '0003f80075177fe6', 2)\n"]], ['Convert a BINARY stored as VARCHAR to BINARY'], 2, 1], [(28566000, 1), [['Note that if there are less than 16 bytes (as in this case), the value is right-padded with zeroes ( 0x0003F80075177FE60000000000000000 ). If you need it left-padded instead, you have to do that yourself:'], ['Finally, note that binary literals can be specified without conversion simply by prefixing them with "0x" and not using quotes:  SELECT 0x0003f80075177fe6  will return a column of type  BINARY(8) . Not relevant for this query, but just for completeness. ']], [[" SELECT CONVERT(BINARY(16), RIGHT(REPLICATE('00', 16) + '0003f80075177fe6', 32), 2)\n"]], ['Convert a BINARY stored as VARCHAR to BINARY'], 2, 1], [(28611170, 1), [["If you're query script and script.pl must be separate but are both Perl scripts you can have the query script run script.pl for you using system().\nAssuming your arguments are separated by / you could do something like this in  your query script:"], ['Then in script.pl you can just loop through @_:']], [[' #!/usr/bin/perl\n\n#query code to get arguments\n$arguments =~ s/\\// /;\n\nsystem ("perl /path/to/script.pl $arguments") or die ("Something went wrong: $?\\n");\n']], ['loop select results as arguments for script'], 3, 0], [(28611170, 2), [['Then in script.pl you can just loop through @_:'], ["Here's the link to perldoc for using  system .  Although I'd only recommend this approach if everything is internal."]], [[' #!/usr/bin/perl\n\nfor my $arg (@_)\n{\n  #script.pl code\n}\n']], ['loop select results as arguments for script'], 3, 0], [(28619830, 0), [['If  timestamp  is a date/time column -- which it should be.  You should not be storing date/times as strings.  Then you can do:'], ['If your timestamp is stored as a string, it is in a sort-of reasonable format.  I would be inclined to translate it using a subquery and just use that.']], [[' SELECT DATE(timestamp), COUNT(eventid)\nFROM `tablex`\nWHERE timestamp >= date_sub(CURRENT_DATE, interval 30 day)\nGROUP BY DATE(timestamp) \n']], ['Querying and grouping by date (Y/m/j) when date is in a Y/m/j H:i:s format'], 2, 1], [(28619830, 1), [['If your timestamp is stored as a string, it is in a sort-of reasonable format.  I would be inclined to translate it using a subquery and just use that.'], ['Note that you can also use  str_to_date()  to convert the string to a date.  I just find it easier in this case to use  date()  and  replace() .']], [[" SELECT thedate, COUNT(eventid)\nFROM (select x.*, date(replace(left(timestamp, '/', '-'), 10) as thedate\n      from `tablex` x\n     ) x\nWHERE thedate >= date_sub(CURRENT_DATE, interval 30 day)\nGROUP BY thedate;\n"]], ['Querying and grouping by date (Y/m/j) when date is in a Y/m/j H:i:s format'], 2, 1], [(28628081, 0), [['To tell the database about candidate keys, you can create a unique index:'], ['Another way to tell the database about a candidate key is a unique constraint:']], [[' create table title (\n    id int primary key, \n    label varchar(50));\ncreate table customer (\n    id int primary key, \n    title varchar(50));\ncreate unique index ux_title_label on title(label);\nalter table customer add constraint fk_customer_title \n    foreign key (title) references title(label);\n']], ['Check Constraint Referencing Unique Column on another Table'], 2, 1], [(28628081, 1), [['Another way to tell the database about a candidate key is a unique constraint:'], ['-10000']], [[' alter table title add constraint uc_title_label unique (label);\n']], ['Check Constraint Referencing Unique Column on another Table'], 2, 1], [(28663276, 1), [['2) Otherwise, I would create a new table thus'], ['plus I would create a foreign key in order to be sure that categories from [customer] table exist also in [category] table:']], [[" CREATE TABLE category -- or dbo.cateogory (note: you should use object's/table's schema)\n(\n    categoryID INT NOT NULL,\n        CONSTRAINT PK_category_categoryID PRIMARY KEY(categoryID),\n    name NVARCHAR(50) NOT NULL -- you should use the propper type (varchar maybe) and max length (100 maybe)\n    --,      CONSTRAINT IUN_category_name UNIQUE(name) -- uncomment this line if you want to have unique categories (nu duplicate values in column [name])\n);\nGO\n"]], ['Change column datatype in SELECT in SQL Server'], 4, 0], [(28663276, 2), [['plus I would create a foreign key in order to be sure that categories from [customer] table exist also in [category] table:'], ['and your query will be']], [[" ALTER TABLE customer \nADD CONSTRAINT FK_customer_categoryID \nFOREIGN KEY (categoryID) REFERENCES category(categoryID)\nGO\n\nINSERT category (categoryID, name)\nSELECT 1, 'First category' UNION ALL\nSELECT 2, 'Second category' UNION ALL\nSELECT 3, 'Third category'\nGO\n"]], ['Change column datatype in SELECT in SQL Server'], 4, 0], [(28663276, 3), [['and your query will be'], ['I would use solution #2.']], [[' SELECT  c.name, c.categoryID, ctg.name AS category_name\nFROM    customer c\nINNER JOIN ctg ON c.categoryID = ctg.categoryID -- or LEFT JOIN if c.categoryID allows NULLs \n']], ['Change column datatype in SELECT in SQL Server'], 4, 0], [(28675581, 0), [['Simply include the columns you need sorted in the  ORDER BY  clause.  It looks like you have three metadata columns that constitute year, month, and day. So try this:'], ["Now look, meta_values are text.  Your months and days (mt2, mt3) values might look like '1', '2' ... '10', '11' etc.  In that case you have to trick MySQL into thinking your values are numbers, or your sorting will come up wonky. This is easy: add zero to the text value. This will typecast your text to integer. The  TRIM()  function gets rid of leading and trailing spaces."]], [[' ORDER BY mt1.meta_value DESC, \n         mt2.meta_value DESC,\n         mt3.meta_value DESC\nLIMIT 0, 10 \n']], ['Multi column ORDER BY for wp_postmeta values'], 5, 1], [(28675581, 1), [["Now look, meta_values are text.  Your months and days (mt2, mt3) values might look like '1', '2' ... '10', '11' etc.  In that case you have to trick MySQL into thinking your values are numbers, or your sorting will come up wonky. This is easy: add zero to the text value. This will typecast your text to integer. The  TRIM()  function gets rid of leading and trailing spaces."], ['Or, as Marcus suggested, you could use a  DATE  object for ordering. You can make a date object out of your three metadata columns like this:']], [[' ORDER BY 0+TRIM(mt1.meta_value) DESC, \n         0+TRIM(mt2.meta_value) DESC,\n         0+TRIM(mt3.meta_value) DESC\nLIMIT 0, 10 \n']], ['Multi column ORDER BY for wp_postmeta values'], 5, 1], [(28675581, 3), [['This is cool because you can then order by it, like so:'], ['You can also use it in WHERE clauses with date arithmetic, for example ....']], [["  ORDER BY STR_TO_DATE(CONCAT_WS('-',\n                       TRIM(mt1.meta_value),\n                       TRIM(mt2.meta_value),\n                       TRIM(mt3_meta_value)),\n             '%Y-%m-%d) DESC\n"]], ['Multi column ORDER BY for wp_postmeta values'], 5, 1], [(28675581, 4), [['You can also use it in WHERE clauses with date arithmetic, for example ....'], ['-10000']], [['  WHERE (thatBigDateExpression) >= NOW() - INTERVAL 2 MONTH\n']], ['Multi column ORDER BY for wp_postmeta values'], 5, 0], [(28679208, 0), [['You need to use a case statement, eg. something like:'], ['Output:']], [[" create table test1 (col1 varchar2(2),\n                    col2 number);\n\nalter table test1 add constraint test1_chk check (col2 < case when col1 = 'A' then 50\n                                                              when col1 = 'B' then 100\n                                                              when col1 = 'C' then 150\n                                                              else col2 + 1\n                                                         end);\n\ninsert into test1 values ('A', 49);\ninsert into test1 values ('A', 50);\ninsert into test1 values ('B', 99);\ninsert into test1 values ('B', 100);\ninsert into test1 values ('C', 149);\ninsert into test1 values ('C', 150);\ninsert into test1 values ('D', 5000);\n\ncommit;\n"]], ['Add multiple CHECK constraints on one column depending on the values of another column'], 2, 1], [(28679208, 1), [['Output:'], ['-10000']], [[" 1 row created.\n\ninsert into test1 values ('A', 50)\nError at line 2\nORA-02290: check constraint (MY_USER.TEST1_CHK) violated\n\n1 row created.\n\ninsert into test1 values ('B', 100)\nError at line 4\nORA-02290: check constraint (MY_USER.TEST1_CHK) violated\n\n1 row created.\n\ninsert into test1 values ('C', 150)\nError at line 6\nORA-02290: check constraint (MY_USER.TEST1_CHK) violated\n\n1 row created.\n\nCommit complete.\n"]], ['Add multiple CHECK constraints on one column depending on the values of another column'], 2, 0], [(28698635, 0), [['You can use  case  with  lead  and  lag :'], ['Results:']], [[" SELECT   D.*,\n         CASE\n            WHEN LAG (D1) OVER (ORDER BY D1) IS NOT NULL\n                 AND (LAG (D1) OVER (ORDER BY D1), LAG (D2) OVER (ORDER BY D1))\n                       OVERLAPS (D1, D2)\n                 OR LEAD (D1) OVER (ORDER BY D1) IS NOT NULL\n                   AND (LEAD (D1) OVER (ORDER BY D1),\n                        LEAD (D2) OVER (ORDER BY D1))\n                         OVERLAPS (D1, D2)\n            THEN\n               'S'\n            ELSE\n               'N'\n         END\n            OVERLAP\n  FROM   MYDATA D;\n"]], ['Oracle query using Window function'], 2, 1], [(28698635, 1), [['Results:'], ['-10000']], [[' NAME                                               D1        D2        OVERLAP\n-------------------------------------------------- --------- --------- -------\nA                                                  01-JAN-10 02-MAR-10 N      \nB                                                  03-MAR-10 20-MAR-10 S      \nC                                                  10-MAR-10 20-SEP-10 S      \nD                                                  10-DEC-10 31-DEC-10 N  \n']], ['Oracle query using Window function'], 2, 0], [(28749544, 0), [['-10000'], ['-10000']], [[' declare @prices table\n(\n    id int identity(1,1),\n    item int,\n    Qty int,\n    Price float\n)\n\ndeclare @orders table\n(\n    id int identity(1000,1),\n    item int,\n    item_qty int\n)\n\ninsert into @prices (item, Qty, Price)\nvalues \n(525001,1, 59),\n(525001,8, 55),\n(525001,13, 45)\n\ninsert into @orders (item, item_qty)\nvalues\n(525001,9),\n(525001,2),\n(525001,50000)\n']], ['Trying to get pricing from quantity breakdown'], 2, 0], [(28749544, 1), [['-10000'], ['-10000']], [[' select Id, max(Price) as retail_price, sum(Item_qty) as items_sold, count(IdOrder) as orders_count\n from\n(\n    select \n        o.item_qty,\n        o.Id as idOrder,\n        p.*,\n        ROW_NUMBER() over (partition by o.Item, o.Id order by p.Qty desc) as num\n    from @orders o\n    join @prices p on p.Item = o.Item and p.Qty <= o.item_qty   \n) T\nwhere t.num = 1\ngroup by id, item\n\n/* \nId  retail_price    items_sold  orders_count\n1   59              2           1\n2   55              9           1\n3   45              50000       1\n*/\n']], ['Trying to get pricing from quantity breakdown'], 2, 1], [(28752104, 0), [['Use row_number analytical function instead:'], ['Output:']], [[" with t(person  ,Mgr_name ,   Mgr_email) as (\nselect 111     ,'brad,pitt'  , 'pitt.brad@test.com' from dual union all\nselect 111     ,'mike,clark' , 'clark.mike@test.com' from dual )\n\nselect person  ,Mgr_name ,   Mgr_email from (\nselect t1.*, row_number() over (order by mgr_name) num from t t1)\nwhere num = 1\n"]], ['Oracle aggregate functions on strings'], 2, 1], [(28752104, 1), [['Output:'], ['-10000']], [['     PERSON MGR_NAME   MGR_EMAIL          \n---------- ---------- -------------------\n       111 brad,pitt  pitt.brad@test.com \n']], ['Oracle aggregate functions on strings'], 2, 0], [(28775590, 0), [['First to unpivot your record(s):'], ['Next, we can assign a ranking to the values based on what we want to see output. To rank the largest column value for an ID 1st, we add:']], [[' select id\n       , columnName\n       , columnValue\nfrom mytable\n     unpivot\n     (\n        columnValue for columnName in(a,b,c)\n     ) as unpvt\n']], ['Get greatest value between columns and associated column name'], 3, 0], [(28775590, 1), [['Next, we can assign a ranking to the values based on what we want to see output. To rank the largest column value for an ID 1st, we add:'], ['Now that we have our values ranked, we can select what we want from that result set:']], [[' select id\n       , columnName\n       , columnValue\n       , rank() over (partition by id order by columnValue DESC, columnName DESC) as rankVal\n    from mytable\n    unpivot\n    (\n        columnValue for columnName in(a,b,c)\n    ) as unpvt\n']], ['Get greatest value between columns and associated column name'], 3, 0], [(28805092, 0), [['You can create scalar function:'], ['And then add new computed column:']], [[' ALTER FUNCTION [dbo].[Test] ( @column1 INT, @column2 INT)\nRETURNS INT\n    WITH SCHEMABINDING\nAS\n    BEGIN\n\n        DECLARE @r INT\n\n        IF @column1 = 15 AND @column2 = 3\n            SET @r = 100\n        ELSE\n            SET @r = NULL\n\n        RETURN @r\n    END\n']], ['Populate extra database column depending on other column values'], 3, 0], [(28805092, 1), [['And then add new computed column:'], ['You can also update your current data with simple update statement like in @Rhys Jones answer and add trigger on table like:']], [[' ALTER TABLE TableName ADD ColumnName AS dbo.Test(column1, column2) PERSISTED\n']], ['Populate extra database column depending on other column values'], 3, 0], [(28840985, 0), [['My favorite, correlated sub-query to get count:'], ['Or, a join with a group by;']], [[" CREATE VIEW [dbo].[Question]\nAS\nSELECT (select COUNT(*) from Answers\n        where QuestionId = question.Id) as 'Answers',\n       question.Id,\n       question.CreatorId,\n       question.Title,\n       question.Content,\n       question.CreationDate\nFROM Questions AS question;\n"]], ['Add rows count in SQL view'], 2, 1], [(28840985, 1), [['Or, a join with a group by;'], ['Note that columns in select list are either argument to aggregate functions, or also listed in GROUP BY clause.']], [[" CREATE VIEW [dbo].[Question]\nAS\nSELECT COUNT(answer.Id) as 'Answers',\n       question.Id,\n       question.CreatorId,\n       question.Title,\n       question.Content,\n       question.CreationDate\nFROM Questions AS question \nJOIN Answers AS answer\nON  answer.QuestionId = question.Id\nGROUP BY question.Id,\n         question.CreatorId,\n         question.Title,\n         question.Content,\n         question.CreationDate;\n"]], ['Add rows count in SQL view'], 2, 1], [(28845170, 0), [['You could to this using a  CURSOR  and  Dynamic SQL :'], ['RESULT']], [[" DECLARE @sql VARCHAR(MAX) = ''\nDECLARE @tableName VARCHAR(100)\n\nDECLARE cur CURSOR LOCAL FORWARD_ONLY FOR\n    SELECT TableName FROM TablesWithAuditLogs\n\nOPEN cur\nFETCH FROM cur INTO @tableName\n\nWHILE @@FETCH_STATUS = 0 BEGIN\n    SELECT @sql ='\n    UPDATE t\n        SET t.CreatedOn = a.CreatedOn\n    FROM [' + @tableName + '] t\n    INNER JOIN AuditLog a\n        ON a.ID = t.AuditLogID'\n\n    EXEC(@sql)\n\n    FETCH FROM cur INTO @tableName\nEND\n\nCLOSE cur\nDEALLOCATE cur\n"]], ['SQL Server 2008 - Migrating AuditLog table to each table'], 2, 1], [(28845170, 1), [['RESULT'], ['SQL FIDDLE']], [[' Contacts\n----------------------------------\nID          AuditLogID  CreatedOn\n----------- ----------- ----------\n10          1           2015-01-02\n11          3           2015-05-06\n\nAddresses\n----------------------------------\nID          AuditLogID  CreatedOn\n----------- ----------- ----------\n20          4           2014-02-01\n21          5           2010-01-01\n\nItems\n----------------------------------\nID          AuditLogID  CreatedOn\n----------- ----------- ----------\n30          2           2015-03-04\n31          6           2011-03-04\n']], ['SQL Server 2008 - Migrating AuditLog table to each table'], 2, 0], [(28846567, 0), [['Simple Boolean algebra. Your current query is this:'], ["and, if I'm reading your requirements correctly, you want it to be this:"]], [[' valueA = a_tble.id and valueB <> b_tble.id\n']], ['chaining AND EXISTS/AND NOT EXISTS in SQL'], 3, 0], [(28846567, 1), [["and, if I'm reading your requirements correctly, you want it to be this:"], ['which translates into:']], [[' valueA = a_tble.id and (valueB <> b_tble.id or valueC <> c_tble.id)\n']], ['chaining AND EXISTS/AND NOT EXISTS in SQL'], 3, 0], [(28846567, 2), [['which translates into:'], ['-10000']], [[' WHERE EXISTS (SELECT 1 FROM a_tbl WHERE valueA = a_tbl.id)\n    AND (NOT EXISTS (SELECT 1 FROM b_tbl WHERE valueB = b_tbl.id)\n     OR  NOT EXISTS (SELECT 1 from c_tbl WHERE valueC = c_tbl.id))\n']], ['chaining AND EXISTS/AND NOT EXISTS in SQL'], 3, 1], [(28848937, 0), [['You might be better of using group_concat:'], ['And in your code, just replace the separator:']], [[' $query = mysql_query("\nSELECT \n    customer.customerId, customer.customerName, order.orderNo, group_concat(order.item SEPARATOR \',\') as order_items\nFROM \n    customer\nINNER JOIN\n    orderInfo on orderInfo.customerId = customer.customerId\nGROUP BY customer.customerId\n");\n']], ['Remove duplicate row from output table'], 2, 1], [(28848937, 1), [['And in your code, just replace the separator:'], ["You won't need rowspan=2 in this case."]], [[" while($order = mysql_fetch_assoc($query))\n{\n echo '<tr>\n  <td>'.$order['orderNo'].'</td>\n  <td>'.$order['customerName'].'</td>\n  <td>'.str_replace(',','<br/>',$order['item']).'</td>\n </tr>';\n}\n"]], ['Remove duplicate row from output table'], 2, 0], [(28927069, 0), [['As both join columns have the same name, you can use the  using  operator in the join which does exactly that: remove the duplicate columns.'], ['-10000']], [[' select *\nfrom a\n  full outer join b using (id);\n']], ['How to full join two tables and return one column for joined field in sql?'], 2, 1], [(28961739, 0), [['You can use  count  in analytic version:'], ['Results:']], [[' select f1, f2 \n  from (\n    select tab.*, count(1) over (partition by f1) cnt from tab \n    ) \n  where cnt>1\n']], ['Select DB records where some key values are the same'], 2, 1], [(28961739, 1), [['Results:'], ['-10000']], [[' F1            F2\n----- ----------\nb            123\nb            456\nc            123\nc            789\n']], ['Select DB records where some key values are the same'], 2, 0], [(28986618, 0), [['Try this:'], ['Result:']], [[" DECLARE @t table(MES_id int, MES_for_col varchar(max))\nINSERT @t values\n(4717, '4717 = ( 4711 + 4712 + 4713)/ 3'),\n(4729, '4729 = ( 4723 + 4724 + 4725 + 4726)/4'),\n(4788, '4788 = ( 4780 + 4781 + 4782 + 4783 + 4784 + 4785 )/6'),\n(4795, '4795 = ( 4793 + 4794 ) / 2')\n\nSELECT MES_id, t.c.value('.', 'VARCHAR(2000)') as column2\nFROM (\n    SELECT MES_id, x = CAST('<t>' + \n        REPLACE(REPLACE(REPLACE(REPLACE(STUFF(SUBSTRING(MES_for_col, 0,\n        CHARINDEX('/', MES_for_col)), 1, CHARINDEX('=', MES_for_col), ''), \n        ' ', ''), ')', ''), '(', ''),  '+', '</t><t>') + '</t>' AS XML)\n    FROM @t\n) a\nCROSS APPLY x.nodes('/t') t(c)\n"]], ['SQL- Need numbers from a column for string'], 2, 1], [(28986618, 1), [['Result:'], ['-10000']], [[' MES_id  column2\n4717    4711\n4717    4712\n4717    4713\n4729    4723\n4729    4724\n....\n']], ['SQL- Need numbers from a column for string'], 2, 0], [(29012160, 1), [["Following your comment, if the min/max(ID) approach isn't viable then you could use NOT IN;"], ["Following the updated question, if I've understood the mapping between the initial example and reality correctly then the query should be something like this;"]], [[" select user\nfrom table\nwhere user not in (select user from table where ID = 'D')\ngroup by user\nhaving count(*) = 3\n"]], ['SQL - I need to see how many users are associated with a specific set of ids'], 3, 1], [(29012160, 2), [["Following the updated question, if I've understood the mapping between the initial example and reality correctly then the query should be something like this;"], ["What is odd is that you appear to have both a table and a column in the table with the same name 'user_id_type'. This isn't the clearest of designs."]], [[" SELECT user_id\nFROM user_id_type\nWHERE user_id not in (select user_id from user_id_type where user_id_type in ('1','2','3','4','5'))\nGROUP BY user_id\nHAVING COUNT(user_id_type)='16'\n"]], ['SQL - I need to see how many users are associated with a specific set of ids'], 3, 1], [(29027827, 1), [['Example output without the  -s  flag:'], ['Example with the  -s  flag:']], [[' oracle@***:/home/oracle/testing> sh test.sh\n\nSQL*Plus: Release 11.2.0.3.0 Production on Fri Mar 13 08:12:21 2015\n\nCopyright (c) 1982, 2011, Oracle.  All rights reserved.\n\nEnter user-name:\nConnected to:\nOracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit Production\nWith the Partitioning, OLAP, Data Mining and Real Application Testing options\n\nSQL> SQL> SQL> SQL> SQL> SQL> SQL> SQL> testing\nSQL> Disconnected from Oracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit Production\nWith the Partitioning, OLAP, Data Mining and Real Application Testing options\n']], ['How can I change the output of SqlPlusresults with PLSQL?'], 3, 0], [(29027827, 2), [['Example with the  -s  flag:'], ['-10000']], [[' oracle@XXX:/home/oracle/testing> sh test.sh\ntesting\n']], ['How can I change the output of SqlPlusresults with PLSQL?'], 3, 0], [(29065148, 0), [['On the other hand, a few triggers are created for a foreign key:'], ['Interestingly enough, MonetDB creates indexes of different types for primary and foreign keys (probably join-index and hash-index, respectively). ']], [[" test=# SELECT tgname AS trigger_name\n  FROM pg_trigger\n WHERE tgname !~ '^pg_';\n trigger_name\n--------------\n(0 rows)\n\ntest=# ALTER TABLE LINEITEM ADD CONSTRAINT LINEITEM_FK1 FOREIGN KEY (L_ORDERKEY)  REFERENCES ORDERS;\nALTER TABLE\ntest=# SELECT tgname AS trigger_name                                                               \n  FROM pg_trigger\n WHERE tgname !~ '^pg_';\n         trigger_name        \n------------------------------\n RI_ConstraintTrigger_a_16419\n RI_ConstraintTrigger_a_16420\n RI_ConstraintTrigger_c_16421\n RI_ConstraintTrigger_c_16422\n"]], ['Database internals: implementation of a foreign key constraint'], 2, 1], [(29065148, 1), [['Interestingly enough, MonetDB creates indexes of different types for primary and foreign keys (probably join-index and hash-index, respectively). '], ["What's more, Oracle enforces primary key constraints using indexes and by default it does not create any index for a foreign key, however, there are some foreign key indexing tips:  https://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:292016138754"]], [[' sql>select * from sys.idxs;\n+------+----------+------+-------------+\n| id   | table_id | type | name        |\n+======+==========+======+=============+\n| 6467 |     6446 |    0 | orders_pk   |\n| 6470 |     6464 |    1 | lineitem_fk |\n+------+----------+------+-------------+\n2 tuples (3.921ms)\n']], ['Database internals: implementation of a foreign key constraint'], 2, 0], [(29113209, 0), [["Based on @warheat1990's answer, you just have to change the connection string. But @warheat1990's answer had a little too much change. So here's my original (LocalDb) connection string:"], ['To connect it to SQL Server instead of LocalDB, I modified the connection string into:']], [[' <add name="DefaultConnection"\n     connectionString="Data Source=(LocalDb)\\v11.0;AttachDbFilename=|DataDirectory|\\aspnet-my_project-20150318100658.mdf;Initial Catalog=my_project-20150318100658;Integrated Security=True"\n     providerName="System.Data.SqlClient"/>\n']], ['How to transfer ASP.NET MVC Database from LocalDb to SQL Server?'], 2, 0], [(29113209, 1), [['To connect it to SQL Server instead of LocalDB, I modified the connection string into:'], ['Thanks to @warheat1990 for the idea of simply changing the Web.config. My first thoughts were to identify and use the feature that VS supplies, if theres any. Because Microsoft doesnt have a concise documentation on how to do this.']], [[' <add name="DefaultConnection"\n     connectionString="Data Source=SERVERNAME\\SQLEXPRESS;Initial Catalog=my_project;Integrated Security=True"\n     providerName="System.Data.SqlClient"/>\n']], ['How to transfer ASP.NET MVC Database from LocalDb to SQL Server?'], 2, 0], [(29141134, 0), [['You could  JOIN   Table1  and  Table2  tables and use  UPDATE  on  Table2  table. '], ['-10000']], [[' UPDATE Table2\nSET Id = (\n          SELECT Id\n          FROM Table1 t1 \n          JOIN Table2 t2\n             ON (t1.Group = t2.Group) AND\n                (t1.StartDate = t2.Date) AND\n                (t1.StartTime = t2.Time)\n          )\n']], ['SQL: Link 2 data sources by Date'], 2, 1], [(29141134, 1), [['-10000'], ['-10000']], [[' UPDATE Table2 t2\nJOIN Table1 t1\nON (t1.Group = t2.Group) AND\n   (t1.StartDate = t2.Date) \nSET t2.Id = t1.Id\nWHERE t2.time BETWEEN t1.StartTime AND t1.EndTime\n']], ['SQL: Link 2 data sources by Date'], 2, 1], [(29169309, 0), [['I would use a denormalized version of #2. Have a  like  document:'], ['With an index on  { "account_id" : 1, "ts" : 1 } , you can efficiently find  like  documents for a specific user ordered by like time. ']], [[' {\n    "_id" : ObjectId(...),\n    "account_id" : 1234,\n    "post_id" : 4321,\n    "ts" : ISODate(...),\n    // additional info about post needed for basic display\n    "post_title" : "The 10 Worst-Kept Secrets of Cheesemongers"\n    // etc.\n}\n']], ['Query and Sort in MongoDB for a many-to-many relationship'], 2, 1], [(29169309, 1), [['With an index on  { "account_id" : 1, "ts" : 1 } , you can efficiently find  like  documents for a specific user ordered by like time. '], ["If you put the basic info about the post into the  like  document, you don't need to retrieve the post document until, say, the user clicks on a link to be shown the entire post."]], [[' db.likes.find({ "account_id" : 1234 }).sort({ "ts" : -1 })\n']], ['Query and Sort in MongoDB for a many-to-many relationship'], 2, 0], [(29240487, 0), [["We'll do this in two steps."], ["Unfortunately, MySql doesn't support CTEs (Common Table Expressions). Here's a version that will work with MySql:"]], [[' --Step 1: Find records the violate the rule\nWith BadIDs AS (\n    --IDs where there is another record with a matching ID and lower number, but greater date\n    select t1.id\n    from [table] t1\n    inner join [table] t2 on t2.id = t1.id \n    where t1.number > t2.number and t1.numberDate < t2.numberDate\n)\n-- Step 2: All IDs not part of the first step:\nselect distinct ID from [table] WHERE ID NOT IN (select ID from BadIDs)\n']], ['How to SELECT (SQL) items only if they are in increasing order?'], 2, 1], [(29240487, 1), [["Unfortunately, MySql doesn't support CTEs (Common Table Expressions). Here's a version that will work with MySql:"], ['-10000']], [[' select distinct ID \nfrom [table] \nWHERE ID NOT IN \n (\n    select t1.id\n    from [table] t1\n    inner join [table] t2 on t2.id = t1.id \n    where t1.number > t2.number and t1.numberDate < t2.numberDate\n )\n']], ['How to SELECT (SQL) items only if they are in increasing order?'], 2, 1], [(29254576, 0), [['2- create thesaurus :'], ['3- create a stored procedure to read from my table [words] and create relationship between synonyms:']], [[" begin\n  ctx_thes.create_thesaurus ('MyThesaurus');\nend;\n"]], ['how to save synonyms in database ( Oracle Text )'], 3, 0], [(29254576, 1), [['3- create a stored procedure to read from my table [words] and create relationship between synonyms:'], ['4- rewrite my query to select synonyms:']], [[" create or replace procedure CreateSynonyms is\n  CURSOR syn_cur is    select s.name_abstract,w.root,w.word_abstract \n  from p words  w , synset s \n  where w.synset_id=s.synset_id and w.root<>s.name_abstract and w.word_abstract<> s.name_abstract\n  order by s.synset_id;\n  syn_rec syn_cur%rowtype;\nBEGIN\nOPEN syn_cur;\nLOOP\n  FETCH syn_cur into syn_rec;\n  EXIT WHEN syn_cur%notfound;\n  begin\n    ctx_thes.create_relation ('MyThesurus', syn_rec.name_abstract, 'syn', syn_rec.word_abstract);\n  END LOOP;\nEND;\n"]], ['how to save synonyms in database ( Oracle Text )'], 3, 0], [(29254576, 2), [['4- rewrite my query to select synonyms:'], ['Hope this will help someone ']], [[' select  /*+ FIRST_ROWS(1)*/  sentence_id,score(1) as sc, isn  \n          where contains(PROCESSED_TEXT,\'<query>\n<textquery>\n   search for somthing here\n <progression>\n <seq><rewrite>transform((TOKENS,  "{", "}", ","))</rewrite></seq>\n <seq><rewrite>transform((TOKENS,  "syn(", ",listing)", " , "))</rewrite>/seq>\n </progression>\n </textquery>\n <score datatype="INTEGER" algorithm="COUNT"/></query>\',1)>0 \n']], ['how to save synonyms in database ( Oracle Text )'], 3, 0], [(29272756, 0), [['For interchanging rows and columns, you need to  UNPIVOT (convert columns into row values) first and then  PIVOT (rows to columns) based on  UNPIVOT  result.'], ['Sometimes you cannot know the values in column  Group  in advance. In such case you need to using  Dynamic Sql . The first step in that is to get the values in the row  Group  to a variable.']], [[" -- Here is the result \nSELECT * FROM \n(\n    -- Unpivot here using CROSS APPLY\n    SELECT [Group],\n    [Values],COLNAMES \n    FROM YOURTABLE\n    CROSS APPLY(VALUES (Value1,'Value1'),(Value2,'Value2'),(Value3,'Value3'))\n    AS COLUMNNAMES([Values],COLNAMES)\n)TAB\nPIVOT\n(\n     -- Specify the values to hold in pivoted column\n     MIN([Values])\n     -- Specify the name of columns\n     FOR [Group] IN([A],[B],[C])\n)P\nORDER BY COLNAMES\n"]], ['Column to Row SQL syntax'], 3, 1], [(29272756, 1), [['Sometimes you cannot know the values in column  Group  in advance. In such case you need to using  Dynamic Sql . The first step in that is to get the values in the row  Group  to a variable.'], ['Now use the  PIVOT  query with  Dynamic Sql . Why we are using  Dynamic Sql  is because  Sql Server  cannot get the column names from the variable unless and otherwise  Dynamic Sql  is used. ']], [[" DECLARE @cols NVARCHAR (MAX)\n\nSELECT @cols = STUFF((SELECT ',' + QUOTENAME([Group]) \n            FROM \n            (\n                SELECT distinct [Group] from YOURTABLE\n            ) c\n            FOR XML PATH(''), TYPE\n            ).value('.', 'NVARCHAR(MAX)') \n        ,1,1,'')\n"]], ['Column to Row SQL syntax'], 3, 0], [(29272756, 2), [['Now use the  PIVOT  query with  Dynamic Sql . Why we are using  Dynamic Sql  is because  Sql Server  cannot get the column names from the variable unless and otherwise  Dynamic Sql  is used. '], ['-10000']], [[" DECLARE @query NVARCHAR(MAX)\nSET @query = '\n            SELECT * FROM \n             (\n                -- Unpivot here using CROSS APPLY\n                SELECT [Group],\n                [Values],COLNAMES \n                FROM YOURTABLE\n                CROSS APPLY(VALUES (Value1,''Value1''),(Value2,''Value2''),(Value3,''Value3''))\n                AS COLUMNNAMES([Values],COLNAMES)\n             ) x\n             PIVOT \n             (\n                 -- Specify the values to hold in pivoted column\n                 MIN([Values])\n                 -- Get the column names from variable\n                 FOR [Group] IN('+@cols+')\n            ) p            \n            ORDER BY COLNAMES;'     \n\nEXEC SP_EXECUTESQL @query\n"]], ['Column to Row SQL syntax'], 3, 0], [(29276354, 0), [['-10000'], ['Test data:']], [[" with t1 as (\n    select\n        one.GroupName,\n        one.GroupJobPoints,\n        (select cast(count(1) as float) from TableTwo where GroupName=one.GroupName and Gender='M')/(select cast(count(1) as float) from TableTwo where GroupName=one.GroupName) FracMale,\n        (select avg(Salary) from TableTwo where GroupName=one.GroupName) AvgSalary\n    from\n        TableOne one\n)\nselect\n    m.GroupName,\n    m.GroupJobPoints,\n    m.AvgSalary,\n    m.FracMale,\n    f.GroupName,\n    f.GroupJobPoints,\n    f.AvgSalary,\n    f.FracMale\nfrom\n    t1 m\n    cross join t1 f\nwhere\n    m.FracMale>=0.60\n    and f.FracMale<=0.40\n    and abs(f.GroupJobPoints-m.GroupJobPoints)/m.GroupJobPoints<=0.04\n    and m.AvgSalary>f.AvgSalary\n;\n"]], ['Select a gender dominated group from a pupulation where one gendergroup has lower average salary but higher jobPoints'], 2, 1], [(29276354, 1), [['Test data:'], ['Output from running all of the above:']], [[" if object_id('TableTwo') is not null drop table TableTwo;\nif object_id('TableOne') is not null drop table TableOne;\ncreate table TableOne (GroupName varchar(32), GroupJobPoints float, primary key (GroupName) );\ncreate table TableTwo (GroupName varchar(32) references TableOne(GroupName), Person_ID int, Gender char(1), Salary float, primary key (Person_ID) );\n\ninsert into TableOne (GroupName, GroupJobPoints ) values ('1',2000);\ninsert into TableOne (GroupName, GroupJobPoints ) values ('2',1950);\n\ndeclare @PersonID int = 0;\ndeclare @i int;\n\nset @i = 0; while (@i < 250) begin set @PersonID=@PersonID+1; insert into TableTwo (GroupName, Person_ID, Gender, Salary ) values ('1',@PersonID,'M',25000); set @i=@i+1; end;\nset @i = 0; while (@i < 50) begin set @PersonID=@PersonID+1; insert into TableTwo (GroupName, Person_ID, Gender, Salary ) values ('1',@PersonID,'F',25000); set @i=@i+1; end;\n\nset @i = 0; while (@i < 20) begin set @PersonID=@PersonID+1; insert into TableTwo (GroupName, Person_ID, Gender, Salary ) values ('2',@PersonID,'M',22000); set @i=@i+1; end;\nset @i = 0; while (@i < 300) begin set @PersonID=@PersonID+1; insert into TableTwo (GroupName, Person_ID, Gender, Salary ) values ('2',@PersonID,'F',22000); set @i=@i+1; end;\n"]], ['Select a gender dominated group from a pupulation where one gendergroup has lower average salary but higher jobPoints'], 2, 0], [(29292248, 0), [['I tried that "insert" can use indicator too, if you want to like this:'], ['If you want to insert NULL into var1, just make indicator < 0:']], [[' short var1_ind, var2_ind;\n\nvoid insert(){\n  EXEC SQL INSERT INTO mytable (var1, var2 ) \n  VALUE (:var1 INDICATOR :var1_ind, :var2 INDICATOR :var2_ind);\n}\n']], ['ecpg insert null with host variable (psotgreSQL)'], 2, 1], [(29292248, 1), [['If you want to insert NULL into var1, just make indicator < 0:'], ['after assign -1 to var1_ind, it would insert NULL to var1 in DB whetever the value of :var1 ']], [[' var1_ind = -1\n']], ['ecpg insert null with host variable (psotgreSQL)'], 2, 0], [(29312505, 0), [['One possible way to select all modules that the student has not registered for, assuming that the student no is  48377767  in this example :'], ['Different approach without  JOIN  :']], [[' SELECT m.*\nFROM Modules m\n     LEFT JOIN StudentsModules sm ON sm.ModuleCode = m.ModuleCode \n                                     AND sm.StudentNo = 48377767\nWHERE sm.ModuleCode IS NULL\n']], ['Select records that are not associated with the other record'], 2, 1], [(29312505, 1), [['Different approach without  JOIN  :'], ['-10000']], [[' SELECT m.*\nFROM Modules m\nWHERE m.ModuleCode NOT IN\n                   (\n                      SELECT ModuleCode\n                      FROM StudentsModules\n                      WHERE StudentNo = 48377767\n                    )\n']], ['Select records that are not associated with the other record'], 2, 1], [(29318004, 0), [['One way to do pagination by groups is to assign a product sequence to the query.  Using variables, this requires a subquery:'], ['With an index on  t(productid) , you can also do this with a subquery.  The condition can then go in a  having  clause:']], [[' select t.*\nfrom (select t.*,\n             (@rn := if(@p = productid, @rn + 1,\n                        if(@rn := productid, 1, 1)\n                       )\n             ) as rn\n      from table t cross join\n           (select @rn := 0, @p := -1) vars\n      order by t.productid\n     ) t\nwhere rn between X and Y;\n']], ['How to select certain numbers of groups in MySQL?'], 2, 1], [(29318004, 1), [['With an index on  t(productid) , you can also do this with a subquery.  The condition can then go in a  having  clause:'], ['-10000']], [[' select t.*,\n       (select count(distinct productid)\n        from t t2\n        where t2.productid <= t.productid)\n       ) as pno\nfrom t\nhaving pno between X and Y;\n']], ['How to select certain numbers of groups in MySQL?'], 2, 1], [(29359799, 0), [['You can use a CSV Splitter for this. Here is the  DelimitedSplit8K  function by Jeff Moden.'], ['Another approach using  NOT IN :']], [[" ;WITH CteDelimitted AS(\n    SELECT\n        t.ClassID,\n        nProdType = CAST(s.Item AS INT)\n    FROM Table2 t\n    CROSS APPLY dbo.DelimitedSplit8K(t.ExcludedList, ',') s\n),\nCteCross AS(\n    SELECT\n        t2.ClassID,\n        t1.nProdType,\n        t1.SprodDesc\n    FROM Table1 t1\n    CROSS JOIN(\n        SELECT DISTINCT ClassID FROM Table2\n    )t2\n\n)\nSELECT * \nFROM CteCross c\nWHERE NOT EXISTS(\n    SELECT 1\n    FROM CteDelimitted\n    WHERE\n        ClassID = c.ClassID\n        AND nProdType = c.nProdType\n)\nORDER BY ClassID, nProdType\n"]], ['Row data from a comma-delimited field used within a select query'], 2, 1], [(29359799, 1), [['Another approach using  NOT IN :'], ['SQL Fiddle']], [[" WITH Cte AS(\n    SELECT\n        t2.ClassID,\n        t1.nProdType,\n        t1.SprodDesc\n    FROM Table1 t1\n    CROSS JOIN(\n        SELECT DISTINCT ClassID FROM Table2\n    )t2\n)\nSELECT *\nFROM Cte c\nWHERE c.nProdType NOT IN(\n    SELECT CAST(s.Item AS INT)\n    FROM Table2\n    CROSS APPLY dbo.DelimitedSplit8K(ExcludedList, ',') s\n    WHERE ClassID = c.ClassID\n)\nORDER BY ClassID, nProdType\n"]], ['Row data from a comma-delimited field used within a select query'], 2, 1], [(29407378, 0), [['try this:'], ['and your life would be easier if your calf_parent table would consist of 3 columns:']], [[" SELECT a.*, cpmd.*, cpfd.*\nFROM dbo.ANIMAL a    \n  LEFT JOIN CALF_PARENT cpm ON a.ID = cpm.Calf AND cpm.IsMother = 'Y'\n  LEFT JOIN ANIMAL cpmd     ON cpmd.ID = cpm.Parent\n  LEFT JOIN CALF_PARENT cpf ON a.ID = cpf.Calf AND cpf.IsMother = 'N'\n  LEFT JOIN ANIMAL cpfd     ON cpfd.ID = cpf.Parent\n"]], ['Selecting Distinct Fields From Joined Rows'], 2, 1], [(29407378, 1), [['and your life would be easier if your calf_parent table would consist of 3 columns:'], ['-10000']], [[' Animal_ID (PK), Father_ID, Mother_ID\n']], ['Selecting Distinct Fields From Joined Rows'], 2, 0], [(29446361, 0), [['SQL Fiddle'], ['If cam_time is time_stamp type then condition should be:']], [[' select distinct t1.id, t1.cam_time \n  from test t1 join test t2 on t1.rowid <> t2.rowid  \n    and trunc(t1.cam_time) = trunc(t2.cam_time)\n  where abs(t1.cam_time-t2.cam_time) <= 2/24\n  order by t1.id\n']], ['select rows having time difference less than 2 hour of a single column'], 2, 1], [(29446361, 1), [['If cam_time is time_stamp type then condition should be:'], ['-10000']], [[" where t1.cam_time between t2.cam_time - interval '2' Hour \n                      and t2.cam_time + interval '2' Hour\n"]], ['select rows having time difference less than 2 hour of a single column'], 2, 0], [(29470119, 0), [['This would work:'], ["Or, as you're using a modern version of MSSQL you could use window functions:"]], [[" select [Room Nights],\n  count([Room Nights]) AS 'Count of RN',\n  cast(\n    (count([Room Nights])\n    /\n    (Select Count([Room Nights]) * 1.0 from HOLDINGS2) \n   ) * 100 as decimal(6,1)\n  ) as '% Distribution'    \nFROM HOLDINGS2\nGROUP BY [Room Nights]\n"]], ['SQL syntax to SUM a Count column for calculating percentage distribution'], 2, 1], [(29470119, 1), [["Or, as you're using a modern version of MSSQL you could use window functions:"], ['-10000']], [[' cast(count([Room Nights])/(sum(count([Room Nights])*1.0) over ()) * 100 as decimal(6,1))\n']], ['SQL syntax to SUM a Count column for calculating percentage distribution'], 2, 1], [(29474365, 0), [['You can use'], ['Replace  TABLE_NAME  with whatever name the table have. If you dont want all the  Ind1,Ind2,Ind3,Ind4  columns reported, use']], [[' SELECT Customer\n       , Date\n       , Ind1\n       , Ind2\n       , Ind3\n       , Ind4\n       , Ind1+Ind2+Ind3+Ind4 As Indicators\n  FROM TABLE_NAME\n']], ['Getting the Sum of Multiple Indicators by Row'], 2, 1], [(29474365, 1), [['Replace  TABLE_NAME  with whatever name the table have. If you dont want all the  Ind1,Ind2,Ind3,Ind4  columns reported, use'], ['-10000']], [[' SELECT Customer\n       , Date\n       , Ind1+Ind2+Ind3+Ind4 As Indicators\n  FROM TABLE_NAME\n']], ['Getting the Sum of Multiple Indicators by Row'], 2, 1], [(29487482, 0), [["While I don't understand the cause of this task, anyway you can do it like :"], ['Output:']], [[' DECLARE @t TABLE ( ID INT )\nDECLARE @c INT  = 8\n\nINSERT  INTO @t\nVALUES  ( 1 ),\n        ( 2 ),\n        ( 3 );\nWITH    cte\n          AS ( SELECT   1 AS rn\n               UNION ALL\n               SELECT   rn + 1\n               FROM     cte\n               WHERE    rn <= @c\n             )\n    SELECT TOP ( @c )\n            *\n    FROM    ( SELECT    ID\n              FROM      @t\n              UNION ALL\n              SELECT    NULL\n              FROM      cte\n            ) t\n    ORDER BY ID DESC      \n']], ['How to add blank rows when select query sql'], 2, 1], [(29487482, 1), [['Output:'], ['-10000']], [[' ID\n3\n2\n1\nNULL\nNULL\nNULL\nNULL\nNULL\n']], ['How to add blank rows when select query sql'], 2, 0], [(29489036, 0), [['use convert to  XML  and  cross apply :'], ['OUTPUT:']], [["   DECLARE @str varchar(50)\n  SET @str='John, Samantha, Bob, Tom'\n\n  SELECT names = y.i.value('(./text())[1]', 'nvarchar(1000)')             \n  FROM \n  ( \n    SELECT \n        n = CONVERT(XML, '<i>' \n            + REPLACE(@str, ',' , '</i><i>') \n            + '</i>')\n  ) AS a \n  CROSS APPLY n.nodes('i') AS y(i)\n"]], ['Split comma separated varchar parameter up into temp table'], 4, 1], [(29489036, 1), [['OUTPUT:'], ["EDIT:  it's not need to the temp table inside the proc so the proc will be:"]], [[' names\n-----\nJohn\n Samantha\n Bob\n Tom\n']], ['Split comma separated varchar parameter up into temp table'], 4, 0], [(29521617, 0), [['Your query seems overly complicated.  In most databases, you can use window functions for this:'], ["You don't specify a database so ANSI-compatible syntax seems reasonable."]], [[" SELECT msisdn, flex_soc,\n       coalesce(base_soc, 'Not Prov') as base_soc, plan_name, limit\nfrom (SELECT flex.msisdn, flex.product_name as Flex_Soc,\n             MAX(case when base_soc_boo = 'Y' then flex.product_name end) over\n                 (partition by flex.msisdn) as base_soc,\n            flex.plan_name, flex.limit\n      FROM table1 flex\n     ) flex\nwhere base_soc_boo = 'N';\n"]], ['using self joins to retrieve unique columns'], 2, 1], [(29521617, 1), [["You don't specify a database so ANSI-compatible syntax seems reasonable."], ['-10000']], [[' +----+--------+-----------+----------+-----------+-------+\n|    | MSISDN | FLEX_SOC  | BASE_SOC | PLAN_NAME | Limit |\n+----+--------+-----------+----------+-----------+-------+\n|  6 |    152 | THRWS33   | THRWS33  | ABC       | 10240 |\n|  7 |    152 | WADADJTH5 | THRWS33  | ABC       |  4092 |\n|  8 |    152 | WHOADJTH2 | THRWS33  | ABC       |  1024 |\n|  9 |    149 | WADADJTH4 | Not Prov | ABC       |   512 |\n| 10 |    149 | WADADJTH5 | Not Prov | ABC       |  1024 |\n+----+--------+-----------+----------+-----------+-------+\n']], ['using self joins to retrieve unique columns'], 2, 0], [(29533346, 0), [["That is, assuming that you're using MySQL or similar, you'll have to modify your statement as such:"], ['2.  Cast A.Code and B.Code to a binary string and compare the two. This is an simple way to compare two strings, byte-by-byte, thus achieving case-insensitivity.']], [[' SELECT Code, BrandName, Count(*) QTY, SUM(Price) TOTAL\nFROM A\nINNER JOIN B\nON A.Code=B.Code COLLATE latin1_bin\nGROUP BY Code, BrandName\n']], ['join 2 tables case sensitive upper and lower case'], 2, 1], [(29533346, 1), [['2.  Cast A.Code and B.Code to a binary string and compare the two. This is an simple way to compare two strings, byte-by-byte, thus achieving case-insensitivity.'], ['-10000']], [[' SELECT Code, BrandName, Count(*) QTY, SUM(Price) TOTAL\nFROM A\nINNER JOIN B\nON BINARY A.Code=B.Code\nGROUP BY Code, BrandName\n']], ['join 2 tables case sensitive upper and lower case'], 2, 1], [(29563877, 0), [['An alternative approach is to remove the characters after the string and before the string.  The following expression does this:'], ['This does assume that there is only one number in the string.  You can check this with a where clause like:']], [[" select val, \n       stuff(stuff(val+'x', patindex('%[0-9][^0-9.]%', val+'x') + 1, len(val), ''\n                  ), 1, patindex('%[0-9]%', val) - 1, '')\nfrom (values ('test123 xxx'), ('123.4'), ('123.4yyyyy'), ('tasdf 8.9'), ('asdb'), ('.2345')) as t(val);\n"]], ['T-SQL to pull decimal values from a string'], 2, 1], [(29563877, 1), [['This does assume that there is only one number in the string.  You can check this with a where clause like:'], ['-10000']], [[" where val not like '%[0-9]%[^0-9.]%[0-9]%'\n"]], ['T-SQL to pull decimal values from a string'], 2, 0], [(29598252, 0), [['Question 2: '], ['Question 1:']], [["    select s.sid, s.sname, s.gpa\n      from student s\n        inner join enroll e\n          on s.sid = e.sid\n      where e.dname = 'Civil Engineering'\n      group by sid\n      having count(distinct cno) = \n        (select count(cno) from course where dname = 'Civil Engineering');\n"]], ['SQL Query: For each department that has one or more majors with a GPA under 1.0, print the name of the department and the average GPA of its majors'], 3, 0], [(29598252, 1), [['Question 1:'], ['or']], [[' select d.dname, avg(s.gpa)\n  from dept d\n    inner join major m\n      on d.dname = m.dname\n    inner join student s\n      on s.sid = m.sid\n  group by d.dname\n  having min(s.gpa) < 1.0\n']], ['SQL Query: For each department that has one or more majors with a GPA under 1.0, print the name of the department and the average GPA of its majors'], 3, 1], [(29598252, 2), [['or'], ['Updated fiddle here:  http://sqlfiddle.com/#!9/d12f4/5']], [['   select m.dname, avg(s.gpa)\n    from major m\n      inner join student s\n        on s.sid = m.sid\n  group by m.dname\n  having min(s.gpa) < 1.0\n']], ['SQL Query: For each department that has one or more majors with a GPA under 1.0, print the name of the department and the average GPA of its majors'], 3, 1], [(29619943, 0), [['[EDIT]'], ['Above query returns:']], [[' SELECT src.ID, src.TicketNo, src.TicketQuantity, src.TicketRate, src.EnteredDate\nFROM (\n    SELECT TicketNo, MAX(EnteredDate) AS MaxEnteredDate\n    FROM Tickets\n    GROUP BY TicketNo\n ) AS mtn INNER JOIN Tickets AS src ON mtn.TicketNo = src.TicketNo AND mtn.MaxEnteredDate = src.EnteredDate\nORDER BY src.EnteredDate DESC\n']], ['Select Multiple distinct with Order By Date Clause'], 2, 1], [(29619943, 1), [['Above query returns:'], ['-10000']], [[' ID  TicketNo    TicketQuantity  TicketRate  EnteredDate\n6   3000        3               2           2015-01-11 18:27:39\n5   3002        6               2           2015-01-11 18:27:31\n2   3001        2               2           2015-01-11 18:27:15\n']], ['Select Multiple distinct with Order By Date Clause'], 2, 0], [(29628590, 0), [['I asked the same question on Moodle Developer Forums and got the answer from Stuart Mealor and Tim Hunt ( Moodle in English: Useful SQL Queries? ). In short, it is the following:'], ['The table and field names might depend on the Moodle version. In 2.5.9, the following statement worked for me:']], [[" UPDATE mdl_qtype_multichoice_options\nSET answernumbering = 'none'\nWHERE questionid IN (SELECT id FROM mdl_question WHERE category = 123)\n"]], ['SQL statement to set numbering style for all multiple choice questions in a Moodle course'], 2, 1], [(29628590, 1), [['The table and field names might depend on the Moodle version. In 2.5.9, the following statement worked for me:'], ['-10000']], [[" UPDATE mdl_question_multichoice\nSET answernumbering = 'none'\nWHERE question IN\n    (SELECT id FROM mdl_question\n     WHERE category = 7);\n"]], ['SQL statement to set numbering style for all multiple choice questions in a Moodle course'], 2, 1], [(29645733, 0), [['You can achieve It with  Common Table Expression  in following:'], ['OUTPUT']], [[" CREATE TABLE #Test\n(\n   Animal NVARCHAR(20),\n   CountAnimals INT,\n   Color NVARCHAR(20)\n)\n\nINSERT INTO #Test VALUES ('Dog', 2, 'brown'), ('Cat', 4, 'black');\n\nWITH CTE AS (\n    SELECT Animal,CountAnimals,Color FROM #Test\n\n    UNION ALL \n\n    SELECT  Animal,CountAnimals-1,Color\n\n    FROM CTE\n    WHERE CountAnimals >= 2\n)\nSELECT Animal,Color\nFROM CTE\nORDER BY Animal DESC\nOPTION (MAXRECURSION 0);\n\nDROP TABLE #Test\n"]], ['How to reverse a GROUP BY like table?'], 2, 1], [(29645733, 1), [['OUTPUT'], ['SQL FIDDLE']], [[' Animal  Color\n Dog    brown\n Dog    brown\n Cat    black\n Cat    black\n Cat    black\n Cat    black\n']], ['How to reverse a GROUP BY like table?'], 2, 0], [(29652394, 0), [['Biggest problem is the easter day, see here:  Computus .\nI think the most efficient way is to hard-code the dates and maintaine them manually.'], ['Then you can use the schedules like this:']], [[" BEGIN\n    DBMS_SCHEDULER.CREATE_SCHEDULE('New_Year', repeat_interval => 'FREQ=YEARLY;BYDATE=0101');\n\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Easter_Sunday',  repeat_interval => 'FREQ=YEARLY;BYDATE=20150405,    20160327,    20170416,    20170416,    20180401,    20190421,    20200412', comments => 'Hard coded till 2020');\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Good_Friday',    repeat_interval => 'FREQ=YEARLY;BYDATE=20150405-2D, 20160327-2D, 20170416-2D, 20170416-2D, 20180401-2D, 20190421-2D, 20200412-2D');\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Easter_Monday',   repeat_interval => 'FREQ=YEARLY;BYDATE=20150405+1D, 20160327+1D, 20170416+1D, 20170416+1D, 20180401+1D, 20190421+1D, 20200412+1D');\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Ascension_Day',   repeat_interval => 'FREQ=YEARLY;BYDATE=20150405+39D,20160327+39D,20170416+39D,20170416+39D,20180401+39D,20190421+39D,20200412+39D');\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Pentecost_Monday', repeat_interval => 'FREQ=YEARLY;BYDATE=20150405+50D,20160327+50D,20170416+50D,20170416+50D,20180401+50D,20190421+50D,20200412+50D');\n\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Repentance_and_Prayer', repeat_interval => 'FREQ=DAILY;BYDATE=1122-SPAN:7D;BYDAY=WED', \n        comments => 'Wednesday before November 23th, Buss- und Bettag');\n    -- alternative solution: \n    --DBMS_SCHEDULER.CREATE_SCHEDULE('Repentance_and_Prayer', repeat_interval => 'FREQ=MONTHLY;BYMONTH=NOV;BYDAY=3 WED', \n    --    comments => '3rd Wednesday in November');\n\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Labor_Day', repeat_interval => 'FREQ=YEARLY;BYDATE=0501');\n    DBMS_SCHEDULER.CREATE_SCHEDULE('German_Unity_Day', repeat_interval => 'FREQ=YEARLY;BYDATE=1003');\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Christmas', repeat_interval => 'FREQ=YEARLY;BYDATE=1225+SPAN:2D');\n\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Christian_Celebration_Days', repeat_interval => 'FREQ=DAILY;INTERSECT=Easter_Sunday,Good_Friday,Easter_Monday,Ascension_Day,Pentecost_Monday,Repentance_and_Prayer,Christmas');\n    -- alternative solution: \n    -- DBMS_SCHEDULER.CREATE_SCHEDULE('Christian_Celebration_Days', repeat_interval => 'FREQ=Good_Friday;BYDAY=1 MON, 6 THU,8 MON');\n    DBMS_SCHEDULER.CREATE_SCHEDULE('Political_Holidays', repeat_interval => 'FREQ=DAILY;INTERSECT=New_Year,Labor_Day,German_Unity_Day');\n\n\nEND;\n/\n"]], ['Sql: difference between two dates'], 4, 0], [(29652394, 2), [['Output next 20 holiays for testing:'], ['I even found a more compact version:']], [[" DECLARE\n    next_run_date TIMESTAMP;\nBEGIN\n    FOR i IN 1..20 LOOP\n        DBMS_SCHEDULER.EVALUATE_CALENDAR_STRING('FREQ=DAILY;INTERSECT='Christian_Celebration_Days,Political_Holidays', NULL, next_run_date, next_run_date);\n        DBMS_OUTPUT.PUT_LINE(next_run_date);\n    END LOOP;\nEND;\n"]], ['Sql: difference between two dates'], 4, 0], [(29660006, 0), [['Get  MAX  value of  PreviousReadDate  for every pair of   (SerialNumber,ReadTypeCode) . So this is what your  GROUP BY  clause should include.'], ['Difference example']], [[" select a.SerialNumber, ReadTypeCode, MAX(PreviousReadDate) from Meter as a\nleft join RegisterLevelInformation as b on a.MeterID = b.MeterID\nwhere ReadType = 'ACT'\ngroup by a.SerialNumber,b.ReadTypeCode\norder by a.SerialNumber\n"]], ['return the last row that meets a condition in sql'], 5, 1], [(29660006, 1), [['Difference example'], ['Here if you apply the query with grouping by 3 columns you would get result:']], [[' ID         MeterID    ReadValue    Consumption  PreviousReadDate    ReadType\n============================================================================\n1          1          250          250          1 jan 2015          EST\n2          1          550          300          1 feb 2015          ACT\n3          1          1000         450          1 apr 2015          EST\n']], ['return the last row that meets a condition in sql'], 5, 0], [(29660006, 2), [['Here if you apply the query with grouping by 3 columns you would get result:'], ['But instead when you only group by  SerialNumber,ReadTypeCode  it would yield result (considering the sample data that I posted):']], [[' SerialNumber | ReadTypeCode | PreviousReadDate\n  ABC1       |    EST       | 1 jan 2015 -- which is MAX of 1 value (1 jan 2015)\n  ABC1       |    ACT       | 1 feb 2015\n  ABC1       |    EST       | 1 apr 2015\n']], ['return the last row that meets a condition in sql'], 5, 0], [(29660006, 3), [['But instead when you only group by  SerialNumber,ReadTypeCode  it would yield result (considering the sample data that I posted):'], ['In this query - you are right indeed - each serial is shown only once.']], [[' SerialNumber | ReadTypeCode | PreviousReadDate\n  ABC1       |    EST       | 1 apr 2015 -- which is MAX of 2 values (1 jan 2015, 1 apr 2015)\n  ABC1       |    ACT       | 1 feb 2015 -- which is MAX of 1 value (because ReadTypeCode is different from the row above\n']], ['return the last row that meets a condition in sql'], 5, 0], [(29660006, 4), [['In this query - you are right indeed - each serial is shown only once.'], ["But this query would produce you odd results you don't expect if you add grouping by more columns (which you have done in your first query -  try it yourself )."]], [[' select a.SerialNumber, count(*) from Meter as a\nleft join RegisterLevelInformation as b on a.MeterID = b.MeterID\ngroup by a.SerialNumber\norder by a.SerialNumber\n']], ['return the last row that meets a condition in sql'], 5, 0], [(29716952, 0), [['This will get the branches without salespeople, ignoring whether orders exist:'], ["Based on your clarification, I believe you want to know what branches haven't had any sales within their state. Start by getting the Salespeople based on the orders they have sold:"]], [[" Select branchnumber\nfrom branch\nwhere branchnumber not in (Select empbranch from employee \n    where emptitle = 'salesperson')\n"]], ['Query for branch numbers with no salesperson'], 4, 0], [(29716952, 1), [["Based on your clarification, I believe you want to know what branches haven't had any sales within their state. Start by getting the Salespeople based on the orders they have sold:"], ['Now you know who sold something, narrow it down by state:']], [[' Select employeeid, empbranch\nfrom employee\njoin orders on orders.salesperson = employee.employeeid\n']], ['Query for branch numbers with no salesperson'], 4, 0], [(29716952, 2), [['Now you know who sold something, narrow it down by state:'], ["So now you've got only the employees that have sold something in their home state.  You need to flip that and get the branches that don't have orders sold by their own salespeople:"]], [[' Select employeeid, empbranch\nfrom employee\njoin orders on orders.salesperson = employee.employeeid\njoin customer on customer.customerid = orders.customerid \njoin branch on employee.empbranch = branch.branchnumber \n    and branch.branchstate = customer.custstate\n']], ['Query for branch numbers with no salesperson'], 4, 0], [(29716952, 3), [["So now you've got only the employees that have sold something in their home state.  You need to flip that and get the branches that don't have orders sold by their own salespeople:"], ['-10000']], [[' Select branchnumber\nfrom branch\nwhere branchid not in (\n    select empbranch\n    from employee\n    join orders on orders.salesperson = employee.employeeid\n    join customer on customer.customerid = orders.customerid \n    join branch on employee.empbranch = branch.branchnumber \n        and branch.branchstate = customer.custstate)\n']], ['Query for branch numbers with no salesperson'], 4, 1], [(29721968, 0), [['Assuming "first level" is defined by  parent_id IS NULL  and the current version Postgres 9.4:'], ['With only few root nodes,  JOIN LATERAL  may be faster:']], [[' SELECT parent_id, count(*) AS referral_ct\nFROM  (\n   SELECT id AS parent_id\n   FROM   tbl\n   WHERE  t1.parent_id IS NULL\n   ) t1\nJOIN   tbl t2 USING (parent_id)\nGROUP  BY 1\nORDER  BY 2 DESC\nLIMIT  1;  -- to only get 1 row with max. referral_ct\n']], ['How to get max count of referal to a root node in a tree'], 2, 1], [(29721968, 1), [['With only few root nodes,  JOIN LATERAL  may be faster:'], ['Related, with more explanation:']], [[' SELECT t1.id, t2.referral_ct\nFROM  (\n   SELECT id\n   FROM   tbl\n   WHERE  parent_id IS NULL\n   ) t1\nLEFT  JOIN LATERAL (\n   SELECT parent_id, count(*) AS referral_ct\n   FROM   tbl\n   WHERE  parent_id = t1.id\n   GROUP  BY 1\n   ) t2 ON true\nORDER   BY 2 DESC\nLIMIT   1;  -- to only get 1 row with max. referral_ct\n']], ['How to get max count of referal to a root node in a tree'], 2, 1], [(29759568, 0), [['It would depend on how much junk you have in your zip codes and phones. For example, you could remove all non-digital characters in those fields with a replace like this one:'], ['And afterwards you could format the resulting digits with a replace like this:']], [[" SELECT REGEXP_REPLACE('234N2&.-@3NDJ23842','[^[:digit:]]+') FROM DUAL\n"]], ['Replace multiple charachters with a sigle line in ORACLE SQL'], 2, 0], [(29759568, 1), [['And afterwards you could format the resulting digits with a replace like this:'], ['I know the examples are not valid as zip codes nor phone numbers but I think they might help you.']], [[" SELECT REGEXP_REPLACE('2342323842','([[:digit:]]{3})([[:digit:]]{3})([[:digit:]]{4})','\\1 \\2 \\3') FROM DUAL\n"]], ['Replace multiple charachters with a sigle line in ORACLE SQL'], 2, 0], [(29771413, 0), [['Use  insert . . . on duplicate key update .  You can do this if you have a unique key on what you want to be unique:'], ['Then, the database will enforce uniqueness.  The statement you want is:']], [[' create unique index idx_results_name_email (name, email);\n']], ['Check if email already exists in database and add/change data'], 2, 0], [(29776360, 2), [['-10000'], ['-10000']], [["To Insert into table INSERT INTO dbo.YourTable\nSELECT CREATEDATE FROM\n(\n    SELECT\n        (CASE WHEN (ISDATE(@data) > 0) THEN CONVERT(DATE, CREATEDATE) \n        ELSE CONVERT(DATE, '01/01/1900') END) as CREATEDATE \n    FROM \n        [dbo].[TestTB]\n) AS Temp\nWHERE\n    CREATEDATE <> CONVERT(DATE, '01/01/1900')\n"]], ['Convert varchar column to datetime in sql server'], 3, 1], [(29782934, 1), [['if the value can be null then you have to do this:'], ['-10000']], [[' CASE COALESCE(timesheet.wed,0) > 0 THEN timesheet.wed/10000 ELSE null END as wed,\n']], ['sql statement with an if inside of it?'], 2, 0], [(29802055, 0), [["LIMIT  isn't a sorting, the  AND  is wrong there and the LIMIT has to be the last clause in the SQL:"], ['']], [[" '+ORDER+BY+Date+DESC+LIMIT+1000'\n"]], ['Multiple sort/filter factors on a Fusion tables query'], 3, 0], [(29802055, 1), [[''], ['-10000']], [[" var base = 'https://www.googleapis.com/fusiontables/v2/query',\r\n  columns = 'SELECT Lat,Lng,Date,Username,TripID',\r\n  from = 'from fusionTableID',\r\n  //apply a filter when you want to\r\n  where = '',\r\n  //group the results when you want to\r\n  groupby = '',\r\n  orderby = 'ORDER BY DATE DESC',\r\n  limit = 'LIMIT 1000',\r\n  key = 'yourApiKey',\r\n  //do you want a JSONP-response? Add a callback-parameter\r\n  callback = '&callback=functionName',\r\n  //prepare the query;\r\n  sql = encodeURIComponent([columns, from, where, groupby, orderby, limit].join(' ')),\r\n  //prepare the url\r\n  url = [base, '?sql=', sql, callback, '&key=', key].join('');\r\n\r\n//see what we got\r\ndocument.body.appendChild(document.createTextNode(url));"]], ['Multiple sort/filter factors on a Fusion tables query'], 3, 1], [(29802055, 2), [['-10000'], ['-10000']], [[' body {\r\n  font-family: Monospace\r\n}']], ['Multiple sort/filter factors on a Fusion tables query'], 3, 0], [(29827229, 1), [['I would recommend not using the class name as the instance name.  I have run into issues in the past where the compiler was confused by that.\nthen on your controller you can set the lists '], ['your drop downs will now be changed to ']], [[' public ActionResult Assign() {\n    BigViewModel vm = new BigViewModel();\n    vm.ProductList = new SelectList(db.BigViewModel.ToList(), "MatProdID", "Product");\n    vm.UserList = new SelectList(db.BigViewModel.ToList(), "MatPackID", "PackerName");\n    return View(vm);\n}\n']], ['MVC4 two drop downs one view'], 3, 0], [(29827229, 2), [['your drop downs will now be changed to '], ['-10000']], [[' @Html.DropDownListFor(model => model.Materials_Product.MatProdID, Model.ProductList)\n']], ['MVC4 two drop downs one view'], 3, 0], [(29871937, 0), [['You can use  exists  ( case–insensitive ):'], ['or  instr  ( case–sensitive ):']], [[" delete from table\nwhere exists (select * from table t where t.string like '%' || table.string || '%')\n"]], ['SQLite - How to remove rows that have a string cell value contained in other rows?'], 2, 1], [(29871937, 1), [['or  instr  ( case–sensitive ):'], ['-10000']], [[' delete from table\nwhere exists (select * from table t where instr(t.string, table.string) > 0)\n']], ['SQLite - How to remove rows that have a string cell value contained in other rows?'], 2, 1], [(29883190, 0), [['Instead of '], ["try to fill in the  null s with a value that would be pushed to the end when sorting (for example, the string  'zzz' , but think of something that would make sense based on the data you have):"]], [[" ORDER BY parent.data->>'f27' ASC\n"]], ['SQL optional join and default value'], 4, 0], [(29883190, 1), [["try to fill in the  null s with a value that would be pushed to the end when sorting (for example, the string  'zzz' , but think of something that would make sense based on the data you have):"], ['use ']], [[" ORDER BY coalesce(parent.data->>'f27', 'zzz') ASC\n"]], ['SQL optional join and default value'], 4, 0], [(29883190, 2), [['use '], ['In the end, you query could look like this:']], [[" ORDER BY parent.data->>'f27' ASC NULLS LAST\n"]], ['SQL optional join and default value'], 4, 0], [(29883190, 3), [['In the end, you query could look like this:'], ["Here's a demo:  http://www.sqlfiddle.com/#!15/d18cc/16"]], [[" SELECT e.*\nFROM entry AS e\nLEFT JOIN entry as parent \n  ON parent.entry_id = cast(e.data->>'f22' as integer)\nWHERE e.deleted = 0 AND e.section_id = $1 AND e.grp_id = $2 \nORDER BY parent.data->>'f27' ASC NULLS LAST\n"]], ['SQL optional join and default value'], 4, 1], [(29923332, 0), [['You can do this with a  left join :'], ['Of course  spot_key  will be  NULL , unless you explicitly assign it a value:']], [[" SELECT spot_key, m.market, panel_member, SUM(weight) as TVR \nFROM (SELECT '9' as market UNION ALL SELECT '300'\n     ) LEFT JOIN\n     break_minute_tvr_fixed b \n     ON b.market = m.market and\n        b.column1 in (1,3,4,2,3,4) and\n        b.section in (1,2,3,4) and\n        b.sex in (1,2) and\n        b.age in (1,2,3,4,5,6,7) and\n        b.spot_key in ( '1:20141017:2129' )  \nGROUP BY spot_key, market;\n"]], ['MySQL: Query to get some rows compulsory'], 2, 1], [(29923332, 1), [['Of course  spot_key  will be  NULL , unless you explicitly assign it a value:'], ['-10000']], [[" SELECT '1:20141017:2129' as spot_key, m.market, panel_member, SUM(weight) as TVR \n"]], ['MySQL: Query to get some rows compulsory'], 2, 0], [(29932394, 0), [['And to combine the old and new values use the ROW_NUMBER() window function, like this:'], ['The result:']], [[" ;with t as(\n    select *,\n    ROW_NUMBER() OVER(partition by userid Order BY lastUpdateDate) rn\n    from @MyTable\n),\na as (\nselect userId, 'locationId' as fieldname,\nlocationId as value, lastUpdateUserId, lastUpdateDate, rn\nfrom t\nUNION ALL\nselect userId, 'roleId' as fieldname,\nroleId as value, lastUpdateUserId, lastUpdateDate, rn\nfrom t\n)\nselect CASE WHEN a2.userId IS NULL THEN 'I' ELSE 'U' END as ChangeType,\na1.userId, a1.lastUpdateDate, a1.lastUpdateUserId, a1.fieldname, a1.value as newValue, a2.value as oldvalue\nFROM a a1 LEFT JOIN a a2\nON a1.userId = a2.userId and a1.fieldname = a2.fieldname\nAND a1.rn = a2.rn+1\norder by 2,3,5\n"]], ['Showing History of changes from a History table'], 2, 1], [(29932394, 1), [['The result:'], ['-10000']], [[' ChangeType userId      lastUpdateDate          lastUpdateUserId fieldname  newValue    oldvalue\n---------- ----------- ----------------------- ---------------- ---------- ----------- -----------\nI          1           2015-04-30 12:20:59.183 7                locationId 1000        NULL\nI          1           2015-04-30 12:20:59.183 7                roleId     1           NULL\nU          1           2015-05-03 12:20:59.183 6                locationId 1100        1000\nU          1           2015-05-03 12:20:59.183 6                roleId     3           1\nU          1           2015-05-07 12:20:59.183 7                locationId 1000        1100\nU          1           2015-05-07 12:20:59.183 7                roleId     3           3\nI          2           2015-05-01 12:20:59.183 9                locationId 1100        NULL\nI          2           2015-05-01 12:20:59.183 9                roleId     5           NULL\nU          2           2015-05-02 12:20:59.183 6                locationId 1110        1100\nU          2           2015-05-02 12:20:59.183 6                roleId     5           5\nI          4           2015-05-04 12:20:59.183 8                locationId 1500        NULL\nI          4           2015-05-04 12:20:59.183 8                roleId     5           NULL\nI          7           2015-05-05 12:20:59.183 9                locationId 1000        NULL\nI          7           2015-05-05 12:20:59.183 9                roleId     8           NULL\nU          7           2015-05-06 12:20:59.183 9                locationId 1100        1000\nU          7           2015-05-06 12:20:59.183 9                roleId     9           8\nI          9           2015-05-08 12:20:59.183 2                locationId 1100        NULL\nI          9           2015-05-08 12:20:59.183 2                roleId     5           NULL\nU          9           2015-05-09 12:20:59.183 5                locationId 1100        1100\nU          9           2015-05-09 12:20:59.183 5                roleId     6           5\n\n(20 row(s) affected)\n']], ['Showing History of changes from a History table'], 2, 0], [(29941637, 0), [['The correct format for  str_to_date  should be'], ['The format that you are using will return null']], [[" mysql> select str_to_date('Friday 08 May 2015','%W %d %M %Y');\n+-------------------------------------------------+\n| str_to_date('Friday 08 May 2015','%W %d %M %Y') |\n+-------------------------------------------------+\n| 2015-05-08                                      |\n+-------------------------------------------------+\n1 row in set (0.00 sec)\n"]], ['Converting MySQL string date to Y-m-d H:i:s'], 2, 1], [(29941637, 1), [['The format that you are using will return null'], ['Here is the list of formatting Specifier  https://dev.mysql.com/doc/refman/5.5/en/date-and-time-functions.html#function_date-format  ']], [[" mysql> select str_to_date('Friday 08 May 2015','%l %d %F %Y');\n+-------------------------------------------------+\n| str_to_date('Friday 08 May 2015','%l %d %F %Y') |\n+-------------------------------------------------+\n| NULL                                            |\n+-------------------------------------------------+\n1 row in set, 1 warning (0.00 sec)\n"]], ['Converting MySQL string date to Y-m-d H:i:s'], 2, 0], [(29949018, 0), [['The cell contains this:'], ["Full stop  should probably be  2E  (it's a 7-bit ASCII character so it's the same byte in many encodings, including UTF-8):"]], [[' d  e  v  .  h  o  w  m  u  c  h\n64 65 76 A9 68 6F 77 6D 75 63 68\n']], ["SQL Select - Where search term contains '.'"], 2, 0], [(29949018, 1), [["Full stop  should probably be  2E  (it's a 7-bit ASCII character so it's the same byte in many encodings, including UTF-8):"], ["But you have  A9 . That's not a 7-bit ASCII character and we don't know what encoding your data uses so we can't tell what it is (but it's clearly not a dot). In ISO-8859-1 and Windows-1252 it'd be a copyright symbol (©). In UTF-8 it'd be an invalid character, typically displayed as  REPLACEMENT CHARACTER  (�) by many clients."]], [[" mysql> SELECT HEX('.');\n+----------+\n| HEX('.') |\n+----------+\n| 2E       |\n+----------+\n1 row in set (0.00 sec)\n"]], ["SQL Select - Where search term contains '.'"], 2, 0], [(30003686, 0), [['Next, define relationship in your  Carousel  model like:'], ['Then, query the  Carousel  model like:']], [[" public function videos()\n{\n    return $this->belongsToMany('YourAppNamespace\\Video');\n}\n"]], ['How do I query a polymorphic pivot table with Eloquent & Laravel 5'], 4, 0], [(30003686, 1), [['Then, query the  Carousel  model like:'], ['You can do the opposite by defining a relationship on your  Video  model like:']], [[' $videos = Carousel::find(2)->videos; //finds all videos associated with carousel having id of 2\n\nreturn $videos;\n']], ['How do I query a polymorphic pivot table with Eloquent & Laravel 5'], 4, 0], [(30003686, 2), [['You can do the opposite by defining a relationship on your  Video  model like:'], ['And, querying like:']], [[" public function carousels()\n{\n    return $this->belongsToMany('YourAppNamespace\\Carousel');\n}\n"]], ['How do I query a polymorphic pivot table with Eloquent & Laravel 5'], 4, 0], [(30003686, 3), [['And, querying like:'], ['-10000']], [[' $carousels = Video::find(2)->carousels; //finds all carousels associated with video having id of 2\n\nreturn $carousels;\n']], ['How do I query a polymorphic pivot table with Eloquent & Laravel 5'], 4, 0], [(30030023, 0), [['This is a pretty typical  greatest-n-per-group  problem. When I see those, I usually use a correlated subquery like this:'], ['This is not the whole solution, as it only gives you the top three scores for each user in its own row. To get the total, you can use  SUM()  wrapped around that subquery like this:']], [[' SELECT *\nFROM myTable m\nWHERE(\n  SELECT COUNT(*)\n  FROM myTable mT\n  WHERE mT.userId = m.userId AND mT.score >= m.score) <= 3;\n']], ['Select sum of top three scores for each user'], 4, 0], [(30030023, 1), [['This is not the whole solution, as it only gives you the top three scores for each user in its own row. To get the total, you can use  SUM()  wrapped around that subquery like this:'], ['Regarding the ordering (which I forgot the first time through), you can just order by totalScore in descending order, and then by MIN(timestamp) in ascending order so that users with the lowest timestamp appears first in the list. Here is the updated query:']], [[' SELECT userId, SUM(score) AS totalScore\nFROM(\n  SELECT userId, score\n  FROM myTable m\n  WHERE(\n    SELECT COUNT(*)\n    FROM myTable mT\n    WHERE mT.userId = m.userId AND mT.score >= m.score) <= 3) tmp\nGROUP BY userId;\n']], ['Select sum of top three scores for each user'], 4, 1], [(30030023, 2), [['Regarding the ordering (which I forgot the first time through), you can just order by totalScore in descending order, and then by MIN(timestamp) in ascending order so that users with the lowest timestamp appears first in the list. Here is the updated query:'], ['As JPW pointed out in the comments, this query will not work if the user has the same score for multiple questions. To settle this, you can add an additional condition inside the subquery to order the users three rows by timestamp as well, like this:']], [[' SELECT userId, SUM(score) AS totalScore\nFROM(\n  SELECT userId, score, timeCol\n  FROM myTable m\n  WHERE(\n    SELECT COUNT(*)\n    FROM myTable mT\n    WHERE mT.userId = m.userId AND mT.score >= m.score) <= 3) tmp\nGROUP BY userId\nORDER BY totalScore DESC, MIN(timeCol) ASC;\n']], ['Select sum of top three scores for each user'], 4, 1], [(30030023, 3), [['As JPW pointed out in the comments, this query will not work if the user has the same score for multiple questions. To settle this, you can add an additional condition inside the subquery to order the users three rows by timestamp as well, like this:'], ['I am still working on a solution to find out how to handle the scenario where the userid, score, and timestamp are all the same. In that case, you will have to find another tiebreaker. Perhaps you have a primary key column, and you can choose to take a higher/lower primary key?']], [[' SELECT userId, SUM(score) AS totalScore\nFROM(\n  SELECT userId, score, timeCol\n  FROM myTable m\n  WHERE(\n    SELECT COUNT(*)\n    FROM myTable mT\n    WHERE mT.userId = m.userId AND mT.score >= m.score \n      AND mT.timeCol <= m.timeCol) <= 3) tmp\nGROUP BY userId\nORDER BY totalScore DESC, MIN(timeCol) ASC;\n']], ['Select sum of top three scores for each user'], 4, 1], [(30099821, 0), [['I think you can do what you want with the  project_milestone  table and  row_number() :'], ['If you need to include  all  projects, even those without two milestones, you can use a  left join :']], [[' select pm.*\nfrom (select pm.*,\n             row_number() over (partition by project_id order by completed_date desc) as seqnum\n      from project_milestone pm\n      where pm.completed_date is not null\n     ) pm\nwhere seqnum = 2;\n']], ['Query to find second largest value from every group'], 2, 1], [(30099821, 1), [['If you need to include  all  projects, even those without two milestones, you can use a  left join :'], ['-10000']], [[' select p.project_id, pm.milestone_id, pm.completed_date\nfrom projects p left join\n     (select pm.*,\n             row_number() over (partition by project_id order by completed_date desc) as seqnum\n      from project_milestone pm\n      where pm.completed_date is not null\n     ) pm\n     on p.project_id = pm.project_id and pm.seqnum = 2;\n']], ['Query to find second largest value from every group'], 2, 1], [(30108652, 0), [['You have to use country look up table join with seller_id and user_id separetly two times, to get user and seller country'], ['OUTPUT']], [[' create table table_1(user_ID int, seller_country_ID int)\ncreate table table_2(user_ID int, users_country_ID int)\ncreate table table_3(country_ID int, country_Name varchar(50))\n\n\ninsert into table_1 values(1, 100)\ninsert into table_1 values(2, 101)\n\ninsert into table_2 values(1, 200)\ninsert into table_2 values(2, 201)\n\n\ninsert into table_3 values(100, \'USA\')\ninsert into table_3 values(101, \'China\')\ninsert into table_3 values(200, \'CANADA\')\ninsert into table_3 values(201, \'Japan\')\n\nSelect table_1.user_ID, uc.country_Name "User Contry", sc.country_Name "Seller Country"\nFROM table_1 INNER JOIN table_2 ON table_1.user_ID= table_2.user_ID\nINNER JOIN table_3 uc ON table_2.users_country_ID= uc.country_ID\nINNER JOIN table_3 sc ON table_1.seller_country_ID= sc.country_ID\n']], ['How to join 3 tables (1 lookup) with SQL'], 2, 1], [(30108652, 1), [['OUTPUT'], ['DEMO SQL FIDDLE']], [[' user_ID   User Contry     Seller Country\n1        CANADA            USA\n2        Japan            China\n']], ['How to join 3 tables (1 lookup) with SQL'], 2, 0], [(30134105, 0), [["I don't know what your exact data looks like, but suppose you have this table, called  tbl :"], ['You could run the following:']], [['         ID        LAT        LON\n---------- ---------- ----------\n         1         20         25\n         2         30         33\n         3         30         33\n         4         55         60\n         5         55         60\n         6         55         60\n']], ['Update duplicate latitude values by iteratively increasing margin'], 4, 0], [(30134105, 1), [['You could run the following:'], ['To get:']], [[' select  id,\n        case when rn > 1 then lat+rn-1 else lat end as lat,\n        lon\nfrom(\nselect  t.*,\n        row_number() over(partition by lat, lon order by id) as rn\nfrom    tbl t\n) x;\n']], ['Update duplicate latitude values by iteratively increasing margin'], 4, 1], [(30134105, 2), [['To get:'], ['Edit (based on your edit)']], [['         ID        LAT        LON\n---------- ---------- ----------\n         1         20         25\n         2         30         33\n         3         31         33\n         4         55         60\n         5         56         60\n         6         57         60\n']], ['Update duplicate latitude values by iteratively increasing margin'], 4, 0], [(30134105, 3), [['Edit (based on your edit)'], ['The above will ascend by .0003 rather than 1.']], [[' select  id,\n        case when rn > .0003 then lat+rn-.0003 else lat end as lat,\n        lon\nfrom(\nselect  t.*,\n        row_number() over(partition by lat, lon order by id)*.0003 as rn\nfrom    tbl t\n) x;\n']], ['Update duplicate latitude values by iteratively increasing margin'], 4, 1], [(30141267, 0), [['If you want screen casts that have none of the 9 tags, then the logic is more like this:'], ['This is actually a small variation on the above query.  Instead of checking that  all  tags are different, this checks that  any  tag is different.  The only change is to the  HAVING  clause:']], [[' SELECT v.screencastId, v.title,\n       GROUP_CONCAT(m.tagName) as tags\nFROM screencasts v JOIN\n     screencastTags m\n     ON v.screencastId = m.screencastId LEFT JOIN\n     (SELECT t.tagName\n      FROM tags t JOIN\n           screencastTags m\n           ON m.tagName = t.tagName\n      GROUP BY t.tagName\n      ORDER BY COUNT(*) DESC, t.tagName DESC\n      LIMIT 9\n     ) tags9\n     ON m.tagname = tags9.tagname\nGROUP BY v.screencastId, v.title\nHAVING SUM(tags9.tagname IS NOT NULL) = 0;\n']], ['How do I add an exception to a query that finds the most popular records?'], 2, 1], [(30141267, 1), [['This is actually a small variation on the above query.  Instead of checking that  all  tags are different, this checks that  any  tag is different.  The only change is to the  HAVING  clause:'], ['-10000']], [[' SELECT v.screencastId, v.title,\n       GROUP_CONCAT(m.tagName) as tags\nFROM screencasts v JOIN\n     screencastTags m\n     ON v.screencastId = m.screencastId LEFT JOIN\n     (SELECT t.tagName\n      FROM tags t JOIN\n           screencastTags m\n           ON m.tagName = t.tagName\n      GROUP BY t.tagName\n      ORDER BY COUNT(*) DESC, t.tagName DESC\n      LIMIT 9\n     ) tags9\n     ON m.tagname = tags9.tagname\nGROUP BY v.screencastId, v.title\nHAVING SUM(tags9.tagname IS NULL) > 0;\n']], ['How do I add an exception to a query that finds the most popular records?'], 2, 1], [(30166727, 0), [['You can use dynamic sql to generate the query to execute based on the values in the first table. Here is an example:'], ["SET @dynamicSQL = 'SELECT ' + (SELECT stuff((select ',' + name + ' AS ' + value\n     from Table1\n     for xml path('')),1,1,'')) + ' FROM Table2'"]], [[' Declare @dynamicSQL nvarchar(200)\n']], ['Select data from one table & then rename the columns based on another table in SQL server'], 2, 0], [(30166727, 1), [["SET @dynamicSQL = 'SELECT ' + (SELECT stuff((select ',' + name + ' AS ' + value\n     from Table1\n     for xml path('')),1,1,'')) + ' FROM Table2'"], ['SQL Fiddle:  http://sqlfiddle.com/#!6/768f9/10']], [[' EXECUTE sp_executesql @dynamicSQL\n']], ['Select data from one table & then rename the columns based on another table in SQL server'], 2, 0], [(30174842, 0), [['Set up:'], ['Query:']], [[" create table sales (\n    ID numeric,\n    type varchar(20),\n    price decimal\n);\n\ninsert into sales values (1,'bike','900.00');\ninsert into sales values (2,'bike','100.00');\n"]], ['Return the proportionate share of the same type'], 2, 0], [(30174842, 1), [['Query:'], ['The inner query gets all the sums by type.  This is an emulation of the  sum(col2) over (partition by col2)  which is available in some databases but not in MySQL.']], [[' select s1.ID, s1.type, s1.price, (s1.price/s2.sum_price) as proportion\nfrom sales s1\ninner join (\n    select type, sum(price) as sum_price\n    from sales\n    group by type\n) s2\non s1.type = s2.type;\n']], ['Return the proportionate share of the same type'], 2, 1], [(30191802, 0), [['Option 1 - Use  DISTINCT  and  SUM  with  OVER  clause:'], ['Option 2 - Use a  derived table  for the  GROUP BY  part:']], [[' SELECT DISTINCT a.*, \n       SUM(DATEDIFF(mi, b.timein, b.timeout)) OVER(PARTITION BY a.id) AS total_mins \nFROM tbl_people a \nLEFT JOIN tbl_register b ON a.id=b.personid\n']], ['SQL Add hours for employees'], 2, 1], [(30191802, 1), [['Option 2 - Use a  derived table  for the  GROUP BY  part:'], ['-10000']], [[' SELECT a.*,\n       total_mins            \nfrom tbl_people a \nleft join (\n    SELECT personid, \n           SUM(DATEDIFF(mi, timein, timeout) AS total_mins \n    FROM tbl_register \n    GROUP BY personid \n ) b ON a.id=b.personid\n']], ['SQL Add hours for employees'], 2, 1], [(30205573, 0), [['You can get the number of days of a given date like this:'], ['And the query:']], [[" DECLARE @date DATETIME = '2014-01-01'\nSELECT DATEDIFF(DAY, @date, DATEADD(MONTH, 1, @date))\n"]], ['SQL: Total days in a month'], 2, 0], [(30211424, 0), [['Select the columns you want with an alias   '], ['and you can get the value like']], [[' SELECT wp_a.name AS a_name FROM wp_a \n']], ['wordpress display date table with inner join and the same variable'], 2, 0], [(30211424, 1), [['and you can get the value like'], ['likewise you can select fields from second table']], [["  $row['a_name']\n"]], ['wordpress display date table with inner join and the same variable'], 2, 0], [(30239227, 0), [['Use  MAX(ID)  of  @t  +  id  for incremented values of  ID  and  ROW_NUMBER()  with  PARTITION BY  to get partitioned values of  VID'], ['Inserted Values']], [[' INSERT INTO @t (ID,VID,Sname,Rname)\nSelect (select MAX(ID) FROM @t) + id as Id,ROW_NUMBER()OVER(partition by id ORDER BY VID)VID,Sname,Rname from @tt\n']], ['How to do autoincrement based on last value from another table?'], 2, 1], [(30239227, 1), [['Inserted Values'], ['-10000']], [[' 4602    1   Bike    Dio\n4602    2   Bike    Pulsar\n4602    3   Bike    Duke\n4603    1   Cloth   jeans\n4603    2   Cloth   shirts\n4603    3   Cloth   short\n']], ['How to do autoincrement based on last value from another table?'], 2, 0], [(30245181, 0), [["You need an additional branch on that conditional, if you're to cover all your bases:"], ["Now, you  could  go with a plain old ELSE block at the end, to catch everything, but I suspect that you're actually looking for something more like:"]], [[' ELSE IF @date1 <= @startdate\n']], ['How to check a date range in SQL?'], 2, 0], [(30263295, 0), [["There's nothing wrong with your SQL.  Check your data."], ['Now if you do this:']], [[" create table planmenu ( \n  name varchar(20),\n  type varchar(20),\n  dishcontent varchar(20)\n);\n\ninsert into planmenu values ('a','b','c');\n"]], ['combining AND operator in mysql'], 4, 0], [(30263295, 2), [['If you do this:'], ["You'll get a record back because the OR makes it so that the first two conditions OR only the third condition has to be true.  It is the equivalent of running this:"]], [[" SELECT * \nFROM planmenu \nWHERE name LIKE '%z%' \nAND type LIKE '%z%' \nOR dishcontent LIKE '%c%';\n"]], ['combining AND operator in mysql'], 4, 0], [(30263295, 3), [["You'll get a record back because the OR makes it so that the first two conditions OR only the third condition has to be true.  It is the equivalent of running this:"], ["Check your data.  You don't have any records matching all three conditions."]], [[" SELECT * \nFROM planmenu \nWHERE (name LIKE '%z%' AND type LIKE '%z%')\nOR dishcontent LIKE '%c%';\n"]], ['combining AND operator in mysql'], 4, 0], [(30298547, 0), [['For example,'], ["UPDATE  OP doesn't want the  ANSI join syntax ."]], [[" WITH SUBQ AS\n  (SELECT dim.MONTH_NAME AS current_month_name ,\n    dim.year_period      AS current_month ,\n    dim.PERIOD_YEAR      AS YEAR ,\n    CASE\n      WHEN dim.year_period NOT LIKE '%01'\n      THEN to_number(CONCAT(TO_CHAR(dim.PERIOD_YEAR-1) , '01' ))\n      WHEN dim.year_period LIKE '%01'\n      THEN to_number(CONCAT(TO_CHAR(dim.PERIOD_YEAR-2) , '01' ))\n    END AS START_DATE ,\n    CASE\n      WHEN dim.year_period NOT LIKE '%01'\n      THEN to_number(CONCAT(TO_CHAR(dim.PERIOD_YEAR) , '01' ))\n      WHEN dim.year_period LIKE '%01'\n      THEN to_number(CONCAT(TO_CHAR(dim.PERIOD_YEAR-1) , '01' ))\n    END AS ENDDATE\n  FROM dim_periods dim\n  WHERE dim.year_period=to_number(TO_CHAR(SYSDATE, 'YYYYMM'))\n  )\nSELECT fd.COLUMNS,\n  q.COLUMNS\nFROM financial_data fd\nJOIN subq q\nON (fd.KEY = q.KEY) -- join key\nWHERE fd.year_period BETWEEN q.start_date AND q.enddate;\n"]], ['Condition in WHERE clause (Oracle)'], 2, 1], [(30298547, 1), [["UPDATE  OP doesn't want the  ANSI join syntax ."], ['-10000']], [[" WITH SUBQ AS\n  (SELECT dim.MONTH_NAME AS current_month_name ,\n    dim.year_period      AS current_month ,\n    dim.PERIOD_YEAR      AS YEAR ,\n    CASE\n      WHEN dim.year_period NOT LIKE '%01'\n      THEN to_number(CONCAT(TO_CHAR(dim.PERIOD_YEAR-1) , '01' ))\n      WHEN dim.year_period LIKE '%01'\n      THEN to_number(CONCAT(TO_CHAR(dim.PERIOD_YEAR-2) , '01' ))\n    END AS START_DATE ,\n    CASE\n      WHEN dim.year_period NOT LIKE '%01'\n      THEN to_number(CONCAT(TO_CHAR(dim.PERIOD_YEAR) , '01' ))\n      WHEN dim.year_period LIKE '%01'\n      THEN to_number(CONCAT(TO_CHAR(dim.PERIOD_YEAR-1) , '01' ))\n    END AS ENDDATE\n  FROM dim_periods dim\n  WHERE dim.year_period=to_number(TO_CHAR(SYSDATE, 'YYYYMM'))\n  )\nSELECT fd.COLUMNS,\n  q.COLUMNS\nFROM financial_data fd,\n  subq q\nWHERE fd.KEY = q.KEY -- join key\nAND fd.year_period BETWEEN q.start_date AND q.enddate;\n"]], ['Condition in WHERE clause (Oracle)'], 2, 1], [(30309531, 0), [['The problem is in your parent SQL:'], ['The parent and subquery should look like this:']], [[' (SELECT COUNT(*)\n FROM\n     (SELECT cjbe.EMPLID\n      FROM PS_JOB cjbe\n      WHERE cjbe.POSITION_NBR = jbe.POSITION_NBR\n      GROUP BY cjbe.EMPLID)) "Qty_In_Position?"\n']], ['How to determine number of records in a subquery'], 2, 0], [(30356880, 0), [['Oracle 11g R2 Schema Setup :'], ['Query 1 :']], [[' CREATE TABLE items ( "user", start_date, end_date ) AS\n          SELECT \'me\', DATE \'2010-01-01\', DATE \'2010-12-31\' FROM DUAL\nUNION ALL SELECT \'me\', DATE \'2015-01-01\', DATE \'2015-12-31\' FROM DUAL\nUNION ALL SELECT \'me\', DATE \'2009-01-01\', DATE \'2009-12-31\' FROM DUAL\nUNION ALL SELECT \'me\', DATE \'2009-01-01\', DATE \'2016-12-31\' FROM DUAL\nUNION ALL SELECT \'me\', DATE \'2012-01-01\', DATE \'2012-12-31\' FROM DUAL\nUNION ALL SELECT \'me\', DATE \'2013-01-01\', DATE \'2013-01-01\' FROM DUAL;\n']], ['Count of days in a period'], 7, 0], [(30356880, 1), [['Query 1 :'], ['Results :']], [[' SELECT "user",\n       TO_CHAR( start_date, \'YYYY-MM-DD\' ) AS start_date,\n       TO_CHAR( end_date, \'YYYY-MM-DD\' ) AS end_date,\n       TO_CHAR( GREATEST(TRUNC(i.start_date), TRUNC(SYSDATE)-INTERVAL \'5\' YEAR), \'YYYY-MM-DD\' ) AS valid_start,\n       TO_CHAR( LEAST(TRUNC(i.end_date),TRUNC(SYSDATE)), \'YYYY-MM-DD\' ) AS valid_end,\n       LEAST(TRUNC(i.end_date),TRUNC(SYSDATE))\n         - GREATEST(TRUNC(i.start_date), TRUNC(SYSDATE)-INTERVAL \'5\' YEAR)\n         + 1\n         AS total_days \nFROM   items i\nWHERE  i."user" = \'me\'\nAND    TRUNC(i.start_date) <= TRUNC(SYSDATE)\nAND    TRUNC(i.end_date)   >= TRUNC(SYSDATE) - INTERVAL \'5\' YEAR\n']], ['Count of days in a period'], 7, 1], [(30356880, 2), [['Results :'], ['If you want the sum of all these valid ranges and are happy to count dates in overlapping ranges multiple times then just wrap it in the  SUM  aggregate function:']], [[' | user | START_DATE |   END_DATE | VALID_START |  VALID_END | TOTAL_DAYS |\n|------|------------|------------|-------------|------------|------------|\n|   me | 2010-01-01 | 2010-12-31 |  2010-05-21 | 2010-12-31 |        225 |\n|   me | 2015-01-01 | 2015-12-31 |  2015-01-01 | 2015-05-21 |        141 |\n|   me | 2009-01-01 | 2016-12-31 |  2010-05-21 | 2015-05-21 |       1827 |\n|   me | 2012-01-01 | 2012-12-31 |  2012-01-01 | 2012-12-31 |        366 |\n|   me | 2013-01-01 | 2013-01-01 |  2013-01-01 | 2013-01-01 |          1 |\n']], ['Count of days in a period'], 7, 0], [(30356880, 3), [['If you want the sum of all these valid ranges and are happy to count dates in overlapping ranges multiple times then just wrap it in the  SUM  aggregate function:'], ['Results :']], [[' SELECT SUM( LEAST(TRUNC(i.end_date),TRUNC(SYSDATE))\n         - GREATEST(TRUNC(i.start_date), TRUNC(SYSDATE)-INTERVAL \'5\' YEAR)\n         + 1 )\n         AS total_days \nFROM   items i\nWHERE  i."user" = \'me\'\nAND    TRUNC(i.start_date) <= TRUNC(SYSDATE)\nAND    TRUNC(i.end_date)   >= TRUNC(SYSDATE) - INTERVAL \'5\' YEAR\n']], ['Count of days in a period'], 7, 1], [(30356880, 4), [['Results :'], ['Now if you want to get a count of all the valid days in the range and not count overlap in ranges multiple times then you can do:']], [[' | TOTAL_DAYS |\n|------------|\n|       2560 |\n']], ['Count of days in a period'], 7, 0], [(30356880, 5), [['Now if you want to get a count of all the valid days in the range and not count overlap in ranges multiple times then you can do:'], ['Results :']], [[' WITH ALL_DATES_IN_RANGE AS (\n  SELECT TRUNC(SYSDATE) - LEVEL + 1 AS valid_date\n  FROM   DUAL\n  CONNECT BY LEVEL <= SYSDATE - (SYSDATE - INTERVAL \'5\' YEAR) + 1\n)\nSELECT COUNT(1) AS TOTAL_DAYS\nFROM   ALL_DATES_IN_RANGE a\nWHERE  EXISTS ( SELECT \'X\'\n                FROM   items i\n                WHERE  a.valid_date BETWEEN i.start_date AND i.end_date\n                AND    i."user" = \'me\' )\n']], ['Count of days in a period'], 7, 1], [(30356880, 6), [['Results :'], ['-10000']], [[' | TOTAL_DAYS |\n|------------|\n|       1827 |\n']], ['Count of days in a period'], 7, 0], [(30391960, 1), [['For example,'], ['-10000']], [[" SQL> SET SERVEROUTPUT ON\nSQL> DECLARE\n  2  TYPE v_array\n  3  IS\n  4    TABLE OF VARCHAR2(200);\n  5    my_array v_array;\n  6  BEGIN\n  7    my_array := v_array('1','2','3','4');\n  8    IF '4' member OF my_array THEN\n  9      dbms_output.put_line('yes');\n 10    ELSE\n 11      dbms_output.put_line('no');\n 12    END IF;\n 13  END;\n 14  /\nyes\n\nPL/SQL procedure successfully completed.\n\nSQL>\n"]], ['oracle sql varray contains an element'], 2, 1], [(30392961, 0), [['This one gives your expected results.  Demo fiddle is here .'], ['Output:']], [[" DECLARE @date DATE = '20150826'\n\nSELECT t1.[Date], t1.Container, \n       (SELECT TOP(1) t2.Location \n               FROM Table1 t2\n               WHERE t2.Container = t1.Container AND t2.[date] < t1.[date]\n               ORDER BY t2.[Date] DESC ) [from], \n        t1.Location [To], t1.Scrapped\nFROM Table1 t1\nWHERE t1.[Date] >= @date\nORDER BY t1.[Date]\n"]], ['Create query that contains movements out of destination list'], 2, 1], [(30392961, 1), [['Output:'], ['-10000']], [[' |                     Date |  Container |   from | To | Scrapped |\n|--------------------------|------------|--------|----|----------|\n| August, 26 2015 00:00:00 | Container1 |      A |  D |   (null) |\n| August, 26 2015 00:00:00 | Container2 |      B |  A |   (null) |\n| August, 26 2015 00:00:00 | Container3 |      C |  B |   (null) |\n| August, 27 2015 00:00:00 | Container1 |      D |  D |        x |\n| August, 27 2015 00:00:00 | Container4 | (null) |  B |   (null) |\n| August, 27 2015 00:00:00 | Container2 |      A |  C |   (null) |\n| August, 27 2015 00:00:00 | Container3 |      B |  A |   (null) |\n']], ['Create query that contains movements out of destination list'], 2, 0], [(30404402, 0), [["PL/SQL doesn't have the  ++  syntactic sugar.  You'd need to explicitly change the value of the variable."], ['At that point, and since you want to ensure consistency, you may be better off hard-coding the  id  values just like you are hard-coding the  value  values, i.e.']], [[" DECLARE\n  id integer := 10;\nBEGIN\n  DELETE FROM myTable;\n  INSERT INTO myTable( id, value ) VALUES( id, 'a value' );\n  id := id + 1;\n  INSERT INTO myTable( id, value ) VALUES( id, 'another value' );\n  id := id + 1;\n  ...\nEND;\n"]], ['Oracle pl/sql script which increments number'], 2, 1], [(30437156, 0), [['Sounds like you need the difference between the  max  and  min  per  epc , so this:'], ['Results from your sample data above:']], [[' select epc, max(`datetime`), min(`datetime`), timediff(max(`datetime`), min(`datetime`))\n  from Track_Record\n  order by timediff(max(`datetime`), min(`datetime`)) desc\n  limit 1;\n']], ['How to select column with greatest difference between dates - MySQL'], 2, 1], [(30437156, 1), [['Results from your sample data above:'], ['-10000']], [[' +-----------------------------+---------------------+---------------------+--------------------------------------------+\n| epc                         | max(`datetime`)     | min(`datetime`)     | timediff(max(`datetime`), min(`datetime`)) |\n+-----------------------------+---------------------+---------------------+--------------------------------------------+\n| 03.0000A89.00016F.000169DCD | 2015-10-15 18:23:18 | 2011-03-01 11:43:26 | 838:59:59                                  |\n+-----------------------------+---------------------+---------------------+--------------------------------------------+\n1 row in set, 1 warning (0.00 sec)\n']], ['How to select column with greatest difference between dates - MySQL'], 2, 0], [(30458856, 0), [['In MYSQL it would be like'], ['In Oracle it would be like']], [[" INSERT INTO tabelname (id, name) \nVALUES (1, 'abc') \nON DUPLICATE KEY UPDATE id = id;\n"]], ['Is there a non database-specific command for "insert or update"'], 3, 1], [(30458856, 1), [['In Oracle it would be like'], ['or you can use merge like this:']], [[" DECLARE\n    x NUMBER:=0;\nBEGIN\n    SELECT nvl((SELECT 1 FROM tabelname WHERE name = 'abc'), 0) INTO x FROM dual;\n\n    IF (x = 1) THEN\n        INSERT INTO tabelname (1,'abc')\n    END IF;\n\nEND;\n"]], ['Is there a non database-specific command for "insert or update"'], 3, 1], [(30458856, 2), [['or you can use merge like this:'], ['-10000']], [[" merge into tablename a\n    using (select 1 id, 'abc' name from dual) b\n        on (a.name = b.name)\n    when not matched then\n   insert( id, name)\n      values( b.id, b.name)\n"]], ['Is there a non database-specific command for "insert or update"'], 3, 1], [(30494810, 1), [['Hope this helps.'], ['Query 1 :']], [[" create table places(\n  id int unsigned not null auto_increment primary key,\n  place_id int,\n  detail_key varchar(50),\n  detail_value varchar(50)\n);\n\ninsert into places (place_id, detail_key, detail_value) values\n(1, 'location','Athens'),(1,'country','Greece'),(1,'longitude','12.3333'),(1,'weather','good');\n"]], ["SQL subqueries to get field's value as a field name on the result"], 9, 0], [(30494810, 2), [['Query 1 :'], ['Query 2 :']], [[' set @sql = null\n']], ["SQL subqueries to get field's value as a field name on the result"], 9, 0], [(30494810, 3), [['Query 2 :'], ['Query 3 :']], [[' select group_concat(distinct\n                    concat(\n                      "max(case detail_key when \'",\n                      detail_key,\n                      "\' then detail_value end) as `",\n                      detail_key,\n                      "`"\n                    )\n       )\ninto @sql\nfrom places\n']], ["SQL subqueries to get field's value as a field name on the result"], 9, 0], [(30494810, 4), [['Query 3 :'], ['Query 4 :']], [[' set @sql = concat("select place_id, ", @sql, " from places group by place_id")\n']], ["SQL subqueries to get field's value as a field name on the result"], 9, 0], [(30494810, 5), [['Query 4 :'], ['Query 5 :']], [[' prepare stmt from @sql\n']], ["SQL subqueries to get field's value as a field name on the result"], 9, 0], [(30494810, 6), [['Query 5 :'], ['Results :']], [[' execute stmt\n']], ["SQL subqueries to get field's value as a field name on the result"], 9, 0], [(30494810, 7), [['Results :'], ['-10000']], [[' | place_id | location | country | longitude | weather |\n|----------|----------|---------|-----------|---------|\n|        1 |   Athens |  Greece |   12.3333 |    good |\n']], ["SQL subqueries to get field's value as a field name on the result"], 9, 0], [(30522930, 0), [['Maybe something like this:'], ['Or if you want a distinct count:']], [[" SELECT count(*)\n(\n   SELECT id FROM Table1 \n   WHERE ttime BETWEEN '29-5-2915 08:17:29' AND '29-5-2915 17:17:29'\n   UNION ALL\n   SELECT id FROM Table2\n   WHERE ttime BETWEEN '29-5-2915 08:17:29' AND '29-5-2915 17:17:29'\n) AS t\n"]], ['SQL Query: Unable to get the count of values between a time stamp from multiple tables'], 2, 1], [(30522930, 1), [['Or if you want a distinct count:'], ['-10000']], [[" SELECT count(*)\n(\n   SELECT id FROM Table1 \n   WHERE ttime BETWEEN '29-5-2915 08:17:29' AND '29-5-2915 17:17:29'\n   UNION\n   SELECT id FROM Table2\n   WHERE ttime BETWEEN '29-5-2915 08:17:29' AND '29-5-2915 17:17:29'\n) AS t\n"]], ['SQL Query: Unable to get the count of values between a time stamp from multiple tables'], 2, 1], [(30577660, 0), [['Exclusive date range:'], ['Inclusive date range:']], [[" if datepart(day, @date2) = datepart(day,dateadd(day, -1,(Cast(Cast(datepart(year, @date2) as varchar) + '-' + Cast(datepart(month, @date2) + 1 as varchar) + '-01' as date))))\nbegin \n   Select datediff(month, @date1, @date2) * 30 - (DATEPART(day, @date1) - 30)\nend\nelse if datepart(day, @date1) = datepart(day,dateadd(day, -1,(Cast(Cast(datepart(year, @date1) as varchar) + '-' + Cast(datepart(month, @date1) + 1 as varchar) + '-01' as date))))\nbegin \n   Select datediff(month, @date1, @date2) * 30 - (30 - datepart(day, @date2))\nend\nelse\nbegin\n   Select datediff(month, @date1, @date2) * 30 - (DATEPART(day, @date1) - datepart(day, @date2))\nend\n"]], ['How to calculate Days between two dates'], 2, 1], [(30577660, 1), [['Inclusive date range:'], ["The If's check to see if either of the dates are the last day of the month. If they are then they treat it as the 30th since each month needs to be 30 days."]], [[" if datepart(day, @date2) = datepart(day,dateadd(day, -1,(Cast(Cast(datepart(year, @date2) as varchar) + '-' + Cast(datepart(month, @date2) + 1 as varchar) + '-01' as date))))\nbegin \n   Select datediff(month, @date1, @date2) * 30 - (DATEPART(day, @date1) - 30) + 1\nend\nelse if datepart(day, @date1) = datepart(day,dateadd(day, -1,(Cast(Cast(datepart(year, @date1) as varchar) + '-' + Cast(datepart(month, @date1) + 1 as varchar) + '-01' as date))))\nbegin \n   Select datediff(month, @date1, @date2) * 30 - (30 - datepart(day, @date2)) + 1\nend\nelse\nbegin\n   Select datediff(month, @date1, @date2) * 30 - (DATEPART(day, @date1) - datepart(day, @date2)) + 1\nend\n"]], ['How to calculate Days between two dates'], 2, 1], [(30578605, 0), [['You are over complicating what should be a simple select with  not exists :'], ['Results:']], [[' SELECT SalesManID, ProductID\nFROM Salesman_Product p\nWHERE NOT EXISTS (\n   SELECT 1\n   FROM  Salesman_Sales s \n   WHERE p.SalesManID = s.SalesManID and p.ProductID = s.ProductID\n)\n']], ['Get result on two table join'], 2, 1], [(30578605, 1), [['Results:'], ['see fiddle here']], [[' SalesManID    ProductID\n1             2\n1             4\n2             4\n']], ['Get result on two table join'], 2, 0], [(30607214, 0), [['Make sure that both columns  FromIDNumber  and  ToIDNumber  have an index, i.e.'], ['I could not find a faster query for your example, though you might try the query without the  DISTINCT  keyword - using  UNION  returns only distinct values by definition. So this SQL gives us the same result as your current query:']], [[' ALTER TABLE Communication ADD INDEX (FromIDNumber);\nALTER TABLE Communication ADD INDEX (ToIDNumber);\n']], ['SQL Insert into and Select multiple columns?'], 3, 0], [(30607214, 1), [['I could not find a faster query for your example, though you might try the query without the  DISTINCT  keyword - using  UNION  returns only distinct values by definition. So this SQL gives us the same result as your current query:'], ['Also try another approach by setting the CommIDTemp.ID column as a primary key and use  INSERT IGNORE  - this is especially useful if you want to update the table frequently without deleting the contents:']], [[' INSERT INTO CommIDTemp (`ID`)\nSELECT FromIDNumber FROM Communication\nUNION \nSELECT ToIDNumberFROM Communication;\n']], ['SQL Insert into and Select multiple columns?'], 3, 0], [(30607214, 2), [['Also try another approach by setting the CommIDTemp.ID column as a primary key and use  INSERT IGNORE  - this is especially useful if you want to update the table frequently without deleting the contents:'], ['-10000']], [[' CREATE TABLE CommIDTemp (ID INT PRIMARY KEY);\n\nINSERT IGNORE INTO CommIDTemp (`ID`)\nSELECT FromIDNumber FROM Communication\nUNION\nSELECT ToIDNumber FROM Communication;\n']], ['SQL Insert into and Select multiple columns?'], 3, 0], [(30616479, 0), [["Here's the basic method to  JOIN  the data, note I've padded out the  INSERT  scripts to have a complete matrix:"], ['And for the  UPDATE  you would do something like this:']], [[' CREATE TABLE #dm_matrix\n    (\n      x FLOAT ,\n      z FLOAT ,\n      avgValue DECIMAL(2, 1)\n    )\n\n\nINSERT  INTO #dm_matrix\nVALUES  ( 1, 1, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 1, 2, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 1, 3, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 1, 4, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 2, 1, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 2, 2, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 2, 3, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 2, 4, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 3, 1, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 3, 2, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 3, 3, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 3, 4, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 4, 1, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 4, 2, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 4, 3, RAND() )\nINSERT  INTO #dm_matrix\nVALUES  ( 4, 4, RAND() )\n\nSELECT  *\nFROM    #dm_matrix\n\nCREATE TABLE #dm_values\n    (\n      vx DECIMAL(2, 1) ,\n      vz DECIMAL(2, 1) ,\n      v FLOAT\n    )\n\nINSERT  INTO #dm_values\n        ( vx, vz )\nVALUES  ( 1 + RAND() * 3, 1 + RAND() * 3 )\nINSERT  INTO #dm_values\n        ( vx, vz )\nVALUES  ( 1 + RAND() * 3, 1 + RAND() * 3 )\n\nSELECT  *\nFROM    #dm_values\n\n-- replace this SELECT with the UPDATE commands below to update values\nSELECT  v.vx ,\n        v.vz ,\n        m.avgValue\nFROM    #dm_values v\n        INNER JOIN #dm_matrix m ON ROUND(v.vx, 0) = m.x\n                                   AND ROUND(v.vz, 0) = m.z\n\nDROP TABLE #dm_matrix\nDROP TABLE #dm_values\n']], ['Updating table with the closest value from a lookup matrix'], 5, 0], [(30616479, 1), [['And for the  UPDATE  you would do something like this:'], ['Matrix:']], [[' UPDATE v\nSET v.v = m.avgValue\nFROM #dm_values v \nINNER JOIN #dm_matrix m ON ROUND(v.vx, 0) = m.x AND ROUND(v.vz, 0) = m.z\n\nSELECT * FROM #dm_values\n']], ['Updating table with the closest value from a lookup matrix'], 5, 0], [(30616479, 2), [['Matrix:'], ['Values:']], [[' x   z   avgValue\n1   1   0.6\n1   2   0.9  -- row 2 below\n1   3   0.4\n1   4   0.5\n2   1   0.7\n2   2   0.4\n2   3   0.5  -- row 1 below\n2   4   0.5\n3   1   0.4\n3   2   0.1\n3   3   0.3\n3   4   0.8\n4   1   0.1\n4   2   1.0\n4   3   0.5\n4   4   0.5  \n']], ['Updating table with the closest value from a lookup matrix'], 5, 0], [(30616479, 3), [['Values:'], ['After Update:']], [[' vx  vz  v\n1.8 2.8 NULL  -- x = 2, z = 3\n1.3 1.5 NULL  -- x = 1, z = 2\n']], ['Updating table with the closest value from a lookup matrix'], 5, 0], [(30616479, 4), [['After Update:'], ['NOTE:']], [[' vx  vz  v\n1.8 2.8 0.5\n1.3 1.5 0.9\n']], ['Updating table with the closest value from a lookup matrix'], 5, 0], [(30643949, 0), [['Try this:'], ['Breakdown: \nThe first argument of the substring is the string that contains the full expression. \nThe second one is the first index after  /id/ .\nThe third one is the desired length - calculated by the first index of  /  after  /id/  - the first index after  /id/ .']], [[" SELECT SUBSTRING(\n       @URL2, \n       CHARINDEX('/id/', @URL2)+4, \n       CHARINDEX('/', @URL2, CHARINDEX('/id/', @URL2)+5)\n        - (CHARINDEX('/id/', @URL2)+4))\n"]], ['How to get a id from a url using SQL QUERY. The ID changes dynamically. the database is Sql server 2008'], 2, 1], [(30643949, 1), [['Breakdown: \nThe first argument of the substring is the string that contains the full expression. \nThe second one is the first index after  /id/ .\nThe third one is the desired length - calculated by the first index of  /  after  /id/  - the first index after  /id/ .'], ['-10000']], [[" SELECT SUBSTRING(\n       @URL, \n       CHARINDEX('/id/', @URL)+4, \n       CASE WHEN CHARINDEX('/', @URL, CHARINDEX('/id/', @URL)+5) > 0 THEN\n       CHARINDEX('/', @URL, CHARINDEX('/id/', @URL)+5)\n        - (CHARINDEX('/id/', @URL)+4)\n       ELSE\n          LEN(@URL)\n       END\n       )\n"]], ['How to get a id from a url using SQL QUERY. The ID changes dynamically. the database is Sql server 2008'], 2, 1], [(30652021, 0), [["If all of the newer rows have the quantity in them, and the older rows don't, you can try something like this:"], ['Alternatively, if all the newer rows have something additional added to the name, try this:']], [[" Select * from MyTable\nwhere [Product] like '%X[0-9]%'\n"]], ['SQL How to select one of two nearly identical rows'], 2, 1], [(30652021, 1), [['Alternatively, if all the newer rows have something additional added to the name, try this:'], ["The first option selects every row where the name of the product includes 'X' followed by a number.  The second will return, for each  item ID , the row with the longest product name.  "]], [[' Select * from (\n  Select *\n  , ROW_NUMBER() over (partition by ItmKey order by len(product) desc) RN\n  from MyTable\n  ) a\nwhere a.RN = 1\n']], ['SQL How to select one of two nearly identical rows'], 2, 1], [(30805539, 0), [["HVD's method is probably the simplest:"], ['In SQL 2012 and above, they made it really easy.']], [[" SELECT DATEADD(YEAR,YEAR(GETDATE()) - 2000,'20000531')\n"]], ['Select a specific date for the current year'], 2, 1], [(30805539, 1), [['In SQL 2012 and above, they made it really easy.'], ['-10000']], [[' SELECT DATEFROMPARTS(YEAR(GETDATE()),05,31)\n']], ['Select a specific date for the current year'], 2, 1], [(30843033, 0), [['The one option left with you is using  NOT EXISTS'], ['Update: Using Join']], [[" SELECT t1.name \n  FROM table1 t1 \n WHERE NOT EXISTS (SELECT 'X' \n                     FROM table2 t2 \n                    WHERE t2.name = t1.name);\n"]], ['Get unmatched records without using oracle minus except not in'], 3, 1], [(30843033, 1), [['Update: Using Join'], ['Or just']], [[' with table_ as \n(\n  select t1.name t1_name, t2.name t2_name\n    from table1 t1\n    left join table2 t2 \n      on t1.name = t2.name)\nselect t1_name \n  from table_\n where t2_name is null;\n']], ['Get unmatched records without using oracle minus except not in'], 3, 1], [(30843033, 2), [['Or just'], ['-10000']], [[' select t1.name\n  from table1 t1\n  left join table2 t2 \n    on t1.name = t2.name\n where t2.name is null;\n']], ['Get unmatched records without using oracle minus except not in'], 3, 1], [(30857779, 1), [['==Update=='], ['See more']], [[' connetionString = "Data Source=ServerName;Initial Catalog=DatabaseName;User ID=UserName;Password=Password"\n']], ['How do I store a SQL statement into a variable'], 2, 0], [(30877040, 1), [['To order based on the strings you have, you can first write a query using a variable to get the position of each string like this:'], ['Once you have that temporary table, you can join it to your original table and update  position  of the original to match  position  of the temp table, like this:']], [[' SET @position := 0;\n\nSELECT @position := @position + 1, name\nFROM(\n  SELECT DISTINCT name\n  FROM myTable\n  ORDER BY name) t;\n']], ['Update table to record position based on text column'], 3, 0], [(30906021, 2), [['These is the how find out column_name is present in another table'], ['Thank you.']], [[" SELECT * FROM(    SELECT letter  FROM `Table_2` ) a JOIN\n(SELECT `COLUMN_NAME` \nFROM `INFORMATION_SCHEMA`.`COLUMNS` \nWHERE `TABLE_SCHEMA`='database_name' \n    AND `TABLE_NAME`='Table_1') b ON a.letter= b. COLUMN_NAME\n"]], ['Select column names from one table based off of values in column of another table'], 3, 1], [(30932071, 0), [['Use analytical functions:'], ['Testdata:']], [[" select distinct\n  id,\n  first_value (status) over (partition by id order by status desc) status,\n  first_value (amt   ) over (partition by id order by status desc) amt\nfrom\n  tq84_a_status_check\nwhere\n  status in ('LC', 'BE')\norder by\n  id;\n"]], ['Query to filter records based on specific conditions'], 2, 1], [(30932071, 1), [['Testdata:'], ['-10000']], [[" create table tq84_a_status_check (\n  id number,\n  status varchar2(10),\n  amt number\n);\n\nselect distinct\n  id,\n  first_value (status) over (partition by id order by status desc) status,\n  first_value (amt   ) over (partition by id order by status desc) amt\nfrom\n  tq84_a_status_check\nwhere\n  status in ('LC', 'BE')\norder by\n  id;\n"]], ['Query to filter records based on specific conditions'], 2, 0], [(30934830, 0), [['I would do the running total using  sum()  as a windowed aggregate function with the  over ...  clause, which works in SQL Server 2012+. '], ["Another approach (that also works in older versions) is to use a self-join and sum up the rows with lower goalminutes. For ease of reading I've used a common table expression to split the goals into two columns for home and guest team:"]], [[' select \n    g.RowId, g.GameDate, t.GoalMinute, p.PlayerName, \n    GoalsHome = COALESCE(SUM(case when TeamRowId = g.TeamHomeRowId then 1 end) OVER (PARTITION BY gamerowid ORDER BY goalminute),0),\n    GoalsGuest = COALESCE(SUM(case when TeamRowId = g.TeamGuestRowId then 1 end) OVER (PARTITION BY gamerowid ORDER BY goalminute),0) \nfrom tblGoals t\njoin tblPlayers p on t.PlayerRowId = p.RowId\njoin tblGames g on t.GameRowId = g.RowId\norder by t.GameRowId, t.GoalMinute\n']], ['row counter with condition in two different columns'], 2, 1], [(30934830, 1), [["Another approach (that also works in older versions) is to use a self-join and sum up the rows with lower goalminutes. For ease of reading I've used a common table expression to split the goals into two columns for home and guest team:"], ["The CTE isn't necessary though, you could just as well use a derived table"]], [[' ;with t as (\n    select \n       g.GoalMinute, g.PlayerRowId, g.GameRowId, \n       case when TeamRowId = ga.TeamHomeRowId then 1 end HomeGoals,\n       case when TeamRowId = ga.TeamGuestRowId then 1 end GuestGoals\n    from tblGoals g\n    join tblGames ga on g.GameRowId = ga.RowId\n)\n\nselect \n    g.RowId, g.GameDate, t.GoalMinute, p.PlayerName, \n    GoalsHome  = (select sum(coalesce(HomeGoals,0)) from t t2 where t2.GoalMinute <= t.GoalMinute and t2.GameRowId = t.GameRowId),\n    GoalsGuest = (select sum(coalesce(GuestGoals,0)) from t t2 where t2.GoalMinute <= t.GoalMinute and t2.GameRowId = t.GameRowId)\nfrom t\njoin tblPlayers p on t.PlayerRowId = p.RowId\njoin tblGames g on t.GameRowId = g.RowId\norder by t.GameRowId, t.GoalMinute\n']], ['row counter with condition in two different columns'], 2, 1], [(30950398, 0), [['I think you sql will useful to you.'], ["Here date_column='20-Mar-2015 TO 30-Mar-2015'"]], [['   eg:- SELECT SUBSTRING(date_column,1,11) AS date_1, \n        SUBSTRING(date_column,16,27) AS date_2; \n']], ['I have a different date format like 20-Mar-2015 to 30-Mar-2015 in a column in sql. i need to split it in two different columns in sql query'], 2, 1], [(30977821, 0), [['I think you want something like this:'], ['Output:']], [[" DECLARE @nw TABLE ( sn INT, [key] VARCHAR(100) )\n\nINSERT  INTO @nw\nVALUES  ( 1, 'and' ),\n        ( 2, 'on' ),\n        ( 3, 'of' ),\n        ( 4, 'the' ),\n        ( 5, 'view' )\n\n\nDECLARE @s VARCHAR(100) = 'view This of is the Man';\nWITH    cte\n          AS ( SELECT   sn ,\n                        REPLACE(@s, [key], '') AS s\n               FROM     @nw\n               WHERE    sn = 1\n               UNION ALL\n               SELECT   n.sn ,\n                        REPLACE(s, n.[key], '') AS s\n               FROM     @nw n\n                        JOIN cte c ON c.sn + 1 = n.sn\n             )\n    SELECT TOP 1 @s =\n            REPLACE(REPLACE(REPLACE(s, ' ', '[]'), '][', ''), '[]', ' ')\n    FROM    cte\n    ORDER BY sn DESC\n"]], ['Title search in SQL With replacement of noice words'], 6, 1], [(30977821, 1), [['Output:'], ['Then you can filter base table like:']], [[' This is Man\n']], ['Title search in SQL With replacement of noice words'], 6, 0], [(30977821, 2), [['Then you can filter base table like:'], ['But if you insist here is the full code for this:']], [[" SELECT * FROM TableName WHERE Title LIKE '%' + @s + '%' \n"]], ['Title search in SQL With replacement of noice words'], 6, 0], [(30977821, 3), [['But if you insist here is the full code for this:'], ['And the code:']], [[" DECLARE @t TABLE\n    (\n      SNo INT ,\n      Title VARCHAR(100)\n    )\nINSERT  INTO @t\n        ( SNo, Title )\nVALUES  ( 1, 'women holding stack  of gifts' ),\n        ( 2, 'Rear view of a man playing golf' ),\n        ( 3, 'Women holding gifts' ),\n        ( 4, 'Women holding gifts' ),\n        ( 5, 'Businessman reading a newspaper and smiling' ),\n        ( 6, 'Hey This some what of is the Man from Chicago' )\n\nDECLARE @nw TABLE\n    (\n      sn INT ,\n      [key] VARCHAR(100)\n    )\n\nINSERT  INTO @nw\nVALUES  ( 1, 'and' ),\n        ( 2, 'on' ),\n        ( 3, 'of' ),\n        ( 4, 'the' ),\n        ( 5, 'view' ),\n        ( 6, 'some' ),\n        ( 7, 'what' )\n"]], ['Title search in SQL With replacement of noice words'], 6, 0], [(30977821, 5), [['And the output:'], ['-10000']], [[' SNo Title                                           sn  s\n6   Hey This some what of is the Man from Chicago   7   Hey This    is  Man from Chicago\n']], ['Title search in SQL With replacement of noice words'], 6, 0], [(31010476, 0), [['A small dataset of random data:'], ['Query 1 :']], [[' CREATE TABLE test (\n  id INT,\n  population INT\n);\nINSERT INTO TEST VALUES (  1, 12 );\nINSERT INTO TEST VALUES (  2, 11 );\nINSERT INTO TEST VALUES (  3, 14 );\nINSERT INTO TEST VALUES (  4,  6 );\nINSERT INTO TEST VALUES (  5,  7 );\nINSERT INTO TEST VALUES (  6,  7 );\nINSERT INTO TEST VALUES (  7,  1 );\nINSERT INTO TEST VALUES (  8, 15 );\nINSERT INTO TEST VALUES (  9, 14 );\nINSERT INTO TEST VALUES ( 10, 14 );\nINSERT INTO TEST VALUES ( 11, 15 );\nINSERT INTO TEST VALUES ( 12, 12 );\nINSERT INTO TEST VALUES ( 13, 11 );\nINSERT INTO TEST VALUES ( 14,  3 );\nINSERT INTO TEST VALUES ( 15,  8 );\nINSERT INTO TEST VALUES ( 16,  1 );\nINSERT INTO TEST VALUES ( 17,  1 );\nINSERT INTO TEST VALUES ( 18,  2 );\nINSERT INTO TEST VALUES ( 19,  3 );\nINSERT INTO TEST VALUES ( 20,  5 );\n']], ['Find group of N similar numbers in group of N+M numbers'], 3, 0], [(31010476, 2), [['Results :'], ['The query above will select  5  rows - to change it to select  N  rows then change the  4 s in the  LAG  function and in the last line to  N-1 .']], [[' | id | population |\n|----|------------|\n| 10 |         14 |\n|  9 |         14 |\n|  3 |         14 |\n| 11 |         15 |\n|  8 |         15 |\n']], ['Find group of N similar numbers in group of N+M numbers'], 3, 0], [(31072333, 1), [['Results:'], ['-10000']], [[' Signed_Integer Binary_Representation_of_Signed_Integer                        Binary_Representation_of_Signed_Big_Integer                    Signed_Integer_Transposed_onto_Big_Integer Binary_Representation_of_Signed_Integer_Trasposed_onto_Big_Integer\n-------------- -------------------------------------------------------------- -------------------------------------------------------------- ------------------------------------------ ------------------------------------------------------------------\n-5381          0xFFFFEAFB                                                     0xFFFFFFFFFFFFEAFB                                             4294961915                                 0x00000000FFFFEAFB\n']], ["unsigned right shift '>>>' Operator in sql server"], 2, 0], [(31086391, 0), [['If the combination of  roll  and  sub  should be unique, you should define such a key in your table:'], ["Note that if you do this, you don't have to explicitly create the index you're creating, the constraint will create on for you. Once you have this is place, you can use the  on duplicate key  syntax you were trying to use:"]], [[' ALTER TABLE student ADD CONSTRAINT student_uq UNIQUE(roll, sub)\n']], ['Insert If duplicate not found in table else update'], 2, 0], [(31124970, 0), [['For SQL Server, if you can handle returning an "extra" column, you can do something like this:'], ['Tested on SQL Server 2008 ']], [["  ;WITH xmlnamespaces('http://www.w3.org/2001/XMLSchema-instance' AS ns)\n  SELECT v.*\n    FROM ( SELECT t.*\n                , (SELECT t.*\n                      FOR xml path('row'), elements xsinil, type\n                  ).value('count(//*/@ns:nil)', 'int') AS NullCount\n            FROM table_name t\n         ) v\n   WHERE v.NullCount = 0\n"]], ['how to filter all columns together having not null value in sql server'], 2, 1], [(31132669, 1), [['30001 to 60000'], ['60001 to 90000']], [[' SELECT *\nFROM artist t1\nORDER BY count DESC\nLIMIT 30000 OFFSET 30001;\n']], ['Is there a way to get a range of records in Postgres using LIMIT keyword'], 3, 1], [(31132669, 2), [['60001 to 90000'], ['-10000']], [[' SELECT *\nFROM artist t1\nORDER BY count DESC\nLIMIT 30000 OFFSET 60001;\n']], ['Is there a way to get a range of records in Postgres using LIMIT keyword'], 3, 1], [(31143856, 0), [['When you display data for a particular company, do it like this ...'], ['This  ORDER BY  clause will do what you want, and it will be stable if there are duplicates.  You can then, in your user interface, move an entry up with a query like this.']], [[' SELECT whatever, whatever\n  FROM phonebook\n WHERE id_company = 11\n ORDER BY ord, phonebook_name, phonebook_number, id_phonebook\n']], ['Getting the highest number from a mysql query'], 2, 1], [(31143856, 1), [['This  ORDER BY  clause will do what you want, and it will be stable if there are duplicates.  You can then, in your user interface, move an entry up with a query like this.'], ['-10000']], [[' UPDATE phonebook SET ord=ord-1 WHERE id_phonebook = :recordnumber\n']], ['Getting the highest number from a mysql query'], 2, 0], [(31173730, 0), [['Generate sample data'], ['Dynamic Crosstab']], [[" use tempdb;\nCREATE TABLE yourtable(\n    id          INT,\n    pname       VARCHAR(20),\n    childname   VARCHAR(20)\n)\nINSERT INTO yourtable VALUES\n(1, 'Parent1', 'p1child1'), \n(1, 'Parent1', 'p1child2'), \n(1, 'Parent1', 'p1child3'), \n(2, 'Parent2', 'p2child1'), \n(2, 'Parent2', 'p2child2'), \n(3, 'Parent3', 'p3child1'), \n(3, 'Parent3', 'p3child2'), \n(3, 'Parent3', 'p3child3'), \n(3, 'Parent3', 'p3child4'), \n(4, 'Parent4', 'p4child1'), \n(4, 'Parent4', 'p4child2'), \n(4, 'Parent4', 'p4child3');\n"]], ['How to display row value as column value in SQL Server (only one column rows value should be displayed as multiple columns)'], 3, 0], [(31173730, 1), [['Dynamic Crosstab'], ['Result']], [[" DECLARE @maxNoChildren INT\nDECLARE @sql1 VARCHAR(4000) = ''\nDECLARE @sql2 VARCHAR(4000) = ''\nDECLARE @sql3 VARCHAR(4000) = ''\n\nSELECT TOP 1 @maxNoChildren = COUNT(*) FROM yourtable GROUP BY id ORDER BY COUNT(*) DESC\n\nSELECT @sql1 = \n'SELECT\n    id\n    ,pname\n'\n\nSELECT @sql2 = @sql2 +\n'   ,MAX(CASE WHEN RN = ' + CONVERT(VARCHAR(5), N) + ' THEN childname END) AS ' + QUOTENAME('child' + CONVERT(VARCHAR(5), N)) + CHAR(10)\nFROM(\n    SELECT TOP(@maxNoChildren)\n        ROW_NUMBER() OVER(ORDER BY (SELECT NULL))\n    FROM sys.columns a\n    --CROSS JOIN sys.columns b\n)T(N)\nORDER BY N\n\nSELECT @sql3 =\n'FROM(\n    SELECT *,\n        RN = ROW_NUMBER() OVER(PARTITION BY id ORDER BY (SELECT NULL))\n    FROM yourtable\n)t\nGROUP BY id, pname\nORDER BY id'\n\nPRINT(@sql1 + @sql2 + @sql3)\nEXEC (@sql1 + @sql2 + @sql3)\n"]], ['How to display row value as column value in SQL Server (only one column rows value should be displayed as multiple columns)'], 3, 1], [(31173730, 2), [['Result'], ['-10000']], [[' | id |   pname |   child1 |   child2 |   child3 |   child4 |\n|----|---------|----------|----------|----------|----------|\n|  1 | Parent1 | p1child1 | p1child2 | p1child3 |   (null) |\n|  2 | Parent2 | p2child1 | p2child2 |   (null) |   (null) |\n|  3 | Parent3 | p3child1 | p3child2 | p3child3 | p3child4 |\n|  4 | Parent4 | p4child1 | p4child2 | p4child3 |   (null) |\n']], ['How to display row value as column value in SQL Server (only one column rows value should be displayed as multiple columns)'], 3, 0], [(31186960, 0), [['One of them is the one in which for the max value found in column  a  you want to display a certain message:'], ['The other possible scenario is that only for the last record in the table you want to display that certain message. And in that scenario your query needs to change to:']], [[" SELECT\n    a\n    , CASE\n        WHEN a = 1 THEN 'ONE'\n        WHEN a = 2 THEN 'TWO'\n        WHEN a = (SELECT MAX(a) FROM test) THEN 'MAX'\n        ELSE 'OTHER'\n     END\nFROM TEST;\n"]], ['Identify last record in CASE'], 2, 1], [(31186960, 1), [['The other possible scenario is that only for the last record in the table you want to display that certain message. And in that scenario your query needs to change to:'], ['-10000']], [[" SELECT\n    a\n    , CASE\n        WHEN a = 1 THEN 'ONE'\n        WHEN a = 2 THEN 'TWO'\n        WHEN a = (SELECT TOP 1 a FROM TEST ORDER BY a DESC) THEN 'MAX'\n        ELSE 'OTHER'\n     END\nFROM TEST\nORDER BY A;\n"]], ['Identify last record in CASE'], 2, 1], [(31194265, 0), [['-10000'], ['Update:']], [[" ALTER TABLE\n        InvoicesElements\nADD CONSTRAINT\n        CHK_GOOD\nCHECK   (good <> 'Bike' OR good IS NULL)\n"]], ['Trigger referring to another subelement table'], 2, 0], [(31194265, 1), [['Update:'], ['-10000']], [[" CREATE TRIGGER\n        TR_InvoicesElements_AIU\nON      InvoicesElements\nAFTER   INSERT, UPDATE\nAS\n        IF EXISTS\n                (\n                SELECT  NULL\n                FROM    INSERTED ie\n                JOIN    Invoices inv\n                ON      inv.id = ie.invoiceId\n                WHERE   ie.good = 'bike'\n                        AND inv.customer = 'ABC'\n                )\n                THROW 50000, 'Not sure why but you cannot sell bikes to ABC', 0\nGO\n\nCREATE TRIGGER\n        TR_Invoices_AIU\nON      Invoices\nAFTER   INSERT, UPDATE\nAS\n        IF EXISTS\n                (\n                SELECT  NULL\n                FROM    InvoiceElements ie\n                JOIN    INSERTED inv\n                ON      inv.id = ie.invoiceId\n                WHERE   ie.good = 'bike'\n                        AND inv.customer = 'ABC'\n                )\n                THROW 50000, 'Not sure why but you cannot sell bikes to ABC', 0\nGO\n"]], ['Trigger referring to another subelement table'], 2, 1], [(31231963, 0), [['Assuming that  id  is unique (as implied by your question), you can use  delete  with  id :'], ['If the  id  can also be the same, you can use  ctid :']], [[' delete from cities c\n    where c.id > (select min(c2.id)\n                  from cities c2\n                  where c2.state = c.state and c2.cities = c.cities\n                 );\n']], ['FInding Duplicate records in a table and deleting those records using postgreSQL'], 2, 1], [(31231963, 1), [['If the  id  can also be the same, you can use  ctid :'], ['-10000']], [[' delete from cities c\n    where c.ctid > (select min(c2.ctid)\n                    from cities c2\n                    where c2.state = c.state and c2.cities = c.cities and\n                          c2.id = c.id\n                   );\n']], ['FInding Duplicate records in a table and deleting those records using postgreSQL'], 2, 1], [(31273373, 0), [['I am not 100 percent sure if I understood the question correctly. But I think Gordon Linoff is missing part of the GROUP BY clause.'], ['fruit_factory:']], [[' SELECT \n    COUNT(DISTINCT(a.id)) AS pears,\n    d.date, # This is what previously was CHANGE_ME\n    c.geo_date\nFROM fruit_factory a\nJOIN dim_date d \n    ON a.run_date < d.date\nLEFT JOIN dim_user u\n    ON u.id = a.user_id \nWHERE a.run_date > u.geo_date\nGROUP BY d.date, c.geo_date\n']], ['Changing WHERE clause using Correlated Queries'], 7, 1], [(31273373, 1), [['fruit_factory:'], ['dim_date:']], [[' id      run_date          user_id\n1       2015-08-30     3\n2       2015-09-01     2\n3       2015-09-02     1\n']], ['Changing WHERE clause using Correlated Queries'], 7, 0], [(31273373, 2), [['dim_date:'], ['previously:']], [[' date\n2015-09-01\n2015-09-02\n']], ['Changing WHERE clause using Correlated Queries'], 7, 0], [(31273373, 3), [['previously:'], ['For August 1st:']], [[' SELECT ... WHERE date < CHANGE_ME.\n']], ['Changing WHERE clause using Correlated Queries'], 7, 0], [(31273373, 4), [['For August 1st:'], ['For August 2nd:']], [[' 1       2015-08-30     3\n']], ['Changing WHERE clause using Correlated Queries'], 7, 0], [(31273373, 5), [['For August 2nd:'], ['Now you use the join, this is what the Join gives you:']], [[' 1       2015-08-30     3\n2       2015-09-01     2\n']], ['Changing WHERE clause using Correlated Queries'], 7, 0], [(31273373, 6), [['Now you use the join, this is what the Join gives you:'], ['As you see, the first row is there twice now, because the join condition was met for both dates.']], [[' id      run_date          user_id    d.date\n1       2015-08-30     3              2015-09-01\n1       2015-08-30     3              2015-09-02\n2       2015-09-01     2              2015-09-02\n']], ['Changing WHERE clause using Correlated Queries'], 7, 0], [(31277383, 0), [['Table layout'], ['Trigger function & trigger']], [[' CREATE TABLE example (\n  example_id     serial PRIMARY KEY\n, totally_unique jsonb NOT NULL\n);\n\nCREATE TABLE example_key (\n  key   text\n, value text\n, PRIMARY KEY (key, value)\n);\n']], ['How to constrain that JSON/JSONB values in a column be completely different?'], 2, 0], [(31281768, 0), [['Step 1: I made your table.'], ['Step 2: Determine the time since the last event.']], [[' WITH event_table AS (\n    SELECT user_id AS dummy_ip,\n           occurred_at,\n           location AS dummy_referer,\n           event_name\n      FROM tutorial.playbook_events \n)\n']], ['How to use SQL to attribute events to visit source in traffic logs?'], 6, 0], [(31281768, 1), [['Step 2: Determine the time since the last event.'], ['Step 3: Find which events mark the beginning of a new session.']], [[' with_last_event AS (\n    SELECT *,\n           LAG(occurred_at,1) OVER (PARTITION BY dummy_ip ORDER BY occurred_at) AS last_event\n      FROM event_table\n)\n']], ['How to use SQL to attribute events to visit source in traffic logs?'], 6, 0], [(31281768, 2), [['Step 3: Find which events mark the beginning of a new session.'], ['Step 4: Create session ids.']], [[" with_new_session_flag AS (\n    SELECT *,\n           CASE WHEN EXTRACT('EPOCH' FROM occurred_at) - EXTRACT('EPOCH' FROM last_event) >= (60 * 10) OR last_event IS NULL \n                THEN 1 ELSE 0 END AS is_new_session,\n           CASE WHEN EXTRACT('EPOCH' FROM occurred_at) - EXTRACT('EPOCH' FROM last_event) >= (60 * 10) OR last_event IS NULL \n                THEN dummy_referer ELSE NULL END AS first_referer\n      FROM with_last_event\n)\n"]], ['How to use SQL to attribute events to visit source in traffic logs?'], 6, 0], [(31281768, 3), [['Step 4: Create session ids.'], ['Step 5: Find the original session referer.']], [[' with_session_ids AS (\n    SELECT *,\n           SUM(is_new_session) OVER (ORDER BY dummy_ip, occurred_at) AS global_session_id,\n           SUM(is_new_session) OVER (PARTITION BY dummy_ip ORDER BY occurred_at) AS user_session_id\n      FROM with_new_session_flag\n)\n']], ['How to use SQL to attribute events to visit source in traffic logs?'], 6, 0], [(31281768, 4), [['Step 5: Find the original session referer.'], ['Step 6: Count some stuff.']], [[' with_session_referer AS (\n    SELECT *,\n           MAX(first_referer) OVER (PARTITION BY global_session_id) AS session_referer\n      FROM with_session_ids\n)\n']], ['How to use SQL to attribute events to visit source in traffic logs?'], 6, 0], [(31281768, 5), [['Step 6: Count some stuff.'], ['This last step is straightforward - filter your events to only the event you care about ( Submit , in your example). Then count the number of events by  session_referer , which is the first referer of the session in which that event occurred. By counting  global_session_id  and  dummy_ip , you can also find how sessions had that event, and how many distinct IPs logged that event. ']], [[" SELECT session_referer,\n       COUNT(1) AS total_events,\n       COUNT(DISTINCT global_session_id) AS distinct_sessions,\n       COUNT(DISTINCT dummy_ip) AS distinct_ips\n  FROM with_session_referer\n WHERE event_name = 'send_message'\n GROUP BY 1\n"]], ['How to use SQL to attribute events to visit source in traffic logs?'], 6, 0], [(31333228, 0), [['In  MySQL  you could use  SUBSTRING_INDEX  in following:'], ['In  SQL Server  will be:']], [[" SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(Id, '>', 1), '<', -1) Email\nFROM Tbl;\n"]], ['How to Extract only email id in SQL SERVER'], 2, 1], [(31333228, 1), [['In  SQL Server  will be:'], ['-10000']], [[" SELECT SUBSTRING(Id, CHARINDEX('<', Id) + 1 , CHARINDEX('>', Id) - CHARINDEX('<', Id) - 1)\nFROM Tbl;\n"]], ['How to Extract only email id in SQL SERVER'], 2, 1], [(31424830, 0), [['Using  NOT EXISTS :'], ['Using  LEFT JOIN :']], [[' SELECT a.*\nFROM TableA a\nWHERE\n    a.userid = @userid\n    AND NOT EXISTS(\n        SELECT 1 \n        FROM TableB b\n        WHERE\n            b.blocked_userid = a.userid\n            AND b.blocker_userid = a.friend_id\n    )\n']], ['SELECT query with exclusions specified in other table - 1'], 2, 1], [(31424830, 1), [['Using  LEFT JOIN :'], ['-10000']], [[' SELECT a.*\nFROM TableA a\nLEFT JOIN TableB b\n    ON b.blocked_userid = a.userid\n    AND b.blocker_userid = a.friend_id\nWHERE\n    a.userid = @userid\n    AND b.blocked_userid IS NULL\n']], ['SELECT query with exclusions specified in other table - 1'], 2, 1], [(31444591, 0), [['In Postgres 9.3+ with built-in  JSON functions :'], ['-10000']], [[' SELECT *\n    , (SELECT count(*) - count(v) FROM json_each_text(row_to_json(t)) x(k,v)) AS ct_nulls\nFROM   tbl t;\n']], ['Count the number of attributes that are NULL for a row'], 4, 1], [(31444591, 1), [['-10000'], ['Since the additional column is  functionally dependent  I would consider  not  to persist it in the table at all. Rather compute it on the fly like demonstrated above or create a tiny function with a  polymorphic  input type for the purpose:']], [[' SELECT *,  (SELECT count(*) - count(v) FROM svals(hstore(t)) v) AS ct_nulls\nFROM   tbl t;\n']], ['Count the number of attributes that are NULL for a row'], 4, 1], [(31444591, 3), [['Then:'], ['You could wrap this into a  VIEW  if you want ...']], [[' SELECT *, f_ct_nulls(t) AS ct_nulls\nFROM   tbl t;\n']], ['Count the number of attributes that are NULL for a row'], 4, 0], [(31448656, 0), [['You can generate sequences of data with the  generate_series()  function:'], ['This generates a row for every month, in a pretty format. If you want to have it like a list, you can aggregate them all in an outer query:']], [[' SELECT to_char(generate_series(min, max, \'1 month\'), \'Mon-YY\') AS "Mon-YY"\nFROM (\n  SELECT date_trunc(\'month\', min(startdate)) AS min, \n         date_trunc(\'month\', max(startdate)) AS max\n  FROM a) sub;\n']], ['How to generate Month list in PostgreSQL?'], 2, 1], [(31468957, 0), [['For 1 to 2:'], ['Result: ']], [[' with cte\nAS\n(\n    SELECT COUNT(DISTINCT Number) as a,Name from test\n    group by name\n)   \nselect DISTINCT x.Number,z.Name \nfrom cte z\ninner join test x\nON z.name = x.name\nWHERE z.a between 1 and 2;\n']], ['SQL Server 2008 R2: Select with condition'], 4, 1], [(31468957, 1), [['Result: '], ['For 1 to 2:']], [[' number  name\n-------------\n111     PersonA\n211     PersonB\n212     PersonB\n311     PersonC\n313     PersonC\n']], ['SQL Server 2008 R2: Select with condition'], 4, 0], [(31468957, 2), [['For 1 to 2:'], ['Result:']], [[' with cte\nAS\n(\n    SELECT COUNT(DISTINCT Number) as a,Name from test\n    group by name\n)   \nselect DISTINCT x.Number,z.Name \nfrom cte z\ninner join test x\nON z.name = x.name\nWHERE z.a between 2 and 2;\n']], ['SQL Server 2008 R2: Select with condition'], 4, 1], [(31468957, 3), [['Result:'], ['-10000']], [[' number  name\n-------------\n211     PersonB\n212     PersonB\n311     PersonC\n313     PersonC \n']], ['SQL Server 2008 R2: Select with condition'], 4, 0], [(31478205, 0), [['You can add DISTINCT to a COUNT:'], ['Or if OrderLineNo always starts with 1 and increases without gaps:    ']], [[' select OrderNo, count(distinct OrderLineNo)\nfrom tab\ngroup by OrderNo;\n']], ['Counting Values based on distinct values from another Column'], 5, 1], [(31478205, 1), [['Or if OrderLineNo always starts with 1 and increases without gaps:    '], ["Based on the comment it's not a count per OrderNo, but a global count. You need to use a Derived Table:"]], [[' select OrderNo, max(OrderLineNo)\nfrom tab\ngroup by OrderNo;\n']], ['Counting Values based on distinct values from another Column'], 5, 1], [(31478205, 2), [["Based on the comment it's not a count per OrderNo, but a global count. You need to use a Derived Table:"], ['or ']], [[' select count(*)\nfrom\n (select distinct OrderNo, OrderLineNo\n  from tab\n ) as dt;\n']], ['Counting Values based on distinct values from another Column'], 5, 1], [(31478205, 3), [['or '], ['or']], [[' select sum(n)\nfrom\n (select OrderNo, max(OrderLineNo) as n\n  from tab\n  group by OrderNo\n ) as dt;\n']], ['Counting Values based on distinct values from another Column'], 5, 1], [(31478205, 4), [['or'], ['-10000']], [[' select sum(Dist_count)\nfrom\n ( select OrderNo,count(distinct OrderLineNo) as Dist_count\n   from Table1\n   group by OrderNo\n ) as dt\n']], ['Counting Values based on distinct values from another Column'], 5, 1], [(31533615, 0), [['Edit'], ['-10000']], [[" DECLARE @Data table (Name varchar(10), Id varchar(10)) -- Id must be varchar for blank value\nINSERT @Data VALUES\n('John', '1'),\n('Peter', '2'),('Peter', '2'), \n('Peter', '3'),--('Peter', ''), --For test\n('Lisa', '4'),\n('Lisa', NULL),\n('David', '5'),\n('David', ''),\n('Ralph', ''), ('Ralph', '')\n"]], ['Combine rows if value is blank'], 2, 0], [(31533615, 1), [['-10000'], ['-10000']], [[" SELECT \n    Name, \n    Id, \n    COUNT(*) + ISNULL(\n        (SELECT COUNT(*) FROM @data WHERE Name = d.Name AND Id = '' AND d.Id <> '')\n    , 0) AS Cnt \nFROM @data d \nWHERE \n    Id IS NULL \n    OR Id <> '' \n    OR NOT EXISTS(SELECT * FROM @data WHERE Name = d.Name AND Id <> '')\nGROUP BY Name, Id\n"]], ['Combine rows if value is blank'], 2, 1], [(31544792, 0), [['Something like this.'], ['or You need to join the result to main table to get the thematic_class1 and thematic_class2 for min  jm_dist  and  data_bands']], [[' SELECT * \nFROM   (SELECT Row_number()OVER(partition BY data_bands ORDER BY jm_dist) AS RN, \n               data_bands, \n               thematic_class1, \n               thematic_class2\n               Avg(sep.jm_dist)OVER(partition BY data_bands) as avarage_jm_dist\n               jm_dist  \n        FROM   separabilities) A \nWHERE  rn = 1 \n']], ['PostgreSQL getting row where one column is min'], 2, 1], [(31544792, 1), [['or You need to join the result to main table to get the thematic_class1 and thematic_class2 for min  jm_dist  and  data_bands'], ['-10000']], [[' SELECT * \nFROM   separabilities A \n       INNER JOIN (SELECT sep.data_bands, \n                          Sum(sep.jm_dist) / Count(sep.data_bands) AS avarage_jm_dist\n                          Min(jm_dist)                             AS jm_dist \n                   FROM   separabilities AS sep \n                   GROUP  BY sep.data_bands) B \n               ON A.data_bands = B.data_bands \n                  AND A.jm_dist = B.jm_dist \nORDER  BY avarage_jm_dist \n']], ['PostgreSQL getting row where one column is min'], 2, 1], [(31565962, 0), [['Done using two sub-queries:'], ['This can further be translated into a single sub-query using a  JOIN .']], [[" SELECT * \nFROM t1 \nWHERE Reqid in \n(\n    SELECT t11.Reqid \n    FROM t1 as t11\n    WHERE \n        (t11.FIELDID='76' AND t11.LISTITEMID='3548') \n        OR (t11.FIELDID='77' AND t11.LISTITEMID='3550')\n) \nAND Reqid in \n(\n    SELECT t11.Reqid \n    FROM t1 as t11\n    WHERE  \n        (t11.FIELDID='86' AND (t11.LISTITEMID='3491' OR t11.LISTITEMID='2380')) \n        OR (t11.FIELDID='87' AND (t11.LISTITEMID='3494' OR t11.LISTITEMID='2386'))\n)\nORDER BY REQUIREMENTID\n"]], ['Get only rows where 2 conditions are fulfilled in Microsoft SQL'], 2, 1], [(31565962, 1), [['This can further be translated into a single sub-query using a  JOIN .'], ['-10000']], [[" SELECT * \nFROM t1 \nWHERE Reqid in \n(\n    SELECT t11.Reqid \n    FROM t1 as t11\n    JOIN t1 as t12 on t11.Reqid = t12.Reqid\n    WHERE \n        ((t11.FIELDID='76' AND t11.LISTITEMID='3548') OR (t11.FIELDID='77' AND t11.LISTITEMID='3550'))\n        AND\n        (\n            (t12.FIELDID='86' AND (t12.LISTITEMID='3491' OR t12.LISTITEMID='2380')) \n            OR (t12.FIELDID='87' AND (t12.LISTITEMID='3494' OR t12.LISTITEMID='2386'))\n        )\n) \nORDER BY REQUIREMENTID\n"]], ['Get only rows where 2 conditions are fulfilled in Microsoft SQL'], 2, 1], [(31643835, 0), [['If I were to guess that you were using MySQL, then you can do use  to_seconds() .  The following gives the average reference price for each minute, along with the date/time of the first price in the interval:'], ['In SQL Server, you can do:']], [[" select min(recievedon), avg(referenceprice)\nfrom dbname\nwhere recievedon >= '2015-06-05 10:30' AND recievedon <= '2015-06-05 10:50'\ngroup by floor(to_seconds(receivedon) / 60) \n"]], ['Difficulty in displaying large number of values on a Chart'], 3, 1], [(31643835, 1), [['In SQL Server, you can do:'], ['If you want the beginning of the period rather than the earlier timestamp:']], [[" select min(receivedon), avg(referenceprice)\nfrom dbname\nwhere recievedon >= '2015-06-05 10:30' AND recievedon <= '2015-06-05 10:50'\ngroup by datediff(minute, 0, receivedon);\n"]], ['Difficulty in displaying large number of values on a Chart'], 3, 1], [(31643835, 2), [['If you want the beginning of the period rather than the earlier timestamp:'], ['-10000']], [[" select dateadd(minute, 0, datediff(minute, 0, receivedon)) as timeperiod,\n       avg(referenceprice)\nfrom dbname\nwhere recievedon >= '2015-06-05 10:30' AND recievedon <= '2015-06-05 10:50'\ngroup by dateadd(minute, 0, datediff(minute, 0, receivedon)) ;\n"]], ['Difficulty in displaying large number of values on a Chart'], 3, 1], [(31659215, 0), [['How about just using a subquery?'], ['Your question is a bit complicated.  This is definitely a  reasonable  approach.  It may be faster to put the subquery in a table and build an index on the table for the join.  However, a red flag is the  count(distinct) .  In my experience with Hive, the following is faster than the above subquery:']], [[' SELECT A.pers_key,\n       B.sum_cost / A.months AS ind1,\n       B.visit_count / A.months AS ind2\nFROM TABLE2 A JOIN\n     (SELECT pers_key, SUM(cost) AS sum_cost,\n             COUNT(DISTINCT visit) AS visit_count\n      FROM TABLE1\n      GROUP BY pers_key\n     ) B\n     ON A.pers_key = B.pers_key;\n']], ['Combining two queries where one uses GROUP BY'], 2, 1], [(31659215, 1), [['Your question is a bit complicated.  This is definitely a  reasonable  approach.  It may be faster to put the subquery in a table and build an index on the table for the join.  However, a red flag is the  count(distinct) .  In my experience with Hive, the following is faster than the above subquery:'], ["It is a bit counter-intuitive (to me) that this version is faster.  But, what happens is that the  group by  is that Hive readily parallelizes the  group by s.  On the other hand, the  count(distinct)  is processed serially.  This sometimes occurs in other databases (I've seen similar behavior in Postgres with  count(distinct) .  And another caveat:  I did not set up the Hive system where I discovered this, so it might be some sort of configuration issue."]], [['      (SELECT pers_key, SUM(sum_cost) AS sum_cost,\n             COUNT(visit) AS visit_count\n      FROM (SELECT pers_key, visit, SUM(cost) as sum_cost\n            FROM TABLE1\n            GROUP BY pers_key, visit\n           ) t\n      GROUP BY pers_key\n     ) B\n']], ['Combining two queries where one uses GROUP BY'], 2, 1], [(31685845, 1), [['With your table structure, you could do something like:'], ['-10000']], [[" UPDATE incoming\n    SET TagName = (SELECT TOP 1 tst.TagName\n                   FROM TagSearchTerms tst JOIN\n                        TagName tn\n                        ON tst.tagname = tn.tagname\n                   WHERE incoming.title like '%' + tst.searchterm + '%'\n                   ORDER BY tn.rank\n                  );\n"]], ['How to tag certain records in a table based on terms within another table?'], 2, 1], [(31720854, 0), [["I assume you already have  spark-context  ( sc ) and  sql-context  ( sql-ctx ). First lets import all the stuff we'll need:"], ['-10000']], [[' (import org.apache.spark.sql.RowFactory)\n(import org.apache.spark.sql.types.StructType)\n(import org.apache.spark.sql.types.StructField)\n(import org.apache.spark.sql.types.Metadata)\n(import org.apache.spark.sql.types.DataTypes)\n']], ['Convert clojure vector to flambo sql row'], 7, 0], [(31720854, 1), [['-10000'], ['-10000']], [[' ;; Vector to Row conversion\n(defn vec->row [v] \n  (RowFactory/create (into-array Object v)))\n\n;; Example data\n(def rows (-> (f/parallelize sc [["foo" 1] ["bar" 2]])\n              (f/map vec->row)))\n']], ['Convert clojure vector to flambo sql row'], 7, 0], [(31720854, 2), [['-10000'], ['-10000']], [[' ;; Define schema\n(def schema\n  (StructType.\n   (into-array StructField\n     [(StructField. "k" (DataTypes/StringType) false (Metadata/empty))\n      (StructField. "v" (DataTypes/IntegerType) false (Metadata/empty))])))\n\n;; Create data frame\n(def df (.createDataFrame sql-ctx rows schema))\n\n;; See if it works\n(.show df)\n']], ['Convert clojure vector to flambo sql row'], 7, 0], [(31720854, 3), [['-10000'], ['-10000']], [[' (.registerTempTable df "df")\n']], ['Convert clojure vector to flambo sql row'], 7, 0], [(31720854, 4), [['-10000'], ['-10000']], [[' (def df-keys (.sql sql-ctx "SELECT UPPER(k) as k FROM df"))\n;; Check results\n(.show df-keys)\n']], ['Convert clojure vector to flambo sql row'], 7, 0], [(31720854, 5), [['-10000'], ['or if you want vectors:']], [[' (.toJavaRDD df-keys)\n']], ['Convert clojure vector to flambo sql row'], 7, 0], [(31720854, 6), [['or if you want vectors:'], ['-10000']], [[' (f/map (.toJavaRDD df-keys) sql/row->vec)\n']], ['Convert clojure vector to flambo sql row'], 7, 0], [(31721962, 0), [['I think you need to do the update  before  doing the  delete .  This query will set the facility id to the lowest facility id for that name:'], ['Then you can delete all but the minimum:']], [[' update hotel_facility hf\n    set facility_id = (select min(f.facility_id)\n                       from facility f join\n                            facility f2\n                            on f.name = f2.name\n                       where f.id = hf.facility_id);\n']], ['Update table with duplicate rows in another table'], 2, 0], [(31721962, 1), [['Then you can delete all but the minimum:'], ['-10000']], [[' delete from facility f\n    where exists (select 1\n                  from facility f2\n                  where f2.name = f.name and f2.id > f.id\n                 );\n']], ['Update table with duplicate rows in another table'], 2, 0], [(31722522, 1), [['Or, perhaps,'], ['This tests that any matching value has  NULL  for  y .']], [[' select t1.x \nfrom @tablename t1 \nwhere not exists (select 1\n                  from @tablename as t2\n                  where t1.x = t2.x and t2.y is not null\n                 ) ;\n']], ['SQL Server all(select ...) is null'], 2, 1], [(31723200, 1), [["The output is a  daterange  which will look like '(2015-07-02, 2015-07-15)'. If you prefer a string format you can change the  daterange(...)  phrase into something like:"], ['or you can simply have two columns:']], [[" (to_char(lag(changed_date) OVER (PARTITION BY project_id ORDER BY changed_date), 'YYYY-MM-DD') ||\n' - ' || to_char(changed_date, 'YYYY-MM-DD') AS changed_date_range\n"]], ["Get date as 'from date' and 'to date' from same column in table"], 3, 0], [(31723200, 2), [['or you can simply have two columns:'], ['-10000']], [[' lag(changed_date) OVER (PARTITION BY project_id ORDER BY changed_date) AS date_from,\nchanged_date AS date_to\n']], ["Get date as 'from date' and 'to date' from same column in table"], 3, 0], [(31741652, 0), [['Schema details'], ['Table data before update']], [[" create table user\n(userid varchar(30));\n\ncreate table logs\n(log_detail varchar(100),\n userid varchar(30));\n\ninsert into user values('user1');\ninsert into user values('user2');\ninsert into user values('user3');\n\ninsert into logs values('update by user1','user3');\ninsert into logs values('inserted by user2','user2');\ninsert into logs values('inserted by user3',null);\n"]], ['Sql update statement with variable'], 4, 0], [(31741652, 1), [['Table data before update'], ['Update Query  ']], [[' |        log_detail | userid |\n|-------------------|--------|\n|   update by user1 |  user3 |\n| inserted by user2 |  user2 |\n| inserted by user3 | (null) |\n']], ['Sql update statement with variable'], 4, 0], [(31741652, 2), [['Update Query  '], ['Table data after update']], [['  update logs join user\nset logs.userid=user.userid\nwhere logs.log_detail LIKE concat("%",user.userID,"%");\n']], ['Sql update statement with variable'], 4, 1], [(31741652, 3), [['Table data after update'], ['-10000']], [[' |        log_detail | userid |\n|-------------------|--------|\n|   update by user1 |  user1 |\n| inserted by user2 |  user2 |\n| inserted by user3 |  user3 |\n']], ['Sql update statement with variable'], 4, 0], [(31771130, 0), [['You can use  AND/OR  logic to simulate the  If-else  condition in  where  clause. Try something like this'], ['or you can also use  Dynamic sql  to do this']], [[' select * from users \nwhere\nparentid= @id \nand \n(\n(@Type = 1 and UserType <> 0)\nor \n(@Type = 2 and UserType = 0)\nor \n(@Type = 3)\n)\n']], ['How to add generic condition to sp select?'], 2, 1], [(31771130, 1), [['or you can also use  Dynamic sql  to do this'], ['-10000']], [[" declare @Id uniqueidentifier = 'some parent guid'\ndeclare @Type int = 1 -- can be 1, 2 or 3\nDeclare @UserType varchar(max) --can be 0, anything else than 0, or all users at once\nDeclare @sql nvarchar(max)\n\nif(@Type = 1)\nset @UserType = ' and UserType <> 0'\nif(@Type = 2)\nset @UserType = ' and UserType = 0'\nif(@Type = 3)\nset @UserType = ''\n\nset @sql = 'select * from users where parentId ='''+ cast(@Id as varchar(25))+''''+ @UserType \n\n--Print @sql\n\nExec sp_executesql @sql\n"]], ['How to add generic condition to sp select?'], 2, 1], [(31831068, 1), [['This is the query that should do the trick:'], ["The result I've got is this:"]], [[' UPDATE posts SET post_score = (SELECT SUM(pvote_score) FROM pvotes WHERE fk_post_id = post_id);\n']], ['SQL Upvote Downvote system'], 2, 0], [(31840220, 0), [['You can use  convert()  and no  from  clause:'], ['or use 112:']], [[" SELECT REPLACE(CONVERT(VARCHAR(10), getdate(), 121), '-', '')\n"]], ['Migrating from Oracle to SQL server. Dual table select query -> SQL server'], 2, 1], [(31840220, 1), [['or use 112:'], ['-10000']], [[' SELECT CONVERT(VARCHAR(8), getdate(), 112)\n']], ['Migrating from Oracle to SQL server. Dual table select query -> SQL server'], 2, 1], [(31855759, 0), [['Query'], ['OUTPUT']], [[" SELECT\nISNULL(REVERSE(STUFF(REVERSE(col),1,PATINDEX('%[0-9]%',REVERSE(col)) -1,'')),'') as col\nFROM\n(\n    VALUES('ABCD123F'),('PORT123G67KK'),('123465'),('ABCDG')\n) as tab(col)\n"]], ['SQL Query/function to remove alphabets only from end'], 2, 1], [(31855759, 1), [['OUTPUT'], ['-10000']], [[" col\nABCD123\nPORT123G67\n123465\n''\n"]], ['SQL Query/function to remove alphabets only from end'], 2, 0], [(31899032, 0), [['Exactly how to do it depends on the DBMS you are using, but I think something like this should do the trick. Inspired by answers to  this  question.'], ['Please note, that if there are several matches for one row in  table2  (for instance, both Anna Smith and Anastasia Smith matching An... Smith), that row will be updated with both. The last one will be the one who sticks, but which one who happend to be last is pretty much random. To check if you have any cases like that, I think you could run this query:']], [[" UPDATE table2\nSET table2.firstname = table1.firstname\nFROM table1, table2\nWHERE\n    table1.lastname = table2.lastname AND \n    table1.firstname LIKE CONCAT(table2.firstname, '%')\n"]], ['Uniqe Replace Query'], 2, 1], [(31899032, 1), [['Please note, that if there are several matches for one row in  table2  (for instance, both Anna Smith and Anastasia Smith matching An... Smith), that row will be updated with both. The last one will be the one who sticks, but which one who happend to be last is pretty much random. To check if you have any cases like that, I think you could run this query:'], ['Disclaimar: I have not tested any of this.']], [[" SELECT table2.firstname, table2.lastname\nFROM table1, table2\nWHERE\n    table1.lastname = table2.lastname AND \n    table1.firstname LIKE CONCAT(table2.firstname, '%')\nGROUP BY table2.firstname, table2.lastname\nHAVING COUNT(*) > 1\n"]], ['Uniqe Replace Query'], 2, 0], [(31944662, 1), [['To extend the query above you then also need to join on the  person  table...'], ['Another alternative to the  LEFT JOIN  is to embed the correllated sub-query in the  SELECT  block.  This is effective when you only have one value to pull from the target table, but less effective if you need to pull many values from the target table...']], [[" CREATE VIEW DAILY_VALUE_DATA AS (\n    SELECT\n        PERSON.id   AS person_id,\n        DATE_TABLE.date,\n        VALUE_TABLE.value\n    FROM\n        PERSON\n    INNER JOIN\n        DATE_TABLE\n            ON  DATE_TABLE.date >=          PERSON.date_of_birth\n            AND DATE_TABLE.date <  COALESCE(PERSON.date_of_death, CURDATE() + 1)\n    LEFT JOIN\n        VALUE_DATA\n            ON  VALUE_DATA.start_date = (SELECT MAX(lookup.start_date)\n                                           FROM VALUE_DATA lookup\n                                          WHERE lookup.start_date <= DATE_TABLE.date\n                                            AND lookup.person_id   = PERSON.id\n                                        )\n);\n\nSELECT * FROM DAILY_VALUE_DATA WHERE person_id = 1 AND date = '2015-08-11'\n"]], ['Building a daily view from a table with an "effective date"'], 3, 1], [(31944662, 2), [['Another alternative to the  LEFT JOIN  is to embed the correllated sub-query in the  SELECT  block.  This is effective when you only have one value to pull from the target table, but less effective if you need to pull many values from the target table...'], ['-10000']], [[" CREATE VIEW DAILY_VALUE_DATA AS (\n    SELECT\n        PERSON.id   AS person_id,\n        DATE_TABLE.date,\n        (SELECT VALUE_DATA.value\n           FROM VALUE_DATA\n          WHERE VALUE_DATA.start_date <= DATE_TABLE.date\n            AND VALUE_DATA.person_id   = PERSON.id\n       ORDER BY VALUE_DATA.start_date DESC\n          LIMIT 1\n        )   AS value\n    FROM\n        PERSON\n    INNER JOIN\n        DATE_TABLE\n            ON  DATE_TABLE.date >=          PERSON.date_of_birth\n            AND DATE_TABLE.date <  COALESCE(PERSON.date_of_death, CURDATE() + 1)\n);\n\nSELECT * FROM DAILY_VALUE_DATA WHERE person_id = 1 AND date = '2015-08-11'\n"]], ['Building a daily view from a table with an "effective date"'], 3, 1], [(31965908, 0), [['You can do this with  charindex  and  reverse .'], ['Demo']], [[" select val \nfrom tbl\nwhere charindex('.', reverse(val)) = 3\n"]], ['Using SQL to query numbers that have more than tenths decimal place'], 2, 1], [(31965908, 1), [['Demo'], ['-10000']], [[" declare @tbl table(val varchar(50))\ninsert into @tbl select '11.02'\ninsert into @tbl select '411.0'\ninsert into @tbl select '11.44'\ninsert into @tbl select '1144.03'\ninsert into @tbl select '1441.5'\n\nselect val \nfrom @tbl\nwhere charindex('.', reverse(val)) = 3\n\noutput:\n11.02\n11.44\n1144.03\n"]], ['Using SQL to query numbers that have more than tenths decimal place'], 2, 1], [(31977969, 0), [['I would do this with grouping sets:'], ['Getting your exact output requires a bit more work.']], [[' select prop1, prop2, sum(val)\nfrom test_data\ngroup by grouping sets ((prop1), (prop2))\n']], ['Oracle SQL - Produce multiple different aggregations using analytic functions?'], 2, 1], [(31977969, 1), [['Getting your exact output requires a bit more work.'], ['This assumes that the first two columns do not contain  NULL  values.  The better way to express the logic is using  GROUPING_ID  or  GROUP_ID() , but I think the logic is easier to follow with  COALESCE() .']], [[" select (case when prop1 is null then 'prop2' else 'prop1' end) as prop_name,\n       coalesce(prop1, prop2) as prop,\n       sum(value)\nfrom test_data\ngroup by grouping sets ((prop1), (prop2));\n"]], ['Oracle SQL - Produce multiple different aggregations using analytic functions?'], 2, 1], [(31978339, 0), [['It sounds like you’re looking for an anti-join. If you can insert  $products  into a temp table, you can use  not exists  to get product ids that are not in the table:'], ['Another approach is to get all the product ids that do exist']], [[' select * from temp_product_ids t\nwhere not exists (\n    select 1 from products p\n    where p.id = t.product_id\n)\n']], ["SQL: Return the values from an array where some of them don't exist in the table"], 3, 1], [(31978339, 1), [['Another approach is to get all the product ids that do exist'], ['and to use  array_diff  to see which values are missing']], [[' select id from products where id in ( $my_products )\n']], ["SQL: Return the values from an array where some of them don't exist in the table"], 3, 0], [(31978339, 2), [['and to use  array_diff  to see which values are missing'], ['-10000']], [[' $missing_products = array_diff($my_products,$database_products);\n']], ["SQL: Return the values from an array where some of them don't exist in the table"], 3, 0], [(32049478, 0), [['Using  DATEADD  and  DATEDIFF :'], ['To use in your  WHERE  clause:']], [[" DECLARE @ThisDate DATE = '20150817'\nSELECT DATEADD(YEAR, -1, DATEADD(MONTH, DATEDIFF(MONTH, '19000101', @ThisDate), '19000101'))\n"]], ['How can I get the last 12 months from the current date PLUS extra days till 1st of the last month retrieved'], 2, 1], [(32049478, 1), [['To use in your  WHERE  clause:'], ['-10000']], [[" DECLARE @ThisDate DATE = '20150817'\nSELECT *\nFROM <your_table>\nWHERE\n    <date_column> >= DATEADD(YEAR, -1, DATEADD(MONTH, DATEDIFF(MONTH, '19000101', @ThisDate), '19000101'))\n"]], ['How can I get the last 12 months from the current date PLUS extra days till 1st of the last month retrieved'], 2, 1], [(32053653, 0), [['First, an answer to your actual question: this is going to connect the two tables together, but the  WHERE  clause at the end will filter out the extra rows you are seeing. No idea what your actual table names are, so please replace them with whatever is necessary. '], ["Performance on that is likely not so great, since that extra  WHERE NOT EXISTS  will slow you down.  A far, far better model would be (written on SQL Server, since I don't have a db2 instance available to me:"]], [[' SELECT *\nFROM \n    Perc p\n     LEFT JOIN \n    Thresh t ON \n        p.Percentage <= t.Percentage    -- return all ranges that are greater than the current value\nWHERE NOT EXISTS\n  (\n    SELECT 1 \n    FROM Thresh x \n    WHERE   -- eliminate ranges that are higher than this range and greater than the current value\n        t.Percentage > x.Percentage AND         \n        p.Percentage <= x.Percentage            \n  )\n']], ['Implementing range condition in a SQL query'], 2, 1], [(32095863, 0), [['Your expected result '], ['Check my fiddle:  http://sqlfiddle.com/#!9/cbb566/7']], [[' user\nname1\nname4 \nname5 \n']], ['SQL query filter, count if'], 3, 0], [(32095863, 2), [['You can   http://sqlfiddle.com/#!9/cbb566/11  :'], ['-10000']], [[" SELECT `user`\nFROM table1 t1\nGROUP BY `user`\nHAVING SUM(IF(`app`='app1',1,0))>0\n AND SUM(IF(`app` LIKE 'not an app%',1,0))>0\n"]], ['SQL query filter, count if'], 3, 1], [(32096616, 0), [['-10000'], ['(Possibly not necessary here, but example of method that can be useful in more complex scenarios.)']], [[' SELECT\n  f,\n  COUNT(*)   overall_occurrences,\n  COUNT(CASE WHEN field = 1 THEN f END)   AS f1_occurrences,\n  COUNT(CASE WHEN field = 2 THEN f END)   AS f2_occurrences,\n  COUNT(CASE WHEN field = 3 THEN f END)   AS f3_occurrences,\n  COUNT(CASE WHEN field = 4 THEN f END)   AS f4_occurrences\nFROM\n(\n\n    SELECT 1 AS field, f1 AS f, datalist.* FROM datalist\n    UNION ALL\n    SELECT 2 AS field, f2 AS f, datalist.* FROM datalist\n    UNION ALL\n    SELECT 3 AS field, f3 AS f, datalist.* FROM datalist\n    UNION ALL\n    SELECT 4 AS field, f4 AS f, datalist.* FROM datalist\n)\n   pivotted\nWHERE\n   somefield = 0\nGROUP BY\n   f\nHAVING\n   COUNT(*) > 1\n']], ['SQL Check duplicated values in different fields'], 2, 1], [(32096616, 1), [['(Possibly not necessary here, but example of method that can be useful in more complex scenarios.)'], ['-10000']], [[' SELECT\n  f,\n  COUNT(*)   overall_occurrences,\n  COUNT(CASE WHEN field = 1 THEN f END)   AS f1_occurrences,\n  COUNT(CASE WHEN field = 2 THEN f END)   AS f2_occurrences,\n  COUNT(CASE WHEN field = 3 THEN f END)   AS f3_occurrences,\n  COUNT(CASE WHEN field = 4 THEN f END)   AS f4_occurrences\nFROM\n(\n\n    SELECT\n        pivotter.field,\n        CASE pivotter.field\n            WHEN 1 THEN datalist.f1\n            WHEN 2 THEN datalist.f2\n            WHEN 3 THEN datalist.f3\n            WHEN 4 THEN datalist.f4\n        END   AS f,\n        datalist.*\n    FROM\n        datalist\n    CROSS JOIN\n    (\n        SELECT 1 AS field\n        UNION ALL\n        SELECT 2 AS field\n        UNION ALL\n        SELECT 3 AS field\n        UNION ALL\n        SELECT 4 AS field\n    )\n        AS pivotter\n)\n   pivotted\nWHERE\n   somefield = 0\nGROUP BY\n   f\nHAVING\n   COUNT(*) > 1\n']], ['SQL Check duplicated values in different fields'], 2, 1], [(32112171, 0), [['You can do it like this:'], ["edit: since Access2k doesn't supprt  cross join  the query can be rewritten as:"]], [[' select distinct b.Key_B, a.Key_A, a.A_1, b1.B_1\nfrom T_A a cross join (select key_b from T_B) b\nleft join T_B b1 on b1.Key_B = b.Key_B and b1.Key_A = a.Key_A;\n']], ['SQL UNION or similar to supply missing absent rows? (Take two)'], 2, 1], [(32112171, 1), [["edit: since Access2k doesn't supprt  cross join  the query can be rewritten as:"], ['-10000']], [[' select distinct c.Key_B, c.Key_A, c.A_1, B1.B_1 \nfrom (\n    select a.Key_A, a.A_1, b.Key_B \n    from T_A a, (select key_b from T_B) b\n) c \nleft join T_B b1 on B1.Key_B = c.Key_B and B1.Key_A = c.Key_A ;\n']], ['SQL UNION or similar to supply missing absent rows? (Take two)'], 2, 1], [(32128843, 0), [['This will give you rows 1 and 3'], ['Just use  DESC  in order by and you will get rows 2 and 4']], [[' Select * from (\n   Select * , Row_number() Over(Partition by a_num, a_code order by id) r_num from Your_Table ) result\nWhere r_num = 1\n']], ['Oracle select query to filter rows'], 2, 1], [(32128843, 1), [['Just use  DESC  in order by and you will get rows 2 and 4'], ['-10000']], [[' Select * from (\n   Select * , Row_number() Over(Partition by a_num, a_code order by id desc) r_num from Your_Table ) result\nWhere r_num = 1\n']], ['Oracle select query to filter rows'], 2, 1], [(32150683, 0), [['I would try something like this:'], ["I feel like my math is slightly off or I'm missing something, however, because I'm currently kind of tired.  I encourage you to look at each of these individually understand what it's doing:"]], [[' FLOOR(B.MaxVal / COUNT(B.bId) OVER (PARTITION BY B.bId)) \n+ CASE \n    WHEN ROW_NUMBER() OVER (PARTITION BY b.bId ORDER BY b.bId) <= (B.MaxVal % COUNT(B.bId) OVER (PARTITION BY B.bId)) THEN 1 \n    ELSE 0 \nEND as "DISTRIBUTED_AVG"\n']], ['SQL distribute values across rows'], 2, 1], [(32150683, 1), [["I feel like my math is slightly off or I'm missing something, however, because I'm currently kind of tired.  I encourage you to look at each of these individually understand what it's doing:"], ['-10000']], [[' SELECT DISTINCT A.aId,\n    B.bId,\n    B.MaxVal,\n    B.MaxVal / Count(B.bId) OVER (PARTITION BY B.bId) AS \'AVG\'\n    FLOOR(B.MaxVal / COUNT(B.bId) OVER (PARTITION BY B.bId)), \n    ROW_NUMBER() OVER (PARTITION BY b.bId ORDER BY b.bId), \n    B.MaxVal % COUNT(B.bId) OVER (PARTITION BY B.bId),\n    ROUND(B.MaxVal / COUNT(B.bId) OVER (PARTITION BY B.bId),0,1) \n    + CASE \n        WHEN ROW_NUMBER() OVER (PARTITION BY b.bId ORDER BY b.bId) <= (B.MaxVal % COUNT(B.bId) OVER (PARTITION BY B.bId)) THEN 1 \n        ELSE 0 \n    END as "DISTRIBUTED_AVG"\nFROM [...]\n']], ['SQL distribute values across rows'], 2, 0], [(32182160, 0), [['If you just want to count the first "word" in the message, then use  substring_index() :'], ['You can do this in Postgres by looking for the first space:']], [[" select substring_index(message, ' ', 1) as messageType, count(*)\nfrom table t\ngroup by substring_index(message, ' ', 1)\norder by count(*) desc;\n"]], ['SQL count regex matches (PostgreSQL)'], 2, 1], [(32182160, 1), [['You can do this in Postgres by looking for the first space:'], ['-10000']], [[" select left(message, position(' ' in message) as messageType, count(*)\nfrom table t\ngroup by messageType\norder by count(*) desc;\n"]], ['SQL count regex matches (PostgreSQL)'], 2, 1], [(32241284, 0), [['SAMPLE DATA'], ['-10000']], [[" CREATE TABLE #Test\n(\n    Id NVARCHAR(100)\n)\nINSERT INTO #Test VALUES ('1;2;12;15;6;77')\n\nCREATE TABLE #Test2\n(\n    Id NVARCHAR(100),\n    Setcolumn NVARCHAR(100)\n)\nINSERT INTO #Test2 VALUES\n(1, 'false'), (2, 'false'), (3, 'false'), (4, 'false')\n"]], ['Filter Columns which have id in splitted String in sqlserver 2008'], 2, 0], [(32241284, 1), [['-10000'], ['-10000']], [[" ;WITH cte AS(\n SELECT   \n     Split.a.value('.', 'VARCHAR(100)') AS Data  \n FROM  \n (\n     SELECT  \n         CAST ('<M>' + REPLACE(Id, ';', '</M><M>') + '</M>' AS XML) AS Data  \n     FROM  #Test\n ) AS A CROSS APPLY Data.nodes ('/M') AS Split(a) \n)\nUPDATE t\nSET t.Setcolumn = 'true'\nFROM cte \nJOIN #Test2 t ON cte.Data = t.Id\n\nSELECT * \nFROM #Test2\n"]], ['Filter Columns which have id in splitted String in sqlserver 2008'], 2, 1], [(32277369, 0), [["In Oracle, if you want a  timestamp  as the result, rather than a  date  (a  date  always includes the time to the second, though, so you may just want a  date ), you'd want to add an  interval  to the  timestamp .  There are various ways to construct an interval-- you can use an interval literal"], ['or you could use the  numtodsinterval  function']], [[" select current_timestamp + interval '10' second\n  from dual\n"]], ['How to add 10 seconds in current_timestamp SQL ( Oracle )'], 2, 1], [(32277369, 1), [['or you could use the  numtodsinterval  function'], ['-10000']], [[" select current_timestamp + numToDSInterval( 10, 'second' )\n  from dual\n"]], ['How to add 10 seconds in current_timestamp SQL ( Oracle )'], 2, 1], [(32288840, 0), [['I think you want an aggregation and left outer join:'], ['The following simpler version would work for your example:']], [[" SELECT T1.Name\nFROM <table1> T1 JOIN\n     #TempSearch ts\n     ON T1.Name LIKE CONCAT('%', Ts.Value, '%')\nGROUP BY t1.Name\nHAVING COUNT(*) = (SELECT COUNT(*) FROM #TempSearch);\n"]], ['Filter results in SQL query for search'], 2, 1], [(32288840, 1), [['The following simpler version would work for your example:'], ['-10000']], [[" select t1.*\nfrom t1\nwhere t1.name like '%' + replace(@ModelName, ' ', '%') + '%';\n"]], ['Filter results in SQL query for search'], 2, 1], [(32304479, 0), [['The easy way is using a months table because you can have empty months.'], ['SQL Fiddle Demo']], [[' create table months (\n   month_id integer,\n   date_ini datetime,\n   date_end datetime\n) \n']], ['Query to total monthly hours for events spanning month borders'], 2, 0], [(32304479, 1), [['SQL Fiddle Demo'], ['You have 4 cases']], [[' WITH ranges as (\n    SELECT *\n    FROM \n        months m \n        LEFT JOIN events e \n            on   e.StartDate <= m.d_end\n            and  e.EndDate >= m.d_begin\n ) \nSELECT r.*, \n       DATEDIFF(hour, \n                CASE \n                    WHEN StartDate > d_begin THEN StartDate\n                    WHEN StartDate IS NULL THEN NULL\n                    ELSE d_begin\n                END, \n                CASE \n                    WHEN EndDate < d_end THEN EndDate\n                    WHEN EndDate IS NULL THEN NULL\n                    ELSE DATEADD(day,1,d_end)\n                END) as Hours\nFROM ranges r\n']], ['Query to total monthly hours for events spanning month borders'], 2, 1], [(32317079, 0), [["Just unnest the array and join it to your table. I'm going to make some assumptions about your schema... This is the record you were referring to, from which you can create an array  r[] :"], ['This is the table that contains values which you want to search for in your array of records:']], [[' CREATE TYPE r AS (\n  id INT,\n  text_value TEXT\n);\n']], ['Search an array of records in a WHERE clause'], 4, 0], [(32317079, 1), [['This is the table that contains values which you want to search for in your array of records:'], ['Now, simply join the two:']], [[" CREATE TABLE t(v) AS\nVALUES ('a'), ('b'), ('c'), ('d');\n"]], ['Search an array of records in a WHERE clause'], 4, 0], [(32317079, 3), [['This will yield'], ['-10000']], [[' v  id  text_value\n-----------------\na  1   a\nb  2   b\n']], ['Search an array of records in a WHERE clause'], 4, 0], [(32332145, 0), [['-10000'], ['The output would look like this:']], [[' CREATE PROCEDURE RETURN_SELECT\nAS BEGIN\n\n    DECLARE @MY_VARIABLE int \n    SELECT @MY_VARIABLE = 2\n    SELECT @MY_VARIABLE\nEND\n\n\nEXEC RETURN_SELECT\n']], ['How to set and return a variable in a Sybase stored procedure'], 2, 1], [(32332145, 1), [['The output would look like this:'], ['As simple as it gets, dont know if it helps, or you wanted something more?']], [[' @MY_VARIABLE\n2\n']], ['How to set and return a variable in a Sybase stored procedure'], 2, 0], [(32367084, 0), [['You need to create an additional table:'], ['Then you can use a  JOIN  to get your result:']], [[' CREATE TABLE book_categories (\n    book_id INT,\n    category_id INT,\n    PRIMARY KEY (book_id, category_id),\n    FOREIGN KEY book_id REFERENCES book (id),\n    FOREIGN KEY category_id REFERENCES category (id)\n)\n']], ['How to fetch details and how to connect category and book table structure ( how to use GROUP_CONCAT)'], 2, 0], [(32367084, 1), [['Then you can use a  JOIN  to get your result:'], ['-10000']], [[' SELECT book_name, GROUP_CONCAT(category_name)\nFROM book AS b\nJOIN book_categories AS bc ON bc.book_id = b.id\nJOIN categoriy AS c ON c.id = bc.category_id\nGROUP BY b.id\n']], ['How to fetch details and how to connect category and book table structure ( how to use GROUP_CONCAT)'], 2, 0], [(32372280, 0), [["Let's create our test data:"], ['MyTable:']], [[" CREATE TABLE MyTable(\n    ID  INT IDENTITY(1, 1),\n    IDType  INT,\n    B   VARCHAR(6)\n)\nINSERT INTO MyTable(IDType, B) VALUES\n(2, 'Rev'), (2, 'Rev'),\n(2, 'Rev'), (1, 'Rev'),\n(1, 'Rev'), (1, 'Rev'),\n(1, 'NotRev'), (1, 'NotRev');\n"]], ['How to return an array of values in output parameter in Stored Proc'], 4, 0], [(32372280, 1), [['MyTable:'], ['Now create your stored procedure:']], [[' ID          IDType      B\n----------- ----------- ------\n1           2           Rev\n2           2           Rev\n3           2           Rev\n4           1           Rev\n5           1           Rev\n6           1           Rev\n7           1           NotRev\n8           1           NotRev\n']], ['How to return an array of values in output parameter in Stored Proc'], 4, 0], [(32372280, 2), [['Now create your stored procedure:'], ['Executing your stored procedure will return:']], [[" CREATE PROCEDURE MyStoredProc\nAS\nBEGIN\n\n    UPDATE MyTable\n        SET IDType = 2\n    OUTPUT INSERTED.ID -- Returns the IDs of the updated rows\n    WHERE \n        IDType = 1\n        AND B = 'REV'\n\nEND\n"]], ['How to return an array of values in output parameter in Stored Proc'], 4, 1], [(32372280, 3), [['Executing your stored procedure will return:'], ['-10000']], [[' ID\n-----------\n4\n5\n6\n']], ['How to return an array of values in output parameter in Stored Proc'], 4, 0], [(32381393, 0), [['Your query:'], ['is correct for what you want to do.  If you are getting the same city on different rows, then perhaps you have a data issue.  For instance, perhaps there are unprintable characters after the city name that look like spaces, but are not.  One way to tell is by delimiting the city name and looking at its length, something like:']], [[" SELECT count(city), city\nFROM cities\nWHERE userid = '1'\nGROUP BY city\nORDER BY count(city) DESC\nLIMIT 5;\n"]], ['SQL order by and group by city'], 2, 0], [(32381393, 1), [['is correct for what you want to do.  If you are getting the same city on different rows, then perhaps you have a data issue.  For instance, perhaps there are unprintable characters after the city name that look like spaces, but are not.  One way to tell is by delimiting the city name and looking at its length, something like:'], ['-10000']], [[' SELECT count(city), concat(\'"\', city, \'"\'), length(city)\nFROM cities\nWHERE userid = \'1\'\nGROUP BY city\nORDER BY count(city) DESC\nLIMIT 5;\n']], ['SQL order by and group by city'], 2, 1], [(32427391, 0), [['When you join tables, you basically query off a result set containing all the combinations of rows from those joined tables that your where clauses then operate off of.  Since you are joining to the  Emp_Certs  table just once and linking only by Employee_ID, you are getting a result set that looks like this (only showing two columns):'], ["1) Link to the table twice, joining for each of the certifications.  Table alias 'a' joins to the Emp_Certs table where the Cert_ID is 1 and table alias 'b' joins to the Emp_Certs table where the Cert_ID is 4:"]], [[' Last_Name    Cert_ID\nJones        1\nJones        3\nJones        4\nSmith        1\nSmith        2\n']], ['SQL query with JOIN involving two criteria from same table'], 4, 0], [(32427391, 1), [["1) Link to the table twice, joining for each of the certifications.  Table alias 'a' joins to the Emp_Certs table where the Cert_ID is 1 and table alias 'b' joins to the Emp_Certs table where the Cert_ID is 4:"], ["This gives you a result set that looks like this (Smith doesn't show up because the join criteria doesn't allow any rows unless the employee can link to table  a  and  b ):"]], [[' SELECT \n    Employees.Employee_ID, Employees.Last_Name, Employees.First_Name \nFROM \n    Employees \nINNER JOIN \n    Emp_Certs a ON Employees.Employee_ID = a.Employee_ID AND a.Cert_ID = 1\nINNER JOIN \n    Emp_Certs b ON Employees.Employee_ID = b.Employee_ID AND b.Cert_ID = 4\nWHERE \n    Employees.Active_Member = Yes\nORDER BY Employees.Last_Name;\n']], ['SQL query with JOIN involving two criteria from same table'], 4, 1], [(32427391, 2), [["This gives you a result set that looks like this (Smith doesn't show up because the join criteria doesn't allow any rows unless the employee can link to table  a  and  b ):"], ['2) Use sub-selects in the where clause to filter the employee id on ids with those certifications (looks like  Access 2010 supports it ):']], [[' Last_Name    a.Cert_ID   b.Cert_ID\nJones        1           4\n']], ['SQL query with JOIN involving two criteria from same table'], 4, 0], [(32427391, 3), [['2) Use sub-selects in the where clause to filter the employee id on ids with those certifications (looks like  Access 2010 supports it ):'], ['-10000']], [[' SELECT \n    Employees.Employee_ID, Employees.Last_Name, Employees.First_Name \nFROM \n    Employees \nWHERE \n    Active_Member = Yes\n    AND Employee_ID in (SELECT Employee_ID FROM Emp_Certs WHERE Cert_ID = 1)\n    AND Employee_ID in (SELECT Employee_ID FROM Emp_Certs WHERE Cert_ID = 4)\nORDER BY Employees.Last_Name;\n']], ['SQL query with JOIN involving two criteria from same table'], 4, 1], [(32437153, 0), [['So you want to replace domain in emails, here is test select:'], ['And update will be:']], [[" select email, replace(email, '@gmail.com', '@custom.com') as new_email \nfrom auth_user \nwhere email like '%@gmail.com';\n"]], ['SQL command to update column value in table'], 2, 0], [(32437153, 1), [['And update will be:'], ['-10000']], [[" update auth_user \nset email = replace(email, '@gmail.com', '@custom.com') \nwhere email like '%@gmail.com';\n"]], ['SQL command to update column value in table'], 2, 1], [(32461027, 0), [['Your logic is close, but it is slightly different:'], ['It might be easier to follow the logic as:']], [["   SELECT DISTINCT\n         (CASE WHEN column2 IN (1, 2) THEN 'name2' // line 5\n               WHEN column2 IN (3, 4) THEN 'name3' // line 6\n              ELSE 'UNKNOWN'\n          END) AS column1\n  FROM table\n  WHERE column3 IS null AND\n        (column4 = True OR column2 NOT IN (3, 4)) \n"]], ['How to not apply logic in SQL where block to all when blocks'], 2, 1], [(32526207, 0), [["You've identified the problem correctly.  The solution is to pre-aggregate the data before the  join :"], ['Actually, for performance purposes a correlated subquery probably should work better:']], [[" SELECT RP.POLNUMBER, RP.EFFDATE, LP.PREMIUM\nFROM TBL_A RP INNER JOIN\n     (SELECT LP.POLNUMBER, SUM(LP.PREMIUM) as PREMIUM\n      FROM TBL_B\n      GROUP BY LP.POLNUMBER\n     ) LP\n     ON RP.POLNUMBER = LP.POLNUMBER\n WHERE RP.MOSTRECENTMODEL = 1 AND RP.POLNUMBER = 'ABC123';\n"]], ['SQL Join Duplicate records'], 2, 1], [(32526207, 1), [['Actually, for performance purposes a correlated subquery probably should work better:'], ['Your filter conditions look highly selective.  There is no reason to aggregate the entire table to just return results for a handful of policies.']], [[" SELECT RP.POLNUMBER, RP.EFFDATE\n       (SELECT SUM(LP.PREMIUM) as PREMIUM\n        FROM TBL_B LP\n        WHERE RP.POLNUMBER = LP.POLNUMBER\n       ) as PREMIUM\nFROM TBL_A RP \nWHERE RP.MOSTRECENTMODEL = 1 AND RP.POLNUMBER = 'ABC123';\n"]], ['SQL Join Duplicate records'], 2, 1], [(32563912, 1), [['By "longest sequence", do you mean the id with the most recurrences? In that case, replace the CTE with:'], ['-10000']], [[' SELECT id FROM mytable GROUP BY id ORDER BY COUNT(*) DESC LIMIT 1\n']], ['Select sequential column records and also find the longest sequence'], 2, 0], [(32565311, 0), [['Not quite sure if I got you right. This will return people who have job 56565 and/or 23232:'], ['If BOTH jobs are required:']], [[' select distinct p.name\nfrom people p\n  join jobs j on p.id = j.peopleid\nwhere j.id in (56565, 23232)\n']], ['SELECT records from two table'], 3, 1], [(32565311, 1), [['If BOTH jobs are required:'], ['The  HAVING  clause can also be written as']], [[' select p.name\nfrom people p\n  join jobs j on p.id = j.peopleid\nwhere j.id in (56565, 23232)\ngroup by p.name\nhaving count(*) > 1\n']], ['SELECT records from two table'], 3, 1], [(32565311, 2), [['The  HAVING  clause can also be written as'], ['Perhaps better performance that way.']], [[' having max(j.id) <> min(j.id)\n']], ['SELECT records from two table'], 3, 0], [(32594433, 0), [['You can use simple  AND ,  OR  operations to get what you want:'], ["If  @param < '1/1/2015' , then the  WHERE  clause becomes:"]], [[" SELECT * \nFROM TABLE \nWHERE ACTIVE_FLAG = 1 \n      AND (\n       (@param < '1/1/2015' AND COLUMN_1 = 'Warehouse')\n        OR\n       (@param >= '1/1/2015' AND COLUMN_2 = 'Warehouse, CA')\n      )\n"]], ['CASE in WHERE clause? Filter query by different column depending a value SQL Server 2008 R2'], 3, 1], [(32594433, 1), [["If  @param < '1/1/2015' , then the  WHERE  clause becomes:"], ["otherwise, in case when  @param >= '1/1/2015' , the  WHERE  clause becomes:"]], [[" ACTIVE_FLAG = 1 AND COLUMN_1 = 'Warehouse'\n"]], ['CASE in WHERE clause? Filter query by different column depending a value SQL Server 2008 R2'], 3, 0], [(32594433, 2), [["otherwise, in case when  @param >= '1/1/2015' , the  WHERE  clause becomes:"], ['-10000']], [[" ACTIVE_FLAG = 1 AND COLUMN_2 = 'Warehouse, CA'\n"]], ['CASE in WHERE clause? Filter query by different column depending a value SQL Server 2008 R2'], 3, 0], [(32615598, 0), [['try this:'], ['if you want to include conditions on your timesheet table, such as \n month(timestamp) = 9 and year(timestamp) = 2015 \nand you do it in the  WHERE  clause, it converts your  outer join  to an  inner join  because the  WHERE  clause requires fields in the timestamp table.  To limit by month and year of your  left outer join ed table, you put the conditions in the  JOIN  clause instead of  WHERE , like:']], [[" SELECT\n    u.UserID AS 'User',\n    u.FullName AS Name,\n    isnull(SUM(Minutes) / 60,0) AS [Time]\nFROM\n    MainUsers u left OUTER JOIN \n    TimeSheet t  ON \n    u.UserID = t.UserID\nGROUP BY\n    u.UserID,\n    u.FullName\nORDER BY\n    u.UserID\n"]], ['Full Outer Join with Group By'], 2, 1], [(32615598, 1), [['if you want to include conditions on your timesheet table, such as \n month(timestamp) = 9 and year(timestamp) = 2015 \nand you do it in the  WHERE  clause, it converts your  outer join  to an  inner join  because the  WHERE  clause requires fields in the timestamp table.  To limit by month and year of your  left outer join ed table, you put the conditions in the  JOIN  clause instead of  WHERE , like:'], ['sql fiddle']], [[" SELECT\n    u.UserID AS 'User',\n    u.FullName AS Name,\n    isnull(SUM(Minutes) / 60,0) AS [Time]\nFROM\n    MainUsers u left OUTER JOIN \n    TimeSheet t  ON \n    u.UserID = t.UserID and\n    month(timestamp) = 9 and year(timestamp) = 2015\nGROUP BY\n    u.UserID,\n    u.FullName\nORDER BY\n    u.UserID\n"]], ['Full Outer Join with Group By'], 2, 1], [(32633252, 0), [["You're very close. You just have a little extra happening in there. Take out the bit after the comma on your  FROM ..  line:"], ['Lastly, you can then use fields from your  K  table in your SELECT statement like:']], [[' CREATE VIEW [dbo].[V_PS_DA]\nAS WITH\ntoday AS\n(   SELECT * \n    FROM dbo.LK_NET_WORK_DAYS -- This contains the date data needed\n    WHERE [DATE] = CAST(GETDATE() AS DATE)\n)\nSELECT \n  p.*,\n  hrs.DATE_ORDINAL      ENTER_HRSC_ORDINAL,\n  strt.DATE_ORDINAL     START_DATE_ORDINAL,\n  ndt.DATE_ORDINAL      END_DATE_ORDINAL,\n  today.DATE_ORDINAL    TODAY_ORDINAL,\n  kst.[Small Title] Small_Title,\n  kt.[Title]    Title,\n  kd.[Demonstration]  Demonstration,\n  ks.SLS    SLS\n\nFROM dbo.PS_DA p\nLEFT JOIN dbo.LK_NET_WORK_DAYS hrs\n  ON p.ENTER_HRSC = hrs.[DATE]\nLEFT JOIN dbo.LK_NET_WORK_DAYS strt\n  ON p.START_DATE = strt.[DATE]\nLEFT JOIN dbo.LK_NET_WORK_DAYS ndt\n  ON p.END_DATE = ndt.[DATE]\nCROSS JOIN today,\nLEFT JOIN dbo.LK_METRICS k\n  ON k.METRIC_ID_OLD = METRIC_NUMBER\n']], ['SQL - Add multiple columns to a VIEW'], 2, 1], [(32633252, 1), [['Lastly, you can then use fields from your  K  table in your SELECT statement like:'], ['-10000']], [[' CREATE VIEW [dbo].[V_PS_DA]\nAS WITH\ntoday AS\n(   SELECT * \n    FROM dbo.LK_NET_WORK_DAYS -- This contains the date data needed\n    WHERE [DATE] = CAST(GETDATE() AS DATE)\n)\nSELECT \n  p.*,\n  k.somefield,\n  k.someotherfield,\n  hrs.DATE_ORDINAL      ENTER_HRSC_ORDINAL,\n  strt.DATE_ORDINAL     START_DATE_ORDINAL,\n  ndt.DATE_ORDINAL      END_DATE_ORDINAL,\n  today.DATE_ORDINAL    TODAY_ORDINAL,\n  kst.[Small Title] Small_Title,\n  kt.[Title]    Title,\n  kd.[Demonstration]  Demonstration,\n  ks.SLS    SLS\n\nFROM dbo.PS_DA p\nLEFT JOIN dbo.LK_NET_WORK_DAYS hrs\n  ON p.ENTER_HRSC = hrs.[DATE]\nLEFT JOIN dbo.LK_NET_WORK_DAYS strt\n  ON p.START_DATE = strt.[DATE]\nLEFT JOIN dbo.LK_NET_WORK_DAYS ndt\n  ON p.END_DATE = ndt.[DATE]\nCROSS JOIN today,\nLEFT JOIN dbo.LK_METRICS k\n  ON k.METRIC_ID_OLD = METRIC_NUMBER\n']], ['SQL - Add multiple columns to a VIEW'], 2, 1], [(32697433, 0), [['You can use  DENSE_RANK()  to give each of your unique combinations of  Surname ,  BirthDate  and  Sex  a unique number, then simply place this into an update statement to update your column:'], ['FULL WORKING EXAMPLE']], [[" UPDATE  t\nSET     ExtID = NewExtID\nFROM    (   SELECT  ExtID,\n                    NewExtID = 'R' + CAST(DENSE_RANK() \n                                            OVER(ORDER BY Surname, Birthdate, Sex) \n                                        AS VARCHAR(10))\n            FROM    dbo.YourTableName\n        ) AS t;\n"]], ['How to Auto-Number Duplicate Rows Using Sequence Based on Multiple Duplicate Columns (T-SQL)'], 7, 1], [(32697433, 1), [['FULL WORKING EXAMPLE'], ['-10000']], [[" IF OBJECT_ID(N'tempdb..#T', 'U') IS NOT NULL\n    DROP TABLE #T;\n\nCREATE TABLE #T\n(   Ref INT, \n    Surname VARCHAR(50), \n    Firstname VARCHAR(50), \n    Birthdate DATE, \n    Sex CHAR(1), \n    ExternalSource VARCHAR(50), \n    ExtID VARCHAR(11)\n);\n\nINSERT #T (Ref, Surname, Firstname, Birthdate, Sex, ExternalSource)\nVALUES\n    (1, 'AAA', 'AA', '2000-01-01', 'M', 'Alpha'),\n    (2, 'BBB', 'BB', '2001-01-01', 'F', 'Beta'),\n    (3, 'AAA', 'AA', '2000-01-01', 'M', 'Beta'),\n    (4, 'CCC', 'CC', '2003-01-01', 'M', 'Alpha'),\n    (5, 'BBB', 'BB', '2001-01-01', 'F', 'Gamma'),\n    (6, 'DDD', 'DD', '2004-01-01', 'M', 'Beta'),\n    (7, 'CCC', 'CC', '2003-01-01', 'M', 'Alpha'),\n    (8, 'AAA', 'AA', '2000-01-01', 'M', 'Gamma');\n\nUPDATE  t\nSET     ExtID = NewExtID\nFROM    (   SELECT  ExtID,\n                    NewExtID = 'R' + CAST(DENSE_RANK() \n                                            OVER(ORDER BY Surname, Birthdate, Sex) \n                                        AS VARCHAR(10))\n            FROM    #T\n        ) AS t;\n\nSELECT  *\nFROM    #T\nORDER BY Ref;       \n"]], ['How to Auto-Number Duplicate Rows Using Sequence Based on Multiple Duplicate Columns (T-SQL)'], 7, 1], [(32697433, 2), [['-10000'], ["Realistically, with a similar index on your base tables you probably don't need this ExtID column, you can just join to the above table to get the ExtID with not a huge performance hit, but on the off chance you did need to update the ExtID column you could use:"]], [[" CREATE TABLE dbo.Ext \n(\n        ID INT IDENTITY(1, 1) NOT NULL,\n        Surname VARCHAR(50) NOT NULL,\n        BirthDate DATE NOT NULL,\n        Sex CHAR(1) NOT NULL,\n        ExtID AS 'R' + CAST(ExtIntID AS VARCHAR(10)),\n    CONSTRAINT PK_Ext__ID PRIMARY KEY (ID),\n);\nCREATE UNIQUE NONCLUSTERED INDEX UQ_Ext__Surname_Birthdate_Sex ON dbo.Ext (Surname, Birthdate, Sex);\n"]], ['How to Auto-Number Duplicate Rows Using Sequence Based on Multiple Duplicate Columns (T-SQL)'], 7, 0], [(32697433, 4), [['If all of this is not suitable, then I would still suggest as above (if possible) removing the  R  from the identifier, and making it just an integer. You can, if needed, create the text column as a computed column:'], ['Then, your update statement is fairly similar:']], [[" CREATE TABLE #T\n(   Ref INT, \n    Surname VARCHAR(50), \n    Firstname VARCHAR(50), \n    Birthdate DATE, \n    Sex CHAR(1), \n    ExternalSource VARCHAR(50), \n    ExtIntID INT,\n    ExtID AS 'R' + CAST(ExtIntID AS VARCHAR(10))\n);\n"]], ['How to Auto-Number Duplicate Rows Using Sequence Based on Multiple Duplicate Columns (T-SQL)'], 7, 0], [(32719239, 0), [['Limiting your results to 3  B Number s at most is easy using the  row_number()  analytic function.'], ['In any case, whatever field(s) define(s) the order of your list, use that in the  order by  clause of the  row_number()  function call:']], [[' select a_number, b_number\n  from (select a_number, b_number,\n               row_number() over (partition by b_number order by null) as rn\n          from your_table)\n where rn <= 3\n']], ['ORACLE: How to check for and remove repeating column values'], 2, 1], [(32732880, 0), [['I assume the table and data as below. '], ['And the query is like this.']], [[" create table visit (visit_to text, visit_by text, visit_on datetime, value int);\ninsert into visit values('x', 'a', '2015-02-02 00:00:00', 1);\ninsert into visit values('x', 'b', '2015-02-16 00:00:00', 2);\ninsert into visit values('y', 'c', '2015-02-18 00:00:00', 3);\ninsert into visit values('x', 'd', '2015-02-14 00:00:00', 4);\n"]], ['Creating views with different columns than table'], 2, 0], [(32732880, 1), [['And the query is like this.'], ['You can try  http://goo.gl/TXomRO']], [[" select\n    visit_to,\n    date(visit_on, 'start of month') year_month,\n    replace(rtrim(group_concat((case when date(date(visit_on, '-15 days'), 'start of month') <> date(visit_on, 'start of month') then visit_by else '' end), (case when date(date(visit_on, '-15 days'), 'start of month') <> date(visit_on, 'start of month') then ' ' else '' end))), ' ', ',') fortnite1,\n    replace(rtrim(group_concat((case when date(date(visit_on, '-15 days'), 'start of month') = date(visit_on, 'start of month') then visit_by else '' end), (case when date(date(visit_on, '-15 days'), 'start of month') = date(visit_on, 'start of month') then ' ' else '' end))), ' ', ',') fortnite2\nfrom visit\ngroup by visit_to, date(visit_on, 'start of month')\n;\n"]], ['Creating views with different columns than table'], 2, 1], [(32768245, 0), [["You'll want to check that records don't exist where 'date from' is less than or equal to the end date in your range and 'date to' is greater than or equal to the start date in your range."], ['As mentioned in a previous comment, this is only good if all of the rooms have a reservation record. If not, better to select from your rooms table like this:  http://sqlfiddle.com/#!9/0b96e/1']], [[" select t1.room\nfrom reservations t1\nwhere not exists (\n  select *\n  from reservations t2\n  where t2.room = t1.room\n  and t2.datefrom <= '2015-08-26'\n  and t2.dateto >= '2015-08-13'\n)\ngroup by room\n"]], ['Select * from table where desired period does not overlap with existing periods'], 2, 1], [(32768245, 1), [['As mentioned in a previous comment, this is only good if all of the rooms have a reservation record. If not, better to select from your rooms table like this:  http://sqlfiddle.com/#!9/0b96e/1'], ['-10000']], [[" select room\nfrom rooms\nwhere not exists (\n  select *\n  from reservations\n  where rooms.room = reservations.room\n  and reservations.datefrom <= '2015-08-26'\n  and reservations.dateto >= '2015-08-13'\n)\n"]], ['Select * from table where desired period does not overlap with existing periods'], 2, 1], [(32802567, 0), [['You just need to add  Gate  to the  group by  and  select :'], ['Oops, sorry about that.  What you actually need is the first count from the  next  hour.  SQL has a great function for that,  lag() .  But not SQLite.  But, you can do it with a correlated subquery:']], [[" SELECT gate, strftime('%Y-%m-%dT%H:00:00.000', DateTime),\n       max(Count) - min(Count) \nFROM GateTbl \nGROUP by gate, strftime('%Y-%m-%dT%H:00:00.000', DateTime);\n"]], ['SQLite query; Group By Hour And By Device'], 2, 0], [(32802567, 1), [['Oops, sorry about that.  What you actually need is the first count from the  next  hour.  SQL has a great function for that,  lag() .  But not SQLite.  But, you can do it with a correlated subquery:'], ['The  coalesce()  is just for the last hour.  This uses the last timestamp during that hour.  If there is only one, then you will get 0 for that hour.']], [[" WITH gh as (\n      SELECT gate, strftime('%Y-%m-%dT%H:00:00.000', DateTime) as dt,\n             MIN(Count) as mincount, MAX(count) as maxcount\n      FROM GateTbl \n      GROUP by gate, strftime('%Y-%m-%dT%H:00:00.000', DateTime)\n     )\nSELECT gh.gate, gh.dt,\n       COALESCE(gh.next_mincount, gh.maxcount) - gh.mincount\nFROM (SELECT gh.*,\n             (SELECT gh2.mincount\n              FROM gh gh2\n              WHERE gh2.gate = gh.gate AND gh2.dt > gh.dt\n              ORDER BY gh2.dt\n              LIMIT 1\n             ) as next_mincount\n      FROM gh\n     ) gh;\n"]], ['SQLite query; Group By Hour And By Device'], 2, 1], [(32819225, 0), [['If you can live with the answer as 3 rows instead of 9, the easiest way is:'], ['Otherwise, you can do this using variables:']], [[" select c.*,\n       substring_index(group_concat(q.id order by rand()), ',', 3) as question_ids\nfrom category c join\n     question q\n     on c.id = q.cat_id\ngroup by c.id\norder by rand();\n"]], ['MySQL Limit joined table'], 2, 1], [(32819225, 1), [['Otherwise, you can do this using variables:'], ['Of course, you should select the columns you actually need rather than using  * .']], [[' select cq.*\nfrom (select c.*, q.*,\n             (@rn := if(@c = c.id, @rn + 1,\n                        if(@c := c.id, 1, 1)\n                       )\n             ) as rn\n      from (select c.*\n            from category c\n            order by rand()\n            limit 3\n           ) c join\n           question q\n           on c.id = q.cat_id cross join\n           (select @c := 0, @rn := 0) params\n      order by c.id, rand()\n     ) cq\nwhere rn <= 3;\n']], ['MySQL Limit joined table'], 2, 1], [(32832623, 1), [['If you want more complicated answers, like especific values, lists of values, you can create one more model: '], ['And then redefine  UserAnswer :']], [[' class QuestionAlternative(models.Model):\n    question = models.ForeignKey(Question)\n    value = models.CharField(...)\n']], ['SQL database (Django) - Relate all records in table B to each record in table A'], 3, 0], [(32832623, 2), [['And then redefine  UserAnswer :'], ['With this, you will have the  Questions  in one place, one  UserAnswer  per question, and the  QuestionAlternative s how many times they must exist. Does not worry about the  ForeignKey  fields, they are not overheads and they build beautiful, reusable structures.']], [[' class UserAnswer(models.Model):\n    question = models.ForeignKey(Question)\n    user = models.ForeignKey(User)\n    answer = models.ForeignKey(QuestionAlternative)\n']], ['SQL database (Django) - Relate all records in table B to each record in table A'], 3, 0], [(32849144, 0), [['MS SQL Server 2008 Schema Setup :'], ['Query 1 :']], [[" CREATE TABLE Table1\n    ([AUDITKEY] varchar(36), [AUDITTYPE] int, [AUDITTYPECODE] varchar(13), [KEYNAME] varchar(9))\n;\n\nINSERT INTO Table1\n    ([AUDITKEY], [AUDITTYPE], [AUDITTYPECODE], [KEYNAME])\nVALUES\n    ('12345678-1234-1234-1234-123456789012', 0, 'before update', 'BLABLABLA'),\n    ('12345678-1234-1234-1234-123456789012', 1, 'after update', 'BLABLABLA'),\n    ('22345678-1234-1234-1234-123456789012', 0, 'before update', 'BLABLA'),\n    ('22345678-1234-1234-1234-123456789012', 1, 'after update', 'ALBALB')\n;\n"]], ['SQL to compare field values within a set of rows grouped by a unique ID per group'], 3, 0], [(32849144, 2), [['Results :'], ['-10000']], [[' |                             AUDITKEY | KEYNAME |\n|--------------------------------------|---------|\n| 22345678-1234-1234-1234-123456789012 |  ALBALB |\n']], ['SQL to compare field values within a set of rows grouped by a unique ID per group'], 3, 0], [(32864721, 0), [['Use  exists :'], ['I should point out that some databases support row constructors with  in .  That allows you to do:']], [[' select t.location, t.warehouse\nfrom table1 t\nwhere exists (select 1\n              from table2 t2\n              where t.location = t2.area and t.warehouse = t2.code\n             );\n']], ['Where clause to check against two columns in another table'], 2, 1], [(32864721, 1), [['I should point out that some databases support row constructors with  in .  That allows you to do:'], ['-10000']], [[' select t.location, t.warehouse\nfrom table1 t\nwhere(t1.location, t1.warehouse) in (select t2.area, t2.code from table2 t2);\n']], ['Where clause to check against two columns in another table'], 2, 1], [(32880727, 0), [['Have you tried using MAX()?'], ['OUTPUT:']], [[' select * from oehr_employees WHERE HIRE_DATE = (SELECT MAX(HIRE_DATE) FROM OEHR_EMPLOYEES)\n']], ['how to get Latest date from table in oracle procedure'], 2, 1], [(32880727, 1), [['OUTPUT:'], ['-10000']], [[' EMPLOYEE_ID FIRST_NAME           LAST_NAME                 EMAIL                     PHONE_NUMBER         HIRE_DATE JOB_ID         SALARY COMMISSION_PCT MANAGER_ID DEPARTMENT_ID\n\n167 Amit    Banda   ABANDA  011.44.1346.729268  21-APR-00   SA_REP  6200    0.1 147 80\n173 Sundita Kumar   SKUMAR  011.44.1343.329268  21-APR-00   SA_REP  6100    0.1 148 80\n']], ['how to get Latest date from table in oracle procedure'], 2, 0], [(32928624, 0), [['Step one is to get a list of the newest dates. You can use this with  MAX(date)  but that alone will just get you the newest date in the table. You can tell the database you want the newest date  per name  with a  GROUP BY  clause. In this case,  GROUP BY name .'], ['Now you can do some date math on  MAX(date)  to determine how old it is. MySQL has  DATEDIFF  to get the difference between two dates in days.   CURRENT_DATE()  gives the current date.  So  DATEDIFF(MAX(date), CURRENT_DATE()) .']], [[' SELECT name, MAX(date)\nFROM names\nGROUP BY name\n']], ['SQL foreach table and get number for duplicate data using reference date'], 3, 0], [(32928624, 1), [['Now you can do some date math on  MAX(date)  to determine how old it is. MySQL has  DATEDIFF  to get the difference between two dates in days.   CURRENT_DATE()  gives the current date.  So  DATEDIFF(MAX(date), CURRENT_DATE()) .'], ['Finally, to append the "days" part, use  CONCAT .']], [[' SELECT name, DATEDIFF(MAX(date), CURRENT_DATE()) as Days\nFROM names\nGROUP BY name\n']], ['SQL foreach table and get number for duplicate data using reference date'], 3, 0], [(32928624, 2), [['Finally, to append the "days" part, use  CONCAT .'], ['You can  play around with it in SQLFiddle .']], [[' SELECT name, CONCAT(DATEDIFF(MAX(date), CURRENT_DATE()), " days") as Days\nFROM names\nGROUP BY name\n']], ['SQL foreach table and get number for duplicate data using reference date'], 3, 0], [(32933497, 0), [['Your method of storing the dates is exactly wrong for what you want to do.  The general form would be:'], ['Now, if you stored the dates normally, then you would simply do:']], [[' where (year = 2014 and day >= 275 or year > 2014) and\n      (year = 2015 and day <= 176 or year < 2015)\n']], ['MySQL select records between day of the year and year'], 2, 1], [(32933497, 1), [['Now, if you stored the dates normally, then you would simply do:'], ["What is really, really nice about this structure is that MySQL can use an index on  date .  That isn't possible with your query."]], [[' where date >= makedate(2014, 275) and date <= makedate(2015, 176)\n']], ['MySQL select records between day of the year and year'], 2, 1], [(32943515, 1), [['Outputs:'], ['You should rewrite as:']], [[' 2015-10-01 10:30:00.000\n2015-10-04 10:30:00.000\n2015-10-05 10:30:00.000\n\n2015-10-01 10:30:00.000\n2015-10-04 10:30:00.000\n\n2015-10-01 10:30:00.000\n2015-10-04 10:30:00.000\n2015-10-05 10:30:00.000\n']], ['Get records between two datetimes in SQL Server'], 3, 0], [(32943515, 2), [['You should rewrite as:'], ['-10000']], [[' SELECT office\nFROM   officebudget\nWHERE  officeid = @officeid\n       AND (\n               (\n                   bkto.DateFrom >= @wkstdate\n                   AND bkto.DateFrom < dateadd(dd, 1 , @wkenddate)\n               )\n               OR (bkto.DateTo >= @wkstdate\n               AND bkto.DateTo < dateadd(dd, 1, @wkenddate))\n           );\n']], ['Get records between two datetimes in SQL Server'], 3, 1], [(32958815, 2), [['Where  count_estimate  is function that analyzes the execution plan to get the estimation:'], ['-10000']], [[' CREATE FUNCTION count_estimate(query text) RETURNS INTEGER AS\n$func$\nDECLARE\n    rec   record;\n    ROWS  INTEGER;\nBEGIN\n    FOR rec IN EXECUTE \'EXPLAIN \' || query LOOP\n    ROWS := SUBSTRING(rec."QUERY PLAN" FROM \' rows=([[:digit:]]+)\');\n    EXIT WHEN ROWS IS NOT NULL;\nEND LOOP;\n\nRETURN ROWS;\nEND\n$func$ LANGUAGE plpgsql;\n']], ['query execution stops when overtake a threshold'], 3, 0], [(32962508, 0), [['SqlFiddleDemo'], ['SqlFiddleDemo']], [[" SELECT UPPER(TO_CHAR(TO_DATE(500,'J'),'Jsp')) || '/=' AS new_value\nFROM dual;  \n"]], ['How to convert number to words - ORACLE'], 3, 1], [(32962508, 1), [['SqlFiddleDemo'], ['-10000']], [[" WITH cte AS\n(\n  SELECT 10 AS num      FROM dual\n  UNION ALL SELECT -500 FROM dual\n  UNION ALL SELECT 0    FROM dual\n)\nSELECT num AS old_value,\n       decode( sign( num ), -1, 'NEGATIVE ', 0, 'ZERO', NULL ) ||\n       decode( sign( abs(num) ), +1, to_char( to_date( abs(num),'J'),'JSP') ) || '/=' AS new_value\nFROM cte\n"]], ['How to convert number to words - ORACLE'], 3, 1], [(32962508, 2), [['-10000'], ['-10000']], [[" WITH cte AS\n(\n  SELECT 10 AS num       FROM dual\n  UNION ALL SELECT -500  FROM dual\n  UNION ALL SELECT 0     FROM dual\n  UNION ALL SELECT 10.3  FROM dual\n  UNION ALL SELECT -10.7 FROM dual\n)\nSELECT \n  num AS old_value,\n  decode( sign( num ), -1, 'NEGATIVE ', 0, 'ZERO', NULL )\n  || decode( sign( abs(num) ), +1, to_char( to_date( abs(TRUNC(num)),'J'),'JSP') )\n  ||\n  CASE\n     WHEN INSTR (num, '.') > 0\n     THEN  ' POINT ' || TO_CHAR (TO_DATE (TO_NUMBER (SUBSTR(num, INSTR (num, '.') + 1)),'J'),'JSP')\n     ELSE NULL\n  END AS new_value\nFROM cte\n"]], ['How to convert number to words - ORACLE'], 3, 1], [(32983858, 0), [['Also try not use reserved words like  date  as fieldnames'], ['With a table  AllDates  to solve day without sales']], [[' with countA as (\n     SELECT date, count(*) as CountA\n     from tableA\n     group by date\n),\ncountB as (\n     SELECT date, count(*) as CountB\n     from tableB\n     group by date\n)\nSELECT A.date, A.CountA, B.CountB\nFROM CountA  A\nINNER JOIN  CountB B\n   ON A.date = B.date\n']], ['Count Two Tables on shared date in Postgresql'], 2, 1], [(32983858, 1), [['With a table  AllDates  to solve day without sales'], ['-10000']], [[' SELECT T.date, \n       CASE \n          WHEN A.CountA IS NULL THEN 0\n          ELSE A.CountA\n       END as CountA,\n       CASE \n          WHEN B.CountB IS NULL THEN 0\n          ELSE B.CountB\n       END as CountB\n\nFROM AllDates T \nLEFT JOIN CountA  A\n       ON T.date = A.date\nLEFT JOIN CountB B\n       ON T.date = B.date\n']], ['Count Two Tables on shared date in Postgresql'], 2, 1], [(32985768, 0), [["Here is a query to get your database's current hit ratio:"], ["However, to show how meaningless this number is, let's artificially increase it:"]], [[' SQL> -- Get initial Buffer Hit Ratio reading...\nSQL> SELECT ROUND((1-(phy.value / (cur.value + con.value)))*100,2) "Cache Hit Ratio"\n  2    FROM v$sysstat cur, v$sysstat con, v$sysstat phy\n  3   WHERE cur.name = \'db block gets\'\n  4     AND con.name = \'consistent gets\'\n  5     AND phy.name = \'physical reads\'\n  6  /\n\nCache Hit Ratio\n---------------\n         90.75\n']], ['how to increase cache hit ratio in Oracle database?'], 3, 0], [(32985768, 2), [["Let's see what happened:"], ["Conclusion: Don't even bother trying to tune the Buffer Hit Ratio!"]], [[' SQL> -- Let\'s measure it again...\nSQL> SELECT ROUND((1-(phy.value / (cur.value + con.value)))*100,2) "Cache Hit Ratio"\n  2    FROM v$sysstat cur, v$sysstat con, v$sysstat phy\n  3   WHERE cur.name = \'db block gets\'\n  4     AND con.name = \'consistent gets\'\n  5     AND phy.name = \'physical reads\'\n  6  /\n\nCache Hit Ratio\n---------------\n          99.94\n']], ['how to increase cache hit ratio in Oracle database?'], 3, 0], [(33020243, 0), [['An alternative that may work for you, depending on your specific need, is to add a  count(*) over ()  to your  select  statement to give you the total number of rows.  It would at least save you from having to re-execute the query a 2nd time.'], ["Or, if you can't change the original query, then you can wrap it like this:"]], [[' select t.*,\n       count(*) over () as num_rows\n  from table t\n where ...\n']], ['SELECT @@ROWCOUNT Oracle equivalent'], 2, 1], [(33020243, 1), [["Or, if you can't change the original query, then you can wrap it like this:"], ['-10000']], [[' select t.*,\n       count(*) over () as num_rows\n  from (query) t\n']], ['SELECT @@ROWCOUNT Oracle equivalent'], 2, 1], [(33050763, 1), [['I would use a different language to separate the columns. First you need the student information and ID for all the student subjects, like this:'], ['Then get the subjects:']], [[' SELECT\n    ST.ID_ST, ST.`NAME`, GROUP_CONCAT(DISTINCT QU.`ID_SB`) AS subject_ids\nFROM STUDENTS AS ST\nLEFT JOIN QUALIFICATIONS AS QU ON\n    ST.ID_ST = QU.ID_ST\nGROUP BY ST.ID_ST\n']], ['Mysql : join three tables with cardinality 1:N'], 4, 0], [(33050763, 2), [['Then get the subjects:'], ['The last part is creating the Excel. The example below is written in PHP:']], [[' SELECT * FROM SUBJECTS\n']], ['Mysql : join three tables with cardinality 1:N'], 4, 0], [(33050763, 3), [['The last part is creating the Excel. The example below is written in PHP:'], ['So, we just loop the students, inside the student-loop we loop the subjects.']], [[" $excelRows = array();\nforeach($students as $student){\n    $excelRow = array($student->id, $student->name);\n    foreach($subjects as $subject){\n        array_push($excelRow, (in_array($subject->id, $student->subject_ids))?'yes':'no');\n    }\n    array_push($excelRows, $excelRow);\n}\n"]], ['Mysql : join three tables with cardinality 1:N'], 4, 0], [(33085816, 0), [["In the meantime, here's what you do."], ['Then if you need to filter or order on some of these items, you wrap this query in an outer query.  For example.']], [[" SELECT m.id, \n       m.cust_id,\n       a.value   AS author,\n       r.value   AS release,\n       p.value   AS price, \n       m.filename,\n       m.hidden\n  FROM media m\n  LEFT JOIN other_table a ON m.id = a.id AND a.rowname = 'author'\n  LEFT JOIN other_table p ON m.id = p.id AND p.rowname = 'price'\n  LEFT JOIN other_table r ON m.id = r.id AND r.rowname = 'release'\n"]], ['Mysql Left join rotate 90° table'], 2, 1], [(33085816, 1), [['Then if you need to filter or order on some of these items, you wrap this query in an outer query.  For example.'], ["It happens, for what it's worth, that WordPress uses this strategy to store arbitrary information in its  wp_postmeta  table."]], [["  SELECT *\n   FROM (\n     SELECT m.id, \n            m.cust_id,\n            a.value   AS author,\n            r.value   AS release,\n            p.value   AS price, \n            m.filename,\n            m.hidden\n       FROM media m\n       LEFT JOIN other_table a ON m.id = a.id AND a.rowname = 'author'\n       LEFT JOIN other_table p ON m.id = p.id AND p.rowname = 'price'\n       LEFT JOIN other_table r ON m.id = r.id AND r.rowname = 'release'\n    ) all\n WHERE release >= '2010-01-01'\n ORDER BY author\n"]], ['Mysql Left join rotate 90° table'], 2, 1], [(33087355, 0), [['It is a little big statement to do it in comment so I will post it as an answer. If my understanding of the problem is correct then it will be like:'], ['Edit:']], [[' select * \nfrom sizeconditionstable t1\njoin specalloytable t2\non (t1.c4 is not null and t2.c4 is not null and t1.c4 = t2.c4) or \n   (t1.c5 is not null and t2.c5 is not null and t1.c5 = t2.c5)\n']], ['SQL Inner join on one field when second is null and on second when first is null'], 2, 0], [(33087355, 1), [['Edit:'], ['This is the version which will join always on  utc  and  colnum  and also on c4 and c5 if they are filled in both tables.']], [[' select * \n    from sizeconditionstable t1\n    join specalloytable t2\n    on (t1.utc = t2.utc and t1.colnum = t2.colnum) and\n       ((t1.c4 = t2.c4) or (t1.c4 is null and t2.c4 is null)) and\n       ((t1.c5 = t2.c5) or (t1.c5 is null and t2.c5 is null))\n']], ['SQL Inner join on one field when second is null and on second when first is null'], 2, 1], [(33108437, 0), [['-10000'], ['The differences are :']], [[" SELECT  [Order].[OrderNumber]\n        ,CASE   WHEN [ShopifyOrder].[PaymentStatusCode] = '2' THEN 'Paid'\n                WHEN [ShopifyOrder].[PaymentStatusCode] = '4' THEN 'Refunded'\n                WHEN [ShopifyOrder].[PaymentStatusCode] = '5' THEN 'Voided'\n                WHEN [ShopifyOrder].[PaymentStatusCode] = '6' THEN 'Partially Refunded'\n                END AS 'PaymentStatus'\n        ,[Store].[StoreName] as 'MarketplaceNames'\n        ,[OrderItem].[SKU]\n        ,[LookupList].[MainSKU]\n        ,[ShippingCharge].[Description] as shippingDescription\n        ,[ShippingCharge].[Amount] as shippingAmount\n        ,[DiscountCharge].[Description] as discountDescription\n        ,[DiscountCharge].[Amount] as discountAmount\n        ,[LookupList].[Classification] as 'Classification'\n        ,[LookupList].[Cost]\n        ,([OrderItem].[Quantity]* [OrderItem].[UnitPrice]) AS 'Sales'\n        ,(([OrderItem].[Quantity] * [LookupList].[Quantity]) * [LookupList].[Cost]) AS 'Total Cost'\n        ,[OrderItem].[Quantity] * [LookupList].[Quantity] AS 'Total Qty'\nFROM [SHIPSERVER].[dbo].[Order]\nJOIN [SHIPSERVER].[dbo].[ShopifyOrder]\nON [Order].[OrderID]=[ShopifyOrder].[OrderID]\nJOIN [SHIPSERVER].[dbo].[OrderItem]\nON [OrderItem].[OrderID]=[Order].[OrderID]\nJOIN [SHIPSERVER].[dbo].[Store]\nON [Order].[StoreID]=[Store].[StoreID]\nLEFT JOIN [SHIPSERVER].[dbo].[LookupList]\nON [OrderItem].[SKU]=[LookupList].[SKU]\nLEFT JOIN [SHIPSERVER].[dbo].[OrderCharge] [ShippingCharge]\nON [Order].[OrderID]=[ShippingCharge].[OrderID] AND [ShippingCharge].[Type] = 'SHIPPING'\nLEFT JOIN [SHIPSERVER].[dbo].[OrderCharge] [DiscountCharge]\nON [Order].[OrderID]=[DiscountCharge].[OrderID] AND [DiscountCharge].[Type] = 'DISCOUNT'\nWHERE ([Store].[StoreName]= 'Shopify')\nAND ([Order].[OrderDate] BETWEEN '2015-09-01 00:00:00.000' AND '2015-09-30 23:59:59.999')\nAND ([Order].[IsManual] = '0')\n"]], ['SQL Server 2014 Join Doubling Line Items'], 3, 1], [(33108437, 1), [['The differences are :'], ['and ']], [['         ,[ShippingCharge].[Description] as shippingDescription\n        ,[ShippingCharge].[Amount] as shippingAmount\n        ,[DiscountCharge].[Description] as discountDescription\n        ,[DiscountCharge].[Amount] as discountAmount\n']], ['SQL Server 2014 Join Doubling Line Items'], 3, 0], [(33108437, 2), [['and '], ["Basically, what I did is I left joined on OrderCharge twice, once for Discount and once for Shipping, with a different alias each time. This means that you're potentially linked to a discount row and potentially linked to a shipping row, and from there getting the data is incredibly easy."]], [[" LEFT JOIN [SHIPSERVER].[dbo].[OrderCharge] [ShippingCharge]\nON [Order].[OrderID]=[ShippingCharge].[OrderID] AND [ShippingCharge].[Type] = 'SHIPPING'\nLEFT JOIN [SHIPSERVER].[dbo].[OrderCharge] [DiscountCharge]\nON [Order].[OrderID]=[DiscountCharge].[OrderID] AND [DiscountCharge].[Type] = 'DISCOUNT'\n"]], ['SQL Server 2014 Join Doubling Line Items'], 3, 0], [(33118186, 0), [['To match the index you created:'], ['you would have to make that:']], [[' CREATE INDEX ON foo(id, date)\n']], ['Optimizing window function in PostgreSQL to use index'], 4, 0], [(33118186, 1), [['you would have to make that:'], ['That aside, you could just run:']], [[' ROW_NUMBER() OVER (PARTITION BY id ORDER BY date DESC <b>NULLS LAST</b>) ']], ['Optimizing window function in PostgreSQL to use index'], 4, 0], [(33118186, 2), [['That aside, you could just run:'], ["But that's probably not what you wanted to ask. Either way, I would make the index:"]], [[' SELECT DISTINCT ON (id)\n       id, date\nFROM   foo\nORDER  BY id, date DESC NULLS LAST;\n']], ['Optimizing window function in PostgreSQL to use index'], 4, 0], [(33118186, 3), [["But that's probably not what you wanted to ask. Either way, I would make the index:"], ['so that  max(date)  is the first index entry per  id .\nRelated:']], [[' CREATE INDEX ON foo(id, date DESC NULLS LAST)\n']], ['Optimizing window function in PostgreSQL to use index'], 4, 0], [(33135937, 0), [["The best query depends on various details: selectivity of the query predicate, cardinalities, data distribution. If  state = 'A'  is a selective condition (view rows qualify), this query should be substantially faster:"], ["If  'A'  is a common value in  state , this more generic query will be faster:"]], [[" SELECT c.user_id, c.state\nFROM   customer_properties c\nLEFT   JOIN customer_properties c1 ON c1.user_id = c.user_id\n                                  AND c1.created_at > c.created_at\nWHERE  c.state = 'A'\nAND    c1.user_id IS NULL;\n"]], ['Retrieve records against most recent state/attribute value'], 2, 1], [(33135937, 1), [["If  'A'  is a common value in  state , this more generic query will be faster:"], ["I removed  NULLS LAST , assuming that  created_at  is defined  NOT NULL . Also, I don't think Redshift has it:"]], [[" SELECT user_id, state\nFROM (\n   SELECT user_id, state\n        , row_number() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn\n   FROM   customer_properties\n   ) t\nWHERE  t.rn = 1\nAND    t.state = 'A';\n"]], ['Retrieve records against most recent state/attribute value'], 2, 1], [(33137311, 1), [['Populating the tables...'], ['Getting info on a tournament...']], [[" INSERT INTO tournTypes VALUES\n(1,2),\n(1,3),\n(2,3),\n(3,1)\n\nINSERT INTO leagueTypes VALUES\n(16,2,0), -- 16 teams, 2 divisions, teams only play within own division\n(8,1,0),\n(28,4,1)\n\nINSERT INTO playoffTypes VALUES\n(8,0), -- 8 teams, single elimination\n(4,0),\n(8,1)\n\nINSERT INTO Schedule VALUES\n('Champions league','2015-12-10','2016-02-10',1),\n('Rec league','2015-11-30','2016-03-04-,2)\n"]], ['How to model several tournaments / brackets types into a SQL database?'], 3, 0], [(33137311, 2), [['Getting info on a tournament...'], ['-10000']], [[" SELECT Name\n,startDate\n,endDate\n,l.noOfTeams as LeagueSize\n,p.noOfTeams as PlayoffTeams\n,case p.doubleElim when 0 then 'Single' when 1 then 'Double' end as Elimination\nFROM Schedule s\nINNER JOIN tournTypes t\nON s.tournId = t.ID\nINNER JOIN leagueTypes l\nON t.leagueId = l.ID\nINNER JOIN playoffTypes p\nON t.playoffId = p.ID\n"]], ['How to model several tournaments / brackets types into a SQL database?'], 3, 0], [(33149080, 0), [["Here's one way to do it using window functions:"], ['The inner query identifies islands of consecutive  area  values. See  grp  value in below partial output from this sub-query:']], [[' SELECT tenant, area, [date], sales,\n       DENSE_RANK() OVER (ORDER BY grpOrder) AS counter\nFROM (\n  SELECT tenant, area, date, sales,       \n         MIN([date]) OVER (PARTITION BY area, grp) AS grpOrder\n  FROM (\n    SELECT tenant, area, [date], sales,           \n           ROW_NUMBER() OVER (ORDER BY date) -\n           ROW_NUMBER() OVER (PARTITION BY area ORDER BY [date]) AS grp\n    FROM tenant ) AS t ) AS s\n']], ['SQL Server Query to Count Number of Changing Values in a Column Sequentially'], 2, 1], [(33149080, 1), [['The inner query identifies islands of consecutive  area  values. See  grp  value in below partial output from this sub-query:'], ['Using window version of  MIN  we can calculate  grp  order: field  grpOrder  holds the minimum date per group.']], [[' area date       grp\n--------------------\n18   2015-01-01  0\n18   2015-01-02  0\n18   2015-01-05  2\n18   2015-01-06  2\n20   2015-01-03  2\n20   2015-01-04  2\n']], ['SQL Server Query to Count Number of Changing Values in a Column Sequentially'], 2, 0], [(33156695, 0), [["Your query looks ok.  But, you don't need the subquery, so a simpler version is:"], ['If you want the average of the  submissions  columns for these groups, use  case :']], [[" SELECT ft.fruit,   \n       COUNT(ftl.fruit_attribute) As attributes_shared_lemon,\n       SUM(ftl.fruit_attribute IS NULL) As attributes_not_shared_lemon\nFROM fruits ft LEFT JOIN\n     fruits ftl\n     ON ft.fruit_attribute = ftl.fruit_attribute and ftl.fruit = 'Lemon'\nGROUP BY ft.fruit;\n"]], ['How to add averages w/ sum (case when...) in MySQL?'], 2, 1], [(33156695, 1), [['If you want the average of the  submissions  columns for these groups, use  case :'], ['-10000']], [[" SELECT ft.fruit,  \n       AVG(CASE WHEN ftl.fruit_attribute IS NOT NULL THEN ft.submissions END) as avg_shared, \n       AVG(CASE WHEN ftl.fruit_attribute IS NULL THEN ft.submissions END) as avg_notshared, \n       COUNT(ftl.fruit_attribute) As attributes_shared_lemon,\n       SUM(ftl.fruit_attribute IS NULL) As attributes_not_shared_lemon\nFROM fruits ft LEFT JOIN\n     fruits ftl\n     ON ft.fruit_attribute = ftl.fruit_attribute and ftl.fruit = 'Lemon'\nGROUP BY ft.fruit;\n"]], ['How to add averages w/ sum (case when...) in MySQL?'], 2, 1], [(33234319, 0), [["Having in mind  Zend's Join Inner declaration :"], ['And being \'$this\', for example, a Zend_Db_Table_Abstract implementation with adapter set to db1 (with _setAdapter()) and schema to "@@@@@" (this is not really necessary because it\'ll use it as default):']], [[' public function joinInner($name, $cond, $cols = self::SQL_WILDCARD, $schema = null)\n']], ['Join two database table zend framework 1.12'], 2, 0], [(33258020, 0), [["It's an even worse idea with an ampersand because of its use for substitution variables, as you're seeing. To create the table and then use substitution variables in the same script you would need to turn off defines before the creation, and then turn them back on afterwards:"], ["But you still couldn't refer to the table name and a substitution variable in the same statement, unless you set  define  to something non-standard:"]], [[' set define off\ncreate table bad_idea("this&that" number);\nset define on\n']], ['Escaping special characters when naming a table column without setting define off'], 3, 1], [(33258020, 1), [["But you still couldn't refer to the table name and a substitution variable in the same statement, unless you set  define  to something non-standard:"], ['If you only need it as a column alias you can do the same thing, and it would be slightly less painful, but still not ideal:']], [[' set define "^"\ninsert into bad_idea("this&that") values (^var);\n']], ['Escaping special characters when naming a table column without setting define off'], 3, 1], [(33258020, 2), [['If you only need it as a column alias you can do the same thing, and it would be slightly less painful, but still not ideal:'], ['-10000']], [[' set define "^"\nselect fieldA "this&that" from tableA where fieldB = ^var;\n']], ['Escaping special characters when naming a table column without setting define off'], 3, 1], [(33267250, 0), [['In regular SQL, you could write:'], ['But, if we assume no duplicates in  mytable , then this variant should work:']], [[' select type\nfrom mytable \ngroup by type\nhaving count(distinct id) = (select count(distinct id) from mytable);\n']], ['SQL for finding types that have all ids on some row'], 3, 1], [(33267250, 1), [['But, if we assume no duplicates in  mytable , then this variant should work:'], ['If the table could contain duplicates, then you can remove them before the aggregation:']], [[' select type\nfrom mytable\ngroup by type\nhaving count(*) = (select count(*)\n                   from (select distinct id from mytable) as t\n                  );\n']], ['SQL for finding types that have all ids on some row'], 3, 1], [(33267250, 2), [['If the table could contain duplicates, then you can remove them before the aggregation:'], ['-10000']], [[' select type\nfrom (select distinct type, id from mytable ) as ti\ngroup by type\nhaving count(*) = (select count(*)\n                   from (select distinct id from mytable) as t\n                  );\n']], ['SQL for finding types that have all ids on some row'], 3, 1], [(33273676, 0), [["That's a simple aggregate. You want a row per foo_name in your results, so you GROUP BY foo_name. Then limit your results in HAVING:"], ['You can easily change your HAVING clause in order to know what types where found for a foo_name, e.g.:']], [[' select foo_name\nfrom my_table\ngroup by foo_name\nhaving count(distinct foo_type) < 3;\n']], ['MySQL find all rows where rows with number of rows for possible values of column is less than n'], 3, 1], [(33275284, 0), [['A general solution is to use  NOT EXISTS  with a reverse condition ( <>  instead of  = ):'], ['Alternatively, specific for this use case, you can use a cleaner query:']], [[' SELECT DISTINCT p.ProjectID\nFROM TblProjects p INNER JOIN TblCustomers ct\n  ON ct.ProjectID = p.ProjectID\nWHERE NOT EXISTS\n  (SELECT 1\n   FROM TblCustomers c\n   WHERE c.ProjectID = p.ProjectID AND (Number % 100) <> 0)\n']], ['How to select parent rows where all children statisfies a condition in SQL?'], 2, 1], [(33275284, 1), [['Alternatively, specific for this use case, you can use a cleaner query:'], ["Here's a  SQLFiddle ."]], [[' SELECT p.ProjectID\nFROM TblProjects p INNER JOIN TblCustomers ct\n  ON ct.ProjectID = p.ProjectID\nGROUP BY p.ProjectID\nHAVING MAX(ct.Number % 100) = 0\n']], ['How to select parent rows where all children statisfies a condition in SQL?'], 2, 1], [(33279715, 0), [['I prefer to approach these types of questions using  group by  and  having :'], ['In any database other than MySQL, you would use this  HAVING  clause:']], [[' SELECT i.order_id\nFROM items i\nGROUP BY i.order_id\nHAVING SUM(i.item_id = 1) > 0 AND\n       SUM(i.item_id = 2) = 0;\n']], ['Filtering orders having one item and not having another one in the same time'], 2, 1], [(33279715, 1), [['In any database other than MySQL, you would use this  HAVING  clause:'], ['This will work in MySQL as well; I just like the shorter notation.']], [[' HAVING SUM(CASE WHEN i.item_id = 1 THEN 1 ELSE 0 END) > 0 AND\n       SUM(CASE WHEN i.item_id = 2 THEN 1 ELSE 0 END) = 0;\n']], ['Filtering orders having one item and not having another one in the same time'], 2, 1], [(33346218, 0), [['You need simple  + :'], ['Generated columns 5.7+']], [[' SELECT id, hodnota1, hodnota2, hodnota1 +  hodnota2 AS spolu\nFROM test;\n']], ['Sum values in MySQL'], 3, 1], [(33367569, 0), [['In terms of optimization, it is often best to put the "constant" list in a temporary table and use a join.  In many databases, this would look like:'], ['Some databases will also support a  where  clause like this:']], [[' select t.*\nfrom table t join\n     (select 1 as x, 1 as y union all select 1, 3 union all select 2, 2\n     ) list\n     on t.x = list.x and t.y = list.y;\n']], ['SQL - where (value1,value2) in list of lists'], 2, 1], [(33372188, 0), [['If the column PARENT_OCS_ID is unreliable, simple ignore it and calculate it correct from the child key.\nThe rest is your original approach'], ['.']], [["  with fix_parent as\n (select OC_ID,\n         SUBSTR (EB_OCS.oc_id, 1, INSTR (EB_OCS.oc_id, '.', -1)-1) as PARENT_OC_ID,\n         TO_NUMBER (SUBSTR (EB_OCS.oc_id, INSTR (EB_OCS.oc_id, '.', -1)+1)) child_number\n  from   TST EB_OCS)\n select   \n    PARENT_OC_ID,  max(child_number) +1 next_child_number\n from fix_parent\n where PARENT_OC_ID in ('4.0.1.1','4.0','4')\n group by PARENT_OC_ID\n order by PARENT_OC_ID; \n"]], ['Oracle REGEXP_LIKE match up to a period (decimal point) or find next sequence in numbers such as Dewey Decimal'], 3, 1], [(33372188, 1), [['.'], ["To get a result for parent '4' add a line"]], [['  PARENT_OC_ID NEXT_CHILD_NUMBER\n ------------ -----------------\n 4.0                         13 \n 4.0.1.1                      4\n']], ['Oracle REGEXP_LIKE match up to a period (decimal point) or find next sequence in numbers such as Dewey Decimal'], 3, 0], [(33372188, 2), [["To get a result for parent '4' add a line"], ['-10000']], [["  insert into TST values ('4.0','4');\n"]], ['Oracle REGEXP_LIKE match up to a period (decimal point) or find next sequence in numbers such as Dewey Decimal'], 3, 0], [(33381751, 1), [['COUNT  '], ['-10000']], [[" select DVD.dvdID,DVD.datePurchased,DVD.filmID,Count(MonthlyStatement.dateHired) from DVD\ninner join MonthlyStatement on DVD.dvdID =MonthlyStatement.dvdID\nwhere to_char(MonthlyStatement.dateHired,'Mon-YYYY')='Oct-2015'\ngroup by DVD.dvdID,DVD.datePurchased,DVD.filmID\norder by DVD.dvdID\n"]], ['ORACLE SQL - Count'], 2, 1], [(33383829, 0), [['To order by the min value of each price range:'], ['-10000']], [[' SELECT id\nFROM (\n  SELECT p.id, min(s.price) as min_price\n  FROM product p\n  JOIN sku s on p.id = s.product_id\n  GROUP BY p.id\n) x\nORDER BY min_price ASC\n']], ["Sorting on child model's price attribute"], 3, 1], [(33383829, 1), [['-10000'], ['and this']], [[' SELECT p.productid\nfrom (\n  SELECT p.productid, s.price,\n       ROW_NUMBER() OVER (PARTITION BY p.productid, ORDER BY s.price ASC) as rn\n  from product p\n  JOIN sku s on p.id = s.product_id\n) x\nwhere rn = 1\n']], ["Sorting on child model's price attribute"], 3, 1], [(33383829, 2), [['and this'], ['But as I said I\'m still not sure if you are ordering by price and removing dup productids (as this is) or if you want to order by the min value and max value of each products price range (as the "duplicate" does).']], [[' SELECT p.productid\nfrom (\n  SELECT p.productid, s.price,\n       ROW_NUMBER() OVER (PARTITION BY p.productid, ORDER BY s.price DESC) as rn\n  from product p\n  join sku s on p.id = s.product_id\n) x\nwhere rn = 1\n']], ["Sorting on child model's price attribute"], 3, 1], [(33402664, 0), [['Using the following to set up test tables'], ['The following query would appear to do what you want:']], [[" --drop table Interests  ----------------------------\nCREATE TABLE Interests\n (\n   InterestId  char(1)  not null\n  ,UserId      int      not null\n )\n\nINSERT Interests values\n  ('A',1)\n ,('A',3)\n ,('B',1)\n ,('B',2)\n ,('B',3)\n ,('B',5)\n ,('C',2)\n ,('D',3)\n ,('D',4)\n\n\n--  drop table Groups  ---------------------\nCREATE TABLE Groups\n (\n   GroupId  int  not null\n  ,UserId   int  not null\n )\n\nINSERT Groups values\n  (-1, 1)\n ,(-1, 2)\n\n\nSELECT * from Groups\nSELECT * from Groups\n"]], ['SQL - Computing overlap between Interests'], 2, 0], [(33428932, 0), [['You can use  UNION :'], ['Alternatively, you can use:']], [[' SELECT COUNT(*) AS numOfDiscounts\nFROM (\n   SELECT discount \n   FROM table1\n   WHERE discount = 12\n\n   UNION ALL\n\n   SELECT discount \n   FROM table2\n   WHERE discount = 12\n\n   UNION ALL\n\n   SELECT discount \n   FROM table3\n   WHERE discount = 12\n   UNION ALL\n\n   SELECT discount \n   FROM table4\n   WHERE discount = 12\n\n   UNION ALL\n\n   SELECT discount \n   FROM table5\n   WHERE discount = 12) AS t\n']], ['How to find a given value appears in how many tables in mysql'], 3, 1], [(33428932, 1), [['Alternatively, you can use:'], ['or:']], [[' SELECT COALESCE((SELECT COUNT(*) FROM table1 WHERE discount = 12),0) + \n       COALESCE((SELECT COUNT(*) FROM table2 WHERE discount = 12),0) + \n       COALESCE((SELECT COUNT(*) FROM table3 WHERE discount = 12),0) + \n       COALESCE((SELECT COUNT(*) FROM table4 WHERE discount = 12),0) + \n       COALESCE((SELECT COUNT(*) FROM table5 WHERE discount = 12),0) AS numOfDiscounts\n']], ['How to find a given value appears in how many tables in mysql'], 3, 1], [(33428932, 2), [['or:'], ['Demo here']], [[' SELECT (SELECT COUNT(CASE WHEN discount=12 THEN 1 END) FROM table1) + \n       (SELECT COUNT(CASE WHEN discount=12 THEN 1 END) FROM table2) + \n       (SELECT COUNT(CASE WHEN discount=12 THEN 1 END) FROM table3) + \n       (SELECT COUNT(CASE WHEN discount=12 THEN 1 END) FROM table4) + \n       (SELECT COUNT(CASE WHEN discount=12 THEN 1 END) FROM table5) AS numOfDiscounts\n']], ['How to find a given value appears in how many tables in mysql'], 3, 1], [(33437351, 0), [['Yes, you can do this without cursors, using cumulative sums:'], ['For an  update , you can use the same logic:']], [[' select t.*,\n       (case when sum(amount) over (order by entryid) <= @amount\n             then amount\n             when sum(amount) over (order by entryid) < @amount + amount\n             then @amount - (sum(amount) over (order by entryid) - amount)\n             else 0\n        end) as distrib\nfrom table t;\n']], ['SQL Server query: Adjust money column'], 2, 1], [(33437351, 1), [['For an  update , you can use the same logic:'], ['-10000']], [[' with toupdate as (\n      select t.*,\n             (case when sum(amount) over (order by entryid) <= @amount\n                   then amount\n                   when sum(amount) over (order by entryid) < @amount + amount\n                   then @amount - (sum(amount) over (order by entryid) - amount)\n                   else 0\n              end) as new_distrib\n      from table t\n     )\nupdate toudpate\n    set distrib = new_distrib;\n']], ['SQL Server query: Adjust money column'], 2, 1], [(33447891, 0), [['Even though you asked to remove the subquery, using a  not exists  subquery might run faster than  not in  especially if the  not in  query returns a lot of values:'], ['If you still rather use  left join , then move your conditions for  from_user  and  to_user  from the  where  to the  on  clause']], [[" SELECT m.id, m.name, m.description\nFROM merchandises m\nWHERE NOT EXISTS (\n    SELECT 1\n    FROM gifts g\n    WHERE g.with_merchandise = m.id\n    AND g.from_user = 'some_user_id'\n    AND g.to_user = 'some_other_user_id'\n)\n"]], ['Flattening nested query in WHERE clause with NOT IN'], 2, 1], [(33447891, 1), [['If you still rather use  left join , then move your conditions for  from_user  and  to_user  from the  where  to the  on  clause'], ['-10000']], [[" SELECT m.id, m.name, m.description\nFROM merchandises m\nLEFT JOIN gifts g ON m.id = g.with_merchandise\n  AND g.from_user = 'some_user_id' AND g.to_user = 'some_other_user_id' \nWHERE g.id IS NULL \nORDER BY m.id ASC\nLIMIT 20 OFFSET 0\n"]], ['Flattening nested query in WHERE clause with NOT IN'], 2, 1], [(33451718, 0), [['The  group_concat  aggregate function should do the trick:'], ['EDIT: \nTo answer the question in the comment, you could add a  separator  clause to replace the comma in the result:']], [[' SELECT GROUP_CONCAT(name ORDER BY name) AS name\nFROM   banned\n']], ['Column as list with comma between'], 2, 1], [(33451718, 1), [['EDIT: \nTo answer the question in the comment, you could add a  separator  clause to replace the comma in the result:'], ['-10000']], [[" SELECT GROUP_CONCAT(name ORDER BY name SEPARATOR '...') AS name\nFROM   banned\n"]], ['Column as list with comma between'], 2, 1], [(33470158, 0), [['You can do something like this:'], ['Results for your example will look like this:']], [[' with ranking as (\n  select ticker, price, dt, \n  rank() over (partition by ticker order by dt desc) as rank\n  from stocks\n)\nselect * from ranking where rank in (1,2);\n']], ["SQL query to select today and previous day's price"], 2, 1], [(33470158, 1), [['Results for your example will look like this:'], ['If your table is large and have performance issues, use a  where  to restrict the data to last 30 days or so.']], [[' | ticker | price |                        dt | rank |\n|--------|-------|---------------------------|------|\n|   AAPL |     6 | October, 23 2015 00:00:00 |    1 |\n|   AAPL |     5 | October, 22 2015 00:00:00 |    2 |\n|   AXP  |     5 | October, 23 2015 00:00:00 |    1 |\n|   AXP  |     3 | October, 22 2015 00:00:00 |    2 |\n']], ["SQL query to select today and previous day's price"], 2, 0], [(33475700, 0), [['Simply execute the next query like this '], ["This will create a new table as 'abc126' with structure/attributes similiar to your events table.\nIf you wish to have the attributes similiar to any other table , change  events  to that table name "]], [[' CREATE TABLE `abc126` LIKE `events`;\n']], ['How to create a table dynamically with a field of main table as its name in Mysql?'], 2, 1], [(33475700, 1), [["This will create a new table as 'abc126' with structure/attributes similiar to your events table.\nIf you wish to have the attributes similiar to any other table , change  events  to that table name "], ["If you want to further modify the new table being created with limited attributes check the mysql 'CREATE TABLE' options."]], [[' CREATE TABLE `abc126` LIKE `tablename`;\n']], ['How to create a table dynamically with a field of main table as its name in Mysql?'], 2, 1], [(33483212, 0), [['Use recursive SQL, Oracle syntax:'], ["Alternatively, SQL standard syntax (the standard and some databases would require a  RECURSIVE  keyword, but Oracle doesn't allow it). A bit more tedious, but more extensible:"]], [[' SELECT *\nFROM t_filters\nSTART WITH parent IS NULL\nCONNECT BY parent = PRIOR id\nORDER SIBLINGS BY id\n']], ['How can I order hierarchy trees by branch in a select statement returning all hierarchy levels?'], 2, 1], [(33483212, 1), [["Alternatively, SQL standard syntax (the standard and some databases would require a  RECURSIVE  keyword, but Oracle doesn't allow it). A bit more tedious, but more extensible:"], ['-10000']], [[" WITH /* RECURSIVE */ r (id, parent, rank, value, path) AS (\n  SELECT id, parent, rank, value, '' || id\n  FROM t_filters\n  WHERE parent IS NULL\n\n  UNION ALL\n\n  SELECT f.id, f.parent, f.rank, f.value, r.path || '/' || f.id\n  FROM r\n  JOIN t_filters f ON r.id = f.parent\n)\nSELECT *\nFROM r\nORDER BY path\n"]], ['How can I order hierarchy trees by branch in a select statement returning all hierarchy levels?'], 2, 1], [(33510248, 0), [['Imagine you have a table  Cars   with fields'], ['But some cars are recreational vehicule and have aditional properties. So instead of add aditional columns in your  Cars  table you create another table  RV_cars']], [[' car_id, color, size, num_wheels\n']], ['sql database - each row in a table with extra data in different tables'], 3, 0], [(33510248, 1), [['But some cars are recreational vehicule and have aditional properties. So instead of add aditional columns in your  Cars  table you create another table  RV_cars'], ['So if you want get all information of one rv car you do']], [[' car_id, bathroom_size, num_bed, bol_tv\n']], ['sql database - each row in a table with extra data in different tables'], 3, 0], [(33510248, 2), [['So if you want get all information of one rv car you do'], ['-10000']], [[' SELECT C.*, R.*\nFROM Cars  C\njoin RV_cars R\n  ON C.car_id = R.car_id\n']], ['sql database - each row in a table with extra data in different tables'], 3, 1], [(33538420, 0), [['Use  regexp'], ['or']], [[" SELECT *\nFROM `tableName`\nWHERE `columnName` REGEXP '[^a-zA-Z0-9]'\n"]], ['MYSQL search if a string contains special characters?'], 2, 1], [(33538420, 1), [['or'], ['-10000']], [[" REGEXP '[^[:alnum:]]'\n"]], ['MYSQL search if a string contains special characters?'], 2, 1], [(33541995, 0), [['You can do this:'], ['DECLARE @cols AS NVARCHAR(MAX);']], [[" SELECT *\nFROM\n(\n    SELECT \n        OrderID,\n        OrderStatus + CountType AS StatusType,\n        DayCount\n    FROM CalendarTable     \n    UNION ALL\n    SELECT \n    OrderID,\n    CASE WHEN CountType = 'Working' THEN 'TotalWorking' ELSE 'TotalCalendar' END,\n    DayCount\n    FROM CalendarTable\n) AS t\nPIVOT\n(\n   MAX(DayCount)\n   For StatusType IN(OpenWorking,\n                     OpenCalendar,\n                     CloseWorking,\n                     CloseCalendar,\n                     PendingWorking,\n                     PendingCalendar,\n                     TotalWorking,\n                     TotalCalendar)\n) AS p;\n"]], ['how to create calculated pivot in sql'], 4, 1], [(33541995, 1), [['DECLARE @cols AS NVARCHAR(MAX);'], ['-10000']], [[" DECLARE @query AS NVARCHAR(MAX);\n\nSELECT @cols = STUFF((SELECT distinct ',' +\n                        QUOTENAME(StatusType)\n                       FROM \n                       (\n                            SELECT \n                              OrderID,\n                              OrderStatus + CountType AS StatusType,\n                              DayCount\n                            FROM CalendarTable     \n                            UNION ALL\n                            SELECT \n                              OrderID,\n                              CASE WHEN CountType = 'Working' THEN 'TotalWorking' ELSE 'TotalCalendar' END,\n                              DayCount\n                            FROM CalendarTable\n                        ) AS t\n                      FOR XML PATH(''), TYPE\n                     ).value('.', 'NVARCHAR(MAX)') \n                        , 1, 1, '');\n\n\nSELECT @query = 'SELECT *\n                FROM\n                (\n                    SELECT \n                      OrderID,\n                      OrderStatus + CountType AS StatusType,\n                      DayCount\n                    FROM CalendarTable     \n                    UNION ALL\n                    SELECT \n                      OrderID,\n                      CASE WHEN CountType = ''Working'' THEN ''TotalWorking'' ELSE ''TotalCalendar'' END,\n                      DayCount\n                    FROM CalendarTable\n                ) AS t\n                PIVOT\n                (\n                   MAX(DayCount)\n                   For StatusType IN(' + @cols + ')' +\n                  ') p';\n\nexecute(@query);\n"]], ['how to create calculated pivot in sql'], 4, 1], [(33541995, 2), [['-10000'], ['']], [[" DECLARE @cols AS NVARCHAR(MAX);\nDECLARE @colnames AS NVARCHAR(MAX);\nDECLARE @query AS NVARCHAR(MAX);\n\nSELECT @cols = STUFF((SELECT distinct ',' +\n                        QUOTENAME(StatusType)\n                       FROM \n                       (\n                            SELECT \n                              OrderID,\n                              OrderStatus + CountType AS StatusType,\n                              DayCount\n                            FROM CalendarTable     \n                            UNION ALL\n                            SELECT \n                              OrderID,\n                              CASE WHEN CountType = 'Working' THEN 'TotalWorking' ELSE 'TotalCalendar' END,\n                              DayCount\n                            FROM CalendarTable\n                            WHERE OrderStatus IN('Active', 'Pending')\n                        ) AS t\n                      FOR XML PATH(''), TYPE\n                     ).value('.', 'NVARCHAR(MAX)') \n                        , 1, 1, '');\n\n\nSELECT @colnames = STUFF((SELECT distinct ',' +\n                        QUOTENAME(StatusType) + ' AS ' + QUOTENAME(StatusTypeName)\n                       FROM \n                       (\n                           SELECT \n                                OrderID,\n                                OrderStatus + CountType AS StatusType,\n                                DayCount,\n                                OrderStatus + CASE WHEN CountType = 'Working' THEN  'WorkDays' ELSE 'CalDays' END AS StatusTypeName\n                            FROM CalendarTable     \n                            UNION ALL\n                            SELECT \n                              OrderID,\n                              CASE WHEN CountType = 'Working' THEN 'TotalWorking' ELSE 'TotalCalendar' END,\n                              DayCount,\n                              CASE WHEN CountType = 'Working' THEN 'TotalWorking' ELSE 'TotalCalendar' END\n                            FROM CalendarTable\n                            WHERE OrderStatus IN('Active', 'Pending')\n                        ) AS t\n                      FOR XML PATH(''), TYPE\n                     ).value('.', 'NVARCHAR(MAX)') \n                        , 1, 1, '');\n\nSELECT @query = 'SELECT OrderID , ' + @colnames + '\n                FROM\n                (\n                    SELECT \n                      OrderID,\n                      OrderStatus + CountType AS StatusType,\n                      DayCount\n                    FROM CalendarTable     \n                    UNION ALL\n                    SELECT \n                      OrderID,\n                      CASE WHEN CountType = ''Working'' THEN ''TotalWorking'' ELSE ''TotalCalendar'' END,\n                      DayCount\n                    FROM CalendarTable\n                    WHERE OrderStatus IN(''Active'', ''Pending'')\n                ) AS t\n                PIVOT\n                (\n                   SUM(DayCount)\n                   For StatusType IN(' + @cols + ')' +\n                  ') p';\n\nexecute(@query);\n"]], ['how to create calculated pivot in sql'], 4, 1], [(33573890, 0), [['As a matter of fact, the invoices table would have the contract sequence number along with the relative invoices IDs. For instance'], ["With your current SELECT, you'll get always :  "]], [[' Project A   Invoice_001 \nProject A   Invoice_002 \n']], ['SQL Add a filtering parameter without altering the data'], 3, 0], [(33573890, 1), [["With your current SELECT, you'll get always :  "], ["But, if you add the invoices Column in your SELECT, you'll probably get : "]], [[' projectA   *titlea*   1111   Jim  \nprojectA   *titlea*   2222   James  \nprojectB   *titleb*   1111   Jim  \nprojectB   *titleb*   3333   Paul  \n']], ['SQL Add a filtering parameter without altering the data'], 3, 0], [(33573890, 2), [["But, if you add the invoices Column in your SELECT, you'll probably get : "], ['So, no more duplicate data !']], [[' projectA   *titlea*   1111   Jim   Invoice_001  \nprojectA   *titlea*   1111   Jim   Invoice_002  \nprojectA   *titlea*   2222   James Invoice_003  \nprojectB   *titleb*   1111   Jim   Invoice_004  \nprojectB   *titleb*   3333   Paul  Invoice_005  \n']], ['SQL Add a filtering parameter without altering the data'], 3, 0], [(33593080, 0), [['You could use  unix_timestamp  for dates after  1970 :'], ['-10000']], [[" SELECT \n  (unix_timestamp('2013-01-01 10:10:10') - unix_timestamp('1970-01-01 00:00:00'))/60 \n"]], ['How to get date difference in minutes using Hive'], 2, 1], [(33593080, 1), [['-10000'], ['SqlFiddleDemoUsingMySQL2']], [[" SELECT from_unixtime(unix_timestamp('2013-01-01 10:10:10') + 10 * 60) AS result\n"]], ['How to get date difference in minutes using Hive'], 2, 1], [(33605918, 0), [['Setup'], ['Query']], [[" CREATE TABLE t\n    (ID NUMBER, NAME VARCHAR2(1), ADMIN NUMBER);\n\nINSERT ALL \n    INTO t (ID, NAME, ADMIN)\n         VALUES (200, 'A', 1)\n    INTO t (ID, NAME, ADMIN)\n         VALUES (300, 'B', 2)\n    INTO t (ID, NAME, ADMIN)\n         VALUES (400, 'C', 3)\n    INTO t (ID, NAME, ADMIN)\n         VALUES (500, 'D', 1)\n    INTO t (ID, NAME, ADMIN)\n         VALUES (600, 'E', 3)\nSELECT * FROM dual;\n"]], ['PL/SQL hierarchical ordering'], 2, 0], [(33605918, 1), [['Query'], ['-10000']], [[" SQL> SELECT lpad(' ',2*(ADMIN-1)) || NAME name_hierarchy FROM t ORDER BY ADMIN, NAME;\n\nNAME_HIERARCHY\n--------------------------------------------------------------------------------\nA\nD\n  B\n    C\n    E\n"]], ['PL/SQL hierarchical ordering'], 2, 1], [(33608191, 0), [['Lets say I have table " T " which has two columns,  EMPNO  and  SAL  such that the  SAL  column is completely  NULL .'], ['Lets  gather statistics  for safe side:']], [[' SQL> SELECT * FROM LALIT.t;\n\n     EMPNO        SAL\n---------- ----------\n      7369\n      7499\n      7521\n      7566\n      7654\n      7698\n      7782\n      7788\n      7839\n      7844\n      7876\n      7900\n      7902\n      7934\n\n14 rows selected.\n']], ['How can I find which column is empty?'], 6, 0], [(33608191, 1), [['Lets  gather statistics  for safe side:'], ['Desired output']], [[" SQL> BEGIN\n  2    DBMS_STATS.gather_table_stats(\n  3      'LALIT',\n  4      'T');\n  5  END;\n  6  /\n\nPL/SQL procedure successfully completed.\n"]], ['How can I find which column is empty?'], 6, 0], [(33608191, 2), [['Desired output'], ["For example, in the standard  EMP  table in SCOTT schema, let's look for the columns having  at least one NULL value ."]], [[" SQL> SELECT column_name,\n  2    num_distinct\n  3  FROM user_tab_columns\n  4  WHERE NUM_DISTINCT = 0\n  5  AND table_name     ='T';\n\nCOLUMN_NAME NUM_DISTINCT\n----------- ------------\nSAL                    0\n"]], ['How can I find which column is empty?'], 6, 0], [(33608191, 5), [['Call the function in  SQL  to get the NULL status of all the column of any table :'], ['So,  NULL_STATUS   1  is the column which has at least one  NULL  value.']], [[" SQL> SELECT c.TABLE_NAME,\n  2         c.COLUMN_NAME,\n  3         FIND_NULL_COL(c.TABLE_NAME,c.COLUMN_NAME) null_status\n  4  FROM all_tab_columns c\n  5  WHERE C.OWNER    ='SCOTT'\n  6  AND c.TABLE_NAME = 'EMP'\n  7  ORDER BY C.OWNER,\n  8    C.TABLE_NAME,\n  9    C.COLUMN_ID\n 10  /\n\nTABLE_NAME COLUMN_NAME NULL_STATUS\n---------- ----------- -----------\nEMP        EMPNO                 0\nEMP        ENAME                 0\nEMP        JOB                   0\nEMP        MGR                   1\nEMP        HIREDATE              0\nEMP        SAL                   0\nEMP        COMM                  1\nEMP        DEPTNO                0\n\n8 rows selected.\n"]], ['How can I find which column is empty?'], 6, 0], [(33613089, 0), [['Test Data:'], ['Query:']], [[" DECLARE @MyTable AS TABLE(DateTimes DATETIME)\nINSERT INTO @MyTable(DateTimes)\nVALUES('2015-05-03 01:06:45')\n,('2015-05-03 04:51:09')\n,('2015-05-03 05:08:11')\n,('2015-05-03 09:33:35')\n,('2015-05-03 13:46:38')\n"]], ['Grouping DateTime by hour in SQL'], 3, 0], [(33613089, 2), [['Results:'], ['-10000']], [[' Hourly\n2015-05-03 01:00:00.000\n2015-05-03 04:00:00.000\n2015-05-03 05:00:00.000\n2015-05-03 09:00:00.000\n2015-05-03 13:00:00.000\n']], ['Grouping DateTime by hour in SQL'], 3, 0], [(33633660, 0), [['First, you need to know the week for each  tint  date with WEEKOFYEAR() function. This value helps you to sum every week separately. Then, you can make a query like this: '], ['Now, you can group your data using with every field (numWeek, usr, dayOfWeek, dateJob and job) to get the detailed query:']], [[' select WEEKOFYEAR(tin) as numWeek,\n           DATE(tin) as dateJob, \n           DAYOFWEEK(tin) dayOfWeek,\n           usr,\n           job,\n           (IF( ISNULL(tout), UNIX_TIMESTAMP(), UNIX_TIMESTAMP(tout) ) - UNIX_TIMESTAMP(tin)) as DiffInOut\n    from wtime;\n']], ['weekly working report from mysql database'], 5, 0], [(33633660, 1), [['Now, you can group your data using with every field (numWeek, usr, dayOfWeek, dateJob and job) to get the detailed query:'], ['and later make an union to get only info per week..']], [[' select numWeek,\n       usr,\n       dayOfWeek,\n       datejob,\n       job,\n       sum(DiffInOut)\nfrom\n  (\n    select WEEKOFYEAR(tin) as numWeek,\n           DATE(tin) as dateJob, \n           DAYOFWEEK(tin) dayOfWeek,\n           usr,\n           job,\n           (IF( ISNULL(tout), UNIX_TIMESTAMP(), UNIX_TIMESTAMP(tout) ) - UNIX_TIMESTAMP(tin)) as DiffInOut\n    from wtime\n  ) result\ngroup by numWeek, usr, dayOfWeek, datejob, job\n']], ['weekly working report from mysql database'], 5, 0], [(33633660, 2), [['and later make an union to get only info per week..'], ['Result:']], [[' union\nselect numWeek,\n       usr,\n       dayOfWeek,\n       null,\n       null,\n       sum(DiffInOut)\nfrom\n  (\n    select WEEKOFYEAR(tin) as numWeek,\n           NULL as dateJob, \n           8 dayOfWeek,\n           usr,\n           job,\n           (IF( ISNULL(tout), UNIX_TIMESTAMP(), UNIX_TIMESTAMP(tout) ) - UNIX_TIMESTAMP(tin)) as DiffInOut\n    from wtime\n  ) result\ngroup by numWeek, usr, dayOfWeek\norder by numWeek, usr, dayOfWeek;\n']], ['weekly working report from mysql database'], 5, 0], [(33633660, 3), [['Result:'], ['PD2:  My query with your SQL Fiddle example, throws this result:']], [[' | numWeek |   usr | dayOfWeek |                    datejob |     job | sum(DiffInOut) |\n|---------|-------|-----------|----------------------------|---------|----------------|\n|      46 | M0005 |         3 | November, 10 2015 00:00:00 | A001942 |          61314 |\n|      46 | M0005 |         8 |                     (null) |  (null) |          61314 |\n|      46 | M0006 |         3 | November, 10 2015 00:00:00 | A001843 |          61314 |\n|      46 | M0006 |         3 | November, 10 2015 00:00:00 | A001814 |              0 |\n|      46 | M0006 |         8 |                     (null) |  (null) |          61314 |\n|      46 | M0007 |         3 | November, 10 2015 00:00:00 | A001814 |          61314 |\n|      46 | M0007 |         3 | November, 10 2015 00:00:00 | .000002 |              0 |\n|      46 | M0007 |         8 |                     (null) |  (null) |          61314 |\n']], ['weekly working report from mysql database'], 5, 0], [(33633660, 4), [['PD2:  My query with your SQL Fiddle example, throws this result:'], ['-10000']], [[' | numWeek |   usr | dayOfWeek |                    datejob |     job | sum(DiffInOut) |\n|---------|-------|-----------|----------------------------|---------|----------------|\n|      45 | M0006 |         4 | November, 04 2015 00:00:00 | ...ENDE |          50972 |\n|      45 | M0006 |         5 | November, 05 2015 00:00:00 | A001860 |           6080 |\n|      45 | M0006 |         5 | November, 05 2015 00:00:00 | ...ENDE |         310399 |\n|      45 | M0006 |         5 | November, 05 2015 00:00:00 | .000001 |           1935 |\n|      45 | M0006 |         5 | November, 05 2015 00:00:00 | .000002 |           4528 |\n|      45 | M0006 |         5 | November, 05 2015 00:00:00 | .000031 |          13434 |\n|      45 | M0006 |         5 | November, 05 2015 00:00:00 | A001814 |           9204 |\n|      45 | M0006 |         8 |                     (null) |  (null) |         396552 |\n|      46 | M0006 |         2 | November, 09 2015 00:00:00 | ...ENDE |          51363 |\n|      46 | M0006 |         2 | November, 09 2015 00:00:00 | .000001 |            114 |\n|      46 | M0006 |         2 | November, 09 2015 00:00:00 | .000002 |           4382 |\n|      46 | M0006 |         2 | November, 09 2015 00:00:00 | A001843 |          13738 |\n|      46 | M0006 |         2 | November, 09 2015 00:00:00 | A001860 |          17046 |\n|      46 | M0006 |         3 | November, 10 2015 00:00:00 | ...ENDE |           1561 |\n|      46 | M0006 |         3 | November, 10 2015 00:00:00 | .000002 |           4374 |\n|      46 | M0006 |         3 | November, 10 2015 00:00:00 | A001814 |           4924 |\n|      46 | M0006 |         3 | November, 10 2015 00:00:00 | A001843 |          25662 |\n|      46 | M0006 |         8 |                     (null) |  (null) |         123164 |\n']], ['weekly working report from mysql database'], 5, 0], [(33648148, 0), [['I have however given it a go. Since you are reusing the same correlated subquery multiple times, it would probably be beneficial to move these to an APPLY so that the result can be reused. I then just tried to pick apart your logic replacing the statements like:'], ['With ']], [[' CASE WHEN <expression1> IS NULL THEN <expression2> ELSE <expression1> END\n']], ['T-SQL Replacing If Else (Case When) with lookup table'], 3, 0], [(33648148, 1), [['With '], ['Giving a final query of:']], [[' ISNULL(<expression1>, <expression2>)\n']], ['T-SQL Replacing If Else (Case When) with lookup table'], 3, 0], [(33648148, 2), [['Giving a final query of:'], ['-10000']], [[" SELECT  CASE WHEN ISNULL(BKTXT.LookupResult, XBLNR.LookupResult) <> 'LEER' THEN\n            ISNULL(BKTXT.LookupResult, XBLNR.LookupResult)\n        ELSE \n            ISNULL(SGTXT.LookupResult, 'App')\n        END         \nFROM    SourceTable\n        CROSS APPLY \n        (   SELECT TOP 1 lookupResult \n            FROM ##lookupDefinition \n            WHERE lookupColumnName = 'BKTXT' \n            AND COEP_SGTXT LIKE lookupValue \n            ORDER BY LEN(lookupValue) DESC\n        ) AS BKTXT\n        CROSS APPLY \n        (   SELECT TOP 1 lookupResult \n            FROM ##lookupDefinition \n            WHERE lookupColumnName = 'XBLNR' \n            AND COEP_SGTXT LIKE lookupValue \n            ORDER BY LEN(lookupValue) DESC\n        ) AS XBLNR\n        CROSS APPLY \n        (   SELECT TOP 1 lookupResult \n            FROM ##lookupDefinition \n            WHERE lookupColumnName = 'SGTXT' \n            AND COEP_SGTXT LIKE lookupValue \n            ORDER BY LEN(lookupValue) DESC\n        ) AS SGTXT;\n"]], ['T-SQL Replacing If Else (Case When) with lookup table'], 3, 1], [(33736317, 1), [['And I get back two value that answer my question "is one teacher enough ?" '], ['-10000']], [[' +--------------------------------------+\n|nbMaxBySingleTeacher|nbTotalCourseToDo|\n+--------------------------------------+\n|         4          |        5        |\n+--------------------------------------+\n']], ['Fewest grouped by distinct - SQL'], 4, 0], [(33736317, 3), [["This tell me the number of teacher that are able to teach the courses I already have AND the new one I want. So if it's over zero, then I don't need a new teacher :"], ['-10000']], [[' +--+\n|nb|\n+--+\n|1 |\n+--+\n']], ['Fewest grouped by distinct - SQL'], 4, 0], [(33736568, 0), [['Oracle knows two ways to extract the hour. One is  EXTRACT(HOUR FROM xx)  where xx must be a timestamp unfortunately:'], ["The other is  TO_CHAR(xx, 'HH24')  which gives you a string:"]], [[' select * from visits where visit_time > extract(hour from cast(:datetime as timestamp)\n']], ['Oracle Database: getting hours as int value from passed date and time parameter'], 2, 1], [(33736568, 1), [["The other is  TO_CHAR(xx, 'HH24')  which gives you a string:"], ['-10000']], [[" select * from visits where visit_time > to_number(to_char(:datetime, 'hh24'))\n"]], ['Oracle Database: getting hours as int value from passed date and time parameter'], 2, 1], [(33791094, 0), [['SqlFiddleDemo'], ['OUTPUT']], [[' WITH n_node as (\n    SELECT "Name", "Attribute",\n           row_number() over (partition by "Name" order by "Date" DESC) rn\n    FROM Nodes \n), \nn_vector as (\n    SELECT "Node", "V_NAME", "color",\n           row_number() over (partition by "Node", "V_NAME" order by "Date" DESC) rn\n    FROM Vectors \n)\nSELECT "Name", "Attribute", "V_NAME", "color"\nFROM n_node\nJOIN n_vector \n  ON n_node.rn = n_vector.rn\n AND n_node.rn = 1\n AND n_node."Name" = n_vector."Node"\nORDER BY "Name" DESC\n']], ['How do I join the most recent row in one table to most recent row in another table (oracle)'], 2, 1], [(33791094, 1), [['OUTPUT'], ['-10000']], [[' | Name | Attribute | V_NAME | color |\n|------|-----------|--------|-------|\n|   14 |        A2 |     V1 |   red |\n|   14 |        A2 |     V2 |  blue |\n|   12 |        B1 |     V3 | black |\n|   12 |        B1 |     V4 | black |\n']], ['How do I join the most recent row in one table to most recent row in another table (oracle)'], 2, 0], [(33791862, 0), [['Oracle 11g R2 Schema Setup :'], ['Query 1 - Count results in 30 minute windows :']], [[" CREATE TABLE table_name (PersistentId, UserId, EnterDate ) AS\n          SELECT 111, 1,  to_date('June 1, 2015 17:05','Month DD, YYYY HH24:MI') FROM DUAL\nUNION ALL SELECT 112, 1,  to_date('June 1, 2015 17:21','Month DD, YYYY HH24:MI') FROM DUAL\nUNION ALL SELECT 113, 1,  to_date('June 1, 2015 17:27','Month DD, YYYY HH24:MI') FROM DUAL\nUNION ALL SELECT 114, 1,  to_date('June 1, 2015 18:25','Month DD, YYYY HH24:MI') FROM DUAL\nUNION ALL SELECT 115, 1,  to_date('June 1, 2015 19:00','Month DD, YYYY HH24:MI') FROM DUAL\nUNION ALL SELECT 116, 2,  to_date('June 1, 2015 18:05','Month DD, YYYY HH24:MI') FROM DUAL\nUNION ALL SELECT 117, 2,  to_date('June 1, 2015 18:21','Month DD, YYYY HH24:MI') FROM DUAL\nUNION ALL SELECT 118, 2,  to_date('June 1, 2015 19:27','Month DD, YYYY HH24:MI') FROM DUAL\n"]], ['sql count rows where diff Dates is less than 30 minutes'], 5, 0], [(33791862, 2), [['Results :'], ['Query 2 - Count all rows that are within 30 minutes of another row :']], [[' | USERID | Count |\n|--------|-------|\n|      1 |     3 |\n|      2 |     2 |\n']], ['sql count rows where diff Dates is less than 30 minutes'], 5, 0], [(33791862, 4), [['Results :'], ['-10000']], [[' | USERID | Count |\n|--------|-------|\n|      1 |     3 |\n|      2 |     2 |\n']], ['sql count rows where diff Dates is less than 30 minutes'], 5, 0], [(33831023, 0), [['I used temp tables (actually  table variables ) to give people an easily run-able solution to this problem.'], ['The meat of the query is here where you loop through the rows of the state accounts table using an index to keep track. Notice that you need to order by state in order to get the desired result (otherwise your index would be reset early).']], [[" declare @tempTablePeople TABLE \n( \n    [name] varchar(50), \n    [state] varchar(50), \n    [order] int\n)\nINSERT INTO @tempTablePeople \nVALUES\n('Jack', 'Virginia', 1),\n('Jill', 'Virginia', 2),\n('Ron', 'Florida', 1),\n('Bob', 'Florida', 2),\n('Scott', 'Florida', 3);\n\ndeclare @tempTableStateAccts TABLE \n( \n    [AcctNo] int,\n    [state] varchar(50)\n)\nINSERT INTO @tempTableStateAccts \nVALUES\n(22234, 'Virginia'),\n(32432, 'Virginia'),\n(02342, 'Florida'),\n(43423, 'Virginia'),\n(69449, 'Virginia'),\n(33233, 'Florida'),\n(52342, 'Florida'),\n(33342, 'Florida'),\n(77742, 'Florida'),\n(69429, 'Virginia')\n\n\n\ndeclare @tempTableStateAcctsPeople TABLE \n(\n    [AcctNo] int,\n    [state] varchar(50),\n    [name] varchar(50)\n)\n\n\nDECLARE @currentAcct int;\nDECLARE @currentState varchar(50);\nDECLARE @lastState varchar(50);\nDECLARE @currentNameIndex int;\nDECLARE @currentName varchar(50);\n"]], ['SQL Server: Alternate Assigning a Row based on a criteria'], 3, 0], [(33831023, 2), [['You can paste both parts of the SQL script, in order, and run it to see the results. '], ['-10000']], [[' AcctNo  state       name\n32432   Virginia    Jack\n69429   Virginia    Jill\n22234   Virginia    Jack\n69449   Virginia    Jill\n43423   Virginia    Jack\n77742   Florida     Ron\n33342   Florida     Bob\n52342   Florida     Scott\n33233   Florida     Ron\n2342    Florida     Bob\n']], ['SQL Server: Alternate Assigning a Row based on a criteria'], 3, 0], [(33860211, 0), [['For extracting the characters before the digits:'], ['For extracting the characters after the digits:']], [[" regexp_replace(fieldname, '\\d.*$', '')\n"]], ['Regex to split values in PostgreSQL'], 3, 0], [(33860211, 1), [['For extracting the characters after the digits:'], ['Final SQL']], [[" regexp_replace(fieldname, '^([^\\d]*\\d*)', '')\n"]], ['Regex to split values in PostgreSQL'], 3, 0], [(33860211, 2), [['Final SQL'], ['See  fiddle .']], [[" select\n  fieldname as original,\n  regexp_replace(fieldname, '\\d.*$', '') as before_s,\n  regexp_replace(fieldname, '^([^\\d]*\\d*)', '') as after_s,\n  cast(nullif(regexp_replace(fieldname, '[^\\d]', '', 'g'), '') as integer) as number\nfrom mytable;  \n"]], ['Regex to split values in PostgreSQL'], 3, 1], [(33860657, 0), [['You can use  SUM  with  CASE WHEN :'], ["I've added  COALESCE  in case  Extra_Seat_Cost  can be nullable. number +  NULL  produces  NULL .\n"]], [[' SELECT SUM(Cost + CASE WHEN Include_Extra = 1   --if Include_Extra is bool delete = 1\n                       THEN COALESCE(Extra_Seat_Cost,0) \n                       ELSE 0 END) AS total\nFROM table_name;\n']], ['Mysql Sum Conditional'], 2, 1], [(33883763, 1), [['You already got it to work, but here is the another way, without changing the table.'], ['You can test it  here .']], [[' SELECT invoice.ID, invoice.Invoice, invoice.Box, invoice.Delivered, invoice_1.Delivered AS Expr1\nFROM invoice, invoice AS invoice_1\nWHERE (((invoice.Invoice)=[invoice_1].[Invoice]) AND (([invoice_1].[Delivered])=Yes));\n']], ['Access SQL Select rows that have value in common with results of condition'], 2, 1], [(33897526, 0), [['Demonstration:'], ['Various ways to select the data:']], [[" create table zone_char(time_stamp datetime year to second, time_zone nchar(5));\ninsert into zone_char values('2015-11-24 21:00:00', '-0500');\ninsert into zone_char values('2015-11-23 15:00:00', '-0600');\ninsert into zone_char values('2015-11-22 17:19:21', '+0515');\ninsert into zone_char values('2015-11-21 02:56:31', '-0430');\n"]], ['Add nchar field to DateTime in Informix'], 6, 0], [(33897526, 2), [['Sample output:'], ['And note how much easier it is when the time zone is represented as an INTERVAL HOUR TO MINUTE:']], [[' 2015-11-24 16:00   2015-11-24 16:00:00   2015-11-24 16:00:00   2015-11-24   16:00:00   Tuesday 24 November 2015 04.00.00 PM\n2015-11-23 09:00   2015-11-23 09:00:00   2015-11-23 09:00:00   2015-11-23   09:00:00   Monday 23 November 2015 09.00.00 AM\n2015-11-22 22:19   2015-11-22 22:19:21   2015-11-22 22:19:21   2015-11-22   22:34:21   Sunday 22 November 2015 10.34.21 PM\n2015-11-20 22:56   2015-11-20 22:56:31   2015-11-20 22:56:31   2015-11-20   22:26:31   Friday 20 November 2015 10.26.31 PM\n']], ['Add nchar field to DateTime in Informix'], 6, 0], [(33897526, 3), [['And note how much easier it is when the time zone is represented as an INTERVAL HOUR TO MINUTE:'], ['SELECT:']], [[" alter table zone_char add hhmm interval hour to minute;\nupdate zone_char set hhmm = time_zone[1,3] || ':' || time_zone[4,5];\n"]], ['Add nchar field to DateTime in Informix'], 6, 0], [(33897526, 5), [['Result:'], ['-10000']], [[' 2015-11-24 21:00:00   -5:00   2015-11-24 16:00   2015-11-24 16:00:00   Tuesday 24 November 2015 04.00.00 PM\n2015-11-23 15:00:00   -6:00   2015-11-23 09:00   2015-11-23 09:00:00   Monday 23 November 2015 09.00.00 AM\n2015-11-22 17:19:21    5:15   2015-11-22 22:34   2015-11-22 22:34:21   Sunday 22 November 2015 10.34.21 PM\n2015-11-21 02:56:31   -4:30   2015-11-20 22:26   2015-11-20 22:26:31   Friday 20 November 2015 10.26.31 PM\n']], ['Add nchar field to DateTime in Informix'], 6, 0], [(33908143, 2), [["EDIT:  Here's a solution!   I don't claim to understand it fully, but   basically it creates a translation table that joins to your string (in the inp_str table).  The connect by, level traverses the length of the string and replaces characters where there is a match in the translation table.  I modified a solution found here:  http://database.developer-works.com/article/14901746/Replace+%28translate%29+one+char+to+many  that really doesn't have a great explanation.  Hopefully someone here will chime in and explain this fully."], ['EDIT 8/10/2016 - Make it a function for encapsulation and reusability so you could use it for multiple columns at once:']], [[' SQL> with trans_tbl(ch_frm, str_to) as (\n     select \'"\',     \'\\"\' from dual union\n     select \'/\',     \'\\/\' from dual union\n     select \'\\\',     \'\\\\\' from dual union\n     select chr(8),  \'\\b\' from dual union -- BS\n     select chr(12), \'\\f\' from dual union -- FF\n     select chr(10), \'\\n\' from dual union -- NL\n     select chr(13), \'\\r\' from dual union -- CR\n     select chr(9),  \'\\t\' from dual       -- HT\n   ),\n   inp_str as (\n     select \'No\' || chr(12) || \'w is \' || chr(9) || \'the "time" for /all go\\od men to \'||\n     chr(8)||\'com\' || chr(10) || \'e to the aid of their \' || chr(13) || \'country\' txt from dual\n   )\n   select max(replace(sys_connect_by_path(ch,\'`\'),\'`\')) as txt\n   from (\n   select lvl\n    ,decode(str_to,null,substr(txt, lvl, 1),str_to) as ch\n    from inp_str cross join (select level lvl from inp_str connect by level <= length(txt))\n    left outer join trans_tbl on (ch_frm = substr(txt, lvl, 1))\n    )\n    connect by lvl = prior lvl+1\n    start with lvl = 1;\n\nTXT\n------------------------------------------------------------------------------------------\nNo\\fw is \\tthe \\"time\\" for \\/all go\\\\od men to \\bcom\\ne to the aid of their \\rcountry\n\nSQL>\n']], ['Escaping special characters for JSON output'], 5, 1], [(33939688, 0), [['Oracle 11g R2 Schema Setup :'], ['Query 1 :']], [[' CREATE TABLE ORDERS (ID NUMBER PRIMARY KEY);\nINSERT INTO ORDERS VALUES (65733);\nINSERT INTO ORDERS VALUES (23423);\nINSERT INTO ORDERS VALUES (456765);\nINSERT INTO ORDERS VALUES (23464);\nINSERT INTO ORDERS VALUES (77532);\ninsert into ORDERS values (23422);\ninsert into ORDERS values (56435);\n\nCREATE TABLE PRODUCTS (\n  ID NUMBER PRIMARY KEY,\n  ORDER_ID NUMBER REFERENCES ORDERS(ID),\n  PARENT_ID NUMBER\n);\nINSERT INTO PRODUCTS VALUES (1,65733,3);\nINSERT INTO PRODUCTS VALUES (2,23423,3);\nINSERT INTO PRODUCTS VALUES (3,77532,4);\nINSERT INTO PRODUCTS VALUES (4,23464,0); \nINSERT INTO PRODUCTS VALUES (5,456765,null);\ninsert into products values (6,23422,7);\ninsert into products values (7,56435,0);\n']], ['How to present tree of id / hierarchical query'], 9, 0], [(33939688, 1), [['Query 1 :'], ['Results :']], [[" WITH WantToPresent( ID ) AS (\n  SELECT 23464 FROM DUAL\n)\nSELECT ORDER_ID\nFROM   PRODUCTS p\nSTART WITH\n  EXISTS( SELECT 'X'\n          FROM   WantToPresent w\n          WHERE  p.ORDER_ID = w.ID )\nCONNECT BY ID = PRIOR parent_id\nUNION\nSELECT ORDER_ID\nFROM   PRODUCTS p\nSTART WITH\n  EXISTS( SELECT 'X'\n          FROM   WantToPresent w\n          WHERE  p.ORDER_ID = w.ID )\nCONNECT BY PRIOR ID = parent_id\nUNION\nSELECT p2.ORDER_ID\nFROM   PRODUCTS p1\n       INNER JOIN\n       PRODUCTS p2\n       ON ( p1.PARENT_ID = p2.PARENT_ID AND p2.PARENT_ID <> 0 )\n       INNER JOIN\n       WantToPresent w\n       ON ( p1.ORDER_ID = w.ID )\n"]], ['How to present tree of id / hierarchical query'], 9, 1], [(33939688, 2), [['Results :'], ['Query 2 :']], [[' | ORDER_ID |\n|----------|\n|    23423 |\n|    23464 |\n|    65733 |\n|    77532 |\n']], ['How to present tree of id / hierarchical query'], 9, 0], [(33939688, 3), [['Query 2 :'], ['Results :']], [[" WITH WantToPresent( ID ) AS (\n  SELECT 23423 FROM DUAL\n)\nSELECT ORDER_ID\nFROM   PRODUCTS p\nSTART WITH\n  EXISTS( SELECT 'X'\n          FROM   WantToPresent w\n          WHERE  p.ORDER_ID = w.ID )\nCONNECT BY \n  ID = PRIOR parent_id\nUNION\nSELECT ORDER_ID\nFROM   PRODUCTS p\nSTART WITH\n  EXISTS( SELECT 'X'\n          FROM   WantToPresent w\n          WHERE  p.ORDER_ID = w.ID )\nCONNECT BY PRIOR ID = parent_id\nUNION\nSELECT p2.ORDER_ID\nFROM   PRODUCTS p1\n       INNER JOIN\n       PRODUCTS p2\n       ON ( p1.PARENT_ID = p2.PARENT_ID AND p2.PARENT_ID <> 0 )\n       INNER JOIN\n       WantToPresent w\n       ON ( p1.ORDER_ID = w.ID )\n"]], ['How to present tree of id / hierarchical query'], 9, 1], [(33939688, 4), [['Results :'], ['Query 3 :']], [[' | ORDER_ID |\n|----------|\n|    23423 |\n|    23464 |\n|    65733 |\n|    77532 |\n']], ['How to present tree of id / hierarchical query'], 9, 0], [(33939688, 5), [['Query 3 :'], ['Results :']], [[" WITH WantToPresent( ID ) AS (\n  SELECT 23464 FROM DUAL UNION ALL\n  SELECT 65733 FROM DUAL\n)\nSELECT ORDER_ID\nFROM   PRODUCTS p\nSTART WITH\n  EXISTS( SELECT 'X'\n          FROM   WantToPresent w\n          WHERE  p.ORDER_ID = w.ID )\nCONNECT BY \n  ID = PRIOR parent_id\nUNION\nSELECT ORDER_ID\nFROM   PRODUCTS p\nSTART WITH\n  EXISTS( SELECT 'X'\n          FROM   WantToPresent w\n          WHERE  p.ORDER_ID = w.ID )\nCONNECT BY PRIOR ID = parent_id\nUNION\nSELECT p2.ORDER_ID\nFROM   PRODUCTS p1\n       INNER JOIN\n       PRODUCTS p2\n       ON ( p1.PARENT_ID = p2.PARENT_ID AND p2.PARENT_ID <> 0 )\n       INNER JOIN\n       WantToPresent w\n       ON ( p1.ORDER_ID = w.ID )\n"]], ['How to present tree of id / hierarchical query'], 9, 1], [(33939688, 6), [['Results :'], ['Query 4 :']], [[' | ORDER_ID |\n|----------|\n|    23423 |\n|    23464 |\n|    65733 |\n|    77532 |\n']], ['How to present tree of id / hierarchical query'], 9, 0], [(33939688, 7), [['Query 4 :'], ['Results :']], [[" WITH WantToPresent( ID ) AS (\n  SELECT 56435 FROM DUAL\n)\nSELECT ORDER_ID\nFROM   PRODUCTS p\nSTART WITH\n  EXISTS( SELECT 'X'\n          FROM   WantToPresent w\n          WHERE  p.ORDER_ID = w.ID )\nCONNECT BY \n  ID = PRIOR parent_id\nUNION\nSELECT ORDER_ID\nFROM   PRODUCTS p\nSTART WITH\n  EXISTS( SELECT 'X'\n          FROM   WantToPresent w\n          WHERE  p.ORDER_ID = w.ID )\nCONNECT BY PRIOR ID = parent_id\nUNION\nSELECT p2.ORDER_ID\nFROM   PRODUCTS p1\n       INNER JOIN\n       PRODUCTS p2\n       ON ( p1.PARENT_ID = p2.PARENT_ID AND p2.PARENT_ID <> 0 )\n       INNER JOIN\n       WantToPresent w\n       ON ( p1.ORDER_ID = w.ID )\n"]], ['How to present tree of id / hierarchical query'], 9, 1], [(33939688, 8), [['Results :'], ['-10000']], [[' | ORDER_ID |\n|----------|\n|    23422 |\n|    56435 |\n']], ['How to present tree of id / hierarchical query'], 9, 0], [(33962020, 0), [['You can try:'], ['For interval and group you can try this:']], [[" SELECT date_format(str_to_date(DATECOLUMN, '%d/%m/%Y'), '%d/%m/%Y') AS MyDate, COUNT(*)\nFROM TABLE \nGROUP BY MyDate\n"]], ['Mysql GROUP BY DATE from text column'], 2, 1], [(33962020, 1), [['For interval and group you can try this:'], ['-10000']], [[" SELECT COUNT(*), MyDate\nFROM TABLE, (\n    SELECT date_format(str_to_date(DATECOLUMN, '%d/%m/%Y'), '%d/%m/%Y') AS MyDate\n    FROM TABLE) Tmp \nWHERE date_format(str_to_date(MyDate, '%d/%m/%Y'), '%Y-%m-%d') >= NOW() - INTERVAL 7 DAY\nGROUP BY MyDate\n"]], ['Mysql GROUP BY DATE from text column'], 2, 1], [(33965409, 0), [['Try this in your SS2014'], ['This you need to get access:']], [[" USE [master]\nGO\nEXEC master.dbo.sp_addlinkedserver \n    @server = N'YourLowerServer', \n    @srvproduct=N'SQL Server' ;\nGO\n"]], ['SQL - Exporting a table with xml colomun into a text file'], 3, 0], [(33965409, 1), [['This you need to get access:'], ['If this is done you can use the  INSERT INTO  from one server directly to the other server. Try this in your SS2014:']], [[" EXEC master.dbo.sp_addlinkedsrvlogin \n    @rmtsrvname = N'YourLowerServer', \n    @locallogin = NULL , \n    @useself = N'True' ;\nGO\n"]], ['SQL - Exporting a table with xml colomun into a text file'], 3, 0], [(33965409, 2), [['If this is done you can use the  INSERT INTO  from one server directly to the other server. Try this in your SS2014:'], ['If you want to get rid of your linked server after this operation use  sp_dropserver  (read here:  https://msdn.microsoft.com/en-us/library/ms174310.aspx )']], [[' INSERT INTO YourLowerServer.YourDatabase.dbo.TableName(col1,col2,...)\nSELECT col1,col2,... FROM dbo.TableName \n']], ['SQL - Exporting a table with xml colomun into a text file'], 3, 0], [(34004813, 0), [['So what I ended up doing instead that solved my issue was joining the table in like this:'], ['And this what those search text fields are:']], [[" JOIN #CityIDs c\n  ON cpcpp.CUST_PROD_PARM_VAL LIKE '' + c.FirstCitySearchText + ''\n  OR cpcpp.CUST_PROD_PARM_VAL LIKE '' + c.LastCitySearchText + ''\n  OR cpcpp.CUST_PROD_PARM_VAL LIKE '' + c.OnlyCitySearchText + ''\n  OR cpcpp.CUST_PROD_PARM_VAL LIKE '' + c.City_ID + ''\n  OR cpcpp.CUST_PROD_PARM_VAL LIKE 'ALL'\n"]], ['find value in comma separated list for each record of a different table'], 2, 0], [(34004813, 1), [['And this what those search text fields are:'], ["I couldn't use the where clauses that were posted because I wasn't sure of how to join the table in to get the city ids, so instead I joined them using the where clause as the join."]], [[" UPDATE c\n   SET c.FirstCitySearchText = CAST(c.City_ID AS VARCHAR(100))+ ',%'\n     , c.LastCitySearchText = '%,' + CAST(c.City_ID AS VARCHAR(100))\n     , c.OnlyCitySearchText = '%,'  + CAST(c.City_ID AS VARCHAR(100)) + ',%'\n  FROM #CityIDs c\n"]], ['find value in comma separated list for each record of a different table'], 2, 0], [(34005749, 0), [['SQL Fiddle'], ['Use  dense_rank  to number the rows if there can be multiple entries per day.']], [[' with rownums as (SELECT row_number() over(partition by category order by cast(entryDate as date) desc) as rn\n                 ,*\n                 FROM dataTable\n)\ndelete from rownums where rn <= 5 --use > 5 for records prior to the last 5 days\n']], ['Query to delete records older than n active dates from each group'], 2, 1], [(34005749, 1), [['Use  dense_rank  to number the rows if there can be multiple entries per day.'], ['-10000']], [[' with rownums as (SELECT dense_rank() over(partition by category order by cast(entryDate as date) desc) as rn\n                     ,*\n                 FROM dataTable)\ndelete from rownums where rn > 5;\n']], ['Query to delete records older than n active dates from each group'], 2, 1], [(34031494, 0), [['First of all you need to start with the subject of what you want to return. That would be users. So this will be your first table to select from (Note here: use AS to rename tables for brevity):'], ['Now assuming we want lots of human readable data such as names we will link the following tables.']], [[' Select *\nFrom users AS u\n']], ['MySQL - Select data from relational tables A, B, C, D, E if record was not found on Table F'], 5, 0], [(34031494, 1), [['Now assuming we want lots of human readable data such as names we will link the following tables.'], ["And to top it off, to find people who didn't attend, they will not be in the attends table so we just check for people where the values are null for attends."]], [[' LEFT OUTER JOIN users_lectures AS ul ON u.id = ul.userid\nLEFT OUTER JOIN lectures AS l ON l.id = ul.lectureid\nLEFT OUTER JOIN courses AS c ON c.id = l.courseid\nLEFT OUTER JOIN attends AS a ON a.userid = u.id AND a.lectureid = l.id\n']], ['MySQL - Select data from relational tables A, B, C, D, E if record was not found on Table F'], 5, 0], [(34031494, 2), [["And to top it off, to find people who didn't attend, they will not be in the attends table so we just check for people where the values are null for attends."], ["As a side note, you won't get any results with this in the WHERE clause"]], [[' WHERE a.userid IS NULL\n']], ['MySQL - Select data from relational tables A, B, C, D, E if record was not found on Table F'], 5, 0], [(34031494, 3), [["As a side note, you won't get any results with this in the WHERE clause"], ['Because you are joining with this statement']], [[' AND attends.lecture_id != users_lectures.lecture_id\n']], ['MySQL - Select data from relational tables A, B, C, D, E if record was not found on Table F'], 5, 0], [(34031494, 4), [['Because you are joining with this statement'], ['Which contradict each other']], [[' LEFT JOIN attends ON attends.lecture_id = users_lectures.lecture_id\n']], ['MySQL - Select data from relational tables A, B, C, D, E if record was not found on Table F'], 5, 0], [(34082441, 0), [['One way of doing it is by the use of correlated subqueries:'], ["The above solution won't work with a set of intervals like the following:"]], [[' SELECT DISTINCT\n       (SELECT MIN(opens)\n       FROM mytable AS t2\n       WHERE t2.opens <= t1.closes AND t2.closes >= t1.opens) AS start,\n       (SELECT MAX(closes)\n       FROM mytable AS t2\n       WHERE t2.opens <= t1.closes AND t2.closes >= t1.opens) AS end       \nFROM mytable AS t1\nORDER BY opens\n']], ['MySQL consolodating table rows with overlapping date spans'], 3, 1], [(34082441, 1), [["The above solution won't work with a set of intervals like the following:"], ["Here's a solution using variables:"]], [[' 1. |-----------|\n2. |----|\n3.           |-----|\n']], ['MySQL consolodating table rows with overlapping date spans'], 3, 0], [(34082441, 2), [["Here's a solution using variables:"], ['The idea is to start from left-most  opens/closes  interval. Variables  @start ,  @end  are used to propagate the incrementally expanding  (as new overlapping rows are being processed) consolidated interval down the interval chain. Once a non-overlapping interval is encountered,  [@start - @end]  is initialized so as to match this new interval and  grp  is incremented by one.']], [[" SELECT MIN(start) AS start, MAX(end) AS end\nFROM (\n  SELECT @grp := IF(@start = '1900-01-01' OR \n                   (opens <= @end AND closes >= @start), @grp, @grp+1) AS grp,        \n         @start := IF(@start = '1900-01-01', opens, \n                      IF(opens <= @end AND closes >= @start, \n                         IF (@start < opens, @start, opens), opens)) AS start,\n         @end := IF(@end = '1900-01-01', closes, \n                    IF (opens <= @end AND closes >= @start, \n                      IF (@end > closes, @end, closes), closes)) AS end                 \n  FROM mytable\n  CROSS JOIN (SELECT @grp := 1, @start := '1900-01-01', @end := '1900-01-01') AS vars\n  ORDER BY opens, DATEDIFF(closes, opens) DESC) AS t\nGROUP BY grp\n"]], ['MySQL consolodating table rows with overlapping date spans'], 3, 1], [(34121399, 1), [['The resulting SQL is:'], ['To satisfy the "only  StatusUpdates  from the current day" condition I have defined  date  and  now  by importing  Database.Esqueleto.Internal.Sql  and:']], [[' SELECT "status_update"."id", "status_update"."subject", "status_update"."message", "user"."email"\nFROM "user", "status_update"\nWHERE ("status_update"."id" = (SELECT "status_update2"."id"\n    FROM "status_update" AS "status_update2"\n    WHERE ("status_update2"."user" = "user"."id")\n    AND (date("status_update2"."posted") = date(date(?)))\n    ORDER BY "status_update2"."posted" DESC\n    LIMIT 1))\nAND ("user"."id" = "status_update"."user")\n']], ['Unique post author from Esqueleto'], 3, 0], [(34121399, 2), [['To satisfy the "only  StatusUpdates  from the current day" condition I have defined  date  and  now  by importing  Database.Esqueleto.Internal.Sql  and:'], ['However, what exactly "from the current day" means to you could be something different (past 24 hours, in a certain timezone, etc.).']], [[' date :: SqlExpr (Value UTCTime) -> SqlExpr (Value Int)\ndate d = unsafeSqlFunction "date" d\n\nnow :: SqlExpr (Value UTCTime)\nnow = unsafeSqlFunction "date" (val "now" :: SqlExpr (Value String))\n']], ['Unique post author from Esqueleto'], 3, 0], [(34191191, 0), [['As I understand it you want to have a list of unique salary values in descending order. This is how you can achieve it:'], ['Alternative:']], [[' SELECT Salary FROM faculty\ngroup by Salary\norder by Salary desc\n']], ['Display the different salary figures earned by faculty members arranged in descending order'], 3, 1], [(34191191, 1), [['Alternative:'], ['This will give you all the salaries in descending order. If two people earn 10k, you will only see 10k once.']], [[' SELECT distinct(Salary) FROM faculty\norder by Salary desc\n']], ['Display the different salary figures earned by faculty members arranged in descending order'], 3, 1], [(34191191, 2), [['This will give you all the salaries in descending order. If two people earn 10k, you will only see 10k once.'], ['This will give you all the salaries grouped by faculty id in descending order with no duplicates within a faculty.']], [[' SELECT Salary FROM faculty\ngroup by FacultyID, Salary\norder by Salary desc\n']], ['Display the different salary figures earned by faculty members arranged in descending order'], 3, 1], [(34218190, 0), [["The syntax here is finding all FromDate that doesn't have an overlapping FromDate and ToDate interval and all ToDates that doesn't have an overlapping FromDate and ToDate interval. Giving them a rownumber according to the date value and matching them on that rownumber:"], ['Result:']], [[' ;WITH CTE as\n(\n  SELECT min(Id) Id ,FromDate, row_number() over (ORDER BY FromDate) rn\n  FROM @temp x\n  WHERE \n    not exists\n      (SELECT * FROM @temp WHERE x.FromDate > FromDate and x.FromDate <= Todate)\n  GROUP BY FromDate\n), CTE2 as\n(\n  SELECT Max(Id) Id ,ToDate, row_number() over (ORDER BY ToDate) rn\n  FROM @temp x\n  WHERE\n    not exists\n      (SELECT * FROM @temp WHERE x.ToDate >= FromDate and x.ToDate < Todate)\n  GROUP BY ToDate\n)\nSELECT SUM(DateDiff(month, CTE.FromDate, CTE2.ToDate))\nFROM CTE\nJOIN CTE2\nON CTE.rn = CTE2.rn\n']], ['T-SQL Calculate duration in months between different years of ranges'], 2, 1], [(34218190, 1), [['Result:'], ['-10000']], [[' 144\n']], ['T-SQL Calculate duration in months between different years of ranges'], 2, 0], [(34221483, 0), [['One solution is to use tally table for multiple split:'], ['Output:']], [[" SELECT id AS f_id, SUBSTRING_INDEX(SUBSTRING_INDEX(t.name, ' ', n.n), ' ', -1) AS word\nFROM mytable t \nCROSS JOIN \n(\n   SELECT a.N + b.N * 10 + 1 n\n     FROM \n    (SELECT 0 AS N UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9) a\n   ,(SELECT 0 AS N UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9) b\n) n\n WHERE n.n <= 1 + (LENGTH(t.name) - LENGTH(REPLACE(t.name, ' ', '')))\nORDER BY id, n\n"]], ['Exploding strings to words and copying to another table'], 3, 1], [(34221483, 1), [['Output:'], ['Exclude words that are less than 3 characters:']], [[' ╔═════╦═══════════╗\n║f_id ║   word    ║\n╠═════╬═══════════╣\n║  1  ║ foo       ║\n║  1  ║ bar       ║\n║  1  ║ something ║\n║  2  ║ something ║\n║  2  ║ else      ║\n╚═════╩═══════════╝\n']], ['Exploding strings to words and copying to another table'], 3, 0], [(34221483, 2), [['Exclude words that are less than 3 characters:'], ['SqlFiddleDemo2']], [[" WHERE n.n <= 1 + (LENGTH(t.name) - LENGTH(REPLACE(t.name, ' ', '')))\n  AND LENGTH(SUBSTRING_INDEX(SUBSTRING_INDEX(t.name, ' ', n.n), ' ', -1)) > 2\n"]], ['Exploding strings to words and copying to another table'], 3, 0], [(34232471, 0), [['You can show the output like this'], ['But you can actually do the whole thing much faster this way (OTTOMH):']], [[" create or replace PROCEDURE SOH_MEMBER IS\n\nCURSOR studC IS\nSELECT* from STUD;\nBEGIN\n  for c1   IN  studC\nLOOP\n  IF C1.CITY = 'sohar'\n  THEN INSERT INTO SOH_STUDENT (NAME, TEL, SEX)\n  VALUES( C1.NAME,  C1.TEL, C1.SEX);\n  end if;\n  END LOOP;\n  END SOH_MEMBER;\n\n/* show the output */\nSelect * From SOH_STUDENT\n"]], ['How to run a cursor inside a procedure in SQL Server'], 2, 1], [(34232471, 1), [['But you can actually do the whole thing much faster this way (OTTOMH):'], ['-10000']], [[" create or replace PROCEDURE SOH_MEMBER IS\n\nInsert Into SOH_STUDENT (NAME, TEL, SEX)\nSELECT NAME, TEL, SEX\nfrom STUD\nWhere CITY = 'sohar'\n\nSelect * From SOH_STUDENT\n"]], ['How to run a cursor inside a procedure in SQL Server'], 2, 1], [(34242338, 0), [['To do this you can use equivalent of  ROW_NUMBER  and  GROUP BY  calculated RowNumber column:'], ['Output:']], [[" SELECT \n    MAX(CASE WHEN Role = 'Admin' THEN Name END) AS `Admin`, \n    MAX(CASE WHEN Role = 'Moderator' THEN Name END) AS `Moderator`, \n    MAX(CASE WHEN Role = 'User' THEN Name END) AS `User`\nFROM (\n      SELECT *\n        ,@row_num := IF(@prev_value=concat_ws('',t.Role),@row_num+1,1) AS RowNumber\n        ,@prev_value := concat_ws('',t.Role)  \n      FROM Organization t,\n         (SELECT @row_num := 1) x,\n         (SELECT @prev_value := '') y\n      ORDER BY t.Role   \n     ) AS sub\nGROUP BY RowNumber\n"]], ['MySQL pivoting with VARCHAR'], 2, 1], [(34242338, 1), [['Output:'], ['-10000']], [[' ╔═════════╦════════════╦══════╗\n║ Admin   ║ Moderator  ║ User ║\n╠═════════╬════════════╬══════╣\n║ Tony    ║ (null)     ║ Sara ║\n║ (null)  ║ (null)     ║ John ║\n╚═════════╩════════════╩══════╝\n']], ['MySQL pivoting with VARCHAR'], 2, 0], [(34245868, 0), [['First, update your table to have integer ips.  The code is not going to work with the string representation.  Here is one method:'], ['Then, run the query by doing something like:']], [[' alter table t add ipstart_int unsigned;\nalter table t add ipend_int unsigned;\n\nupdate t\n    set ipstart_int = dbo.IPAddressToInteger(ipstart),\n        ipend_int = dbo.IPAddressToInteger(ipend);\n']], ['Return record with start IP and end IP as range that an IP address falls between?'], 2, 0], [(34245868, 1), [['Then, run the query by doing something like:'], ['With a bit of luck, this will use the index and be very quick.  You can then compare the resulting end ip to be sure that  @ip  is, indeed, in the right range.']], [[' select top 1 ip.*\nfrom t ip\nwhere ip.ipstart > dbo.IPAddressToInteger(@ip)\norder by ipstart asc;\n']], ['Return record with start IP and end IP as range that an IP address falls between?'], 2, 0], [(34251134, 1), [['-10000'], ['Demo']], [[" SELECT REVERSE('1234')\n-- 4321\n"]], ['Reversing a number using reverse for loop in Postgresql in PgAdmin'], 2, 1], [(34254637, 0), [['One solution is to use a GROUP BY query, grouping by FixtureID and counting the rows for each FixtureID. This query will select all FixtureIDs with both players 1 and 3:'], ['then to get the record from the Results table you can use this query:']], [[' select\n  FixtureID\nfrom\n  Results\nwhere\n  PlayerID IN (1,3)\ngroup by\n  FixtureID\nhaving\n  count(*)=2\n']], ['SQL Query to return rows where a column value appears multiple time'], 2, 0], [(34273934, 0), [['Change one of arguments to  NUMERIC  to avoid integer division'], ['or:']], [[' SELECT (4 -1) / 2.0  AS result\n']], ['Netezza automatically rounding down decimal values'], 3, 1], [(34273934, 1), [['or:'], ['Division:']], [[' SELECT (4-1) / CAST(2 AS NUMERIC(15,6)) AS result\n']], ['Netezza automatically rounding down decimal values'], 3, 1], [(34273934, 2), [['Division:'], ['-10000']], [[' 1 / 10   -> 0\n1.0 / 10 -> 0.1\n1 / 10.0 -> 0.1\n1.0/10.0 -> 0.1\n']], ['Netezza automatically rounding down decimal values'], 3, 0], [(34278143, 0), [['An easy solution is just to require that the entry is not in your completed tasks table:'], ['Result:']], [[' select * from users, tasks\nwhere not exists (\n    select * from users_tasks\n    where users.id = users_tasks.user_id and tasks.id = users_tasks.task_id\n);\n']], ['Mysql finding results not present in jointable'], 2, 1], [(34278143, 1), [['Result:'], ['-10000']], [[' +------+-------+------+-------------+\n| id   | name  | id   | name        |\n+------+-------+------+-------------+\n|    3 | susie |    2 | Shower      |\n|    2 | mike  |    3 | Check Email |\n|    3 | susie |    3 | Check Email |\n+------+-------+------+-------------+\n']], ['Mysql finding results not present in jointable'], 2, 0], [(34309419, 0), [['Calculate running sum of  Qty  to know how many rows to skip from  ExtInvoice  using '], ['I added one more  P_No  to verify that results are partitioned correctly.']], [[' SUM(Qty) OVER (PARTITION BY P_No ORDER BY NumOrder)\n']], ['How to Join tables to assign one record to multiple records in a "FIFO" order'], 4, 0], [(34309419, 1), [['I added one more  P_No  to verify that results are partitioned correctly.'], ['I the final query you should list actual column names instead of  * .\nTo make it work efficiently there should be an index for  ExtInvoice  table on  (P_No, NumOrder) .']], [[" DECLARE @ExtInvoice TABLE \n(Ext_Invoice int, P_No int, Part int, InvoiceDate int, Due_Date int, NumOrder int);\n\nINSERT INTO @ExtInvoice\n(Ext_Invoice, P_No, Part, InvoiceDate, Due_Date, NumOrder)\nVALUES\n(571, 607, 7991, 151116, 151222, 1),\n(572, 607, 7991, 151120, 151228, 2),\n(573, 607, 7991, 151127, 160104, 3),\n(574, 608, 7991, 151127, 160104, 1);\n\n\nDECLARE @InternalInvoice TABLE\n(Invoice_No int, Original varchar(5), P_No int, Part int, Qty int, NumOrder int);\n\nINSERT INTO @InternalInvoice\n(Invoice_No, Original, P_No, Part, Qty, NumOrder)\nVALUES\n(198, '607', 607, 7991, 2, 1),\n(199, 'RE607', 607, 7991, 1, 2),\n(200, 'RE607', 607, 7991, 1, 3),\n(201, 'RE608', 608, 7991, 1, 1);\n"]], ['How to Join tables to assign one record to multiple records in a "FIFO" order'], 4, 0], [(34309419, 2), [['I the final query you should list actual column names instead of  * .\nTo make it work efficiently there should be an index for  ExtInvoice  table on  (P_No, NumOrder) .'], ['Result']], [[' WITH\nCTE_InternalInvoices\nAS\n(\n    SELECT\n        I.*\n        ,SUM(Qty) OVER (PARTITION BY P_No ORDER BY NumOrder) AS SumQty\n    FROM\n        @InternalInvoice AS I\n)\nSELECT\n    *\nFROM\n    CTE_InternalInvoices\n    OUTER APPLY\n    (\n        SELECT TOP(CTE_InternalInvoices.Qty) *\n        FROM @ExtInvoice AS E\n        WHERE\n            E.P_No = CTE_InternalInvoices.P_No\n            AND E.NumOrder > CTE_InternalInvoices.SumQty - CTE_InternalInvoices.Qty\n        ORDER BY E.NumOrder\n    ) AS CA\nORDER BY CTE_InternalInvoices.Invoice_No;\n']], ['How to Join tables to assign one record to multiple records in a "FIFO" order'], 4, 1], [(34309419, 3), [['Result'], ['SQL Fiddle']], [[' +------------+----------+------+------+-----+----------+--------+-------------+------+------+-------------+----------+----------+\n| Invoice_No | Original | P_No | Part | Qty | NumOrder | SumQty | Ext_Invoice | P_No | Part | InvoiceDate | Due_Date | NumOrder |\n+------------+----------+------+------+-----+----------+--------+-------------+------+------+-------------+----------+----------+\n|        198 | 607      |  607 | 7991 |   2 |        1 |      2 | 571         | 607  | 7991 | 151116      | 151222   | 1        |\n|        198 | 607      |  607 | 7991 |   2 |        1 |      2 | 572         | 607  | 7991 | 151120      | 151228   | 2        |\n|        199 | RE607    |  607 | 7991 |   1 |        2 |      3 | 573         | 607  | 7991 | 151127      | 160104   | 3        |\n|        200 | RE607    |  607 | 7991 |   1 |        3 |      4 | NULL        | NULL | NULL | NULL        | NULL     | NULL     |\n|        201 | RE608    |  608 | 7991 |   1 |        1 |      1 | 574         | 608  | 7991 | 151127      | 160104   | 1        |\n+------------+----------+------+------+-----+----------+--------+-------------+------+------+-------------+----------+----------+\n']], ['How to Join tables to assign one record to multiple records in a "FIFO" order'], 4, 0], [(34314266, 0), [['You also have another option, to '], ['Then you can have a static field indicating which table each record is from, such as ']], [['       select from Table 1 \nUNION select from Table 2\n']], ['How can I mark which rows come from which table when I do a join?'], 2, 0], [(34314266, 1), [['Then you can have a static field indicating which table each record is from, such as '], ['This option will probably create more work in your code, but may put less burden on the database server.']], [["       SELECT 'Table 1' table, field1, field2 FROM Table1 \nUNION SELECT 'Table 2' table, field1, field2 FROM Table2\n"]], ['How can I mark which rows come from which table when I do a join?'], 2, 0], [(34340729, 0), [["If you think about it, you're wanting to update rows in your w_product_d table where the created_on_dt is null, which means that your update statement will have a basic structure of:"], ["Once you have that, it's easy then to slot in the column you're updating and what you're updating it with:"]], [[' update w_product_d wpd\nset    ...\nwhere  wpd.created_on_dt is null;\n']], ['Need to update data from another database using db link'], 2, 0], [(34353369, 0), [['You can do this with conditional aggregation:'], ['Another way is use  exists :']], [[' select parentid \nfrom tablename\ngroup by parentid\nhaving sum(case when datavalue = 1 then 1 else 0 end) > 0 and\n       sum(case when datavalue = 6 then 1 else 0 end) > 0\n']], ['Find group of records that match multiple values'], 3, 1], [(34353369, 1), [['Another way is use  exists :'], ['Another way is counting distinct occurrences:']], [[' select distinct parentid\nfrom tablename t1\nwhere exists(select * from tablename where parentid = t1.parentid and datavalue = 1) and\n      exists(select * from tablename where parentid = t1.parentid and datavalue = 6)\n']], ['Find group of records that match multiple values'], 3, 1], [(34353369, 2), [['Another way is counting distinct occurrences:'], ['-10000']], [[' select parentid \nfrom tablename\nwhere datavalue in(1, 6)\ngroup by parentid\nhaving count(distinct datavalue) = 2\n']], ['Find group of records that match multiple values'], 3, 1], [(34417879, 0), [['Oracle 11g R2 Schema Setup :'], ['Query 1 - The  ono and  pno s for the  pno  which has sold the maximum total quantity in December 2015 :']], [[" create table orders (\n  ono      number(5) not null primary key,\n  cno      number(5),\n  eno      number(4),\n  received date,\n  shipped  date\n);\n\nINSERT INTO orders\nSELECT 1020, 1, 1, DATE '2015-12-21', NULL FROM DUAL UNION ALL\nSELECT 1021, 1, 1, DATE '2015-12-20', DATE '2015-12-20' FROM DUAL UNION ALL\nSELECT 1022, 1, 1, DATE '2015-12-18', DATE '2015-12-20' FROM DUAL UNION ALL\nSELECT 1023, 1, 1, DATE '2015-12-21', NULL FROM DUAL UNION ALL\nSELECT 1024, 1, 1, DATE '2015-12-20', DATE '2015-12-20' FROM DUAL;\n\ncreate table odetails (\n  ono      number(5) not null references orders(ono),\n  pno      number(5) not null,\n  qty      integer check(qty > 0),\n  primary key (ono,pno)\n);\n\nINSERT INTO odetails\nSELECT 1020, 10506, 1 FROM DUAL UNION ALL\nSELECT 1020, 10507, 1 FROM DUAL UNION ALL\nSELECT 1020, 10508, 2 FROM DUAL UNION ALL\nSELECT 1020, 10509, 3 FROM DUAL UNION ALL\nSELECT 1021, 10601, 4 FROM DUAL UNION ALL\nSELECT 1022, 10601, 1 FROM DUAL UNION ALL\nSELECT 1022, 10701, 1 FROM DUAL UNION ALL\nSELECT 1023, 10800, 1 FROM DUAL UNION ALL\nSELECT 1024, 10900, 1 FROM DUAL;\n"]], ['Find highest and lowest selling item in a table'], 5, 0], [(34417879, 2), [['Results :'], ['Query 2 - The  ono  and  pno s for the items which have sold the maximum quantity in a single order in December 2015 :']], [[' |  ONO |   PNO | TOTAL_QTY |\n|------|-------|-----------|\n| 1021 | 10601 |         5 |\n| 1022 | 10601 |         5 |\n']], ['Find highest and lowest selling item in a table'], 5, 0], [(34417879, 4), [['Results :'], ['-10000']], [[' |  ONO |   PNO | QTY |\n|------|-------|-----|\n| 1021 | 10601 |   4 |\n']], ['Find highest and lowest selling item in a table'], 5, 0], [(34435022, 0), [['This is a bit tricky, because the  id  could be to either table.  One solution is  group by  with a  union all .  Here is a generic approach, assuming that the ids in the two reference table have different values:'], ['Note:  In MySQL, I would write this query as:']], [[" select b.boxid\nfrom boxes b left join\n     (select id, name \n      from toys t\n      union all\n      select id, name\n      from kitchen k\n     ) tk\n     on b.id = tk.id\ngroup by b.boxid\nhaving sum(case when tk.name = 'Car' then 1 else 0 end) > 0 and\n       sum(case when tk.name = 'Fork' then 1 else 0 end) > 0;\n"]], ['Finding out how two tables are connected by looking in a third'], 2, 1], [(34435022, 1), [['Note:  In MySQL, I would write this query as:'], ['You could write it this way in any SQL dialect, actually.']], [[" select b.boxid\nfrom boxes b left join\n     (select id, name \n      from toys t\n      where t.name in ('Car', 'Fork')\n      union all\n      select id, name\n      from kitchen k\n      where k.name in ('Car', 'Fork')\n     ) tk\n     on b.id = tk.id\ngroup by b.boxid\nhaving count(distinct name) = 2;\n"]], ['Finding out how two tables are connected by looking in a third'], 2, 1], [(34486588, 0), [["Edit: In case you can't use the OVER clause on aggregate functions in 2000, the following should accomplish the same thing.  Sorry I missed the 2000 requirement, and unfortunately you need either a subquery or derived table.  The fastest way to accomplish this type of problem depends on the data, but I like to do the grouping on the key only in a derived table, and then join to that, which I believe becomes better performing for larger sets of data."], ["I believe the following query might be an easier to read version of what you're looking for:"]], [[' select i.ImportNo,\n    i.ImportDate,\n    coalesce(i_s.Completed, 0) as Completed,\n    v.ID VendorID,\n    v.Name,\n    case when grp.Completed = grp.Total then 1\n        else 0\n    end as BatchCompleted\nfrom Imports i\nleft join Vendors v on i.ImportDate between v.StartDate and v.EndDate\nleft join ImportsStatus i_s on i.ImportNo = i_s.ImportNo and v.ID = i_s.VendorID\njoin (select i.ImportNo,\n        sum(cast(i_s.Completed as int)) Completed,\n        count(v.ID) Total\n    from Imports i\n    left join Vendors v on i.ImportDate between v.StartDate and v.EndDate\n    left join ImportsStatus i_s on i.ImportNo = i_s.ImportNo and v.ID = i_s.VendorID\n    group by i.ImportNo\n) grp on grp.ImportNo = i.ImportNo\n']], ['Querying possible choices and existing transactions'], 2, 1], [(34486588, 1), [["I believe the following query might be an easier to read version of what you're looking for:"], ['The idea here is to use partitioned sums/counts instead of subqueries to determine if the batch is completed or not.  It also uses  LEFT JOIN  to ensure each import is included.  I reordered and placed ImportsStatus at the end to prevent the duplicate problem you were having.']], [[' select i.ImportNo,\n    i.ImportDate,\n    coalesce(i_s.Completed, 0) as Completed,\n    v.ID VendorID,\n    v.Name,\n    iif(sum(cast(i_s.Completed as int)) over (partition by i.ImportNo) = count(v.ID) over (partition by i.ImportNo), 1, 0) as BatchCompleted\nfrom Imports i\nleft join Vendors v on i.ImportDate between v.StartDate and v.EndDate\nleft join ImportsStatus i_s on i.ImportNo = i_s.ImportNo and v.ID = i_s.VendorID\n']], ['Querying possible choices and existing transactions'], 2, 1], [(34508028, 0), [['Using sum, you can achieve the results, there are many other ways to do so. '], ['UPDATE: \nIf you want the values in a cursor, you can write the code like this']], [[" SELECT CASE\n           WHEN SUM(CASE\n                        WHEN c2.movetype = 'C' THEN\n                         1\n                        WHEN c2.movetype = 'D' THEN\n                         -1\n                        ELSE\n                         0\n                    END) = 0 THEN\n            'Y'\n           ELSE\n            'N'\n       END\n  FROM com24 c2\n WHERE c2.csnstat != 90\n GROUP BY c2.poliref,\n          c2.inrctyp,\n          c2.inrcref,\n          c2.csntype,\n          c2.duedate,\n          c2.itrno\n"]], ['select Y if column if difference of count(colmn1) with value A and B is 0 using aggregate funtion'], 2, 1], [(34508028, 1), [['UPDATE: \nIf you want the values in a cursor, you can write the code like this'], ['-10000']], [[" CURSOR C1 AS\nWITH t_table AS (\n    SELECT c2.poliref,\n           c2.inrctyp,\n           c2.inrcref,\n           c2.csntype,\n           c2.duedate,\n           c2.itrno,\n           CASE\n               WHEN SUM(CASE\n                        WHEN c2.movetype = 'C' THEN\n                         1\n                        WHEN c2.movetype = 'D' THEN\n                         -1\n                        ELSE\n                         0\n                    END) = 0 THEN\n            'Y'\n           ELSE\n            'N'\n           END AS flag\n      FROM com24 c2\n     WHERE c2.csnstat != 90\n     GROUP BY c2.poliref,\n              c2.inrctyp,\n              c2.inrcref,\n              c2.csntype,\n              c2.duedate,\n              c2.itrno)\nSELECT *\n  FROM t_table       \n WHERE flag = 'Y';\n"]], ['select Y if column if difference of count(colmn1) with value A and B is 0 using aggregate funtion'], 2, 1], [(34516501, 0), [['If you are using  SQL Server 2012+  you could use  FORMAT  function:'], ['Output:']], [[" DECLARE @cols AS NVARCHAR(MAX);\n\n;WITH cte AS       -- get only one date per month/year\n(\n  SELECT MIN(StartDate) AS StartDate\n  FROM #Products2 \n  GROUP BY YEAR(StartDate),MONTH(StartDate)\n)\nSELECT @cols = STUFF((SELECT  ',' + QUOTENAME(FORMAT(StartDate, 'MMM-yy'))\n                      FROM cte\n                      ORDER BY StartDate      \n                      FOR XML PATH('')),\n                    1, 1, N'');\n\nSELECT @cols;\n"]], ['MSSQL Order by date with distinct'], 2, 1], [(34516501, 1), [['Output:'], ['-10000']], [[' ╔══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n║                                                        result                                                        ║\n╠══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n║ [Dec-15],[Jan-16],[Feb-16],[Mar-16],[Apr-16],[May-16],[Jun-16],[Jul-16],[Aug-16],[Sep-16],[Oct-16],[Nov-16],[Dec-16] ║\n╚══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n']], ['MSSQL Order by date with distinct'], 2, 0], [(34604707, 0), [['To Insert into C, the query used above is correct- '], ['To delete from B, you can use the below query- ']], [[' Insert into C (productid,partid) \nselect A.productid, A.partid \nfrom A join B on A.productid = B.productid AND A.partid = B.partid\n']], ['how to join tables when the join is on 2 fields?'], 2, 0], [(34604707, 1), [['To delete from B, you can use the below query- '], ['Since you have to delete the records in B so you have to give that in delete statement.']], [[' Delete B from B\njoin C\non C.productid = B.productid \nAND C.partid = B.partid\n']], ['how to join tables when the join is on 2 fields?'], 2, 0], [(34610639, 0), [['Looks like you need  FULL OUTER JOIN  and exclude common part. You can simulate it with:'], ['SqlFiddleDemo']], [[' SELECT T1.col_name\nFROM T1 \nLEFT JOIN T2\n  ON T1.col_name = T2.col_name\nWHERE T2.col_name IS NULL\nUNION\nSELECT T2.col_name\nFROM T2 \nLEFT JOIN T1\n  ON T1.col_name = T2.col_name\nWHERE T1.col_name IS NULL;\n']], ['Combine two tables, exclude same records'], 5, 1], [(34610639, 1), [['SqlFiddleDemo'], ['-10000']], [[' ╔══════════╗\n║ col_name ║\n╠══════════╣\n║ C        ║\n║ D        ║\n║ E        ║\n║ F        ║\n║ G        ║\n╚══════════╝\n']], ['Combine two tables, exclude same records'], 5, 0], [(34610639, 3), [['You could easily expand it with additional columns.'], ['Output:']], [[" SELECT 'T1' AS tab_name, T1.col_name, T1.col1, NULL AS col2\nFROM  T1\nLEFT JOIN  T2\n  ON T1.col_name=  T2.col_name\nWHERE T2.col_name IS NULL\nUNION\nSELECT 'T2' AS tab_name, T2.col_name, NULL, T2.col2\nFROM  T2\nLEFT JOIN  T1\n  ON T1.col_name=  T2.col_name\nWHERE T1.col_name IS NULL;\n"]], ['Combine two tables, exclude same records'], 5, 1], [(34610639, 4), [['Output:'], ['-10000']], [[' ╔══════════╦══════════╦══════╦═════════════════════╗\n║ tab_name ║ col_name ║ col1 ║        col2         ║\n╠══════════╬══════════╬══════╬═════════════════════╣\n║ T1       ║ C        ║    3 ║                     ║\n║ T1       ║ D        ║    4 ║                     ║\n║ T2       ║ E        ║      ║ 2016-01-03 00:00:00 ║\n║ T2       ║ F        ║      ║ 2016-01-02 00:00:00 ║\n║ T2       ║ G        ║      ║ 2016-01-01 00:00:00 ║\n╚══════════╩══════════╩══════╩═════════════════════╝\n']], ['Combine two tables, exclude same records'], 5, 0], [(34612343, 0), [['Failed Example'], ['This example shows a method that does work.  Here the SQL statement is built as a string, which is then executed.']], [[" /* Anti-pattern.\n * Does not work.\n */\nDECLARE @Server    SYSNAME = 'Server001';\n\nSELECT\n    *\nFROM\n    @Server.Database1.dbo.Table1\n;\n"]], ['SQL Server Linked Server Join'], 2, 0], [(34612343, 1), [['This example shows a method that does work.  Here the SQL statement is built as a string, which is then executed.'], ['As ever; please be careful when generating and executing dynamic SQL statements.  You do not want to open yourself up to  SQL injection  attacks.  Look into  OPENROWSET  or check the passed server name against the code kindly supplied by @Devart above (SELECT name FROM sys.servers WHERE server_id > 0) before executing.']], [[" /* Dynamic SQL statement.\n * Will work.\n */\nDECLARE @Server    SYSNAME = 'Server001';\nDECLARE @Statement    NVARCHAR(255);\n\nSET @Statement = 'SELECT * FROM ' + QUOTENAME(@Server) + '.Database1.dbo.Table1;';\n\nEXECUTE sp_ExecuteSQL @Statement;\n"]], ['SQL Server Linked Server Join'], 2, 1], [(34643471, 0), [['This query:'], ['Produces the desired result:']], [[' select  data.* \n        ,p.*\nfrom    data\ninner join p ON \n        (bitand(data.bits,2)=p.bits OR bitand(data.bits,66)=p.bits) OR\n        (bitand(data.bits,16)=p.bits) \norder by tt.bits, p.bits\n']], ['Using BITAND in JOIN clause'], 2, 1], [(34643471, 1), [['Produces the desired result:'], ['-10000']], [[' BITS    ORGANS                  BUCKET\n2       LUNG [2]                LUNG [2]\n18      LUNG [2]; KIDNEY [16]   LUNG [2]\n18      LUNG [2]; KIDNEY [16]   KIDNEY [16]\n64      HEART [64]              HEART [64]\n66      LUNG [2]; HEART [64]    LUNG [2]\n']], ['Using BITAND in JOIN clause'], 2, 0], [(34660036, 0), [['It seems you are trying to perform variable substitution on a SQL table name.'], ['If your different databases are hosted on the same MySQL server, you can write queries that refer to more than one of them at a time. Simply give the database name as well as the table name.  For example, if you have databases  db1  and  db2  you can do this.']], [['   FROM dbName.table_guest_[??note: need to insert e.ID??] a \n']], ['MySQL subquery from another database where table name depends on main query'], 2, 0], [(34687839, 0), [['You could first select the time of the first record with the special condition, in a sub-select (I put it in a  with  clause). This would return exactly one record per Folder. And then select all records for the same folder that have a time stamp that is not less than that one:'], ['Also note that your way of calculating "yesterday at 18:00" can be done a lot more efficient, as I have included in the query above:']], [[' WITH StartRec AS ( \n    SELECT  FolderNo, MIN(SetDatetime) SetDatetime\n    FROM    ST3ROTE_Message\n    WHERE   FolderNo = @DropSelect\n        AND MessageNumber = 27 -- your starting condition\n        AND SetDatetime BETWEEN \n              DATEADD(hour, 18, DATEDIFF(day, 1, GETDATE())) \n              AND CURRENT_TIMESTAMP\n    GROUP BY FolderNo)\nSELECT     M.ProductionID, M.FolderNo, M.SetDatetime, \n           M.MessageNumber, M.MessageText, M.MessageLocation, \n           MD.GrossCopies, MD.NetCopies, MD.Speed \nFROM       ST3ROTE_Message AS M\nINNER JOIN StartRec\n        ON StartRec.FolderNo = M.FolderNo \n       AND StartRec.SetDatetime <= M.SetDatetime\nLEFT JOIN  ST3ROTE_MessageData AS MD\n        ON M.MessageID = MD.MessageID \nWHERE      M.FolderNo = @DropSelect\n']], ['SQL Select command to ignore until a condition is met'], 4, 1], [(34687839, 1), [['Also note that your way of calculating "yesterday at 18:00" can be done a lot more efficient, as I have included in the query above:'], ["Since you said in comments that  SetDateTime  reflects the timestamp of an event that happened, and can never be a time in the future, you don't really need a  BETWEEN  condition for. You could replace:"]], [[' DATEADD(hour, 18, DATEDIFF(day, 1, GETDATE())) \n']], ['SQL Select command to ignore until a condition is met'], 4, 0], [(34687839, 2), [["Since you said in comments that  SetDateTime  reflects the timestamp of an event that happened, and can never be a time in the future, you don't really need a  BETWEEN  condition for. You could replace:"], ['By:']], [['         SetDatetime BETWEEN \n          DATEADD(hour, 18, DATEDIFF(day, 1, GETDATE())) \n          AND CURRENT_TIMESTAMP\n']], ['SQL Select command to ignore until a condition is met'], 4, 0], [(34687839, 3), [['By:'], ['-10000']], [['         SetDatetime >= DATEADD(hour, 18, DATEDIFF(day, 1, GETDATE()))\n']], ['SQL Select command to ignore until a condition is met'], 4, 0], [(34696374, 0), [['The following two examples use the  DefaultDir  property in your provider string and should get your statement to work:'], ['Or']], [[' SELECT * FROM OPENROWSET(\'MSDASQL\',\'Driver={Microsoft Access Text Driver (*.txt, *.csv)}; Extended Properties="text; HDR=YES; FMT=Delimited"; DefaultDir=E:\\folder\\sub folder;\',\'SELECT * FROM [my file#txt]\');\n']], ['openrowset - How to select from a filename with white spaces?'], 2, 1], [(34696374, 1), [['Or'], ['-10000']], [[' SELECT * FROM OPENROWSET(\'MSDASQL\',\'Driver={Microsoft Access Text Driver (*.txt, *.csv)}; Extended Properties="text; HDR=YES; FMT=Delimited"; DefaultDir=E:\\folder\\sub folder;\',\'SELECT * FROM "my file.txt"\');\n']], ['openrowset - How to select from a filename with white spaces?'], 2, 1], [(34712380, 0), [['You can use a bunch of nested  iif()  statements.  An alternative is to use  instr() :'], ['Note:  this works fine for single character codes.  For longer codes, you should use delimiters:']], [[' select *\nfrom TableA\nwhere [A_Design] In ("A", "D", "C" , "B")\norder by instr("ADCB", A_Design);\n']], ['In SQL(Ms-Access) how to Order By customized order? (Solved)'], 2, 1], [(34712380, 1), [['Note:  this works fine for single character codes.  For longer codes, you should use delimiters:'], ['-10000']], [[' select *\nfrom TableA\nwhere [A_Design] In ("A", "D", "C" , "B")\norder by instr(",A,D,C,B,", "," & A_Design & ",");\n']], ['In SQL(Ms-Access) how to Order By customized order? (Solved)'], 2, 1], [(34722021, 0), [['One way is recursive common table expression:'], ['Query:']], [[' CREATE TABLE test(id INT, "name" VARCHAR(100), expression VARCHAR(100));\n\nINSERT INTO test(id,  "name", expression)\nSELECT 1,  \'width\', NULL                      \nUNION ALL SELECT 2, \'length\', NULL                      \nUNION ALL SELECT 3, \'area\'  ,  \'[1] * [2]\' \nUNION ALL SELECT 4, \'height\', NULL\nUNION ALL SELECT 5, \'volume\', \'[3] * [4]\'       \nUNION ALL SELECT 6, \'volumne_alt\', \'[2]^3\';\n']], ['Replace multiple IDs within text expression'], 5, 0], [(34722021, 2), [['Output:'], ['-10000']], [[' ╔═════╦══════════════╦════════════════════╗\n║ id  ║    name      ║     expression     ║\n╠═════╬══════════════╬════════════════════╣\n║  3  ║ area         ║ [width] * [length] ║\n║  5  ║ volume       ║ [area] * [height]  ║\n║  6  ║ volumne_alt  ║ [length]^3         ║\n╚═════╩══════════════╩════════════════════╝\n']], ['Replace multiple IDs within text expression'], 5, 0], [(34722021, 3), [['-10000'], ['Output:']], [[" WITH cte AS\n(...\n)\nUPDATE test AS t\nSET expression = c.expression\nFROM cte AS c\nWHERE t.id = c.id AND c.expression !~ '(.*)\\[(\\d+)\\](.*)';\n"]], ['Replace multiple IDs within text expression'], 5, 0], [(34722021, 4), [['Output:'], ['-10000']], [[' ╔═════╦══════════════╦════════════════════╗\n║ id  ║    name      ║     expression     ║\n╠═════╬══════════════╬════════════════════╣\n║  1  ║ width        ║ (null)             ║\n║  2  ║ length       ║ (null)             ║\n║  3  ║ area         ║ [width] * [length] ║\n║  4  ║ height       ║ (null)             ║\n║  5  ║ volume       ║ [area] * [height]  ║\n║  6  ║ volumne_alt  ║ [length]^3         ║\n╚═════╩══════════════╩════════════════════╝\n']], ['Replace multiple IDs within text expression'], 5, 0], [(34766139, 0), [['Yes it is, for instance  HASHBYTES :'], ['Output:']], [[" DECLARE @TABLE TABLE(A nvarchar(100),B nvarchar(100));\nINSERT INTO @TABLE VALUES (N'A²', N'A2')\n\nSELECT *\nFROM @TABLE \nWHERE HASHBYTES('SHA2_256',A) <> HASHBYTES('SHA2_256',B);\n"]], ['Compare two nvarchar columns with Unicode text in SQL server 2012'], 2, 1], [(34766139, 1), [['Output:'], ['Anyway the collation solution is the cleanest one.']], [[' ╔════╦════╗\n║ A  ║ B  ║\n╠════╬════╣\n║ A² ║ A2 ║\n╚════╩════╝\n']], ['Compare two nvarchar columns with Unicode text in SQL server 2012'], 2, 0], [(34773830, 0), [["This seems the simplest method if you're prepared to use a Stored Procedure and temporary table:"], ['The following "trick" is slightly more complex but should do it without using stored procedures, temporary tables or variables:']], [[' CREATE PROCEDURE sp_sanitize_mrbs()\nBEGIN\n    DROP TEMPORARY TABLE IF EXISTS mrbs_to_sanitize;\n    CREATE TEMPORARY TABLE mrbs_to_sanitize (\n      id int auto_increment primary key,\n      room2_id int,\n      room3_id int);\n\n    -- "I want to go through the table, and when room 2 & 3 both have\n    -- entries at the same time and with the same name I want to..."\n    INSERT INTO mrbs_to_sanitize (room2_id, room3_id)\n    SELECT m1.id, m2.id\n    FROM mrbs_entry m1\n    CROSS JOIN mrbs_entry m2\n    WHERE m1.start_time = m2.start_time\n      AND m1.name = m2.name\n      AND m1.room_id = 2\n      AND m2.room_id = 3;\n\n    -- ...change room 2\'s room_id to 1\n    UPDATE mrbs_entry me\n    JOIN mrbs_to_sanitize mts\n    ON me.id = mts.room2_id\n    SET me.room_id = 1;\n\n    -- "...and delete the entry for room 3."\n    DELETE me\n    FROM mrbs_entry me\n    JOIN mrbs_to_sanitize mts\n    ON me.id = mts.room3_id;\nEND//\n\n-- ...\n-- The Stored Procedure can now be called any time you like:\nCALL sp_sanitize_mrbs();\n']], ['UPDATE and DELETE a set of rows when the operations affect the set'], 2, 1], [(34773830, 1), [['The following "trick" is slightly more complex but should do it without using stored procedures, temporary tables or variables:'], ['Explanation of Method 2']], [[' -- "I want to go through the table, and when room 2 & 3 both have\n-- entries at the same time and with the same name I want to..."\n\n-- "...change room 2\'s room_id to 1"\nUPDATE mrbs_entry m1\nCROSS JOIN mrbs_entry m2\n-- temporarily mark this row as having been updated\nSET m1.room_id = 1, m1.name = CONCAT(m1.name, \' UPDATED\')\nWHERE m1.start_time = m2.start_time\n  AND m1.name = m2.name\n  AND m1.room_id = 2\n  AND m2.room_id = 3;\n\n-- "...and delete the entry for room 3."\nDELETE m2 FROM mrbs_entry m1\nCROSS JOIN mrbs_entry m2\nWHERE m1.start_time = m2.start_time\n  AND m1.name = CONCAT(m2.name, \' UPDATED\')\n  AND m1.room_id = 1\n  AND m2.room_id = 3;\n\n-- now remove the temporary marker to restore previous value\nUPDATE mrbs_entry\nSET name = LEFT(name, CHAR_LENGTH(name) - CHAR_LENGTH(\' UPDATED\'))\nWHERE name LIKE \'% UPDATED\';\n']], ['UPDATE and DELETE a set of rows when the operations affect the set'], 2, 1], [(34786699, 1), [['Or using  XmlTable'], ['Using UpdateXml, assuming the record I am updating has the above XML in a column:']], [[' SELECT xt.Node1, xt.Node2\nFROM XmlTable(\'/test/block\'\n         PASSING XmlType(\'<test>\n<block><node1>value1a</node1><node2>value2a</node2></block>\n<block><node1>value1b</node1><node2>value2b</node2></block>\n<block><node1>value1c</node1><node2>value2c</node2></block>\n</test>\')\n        COLUMNS\n        "Node1"     VARCHAR2(20)   PATH \'node1\',\n        "Node2"     VARCHAR2(20)   PATH \'node2\') AS xt;\n']], ['Select and Update Oracle BLOB column with XMLQUERY'], 5, 0], [(34786699, 4), [['Here is a working stand alone example showing the various methods mentioned above:'], ['-10000']], [[' DECLARE varchar_data    VARCHAR2(500);\n        blob_data       BLOB;\n        xml_data        XMLType;\n        node1Val        VARCHAR(20);\n        node2Val        VARCHAR(20);\n\nBEGIN\n    select \'<test>\n<group><node1>value1a</node1><node2>value2a</node2></group>\n<group><node1>value1b</node1><node2>value2b</node2></group>\n<group><node1>value1c</node1><node2>value2c</node2></group>\n<group><node1>value1d</node1><node2>value2d</node2></group>\n</test>\' into varchar_data from dual;\n\n    select UTL_RAW.CAST_TO_RAW(varchar_data) into blob_data from dual;\n\n    select XmlType(blob_data, 1) into xml_data from dual;\n    dbms_output.put_line(xml_data.getClobVal());\n\n    select xt.Node1, xt.Node2\n    into node1Val, node2Val\n    from XmlTable(\'/test/group\' \n        passing XmlType(blob_data, 1)\n        columns Node1     VARCHAR2(20)    path \'node1\',\n                Node2     VARCHAR2(20)    path \'node2\'\n        ) xt\n    where xt.Node1 = \'value1c\';\n    dbms_output.put_line(\'node1Val = \'\'\' || node1Val || \'\'\', node2Val = \'\'\' || node2Val || \'\'\';\'); \n\n    -- Using UpdateXml to update the XML, that will return an XmlType \n    -- so we call GetClobVal() to let CAST_TO_RAW convert to BLOB.\n    select UTL_RAW.CAST_TO_RAW(\n        UpdateXml(\n            XmlType(blob_data, 1), \n            \'/test/group/node2[../node1/text() = "value1c"]/text()\', \n            \'zzzz\').GetClobVal()\n        ) into blob_data\n    from dual; \n\n    select XmlType(blob_data, 1) into xml_data from dual;\n    dbms_output.put_line(xml_data.getClobVal());\n\n    select xt.Node1, xt.Node2\n    into node1Val, node2Val\n    from XmlTable(\'/test/group\' \n        passing XmlType(blob_data, 1)\n        columns Node1     VARCHAR2(20)    path \'node1\',\n                Node2     VARCHAR2(20)    path \'node2\'\n        ) xt\n    where xt.Node1 = \'value1c\';\n    dbms_output.put_line(\'node1Val = \'\'\' || node1Val || \'\'\', node2Val = \'\'\' || node2Val || \'\'\';\'); \n\nEND;\n']], ['Select and Update Oracle BLOB column with XMLQUERY'], 5, 1], [(34845881, 0), [["so you need to  ESCAPE  the  square bracket's  "], ['or']], [[" select 1 \nwhere '[Error] Something failed in (Freds) session'\nlike '%\\[Error] Something failed in (%) session%' escape '\\'\n"]], ['How do I use a wild card in the middle of an sql server like query'], 2, 1], [(34845881, 1), [['or'], ['-10000']], [[" select 1 \nwhere '[Error] Something failed in (Freds) session'\nlike '%[[]Error] Something failed in (%) session%'\n"]], ['How do I use a wild card in the middle of an sql server like query'], 2, 1], [(34875353, 0), [['This can be a bit tricky using a single statement, because SQL Server likes to optimize things.  So the obvious:'], ["Also doesn't work.  One method is to enumerate things and use a  join  or correlated subquery:"]], [[' update t \n    set t.actiecode = (select top 1 actiecode \n                       from data_mgl_campagnemails_codes\n                       order by newid()\n                      )\n    from data_mgl_campagnemails_transfer t;\n']], ['Update statement with lookup table'], 3, 0], [(34875353, 1), [["Also doesn't work.  One method is to enumerate things and use a  join  or correlated subquery:"], ['Another way is to "trick" SQL Server into running the correlated subquery more than once.  I think something like this:']], [[' with t as (\n      select t.*, row_number() over (order by newid()) as seqnum\n      from data_mgl_campagnemails_transfer t\n     ),\n     a as (\n      select a.*, row_number() over (order by newid()) as seqnum\n      from data_mgl_campagnemails_codes a\n     )\nupdate t\n    set t.actiecode = (select top 1 actiecode from a)\n    from t join\n         a\n         on t.seqnum = a.seqnum;\n']], ['Update statement with lookup table'], 3, 1], [(34875353, 2), [['Another way is to "trick" SQL Server into running the correlated subquery more than once.  I think something like this:'], ['-10000']], [[' update t \n    set t.actiecode = (select top 1 actiecode \n                       from data_mgl_campagnemails_codes\n                       where t.CustomerId is not null -- references the outer table but really does nothing\n                       order by newid()\n                      )\n    from data_mgl_campagnemails_transfer t;\n']], ['Update statement with lookup table'], 3, 1], [(34876711, 0), [['Thanks for the tips @symcbean and @gordon-linoff, my final query looks like this:  '], ['It transforms this: ']], [[" SELECT *\nFROM versions WHERE CONCAT(\n        LPAD(SUBSTRING_INDEX(SUBSTRING_INDEX(version_number, '.', 1), '.', -1), 10, '0'),\n        LPAD(SUBSTRING_INDEX(SUBSTRING_INDEX(version_number, '.', 2), '.', -1), 10, '0'),\n        LPAD(SUBSTRING_INDEX(SUBSTRING_INDEX(version_number, '.', 3), '.', -1), 10, '0') \n       ) > CONCAT(LPAD(2,10,'0'), LPAD(1,10,'0'), LPAD(27,10,'0'));\n"]], ['MySQL query - compare version numbers'], 3, 1], [(34876711, 1), [['It transforms this: '], ['to this:']], [[' 3.11.9 > 2.1.27\n']], ['MySQL query - compare version numbers'], 3, 0], [(34876711, 2), [['to this:'], ['-10000']], [[" '000000000300000000110000000009' > '000000000200000000010000000027'\n"]], ['MySQL query - compare version numbers'], 3, 0], [(34908511, 0), [['I would do this with a simple  update :'], ['This restarts the ordering for each parent.  If you have a particular parent in mind, use a  WHERE  clause:']], [[' with toupdate as (\n      select m.*, row_number() over (partition by parent order by title) as seqnum\n      from menu\n     )\nupdate toupdate\n    set m_order = toupdate.seqnum;\n']], ['Update an ordinal column based on the alphabetic ordering of another column'], 2, 1], [(34908511, 1), [['This restarts the ordering for each parent.  If you have a particular parent in mind, use a  WHERE  clause:'], ['-10000']], [[' where parentid = @parentid and m_order <> toupdate.seqnum\n']], ['Update an ordinal column based on the alphabetic ordering of another column'], 2, 0], [(34954765, 0), [['Just for the sake of completeness. You can also use  INTERSECT :'], ['This will return only one pair of matching rows, i.e.:']], [[' Select FirstName, LastName\nFrom People\n\nINTERSECT\n\nSelect LastName, FirstName\nFrom People\n']], ['Find rows where the value in column 1 exists in colunm2'], 3, 1], [(34954765, 1), [['This will return only one pair of matching rows, i.e.:'], ['even if original data has  Doc Jones  or  Jones Doc  more than once:']], [[' +-----------+----------+\n| FirstName | LastName |\n+-----------+----------+\n| Doc       | Jones    |\n| Jones     | Doc      |\n+-----------+----------+\n']], ['Find rows where the value in column 1 exists in colunm2'], 3, 0], [(34954765, 2), [['even if original data has  Doc Jones  or  Jones Doc  more than once:'], ['-10000']], [[" DECLARE @People TABLE ([FirstName] varchar(50), [LastName] varchar(50));\n\nINSERT INTO @People ([FirstName], [LastName]) VALUES\n('Doc', 'Jones'),\n('Doc', 'Jones'),\n('Jones', 'Doc'),\n('Doc', 'Holiday'),\n('John', 'Doe');\n"]], ['Find rows where the value in column 1 exists in colunm2'], 3, 0], [(35011175, 0), [['You are maybe looking for the  group_concat  function:'], ['Output of the SQL is:']], [[" SELECT     MASTER.animal, MASTER.species, \n           group_concat(BI.properties separator ', ') as Properties\nFROM       MASTER\nLEFT JOIN  BOARD_INFO BI\n       ON (MASTER.animal = BI.animal)\nGROUP BY   MASTER.animal, MASTER.species\n"]], ['MySQL Left Join with fundamentally differently structured tables'], 2, 1], [(35011175, 1), [['Output of the SQL is:'], ['Your PHP can stay like it is.']], [[' +--------+---------+-------------------------------+\n| animal | species | properties                    |\n+--------+---------+-------------------------------+\n| dog    | mammal  | has ears, has a tail, has fir |\n| cat    | mammal  | meows, hunts birds            |\n| turtle | reptile | (null)                        | \n+--------+---------+-------------------------------+\n']], ['MySQL Left Join with fundamentally differently structured tables'], 2, 0], [(35036298, 0), [["If you subtract one from the other each contiguous block of dates gets the same answer, which I've called 'slot_no':"], ['With this data every row gets either -1, 0 or 1. (You can add two to those to make them more friendly if you want, but that only really works if the gaps in the data are single days). You can then group by that slot number:']], [[' select attndate,\n  attndate - min(attndate) over ()\n    - row_number() over (order by attndate) as slot_no\nfrom your_table;\n']], ['Need Oracle sql query for grouping the date'], 3, 0], [(35036298, 1), [['With this data every row gets either -1, 0 or 1. (You can add two to those to make them more friendly if you want, but that only really works if the gaps in the data are single days). You can then group by that slot number:'], ['With some generated data:']], [[' with cte as (\n  select attndate,\n    attndate - min(attndate) over ()\n      - row_number() over (order by attndate) as slot_no\n  from your_table\n)\nselect dense_rank() over (order by slot_no) as slot_no,\n  min(attndate) as attnfrom, max(attndate) as attntill\nfrom cte\ngroup by slot_no\norder by slot_no;\n']], ['Need Oracle sql query for grouping the date'], 3, 1], [(35041250, 0), [['You can use the following sql script to insert the values required into your table:'], ['Note:  If you want to insert values:']], [[" INSERT INTO target (id, letter, `number`)\nSELECT rn, col, (rn - 1) % 4 + 1 AS seq\nFROM (\nSELECT col, @rn := @rn + 1 AS rn \nFROM (\n   SELECT 'a' AS col UNION ALL SELECT 'b' UNION ALL\n   SELECT 'c' UNION ALL SELECT 'd') AS t\nCROSS JOIN (\n   SELECT 1 AS x UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL \n   SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL\n   SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 ) AS t1\nCROSS JOIN (\n   SELECT 1 AS x UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL \n   SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL\n   SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1 ) AS t2\nCROSS JOIN (SELECT @rn := 0) AS var  ) AS s\nWHERE rn <= 456\n"]], ['Auto insert rows with repeated data, following two patterns'], 3, 1], [(35041250, 1), [['Note:  If you want to insert values:'], ['instead of values:']], [[" id, letter, number\n1   'a'     1\n2   'b'     1\n3   'c'     1\n4   'd'     1\n5   'a'     2\n6   'b'     2\n7   'c'     2\n8   'd'     2\n... etc\n"]], ['Auto insert rows with repeated data, following two patterns'], 3, 0], [(35041250, 2), [['instead of values:'], ['then simply replace  (rn - 1) % 4 + 1 AS seq  with  (rn - 1) DIV 4 + 1 AS seq .']], [[" id, letter, number\n1   'a'     1\n2   'b'     2\n3   'c'     3\n4   'd'     4\n5   'a'     1\n6   'b'     2\n7   'c'     3\n8   'd'     4\n... etc\n"]], ['Auto insert rows with repeated data, following two patterns'], 3, 0], [(35093560, 0), [['Try this:'], ['You can alternatively use an  INNER JOIN :']], [[' SELECT "AuthorId", COUNT(*)\nFROM BookAuthorMapping\nWHERE "BookId" IN (SELECT "BookId" FROM BookAuthorMapping WHERE "AuthorId" = 1)\nGROUP BY "AuthorId"\n']], ['Find all co authors - Faceting/Grouping for many to many mapping table'], 2, 1], [(35093560, 1), [['You can alternatively use an  INNER JOIN :'], ['Demo here']], [[' SELECT t1."AuthorId", COUNT(*)\nFROM BookAuthorMapping AS t1\nINNER JOIN BookAuthorMapping AS t2 ON t1."BookId" = t2."BookId" AND t2."AuthorId" = 1\nGROUP BY t1."AuthorId"\n']], ['Find all co authors - Faceting/Grouping for many to many mapping table'], 2, 1], [(35104380, 0), [['try this query:'], ['in case if you want them joined that is how it goes']], [["     (SELECT * from messages where id_sender='$lgn_id' order by date_msg desc limit 1)\n    UNION ALL\n    (SELECT * from messages where id_receiver='$lgn_id' order by date_msg desc limit 1)\n"]], ['Need to get the messages between the user identified by LoginId and others'], 2, 1], [(35104380, 1), [['in case if you want them joined that is how it goes'], ['-10000']], [["     SELECT Msg1.id_sender, Msg1.id_receiver Msg1.date_msg, Msg2.id_sender, Msg2.id_receiver, Msg2.date_msg \n    FROM messages Msg1 join messages Msg2 \n    WHERE Msg1.id_receiver=Msg2.id_sender and Msg1.id_receiver='$lgn_id' or Msg2.id_sender='$lgn_id' order by date_msg desc limit 1\n"]], ['Need to get the messages between the user identified by LoginId and others'], 2, 1], [(35150739, 0), [['You can use arguments in the query alias:'], ['You can also use  join  instead of a subquery, example:']], [[' with selected_ids(id) as (\n    values (1), (3), (5)\n)\nselect *\nfrom someTable\nwhere id = any (select id from selected_ids)\n']], ['Creating tables on-the-fly'], 2, 1], [(35150739, 1), [['You can also use  join  instead of a subquery, example:'], ['-10000']], [[" create table some_table (id int, str text);\ninsert into some_table values\n(1, 'alfa'),\n(2, 'beta'),\n(3, 'gamma');\n\nwith selected_ids(id) as (\n    values (1), (2)\n)\nselect *\nfrom some_table\njoin selected_ids\nusing(id);\n\n id | str  \n----+------\n  1 | alfa\n  2 | beta\n(2 rows)\n"]], ['Creating tables on-the-fly'], 2, 1], [(35183616, 0), [["Why don't you want to use  LAST_DAY()  function:"], ['Output:']], [[' SELECT SYSDATE, trunc(LAST_DAY(SYSDATE)) last, \n   LAST_DAY(SYSDATE) - SYSDATE days_left FROM DUAL;\n']], ['SQL Query with date that does not exist'], 2, 1], [(35183616, 1), [['Output:'], ['-10000']], [[' SYSDATE           LAST               DAYS_LEFT\n----------------- ----------------- ----------\n03.02.16 18:38:26 29.02.16 00:00:00         26\n\n1 row selected.\n']], ['SQL Query with date that does not exist'], 2, 0], [(35222092, 0), [['Either  JOIN  estate_comforts twice, one time for comfort_id 1, and another time for comfort_id 2:'], ['Alternatively, do a  GROUP BY  on estate_comforts to find estate_id with at least two different comfort_id values. Join with that result:']], [[' SELECT DISTINCT "estates".*\nFROM   "estates"\n   INNER JOIN "estate_comforts" ec1\n          ON "estates"."id" = ec1."estate_id"\n   INNER JOIN "estate_comforts" ec2\n          ON "estates"."id" = ec2."estate_id"\nWHERE ec1."comfort_id" = \'1\'\n  AND ec2."comfort_id" = \'2\'\n']], ['Sql query to search for multiple match in junction table'], 2, 1], [(35222092, 1), [['Alternatively, do a  GROUP BY  on estate_comforts to find estate_id with at least two different comfort_id values. Join with that result:'], ['-10000']], [[' select e.*\nfrom "estates" e\n  join (select "estate_id"\n        from "estate_comforts"\n        WHERE  "comfort_id" IN ( \'1\', \'2\' ) \n        group by "estate_id"\n        having count(distinct "comfort_id") >= 2) ec ON e."id" = ec."estate_id"\n']], ['Sql query to search for multiple match in junction table'], 2, 1], [(35232556, 0), [['Example data:'], ['The query:  ']], [[" create table msg (\n    id int primary key,\n    from_person text,\n    to_person text,\n    ts timestamp without time zone\n);\n\ninsert into msg values\n(1, 'nancy',   'charlie', '2016-02-01 01:00:00'),\n(2, 'bob',     'charlie', '2016-02-01 01:00:00'),\n(3, 'charlie', 'nancy',   '2016-02-01 01:00:01'),\n(4, 'mary',    'charlie', '2016-02-01 01:02:00');\n"]], ['In SQL how to select previous rows based on the current row values?'], 3, 0], [(35238887, 0), [["I created this structure and I think that's similar to yours:"], ['First query :']], [[" create class Post\n\ncreate property Post.datePosted date\n\ninsert into Post (datePosted) values ('2016-01-25')\ninsert into Post (datePosted) values ('2016-01-28')\ninsert into Post (datePosted) values ('2016-01-25')\ninsert into Post (datePosted) values ('2016-02-04')\n"]], ['OrientDB - Group by date query'], 7, 0], [(35238887, 1), [['First query :'], ['Output :']], [[" select day, count(*) as posts from (select datePosted.format('yyyy-MM-dd') as day from Post) \ngroup by day\n"]], ['OrientDB - Group by date query'], 7, 1], [(35238887, 2), [['Output :'], ['Second query :']], [[' ----+------+----------+-----\n#   |@CLASS|day       |posts\n----+------+----------+-----\n0   |null  |2016-01-25|2\n1   |null  |2016-01-28|1\n2   |null  |2016-02-04|1\n----+------+----------+-----\n']], ['OrientDB - Group by date query'], 7, 0], [(35238887, 3), [['Second query :'], ['Output :']], [[" select datePosted.format('yyyy-MM-dd'), count(*) as posts from Post group by datePosted\n"]], ['OrientDB - Group by date query'], 7, 1], [(35238887, 4), [['Output :'], ['Java Code :']], [[' ----+------+----------+-----\n#   |@CLASS|datePosted|posts\n----+------+----------+-----\n0   |null  |2016-01-25|2\n1   |null  |2016-01-28|1\n2   |null  |2016-02-04|1\n----+------+----------+-----\n']], ['OrientDB - Group by date query'], 7, 0], [(35238887, 5), [['Java Code :'], ['Output :']], [[' private static String remote = "remote:localhost/";\n    public static void main(String[] args) {\n        String dbName = "DBname";\n        String path = remote + dbName;\n        OServerAdmin serverAdmin;\n        try {\n            serverAdmin = new OServerAdmin(path).connect("root", "root");\n            if (serverAdmin.existsDatabase()) { // if DB already exists\n                System.out.println("Database \'" + dbName + "\' already exists");\n                ODatabaseDocumentTx db = new ODatabaseDocumentTx(path);\n                db.open("root", "root");\n                Iterable<ODocument> results = db\n                    .command(new OSQLSynchQuery<ODocument>(\n                            "select day, count(*) as posts from (select datePosted.format(\'yyyy-MM-dd\') as day from Post) group by day"))\n                    .execute();\n                for (ODocument result : results) {\n                    System.out.println("Day: " + result.field("day") + "   Posts: " + result.field("posts"));\n                }\n                db.close();\n            }\n            else {\n                serverAdmin.createDatabase(dbName, "document", "plocal");\n                System.out.println("Database " + dbName + " created");\n            }\n            serverAdmin.close();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n']], ['OrientDB - Group by date query'], 7, 0], [(35238887, 6), [['Output :'], ['-10000']], [[' Day: 2016-01-25   Posts: 2\nDay: 2016-01-28   Posts: 1\nDay: 2016-02-04   Posts: 1\n']], ['OrientDB - Group by date query'], 7, 0], [(35260298, 0), [['You can define an aggregate for the null check (assuming postgresql):'], ['And use it in a query:']], [[" from django.db.models import Aggregate\nclass AnyNotNull(Aggregate):\n    function = 'ANY'\n    template = 'true = %(function)s(array_agg(%(expressions)s is not null))'\n"]], ['How can I annotate a queryset with information from another model, or paginate a queryset built with raw in the Django Rest Framework?'], 2, 0], [(35260298, 1), [['And use it in a query:'], ['This will annotate the tense objects with true in selected if the user has access.']], [[" Tense.objects.filter(\n    Q(verbuser_tenses__isnull = True) |\n    Q(verbuser_tenses__verbuser_id = user_id)\n    ).annotate(selected = AnyNotNull('verbuser_tenses__verbuser_id')\n    ).order_by('id')\n"]], ['How can I annotate a queryset with information from another model, or paginate a queryset built with raw in the Django Rest Framework?'], 2, 0], [(35263742, 0), [['For each product, you can use  NOT EXISTS  to make sure no image with lower id exists:'], ["Alternatively, have a sub-query that returns each pid's minimum id, join one more time with that sub-query:"]], [[' select p.id, p.product, pi.id, pi.pid, pi.image\nfrom products as p\n  join product_image as pi on p.id = pi.pid\nwhere not exists (select * from product_image as pi2\n                  where pi2.pid = pi.pid\n                    and pi2.id < pi.id)\n']], ['join table.A with table.B, table.B having multiple rows with respect to one id from table.A'], 2, 1], [(35263742, 1), [["Alternatively, have a sub-query that returns each pid's minimum id, join one more time with that sub-query:"], ['May execute faster on MySQL.']], [[' select p.id, p.product, pi.id, pi.pid, pi.image\nfrom products as p\n  join product_image as pi on p.id = pi.pid\n  join (select pid, min(id) as id from product_image group by pid) pi2\n      on pi.id = pi2.id and pi.pid = pi2.pid\n']], ['join table.A with table.B, table.B having multiple rows with respect to one id from table.A'], 2, 1], [(35268549, 0), [["For this example, let's assume this your destination table:"], ['You then need to use  IDENTITY_INSERT...ON  to ensure you can insert the data from your source table:']], [[' CREATE TABLE dbo.YourTable(YourTableId INT IDENTITY(1,1), SomeData INT)\n']], ['insert into a big table where the PK is not an identity'], 6, 0], [(35268549, 1), [['You then need to use  IDENTITY_INSERT...ON  to ensure you can insert the data from your source table:'], ['After you have migrated the data, you need to witch the  IDENTITY_INSERT  off again:']], [[' SET IDENTITY_INSERT dbo.YourTable ON\n\n--copy data from source table\nINSERT INTO dbo.YourTable\n(YourTableId, SomeData)\nSELECT 1,1\nUNION\nSELECT 2,2\n']], ['insert into a big table where the PK is not an identity'], 6, 0], [(35268549, 2), [['After you have migrated the data, you need to witch the  IDENTITY_INSERT  off again:'], ['Add the primary key:']], [[' SET IDENTITY_INSERT dbo.YourTable OFF\n']], ['insert into a big table where the PK is not an identity'], 6, 0], [(35268549, 3), [['Add the primary key:'], ['And then reseed your primary key with the  RESEED  value being equal to the current maximum PK value']], [[' ALTER TABLE dbo.[YourTable] ADD CONSTRAINT PK_YourTable_YourTableID PRIMARY KEY CLUSTERED (YourTableID) \n']], ['insert into a big table where the PK is not an identity'], 6, 0], [(35268549, 4), [['And then reseed your primary key with the  RESEED  value being equal to the current maximum PK value'], ['After running this command, this record will be inserted with a value of 3 for  YourTableId']], [[" DBCC CHECKIDENT ('[YourTable]', RESEED, 2)\n"]], ['insert into a big table where the PK is not an identity'], 6, 0], [(35268549, 5), [['After running this command, this record will be inserted with a value of 3 for  YourTableId'], ['-10000']], [[' INSERT INTO dbo.YourTable\nSELECT 3\n']], ['insert into a big table where the PK is not an identity'], 6, 0], [(35291850, 0), [['The way you are storing your data is really bad practice. However here is a solution for training purposes:'], ['Result:']], [[" DECLARE \n   @str1 varchar(30) = 'A1,B1,C1',\n   @str2 varchar(30) = 'A2,B2,C2',\n   @result varchar(60)\n\n;WITH split as\n(\n  SELECT t.c.value('.', 'VARCHAR(2000)') x\n  FROM (\n      SELECT x = CAST('<t>' + \n          REPLACE(@str1 + ',' + @str2, ',', '</t><t>') + '</t>' AS XML)\n  ) a\nCROSS APPLY x.nodes('/t') t(c)\n)\nSELECT\n  @result =\n    STUFF(( \n        SELECT ',' + x\n        FROM split\n        ORDER BY x\n        for xml path(''), type \n          ).value('.', 'varchar(max)'), 1, 1, '')\n\nSELECT @result\n"]], ['SQL concatenate strings'], 2, 1], [(35291850, 1), [['Result:'], ['-10000']], [[' A1,A2,B1,B2,C1,C2\n']], ['SQL concatenate strings'], 2, 0], [(35293084, 0), [['You can use  generate_series() :'], ['You can do the same thing with a lateral join:']], [[' select t.id, t.value\nfrom (select t.id, t.value, generate_series(1, t.value)\n      from t \n     ) t;\n']], ['Duplicate (repeat) rows in sql query result'], 2, 1], [(35293084, 1), [['You can do the same thing with a lateral join:'], ['-10000']], [[' select t.id, t.value\nfrom t, lateral\n     generate_series(1, t.value);\n']], ['Duplicate (repeat) rows in sql query result'], 2, 1], [(35295861, 0), [['You can try this:'], ['So for your view you can use:']], [[" DECLARE @date VARCHAR(50) = '102915'\n\nSELECT   CAST(  CAST( '20'+                  --prefix for the year 2000\n                      SUBSTRING( @date,5,2)+ --year\n                      SUBSTRING( @date,1,2)+ --month\n                      SUBSTRING( @date,3,2)  --day\n                 AS VARCHAR(10)) \n          AS DATE)\n"]], ['Converting nvarchar to DATE'], 3, 1], [(35295861, 2), [['To have the date in the format mm-dd-yyyy you need to use CONVERT you can see the different conversions  here :'], ['-10000']], [[" create view v1 as\n        Select convert(VARCHAR ,CAST( CAST( '20'+                  --prefix for the year 2000\n                              SUBSTRING( [ISSUE],5,2)+ --year\n                              SUBSTRING( [ISSUE],1,2)+ --month\n                              SUBSTRING( [ISSUE],3,2)  --day\n                         AS VARCHAR(10)) \n                   AS DATE), 110) as ISSUE\n              , \n            convert(VARCHAR ,CAST(  CAST( '20'+                  --prefix for the year 2000\n                              SUBSTRING( [EXPIRE],5,2)+ --year\n                              SUBSTRING( [EXPIRE],1,2)+ --month\n                              SUBSTRING( [EXPIRE],3,2)  --day\n                         AS VARCHAR(10)) \n                   AS DATE), 110)  as EXPIRE\n        from tablename\n"]], ['Converting nvarchar to DATE'], 3, 1], [(35321999, 0), [["2) create a baseline migration. EF will use this as a starting point so you won't get a bunch of code to create the objects that already exist. The ignore changes flag tells EF not to create the existing objects.  https://msdn.microsoft.com/en-us/data/dn579398.aspx?f=255&MSPPError=-2147217396#option1"], ['3) Now modify your schema as you normally would and create a migration:']], [[' create-migration InitialCodeFirst -IgnoreChanges\n']], ['Entity Framework DB Migration Script'], 3, 0], [(35321999, 1), [['3) Now modify your schema as you normally would and create a migration:'], ['4) Create a script for a different database (like PROD) by using -Script. This will not update your database it just creates a script, so I usually run it a second time without -Script:']], [[' add-migration SomeNewThing\n']], ['Entity Framework DB Migration Script'], 3, 0], [(35321999, 2), [['4) Create a script for a different database (like PROD) by using -Script. This will not update your database it just creates a script, so I usually run it a second time without -Script:'], ['5) DBA runs script and this will add a record to __MigrationHistory to identify it as being applied.']], [[' update-database -Script    // creates a script (in VS), but does not apply\nupdate-database            // updates the database your connect string points to\n']], ['Entity Framework DB Migration Script'], 3, 0], [(35330341, 0), [['Here is one way to do it in  SQL Server'], ['Result:']], [[" ;WITH cte\n     AS (SELECT Replace(col, '_', '.') + '.' AS col\n         FROM   (VALUES ('Abc_abc_1.2.3'),\n                        ('PQRST.abc_1'),\n                        ('XY.143_z')) tc (col))\nSELECT original_col = col,\n       column_1=COALESCE(LEFT(col, Charindex('.', col) - 1), ''),\n       column_2=COALESCE(Substring(col, P1.POS + 1, P2.POS - P1.POS - 1), ''),\n       column_3=COALESCE(Substring(col, P2.POS + 1, P3.POS - P2.POS - 1), ''),\n       column_4=COALESCE(Substring(col, P3.POS + 1, P4.POS - P3.POS - 1), ''),\n       column_4=COALESCE(Substring(col, P4.POS + 1, P5.POS - P4.POS - 1), '')\nFROM   cte\n       CROSS APPLY (VALUES (CASE\n                     WHEN Charindex('.', col) >= 1 THEN Charindex('.', col)\n                   END)) AS P1(POS)\n       CROSS APPLY (VALUES (CASE\n                     WHEN Charindex('.', col, P1.POS + 1) >= 1 THEN Charindex('.', col, P1.POS + 1)\n                   END)) AS P2(POS)\n       CROSS APPLY (VALUES (CASE\n                     WHEN Charindex('.', col, P2.POS + 1) >= 1 THEN Charindex('.', col, P2.POS + 1)\n                   END )) AS P3(POS)\n       CROSS APPLY (VALUES (CASE\n                     WHEN Charindex('.', col, P3.POS + 1) >= 1 THEN Charindex('.', col, P3.POS + 1)\n                   END)) AS P4(POS)\n       CROSS APPLY (VALUES (CASE\n                     WHEN Charindex('.', col, P4.POS + 1) >= 1 THEN Charindex('.', col, P4.POS + 1)\n                   END)) AS P5(POS) \n"]], ['How to split value using underscore (_) and period (.)?'], 2, 1], [(35330341, 1), [['Result:'], ['-10000']], [[' ╔════════════════╦══════════╦══════════╦══════════╦══════════╦══════════╗\n║  original_col  ║ column_1 ║ column_2 ║ column_3 ║ column_4 ║ column_4 ║\n╠════════════════╬══════════╬══════════╬══════════╬══════════╬══════════╣\n║ Abc.abc.1.2.3. ║ Abc      ║ abc      ║ 1        ║        2 ║        3 ║\n║ PQRST.abc.1.   ║ PQRST    ║ abc      ║ 1        ║          ║          ║\n║ XY.143.z.      ║ XY       ║ 143      ║ z        ║          ║          ║\n╚════════════════╩══════════╩══════════╩══════════╩══════════╩══════════╝\n']], ['How to split value using underscore (_) and period (.)?'], 2, 0], [(35354450, 0), [['You want to use a  subquery  to find the  orderid s that you want to delete in a child table:'], ["Then you're able to delete the corresponding orders:"]], [[" delete from orderdetail where orderid in (\n     select orderid from orders\n      where customerid = '12341'\n);\n"]], ['list of states with the total number of units that have been sold to that state'], 2, 0], [(35354450, 1), [["Then you're able to delete the corresponding orders:"], ['If  your tables are set up with a  cascading delete , you can just execute the 2nd delete statement (without first going to execute the first statement).']], [[" delete from orders\n where customerid = '12341';\n"]], ['list of states with the total number of units that have been sold to that state'], 2, 0], [(35361258, 0), [['You can do that using CTE like below( Only if you want to avoid a function )'], ['By creating a function it can be like']], [[' WITH cte (id)\nAS (\n    INSERT INTO another_table (sensorname,starttime)\n    SELECT sensorname\n          ,starttime\n    FROM sensors WHERE id = id \n    returning id;\n    )\nDELETE\nFROM\nsensors\nWHERE id IN (SELECT *FROM cte);\n']], ['Calling Postgres Stored Procedure with arguments and insert values from a given select'], 3, 1], [(35361258, 1), [['By creating a function it can be like'], ['Usage:']], [[' create or replace function fn(id int) returns void as\n$$\ninsert into another_table(sensorname,starttime)  \nSELECT sensorname, starttime from sensors where id =id;\ndelete from sensors where id =id;\n$$\nlanguage sql\n']], ['Calling Postgres Stored Procedure with arguments and insert values from a given select'], 3, 1], [(35361258, 2), [['Usage:'], ['-10000']], [[' select fn(12)\n']], ['Calling Postgres Stored Procedure with arguments and insert values from a given select'], 3, 0], [(35391959, 0), [['Activated'], ['or']], [[' sum(CAST(activated as INT)) as TotalActivated\n']], ['Joined query, with group by and sub count based on a column'], 4, 1], [(35391959, 1), [['or'], ['Not activated']], [[' (select sum(CAST(activated as INT)) FROM products WHERE product_type_id = p.product_type_id) as TotalActivated\n']], ['Joined query, with group by and sub count based on a column'], 4, 1], [(35391959, 2), [['Not activated'], ['or']], [[' sum(case when activated = 1 then 0 else 1 end) as NotActivated\n']], ['Joined query, with group by and sub count based on a column'], 4, 1], [(35391959, 3), [['or'], ['-10000']], [[' (select sum(case when activated = 1 then 0 else 1 end) FROM products WHERE product_type_id = p.product_type_id) as NotActivated\n']], ['Joined query, with group by and sub count based on a column'], 4, 1], [(35435745, 0), [['Just replace  =  with  in :'], ['If you want only the (whatever) first:']], [[' where ovr.progressivo in (\n']], ['Postgresql query join only first row that match pattern'], 2, 0], [(35435745, 1), [['If you want only the (whatever) first:'], ['If you have a criteria to what is first add it to the  order by  clause']], [[" select distinct on (ovr.progressivo)\n    ovr.progressivo,\n    ovr.art_codice,\n    ovr.descrizione1,\n    ovr.descrizione2,\n    ovr.riga\nfrom ovr\nwhere ovr.progressivo in (\n    select progressivo\n    from ovr\n    where\n        ovr.art_codice ~~ '0034%'::text or\n        ovr.art_codice ~~ '0035%'::text or\n        ovr.art_codice ~~ '0036%'::text\n    group by progressivo\n)\norder by ovr.progressivo\n"]], ['Postgresql query join only first row that match pattern'], 2, 1], [(35471226, 0), [['What about  split_part ?'], ['Example:']], [[" SELECT split_part(column, '/', 3) FROM table\n"]], ['SQL Regex to select string between second and third forward slash'], 2, 1], [(35471226, 1), [['Example:'], ['Returns:  required string']], [[" select split_part ('/abc/required_string/2/', '/', 3)\n"]], ['SQL Regex to select string between second and third forward slash'], 2, 1], [(35478088, 0), [['Oracle Setup :'], ['Query -  IN  clause has all parents explanded :']], [[' CREATE TABLE hierarchy ( id, parent_id ) AS\n  SELECT 1, NULL FROM DUAL UNION ALL\n  SELECT 2, 1 FROM DUAL UNION ALL\n  SELECT 3, 2 FROM DUAL UNION ALL\n  SELECT 4, 1 FROM DUAL UNION ALL\n  SELECT 5, 4 FROM DUAL UNION ALL\n  SELECT 6, 5 FROM DUAL UNION ALL\n  SELECT 7, NULL FROM DUAL UNION ALL\n  SELECT 8, 7 FROM DUAL UNION ALL\n  SELECT 9, 8 FROM DUAL UNION ALL\n  SELECT 10, 9 FROM DUAL UNION ALL\n  SELECT 11, 8 FROM DUAL;\n']], ['Fetch recursive tree with only certain elements "expanded"'], 7, 0], [(35478088, 1), [['Query -  IN  clause has all parents explanded :'], ['Output :']], [[" SELECT LPAD( '+ ', LEVEL*2, ' ' ) || id\nFROM   hierarchy\nSTART WITH parent_id IS NULL\nCONNECT BY PRIOR id = parent_id\nAND        parent_id IN ( 1, 2, 4, 5, 7, 8, 9 );\n"]], ['Fetch recursive tree with only certain elements "expanded"'], 7, 1], [(35478088, 2), [['Output :'], ['Query -  IN  clause has all parents expanded except 4 and 8 :']], [[' + 1\n  + 2\n    + 3\n  +4\n    + 5\n      + 6\n+ 7\n  + 8\n    + 9\n      + 10\n    + 11\n']], ['Fetch recursive tree with only certain elements "expanded"'], 7, 0], [(35478088, 3), [['Query -  IN  clause has all parents expanded except 4 and 8 :'], ['Output :']], [[" SELECT LPAD( '+ ', LEVEL*2, ' ' ) || id\nFROM   hierarchy\nSTART WITH parent_id IS NULL\nCONNECT BY PRIOR id = parent_id\nAND        parent_id IN ( 1, 2, 5, 7, 9 );\n"]], ['Fetch recursive tree with only certain elements "expanded"'], 7, 1], [(35478088, 4), [['Output :'], ['Update - Showing leaf nodes :']], [[' + 1\n  + 2\n    + 3\n  +4\n+ 7\n  + 8\n']], ['Fetch recursive tree with only certain elements "expanded"'], 7, 0], [(35478088, 5), [['Update - Showing leaf nodes :'], ['Output :']], [[" SELECT LPAD( '+ ', LEVEL*2, ' ' ) || id AS value,\n       isleaf\nFROM   (\n  -- Find the leaves first (as if all parents are expanded)\n  SELECT h.*,\n         CONNECT_BY_ISLEAF AS isLeaf\n  FROM   hierarchy h\n  START WITH parent_id IS NULL\n  CONNECT BY PRIOR id = parent_id\n)\nSTART WITH parent_id IS NULL\nCONNECT BY PRIOR id = parent_id\nAND        parent_id IN ( 1, 2, 4, 7, 9 );\n"]], ['Fetch recursive tree with only certain elements "expanded"'], 7, 1], [(35478088, 6), [['Output :'], ['1  Indicates that the node has no children and  0  indicates that the node has children (even though they might not be expanded).']], [[' VALUE                ISLEAF\n---------------- ----------\n+ 1                       0 \n  + 2                     0 \n    + 3                   1 \n  + 4                     0 \n    + 5                   0 \n+ 7                       0 \n  + 8                     0 \n']], ['Fetch recursive tree with only certain elements "expanded"'], 7, 0], [(35508881, 0), [['You can always do it with a union. '], ['Or using row_number:']], [[" select top (SELECT Limit FROM Table2 WHERE _Element='A') * from Table1\nWHERE attribute = A\nUNION ALL\nselect top (SELECT Limit FROM Table2 WHERE _Element='B') * from Table1\nWHERE attribute = B\nUNION ALL\nselect top (SELECT Limit FROM Table2 WHERE _Element='C') * from Table1\nWHERE attribute = C\n"]], ['SQL/PostgreSQL: How to select limited amount of rows of different types based on limits stored in a different table?'], 2, 1], [(35508881, 1), [['Or using row_number:'], ['-10000']], [['  with cte as (SELECT _Key, \nattribute, \nROW_NUMBER() OVER (Partition by attribute Order by _Key ASC) as rowno\n    From Table1)\n    SELECT * FROM cte\n    LEFT JOIN Table2 on Table2.Element = Table1.attribute\n    WHERE rowno >= Limit\n']], ['SQL/PostgreSQL: How to select limited amount of rows of different types based on limits stored in a different table?'], 2, 1], [(35574490, 0), [['Oracle Setup :'], ['Query']], [[" CREATE OR REPLACE FUNCTION split_String(\n  i_str    IN  VARCHAR2,\n  i_delim  IN  VARCHAR2 DEFAULT ','\n) RETURN SYS.ODCIVARCHAR2LIST DETERMINISTIC\nAS\n  p_result       SYS.ODCIVARCHAR2LIST := SYS.ODCIVARCHAR2LIST();\n  p_start        NUMBER(5) := 1;\n  p_end          NUMBER(5);\n  c_len CONSTANT NUMBER(5) := LENGTH( i_str );\n  c_ld  CONSTANT NUMBER(5) := LENGTH( i_delim );\nBEGIN\n  IF c_len > 0 THEN\n    p_end := INSTR( i_str, i_delim, p_start );\n    WHILE p_end > 0 LOOP\n      p_result.EXTEND;\n      p_result( p_result.COUNT ) := SUBSTR( i_str, p_start, p_end - p_start );\n      p_start := p_end + c_ld;\n      p_end := INSTR( i_str, i_delim, p_start );\n    END LOOP;\n    IF p_start <= c_len + 1 THEN\n      p_result.EXTEND;\n      p_result( p_result.COUNT ) := SUBSTR( i_str, p_start, c_len - p_start + 1 );\n    END IF;\n  END IF;\n  RETURN p_result;\nEND;\n/\n\nCREATE TABLE xyz ( weekend_days ) AS\nSELECT 'SATURDAY,SUNDAY' FROM DUAL;\n\nCREATE TABLE abc ( act_date ) AS\nSELECT DATE '2016-02-02' FROM DUAL UNION ALL\nSELECT DATE '2016-02-06' FROM DUAL;\n"]], ['Search a value in the column value that stores comma separated values'], 4, 0], [(35574490, 2), [['Output :'], ['Alternate Query :']], [[' ACT_DATE  WEEKEND_FLAG\n--------- ------------\n06-FEB-16            1 \n02-FEB-16            0 \n']], ['Search a value in the column value that stores comma separated values'], 4, 0], [(35575481, 0), [['-10000'], ['-10000']], [[" CREATE TABLE tosplit\n        ( id text NOT NULL\n        , name text\n        , details text\n        );\n\nINSERT INTO tosplit( id , name , details ) VALUES\n ( '1.3.1-3' , 'Jack' , 'a' )\n,( '5.4.1-2' , 'John' , 'b' )\n,( '1.4.5' , 'Alex' , 'c' )\n\n\nWITH zzz AS (\n        SELECT id\n        , regexp_replace(id, '([0-9\\.]+\\.)([0-9]+)-([0-9]+)', e'\\\\1', e'g') AS one\n        , regexp_replace(id, '([0-9\\.]+\\.)([0-9]+)-([0-9]+)', e'\\\\2', e'g') AS two\n        , regexp_replace(id, '([0-9\\.]+\\.)([0-9]+)-([0-9]+)', e'\\\\3', e'g') AS three\n        , name\n        , details\n        FROM tosplit\n        )\n    SELECT z1.id\n        -- , z1.one\n        , z1.one || generate_series( z1.two::integer, z1.three::integer)::text AS four\n        , z1.name, z1.details\nFROM zzz z1\nWHERE z1.two <> z1.one\nUNION ALL\nSELECT z0.id\n        -- , z0.one\n        , z0.one AS four\n        , z0.name, z0.details\nFROM zzz z0\nWHERE z0.two = z0.one\n        ;\n"]], ['PostgreSQL- splitting rows'], 2, 1], [(35575481, 1), [['-10000'], ['-10000']], [[' CREATE TABLE\nINSERT 0 3\n   id    | four  | name | details \n---------+-------+------+---------\n 1.3.1-3 | 1.3.1 | Jack | a\n 1.3.1-3 | 1.3.2 | Jack | a\n 1.3.1-3 | 1.3.3 | Jack | a\n 5.4.1-2 | 5.4.1 | John | b\n 5.4.1-2 | 5.4.2 | John | b\n 1.4.5   | 1.4.5 | Alex | c\n']], ['PostgreSQL- splitting rows'], 2, 0], [(35577600, 1), [['On second glance, you seem to want the data aggregated and  then  cumulatively summed.  For this:'], ['-10000']], [[" SELECT ID, LEFT(Classification, 3),\n       SUM(SUM(Area)) over (partition by LEFT(Classification, 3) order by ID)\nFROM MyTable\nWHERE Classification LIKE '1-2-%' OR     \n      Classification LIKE '1-4-%'\nGROUP BY ID, LEFT(Classification, 3);\n"]], ['Using wildcard characters in SUM function'], 2, 1], [(35578867, 0), [['Most versions of SQL support  ESCAPE :'], ['For instance:']], [[" where lastname like '%/%' escape '/'\n"]], ['to find the string(e.g name) which ends with % in sql'], 2, 1], [(35578867, 1), [['For instance:'], ['-10000']], [[" where right(lastname, 1) = '%'\n"]], ['to find the string(e.g name) which ends with % in sql'], 2, 1], [(35640282, 0), [['This dataset gives you only the latest version as well as two columns corresponding to open and closed:'], ['Now we just join this back to projects:']], [["     SELECT \n    FeedbackID, FeedbackVersion,\n    CASE WHEN Status='Open' THEN 1 ELSE 0 END As OpenCount\n    CASE WHEN Status='Closed' THEN 1 ELSE 0 END As ClosedCount\n    FROM Feedback F\n    WHERE FeedbackVersion = (\n             SELECT MAX(FeedbackVersion)\n             FROM Feedback FM\n             WHERE FM.FeedbackID = F.FeedbackID \n             )\n"]], ['Three table join sql server to get latest versions and count'], 2, 0], [(35640282, 1), [['Now we just join this back to projects:'], ["It's not clear what you want to do with  ProjectID  records with old versions. i.e. if project id 7  only  exists in  ProjectID  against an old version, it will not appear in this query."]], [[" SELECT P.ProjectID, SUM(OpenCount), SUM(ClosedCount)\nFROM ProjectID P\nINNER JOIN\n(\n    SELECT \n    FeedbackID, FeedbackVersion,\n    CASE WHEN Status='Open' THEN 1 ELSE 0 END As OpenCount\n    CASE WHEN Status='Closed' THEN 1 ELSE 0 END As ClosedCount\n    FROM Feedback F\n    WHERE FeedbackVersion = (\n             SELECT MAX(FeedbackVersion)\n             FROM Feedback FM\n             WHERE FM.FeedbackID = F.FeedbackID \n             )\n) MaxVersion\nON  P.FeedbackID=MaxVersion.FeedbackID\nAND P.FeedbackVersion=MaxVersion.FeedbackVersion\nGROUP BY P.ProjectID\n"]], ['Three table join sql server to get latest versions and count'], 2, 0], [(35647425, 0), [['SQL:'], ['Output(as expected):']], [[" -- data preparation for demo\ncreate table tbl(Name char(100), id int, Col1 int, Col2 int, Col3 char(20), Col4 char(20), Total int, Balance int);\ninsert into tbl values\n('Row1',1,6,1,'A','Z',0,0),\n('Row2',2,2,3,'B','Z',0,0),\n('Row3',3,9,5,'B','Y',0,0),\n('Row4',4,12,8,'C','Y',0,0);\nSELECT * FROM tbl;\n\n-- Query needed\nSET @bal = 0;\nUPDATE tbl\nSET\n    Total = CASE    WHEN Col3 = 'A' and Col4 <> 'Z'\n                        THEN Col1+Col2\n                    WHEN Col3 = 'B' and Col4 <> 'Z'\n                        THEN Col1-Col2\n                    WHEN Col3 = 'C' and Col4 <> 'Z'\n                        THEN Col1*Col2\n                    ELSE 0 END,\n    Balance = (@bal:=@bal + Total);\nSELECT * FROM tbl;\n"]], ['Update the total based on the previous row of balance'], 2, 1], [(35647425, 1), [['Output(as expected):'], ['-10000']], [[" mysql> SELECT * FROM tbl;\n+------+------+------+------+------+------+-------+---------+\n| Name | id   | Col1 | Col2 | Col3 | Col4 | Total | Balance |\n+------+------+------+------+------+------+-------+---------+\n| Row1 |    1 |    6 |    1 | A    | Z    |     0 |       0 |\n| Row2 |    2 |    2 |    3 | B    | Z    |     0 |       0 |\n| Row3 |    3 |    9 |    5 | B    | Y    |     0 |       0 |\n| Row4 |    4 |   12 |    8 | C    | Y    |     0 |       0 |\n+------+------+------+------+------+------+-------+---------+\n4 rows in set (0.00 sec)\n\nmysql> -- Query needed\nmysql> SET @bal = 0;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> UPDATE tbl\n    -> SET\n    ->     Total = CASE    WHEN Col3 = 'A' and Col4 <> 'Z'\n    ->                         THEN Col1+Col2\n    ->                     WHEN Col3 = 'B' and Col4 <> 'Z'\n    ->                         THEN Col1-Col2\n    ->                     WHEN Col3 = 'C' and Col4 <> 'Z'\n    ->                         THEN Col1*Col2\n    ->                     ELSE 0 END,\n    ->     Balance = (@bal:=@bal + Total);\nQuery OK, 2 rows affected (0.00 sec)\nRows matched: 4  Changed: 2  Warnings: 0\n\nmysql>\nmysql> SELECT * FROM tbl;\n+------+------+------+------+------+------+-------+---------+\n| Name | id   | Col1 | Col2 | Col3 | Col4 | Total | Balance |\n+------+------+------+------+------+------+-------+---------+\n| Row1 |    1 |    6 |    1 | A    | Z    |     0 |       0 |\n| Row2 |    2 |    2 |    3 | B    | Z    |     0 |       0 |\n| Row3 |    3 |    9 |    5 | B    | Y    |     4 |       4 |\n| Row4 |    4 |   12 |    8 | C    | Y    |    96 |     100 |\n+------+------+------+------+------+------+-------+---------+\n4 rows in set (0.00 sec)\n"]], ['Update the total based on the previous row of balance'], 2, 0], [(35661363, 0), [['It sounds like you just need  GROUP BY :'], ['Okay, I realized you are not asking for a count but for the sequence number. In that case you can say this:']], [[" SELECT  uuid, project_name, to_char(analysis_date, 'YYYY-MM-DD') d, count(*)\nFROM    t\nGROUP BY uuid, project_name, d\nORDER BY uuid, project_name, d\n;\n"]], ['How to create a pseudo-column showing the "occurrence number" in a day in PostgreSQL?'], 2, 0], [(35661363, 1), [['Okay, I realized you are not asking for a count but for the sequence number. In that case you can say this:'], ["Or if you want independent numbering within each project, include that in the  PARTITION  like this:  PARTITION BY project_name, to_char(analysis_date, 'YYYY-MM-DD') ."]], [[" SELECT  uuid, project_name, to_char(analysis_date, 'YYYY-MM-DD') d, \n        row_number() OVER (PARTITION BY analysis_date::date ORDER BY analysis_date)\nFROM    t\nORDER BY uuid, project_name, d\n; \n"]], ['How to create a pseudo-column showing the "occurrence number" in a day in PostgreSQL?'], 2, 1], [(35700944, 0), [['Add the values together for each record, and then use an aggregate to sum the rows.  Since they are Boolean values adding zero will not effect the summed result.'], ['If you need a data set grouped by each kw... you could do it this way as well... it would be better performance than querying by each kw individually.']], [[' SELECT sum(MO+DI+MI+DO) myResult\nFROM name\nwhere kw = 8\n']], ['sql table with 4 bool columns and 1 int column. How to add all bools from one int together'], 2, 1], [(35700944, 1), [['If you need a data set grouped by each kw... you could do it this way as well... it would be better performance than querying by each kw individually.'], ['-10000']], [[' SELECT kw, sum(MO+DI+MI+DO) myResult\nFROM name\nGROUP BY kw\n']], ['sql table with 4 bool columns and 1 int column. How to add all bools from one int together'], 2, 1], [(35701321, 0), [['Try this:'], ['Update:  if your XML looks like this:']], [[" SELECT\n    Name = xc.value('(NAME)[1]', 'varchar(50)'),\n    CompEnabled = xc.value('(PROPERTIES/COMP_ENABLED)[1]', 'varchar(10)')\nFROM \n    dbo.YourTable\nCROSS APPLY\n    SC.nodes('/SC_ROOT/COMPONENTS/COMPONENT') AS XT(XC)\nWHERE\n    xc.value('(NAME)[1]', 'varchar(50)') LIKE '%Detection'\n"]], ['Querying XML data from a SQL Server table'], 3, 1], [(35701321, 1), [['Update:  if your XML looks like this:'], ['then use this code to get the results:']], [[' <COMPONENT>\n  <NAME>Status A Detection</NAME>\n  <PROPERTIES NAME="COMP_ENABLED" VALUE="True" />\n</COMPONENT>\n']], ['Querying XML data from a SQL Server table'], 3, 0], [(35701321, 2), [['then use this code to get the results:'], ['-10000']], [[' SELECT\n    Name = xc.value(\'(NAME)[1]\', \'varchar(50)\'),\n    CompEnabled = xc.value(\'(PROPERTIES[@NAME="COMP_ENABLED"]/@VALUE)[1]\', \'varchar(10)\')\nFROM \n    dbo.YourTable\nCROSS APPLY\n    SC.nodes(\'/SC_ROOT/COMPONENTS/COMPONENT\') AS XT(XC)\nWHERE\n    xc.value(\'(NAME)[1]\', \'varchar(50)\') LIKE \'%Detection\'\n']], ['Querying XML data from a SQL Server table'], 3, 1], [(35753972, 1), [['To handle more column just add them to:'], ['-10000']], [[' val FOR col_name IN (Value1, Value2, Value3, ValueN)\n']], ['Using countif in Oracle sql to calculate for each row'], 4, 0], [(35753972, 2), [['-10000'], ['Output:']], [[" SELECT t.*, sub.High, sub.Medium, sub.Low\nFROM tab t\nJOIN (SELECT ID, Name, \n         COUNT(CASE WHEN val = 'High' THEN 1 END)   AS High,\n         COUNT(CASE WHEN val = 'Medium' THEN 1 END) AS Medium,\n         COUNT(CASE WHEN val = 'Low' THEN 1 END)    AS Low\n      FROM tab\n      UNPIVOT( val FOR col_name IN (Value1, Value2, Value3, ValueN)) unpvt\n      GROUP BY ID, Name) sub\n  ON t.ID = sub.ID\n"]], ['Using countif in Oracle sql to calculate for each row'], 4, 1], [(35753972, 3), [['Output:'], ['-10000']], [[' ╔════╦══════╦════════╦════════╦════════╦════════╦══════╦════════╦═════╗\n║ ID ║ Name ║ Value1 ║ Value2 ║ Value3 ║ ValueN ║ High ║ Medium ║ Low ║\n╠════╬══════╬════════╬════════╬════════╬════════╬══════╬════════╬═════╣\n║  1 ║ A    ║ High   ║ High   ║ Low    ║ Medium ║    2 ║      1 ║   1 ║\n║  2 ║ AB   ║ Low    ║ Medium ║ Low    ║ High   ║    1 ║      1 ║   2 ║\n║  3 ║ ABC  ║ High   ║ Low    ║ Low    ║ High   ║    2 ║      0 ║   2 ║\n╚════╩══════╩════════╩════════╩════════╩════════╩══════╩════════╩═════╝\n']], ['Using countif in Oracle sql to calculate for each row'], 4, 0], [(35756149, 0), [['The second argument of  .join()  is the join condition:'], ["You'll also need to make sure convert your sub- Query  into a  select  with correctly labeled columns:"]], [[' db.session.query(RevisionModel.id) \\\n          .join(subquery, and_(subquery.c.content_id == RevisionModel.content_id,\n                               subquery.c.min_ts_created == RevisionModel.ts_created))\n']], ['Converting SQL query with inner select to sqlalchemy'], 2, 0], [(35777522, 0), [['Get everything from the view, then just add two columns as null.'], ['EDIT:\nAfter the initial creation you can do:']], [[' SELECT *, null as location, null as roles\nINTO new_table\nFROM the_view\n']], ['update table from a view present in ms sql database'], 3, 1], [(35777522, 1), [['EDIT:\nAfter the initial creation you can do:'], ['or']], [[' INSERT INTO new_table\nSELECT *, null as location, null as roles\nFROM the_view\n']], ['update table from a view present in ms sql database'], 3, 0], [(35777522, 2), [['or'], ['-10000']], [[' INSERT INTO new_table (firstName, lastName, employee_id)\nSELECT *\nFROM the_view\n']], ['update table from a view present in ms sql database'], 3, 0], [(35800153, 0), [['With the following code... (all credit to original author)'], ["When you don't want to replace [DATABASE NAME] manually you can use the following variable"]], [[" SELECT Count(*)\nINTO @exists\nFROM information_schema.tables \nWHERE table_schema = [DATABASE_NAME]\nAND table_type = 'BASE TABLE'\nAND table_name = 'oldName';\nSET @query = If(@exists=0,'RENAME TABLE oldName TO newName','SELECT \\'nothing to rename\\' status');\nPREPARE stmt FROM @query;\nEXECUTE stmt;\n"]], ['RENAME table if target table does not exist'], 2, 1], [(35800153, 1), [["When you don't want to replace [DATABASE NAME] manually you can use the following variable"], ['-10000']], [[' SELECT DATABASE() INTO @db_name FROM DUAL;\n']], ['RENAME table if target table does not exist'], 2, 0], [(35802709, 0), [["You don't need only one"], ['This is the same as a join with two clauses']], [[' WHERE\n   (otherPersons, date) IN (\n      SELECT\n         person, MIN(date)\n      FROM\n         orders\n      WHERE\n         date > "1/1/2015" and date < "1/31/2015"\n      GROUP BY\n        person\n    )\n      GROUP BY\n        person\n']], ['using MIN within WHERE'], 2, 1], [(35804288, 0), [['The query you need is'], ["Note : Make sure you're not confusing empty string  ''  with  NULL . In DB2, those are not the same. If your values are actually  NULL , your query would need to be:"]], [[" UPDATE client SET address_1 = address_2, address_2 = ''\nWHERE address_1 = '' AND address_2 != ''\n"]], ['How to update the same column for multiple rows in DB2'], 2, 1], [(35804288, 1), [["Note : Make sure you're not confusing empty string  ''  with  NULL . In DB2, those are not the same. If your values are actually  NULL , your query would need to be:"], ['-10000']], [[' UPDATE client SET address_1 = address_2, address_2 = NULL\nWHERE address_1 IS NULL AND address_2 IS NOT NULL\n']], ['How to update the same column for multiple rows in DB2'], 2, 1], [(35822621, 0), [['Using  JOIN'], ['Another way using  EXISTS  ']], [[' SELECT sc.schid, \n       sc.schname \nFROM   student s \n       JOIN school sc \n         ON s.schid = sc.schid \nGROUP  BY sc.schid, \n          sc.schname \nHAVING( CASE WHEN status IS NULL THEN 1 END ) = Count(*) \n']], ['SQL query using NULL'], 2, 1], [(35822621, 1), [['Another way using  EXISTS  '], ['-10000']], [[' SELECT sc.schid, \n       sc.schname \nFROM   school sc \nWHERE  EXISTS (SELECT 1 \n               FROM   student s \n               WHERE  s.schid = sc.schid \n               HAVING( CASE WHEN status IS NULL THEN 1 END ) = Count(*)) \n']], ['SQL query using NULL'], 2, 1], [(35840854, 0), [['You can easy use this:'], ['And for your second question, something like this:']], [[' select sessid,min(timestart) FROM mytable GROUP by sessid;\n']], ['Get frist date from timestamp in SQL'], 2, 1], [(35869713, 0), [['You can use  ROW_NUMBER   for this:'], ['Edit:  In case of ties you can extend the  ORDER BY  clause of  ROW_NUMBER  so as to selectively pick either the smaller  TrackID :']], [[' SELECT TrackID,  IMEI, LastDate\nFROM (\n  SELECT TrackID,  IMEI, LastDate, \n         ROW_NUMBER() OVER (PARTITION BY IMEI \n                            ORDER BY LastPacketTime DESC) AS rn\n  FROM dbo.Tracks) AS t\nWHERE t.rn = 1\n']], ['How can I include primary key when using SELECT MAX() and GROUP BY?'], 3, 1], [(35869713, 1), [['Edit:  In case of ties you can extend the  ORDER BY  clause of  ROW_NUMBER  so as to selectively pick either the smaller  TrackID :'], ['or the bigger one:']], [[' ORDER BY LastPacketTime DESC, TrackID\n']], ['How can I include primary key when using SELECT MAX() and GROUP BY?'], 3, 0], [(35869713, 2), [['or the bigger one:'], ['-10000']], [[' ORDER BY LastPacketTime DESC, TrackID DESC\n']], ['How can I include primary key when using SELECT MAX() and GROUP BY?'], 3, 0], [(35903825, 0), [['-10000'], ['And then,']], [[' select id, fruit, row_number() over (partition by fruit order by id) as running_total\nfrom fruits\norder by id\n']], ['How to calculate "running total" in SQL'], 2, 0], [(35903825, 1), [['And then,'], ['-10000']], [[' alter table Fruits add RUNNING_TOTAL int null\n\nupdate fruits set running_total = subquery.running_total\nfrom fruits\ninner join (\n select id, row_number() over (partition by fruit order by id) as running_total\n from fruits\n )subquery on fruits.id = subquery.id\n\nselect * from fruits\n']], ['How to calculate "running total" in SQL'], 2, 0], [(35913338, 0), [["Using Aleksej's data but expanded to multiple rows, you can do:"], ['Which gets:']], [[' set verify off\n\naccept subtitute_value prompt \'insert smt: \';\n\nttitle center "Report for: " subttitle skip 5\ncolumn column1 new_value subttitle\nbreak on column1 skip page\n\nselect column1, column2, column3\nfrom table1\nwhere upper(table1.column1) like upper(\'%&subtitute_value%\')\norder by column1; -- and others\n']], ['Substitute variable with case-insensitive pattern matching and match shown in report title'], 2, 1], [(35913338, 1), [['Which gets:'], ['The  column ... new_value subttitle  defines the  subtitle  referred to in the  ttitle  directive. Not that is not referred to as a substitution variable, to no  &  here. You need to break on the column being used for the title, as noted in the documentation. And if you  only  want to see the value in the title, not in the report itself, you can add  noprint  to that  column  directive.']], [[' insert smt: ora\n\n                           Report for: 123 ORAC LE 333\n\n\n\n\nCOLUMN1                 COLUMN2 COLUMN3\n-------------------- ---------- --------------------\n123 ORAC LE 333              95 Some text\n                             99 Some text\n\n                             Report for: xxOracleyy\n\n\n\n\nCOLUMN1                 COLUMN2 COLUMN3\n-------------------- ---------- --------------------\nxxOracleyy                   13 Some text\n                              7 Some text\n                             42 Some text\n                              5 Some text\n                             71 Some text\n\n7 rows selected.\n']], ['Substitute variable with case-insensitive pattern matching and match shown in report title'], 2, 0], [(36057894, 0), [['Do a  GROUP BY , use  COUNT  (which only counts non-null values):'], ["If values are not null but '.' (or something else), do use  case  expressions to do conditional counting, something like:"]], [[' select id,\n       count(value1) as value1,\n       count(value2) as value2,\n       count(value3) as value3\nfrom table1\ngroup by id\n']], ['Count number of values per id'], 2, 1], [(36057894, 1), [["If values are not null but '.' (or something else), do use  case  expressions to do conditional counting, something like:"], ['-10000']], [[" select id,\n       count(case when value1 <> '.' then 1 end) as value1,\n       count(case when value2 <> '.' then 1 end) as value2,\n       count(case when value3 <> '.' then 1 end) as value3\nfrom table1\ngroup by id\n"]], ['Count number of values per id'], 2, 1], [(36086980, 0), [['You could create a new table with the hierarchical structure, and an auto incrementing ID, like this:'], ['Then you would first add the level 1 elements to it, as they have no parent:']], [[' create table hierarchy (\n  id int not null identity (1,1) primary key,\n  element varchar(100),\n  parent int\n);\n']], ['Generate a parent-child hierarchy from table with levels paths'], 4, 0], [(36086980, 3), [['This pattern you can repeat to the next levels:'], ['... etc, as far into the levels as needed.']], [[' insert into hierarchy (element, parent)\n  select     distinct f.level3, h2.id\n  from       hierarchy h1\n  inner join hierarchy h2\n          on h2.parent = h1.id\n  inner join flat f\n          on f.level1 = h1.element\n         and f.level2 = h2.element\n  where      h1.parent is null;\n\ninsert into hierarchy (element, parent)\n  select     distinct f.level4, h3.id\n  from       hierarchy h1\n  inner join hierarchy h2\n          on h2.parent = h1.id\n  inner join hierarchy h3\n          on h3.parent = h2.id\n  inner join flat f\n          on f.level1 = h1.element\n         and f.level2 = h2.element\n         and f.level3 = h3.element\n  where      h1.parent is null;\n\ninsert into hierarchy (element, parent)\n  select     distinct f.level5, h3.id\n  from       hierarchy h1\n  inner join hierarchy h2\n          on h2.parent = h1.id\n  inner join hierarchy h3\n          on h3.parent = h2.id\n  inner join hierarchy h4\n          on h4.parent = h3.id\n  inner join flat f\n          on f.level1 = h1.element\n         and f.level2 = h2.element\n         and f.level3 = h3.element\n         and f.level4 = h4.element\n  where      h1.parent is null;\n\ninsert into hierarchy (element, parent)\n  select     distinct f.level6, h3.id\n  from       hierarchy h1\n  inner join hierarchy h2\n          on h2.parent = h1.id\n  inner join hierarchy h3\n          on h3.parent = h2.id\n  inner join hierarchy h4\n          on h4.parent = h3.id\n  inner join hierarchy h5\n          on h5.parent = h4.id\n  inner join flat f\n          on f.level1 = h1.element\n         and f.level2 = h2.element\n         and f.level3 = h3.element\n         and f.level4 = h4.element\n         and f.level5 = h5.element\n  where      h1.parent is null;\n']], ['Generate a parent-child hierarchy from table with levels paths'], 4, 1], [(36117235, 0), [['collect_list will give you a list without removing duplicates.\ncollect_set will automatically remove duplicates\nso just '], ['https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/functions.scala']], [[' select \nName,\ncount(distinct color) as Distinct, # not a very good name\ncollect_set(Color) as Values\nfrom TblName\ngroup by Name\n']], ['SQL on Spark: How do I get all values of DISTINCT?'], 2, 1], [(36131131, 0), [['First of all, do proper joins, then add a  GROUP BY :'], ["I don't know Oracle very well, but I suppose you could do something like"]], [[" SELECT o.ORDERNUMBER, p.PRODUCTNAME, SUM(od.quantity)\nFROM ORDERS o\n  JOIN order_details od ON o.ORDERNUMBER= od.ORDERNUMBER\n  JOIN PRODUCTS p ON od.ProductCode = p.ProductCode\nWHERE SHIPPEDDATE LIKE '%MAY-04'\nGROUP BY o.ORDERNUMBER, p.PRODUCTNAME\n"]], ['How to sort my sql statement by products as well as report a quantity'], 3, 1], [(36176385, 0), [['You can do what you want using aggregation:'], ['You might was conditional logic for  UniqueDatabaseNo  as well:']], [[" select max(UniqueDatabaseNo) as UniqueDatabaseNo, Creditor,\n       max(case when BankAccountNo like '[a-Z][a-Z]%' then BankAccountNo end) as BankAccountNo\nfrom t\ngroup by Creditor;\n"]], ['Moving value from below row to upper one'], 2, 1], [(36239016, 0), [["If that's true, then the most elegant and redundancy free way to represent this is to choose one of the items of such as subset as a representative of the entire subset. This is reflected by the following table design:"], ['Example:']], [[' item(id, equivalence_id, other attributes, ...)\n']], ['Database: item can have alternatives, how to link in database?'], 3, 0], [(36239016, 1), [['Example:'], ['To find all items equivalent to a specific one, query']], [[' id   equivalence_id   name\n1    1                abc\n2                     def\n3    1                ghi\n4    4                jkl\n5    4                mno\n']], ['Database: item can have alternatives, how to link in database?'], 3, 0], [(36249094, 0), [['Something like this(sorry, not tested):'], ['Code from comment by @Chandan which works for conditions mentioned in the question:']], [[' begin\n  ctx_ddl.create_preference(\'comma_lexer\', \'BASIC_LEXER\');\n  ctx_ddl.set_attribute(\'comma_lexer\', \'PRINTJOINS\', \'\'\'()/^&"\');\n  ctx_ddl.set_attribute(\'comma_lexer\', \'PUNCTUATIONS\', \',.-?!\');\nend;\n/\n\ncreate index node_sequence_index \n  on testtable(node_sequence)\n  indextype is ctxsys.context \n  parameters (\'lexer comma_lexer\')\n;\n']], ['How to index a comma separated text column using Oracle text'], 2, 1], [(36249094, 1), [['Code from comment by @Chandan which works for conditions mentioned in the question:'], ['-10000']], [[" begin \n  ctx_ddl.create_preference('comma_lexer', 'BASIC_LEXER');\n  ctx_ddl.set_attribute('comma_lexer', 'WHITESPACE', ',');\n  ctx_ddl.set_attribute('comma_lexer', 'NUMGROUP', '#'); \nend; \n/\n\ncreate index node_sequence_index \n  on testtable(node_sequence) \n  indextype is ctxsys.context \n  parameters ('lexer comma_lexer')\n;\n"]], ['How to index a comma separated text column using Oracle text'], 2, 1], [(36281485, 0), [['Use Filter expression:'], ['If you want to get particular element from the list, for example the first one, use this:']], [[' =Join(Filter(Fields!Software.Value,"Office"),",")\n']], ['Report Builder expression SQL list certain values only'], 2, 1], [(36294617, 0), [["You shouldn't compare timestamp values using  LIKE . To select the rows with a time between 06:00 and 14:00 cast the timestamp to a  time  and compare that:"], ['The same "trick" can be used to create the shift column: ']], [[" SELECT creation_time, product_id, warehouse_name\nFROM products \nWHERE creation_time::time BETWEEN time '06:00:00' AND time '14:00:00';\n"]], ['Creating view with additional column based on multiple condition'], 2, 1], [(36294617, 1), [['The same "trick" can be used to create the shift column: '], ["The  between  operator includes both values that's why the second check starts 1 second after 14:00"]], [[" SELECT creation_time, product_id, warehouse_name, \n       case \n         when creation_time::time between time '06:00:00' AND time '14:00:00' then 1\n         when creation_time::time BETWEEN time '14:00:01' AND time '22:00:00' then 2\n         else 3\n       end as shift_number\nFROM products;\n"]], ['Creating view with additional column based on multiple condition'], 2, 1], [(36330259, 0), [["You can use this code to get the result you're looking for:"], ["you're not respecting / including the  XML namespace  that's defined on the XML document"]], [[" ;WITH XMLNAMESPACES(DEFAULT 'http://somelongasslink.org/hasalsosomestuffhere')\nSELECT\n    rq.Name,\n    LocalID = TC.value('(LocalId)[1]', 'nvarchar(10)') \nFROM \n     [database].[requests] rq\nCROSS APPLY\n    rq.Data.nodes('/Dataform') AS TX(TC)\nGO\n"]], ['Flattening xml data in sql'], 2, 1], [(36330259, 1), [["you're not respecting / including the  XML namespace  that's defined on the XML document"], ['-10000']], [[' <Dataform xmlns="http://somelongasslink.org/hasalsosomestuffhere" \n          *******************************************************\n']], ['Flattening xml data in sql'], 2, 0], [(36377860, 0), [['You want to select nicknames from users:'], ['You only want to select records where the phone number is in the set of friends of user 1:']], [[' select nickname\nfrom users\n']], ['SELECT value WHERE IN SELECT'], 3, 0], [(36377860, 1), [['You only want to select records where the phone number is in the set of friends of user 1:'], ['Combined:']], [[' where phone in\n(\n  select phone\n  from phonebook\n  where ownerid = 1\n)\n']], ['SELECT value WHERE IN SELECT'], 3, 0], [(36377860, 2), [['Combined:'], ['-10000']], [[' select nickname\nfrom users\nwhere phone in\n(\n  select phone\n  from phonebook\n  where ownerid = 1\n);\n']], ['SELECT value WHERE IN SELECT'], 3, 1], [(36402026, 0), [['Try it like this:'], ['The result']], [[" CREATE TABLE #test(id INT,value VARCHAR(100),condition INT);\nINSERT INTO #test VALUES\n (1,'value1',0)\n,(2,'value2',0)\n,(3,'value3',1)\n,(4,'value4',1);\n\nWITH MyDistinctConditions AS\n(\n    SELECT DISTINCT condition\n    FROM #test \n)\nSELECT c.condition\n      ,(SELECT STUFF(\n                      (\n                      SELECT ', ' + CAST(t.id AS VARCHAR(10)) \n                      FROM #test AS t \n                      WHERE t.condition=c.condition\n                      FOR XML PATH('')),1,2,'')) AS ids\n      ,(SELECT STUFF(\n                      (\n                      SELECT ', ' + t.value \n                      FROM #test AS t \n                      WHERE t.condition=c.condition\n                      FOR XML PATH('')),1,2,'')) AS [values]\nFROM MyDistinctConditions AS c;\n\nDROP TABLE #test;\n"]], ['Tsql all ids and values in one row'], 2, 1], [(36402026, 1), [['The result'], ['-10000']], [[' condition   ids     values\n0           1, 2    value1, value2\n1           3, 4    value3, value4\n']], ['Tsql all ids and values in one row'], 2, 0], [(36425557, 0), [['You could do the brute-force approach with a table that you gradually populate. Assuming your  test  table looks something like:'], ['then the  result  table could be created with:']], [[' create table test (tablename varchar2(9), columnvalue varchar2(11), rankofcolumn number);\n']], ['SQL replacement for Recursive CTE'], 5, 0], [(36425557, 1), [['then the  result  table could be created with:'], ['Then create the result entries for the lowest rank:']], [[' create table result (tablename varchar2(9), columnvalue varchar2(11), rankofcolumn number,\n  path varchar2(50));\n']], ['SQL replacement for Recursive CTE'], 5, 0], [(36425557, 2), [['Then create the result entries for the lowest rank:'], ['And repeatedly add rows building on the highest existing rank, getting the following values (if there are any for that  tablename ) from the  test  table:']], [[' insert into result (tablename, columnvalue, rankofcolumn, path)\nselect t.tablename, t.columnvalue, t.rankofcolumn, t.columnvalue\nfrom test t\nwhere t.rankofcolumn = 1;\n\n3 rows inserted.\n']], ['SQL replacement for Recursive CTE'], 5, 0], [(36425557, 4), [['After all those iterations the table now contains:'], ['Tested in Oracle but trying to avoid anything Oracle-specific; might need tweaking for WX2 of course.']], [[' select * from result\norder by tablename, rankofcolumn;\n\nTABLENAME COLUMNVALUE RANKOFCOLUMN PATH                                             \n--------- ----------- ------------ --------------------------------------------------\nA         C1                     1 C1                                                \nA         C2                     2 C1->C2                                            \nA         C3                     3 C1->C2->C3                                        \nA         C4                     4 C1->C2->C3->C4                                    \nB         CX1                    1 CX1                                               \nB         CX2                    2 CX1->CX2                                          \nC         CY1                    1 CY1                                               \nC         CY2                    2 CY1->CY2                                          \nC         CY3                    3 CY1->CY2->CY3                                     \n']], ['SQL replacement for Recursive CTE'], 5, 0], [(36433001, 0), [['-10000'], ['The alternative is to use temp table:']], [[' select id from temptable;\nselect name from temptable;\n']], ['With structure - using multiple select queries without repeating the "with"'], 2, 0], [(36433001, 1), [['The alternative is to use temp table:'], ['-10000']], [[' SELECT .... INTO #temptable FROM ...; -- your query from CTE\nSELECT id   FROM #temptable; \nSELECT name FROM #temptable;\n']], ['With structure - using multiple select queries without repeating the "with"'], 2, 1], [(36435813, 0), [['you can do it much easier, and probably faster:'], ['EDIT: \nthe same result you can get by this query:']], [[' WITH\n  parms as (select \'Phase 1\' AS "Phase1", \'Phase 2\' AS "Phase2", \'Phase 3\' AS "Phase3", \'{091225F8-4606-401C-872E-FC5ACDC1D8E2}\' AS case_id from dual)\nSELECT \ndc.case_id, \nparms."Phase1", \nSELECT Max(updated_ts) FROM a_identifiers WHERE identifier_value = parms."Phase1" AND group_ID = dc.case_ID) AS "Phase1Enddt",\nparms."Phase2",\nSELECT Max(updated_ts) FROM a_identifiers WHERE identifier_value = parms."Phase2" AND group_ID = dc.case_ID) AS "Phase2Enddt",\nparms."Phase3",\nSELECT Max(updated_ts) FROM a_identifiers WHERE identifier_value = parms."Phase3" AND group_ID = dc.case_ID) AS "Phase3Enddt",\nFROM parms, cmreporting.d_solution ds\nINNER JOIN cmreporting.d_case dc ON ds.solution_sqn = dc.solution_sqn\nWHERE dc.case_id = parms.case_id \nAND rownum = 1 --if ther is more then one row\n']], ['Need multiple maxdates-oracle sql developer 4.0.2'], 2, 1], [(36435813, 1), [['EDIT: \nthe same result you can get by this query:'], ['-10000']], [[' WITH\n  parms as (select \'Phase 1\' AS "Phase1", \'Phase 2\' AS "Phase2", \'Phase 3\' AS "Phase3", \'{091225F8-4606-401C-872E-FC5ACDC1D8E2}\' AS case_id from dual)\nSELECT \ngroup_ID as case_id, \nparms."Phase1", \nMax(Case When identifier_value = parms."Phase1" Then updated_ts End) AS "Phase1Enddt",\nparms."Phase2",\nMax(Case When identifier_value = parms."Phase2" Then updated_ts End) AS "Phase2Enddt",\nparms."Phase3",\nMax(Case When identifier_value = parms."Phase3" Then updated_ts End) AS "Phase3Enddt",\nFROM parms, a_identifiers\nWhere Exists (Select 1 From cmreporting.d_solution ds\n  INNER JOIN cmreporting.d_case dc ON ds.solution_sqn = dc.solution_sqn\n  WHERE dc.case_id = a_identifiers.group_ID)\nAND group_ID = parms.case_ID\nGROUP BY group_ID\n']], ['Need multiple maxdates-oracle sql developer 4.0.2'], 2, 1], [(36468687, 0), [['Use a loop to iterate through the results of your query.'], ['c#:']], [[" SELECT EmailAddress \nFROM Customers` \nWHERE EmailFlag = 'true'` \nAND DATEDIFF(day, GETDATE(),DateOfVisit) >= 90;\n"]], ['How to perform an action on one result at a time in a sql query return that should return multiple results?'], 2, 1], [(36468687, 1), [['c#:'], ['This is just a draft. You should replace the comments with the actual code to make it work. No need to fetch from your initial query 1 result at a time.']], [[' foreach(DataRow dr in queryResult.Tables[0].Rows)\n{\n   string email = dr["EmailAddress"].ToString();\n   // Code to send email\n   //Execute Query UPDATE Customers SET EmailFlag = False WHERE EmailAddress = email \n}\n']], ['How to perform an action on one result at a time in a sql query return that should return multiple results?'], 2, 0], [(36478669, 0), [['If you are using  SQL Server  you could split and calculate sum:'], ['Output:']], [[" CREATE TABLE tab(ID INT IDENTITY(1,1), col VARCHAR(1000));\n\nINSERT INTO tab(col) VALUES('5212667+5212662'),('1+2+3'),('2'), (NULL), ('1+-1');\n\nSELECT *\nFROM tab\nCROSS APPLY (\n    SELECT [result] = SUM( Split.a.value('.', 'BIGINT'))\n    FROM (SELECT [X] = CAST ('<M>'+REPLACE(col, '+', '</M><M>') + '</M>' AS XML)) AS A \n    CROSS APPLY X.nodes ('/M') AS Split(a)\n) AS s;\n"]], ['SQL: converting a + separated list to an integer'], 2, 1], [(36478669, 1), [['Output:'], ['-10000']], [[' ╔════╦═════════════════╦══════════╗\n║ ID ║       col       ║  result  ║\n╠════╬═════════════════╬══════════╣\n║  1 ║ 5212667+5212662 ║ 10425329 ║\n║  2 ║ 1+2+3           ║ 6        ║\n║  3 ║ 2               ║ 2        ║\n║  4 ║ NULL            ║ NULL     ║\n║  5 ║ 1+-1            ║ 0        ║\n╚════╩═════════════════╩══════════╝\n']], ['SQL: converting a + separated list to an integer'], 2, 0], [(36510415, 0), [['Can you do something like this?'], ['But you can re-factor your database so you merge the newspapers and magazines tables into a single table (which you can then easily reference); like this:']], [[' CREATE TABLE subscription (\n  custID     INT\n             CONSTRAINT subscription__custid__fk REFERENCES Customer( CustomerId ),\n  name       VARCHAR2(50)\n             CONSTRAINT subscription__mag_name__fk REFERENCES Magazine( Name )\n             CONSTRAINT subscription__news_name__fk REFERENCES Newspaper( Name ),\n  startdate  DATE\n             CONSTRAINT subscription__startdate__nn NOT NULL,\n  enddate    DATE\n);\n']], ['one attribute referencing, attributes in two different tables'], 2, 1], [(36518328, 1), [['This also prevents an "accident" in the  where  clause.  If you change this:'], ['to:']], [[' where condition x or condition y\n']], ['Readable "always false" evaluation in TSQL'], 3, 0], [(36518328, 2), [['to:'], ['The parentheses are wrong.']], [[' where 1 = 0 and condition x or condition y\n']], ['Readable "always false" evaluation in TSQL'], 3, 0], [(36535515, 0), [['You can use the in clause  in where clause '], ['or you can use in join condition ']], [[" SELECT \nstudent_record.id,\nSUM(courses.crd * grades.points) AS sum_grade_credits\nFROM grades \nINNER JOIN student_record ON grades.letter = student_record.grade\nINNER JOIN courses ON courses.course_no = student_record.course_no \nWHERE student_record.id=2255\nAND student_record.grade not in ('NP', 'NF');\n"]], ['how to use not in clause with SUM clause in SQL'], 2, 1], [(36535515, 1), [['or you can use in join condition '], ['-10000']], [[" SELECT \nstudent_record.id,\nSUM(courses.crd * grades.points) AS sum_grade_credits\nFROM grades \nINNER JOIN student_record ON (grades.letter = student_record.grade \n  and student_record.grade  not in ( 'NP', 'NF'))\nINNER JOIN courses ON courses.course_no = student_record.course_no \nWHERE student_record.id=2255;\n"]], ['how to use not in clause with SUM clause in SQL'], 2, 1], [(36550777, 0), [['In MySQL:'], ['In SQL Server:']], [[' SELECT  o.*,\n        AVG(answer_3)\nFROM    surveyUserResponse sur\nJOIN    workshops w\nUSING   (survey_id)\nJOIN    organizers o\nUSING   (organizer_id)\nGROUP BY\n        organizer_id\n']], ['Average rating from SQL database survey data'], 2, 1], [(36550777, 1), [['In SQL Server:'], ['-10000']], [[' SELECT  *\nFROM    organizers o\nCROSS APPLY\n        (\n        SELECT  AVG(answer_3)\n        FROM    workshops w\n        JOIN    surveyUserResponse sur\n        ON      sur.survey_id = w.survey_id\n        WHERE   w.organizer_id = o.organizer_id\n        ) q (rating)\n']], ['Average rating from SQL database survey data'], 2, 1], [(36569182, 0), [['This should get what you want:'], ["Alternatively you could do it with a sub-query if it makes subsequent alterations easier, though generally speaking these don't perform as well:"]], [[' select A.Name, B.Surname, count(*), C.Pages\n  from TableA\n       Join TableB on A.Number = B.Number\n       Join TableC on A.Number = C.Number\ngroup by A.Name, B.Surname, C.Pages;\n']], ['SQL distinct values in multiple tables'], 2, 1], [(36569182, 1), [["Alternatively you could do it with a sub-query if it makes subsequent alterations easier, though generally speaking these don't perform as well:"], ['-10000']], [[' select A.Name, B.Surname,\n       (select count(*)\n          from TableBB\n         where B.Number = A.Number) As CNT,\n       C.Pages\n  from TableA\n       Join TableC on A.Number = C.Number;\n']], ['SQL distinct values in multiple tables'], 2, 1], [(36572728, 0), [['Try using conditional aggregation using  CASE EXPRESSION  . Your idea is correct, you need to join first all three tables, and then as you can see I joined to manager tables on  m.manager_id IN(s.manager_id,r.manager_id,c.manager_id)  . The aggregation after is to pivot the output since there will be 3 records for each name, containing manager_name for each one of the tables.'], ["If  you can have missing data - nulls on any of the site_table id columns, which doesn't sound very reasonable by the data you provided and even by the idea of this structure, then use a left join"]], [[' SELECT s.name,\n      MAX(CASE WHEN s.manager_id = m.manager_id THEN m.name END) as GM_NAME,\n      MAX(CASE WHEN r.manager_id= m.manager_id THEN m.name END) as RM_NAME,\n      MAX(CASE WHEN c.manager_id = m.manager_id THEN m.name END) as CM_NAME\nFROM site_table s\nINNER JOIN region_table r ON(s.region_id = r.region_id)\nINNER JOIN country_table c ON(s.country_id = c.country_id)\nINNER JOIN manager_table m ON(m.manager_id IN(s.manager_id,r.manager_id,c.manager_id))\nGROUP BY s.name\n']], ['Joining one table through other tables to another'], 2, 1], [(36572728, 1), [["If  you can have missing data - nulls on any of the site_table id columns, which doesn't sound very reasonable by the data you provided and even by the idea of this structure, then use a left join"], ['-10000']], [[' SELECT s.name,\n      MAX(CASE WHEN s.manager_id = m.manager_id THEN m.name END) as GM_NAME,\n      MAX(CASE WHEN r.manager_id= m.manager_id THEN m.name END) as RM_NAME,\n      MAX(CASE WHEN c.manager_id = m.manager_id THEN m.name END) as CM_NAME\nFROM site_table s\nLEFT JOIN region_table r ON(s.region_id = r.region_id)\nLEFT JOIN country_table c ON(s.country_id = c.country_id)\nLEFT JOIN manager_table m ON(m.manager_id IN(s.manager_id,r.manager_id,c.manager_id))\nGROUP BY s.name\n']], ['Joining one table through other tables to another'], 2, 1], [(36583115, 0), [['You could always simulate  ROW_NUMBER :'], ['Output:']], [[' WITH cte AS\n(\n     SELECT *,\n           (SELECT COUNT(*) + 1 \n            FROM "events" e1\n            WHERE e1.event_type = e.event_type\n              AND e1.time > e.time) AS rn\n     FROM "events" e\n)\nSELECT c.event_type, c."value" - c2."value" AS "value"\nFROM cte c\nJOIN cte c2\n  ON c.event_type = c2.event_type\n AND c.rn = 1 AND c2.rn = 2\nORDER BY event_type, time;\n']], ['SQLite difference between latest and second latest row'], 2, 1], [(36583115, 1), [['Output:'], ['-10000']], [[' ╔═══════════════╦═══════╗\n║ event_type    ║ value ║\n╠═══════════════╬═══════╣\n║            2  ║    -5 ║\n║            3  ║     4 ║\n╚═══════════════╩═══════╝\n']], ['SQLite difference between latest and second latest row'], 2, 0], [(36586811, 0), [['I think you just need a  where  clause.  For the filtering:'], ["I'm not sure what you want to return when both  column3  and  column4  meet the respective conditions, but I think this is what you want:"]], [[" select t.*\nfrom data_tbl t\nwhere (column2 = 'Condition_1') and\n      (column3 = 'Condition_2' or column4 = 'Condition_3);\n"]], ['Select statement subquery, multiple conditions'], 2, 1], [(36586811, 1), [["I'm not sure what you want to return when both  column3  and  column4  meet the respective conditions, but I think this is what you want:"], ['-10000']], [[" select (case when column3 = 'Condition_2' then column3 else column4 end)\nfrom data_tbl t\nwhere (column2 = 'Condition_1') and\n      (column3 = 'Condition_2' or column4 = 'Condition_3);\n"]], ['Select statement subquery, multiple conditions'], 2, 1], [(36598033, 0), [['That sounds like a job for  EXISTS()  which will check if a record with the same (column1,column2) exists.'], ['Can also be done with an  INNER JOIN  :']], [[' SELECT * FROM Table1 t\nWHERE EXISTS(SELECT 1 FROM Table2 s\n             WHERE t.column1 = s.column1 and t.column2 = s.column2)\n']], ['Mysql select * FROM table_one WHERE columns_one and columns_two in tables one and 2 have the same data'], 2, 1], [(36598033, 1), [['Can also be done with an  INNER JOIN  :'], ['-10000']], [[' SELECT t.* FROM Table1 t\nINNER JOIN Table2 s\n ON(t.column1 = s.column1 and t.column2 = s.column2)\n']], ['Mysql select * FROM table_one WHERE columns_one and columns_two in tables one and 2 have the same data'], 2, 1], [(36650818, 0), [["The following will delete all rows that are not themselves parents. If the table is big and there's no index on ParentCommentID, it might take a while to run..."], ['If the table is truly large, a big delete can do bad things to your system, such as locking the table and bloating the transaction log file. The following will limit just how many rows will be deleted:']], [[' DELETE Comment\n from Comment co\n where not exists (--  Correlated subquery\n                   select 1\n                    from Comment\n                    where ParentCommentID = co.ID)\n']], ['SQL delete records in order'], 3, 1], [(36650818, 1), [['If the table is truly large, a big delete can do bad things to your system, such as locking the table and bloating the transaction log file. The following will limit just how many rows will be deleted:'], ["As deleting some but not all might not be so useful, here's a looping structure that will keep going until everything's gone:"]], [[' DELETE top (1000) Comment  --  (1000 is not very many)\n from Comment co\n where not exists (--  Correlated subquery\n                   select 1\n                    from Comment\n                    where ParentCommentID = co.ID)\n']], ['SQL delete records in order'], 3, 1], [(36650818, 2), [["As deleting some but not all might not be so useful, here's a looping structure that will keep going until everything's gone:"], ["This last, of course, is dangerous (note the begin/end transaction used for testing!) You'll want  WHERE  clauses to limit what gets deleted, and something or to ensure you don't somehow hit an infinite loop--all details that depend on your data and circumstances."]], [[' DECLARE @Done int = 1\n\n--BEGIN TRANSACTION\n\nWHILE @Done > 0\n BEGIN\n    --  Loop until nothing left to delete\n    DELETE top (1000) Comment\n     from Comment co\n     where not exists (--  Correlated subquery\n                       select 1\n                        from Comment\n                        where ParentCommentID = co.ID)\n    SET @Done = @@Rowcount\n\n END\n\n--ROLLBACK\n']], ['SQL delete records in order'], 3, 1], [(36741708, 0), [['You can use cte for that count:'], ['Output be like:']], [[" DECLARE\n@DateTime1 datetime = '2016-04-20 13:30',\n@DateTime2 datetime = '2016-04-21 07:15'\n\n;WITH times AS(\nSELECT  @DateTime1 as d,\n        CASE WHEN DATEPART(hour,@DateTime1) between 6 and 22 then 'd' else 'n' end as a,\n        0 as m\nUNION ALL\nSELECT  DATEADD(minute,1,d),\n        CASE WHEN DATEPART(hour,DATEADD(minute,1,d)) between 6 and 22 then 'd' else 'n' end as a,\n        DATEDIFF(minute,d,DATEADD(minute,1,d)) \nFROM times\nWHERE DATEADD(minute,1,d) <= @DateTime2\n)\n\nSELECT  CASE WHEN a = 'd' THEN 'DayTime' ELSE 'NightTime' END as TimePart,\n        sum(m)/60 as H,\n        sum(m) - (sum(m)/60)* 60 as M\nFROM times\nGROUP BY a\nOPTION (MAXRECURSION 0)\n"]], ['SQL calculate DayTime and NightTime between two DateTime values'], 2, 1], [(36741708, 1), [['Output be like:'], ['-10000']], [[' TimePart  H           M\n--------- ----------- -----------\nDayTime   10          45\nNightTime 7           0\n\n(2 row(s) affected)\n']], ['SQL calculate DayTime and NightTime between two DateTime values'], 2, 0], [(36770316, 0), [['Hmmm . . .  One way uses aggregation:'], ['However, assuming you have an  a  table, then I prefer this method:']], [[' select a_id\nfrom t\ngroup by a_id\nhaving sum(case when b_id not in (1, 2, 3, 4, 5) then 1 else 0 end) = 0;\n']], ['Select from cross-reference based on inclusion (column values being subset)'], 2, 1], [(36770316, 1), [['However, assuming you have an  a  table, then I prefer this method:'], ['This saves the expense of aggregation and the lookup can take advantage of an appropriate index (on  t(a_id, b_id) ) so this should have better performance.']], [[' select a_id\nfrom a\nwhere not exists (select 1\n                  from t\n                  where t.a_id = a.a_id and t.b_id not in (1, 2, 3, 4, 5)\n                 );\n']], ['Select from cross-reference based on inclusion (column values being subset)'], 2, 1], [(36834990, 0), [['After first  insert  you have to use  update  statement. like this:'], ['OR you can do this just as one  insert :']], [[" update schedule \nset place='Room A'\n"]], ['Insert in SQL from a certain date'], 2, 1], [(36834990, 1), [['OR you can do this just as one  insert :'], ['-10000']], [[" INSERT INTO schedule (date, place)\n  VALUES\n  ('2016-05-16 13:00:00','Room A'),\n  ('2016-05-16 14:00:00','Room A'),\n  ('2016-05-16 15:00:00','Room A'),\n  ('2016-05-16 16:00:00','Room A'),\n  ('2016-05-16 17:00:00','Room A'),\n  ('2016-05-17 13:00:00','Room A'),\n  ('2016-05-17 14:00:00','Room A'),\n  ('2016-05-17 15:00:00','Room A'),\n  ('2016-05-17 16:00:00','Room A'),\n  ('2016-05-17 17:00:00','Room A'),\n  ('2016-05-18 13:00:00','Room A'),\n  ('2016-05-18 14:00:00','Room A'),\n  ('2016-05-18 15:00:00','Room A'),\n  ('2016-05-18 16:00:00','Room A'),\n  ('2016-05-18 17:00:00','Room A'),\n  ('2016-05-19 13:00:00','Room A'),\n  ('2016-05-19 14:00:00','Room A'),\n  ('2016-05-19 15:00:00','Room A'),\n  ('2016-05-19 16:00:00','Room A'),\n  ('2016-05-19 17:00:00','Room A');\n"]], ['Insert in SQL from a certain date'], 2, 1], [(36909436, 0), [["andFilterWhere  and  orFilterWhere  doesn't allow nesting this way since they operate on the query object - not on a condition object. You could define your query this way:"], ['You can even put it all into one  where  method call:']], [[" $query->where(\n    ['and',\n        [\n            'between',\n            'str_to_date(\\'' . $this->dateRecherche . '\\', \\'%d/%m/%Y %H:%i\\')',\n            new Expression('str_to_date(erDateDebut, \\'%d/%m/%Y %H:%i\\')'),\n            new Expression('str_to_date(erDateFin, \\'%d/%m/%Y %H:%i\\')'),\n        ],\n        [\n            'not', ['erDateFin' => null],\n        ]\n    ]);\n\n$query->orWhere(\n    ['and',\n        [\n            'between',\n            'str_to_date(\\'' . $this->dateRecherche . '\\', \\'%d/%m/%Y %H:%i\\')',\n            new Expression('str_to_date(erDateDebut, \\'%d/%m/%Y %H:%i\\')'),\n            new Expression('now()'),\n        ],\n        [\n            'is', 'erDateFin', null,\n        ]\n    ]);\n"]], ['yii2 how to create and condition in another one'], 3, 1], [(36909436, 1), [['You can even put it all into one  where  method call:'], ['As you probably already know, count can be done with']], [[" $query->where(\n    ['or',\n        ['and',\n            [\n                'between',\n                'str_to_date(\\'' . $this->dateRecherche . '\\', \\'%d/%m/%Y %H:%i\\')',\n                new Expression('str_to_date(erDateDebut, \\'%d/%m/%Y %H:%i\\')'),\n                new Expression('str_to_date(erDateFin, \\'%d/%m/%Y %H:%i\\')'),\n            ],\n            [\n                'not', ['erDateFin' => null],\n            ]\n        ],\n        ['and',\n            [\n                'between',\n                'str_to_date(\\'' . $this->dateRecherche . '\\', \\'%d/%m/%Y %H:%i\\')',\n                new Expression('str_to_date(erDateDebut, \\'%d/%m/%Y %H:%i\\')'),\n                new Expression('now()'),\n            ],\n            [\n                'is', 'erDateFin', null,\n            ]\n        ]\n    ]);\n"]], ['yii2 how to create and condition in another one'], 3, 1], [(36909436, 2), [['As you probably already know, count can be done with'], ['-10000']], [[' $count = $query->count();\n']], ['yii2 how to create and condition in another one'], 3, 0], [(36921158, 0), [['I found one way of getting the desired results, by writing a row_number() sub select limit to the desired window size. Which gives each entry per date s.th like this'], ['In the next step one can use ']], [[' Date         Name      Value    Row_Num\n---------------------------------------\n2015-01-01    A         12        0\n2015-01-01    A         12        1\n2015-01-01    A         12        2\n2015-01-01    A         12        3\n']], ['JOIN multiple rows to multiple columns in single row Netezza/Postgres'], 2, 0], [(36921158, 1), [['In the next step one can use '], ['which then can be joined on the initial table and pivoted. This will allow for any arbitrary combination of Names per date. ']], [[" (Date + Row_Num*INTERVAL'1 DAY')::DATE \n"]], ['JOIN multiple rows to multiple columns in single row Netezza/Postgres'], 2, 0], [(36936128, 0), [['Although you can fiddle around with conversion codes, just use replace:'], ["Or, if you don't want to be dependent on the local date format:"]], [[" REPLACE(CONVERT(NVARCHAR(255), Column_1) + CONVERT(NVARCHAR(255), Column_2), '-', '') AS TEST\n"]], ['Convert date to nvarchar and merge two columns'], 2, 1], [(36936128, 1), [["Or, if you don't want to be dependent on the local date format:"], ['-10000']], [[' CONVERT(NVARCHAR(255), Column_1, 112) + CONVERT(NVARCHAR(255), Column_2, 112) AS TEST\n']], ['Convert date to nvarchar and merge two columns'], 2, 1], [(36988239, 0), [['-10000'], ['Output:']], [[" WITH cte AS\n(\n   SELECT DISTINCT ID, (DENSE_RANK() OVER(ORDER BY ID) - 1)/3 AS grp \n   FROM #Temp\n)\nSELECT DISTINCT STUFF((SELECT ',' + ID\n                       FROM cte T1\n                       WHERE T1.grp = T2.grp\n                       ORDER BY ID\n                       FOR XML PATH('')\n                       ), 1, 1, '') ID\nFROM cte T2;\n"]], ['T-SQL- Concatenate variable # of rows'], 2, 1], [(36988239, 1), [['Output:'], ['-10000']], [[' ╔═════════════╗\n║     ID      ║\n╠═════════════╣\n║ 123,234,345 ║\n║ 456,567,678 ║\n║ 789,890,901 ║\n╚═════════════╝\n']], ['T-SQL- Concatenate variable # of rows'], 2, 0], [(36989059, 0), [['-10000'], ['To explicitly perform string to numeric casting :']], [[" select * from workpaths where to_char(wp_stime,'hh24') between 9 and 16; \n"]], ['oracle database: select between certain time of the day'], 2, 1], [(36989059, 1), [['To explicitly perform string to numeric casting :'], ['-10000']], [[" select * from workpaths where to_number(to_char(wp_stime,'hh24')) between 9 and 16; \n"]], ['oracle database: select between certain time of the day'], 2, 1], [(37009235, 0), [['You are looking for this'], ['or Case can be simplified by  Coalesce/Isnull  function']], [[' SELECT\nCASE WHEN P1 IS NOT NULL THEN P1 ELSE P2 END AS P,\nCOUNT(SomeData) AS Counts\nFROM MyTable\nGROUP BY CASE WHEN P1 IS NOT NULL THEN P1 ELSE P2 END\n']], ['SQL Query query matching columns and counting rows'], 2, 1], [(37009235, 1), [['or Case can be simplified by  Coalesce/Isnull  function'], ['-10000']], [[' SELECT\nCOALESCE(P1,P2) AS P,\nCOUNT(SomeData) AS Counts\nFROM MyTable\nGROUP BY COALESCE(P1,P2)\n']], ['SQL Query query matching columns and counting rows'], 2, 1], [(37064962, 0), [['Try this'], ['Result:']], [[" DECLARE @a varchar(500), @v varchar(500)\nSET @a='MALTON ROAD WICKLOW EIRE'\nSELECT @v = LTRIM(RTRIM(SUBSTRING(@a,1,charindex('EIRE',@a)-1)))\nSELECT REVERSE( LEFT( REVERSE(@v), \n            ISNULL(NULLIF(CHARINDEX(' ', REVERSE(@v)),0)-1,LEN(@v)) ) )\n"]], ['Get the word before particular word in sql'], 2, 1], [(37064962, 1), [['Result:'], ['-10000']], [[' DATA                        RESULT\n-----------------------------------\nMALTON EIRE                 MALTON\nMALTON ROAD WICKLOW EIRE    WICKLOW\n']], ['Get the word before particular word in sql'], 2, 0], [(37084523, 0), [['Group by a case statement that selects the pairs in alphabetical order:'], ['If you simply want unique values (as opposed to a grouping for aggregation) then you can use  distinct  instead of  group by']], [[" select case when col1 < col2 then col1 else col2 end as col1,\ncase when col1 < col2 then col2 else col1 end as col2\nfrom (\n    select 'a' as col1, 'b' as col2\n    union all\n    select 'b', 'a'\n    union all\n    select 'c', 'd'\n    union all\n    select 'a', 'c'\n    union all\n    select 'a', 'd'\n    union all\n    select 'b', 'c'\n    union all\n    select 'd', 'a'\n) t group by case when col1 < col2 then col1 else col2 end,\ncase when col1 < col2 then col2 else col1 end\n"]], ['Grouping of pairs in sql'], 2, 1], [(37084523, 1), [['If you simply want unique values (as opposed to a grouping for aggregation) then you can use  distinct  instead of  group by'], ['-10000']], [[" select distinct case when col1 < col2 then col1 else col2 end as col1,\ncase when col1 < col2 then col2 else col1 end as col2\nfrom (\n    select 'a' as col1, 'b' as col2\n    union all\n    select 'b', 'a'\n    union all\n    select 'c', 'd'\n    union all\n    select 'a', 'c'\n    union all\n    select 'a', 'd'\n    union all\n    select 'b', 'c'\n    union all\n    select 'd', 'a'\n) t\n"]], ['Grouping of pairs in sql'], 2, 1], [(37088208, 0), [['EDIT: in your case I think the query below should work'], ["or if you're using SQL Server 2012 or later,  this should run quicker:"]], [[' WITH    \nrows AS (\n        SELECT  *, ROW_NUMBER() OVER (ORDER BY gps_time) AS rn\n        FROM    rawtTackHistory_A2Z where car_id = 12956 \n),\ndifferences AS (\n    SELECT  mc.rn, mc.gps_time,DATEDIFF(second, mc.gps_time, mp.gps_time) time_diff\n    FROM    rows mc\n    JOIN    rows mp\n    ON      mc.rn = mp.rn - 1\n)\nSELECT t1.gps_time, t1.time_diff, SUM(t2.time_diff) time_sum\nFROM differences t1\nINNER JOIN differences t2 \nON t1.rn >= t2.rn\nGROUP BY t1.rn, t1.gps_time, t1.time_diff\nORDER BY t1.rn\n']], ['how to add data two colums add after add two add next'], 2, 1], [(37088208, 1), [["or if you're using SQL Server 2012 or later,  this should run quicker:"], ["It's using a windowing clause ( OVER ).  More detail here:  https://msdn.microsoft.com/en-us/library/ms189461.aspx"]], [[' SELECT gps_time\n     , DATEDIFF(second, LAG(gps_time) OVER (ORDER BY gps_time), gps_time) time_diff\n     , DATEDIFF(second, MIN(gps_time) OVER (ORDER BY gps_time), gps_time) time_sum\nFROM rawtTackHistory_A2Z \nORDER BY gps_time\n']], ['how to add data two colums add after add two add next'], 2, 1], [(37109635, 0), [['DATA  -'], ['QUERY 1']], [[' +-------+--------+-----------+------+-------------+------+------+--------+\n| EMPNO | ENAME  |    JOB    | MGR  |  HIREDATE   | SAL  | COMM | DEPTNO |\n+-------+--------+-----------+------+-------------+------+------+--------+\n|  7369 | SMITH  | CLERK     | 7902 | 17/Dec/1980 |  800 |      |     20 |\n|  7499 | ALLEN  | SALESMAN  | 7698 | 20/Feb/1981 | 1600 |  300 |     30 |\n|  7521 | WARD   | SALESMAN  | 7698 | 22/Feb/1981 | 1250 |  500 |     30 |\n+-------+--------+-----------+------+-------------+------+------+--------+\n']], ['MIN on a date field'], 5, 0], [(37109635, 1), [['QUERY 1'], ['RESULT 1  ']], [[" select MIN(TO_DATE(hiredate, 'DD-Mon-YY')) from emp;\n"]], ['MIN on a date field'], 5, 0], [(37109635, 2), [['RESULT 1  '], ['QUERY 2']], [[' 17/12/2080\n']], ['MIN on a date field'], 5, 0], [(37109635, 4), [['RESULT 2'], ['As you can see the century is messed up when you use  TO_DATE  function in QUERY 1. However, the result is as expected in QUERY 2']], [[' 17/12/1980\n']], ['MIN on a date field'], 5, 0], [(37111927, 1), [['Sample Code'], ['Result']], [[" CREATE TYPE varchar_tab_t AS TABLE OF VARCHAR2(30);\n/\n\n\nCREATE OR REPLACE function MY_FUNCTION (sqlstring in varchar2) return varchar_tab_t IS\n v_values_tab varchar_tab_t;\nBEGIN\n\n  EXECUTE IMMEDIATE sqlstring bulk collect into v_values_tab;\n  return v_values_tab;  \nEND MY_FUNCTION;\n/\n\n\nwith table_a (id, SQL_STATEMENT) as \n  (select 1, 'Select 1 from dual union select 2 from dual union select 3 from dual' from dual)\n, table_b (id, value) as \n  (            select 1, 1 from dual \n    union  all select 1, 2 from dual \n    union  all select 1, 5 from dual -- this one should not be shown\n   )  \n SELECT *\n   FROM table_B, table_A \n   WHERE table_B.id = table_A.id\n     AND table_B.value IN (select column_value from Table(MY_FUNCTION(Table_A.SQL_Statement)))\n"]], ['Oracle sql execute sql from varchar field'], 3, 1], [(37111927, 2), [['Result'], ['-10000']], [[' 1   1   1   Select 1 from dual union select 2 from dual union select 3 from dual\n1   2   1   Select 1 from dual union select 2 from dual union select 3 from dual\n']], ['Oracle sql execute sql from varchar field'], 3, 0], [(37148559, 0), [['-10000'], ['Result :']], [['1) Get matrix select c1.class src_class, c2.class dst_class\nfrom (select distinct class from classes) c1\njoin (select distinct class from classes) c2\norder by src_class, dst_class\n']], ['Calculating overlap in MySQL'], 6, 0], [(37148559, 1), [['Result :'], ['-10000']], [[' src_class      dst_class\n-----------------------------\nalgebra        algebra\nalgebra        gym\nalgebra        world_history\ngym            algebra\ngym            gym\ngym            world_history\nworld_history  algebra\nworld_history  gym\nworld_history  world_history\n']], ['Calculating overlap in MySQL'], 6, 0], [(37148559, 2), [['-10000'], ['Result :']], [['2) Join list of students that match the source and destination select c1.class src_class, c2.class dst_class, count(v.student_id) overlap\nfrom (select distinct class from classes) c1\njoin (select distinct class from classes) c2\nleft join classes v on\n(\n    v.class = c1.class\n    and v.student_id in (select student_id from classes\n                         where class = c2.class)\n)\ngroup by src_class, dst_class\norder by src_class, dst_class\n']], ['Calculating overlap in MySQL'], 6, 0], [(37148559, 3), [['Result :'], ['-10000']], [[' src_class      dst_class      overlap\n-------------------------------------\nalgebra        algebra           7\nalgebra        gym               2\nalgebra        world_history     1\ngym            algebra           2\ngym            gym               5\ngym            world_history     2\nworld_history  algebra           1\nworld_history  gym               2\nworld_history  world_history     6\n']], ['Calculating overlap in MySQL'], 6, 0], [(37148559, 4), [['-10000'], ['Result :']], [['3 - Make a different calcul if classes are equals select c1.class src_class, c2.class dst_class, count(v.student_id) overlap\nfrom (select distinct class from classes) c1\njoin (select distinct class from classes) c2\nleft join classes v on\n(\n    v.class = c1.class and\n    (\n        -- When classes are equals\n        -- Students presents only in that class\n        (c1.class = c2.class\n         and 1 = (select count(*) from classes\n                  where student_id = v.student_id))\n    or\n        -- When classes are differents\n        -- Students present in both classes\n        (c1.class != c2.class\n         and v.student_id in (select student_id from classes\n                              where class = c2.class))\n    )\n)\ngroup by src_class, dst_class\norder by src_class, dst_class\n']], ['Calculating overlap in MySQL'], 6, 0], [(37148559, 5), [['Result :'], ['-10000']], [[' src_class      dst_class      overlap\n-------------------------------------\nalgebra        algebra           5\nalgebra        gym               2\nalgebra        world_history     1\ngym            algebra           2\ngym            gym               2\ngym            world_history     2\nworld_history  algebra           1\nworld_history  gym               2\nworld_history  world_history     4\n']], ['Calculating overlap in MySQL'], 6, 0], [(37173392, 0), [['First of, to determine if your sample_id is a single value or a list of values:'], ['Then, to open up the list of ids in a comma-separated list of samples you can unnest the array returned by string_to_array:']], [[" -- (sample_id ~ '^ *\\d\\+ *$') returns true if there is one number only\nSELECT CASE WHEN sample_id ~ '^ *\\d\\+ *$' THEN sample_id::int END\n"]], ['PostgreSQL function check if field is CSV'], 2, 0], [(37173392, 1), [['Then, to open up the list of ids in a comma-separated list of samples you can unnest the array returned by string_to_array:'], ["You can use that for either single or multiple numbers (since there is just one value, you'll get only one row)."]], [[" SELECT i\nFROM unnest(string_to_array(sample_id, ',')::int[]) i\n"]], ['PostgreSQL function check if field is CSV'], 2, 0], [(37181919, 0), [["If you have a fixed character to replace ( 's' in your example) you can use this:"], ['You can even use regexp to count the occurrences for you:']], [[" with test(string) as ( select 'Root#root#abc#test#stest#s#beta#402' from dual)\nselect regexp_replace(string, '(.*)#(.*)#(.*)#(.*)#(.*)#s', '\\1#\\2#\\3#\\4#\\5#S')\nfrom test\n"]], ['Oracle SQL replace Character'], 3, 1], [(37181919, 1), [['You can even use regexp to count the occurrences for you:'], ['With a different approach, without regexp, you can try:']], [[" select regexp_replace(string, '(([^#]*#){5,5})s', '\\1S')\nfrom test\n"]], ['Oracle SQL replace Character'], 3, 1], [(37181919, 2), [['With a different approach, without regexp, you can try:'], ["This simply cuts the string in 3 parts (from the begigging to the 5th '#', the following character, the remaining part) and does  upper  of the character.\nThis can handle different characters, with no need to hardcode 's'"]], [[" select substr(string, 1, instr(string, '#', 1, 5) ) ||\n       upper(substr(string, instr(string, '#', 1, 5)+1, 1)) ||\n       substr(string, instr(string, '#', 1, 5) + 2)\nfrom test\n"]], ['Oracle SQL replace Character'], 3, 1], [(37247507, 1), [['MySQL 5.6 Schema :'], ['Query 1 :']], [[' CREATE TABLE IF NOT EXISTS `tablea` (\n  `value` int(11) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\nINSERT INTO `tablea` (`value`) VALUES\n    (1),\n    (2),\n    (3),\n    (4),\n    (5),\n    (6);\n\nCREATE TABLE IF NOT EXISTS `tableb` (\n  `value` int(11) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT;\n\nINSERT INTO `tableb` (`value`) VALUES\n    (1),\n    (2),\n    (7),\n    (8),\n    (9),\n    (0);\n']], ['Data Base Query - I have a two table A and B. I have to fetch the data only from'], 4, 0], [(37247507, 3), [['Results :'], ['-10000']], [[' | value |\n|-------|\n|     3 |\n|     4 |\n|     5 |\n|     6 |\n']], ['Data Base Query - I have a two table A and B. I have to fetch the data only from'], 4, 0], [(37270805, 0), [['Query - Use a recursive sub-query factoring clause :'], ['Query - Hierarchical Query :']], [[" WITH table_name ( list ) AS (\n  SELECT '1,2,3,4,5,6' FROM DUAL\n),\nrsqfc ( list ) AS (\n  SELECT list FROM table_name\n  UNION ALL\n  SELECT SUBSTR( list, INSTR( list, ',', -1 ) -1 )\n  FROM   rsqfc\n  WHERE  INSTR( list, ',', -1 ) > 0\n)\nSELECT * FROM rsqfc;\n"]], ['Oracle substring table based on hierarchy'], 3, 1], [(37270805, 1), [['Query - Hierarchical Query :'], ['(Both output the same)']], [[" WITH table_name ( list ) AS (\n  SELECT '1,2,3,4,5,6' FROM DUAL\n)\nSELECT CASE LEVEL\n            WHEN 1 THEN list\n            ELSE SUBSTR( list, 1, INSTR( list, ',', -1, LEVEL - 1 ) - 1 )\n            END AS list\nFROM   table_name\nCONNECT BY INSTR( list, ',', -1, LEVEL - 1 ) > 0;\n"]], ['Oracle substring table based on hierarchy'], 3, 1], [(37270805, 2), [['(Both output the same)'], ['-10000']], [[' list\n------------\n1,2,3,4,5,6\n1,2,3,4,5\n1,2,3,4\n1,2,3\n1,2\n1\n']], ['Oracle substring table based on hierarchy'], 3, 0], [(37303429, 0), [['TRY '], ['OR something like this.']], [[' ORDER BY COALESCE(clearedTime, alarmTime)\n']], ['Postgres Order by multi columns with a condition'], 2, 1], [(37303429, 1), [['OR something like this.'], ['-10000']], [[' ORDER BY CASE \n             WHEN clearedTime IS NULL THEN NULL\n                                      ELSE 1 \n         END NULLS FIRST,\n         alarm.alarmTime DESC,\n         alarm.clearedTime DESC -- optional to solve tie between 415068 and 415073       \n']], ['Postgres Order by multi columns with a condition'], 2, 1], [(37316901, 0), [['Use a union all:'], ["EDIT:\nIn addition to @ThorstenKettner 's comment: If ID is not nummeric or for any reason you can not use it for the sort, then you could do it like this:"]], [[" select id, name from xxx -- is your query\nunion all\nselect 999 as id, 'XY Ltd' as name \n"]], ['How do I append a row with specific values to the output of my T-SQL query?'], 2, 1], [(37316901, 1), [["EDIT:\nIn addition to @ThorstenKettner 's comment: If ID is not nummeric or for any reason you can not use it for the sort, then you could do it like this:"], ['-10000']], [[" select ID, Name\nfrom \n(\n    select 1 as SpecialSort, ID, Name from xxx -- is your query\n    union all\n    select 2 as SpecialSort, 999 as ID, 'XY Ltd' as Name\n) AllData\norder by SpecialSort asc -- like this your manually added row will appear at the end\n"]], ['How do I append a row with specific values to the output of my T-SQL query?'], 2, 1], [(37405073, 0), [["Remove  $  from  '%$Keurig%' . Try this"], ['With  $searchtag  try somthing like this']], [[" SELECT I.itemName,P.firstName,P.lastName\n  FROM `ITEM` I, `PROFILE` P\n  WHERE I.pID=P.pID AND I.itemName LIKE '%Keurig%'\n"]], ['SQL LIKE from multiple table'], 2, 1], [(37405073, 1), [['With  $searchtag  try somthing like this'], ['-10000']], [[' $sql = "SELECT I.itemName,P.firstName,P.lastName\n  FROM `ITEM` I, `PROFILE` P\n  WHERE I.pID=P.pID AND I.itemName LIKE \'%".$searchtag."%\'";\n']], ['SQL LIKE from multiple table'], 2, 1], [(37449748, 0), [["Here is how you add a column to a table. I'm assuming projectNbr is an integer:"], ['Then to fill your new column from the Importthis table, it would look something like this:']], [[' ALTER TABLE dbo.WTS_EXT_Project ADD COLUMN projectNbr INT\n']], ['SQL Joining and Update'], 2, 0], [(37452178, 1), [['Then it is simple to get the rows:'], ['-10000']], [[" SELECT ID, NAME, COLOR\nFROM PEOPLE\nWHERE  id, name in (\n    SELECT ID, NAME\n    FROM PEOPLE\n    WHERE  INSTR(:COLORS, WARECOLOR) > 0\n    GROUP ID, NAME\n    HAVING COUNT(*) = regexp_count(:COLORS,'[|]') - 1 ;\n )\n;\n"]], ['How can I use AND condition using array parameter in a query'], 2, 0], [(37458399, 0), [['-10000'], ['Let say the table is status as below']], [[' Select status, count(*)\nfrom Ticket\ngroup by status\n']], ['Count all rows by status'], 3, 1], [(37458399, 1), [['Let say the table is status as below'], ['The query will be']], [[' CREATE TABLE _STATUS(\n  STATUS INTEGER,\n STATUS_NAME TEXT\n)\n;\n\nCREATE TABLE TICKET(\n ID INTEGER NOT NULL,\n TITLE TEXT,\n STATUS INTEGER,\n LAST_UPDATED DATE,\n CREATED DATE\n)\n;\n']], ['Count all rows by status'], 3, 0], [(37458399, 2), [['The query will be'], ['-10000']], [[' select  s.status,COUNT(t.*)\nfrom _status t left join ticket t\non s.status = t.status\ngroup by s.status\n']], ['Count all rows by status'], 3, 1], [(37540721, 0), [['Just use  CASE EXPRESSION  , I prefer it as it is easier to read:'], ["EDIT:  If you want to order first by if one of them is 'R', then if one of the columns is 'Y' ..."]], [[" ORDER BY CASE WHEN FC = 'R' THEN 1\n              WHEN FC = 'Y' THEN 2\n              WHEN FC = 'G' THEN 3\n         END,\n         CASE WHEN FM = 'R' THEN 1\n              WHEN FM = 'Y' THEN 2\n              WHEN FM = 'G' THEN 3\n         END,\n         CASE WHEN MS = 'R' THEN 1\n              WHEN MS = 'Y' THEN 2\n              WHEN MS = 'G' THEN 3\n         END\n"]], ['Concatenate in order by using decode in Oracle'], 2, 1], [(37540721, 1), [["EDIT:  If you want to order first by if one of them is 'R', then if one of the columns is 'Y' ..."], ['-10000']], [[" ORDER BY CASE WHEN 'R' IN(FC,FM,MS) THEN 1\n              ELSE 2\n         END,\n         CASE WHEN 'Y' IN(FC,FM,MS) THEN 1\n              ELSE 2\n         END,\n         CASE WHEN 'G' IN(FC,FM,MS) THEN 1\n              ELSE 2\n         END\n"]], ['Concatenate in order by using decode in Oracle'], 2, 0], [(37585047, 0), [['Use  between :'], ['Sample execution with the given sample data:']], [[" DECLARE @date date = '2015-03-30'\n\nSELECT [Signature]\nFROM YourTable\nWHERE @date between [From] and [To]\n"]], ['TSQL - Search a date in database'], 2, 1], [(37611560, 0), [["It's Purely based on your sample Data "], ['In your query I have modified the Answer ']], [[" DECLARE @Table1 TABLE \n    (projName varchar(1), percentage int)\n;\n\nINSERT INTO @Table1\n    (projName, percentage)\nVALUES\n    ('A', 10),\n    ('A', 25),\n    ('B', 20),\n    ('B', 30)\n;\n\nSelect CASE WHEN RN = 1 THEN projName ELSE NULL END projName, percentage from (\nselect projName, percentage,ROW_NUMBER()OVER(PARTITION BY projName ORDER BY (SELECT NULL))RN from @Table1 )T\n"]], ['SQL query for display one field only once which having multiple record'], 2, 0], [(37611560, 1), [['In your query I have modified the Answer '], ['-10000']], [[' Select CASE WHEN T.RN = 1 THEN T.projName ELSE NULL END projName, T.percentage FROM  (select \ni.invoice_id,\npr.name as projname ,\nROW_NUMBER()OVER(PARTITION BY projName ORDER BY (SELECT NULL))RN\nfrom annexure a,\nproject pr,\nsow s,\ninvoice i \nwhere pr.project_id = s.project_id \nand a.sow_id = s.sow_id \nand i.annexure_id = a.annexure_id \ngroup by pr.name,i.invoice_date,i.invoice_id )T\n']], ['SQL query for display one field only once which having multiple record'], 2, 1], [(37620195, 0), [['It is common for analytic functions to be used through a derived table so that the column is produced and then accessed later by a subsequent clauses via the column alias. It is particularly common when needing to use row_number() results in a where clause. e.g.'], ['Here I believe the same logic applies, you want to calculate a sortorder column THEN place the data into an XML result. My guess is you want to partition by job number.']], [[' select * from (select *\n                  , row_number(partition by X order by Y) as rn\n               from table1\n               ) as d\nwhere d.rn = 1\n']], ['SQL ROW_NUMBER() always return 1 for each row'], 3, 0], [(37620195, 2), [['and as a full query:'], ['-10000']], [[' SELECT (\n        SELECT\n              CAST(\'<\' + V_CONSTAT_ACTUAL_DATES.JOB_NUMBER + \'>\' +\n              CAST((\n                    SELECT (\n                                 SELECT\n                                       CONVERT(date, d.DATE_TO_END) AS \'closingDate\'\n                                 FOR xml PATH (\'\'), TYPE\n                           )\n                         , (\n                                 SELECT\n                                       DATEDIFF(dd, d.ID67, V_CONSTAT_ACTUAL_DATES.DATE_TO_END) - 1 AS \'DaysOfConstruction\'\n                                 FOR xml PATH (\'\'), TYPE\n                           )\n                         , (\n                                 SELECT\n                                       DATEDIFF(dd, GETDATE(), d.DATE_TO_END) AS \'DaysToClosing\'\n                                 FOR xml PATH (\'\'), TYPE\n                           )\n                         , (\n                                 SELECT\n                                       CASE\n                                             WHEN COALESCE(d.IDNOTES2, \'\') = \'\' THEN \' \'\n                                             ELSE d.IDNOTES2\n                                       END AS \'notes\'\n                                 FOR xml PATH (\'\'), TYPE\n                           )\n                         , (\n                                 SELECT\n                                       DATEDIFF(dd, d.ID187, d.ID187) AS \'ScheduleVariance\'\n                                 FOR xml PATH (\'\'), TYPE\n                           )\n                         , (\n                                 SELECT\n                                       SortOrder\n                                 FROM (\n                                       SELECT\n                                             d.SortOrder\n                                 ) AS SubQuery\n                                 FOR xml PATH (\'\'), TYPE\n                           )\n\n\n                    FOR xml PATH (\'\')\n              )\n              AS varchar(max)\n\n              )\n              + \'</\' + V_CONSTAT_ACTUAL_DATES.JOB_NUMBER + \'>\'\n              AS xml)\n  )\nFROM (\n  SELECT\n        *\n      , ROW_NUMBER() OVER (PARTITION BY V_CONSTAT_ACTUAL_DATES.JOB_NUMBER\n                            ORDER BY V_CONSTAT_ACTUAL_DATES.DATE_TO_END) AS "SortOrder"\n  FROM homefront.dbo.V_CONSTAT_PROJ_DATES V_CONSTAT_PROJ_DATES\n        INNER JOIN homefront.dbo.V_CONSTAT_ACTUAL_DATES V_CONSTAT_ACTUAL_DATES ON V_CONSTAT_PROJ_DATES.JOB_NUMBER = V_CONSTAT_ACTUAL_DATES.JOB_NUMBER\n        INNER JOIN homefront.dbo.V_CONSTAT_BASE_DATES V_CONSTAT_BASE_DATES ON V_CONSTAT_ACTUAL_DATES.JOB_NUMBER = V_CONSTAT_BASE_DATES.JOB_NUMBER\n                    AND V_CONSTAT_PROJ_DATES.JOB_NUMBER = V_CONSTAT_BASE_DATES.JOB_NUMBER\n        INNER JOIN homefront.dbo.V_CONSTAT_SCH_DATES V_CONSTAT_SCH_DATES ON V_CONSTAT_BASE_DATES.JOB_NUMBER = V_CONSTAT_SCH_DATES.JOB_NUMBER\n                    AND V_CONSTAT_PROJ_DATES.JOB_NUMBER = V_CONSTAT_SCH_DATES.JOB_NUMBER\n                    AND V_CONSTAT_ACTUAL_DATES.JOB_NUMBER = V_CONSTAT_SCH_DATES.JOB_NUMBER\n  WHERE V_CONSTAT_ACTUAL_DATES.AREA_DESC = \'Ancaster Augusta Ph 4(A) Condos\'\n        AND V_CONSTAT_ACTUAL_DATES.DATE_TO_END >= GETDATE()\n  ) AS d\nORDER BY\n      V_CONSTAT_ACTUAL_DATES.DATE_TO_END\nFOR xml PATH (\'\'), ROOT (\'Root\')\n']], ['SQL ROW_NUMBER() always return 1 for each row'], 3, 1], [(37624090, 1), [['First lets determine difference between consecutive rows sorted by time:'], ['Then find minimum over all diffs for a given type:']], [[' // Partition by type and sort by time\nval w1 = Window.partitionBy($"Type").orderBy($"Time")\n\n// Difference between this and previous\nval diff = $"time" - lag($"time", 1).over(w1)\n']], ['Adding an extra column that represents the difference between the closest difference of a previous column'], 4, 0], [(37624090, 2), [['Then find minimum over all diffs for a given type:'], ['If your goal is to find a minimum distance between current row and any other row in a group you can use a similar approach ']], [[' // Partition by time unordered and take unbounded window\nval w2 = Window.partitionBy($"Type").rowsBetween(Long.MinValue, Long.MaxValue)\n\n// Minimum difference over type\nval minDiff = min(diff).over(w2)\n\ndf.withColumn("min_diff",  minDiff).show\n\n\n// +----+----+--------+\n// |type|time|min_diff|\n// +----+----+--------+\n// |   A| -10|       4|\n// |   A|   1|       4|\n// |   A|   5|       4|\n// |   B|   3|       6|\n// |   B|   9|       6|\n// +----+----+--------+\n']], ['Adding an extra column that represents the difference between the closest difference of a previous column'], 4, 0], [(37624090, 3), [['If your goal is to find a minimum distance between current row and any other row in a group you can use a similar approach '], ['-10000']], [[' import org.apache.spark.sql.functions.{lead, when}\n\n// Diff to previous\nval diff_lag = $"time" - lag($"time", 1).over(w1)\n\n// Diff to next\nval diff_lead = lead($"time", 1).over(w1) - $"time"\n\nval diffToClosest = when(\n  diff_lag < diff_lead || diff_lead.isNull, \n  diff_lag\n).otherwise(diff_lead)\n\ndf.withColumn("diff_to_closest", diffToClosest)\n\n// +----+----+---------------+\n// |type|time|diff_to_closest|\n// +----+----+---------------+\n// |   A| -10|             11|\n// |   A|   1|              4|\n// |   A|   5|              4|\n// |   B|   3|              6|\n// |   B|   9|              6|\n// +----+----+---------------+\n']], ['Adding an extra column that represents the difference between the closest difference of a previous column'], 4, 1], [(37648860, 0), [['Assuming that your main table is:'], ['We can use the below query:']], [[' create table mydata\n(ReportDate date,\n department varchar2(20),\n Employee varchar2(20));\n']], ['Summary data even when department is missing for a day'], 2, 0], [(37661098, 0), [['By using  NULLIF  you can achieve it.'], ['Result']], [[" SELECT  Id, STUFF(COALESCE(N',' + NULLIF(Name1, ''), N'') + COALESCE(N',' + NULLIF(Name2, ''), N'')\n              + COALESCE(N',' + NULLIF(Name3, ''), N''), 1, 1, '') AS ConcateStuff\nFROM    #Temp;\n"]], ['Concatenate several columns as comma-separated string'], 2, 1], [(37661098, 1), [['Result'], ['-10000']], [[' Id  ConcateStuff\n-----------------\n1   Name1,Name3\n2   Name1,Name2,Name3\n3   Name3\n4   Name3\n']], ['Concatenate several columns as comma-separated string'], 2, 0], [(37662540, 0), [["With further thought I imagine you could use an EXEC statement to generate the SQL needed for a particular hierarchy level, rather than generating manually as below (which will have some optimisations as e.g. we know if an entry does not have anything at L3 it won't have anything at L4 either)."], ['Results (apologies for bad formatting):']], [[" WITH resultset (resultid, parentid, valuex) AS (\nSELECT 1,0,'Grandparent' UNION ALL\nSELECT 2,1,'Parent1' UNION ALL\nSELECT 3,1,'Parent2' UNION ALL\nSELECT 4,2,'Child1' UNION ALL\nSELECT 5,2,'Child2' UNION ALL\nSELECT 6,3,'Child3' UNION ALL\nSELECT 7,3,'Child4' UNION ALL\nSELECT 8,4,'Child1_Child1' UNION ALL\nSELECT 9,7,'Child4_Child1' UNION ALL\nSELECT 10,6,'Child3_Child1')\nSELECT l1.resultid , l1.parentid, l1.valuex, l2.resultid l2val, l3.resultid l3val,l4.resultid l4val,\n\n-- rewrite COALESCE so clearer how this matches the pattern below\nCASE WHEN l4.resultid IS NULL THEN\nCASE WHEN l3.resultid IS NULL THEN\nCASE WHEN l2.resultid IS NULL THEN l1.valuex \nELSE l2.valuex END\nELSE l3.valuex END\nELSE l4.valuex END o1,\n\nCASE WHEN l4.resultid IS NULL THEN \nCASE WHEN l3.resultid IS NULL THEN \nCASE WHEN l2.resultid IS NULL THEN '' \nELSE l1.valuex END\nELSE COALESCE (l2.valuex, l1.valuex, '') END\nELSE COALESCE (l3.valuex, l2.valuex, l1.valuex, '') END o2,\n\nCASE WHEN l3.resultid IS NULL THEN ''\nWHEN l4.valuex IS NULL THEN l1.valuex\nELSE l2.valuex END o3,\n\nCASE WHEN l2.valuex IS NULL THEN '' \nWHEN l4.valuex IS NULL THEN '' ELSE l1.valuex END o4\n\nFROM resultset l1\nleft join resultset l2 on l1.parentid = l2.resultid\nleft join resultset l3 on l2.parentid = l3.resultid\nleft join resultset l4 on l3.parentid = l4.resultid\nORDER BY o1, o2, o3, o4\n"]], ['Order by (parent, child group) and values alphabetically'], 2, 1], [(37662540, 1), [['Results (apologies for bad formatting):'], ['-10000']], [[' RESULTID    PARENTID    VALUEX          L2VAL   L3VAL   L4VAL   O1          O2      O3      O4\n    1       0           Grandparent     (null)  (null)  (null)  Grandparent         \n    2       1           Parent1         1       (null)  (null)  Grandparent Parent1     \n    4       2           Child1          2       1       (null)  Grandparent Parent1 Child1  \n    8       4           Child1_Child1   4       2       1       Grandparent Parent1 Child1  Child1_Child1\n    5       2           Child2          2       1       (null)  Grandparent Parent1 Child2  \n    3       1           Parent2         1       (null)  (null)  Grandparent Parent2     \n    6       3           Child3          3       1       (null)  Grandparent Parent2 Child3  \n    10      6           Child3_Child1   6       3       1       Grandparent Parent2 Child3  Child3_Child1\n    7       3           Child4          3       1       (null)  Grandparent Parent2 Child4  \n    9       7           Child4_Child1   7       3       1       Grandparent Parent2 Child4  Child4_Child1\n']], ['Order by (parent, child group) and values alphabetically'], 2, 0], [(37685156, 0), [['1st attempt:'], ['Second attempt:']], [[' With CTE AS (\nselect id, name, date, connect_by_root name as "Group",\nROW_NUMBER() over (partition by connect_by_root name order by ID ) RN\nfrom myTable\nwhere connect_by_isleaf = 1\nstart with parentid = 0\nconnect by prior id = parentid)\nSelect * from cte where RN <= 2\n']], ['How to limit the number of rows returned for each group'], 2, 1], [(37685156, 1), [['Second attempt:'], ['-10000']], [[' With CTE AS (\nselect id, name, date, connect_by_root name as "Group" from myTable\nwhere connect_by_isleaf = 1\nstart with parentid = 0\nconnect by prior id = parentid),\n\nCTE2 as (Select A.*, \n        Row_number() over (partition by Group order by ID) RN from CTE A)\nSelect * from cte2 where RN <= 2\n']], ['How to limit the number of rows returned for each group'], 2, 1], [(37691287, 0), [['You need to order better by  ID  than  post_date  or  post_author  excluding admin  post_author>1 :'], ['-10000']], [[" SELECT *\nFROM `wp_posts` \nWHERE `post_author` != 1 \nAND `post_status` = 'publish'\nAND `post_type` = 'my_custom_type' \nGROUP BY `post_author` \nORDER BY `ID` DESC, `post_author` ASC LIMIT 5\n"]], ['SQL: Wordpress users ordered by the date of their latest post (CPT)'], 2, 1], [(37691287, 1), [['-10000'], ["author_count  is the generated column that counts total  'published'  posts, with a  'post_type' = 'my_custom_type'  for each selected author."]], [[" select t1.*, t2.author_count\nfrom `wp_posts` t1\ninner join (\n    select max(`ID`) as `ID`, `post_author`, count(1) as author_count\n    from `wp_posts`\n    where `post_author` != '1'\n    and `post_status` = 'publish'\n    and `post_type` = 'my_custom_type'\n    group by `post_author`\n) t2 on t1.`ID` = t2.`ID` and t1.`post_author` = t2.`post_author` \norder by t1.`ID` desc limit 5\n"]], ['SQL: Wordpress users ordered by the date of their latest post (CPT)'], 2, 1], [(37712305, 0), [['Oracle Setup :'], ['Query :']], [[' CREATE TABLE table_name ( value ) AS\nSELECT 0.004722222222222222222222222222222222222223 FROM DUAL UNION ALL\nSELECT 3.12383101851851851851851851851851851851 FROM DUAL UNION ALL\nSELECT 0.000856481481481481481481481481481481481479 FROM DUAL UNION ALL\nSELECT 0.002592592592592592592592592592592592592593 FROM DUAL UNION ALL\nSELECT 0.001041666666666666666666666666666666666667 FROM DUAL;\n']], ['How do I convert a decimal representation of Days into the number of hours and minutes in Oracle SQL?'], 5, 0], [(37712305, 2), [['Output :'], ['Query 2 :']], [[" NUMTODSINTERVAL(VALUE,'DAY')\n----------------------------\n0 0:6:48.0                   \n3 2:58:19.0                  \n0 0:1:14.0                   \n0 0:3:44.0                   \n0 0:1:30.0                   \n"]], ['How do I convert a decimal representation of Days into the number of hours and minutes in Oracle SQL?'], 5, 0], [(37712305, 4), [['Output :'], ['-10000']], [[' PERIOD\n------------------------------------\n6 Minutes 48 Seconds\n3 Days 2 Hours 58 Minutes 19 Seconds\n1 Minutes 14 Seconds\n3 Minutes 44 Seconds\n1 Minutes 30 Seconds\n']], ['How do I convert a decimal representation of Days into the number of hours and minutes in Oracle SQL?'], 5, 0]]